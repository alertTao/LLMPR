,text,summary
0,"<desc> when service type is nodeport, install will failed with error: render error in ""graylog/templates/notes.txt"": template: graylog/templates/notes.txt:9:131: executing ""graylog/templates/notes.txt"" at <{{template ""fullname...>: template ""fullname"" not defined dco signed </desc> <cmt> [stable/graylog] add namespace in notes.txt when get secret </cmt> <cmt> [stable/graylog] increase chart version to 0.1.2 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> [stable/graylog] fix error when service type is nodeport </cmt>",fix notes.txt when service type is nodeport
1,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: formidablelabs/react-swipeable#103 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> add rotationangle prop </cmt> <cmt> add rotationangle prop to test </cmt>",add rotationangle prop to react-swipeable
2,"<desc> set max-width on search box and selection area pinned the ""clear"" icon to the top right on multiple selects fixes #5863. </desc> <cmt> switch clear button to no longer be floated </cmt> <cmt> this also adds a consistent padding to the right side of the selection </cmt> <cmt> area to allow the clear button to be absolutely positioned on the right </cmt> <cmt> side without having to worry about it colliding with one of the </cmt> <cmt> selected elements. this is not ideal since it always shows up, even </cmt> <cmt> when the clear button is not enabled. this is also not ideal since </cmt> <cmt> it maintains the padding for the second row and beyond, even though </cmt> <cmt> the clear button is not visible on those rows. </cmt> <cmt> we can see if we can work through those issues later. but for now </cmt> <cmt> it's working consistent in both chrome and ie. </cmt> <cmt> set max-width to 100% on search box </cmt> <cmt> this should keep the search box set so it does not overflow the </cmt> <cmt> container that it is held within. so when people search for incredibly </cmt> <cmt> long strings, it properly maintains width and does not break out of </cmt> <cmt> the container and cause rendering issues. </cmt> <cmt> set max-width on the individual selections </cmt> <cmt> this sets the max width on the individual selections such that </cmt> <cmt> selections with abnormally long width will not exceed the size of </cmt> <cmt> the container and break rendering. in order to remain consistent with </cmt> <cmt> how the display is done for a single select, we do not allow the </cmt> <cmt> contents of selection in a multiple select to break across lines. </cmt> <cmt> in order to fix a rendering issue that occurs when the overflow </cmt> <cmt> is set to anything other than visible on the list item, we set </cmt> <cmt> vertical-align to baseline to ensure that all of the list items </cmt> <cmt> are vertically aligned to the same location. if we don't set this, a </cmt> <cmt> channel that is roughly 5px tall starts to form between the rows. it's </cmt> <cmt> not clear what causes this channel to form but the current solution </cmt> <cmt> for working around it is to correct the vertical alignment which </cmt> <cmt> appears to cause it to collapse and not form. </cmt> <iss> 4.1.0 beta text wrapping or not aligned. </iss>",fix long text causing the search box and selections to overflow on multiple selects
3,"<desc> original pull-request #14203 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix issue #14202 </cmt> <cmt> testcase for issue 14202 </cmt> <cmt> fix issue #14202 </cmt>",cherry pick #14203 to 20.6: fix issue #14202
4,"<desc> in general the behavior of window stores with retainduplicates is not well documented or enforced, so we should attempt to clarify things better in the javadocs and in the code itself. this explicitly skips the put/delete when the value is null and duplicates are allowed, and specifies this behavior in the docs. also adds in a test i left out in the earlier pr #8564 </desc> <cmt> add missing test, clarify nulls in jvadocs </cmt> <cmt> skip delete with duplicates </cmt>",explicit handling of null values with retainduplicates
5,<desc> continuation of #36142 todo: during the merge i removed the import gymnastics from pandas/core/arrays/string_arrow.py. we added since arrowstringdtype should always be available. i think this is no longer the case and we want to move the import checks to stringdtype. i expect envs without pyarrow to fail for now. test_arrow_roundtrip is failing. stringdtype.__from_arrow__ needs updating. address @jorisvandenbossche comments #36142 (comment) and #36142 (comment) some other test failures assertionerror: assert 'unknown-array' == 'string' </desc> <cmt> implement basedtypetests for arrowstringdtype </cmt> <cmt> refactor to use parametrized stringdtype </cmt> <cmt> abs-imports </cmt> <cmt> post merge fixup </cmt>,stringdtype parameterized by storage (python or pyarrow)
6,"<desc> this adds bilinear filtering mode for the texture sampler, adds an option to the texture menu in 3dfileviewer to set magnification filters and allows zooming in/out via mouse wheel. </desc> <cmt> libgl: implement gl_linear texture filter </cmt> <cmt> 3dfileviewer: add magnification filters to texture menu </cmt> <cmt> 3dfileviewer: allow zooming via mouse wheel </cmt>",add bilinear texture sampling and more texture options for 3dfileviewer
7,"<desc> these two patches add regulators for the cs42448 codec, constrain the sample rates and add a hard reset gpio for the sound card. </desc> <cmt> audioinjector addons dts : add reset and regulators for the octo product. </cmt> <cmt> this patch adds a reset gpio for the audioinjector.net octo sound card. </cmt> <cmt> this patch adds missing regulators for the cs42448 codec. </cmt> <cmt> audioinjector octo : consolidate sample rates and add a codec reset. </cmt> <cmt> this patch consolidates the sample rates which the audioinjector.net octo </cmt> <cmt> sound card can use. the consolidation of sample rates are due to the </cmt> <cmt> capabilities of the cs42448 codec. </cmt> <cmt> this codec also requires a hard reset using the gpio pin 5 upon probe. </cmt>","audioinjector octo sound card, updates"
8,"<desc> optunasearch accepts both distribution dictionary or define-by-run as a definition for the search space. the latter should not be used, when evaluated_rewards is provided. creation of trials in optuna only allows the distribution strategy. this pr adds docs for this case and provides a meaningful error when define-by-run is used with evaluated_rewards closes #18587 i've run scripts/format.sh to lint the changes in this pr. i need some guidance how to run the tests. is there guidance on how to execute the tests? installing the dependencies inside the python folder and running python -m unittest fails to execute the tests: importerror: failed to import test module: ray. </desc> <cmt> [tune]: optunasearch check space compatibility </cmt> <cmt> run scripts/format.sh </cmt> <iss> [tune]: optunasearch define-by-run space incompatible with evaluated_rewards </iss>",check compatibility of search space with evaluated_rewards
9,<desc> make sure batch_size is correct for gpt2 and ctrl - these models need a slightly different behavior since the shape of input_ids can change depending on whether the past variable is inserted or not. see also: pr: #3033 and its issue: #3031 </desc> <cmt> fix issue 3289 </cmt> <cmt> fix attention mask if input_ids none behavior </cmt> <iss> gpt-2 attention_mask reshaping uses input_ids first dimension </iss>,fix input ids can be none attn mask
10,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> adding redux reliance </cmt> <cmt> adding redux reliance </cmt>",update wepy-redux typing to add getstore / setstore
11,"<desc> add @spiorder support and apply precedence support for transport spi (commandcenter, heartbeatsender). none add a @spiorder annotation to indicate precedence. also update spiloader to support get the spi with the highest precedence. add precedence support for transport spi (commandcenter, heartbeatsender). two providers now will choose the instance with the highest precedence. run a demo, put with two different transport modules, then see whether the spi of higher order is activated. none </desc> <cmt> add @spiorder annotation and update spi loader for loading spi with highest precedence </cmt> <cmt> make commandcenterprovider and heartbeatsenderprovider choose the instance with highest precedence </cmt>",add spi precedence support and apply for transport spi
12,"<desc> currently it is not easily possible to distinguish between unmatched subpatterns (i.e. unset substrings) and empty matches in preg_match(_all); in both cases an empty string is yielded. using preg_offset_capture makes that possible (negative offset indicate unmatched subpatterns), but that seems to be unnecessarily clumsy. in bug #61780 it has been proposed not to set the respective keys in $matches, but that might be too big a bc break even for php 7.0.0. setting those to null, however, might be acceptable, and would still allow to distinguish between the two cases (even with isset). therefore i think this pr would resolve bug #61780. </desc> <cmt> added failing tests for bug #61780 </cmt> <cmt> changed preg_*() to yield null instead of '' for unset substrings </cmt> <cmt> adjusted other tests to cater to changed behavior </cmt> <cmt> added test to clearly show distinction between unset (aka unmatched) subpattern and an empty match </cmt>",distinguish between unmatched subpatterns and empty matches in preg_*()
13,"<desc> this is related to #28898. this pr implements pooling of bytes arrays when reading from the wire in the http server transport. in order to do this, we must integrate with netty reference counting. that manner in which this pr implements this is making pages in inboundchannelbuffer reference counted. when we accessing the underlying page to pass to netty, we retain the page. when netty releases its bytebuf, it releases the underlying pages we have passed to it. </desc> <cmt> work on implementing reference counting for http reading </cmt> <cmt> wip </cmt> <cmt> hook up reference counting </cmt> <cmt> add tests </cmt> <cmt> change names </cmt>",add byte array pooling to nio http transport
14,"<desc> hi, i am the author of the docker-registry-frontend web app. it is a web application for browsing and manipulating a docker registry by using the docker registry api and not the docker remote api. that is why i've create an extra page in the docker documentation under ""reference -> docker registry api client libraries"". this is where i started listing libraries and webapps just like on the ""reference -> docker remote api client libraries"". the only exception is that those libraries deal with the docker registry api. please, accept my pull request or let me know what else i can do for the pr to be accepted. since i only edited a few lines in the documentation, i consider my changes an exception to the normal contribution guidelines. but let me know if you think different. thank you in advance konrad </desc> <cmt> create registry_api_client_libraries.md </cmt> <cmt> add registry_api_client_libraries.md to mkdocs.yml </cmt>",improve docs with note about registry frontend web app
15,"<desc> former  #6447 by @tomoaki0705 what does this pr change? allow user to pack 32 bit float data in to 16bit float data (half) check compiler support check hw support before executing add test doing round trip conversion from / to fp32 treat array correctly if size is not multiple of 4 add declaration to prevent warning </desc> <cmt> add feature to convert fp32(float) to fp16(half) </cmt> <cmt> * check compiler support </cmt> <cmt> * check hw support before executing </cmt> <cmt> * add test doing round trip conversion from / to fp32 </cmt> <cmt> * treat array correctly if size is not multiple of 4 </cmt> <cmt> * add declaration to prevent warning </cmt> <cmt> * make it possible to enable fp16 on 32bit arm </cmt> <cmt> * let the conversion possible on non-supported hw, too. </cmt> <cmt> * add test using both hw and sw implementation </cmt> <cmt> follow other interface </cmt> <cmt> * remove usehw option </cmt> <cmt> * update test </cmt> <cmt> fix warning of doc </cmt> <cmt> * update the comment to real header </cmt> <cmt> fix cmake </cmt> <cmt> * enable fp16 feature correctly with gcc on x86/x86_64 </cmt> <cmt> fix corner case when number is small </cmt> <cmt> fix warning </cmt> <cmt> fix to support wider compiler </cmt> <cmt> * check compiler more strictly </cmt> <cmt> * use gcc version of fp16 conversion if it's possible (gcc 4.7 and later) </cmt> <cmt> * use current sw implementation in other cases </cmt> <cmt> fix run time error on mac </cmt> <cmt> * integrate hw version and sw version to same function </cmt> <cmt> fix warning of build </cmt> <cmt> fix run time error </cmt>",add feature to convert fp32(float) to fp16(half) using hw instructions
16,<desc> this pull request does the following: updates the windows 8.1 universal app cpp-templates to not display the messagebox when the close button is press. updates the app termination code to call cleanup() on the angle opengles context. this correctly shuts down the windows store app. updates external/config.json version to version to v3-deps-44 updated to correctly configure angle to automatically call trim() on the directx device when the app is suspended. this is a requirement to pass windows app certification testing. this pull request depends upon the pull request cocos2d/cocos2d-x-3rd-party-libs-bin#130. this pull request will not build until the cocos2d-x-3rd-party-libs-bin request is pulled. </desc> <cmt> removed cc_platform_winrt code. it is now allowed to exit a winrt app </cmt> <cmt> added  egl_platform_angle_enable_automatic_trim_angle </cmt> <cmt> made cleanup() public </cmt> <cmt> cleaned up draw() </cmt> <cmt> cleaned up draw() </cmt> <cmt> need to call cleanup() if app is terminating </cmt> <cmt> update windows 8.1 univeral app cpp-template files </cmt> <cmt> updated version to v3-deps-44 </cmt>,v3 winrt fix to update angle and correctly handle app termination
17,"<desc> merge master into types-2.0 as of 07/28 </desc> <cmt> changed atomicblockutils and keybindingutil from interfaces to classes with static functions (#10324) </cmt> <cmt> fixing a few minor issues in webpack-stream. (#10253) </cmt> <cmt> document changes in 0.28 and 0.29 in react native (#10309) </cmt> <cmt> * rn: widen limit of refreshcontrol </cmt> <cmt> * rn: update navigationexperimental to 0.28 </cmt> <cmt> * rn: define new method from 0.28 </cmt> <cmt> * rn: promisify requestpermissions per 0.28 </cmt> <cmt> * rn: remove onnavigate method </cmt> <cmt> see: </cmt> <cmt> * rn: add onnavigateback method </cmt> <cmt> see: </cmt> <cmt> * rn: deprecate statusbarios </cmt> <cmt> * rn: update stylesheet api per 0.29 </cmt> <cmt> * rn: define keyboardavoidingview added in 0.29 </cmt> <cmt> * rn: define savetocameraroll added in 0.29 </cmt> <cmt> * rn: define cancellable from interactionmanager </cmt> <cmt> * rn: add new possible values of flexdirection </cmt> <cmt> * rn: define linebreakmode </cmt> <cmt> * rn: allow zindex prop </cmt> <cmt> * rn: allow dimension limits </cmt> <cmt> * rn: specify type of refreshcontrol </cmt> <cmt> * rn: mark properties as optional </cmt> <cmt> * rn: clarify parameter naming </cmt> <cmt> * rn: mark optional property as optional </cmt> <cmt> * rn: definite explicit ref type </cmt> <cmt> * rn: restore stylesheet.create to restore compatibility </cmt> <cmt> added headers constructor options to whatwg-fetch (#10313) </cmt> <cmt> impl: updated definitions for oracledb (#10323) </cmt> <cmt> update select2 to have selectonclose option (#10326) </cmt> <cmt> option documented at </cmt> <cmt> added definition for react-file-input react component (#10325) </cmt> <cmt> * added definition for react-file-input react component </cmt> <cmt> * added newline at end of file </cmt> <cmt> added definitions for the react-file-reader-input react component. (#10327) </cmt> <cmt> sleep (#10333) </cmt> <cmt> add electron specific versions to process.versions (#10320) </cmt> <cmt> fix uuid.js definitions. (#10318) </cmt> <cmt> protobufjs: updated message interfaces (#10198) </cmt> <cmt> * protobufjs: updated message interfaces </cmt> <cmt> * added protobuf.util interface </cmt> <cmt> * fixed load functions of protobuf namespace </cmt> <cmt> base on the protobuf.js api docmentation. </cmt> <cmt> * use {} instead of object </cmt> <cmt> fixed according to pr commit note. </cmt> <cmt> multiple minor fixes (#10339) </cmt> <cmt> * better typing of onshouldstartloadwithrequest in webviewpropertiesios </cmt> <cmt> * fixes to webviewproperties </cmt> <cmt> * missing methods in navigator </cmt> <cmt> * fix of platform.select() </cmt> <cmt> * added support for interfacing with native-modules </cmt> <cmt> * added support for interfacing with native-modules </cmt> <cmt> * added dev variable </cmt> <cmt> * update to header notes </cmt> <cmt> * examples: alternative styles declaration </cmt> <cmt> webcomponents.js: add typings for element.createshadowroot (#10330) </cmt> <cmt> * webcomponents.js: add typings for element.createshadowroot </cmt> <cmt> createshadowroot is deprecated in the official shadow dom spec, </cmt> <cmt> but is the way to attach a shadow root in the current released </cmt> <cmt> version of webcomponents.js. </cmt> <cmt> * webcomponents.js: remove spurious extra line </cmt> <cmt> * webcomponents.js: remove readonly modifier </cmt> <cmt> not supported until ts2. </cmt> <cmt> * webcomponents.js: add element.shadowroot property </cmt> <cmt> adding a couple missing highcharts properites (#10340) </cmt> <cmt> * adding a couple missing highcharts properites </cmt> <cmt> * fixing indentation </cmt> <cmt> * indentation </cmt> <cmt> # conflicts: </cmt> <cmt> #	fetch-mock/fetch-mock-tests.ts </cmt> <cmt> #	react/index.d.ts </cmt> <cmt> move change from master to its corresponding index.d.ts </cmt>",merge master into release-2.0 on 07/28
18,"<desc> this pr includes: a ""nav layer"" to allow hjkl arrow keys while holding spacebar. in a previous commit, the keymap macro was changed to point to keymap_mit, which broke my offset spacebar. i redefine keymap in my keymap.c file now. minor changes to jj40.c so that compilation doesn't break if you have rgblight_enable = no. a keymap-specific rules.mk and config.h for oscillope. </desc> <cmt> add navigation layer for hjkl arrow keys </cmt> <cmt> fix oscillope keymap after jj40.h changes. also fix jj40.c so that it can build without rgblight if you don't want that enabled. </cmt>",fixes for jj40 and oscillope keymap
19,"<desc> this patch serie also takes in account @serhiy-storchaka review on my previous pr #1513. </desc> <cmt> regrtest: add --slowest alias to --slow </cmt> <cmt> make buildbottest: add --slowest option </cmt> <cmt> regrtest: add ""- "" prefix to --slowest output </cmt> <cmt> regrtest: fix an outdated comment </cmt> <cmt> regrtest: replace permissionerror </cmt> <cmt> replace permissionerror with oserror and check on exc.errno. </cmt> <cmt> permissionerror was added to python 3.3. </cmt> <cmt> regrtest: add -3 -tt options to run python scripts </cmt> <cmt> regrtest: backport --list-tests option </cmt> <cmt> regrtest: backport ""tests result: xxx"" summary </cmt> <cmt> regrtest: backport total duration </cmt> <cmt> regrtest: add timestamp to the progress </cmt> <cmt> regrtest: describe previous test state </cmt> <cmt> * add the state of the test: passed, failed, etc. </cmt> <cmt> * if a test took longer than 30 seconds, log its execution time </cmt> <cmt> regrtest: -jn logs running workers </cmt>",backport regrtest features from master to 2.7
20,<desc> rewrites all the tests for the line chart type for the new metadata structure in #2346 note: test must be re-enabled in gulpfile.js </desc> <cmt> rewrite line chart tests to match new metadata structure </cmt> <cmt> change spaces to tabs in line tests </cmt>,update line tests to match new metadata system
21,"<desc> this pr has enhancements to the reporter (in gatsby cli) and ""local reporter"" (in gatsby). the reporter class has added errormap -> plugins can register new structured errors in onpreinit by calling reporter.seterrormap </desc> <cmt> pass an error map to the reporter.error </cmt> <cmt> pass an error map to the reporter.error </cmt>",pass an errormap to reporter.error
22,"<desc> @mli, @zackchase, @madjam, @nswamy, @roshrini, @jiajiechen please review and merge </desc> <cmt> create markdown file for large scale image classification tutorial. </cmt> <cmt> add preprocessing instructions </cmt> <cmt> add some training instructions </cmt> <cmt> minor edit </cmt> <cmt> complete training section </cmt> <cmt> add some scalability data </cmt> <cmt> add speedup graph </cmt> <cmt> add troubleshooting guidelines </cmt> <cmt> minor edits </cmt> <cmt> minor fixes </cmt> <cmt> minor fixes </cmt> <cmt> minor fix </cmt> <cmt> minor fix </cmt> <cmt> minor fix </cmt> <cmt> minor fixes. </cmt>",tutorial for large scale image classification
23,"<desc> this pr is more documentation about: targeting cpu or gpu devices (in any configuration) using gpu_device_id and gpu_platform_id targeting intel hd graphics (by disabling dedicated gpus) opencl sdk correspondence with targets (intel, amd, nvidia) with examples (such as using intel sdk for opencl on amd gpus) requesting user to use default device for debugging to avoid useless issues (training on a device that does not exist) if someone has the ability to test the sdks on the other configurations, it would be great. </desc> <cmt> add gpu windows document link </cmt> <cmt> add gpu targeting and sdk correspondence table </cmt> <cmt> add targeting link </cmt> <cmt> request default targeting for debugging </cmt>","add more details about gpu (correspondence, targeting)"
24,"<desc> this adds partial support for the align-items property also a minor bug was fixed where a dimension of ""auto"" was seen as ""definite"" which is wrong. </desc> <cmt> libweb: add proper parsing of the alignitems property </cmt> <cmt> this teaches all the relevant places about 'align-items'. </cmt> <cmt> libweb: flexbox: make step 11 of the layout algorithm more align aware </cmt> <cmt> libweb: flexbox: somewhat suppport ""align-items"" </cmt> <cmt> there probably are a lot of edge cases missing but this moves us forward </cmt> <cmt> at least a bit. </cmt> <cmt> libweb: avoid setting definite {width,height} when ""auto"" is specified </cmt> <cmt> auto is not specified at all. </cmt>",support align items and stuff
25,"<desc> documentation states that ""return response::view('home', 200, $headers);"" can return a custom response with a view, a state code, and headers, but response::view() does not take a status code as the second parameter, and the third parameter is actually the view binding data. </desc> <cmt> update laravel/documentation/views/home.md </cmt> <cmt> response::view() does not take a status code as the second parameter. </cmt> <cmt> changed header to data </cmt>","removes status parameter for response::view() in documentation section ""views & responses"""
26,"<desc> rnpm-plugin-windows was using a dependency that it wasn't declaring. rather than having rnpm declare a specific react-native-community\cli dependency, which can cause issues since different rn versions require different versions of the cli. i changed the dependency to use another package. this also changes the cli to only prompt the vnext/legacy prompt when used against rn 0.59. since thats the only version that has a good legacy and vnext version. if the user it using >=0.60 we will automatically use the vnext version. microsoft reviewers: open in codeflow </desc> <cmt> fix cli dependency </cmt> <cmt> change files </cmt> <cmt> wrong version in package.json </cmt>",rnpm-plugin-windows fails when using npm
27,"<desc> it's extremely common, as evidenced by the commit in this pr of rails conversions, to set a default value for a class_attribute. so let's provide that directly. </desc> <cmt> allow a default value to be declared for class_attribute </cmt> <cmt> convert to using class_attribute default rather than explicit setter </cmt>",add option for class_attribute default
28,<desc> i have created an italian layout for the ergodox keyboard and wanted to share it. </desc> <cmt> added italian layout </cmt> <cmt> updated readme </cmt> <cmt> fixed italian kymap readme </cmt> <cmt> fixed layout title in ergodox ez italian keymap </cmt> <cmt> removed images from ergodox ez italian layout </cmt>,italian layout for ergodox keyboard
29,<desc> this removes import type usage from our core files since import type requires a higher typescript version than currently expected. fixes: #19300 </desc> <cmt> remove import type syntax </cmt> <iss> v10.0.2 causing a type error </iss>,remove import type syntax from core files
30,<desc> closes #13227 </desc> <cmt> feat: enable compat mode on test runner </cmt> <cmt> assert esm test modules are loaded as side modules </cmt> <cmt> check top level assertions cjs </cmt> <cmt> fix compat mode invocation on test runner </cmt> <cmt> add esm test with deno.test </cmt> <cmt> fix running cjs modules on compat mode </cmt> <iss> support compat mode in deno test </iss>,"add support for ""deno test --compat"""
31,"<desc> backport of #11143 fixes #11206 feature no no invalid absolute paths that produced an error before may know resolved correctly, but i won't consider this as breaking webpack supports options.resolve.roots option. defaults to options.context. if request is an server-relative url (starting with /)  webpack will try to resolve path.join(root[i], request) after trying to resolve the path as absolute path on non-windows systems </desc> <cmt> add roots option </cmt> <cmt> improve description in config schema </cmt>",backport of resolve.roots for webpack 4
32,"<desc> removes a further layer of indirection for calling python functions, by replacing _pyeval_evalcodewithname() which took a large an incoherent set of parameters with _pyeval_vector() which takes fewer than half the parameters, and is more efficient in the common case of calling a function. skipping news as this should have no visible effect on api or performance, nor does it fix any bugs. it just makes our life easier in the future. </desc> <cmt> further refactoring of pyeval_evalcode and friends. break into make-frame, and eval-frame parts. </cmt> <cmt> simplify function vector call using new _pyeval_vector. </cmt> <cmt> remove unused internal functions: _pyeval_evalcodewithname and _pyeval_evalcode. </cmt> <cmt> don't use legacy function pyeval_evalcodeex. </cmt> <cmt> further simplifications. </cmt> <cmt> fix up after rebase. </cmt> <cmt> remove locals from frame descriptor. make _pyeval_vector parameters more like other vector calls. </cmt>",further refactoring of pyeval_ functions.
33,"<desc> this allows to pass -1 with the simsetsegmentationobjectid api to turn off segmentation for the matched objects. see #776. </desc> <cmt> allow negative stencil values to turn off custom depth rendering </cmt> <cmt> this is useful when you don't want to have certain objects show up in the </cmt> <cmt> segmentation view, such as leaves on the floor. </cmt> <cmt> add documentation for unsetting object id </cmt>",allow to unset segmentation object id
34,"<desc> in the previous implementation of the editor we recycled dom nodes using a pool. during the rewrite we dropped this behavior to keep things simple but we've decided we are not comfortable shipping a component that produced this many nodes as garbage. below is an example of scrolling all the way to the top/bottom of a large file repeatedly. before: after: note the number of nodes (in green) has reduced from ~50k to ~5k (10x reduction). node consumption would be completely flat if not for the octicons being injected into every line number via ::before pseudo-elements in css. in the future it might be nice to revisit our approach to line number icons, but it's a too big project to take on right now. ed with @nathansobo. </desc> <cmt> recycle line nodes </cmt> <cmt> recycle line number nodes </cmt>",recycle line and line number dom nodes
35,"<desc> the regression tests discovered a couple ways in which #2276 and #2295 caused failures to correctly derive compression parameters. the regression test results now have a much smaller diff against v1.4.6: --- tests/regression/results.csv +++ results-eee51a66.csv @@ -26,4 +26,4 @@ -silesia,     level 5,           compress cctx,                4710237 -silesia,     level 6,           compress cctx,                4660057 -silesia,     level 7,           compress cctx,                4596295 -silesia,     level 9,           compress cctx,                4543924 +silesia,     level 5,           compress cctx,                4710236 +silesia,     level 6,           compress cctx,                4660056 +silesia,     level 7,           compress cctx,                4596296 +silesia,     level 9,           compress cctx,                4543925 @@ -39 +39 @@ -silesia,     explicit params,   compress cctx,                4794666 +silesia,     explicit params,   compress cctx,                4794677 @@ -90,4 +90,4 @@ -silesia,     level 5,           zstdcli,                      4710285 -silesia,     level 6,           zstdcli,                      4660105 -silesia,     level 7,           zstdcli,                      4596343 -silesia,     level 9,           zstdcli,                      4543972 +silesia,     level 5,           zstdcli,                      4710284 +silesia,     level 6,           zstdcli,                      4660104 +silesia,     level 7,           zstdcli,                      4596344 +silesia,     level 9,           zstdcli,                      4543973 @@ -103 +103 @@ -silesia,     explicit params,   zstdcli,                      4797100 +silesia,     explicit params,   zstdcli,                      4797112 @@ -129 +129 @@ -silesia.tar, explicit params,   zstdcli,                      4822354 +silesia.tar, explicit params,   zstdcli,                      4822362 @@ -149 +149 @@ -github,      level 5 with dict, zstdcli,                      40938 +github,      level 5 with dict, zstdcli,                      40741 @@ -180,4 +180,4 @@ -silesia,     level 5,           advanced one pass,            4710237 -silesia,     level 6,           advanced one pass,            4660057 -silesia,     level 7,           advanced one pass,            4596295 -silesia,     level 9,           advanced one pass,            4543924 +silesia,     level 5,           advanced one pass,            4710236 +silesia,     level 6,           advanced one pass,            4660056 +silesia,     level 7,           advanced one pass,            4596296 +silesia,     level 9,           advanced one pass,            4543925 @@ -194 +194 @@ -silesia,     explicit params,   advanced one pass,            4797086 +silesia,     explicit params,   advanced one pass,            4797095 @@ -220 +220 @@ -silesia.tar, explicit params,   advanced one pass,            4808581 +silesia.tar, explicit params,   advanced one pass,            4808589 @@ -272,4 +272,4 @@ -silesia,     level 5,           advanced one pass small out,  4710237 -silesia,     level 6,           advanced one pass small out,  4660057 -silesia,     level 7,           advanced one pass small out,  4596295 -silesia,     level 9,           advanced one pass small out,  4543924 +silesia,     level 5,           advanced one pass small out,  4710236 +silesia,     level 6,           advanced one pass small out,  4660056 +silesia,     level 7,           advanced one pass small out,  4596296 +silesia,     level 9,           advanced one pass small out,  4543925 @@ -286 +286 @@ -silesia,     explicit params,   advanced one pass small out,  4797086 +silesia,     explicit params,   advanced one pass small out,  4797095 @@ -312 +312 @@ -silesia.tar, explicit params,   advanced one pass small out,  4808581 +silesia.tar, explicit params,   advanced one pass small out,  4808589 @@ -364,4 +364,4 @@ -silesia,     level 5,           advanced streaming,           4710237 -silesia,     level 6,           advanced streaming,           4660057 -silesia,     level 7,           advanced streaming,           4596295 -silesia,     level 9,           advanced streaming,           4543924 +silesia,     level 5,           advanced streaming,           4710236 +silesia,     level 6,           advanced streaming,           4660056 +silesia,     level 7,           advanced streaming,           4596296 +silesia,     level 9,           advanced streaming,           4543925 @@ -378 +378 @@ -silesia,     explicit params,   advanced streaming,           4797100 +silesia,     explicit params,   advanced streaming,           4797112 @@ -404 +404 @@ -silesia.tar, explicit params,   advanced streaming,           4808608 +silesia.tar, explicit params,   advanced streaming,           4808618 @@ -456,4 +456,4 @@ -silesia,     level 5,           old streaming,                4710237 -silesia,     level 6,           old streaming,                4660057 -silesia,     level 7,           old streaming,                4596295 -silesia,     level 9,           old streaming,                4543924 +silesia,     level 5,           old streaming,                4710236 +silesia,     level 6,           old streaming,                4660056 +silesia,     level 7,           old streaming,                4596296 +silesia,     level 9,           old streaming,                4543925 @@ -524,4 +524,4 @@ -silesia,     level 5,           old streaming advanced,       4710237 -silesia,     level 6,           old streaming advanced,       4660057 -silesia,     level 7,           old streaming advanced,       4596295 -silesia,     level 9,           old streaming advanced,       4543924 +silesia,     level 5,           old streaming advanced,       4710236 +silesia,     level 6,           old streaming advanced,       4660056 +silesia,     level 7,           old streaming advanced,       4596296 +silesia,     level 9,           old streaming advanced,       4543925 @@ -538 +538 @@ -silesia,     explicit params,   old streaming advanced,       4797100 +silesia,     explicit params,   old streaming advanced,       4797112 @@ -564 +564 @@ -silesia.tar, explicit params,   old streaming advanced,       4808608 +silesia.tar, explicit params,   old streaming advanced,       4808618 @@ -630,4 +630,4 @@ -github,      level 5 with dict, old streaming advanced cdict, 39158 -github,      level 6 with dict, old streaming advanced cdict, 38748 -github,      level 7 with dict, old streaming advanced cdict, 38744 -github,      level 9 with dict, old streaming advanced cdict, 38992 +github,      level 5 with dict, old streaming advanced cdict, 39159 +github,      level 6 with dict, old streaming advanced cdict, 38749 +github,      level 7 with dict, old streaming advanced cdict, 38746 +github,      level 9 with dict, old streaming advanced cdict, 38993 i'm still not sure why the explicit params case is so slightly different. </desc> <cmt> pull cparam override logic into helper </cmt> <cmt> do more complete cparams deduction in non-ddss path of zstd_createcdict_advanced2 </cmt> <cmt> call zstd_getcparamsfromcctxparams() instead of zstd_getcparams_internal(). </cmt> <cmt> make zstd_createcdict_advanced2() cctxparams arg const </cmt> <cmt> fall back if derived cparams are incompatible with ddss; refactor cdict creation </cmt> <cmt> rewrite zstd_createcdict_advanced() as a wrapper around </cmt> <cmt> zstd_createcdict_advanced2(). evaluate whether to use ddss mode *after* fully </cmt> <cmt> resolving cparams. if not, fall back. </cmt>",fix compression parameter derivation bugs introduced by ddss changes
36,<desc> this nicely avoids any conflict in state appearing between the c++ code and the c code. </desc> <cmt> use the first received status as authoritative. </cmt> <cmt> so that later cancellations do not clobber status. </cmt> <cmt> update c++ code to set status via the c api. </cmt> <cmt> this prevents mismatches from breaking tests. </cmt> <cmt> libevent snuck in </cmt> <cmt> clang-format </cmt> <cmt> merge github.com:google/grpc into cppapi </cmt>,make the c++ api use c api calls to fiddle with status
37,<desc> fixing build </desc> <cmt> icp-8046 z-wave siren mistakenly always send 10 config commands </cmt> <cmt> this rework attempts to move away from a counter to a flag-based system based on receiving a config report with a correct value in it. </cmt> <cmt> icp-8046 z-wave siren mistakenly always send 10 config commands </cmt> <cmt> this rework attempts to move away from a counter to a flag-based system based on receiving a config report with a correct value in it. </cmt> <cmt> change check to an explicit null check in case of 0 config values </cmt> <cmt> fixes some small errors </cmt> <cmt> fix spaces </cmt> <cmt> remove magic numbers </cmt> <cmt> icp-8046 </cmt>,icp-8046 z-wave siren configuration rework
38,"<desc> (cherry-pick of #24805 to swift-5.1-branch reviewed by @benlangmuir) rdar://problem/50696432 </desc> <cmt> [codecompletion] enable context type analysis for implict member expression </cmt> <cmt> at argument part of implict member expression, we need context type </cmt> <cmt> analysis to complete arguments. </cmt> <cmt> rdar://problem/50696432 </cmt> <cmt> (cherry picked from commit 14d2f7c0a7e7de28bc4df7484e32b9238ae92f8f) </cmt> <cmt> conflicts: </cmt> <cmt> lib/ide/exprcontextanalysis.cpp </cmt> <cmt> [codecompletion] enable call signature completion for unresolved member </cmt> <cmt> rdar://problem/50696432 </cmt> <cmt> (cherry picked from commit 5b5d342995ff507abea38c43aff59d19dfe0f176) </cmt> <cmt> [codecompletion] look through applyexpr to get referenced decl </cmt> <cmt> for example: </cmt> <cmt> let x: myclass = .create(<#complete#>) </cmt> <cmt> this expression ends up with: </cmt> <cmt> (call_expr </cmt> <cmt> (dot_syntax_self_apply_expr </cmt> <cmt> (decl_ref_expr decl='c.create(_:arg1)' </cmt> <cmt> (type_expr type=myclass)))) </cmt> <cmt> so we need to look through 'dotsyntaxselfapplyexpr' to get the decl. </cmt> <cmt> (cherry picked from commit 557505d5996872c2f28397caf2e5280c722fe157) </cmt> <cmt> [codecompletion] add test cases for call arg completion </cmt> <cmt> static methods, implicit member. </cmt> <cmt> (cherry picked from commit e9e5134c32016e5e03d0e8a4eea44cc31f176e01) </cmt>",call argument completion for implicit member expression
39,"<desc> i also converted two tests from using thread::spawn(...).join() just for catching panics, to catch_panic, so that miri can run them. </desc> <cmt> enable panic-catching tests in miri </cmt> <cmt> use catch_panic instead of thread::spawn to catch panics </cmt> <cmt> enable panic-catching tests in miri </cmt> <cmt> enable more panic-catching tests in miri </cmt>",run panic-catching tests in liballoc
40,"<desc> ""summary_op"" is a tensor, so it's incorrectly labeled as an op. this change renames it to ""summary"", and makes the corresponding changes in the explanation. </desc> <cmt> ""summary_op"" -> ""summary"" in tutorial code </cmt> <cmt> ""summary_op"" is a tensor, so it's incorrectly labeled as an op. this change renames it to ""summary"", and makes the corresponding changes in the explanation. </cmt> <cmt> rename tensor ""summary_op"" to ""summary"" in tutorial </cmt> <cmt> ""summary_op"" is a tensor, so it's incorrectly labeled as an op. this change renames it to ""summary"", and makes the corresponding changes in the explanation. </cmt>","rename tensor ""summary_op"" to ""summary"" in the 101 tutorial"
41,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: setupintents and invoice_settings </desc> <cmt> stripe: added invoice_settings on customer </cmt> <cmt> stripe: added setupintents </cmt>,"added setupintents, and added invoice_settings on customer"
42,"<desc> in certain situations, a developer may require the border of a material to be painted behind its child. for example a card widget that has a full width image across the top half. in that scenario, the image should ideally be painted above the border with regards to z-position. this change exposes a flag on material widget to achieve this behavior. additionally, the same flag is exposed on card widget to allow the card widget to pass this down to its material. i added a couple golden tests to verify this new behavior. goldens are here: flutter/goldens@46a3d26 </desc> <cmt> expose a flag to set the position of border painting either below or above child widget for material </cmt> <cmt> tweak comments for new property </cmt> <cmt> add golden tests for new functionality </cmt> <cmt> update goldens.version </cmt>",add material/card borderonforeground flag to allow border to be painted behind the child widget
43,"<desc> ports #7952 to fix #7270 for typescript 1.8. @mhegazy @ryancavanaugh </desc> <cmt> use an emit helper for jsx spread attributes. </cmt> <cmt> remove unnecessary 'null'/'undefined' check, removed temp for args length. </cmt> <cmt> changed emit to use 'object.prototype.hasownproperty'. </cmt> <cmt> accepted baselines. </cmt>",port new '__assign' helper to typescript 1.8
44,<desc> these cherry-picks are needed to fix tflite arm pip build. </desc> <cmt> temporary disable xnnpack on armhf linux python wheel build </cmt> <cmt> piperorigin-revid: 411954096 </cmt> <cmt> change-id: i0464fe508d1a0d724799905c16acdf7a698c7f34 </cmt> <cmt> tflite_runtime: add a way to override wheel's platform name </cmt> <cmt> piperorigin-revid: 414570169 </cmt> <cmt> change-id: i853bd6725c54595e712977f12d6c14b3d610068d </cmt>,r2.7 cherry-picks to fix tflite arm pip build
45,"<desc> while developing a simple webapp displaying maintainers of a namespace, i found that some github id referenced in author field are nonexistent (for most of them: twitter username was used instead of github id). this pull request fix these invalid github id. several modules ansible version ansible-playbook 2.5.0 (devel 1d14016087) last updated 2017/10/17 18:36:56 (gmt +200) it remains some fields to fix: inexistent @rnh556 id (i am not sure if @rnh556 and @stealthllama are the same person): what should we do ? remove the invalid id ? ansible/lib/ansible/modules/network/panos/panos_nat_rule.py line 17 7623c2f author: ""luigi mori (@jtschichold), ivan bojer (@ivanbojer), robert hagen (@rnh556)"" ansible/lib/ansible/modules/network/panos/panos_object.py line 34 7623c2f author: ""bob hagen (@rnh556)"" ansible/lib/ansible/modules/network/panos/panos_security_rule.py line 23 7623c2f author: ""ivan bojer (@ivanbojer), robert hagen (@rnh556)"" @cloudengine-ansible (which is a repository) used in cloudengine modules </desc> <cmt> replace twitter username with github id </cmt> <cmt> see 8bfa19c4aff827c8b114732f0bd9193df73552bf </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see 22766906b036cc211447cc4d4c4d0ad64283edc4 </cmt> <cmt> fix github id: add missing letters </cmt> <cmt> see: </cmt> <cmt> - nxos_banner.py: 9c6ee8d0bb1419ee7748f6fb53ea78d9769f3f3a </cmt> <cmt> - nxos_logging.py: e37e736ddbc8a0fc4c9978dcf56eeee841332e3a </cmt> <cmt> - net_user.py: f6a4803669548f3c4fdfd8fc26b8264e46fdc1f1 </cmt> <cmt> remove nonexistent author, use github organization </cmt> <cmt> see </cmt> <cmt> not sure how ansibullbot will handle an organization id, but </cmt> <cmt> other deprecated modules already use it. </cmt> <cmt> replace twitter username with github id </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see bf59d1cc1ed8d778c17f0a15dda3c56d181f4aff </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see d02a9016a2e6023e0dce8d5ed7c0baacc1504e27 </cmt> <cmt> author: use github id </cmt> <cmt> see 0847bfecd672f6b2e0e4429e998df7c6e7042b1c </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see a59684fddda79f873595477355be24deb3a616fb </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see 94f9bb962f406497ec3648a5339b7e8526b2c9f6 </cmt> <cmt> replace twitter username with github id </cmt> <cmt> see 40b7dffea8a2486be324f135cc615c7d00a06ffe </cmt>",fix invalid github id in author field
46,"<desc> the argument animate doesn't reflect what the documentation says. it sounds like slick should animate when true is given, but it actually won't. the argument indicates whether slick should not apply animations, and so is named dontanimate. this pr conforms the naming to the original one. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. </desc> <cmt> rename the 3rd argument of slickgoto according to slick documentation </cmt> <cmt> - this option indicates whether slick should not apply animations on updating its position: </cmt> <cmt> add a test calling slickgoto to test the previously renamed argument </cmt>",rename argument of slickgoto according to the documentation
47,<desc> it might be useful for downstream projects to build from the current master without having to clone. this additional doc explains how. </desc> <cmt> updating docs with pip way to build from source </cmt> <cmt> wording </cmt>,adding documentation for building from current master without cloning.
48,<desc> use different socket path for win32 see:  also: </desc> <cmt> remove the skipping of the socket http test </cmt> <cmt> use different socket path for win32 </cmt> <cmt> - see: </cmt> <cmt> - also: </cmt> <cmt> updating axios in types to be lower case (#2797) </cmt>,use different socket for win32 test
49,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). documentation found here increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [@types/rpio] fix poll parameter to accept null </cmt> <cmt> as written in the poll function documentation the cb parameter should accept null as a value. </cmt> <cmt> update rpio-tests.ts </cmt> <cmt> add myself as contributor </cmt>",allow null as callback value for poll()
50,"<desc> hi all, links to the discussion and resolution of this nep have been added to the main document. thanks! </desc> <cmt> added discussion link to the mailing list thread. </cmt> <cmt> changing nep0044 status to accepted. </cmt>",move nep 44 to accepted status
51,"<desc> lots of cleanups become available after this.  i did some of that in the tests here, but left most of it for follow-ups to keep the diff manageable. </desc> <cmt> depr: disallow add/sub of timestamp, datetimeindex, timedeltaindex </cmt> <cmt> remove comment </cmt> <cmt> standardize on typeerror </cmt> <cmt> whatsnew </cmt>","integer add/sub for timestamp, datetimeindex, timedeltaindex"
52,<desc> we show an error when getstaticparams is added to a page without getstaticprops although the error was not being triggered when built in serverless mode. i also moved the test to it's own suite since it was only being tested for dev mode before </desc> <cmt> make sure to show missing getstaticprops error in serverless mode </cmt>,fix missing getstaticprops error in serverless mode
53,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> add encrypt and decrypt to pubnub types </cmt> <cmt> add comment for decrypt parameters </cmt>,add encrypt and decrypt methods
54,<desc> resolves #54655 for post-refactor valuessourceconfig.  will need a slightly different solution to backport to 7.7.x </desc> <cmt> test for value script that changes type </cmt> <cmt> prioritize user value type hints </cmt> <iss> value scripts that change the field type are broken </iss>,aggregation support for value scripts that change types
55,"<desc> add simple integration for junit, create sample test class. fix #21 improve process signal handling, make sure we terminate all spawned subprocesses </desc> <cmt> makes the timer a daemon thread. </cmt> <cmt> bumping version </cmt> <cmt> refactoring assume role function </cmt> <cmt> merged in bugfix/set-timer-to-daemon (pull request #27) </cmt> <cmt> makes the timer a daemon thread </cmt>",add junit integration + example test class
56,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. sortby: source code, docs hitsperpage: source code, docs menuselect: source code, docs searchbox: source code, docs </desc> <cmt> update props for sortby </cmt> <cmt> add props for hitsperpage </cmt> <cmt> add props for menuselect </cmt> <cmt> add inputid prop for searchbox </cmt> <cmt> add onkeydown to searchbox props </cmt> <cmt> add classname to updated props </cmt> <cmt> update react-instantsearch version comment </cmt>",update component props for v6.12
57,"<desc> so this pr adds a profile setting called ""confirmclosealltabs"", that allows one to enable or disable the ""do you want close all tabs?"" dialog that appears when you close a window with multiple open tabs. it current defaults to ""true"". also adds a checkbox to that dialog that also sets ""confirmclosealltabs"" closes #3883 cla signed. if not, go over here and sign the cla requires documentation to be updated i added a checkbox to the close dialog to set this setting, but i'm not sure how to best go about actually changing the setting from code; am open to suggestions, as to how it should be done, or if i should also just remove it and stick with the profile setting. set ""confirmclosealltabs"" to false in my profile.json file. opened a 2nd tab. closed the window observed that there was no confirmation before the window closed. set ""confirmclosealltabs"" to true repeat steps 2 and 3 observe that there was a confirmation before the window closed. </desc> <cmt> add option+checkbox to disable the ""do you want close all tabs?"" dialog. </cmt> <cmt> the word ""confirm"" has an ""r"" in it. *faceplam* </cmt> <iss> feature request: close on multiple tabs confirmation dialog being optional. </iss>",no more are you sure boxes
58,<desc> related issue: #37996 added some basic usage examples for models in keras.applications. the arguments were already added to the nightly so the changes made are: add example of extracting features using premade models fix the issue were argument option sublist was not at the right indent level reworded the pooling mode argument in models' description to be more concise add raises exception list where absent add doctest example of creating a model and what type of model it should return </desc> <cmt> add examples to vgg16 </cmt> <cmt> add examples to densenet models </cmt> <cmt> fix sub-list indent on argument list on models. </cmt> <cmt> add raise list to densenet models </cmt> <cmt> fix accidental typo on the added example densenet </cmt> <cmt> add examples to inception resnet v2 </cmt> <cmt> add examples to inceptionv3 </cmt> <cmt> add examples to mobilenet </cmt> <cmt> add examples to mobilenetv2 </cmt> <cmt> add examples to nasnet models </cmt> <cmt> add examples to resnet models </cmt> <cmt> add examples to resnetv2 models </cmt> <cmt> add examples to vgg19 </cmt> <cmt> add examples to xception model </cmt> <cmt> change keras to tensorflow.keras in added examples </cmt> <cmt> delete extra spaces from the changes & fix indent on sublists </cmt>,add usage examples and improve documentation on tf.keras.applications models
59,"<desc> two warnings fixed: incorrectly default'ing operator= in a struct with a const data member (removed the line) implicitly casting an int to a uint32_t; i suppose that ideally the cast shouldn't be necessary to begin with, but while it is still being done, better to have it explicit.  this also fixes a warning. </desc> <cmt> do not attempt to default operator= when it is implicitly deleted </cmt> <cmt> make an implicit cast from int --> uint32_t explicit. </cmt> <cmt> perhaps this casting should not happen to begin with, but better </cmt> <cmt> to make it explicit where it is happening for readability.  this </cmt> <cmt> fixes a compiler warning. </cmt>",fix some minor warnings found with a recent clang version
60,"<desc> build and run stress tests using java 17, as well as the existing java 11. the disruptor 4 will still target java 11 as the minimum requirement and not use any java 17 only features. this is just to check the project builds on java 17 and we don't introduce any code that is going to break in the next lts release. </desc> <cmt> fix javadoc header level </cmt> <cmt> jdk17 javadoc apparently won't let us use a h3 under a h1 </cmt> <cmt> jdk 17 requires fully qualified yield usage </cmt> <cmt> update gradle from 7.1 to 7.2 </cmt> <cmt> update gradle from asciidoctor plugin from 3.3.0 to 3.3.2 </cmt> <cmt> 3.3.0 did not support gradle 7.2, it got errors trying to find the grale-internal guava dependency </cmt> <cmt> add jdk 17 to github build/jcstress actions </cmt> <cmt> jdk 17 is the latest jdk version and, more importantly, an lts version. </cmt> <cmt> it could be nice ot know if the disruptor worked with it as well as jdk 11, the current target version. </cmt>",add use of java 17 to ci
61,<desc> modifying regular expressions ansible/modules/network/cloudengine/ce_vxlan_arp.py </desc> <cmt> update ce_vxlan_arp to fix bugs (#61995) </cmt> <cmt> * update ce_vxlan_arp to fix bugs </cmt> <cmt> * update ce_vxlan_arp to fix bugs </cmt> <cmt> (cherry picked from commit 12512f731984ecb5bacb750e555dc4ef697c2b12) </cmt> <cmt> update ce_vxlan_arp to fix bugs </cmt>,[backport/2.8/61995]update ce_vxlan_arp to fix bugs
62,"<desc> this establishes a real def-use relation from the self-parameter to any instruction which uses the dynamic-self type. this is an addition to what was already done for opened archetypes. the biggest part of this commit is to rename ""openedarchetypeoperands"" to ""typedependentoperands"" as this name is now more appropriate. other than that the change includes: *) type-dependent operands are now printed after a sil instruction in a comment as ""type-defs:"" (for debugging) *) funcationsignatureopts doesn't need to explicitly check if a function doesn't bind dynamic self to remove a dead self metadata argument *) the check if a function binds dynamic self (used in the inliner) is much simpler now *) also collect type-dependent operands for applyinstbase::substcalleetype and not only in the substitution list *) with this silinstruction::mayhaveopenedarchetypeoperands (used in cse) is not needed anymore and removed *) fixed a bug in the cloner: silbuilderwithpostprocess now inherits the openedarchetypestracker from it's original builder *) add type dependent operands to dynamic_method instruction regarding the generated code it should be a nfc. </desc> <cmt> fixed a bug in silcloner: silbuilderwithpostprocess now inherits the openedarchetypestracker from it's original builder </cmt> <cmt> sil: add the self-parameter to the list of type-dependent operands if an instruction uses the dynamic-self type. </cmt> <cmt> this establishes a real def-use relation from the self-parameter to any instruction which uses the dynamic-self type. </cmt> <cmt> this is an addition to what was already done for opened archetypes. </cmt> <cmt> the biggest part of this commit is to rename ""openedarchetypeoperands"" to ""typedependentoperands"" as this name is now more appropriate. </cmt> <cmt> other than that the change includes: </cmt> <cmt> *) type-dependent operands are now printed after a sil instruction in a comment as ""type-defs:"" (for debugging) </cmt> <cmt> *) funcationsignatureopts doesn't need to explicitly check if a function doesn't bind dynamic self to remove a dead self metadata argument </cmt> <cmt> *) the check if a function binds dynamic self (used in the inliner) is much simpler now </cmt> <cmt> *) also collect type-dependent operands for applyinstbase::substcalleetype and not only in the substitution list </cmt> <cmt> *) with this silinstruction::mayhaveopenedarchetypeoperands (used in cse) is not needed anymore and removed </cmt> <cmt> *) add type dependent operands to dynamic_method instruction </cmt> <cmt> regarding the generated code it should be a nfc. </cmt>","add the self-parameter to the list of type-dependent operands, 2nd try"
63,"<desc> for example, given the following code: template string with multiple lines specifying a range that includes only the first line will now result in both lines being formatted, since the node specified by the range stretches over both lines. before, there would be an error: syntaxerror: unterminated template (1:1) </desc> <cmt> move range extension code into helper functions </cmt> <cmt> add findnodebyoffset() helper </cmt> <cmt> this was adapted from </cmt> <cmt> test extending formatted range to entire node </cmt> <cmt> fix extending formatted range to entire node </cmt>",find nearest node when formatting range
64,"<desc> shippable.yml, ansible-test, integration tests </desc> <cmt> switch tests from rhel 7.5 to 7.6. </cmt> <cmt> (cherry picked from commit 6745ee7cc86c50f79b24fb701d1e4680320a576b) </cmt> <cmt> remove ci platform: freebsd/10.4 </cmt> <cmt> (cherry picked from commit e6ffc4f89a27853e2ce983bc51a982b5a138d1bd) </cmt> <cmt> support skip of platforms by version in tests. (#48826) </cmt> <cmt> * support skip of platforms by version in tests. </cmt> <cmt> previously a remote platform could be skipped completely using the alias: </cmt> <cmt> skip/{platform} such as skip/rhel </cmt> <cmt> now a specific platform version can be skipped using the alias: </cmt> <cmt> skip/{platform}{version} such as skip/rhel7.6 </cmt> <cmt> this feature is available for platforms specified with the --remote option. </cmt> <cmt> * add skip by version to the docs. </cmt> <cmt> (cherry picked from commit 8066acc90c13595039812bd8f9eb1fcaaca1a890) </cmt> <cmt> add --raw option to ansible-test shell command. </cmt> <cmt> it is currently supported only with the --remote option. </cmt> <cmt> this makes it easier to troubleshoot new instances which are not </cmt> <cmt> yet supported by the setup scripts used by ansible-test. </cmt> <cmt> (cherry picked from commit 0826a008039c45f4fcf2d428c9267decdaeb7de2) </cmt> <cmt> fix ansible-test skip warning message. </cmt> <cmt> (cherry picked from commit 3b705efc93fdf6553c05d139dfb49fe6a5aa6483) </cmt> <cmt> fix lookup_passwordstore test skipping. (#49178) </cmt> <cmt> * fix lookup_passwordstore test skipping. </cmt> <cmt> skip all of rhel instead of specific versions. </cmt> <cmt> skip all of centos < 7 instead of specific versions. </cmt> <cmt> this makes the test more robust when testing newer versions. </cmt> <cmt> tests could be executed on rhel if epel was installed during the test. </cmt> <cmt> (cherry picked from commit 704dae2cda5ef3a7303b37de7bb0004f0a2ba581) </cmt>",backport test infra updates and test fixes.
65,"<desc> added datacollatorforpermutationlanguagemodeling in data/data_collator.py to return necessary inputs (applies masking and generates revelant tensors input_ids, perm_mask, target_mask and labels as per  also looked into ctrl - it uses a clm loss just like gpt and gpt-2, so should work out of the box with this script (provided past is taken care of similar to mems for xlnet). added a few words in the comments to reflect this. changed calls and imports appropriately. resolves: #4739, #2008 (partially) </desc> <cmt> added data collator for xlnet language modeling and related calls </cmt> <cmt> added datacollatorforxlnetlanguagemodeling in data/data_collator.py </cmt> <cmt> to generate necessary inputs for language modeling training with </cmt> <cmt> xlnetlmheadmodel. also added related arguments, logic and calls in </cmt> <cmt> examples/language-modeling/run_language_modeling.py. </cmt> <cmt> resolves: #4739, #2008 (partially) </cmt> <cmt> changed name to datacollatorforpermutationlanguagemodeling </cmt> <cmt> changed the name of datacollatorforxlnetlanguagemodeling to the more general datacollatorforpermutationlanguagemodelling. </cmt> <cmt> removed the --mlm flag requirement for the new collator and defined a separate --plm_probability flag for its use. </cmt> <cmt> ctrl uses a clm loss just like gpt and gpt-2, so should work out of the box with this script (provided past is taken care of </cmt> <cmt> similar to mems for xlnet). </cmt> <cmt> changed calls and imports appropriately. </cmt> <iss> extending run_language_modeling.py for xlnet </iss>",added data collator for permutation (xlnet) language modeling and related calls
66,<desc> mainly just sprucing up the 1upkeyboards keyboards to adhere to qmk's modern standards some changes are usage of #pragma once = in favor of ?= in rules.mk minor readme tweaks my code follows the code style of this project. i have read the contributing document. </desc> <cmt> use #pragma once </cmt> <cmt> get rid of code for unused indicators </cmt> <cmt> pragma once and other small fixes for consistency </cmt> <cmt> use #pragma once </cmt> <cmt> pragma once and other small fixes for consistency </cmt> <cmt> add a short blurb to the readme </cmt>,some minor refactoring of stuff i've done in 1upkeyboards directory
67,"<desc> (post updated 08/05/19) related to #5070 - decision regions #9173 - heatmaps and gridsearch #14349 - gridsearch #13448 - sklearn.plot #12599 - partial dependence #8425 - calibration curve scikit-learn defines a simple api for creating visualizations for machine learning. the key features of this api is to run calculations once and to have the flexibility to adjust the visualizations after the fact. this logic is encapsulated into a display object where the computed data is stored and the plotting is done in a plot method. the display object's __init__ method contains only the data needed to create the visualization. the plot method takes in parameters that only have to do with visualization, such as a matplotlib axes. the plot method will store the matplotlib artists as attributes allowing for style adjustments through the display object. a plot_* helper function accepts parameters to do the computation and the parameters used for plotting. after the helper function creates the display object with the computed values, it calls the display's plot method. note that the plot method defines attributes related to matplotlib, such as the line artist. this allows for customizations after calling the plot method. for example, the roccurvedisplay defines the following methods: class roccurvedisplay: def __init__(self, fpr, tpr, roc_auc, estimator_name): ... self.fpr = fpr self.tpr = tpr self.roc_auc = roc_auc self.estimator_name = estimator_name def plot(self, ax=none, name=none, **kwargs): ... self.line_ = ... self.ax_ = ax self.figure_ = ax.figure_ together with a plotting function to create this object: def plot_roc_curve(estimator, x, y, pos_label=none, sample_weight=none, drop_intermediate=true, response_method=""auto"", name=none, ax=none, **kwargs): # do computation viz = roccurvedisplay(fpr, tpr, roc_auc, estimator.__class__.__name__) return viz.plot(ax=ax, name=name, **kwargs) here is a notebook demonstrating a workflow for using this api. here are what the api implemenation looks like for other visualizations: confusion matrix grid search learning curve roc curve partial dependence </desc> <cmt> wip </cmt> <cmt> enh adds plot_roc_curve </cmt> <cmt> doc adds docs </cmt> <cmt> bug fix </cmt> <cmt> doc adds label to parameters </cmt> <cmt> doc adds label as a parameter </cmt> <cmt> api update with kwargs </cmt>",plotting api starting with roc curve
68,"<desc> related: #15194 in continuation of pr #15194, i've added a test for the description field of the variable. thank you very much @kaxil, @xinbinhuang for all the tips & hints. let me know if anything more is needed. </desc> <cmt> add description field in variable (#12413) </cmt> <cmt> change description file to text </cmt> <cmt> rebase migration on master </cmt> <cmt> remove length parameter from description column for compatibility with postgres </cmt> <cmt> delete past migration revision </cmt> <cmt> add variable description retrieval test </cmt>",adds a test for the description field in variable
69,"<desc> a gl context is an opaque integer from the user's perspective. internally it is a heap allocation, and in pthreads we use that location in memory to coordinate gl things between threads. however, in a non-pthreads build that isn't necessary - we can just use an integer id. doing so avoids using malloc/free, which in small programs can avoid bringing in malloc/free unnecessarily. this helps several of the code size tests by around 3% (see diff). noticed while looking at </desc> <cmt> optimize </cmt> <cmt> simpler </cmt> <cmt> fix </cmt> <cmt> smaller </cmt> <cmt> update tests </cmt>",use malloc() in gl context creation only with pthreads
70,"<desc> for 1/2 the plugins in x-pack, the integtest task is now a no-op and all of the tests are now executed via a test, yamlresttest, javaresttest, or internalclustertest. this includes the following projects: async-search, autoscaling, ccr, enrich, eql, frozen-indicies, data-streams, graph, ilm, mapper-constant-keyword, mapper-flattened, ml a few of the more specialized qa projects within these plugins have not been changed with this pr due to additional complexity which should be addressed separately. a follow up pr will address the remaining x-pack plugins (this pr is big enough as-is). related: #61802 related: #56841 related: #59939 related: #55896 </desc> <cmt> async-search </cmt> <cmt> address java rest tests </cmt> <cmt> autoscaling </cmt> <cmt> ccr:rest </cmt> <cmt> enrich </cmt> <cmt> eql </cmt> <cmt> enrich fixes </cmt> <cmt> data stream fixes </cmt> <cmt> ccr:rest fixes </cmt> <cmt> autoscale fix </cmt> <cmt> frozen-indices </cmt> <cmt> graph </cmt>",convert first 1/2 x-pack plugins from integtest to [yaml | java]resttest or internalclustertest
71,"<desc> this pr fixes a memory leak when mapping buttons with peripheral add-ons, and an error where peripheral add-on dlls aren't unloaded upon shutdown. also included is a possible fix for the controller dialog. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) </desc> <cmt> [controller dialog] fix keypress being absorbed after mapping </cmt> <cmt> [peripherals] fix add-ons not being destroyed on exit </cmt> <cmt> [peripherals] fix memory leak in button mapping commands </cmt>",fix memory and resource leak
72,"<desc> it feels strange that blockassembler's constructor inspects command-line options to set its configurable fields. this pr introduces a blockassembler::options struct which can be constructed from the command-line options, but is constructed with static values for tests instead. </desc> <cmt> abstract out blockassembler options </cmt> <cmt> run miner_tests with fixed options </cmt>",abstract out the command line options for block assembly
73,<desc> fixing type check errors within rwa when testing in ci: </desc> <cmt> chore: run tests against rwa in current branch </cmt> <cmt> - update rwa testing job to use yarn </cmt> <cmt> fix(ci): install cypress binary w/ yarn when yarn.lock present </cmt> <cmt> fix(ci): fix command formatting </cmt>,rwa type check when testing against staging
74,"<desc> adds the translation documentation into the version-3.1 branch continuation of #2353. @tomchristie a couple of new errors were added in 3.1. they're in the django.po on this branch, but weren't in the file on the original pr i made. </desc> <cmt> instructions on how to translate rest framework error messages </cmt> <cmt> match drf style guide </cmt> <cmt> add info about how django chooses which language to use </cmt> <cmt> update internationalisation instructions to prevent symlinking; add base .po file </cmt> <cmt> fix spelling & grammar errors </cmt> <cmt> update error messages for language and consistency </cmt> <cmt> update expected error messages in tests </cmt> <cmt> capitalise django </cmt> <cmt> add missing period; update generated translations </cmt>",document how to translate drf error messages (version 3.1)
75,<desc> i merged hswolff's pr #2279 and added directory structure </desc> <cmt> move ember admin to use es6 modules </cmt> <cmt> - adds required dependencies to package.json </cmt> <cmt> and to bower.json </cmt> <cmt> - added required grunt tasks to transpile and </cmt> <cmt> concat ember admin files </cmt> <cmt> added directory structure </cmt>,merged into ember and added directory structure
76,"<desc> if a listener is torn down shortly after it is created, a tls callback invoked by the filter config object access objects that are deleted. this pr fixes the issue. risk level: low-medium testing: unit tests; also tested fix manually with patched envoy. docs changes: n\a release notes:  n\a </desc> <cmt> fix datarace </cmt> <cmt> lifetimes </cmt> <cmt> comment </cmt> <cmt> test </cmt> <cmt> format fix </cmt>",fix data race that leads to seg fault
77,"<desc> this pr watches for all files and directories being created and deleted out of the program files directory. this will trigger the application to reindex after a delay. i don't think this is a permanent solution, and we will have to put more though into how to do this in a less intrusive way. references pr checklist applies to #2398 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx detailed description of the pull request / additional comments this is not perfect.  we get multiple  writes on installing or uninstalling the uwp app.   the idea is an initial write will trigger a timed delay of the reindex, if another write is detected within that time span it resets the timer.   if the install has delays between file writes we will reindex multiple times (not good). also there seems to be thread contention that causes stalls if we are querying for apps while the uwp apps are being reindexed. validation steps performed launch the app.  verify no ""reindexing"" is a happening. uninstall terminal, and verify that it triggers a reindex, and that terminal no longer appears in the results. reinstall terminal, and verify that it triggers a reindex and that the terminal will now appear in the results. note:  there is about a 10-15 second delay after installing, for the results to be reflected in the ui. </desc> <cmt> adding file watchers for uwp detecting when apps are installed or deleted and reindexing the uwp apps </cmt> <cmt> removing unused namespace. </cmt> <cmt> looking at files and not filtering is better because the timer is more likely to reset while an install is happening, preventing uneeded indexing </cmt>",reindex uwp apps when apps are installed or uninstalled.
78,"<desc> under certain conditions, the qualcomm ril and friends like to spend tens or hundreds of milliseconds doing non-preempt-able work of some sort, which doesn't play well with the 100hz loops in boardd and controlsd. since they can't play nice together, we'll have them play on different playgrounds. changes: pin low priority interrupts (modem, wifi, flash storage) to cpu 1, the second kryo efficiency core pin the highest-demand real-time tasks to cpu 3, the second kryo performance core prevent all android stuff from running on cpu 3, but allow op processes to overflow there tweak all op real-time priorities to sit clearly above android mediaserver and system_server general thinking is there's a nice usb->boardd->controlsd and reverse flow that shouldn't result in much contention or preemption among the three. with these changes, boardd no longer takes missed cycles under any realistic conditions i've been able to find. it now handles sim eject and reinsert cleanly, which it didn't before. it does a much better, but not completely perfect job of surviving modem subsystem restart, but that's a more difficult scenario and not representative of a real-world event. </desc> <cmt> wip: reduce boardd and other lags </cmt> <cmt> copypasta fault </cmt>",reduce scheduler latency for realtime processes
79,"<desc> prior to this change, a parentdatawidget was bound to a particular ancestor renderobjectwidget type, whose renderobject was responsible for setting up the parent data that the parentdatawidget would write to. a given parentdatawidget could not be re-used with another renderobjectwidget type as ancestor. for example, a new implementation of stack (e.g. superstack widget) was not able to re-use the positioned widget, because it was bound to the existing stack widget. this change loosens the contract between parentdatawidget and ancestor renderobjectwidget types. any renderobjectwidget type can be used as an ancestor for a parentdatawidget as long as the renderobject of the renderobjectwidget sets up the parentdata type expected by the parentdatawidget. related issues required for fixing #45797. i added the following tests: test to verify that a parentdatawidget can be used with different renderobjectwidget types as ancestors. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. afiak, this is not a breaking change as defined in the breaking change policy, but since this may effect some users negatively, i am providing a migration guide: flutter/website#3525. </desc> <cmt> parentdatawidgets can be used with different ancestor renderobjectwidget types </cmt> <cmt> ++ </cmt> <cmt> fix doc </cmt>",make parentdatawidget usable with different ancestor renderobjectwidget types
80,<desc> closes #15842 repair the component testing build for windows forked  made relative paths of specs on windows use forward slash instead of backslash for posix compatible paths. allowing the runner-ct to parse them on the front-end into directories. now component testing works on windows </desc> <cmt> feat: add lazy-compile-webpack-plugin to cypress </cmt> <cmt> fix: normalize spec file relative paths on windows </cmt> <iss> [7.0.0] doesn't display list of specs in cypress component test runner </iss>,make component testing windows compatible
81,"<desc> add std::function wrapper to read/write index; in our case, we may read/write index from/to hdfs. add indexivf::access; </desc> <cmt> add access function to indexivf; </cmt> <cmt> - access for indexivf; </cmt> <cmt> - write_index/read_index with std::function<...>; </cmt> <cmt> - fix test compile on mac; </cmt> <cmt> - adjust write/read with std::function; </cmt>",read/write index with std::function wrapper
82,<desc> made changes make test descriptions more readable as run command and run_command can cause some confusion. also the case with rails env and rails_env. </desc> <cmt> - made changes to have test cases in actions_test more readable. </cmt> <cmt> - made changes to have test cases in actions_test more readable. </cmt> <cmt> changed description with tests related to rails_command. </cmt>,having more readable test descriptions in railties actions_test.rb
83,<desc> breaking change: description: checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> martin pointed out in previous pr that no ending '.' in logging </cmt> <cmt> add support for xiaomi vibration sensor </cmt>,deconz support xiaomi vibration sensor
84,"<desc> this is a continuation of the discussion in #2959, and focuses on making view easier to extend by users wishing to use non-jquery libraries. it's similar in plugability to backbone.ajax or other overridable parts of backbone. native views and non-jquery dom libraries would be able to create a native view implementation by overriding $, make, remove, setelement, delegate, and undelegateevents (see the nativeview reference implementation). this preserves the majority of the public contract of view (with the notable exception of view#$ and view.$el), and the public interface of the constructor (including passing options), delegateevents/undelegateevents, render, remove, and setelement would be virtually unchanged. the pr also re-adds view#make. the next step would be to remove backbone.$() calls from history and perhaps extend view#setelement and view#make to use a common exposed createelement utility. update for folks tuning in late: the final list of overridable methods is available on the wiki with instructions for how to use it in your own project. </desc> <cmt> revert c1e62cda: add view#make back in for overriding </cmt> <cmt> add view#delegate as a single event listener version of delegateevents for easier overriding </cmt>",view hooks for native and non-jquery libraries
85,"<desc> see #11857 adds default values to the docstring, and removes an extra sentence from max_eps, which doesn't seem to be correct. this is yet another pr to simplify #11857, decoupling certain aspects of that pr from it. </desc> <cmt> improve docstring </cmt> <cmt> fix default metric </cmt>",improve docstring and add default values.
86,<desc> added pt_pt-utf8 language pack and fixed some minor compiler warnings. harmonize file suffix for the current existing utf8 language packs. updated all configuration files to reflect the new language packs. </desc> <cmt> added pt_pt-utf8 language pack; fixed some minor compiler warnings; harmonize file suffix for the current existing utf8 language packs; updated all configuration files to reflect the new language packs </cmt> <cmt> missing coma comment correction for all config files </cmt> <cmt> missing coma comment correction for the default cofig file </cmt>,add pt_pt-utf8 language pack and fix some minor compiler warnings
87,<desc> this pr introduces support for the yoruba language. current range of support includes: stopwords lexical attributes checkers i.e like_num tokenization using  lemmatizer index </desc> <cmt> adding support for yoruba </cmt> <cmt> test text </cmt> <cmt> updated test string. </cmt>,adding support for yoruba language
88,"<desc> backport of #16421 this pr fixes the black screen shown in emulators across some gles platforms. test build, based on libreelec 9.2 and kodi 18.5, available here:  bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) </desc> <cmt> crendersystemgles: add no-alpha texture shader </cmt> <cmt> retroplayer/gles: use no-alpha texture shader </cmt> <cmt> fixes black screen with rgb emulators on rpi. </cmt>",fix black screen for rgb emulators
89,<desc> checklist closing issues: #issue i wrote some lines in the radare2book </desc> <cmt> fix return values to int </cmt> <cmt> add support to mg to read files in chunks </cmt> <cmt> add support fs_io plugin when read files in chunks </cmt> <cmt> change return value to in in read and write of r_fs_plugin_t </cmt> <cmt> refactor code of mg command to support streaming </cmt> <cmt> truncate destination file if exists </cmt> <cmt> removing warnings due to incompatible pointer </cmt> <cmt> add offset and size optional parameters to mg cmd </cmt>,add support to stream files using mg
90,"<desc> for easier testing of aclk, it is useful to connect to an arbitrary mqtt wss brokers. this allows doing that easily by adding -daclk_disable_challenge to the compiler. this will disable challenge-response functionality which is supported and specific only to netdata cloud. during the implementation, i noticed we are unnecessarily passing the port as both string and integer and carrying that around the code. this fixes also that problem. review the 2 commits separately for a clearer picture as one does code cleanup and the second one actually implements the feature, component name aclk compile with -daclk_ssl_allow_self_signed -daclk_disable_challenge, set up cloud base url = 127.0.0.1:9002 in cloud.conf. set mosquito broker (compiled with wss support) to listen with wss listener on port 9002. example mosquito config: port 1883 listener 9002 protocol websockets certfile server.crt keyfile server.key log_dest stdout log_type all websockets_log_level 9999 agent should skip challenge-response and connect to the broker successfully. </desc> <cmt> remove unnecessary back and forth conversions </cmt> <cmt> allow simple disable of aclk challenge for devs </cmt>",allow connecting to arbitrary mqtt wss broker for devs
91,"<desc> add description section for the operations_producer to rocketmq develop guide: add description section for operations_producer to english rocketmq develop guide browse the section 1 in the best_practice.md follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> [rip-9] add the introduction of the basic samples in rocketmq </cmt> <cmt> [rip-9] add the introduction of the basic samples in rocketmq </cmt> <cmt> [rip-9] add the introduction of the basic samples in rocketmq </cmt> <cmt> [rip-9] add the introduction of operations_producer in rocketmq </cmt>",add the introduction of the operations_producer in rocketmq
92,"<desc> recently, presets have been added to the preheat menu in the msui lvgl interface, which are defined in the configuration.h file (only extruder). this merge request adds a temperature preset to the preheat menu for the bed. #define preheat_1_label       ""pla"" #define preheat_1_temp_hotend 180 #define preheat_1_temp_bed     70 #define preheat_2_label       ""abs"" #define preheat_2_temp_hotend 240 #define preheat_2_temp_bed    110 preset for bed in preheat menu for pla/abs see demo video: </desc> <cmt> update draw_preheat.cpp </cmt> <cmt> update draw_preheat.cpp </cmt> <cmt> update draw_preheat.cpp </cmt>",mks ui lvgl bed preheat presets
93,"<desc> this pr adds a new endpoint to request a someone else set up a project: post /organizations/<organization_slug>/request-project-creation/ this endpoint takes just one parameter: targetuseremail. this endpoint is going to be used when we detect an organization that has requests coming from a mobile app but doesn't have a mobile project set up. we will show a cta to the user asking them to set up a project or ask someone else to set it up. note that part of the goal is to get new users which means we might send this to non-sentry users as well which is why the endpoint only takes an email address instead of a user id. at some point, we may do a more sophisticated flow that combines requesting/inviting a member to join and requesting a new project. also, this endpoint may be modified to work with other types of project creation flows in the future. we would add a new parameter to denote the type of project to be created but for now, the only use case is mobile so need to add the parameter yet. </desc> <cmt> first version of request project endpoint </cmt> <cmt> update text </cmt> <cmt> update link </cmt>",feat(mobile-prompt) request project endpoint
94,<desc> simdjson has moved forward! the fuzzers have been refreshed to use the new api. </desc> <cmt> move from deprecated interface in fuzz dump raw tape </cmt> <cmt> update fuzz_dump to the non deprecated replacement </cmt> <cmt> replace use of deprecated api </cmt>,do not use deprecated apis in the fuzzers
95,"<desc> various fixes related to using projections of associated types in impls. i'm not sure that this totally works, but it seems to fix a lot of the problems. fixes #20624. fixes #20559. fixes #20666. fixes #17826. r? @nick29581 </desc> <cmt> normalize types in impls, add test for coherence failure. </cmt> <cmt> fixes #20624. </cmt> <cmt> normalize types in supertraits when checking that impls are valid during wf. </cmt> <cmt> fixes #20559. </cmt> <cmt> rename test to fit naming convention. </cmt> <iss> identify traits in libstd that should use associated types (as output parameters) </iss> <iss> redundant impls required when trait bound uses an associated type </iss> <iss> projection types permit coherence violations </iss> <iss> bounds don't work on nested associated types </iss>",normalize associated types in impls/coherence
96,"<desc> this pr removes wox project and migrates all class into powerlauncher project. pr checklist applies to #3871 cla signed. if not, go over here and sign the cla tests added/passed detailed description of the pull request / additional comments this pr makes the following changes : move all files from wox to powerlauncher project. fix all static analysis errors in migrated files. delete wox project. updated msi. following static analysis errors have been suppressed in mainviewmodel.cs : #pragma warning disable ca1308 // normalize strings to uppercase var query = querytext.tolower(cultureinfo.invariantculture).trim(); #pragma warning restore ca1308 // normalize strings to uppercase we currently convert all strings to lowercase across all plugins. this would require updating all plugins and projects to use toupper function for string normalization. it would be better to make this change as part of seperate pr. #pragma warning disable ca1031 // do not catch general exception types catch (exception) #pragma warning restore ca1031 // do not catch general exception types this error asks to use more specific exception type in catch block. since this is an interop code, it is not very clear which specific exception should be used. validation steps performed manually verified that all plugins function correctly and msi is built without any errors. </desc> <cmt> moved all files from wox to powerlauncher </cmt> <cmt> removed wox project </cmt> <cmt> changed namespace for imported files </cmt> <cmt> resolved errors for vm </cmt> <cmt> added build dependency order </cmt> <cmt> fixed errors in helper class </cmt> <cmt> remove wox files </cmt> <cmt> fixed errors in singleinstance class </cmt>",migrate files from wox to powerlauncher
97,"<desc> this pr supersedes pr #4654 as it was growing too large. all comments in that pr should be addressed here. i will attempt to break the prs for the topology optimization effort into 3 prs total and will follow this general plan: this pr only adds the graph nodes and graph. the graph nodes will hold the information used to make calls to the internaltopologybuilder when using the dsl. graph nodes are stored in the streamstopologygraph until the final topology needs building then the graph is traversed and optimizations are made at that point.  there are no tests in this pr relying on the follow-up pr to use all current streams tests, which should suffice. pr 2 will intercept all dsl calls and build the graph.  the internalstreamsbuilder uses the graph to provide the required info to the internaltopologybuilder and build a topology.  the condition of satisfaction for this pr is that all current unit, integration and system tests pass using the graph. pr 3 adds some optimizations mainly automatically repartitioning for operations that may modify a key and have child operations that would normally create a separate repartition topic, saving possible unnecessary repartition topics.  for example the following topology: kstream<string, string> mappedstreamother = inputstream.map(new keyvaluemapper<string, string, keyvalue<? extends string, ? extends string>>() { @override public keyvalue<? extends string, ? extends string> apply(string key, string value) { return keyvalue.pair(key.substring(0, 3), value); } }); mappedstreamother.groupbykey().windowedby(timewindows.of(5000)).count().tostream().to(""count-one-out""); mappedstreamother.groupbykey().windowedby(timewindows.of(10000)).count().tostream().to(""count-two-out""); mappedstreamother.groupbykey().windowedby(timewindows.of(15000)).count().tostream().to(""count-three-out""); would create 3 repartion topics, but after applying an optimization strategy, only one is created. </desc> <cmt> kafka-6761: part 1 of 3 adding graph nodes </cmt> <cmt> kafka-6761: make builder params final </cmt>",part 1 of 3; graph nodes
98,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fix exception cannot convert column ... because it is constant but values of constants are different in source and result which could rarely happen when functions now(), today(), yestarday(), randconstant() are used. detailed description (optional): changed in expressionanalyzer: expressionactions from getsampleblock are used now in readimpl. also value for  functions now(), today(), yestarday(), randconstant() is determined in functionbuilder. fixes #7100. </desc> <cmt> use new iface for now function. use current time value from function builder. </cmt> <cmt> use new iface for now function. use current time value from function builder. </cmt> <cmt> use new iface for now function. use current time value from function builder. </cmt> <iss> clickhouse benchmark <<< ""select now()"" does not work on master </iss>",fix header for function 'now'
99,"<desc> add strict object that was added in version 1.5 and missing notdeepstrictequal function add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> @types/assert: add missing assert.strict type </cmt> <cmt> add missing notdeepstrictequal </cmt>",update definitions to version 1.5
100,"<desc> adds a headers dict param to ovirt authentication. this allows adding filter: true http header to each api call (needed for non-admin users). ovirt module ansible version ansible 2.3.1.0 config file = /etc/ansible/ansible.cfg configured module search path = default w/o overrides python version = 2.7.5 (default, nov  6 2016, 00:28:07) [gcc 4.8.5 20150623 (red hat 4.8.5-11)] none </desc> <cmt> add filter param to ovirt module auth </cmt> <cmt> update docs to include new filter param </cmt>",add headers param to auth
101,<desc> this pull request adds amqps protocol support for rabbitmq export bug fix: no fixed tickets: #1687 </desc> <cmt> adding in optional protocol variable for rabbitmq export which adds in support for amqps protocol </cmt> <cmt> needed to handle case where no protocol was specified in configuration. so added in an if clause to check if the protocol was present </cmt> <iss> exports: support rabbitmq amqps </iss>,add amqps protocol suppport for rabbitmq export
102,"<desc> react js ebooks for begginer its really help to learn react from basic because at the leanpub, we can get this book for free, and its sell by its owner read our contributing guidelines </desc> <cmt> add: indonesia react ebooks </cmt> <cmt> add: indonesia react js ebook </cmt> <cmt> add: react js ebooks </cmt> <cmt> add: react js ebook (indonesia) </cmt>",react js untuk pemula (indonesia)
103,"<desc> this is a major simplification to the code path for forming protocol method calls. </desc> <cmt> silgen: simplify silgenapply a bit </cmt> <cmt> we were passing around a ton of unused parameters, </cmt> <cmt> just remove them. </cmt> <cmt> silgen: remove silgenfunction::archetypeopenings </cmt> <cmt> silbuilder now tracks data dependencies between instructions </cmt> <cmt> that open existentials and uses of the opened type, so </cmt> <cmt> silgen's mechanism for this is no longer needed. </cmt> <cmt> in particular, this simplifies archetypecalleebuilder. </cmt>",rip out silgenapply's archetypecalleebuilder
104,"<desc> a new guide to help users optimize performance of the netdata agent. this pr takes most of its information from a few older, disparate files, condenses them, and deletes/deprecates them. component name area/docs </desc> <cmt> init guide </cmt> <cmt> working on guide </cmt> <cmt> finish first draft of performance guide </cmt>",how to optimize netdata's performance
105,<desc> bbc39fa move c++ code into the c runtime api header. revert this part of bbc39fa. see #19084 for the fundamental issue. </desc> <cmt> revert move of error api to c runtime api </cmt> <cmt> add warning </cmt>,make c runtime api a c api again
106,"<desc> produces a solid 1% speedup see faster-cpython/ideas#80 for full discussion. </desc> <cmt> remove unsafe _pyobject_gc_calloc function. </cmt> <cmt> place __dict__ immediately before gc header for variable sized objects and plain python objects. work in progress. </cmt> <cmt> restore documented behavior of tp_dictoffset. </cmt> <cmt> fix up lazy dict creation logic to use managed dict pointers. </cmt> <cmt> manage values pointer, placing them directly before managed dict pointers. </cmt> <cmt> refactor a bit. </cmt> <cmt> fix specialization of managed values. </cmt> <cmt> convert hint-based load/store attr specialization target managed dict classes. </cmt> <cmt> specialize load_method for managed dict objects. </cmt> <cmt> use newer api internally. </cmt>",place dict and values pointer at fixed (negative) offset just before gc header.
107,"<desc> this pr adds features: users can feed data whose batch number is less than gpu card number in inference phase. the data loading order of dataloader keeps the same as the user-defined data source. </desc> <cmt> sequential reader stage 1, test=develop </cmt> <cmt> merge develop to solve conflict, test=develop </cmt> <cmt> fix ut, test=develop </cmt> <cmt> fix iterable=false reset bug, add some logs and polish code, test=develop </cmt>",reader sequential and inference partial feed
108,<desc> this pr resolves an issue on keeping all block logs in retained folder rather than moving them to archive. the default setting is changed from keeping 10 block logs in retained directory to keep all the logs there. select one: select any that apply: </desc> <cmt> update block_log_config.hpp </cmt> <cmt> update config.hpp </cmt> <cmt> update controller.hpp </cmt> <cmt> update log_catalog.hpp </cmt> <cmt> update chain_plugin.cpp </cmt>,keep all block logs in retained directory
109,<desc> fixes conflict in #32550 removed fluttereventlogger since it doesn't rethrow gradle failures anymore. </desc> <cmt> updates latest gradle & kotlin versions </cmt> <cmt> remove the event logger </cmt> <cmt> missing gradle version in flutter tools </cmt> <cmt> gradle 3.4.1 </cmt> <cmt> gradle 3.4.2 </cmt> <cmt> kotlin 1.3.41 </cmt>,update kotlin and gradle version
110,"<desc> no issues fixed new algorithm added new file added at cosmos/code/data_structures/src/list/singly_linked_list/operations/delete including the algorithm for deletion of nth node in a linked list </desc> <cmt> create something random.py </cmt> <cmt> agar koi bug theek kar raha hai to uska reference issue number nahi to feature kya hua </cmt> <cmt> jaise stack  and que add kar dun to?? </cmt> <cmt> tab uske baare me detail ki tune add kya kia. bas, ab commit new file </cmt> <cmt> delete something random.py </cmt> <cmt> algorithm for deleting nth node </cmt>",added new algorithm for deletion of nth node in singly linked list
111,"<desc> this pr refactors the pointer event classes so that if a pointer event is transformed, its localposition and localdelta are computed only when first used, and other properties are deferred to the original event instead of stored in the object. why? the local* fields are used less often, but takes quite some computation due to the matrix multiplication. events are dispatched to every object along the hit test result, and the local* fields are calculated unselectively, then discarded without being used most of the time. besides, the ~25 fields of pointerevent are also assigned every time without any modification, which we can see some room of improvement. how much does it matter? currently move events can be dispatched at a high frequency to all objects along the hit test result, which affects only when the screen is being touched. hover events can also be dispatched frequently, but they are only dispatched to mouse-related objects, which is a small subset of the entire tree. but this might change. pr #63834 proposes to dispatch hover events to all objects, so that they're treated like the other events. this will help fix a few issues as described in the pr, while tightening the performance restriction of event dispatching. how much does it improve, or worsen? a new benchmark, bench_mouse_region_mixed_grid_hover, is proposed in #63808 to measure the performance of dispatching events to non-mouse widgets by making mouse hover over a number of heavily nesting containers and mouseregions. following is the average result of 3 different cases: the current master; after applying ""native hover""; after applying ""native hover"" and ""lazy local"" (this pr) drawframeduration hittestduration current master ~1650 ~780 native hover ~1679 ~933 native hover + lazy local ~1655 ~765 any api change? yes, in a minor way. currently, each pointer kind has up to 3 constructors (or factories): unnamed constructor .transformed .frommouseevent this pr changes the unnamed constructor so that they no longer accepts the following arguments: localposition, localdelta, original, and transform. this is in order to ensure the relationship between the untransformed properties, transformed properties, and transform, is correct. to generate a transformed event (e.g. one with a specific localposition), create an untransformed event then use .transformed. // currently allowed pointerdownevent(position: offset(100, 100), localposition(110, 120)) // after pr pointerdownevent(position: offset(100, 100)).transformed(matrix4.translationvalue(10, 10)) also, the transformed events are now of a series of private subclasses. for example, pointerdownevent.transformed actually produces an instance of _transformeddownevent, which is a subclass of pointerdownevent. this should not break anything unless some code is doing strict type equality check, which should be changed to isa<t>(). // before pr expect(event.runtimetype, pointerdownevent); // after pr expect(event, isa<pointerdownevent>()); related issues #63808, which benchmarks this issue #63834, whose performance issue this issue is trying to solve i added the following tests: replace this with a list of the tests that you added as part of this pr. a change in behavior with no test covering it will likely get reverted accidentally sooner or later. prs must include tests for all changed/updated/fixed behaviors. see test coverage. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> impl </cmt> <cmt> hide new classes </cmt>",lazily compute pointerevent's transformed positions
112,"<desc> for details see the commit list </desc> <cmt> stdlib: use existing decodecstring for initializing a string with a null-terminated c string. </cmt> <cmt> and remove the now unused _sentinelcollection utility. </cmt> <cmt> tests: remove an obsolete fixme-comment from the character_literals test </cmt> <cmt> silcombine: make the value_to_bridge_object peephole less conservative. </cmt> <cmt> we can always eliminate arc operations on the result of a value_to_bridge_object instruction. </cmt> <cmt> there is no need to restrict the operand to a specific sil pattern. </cmt> <cmt> stdlib: change the representation of unsafebufferpointer from start+end pointers to start-pointer + count. </cmt> <cmt> this saves a few instructions for some operations, like getting the count. </cmt> <cmt> also, it avoids the check for unwrapping the optional end pointer. for example, iterating over an unsafe buffer now has no overhead. </cmt> <cmt> also remove the _unboundedstartingat initializer, which is not needed anymore. </cmt> <cmt> stdlib: improve existential collection performance for -osize. </cmt> <cmt> making sure that makeiterator is always inlined, enables devirutalization of the iterator calls. </cmt> <cmt> inlining was not done with -osize which resulted in pretty bad performance when iterating over an existential collection. </cmt> <cmt> stdlib: let the construction of a small string literal compile down to 2 constant loads. </cmt> <cmt> the main part of this is to rewrite the small string literal-constructor to work with values (= shifting bytes) instead of setting bytes in memory. </cmt> <cmt> this allows the compiler to fold away everything and end up with the optimal code for small string literals. </cmt>","some performance improvements in the stdlib, mainly for small string literals"
113,"<desc> add leaf nodes to referencecountophandle. support eager deletion of selectedrows. support eager deletion of unused variables when multiple gpus are used, which would not be deleted in the previous version. change data member var_names_ in referencecountophandle to a map, since functions in scope is lockable and var_names_ may be duplicate. reduce mergeadd operations in adam when selectedrows is strictly sorted. </desc> <cmt> merge develop </cmt> <cmt> enhance eager deletion </cmt> <cmt> merge develop </cmt>",enhance eager delete and sparse adam
114,"<desc> there is still a call to 'virtualmachinesclient.get' directly in azure_backoff, which does not go through the cache approach. this pr uniforms all calls for getting azure vm to use 'getvirtualmachine'. also refine unused 'exists' return value. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): related #57031 follow-up #57432 release note: </desc> <cmt> remove exists return value from getvirtualmachine </cmt> <cmt> remove virtualmachineclientgetwithretry </cmt>",uniform azure vm api calls
115,"<desc> this pr changes (delete as applicable) i have fix nullable and multiple for conforming to jsdoc. </desc> <cmt> fix nullable types </cmt> <cmt> fix multiple types on gameobjects </cmt> <cmt> fix multiple types on actions </cmt> <cmt> fix many multiple types </cmt> <cmt> fix multiple types on geom </cmt> <cmt> fix multiple types on math </cmt> <cmt> fix multiple types on physics, texture and input </cmt> <cmt> fix multiple types on tilemaps </cmt> <cmt> fix remaining multiple types </cmt>",fix nullable and multiple types
116,"<desc> slider: clamped value to min and max in setrange. allowed min to be same as max. added check, if min is the same as max, avoid division be zero. texturepacker2: added possibility to force the output texturepack to be square (can be set by boolean forcesquareoutput. my motivation is the following: in some cases mipmaps don't work unless the texture is square. btw: sorry for making another pull request as i did not find out how to update the previous one. </desc> <cmt> added boolean forcesquareoutput for settings. this can be used to make </cmt> <cmt> sure that the output images are squares. my main motivation: in opengl </cmt> <cmt> es 1.0, mipmaps require square textures. </cmt> <cmt> changed the commit according to seraphim6x7 suggestion. </cmt> <cmt> clamping for value in setrange. </cmt> <cmt> allow min to be same as max. </cmt> <cmt> if min is the same as max avoid division by 0. </cmt>",fixes to slider and texturepacker2
117,"<desc> closes #32803 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> test for named aggregation with resample.agg. </cmt> <cmt> allow named aggregation for resample.agg. </cmt> <iss> namedagg error: aggregate() missing 1 required positional argument: 'func' </iss>",allow named aggregation with resampler.agg
118,"<desc> i noticed that activating caps lock on my jj40 would cause the board to hang. u/wanleg on reddit suggested disabling the caps lock led, and since i have no leds on my board, i've done that for all of the lock leds. i've also added a reset key to my layout to make programming the board easier and adjusted tapping_term for accessing the nav layer. </desc> <cmt> adjust tapping_term to make accessing the nav layer easier </cmt> <cmt> jj40: add reset key to lower layer. </cmt> <cmt> disable all lock leds on ""oscillope"" keymap. </cmt> <cmt> i'm not 100% sure why yet, but attempting to turn on a lock led on my v1 </cmt> <cmt> jj40 pcb causes the pcb to become unresponsive. the easy fix is to just </cmt> <cmt> disable all of the lock leds, since i don't have any leds on my keyboard </cmt> <cmt> anyway. </cmt> <cmt> many thanks to u/wanleg on reddit for suggesting this fix: </cmt>",fix jj40 capslock and minor keymap updates
119,"<desc> what's in this pull request? resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> escapeanalysis: fix a bug in graph merging </cmt> <cmt> this bug can end up in doing wrong stack promotion. </cmt> <cmt> silcombine: fix insertion of dealloc_stacks in the partial_apply-apply -> apply conversion. </cmt> <cmt> rdar://problem/25387206 </cmt> <cmt> re-instate ""stdlib: add some inlining attributes to help the optimizer getting the right inlining decisions."" </cmt> <cmt> this re-instates commit 8b0e36779e81f6aee4c858d9d698ae711f35b189 </cmt> <cmt> re-instate ""performanceinliner: improve the inlining heuristic to reduce code size."" </cmt> <cmt> ...with a fix in the shortest-path-analysis </cmt> <cmt> this reinstates commit 4bd12167022293c1edd16caa10016308b6e54fe2 </cmt>",re-instate inliner changes with required other bug fixes
120,<desc> this adds a bare-bones load_package() api that implements #14177 more details can be found in the user-facing docs draft:  it currently supports: uploading the package working directory and adding it to the worker python path via the runtime_env mechanism. github raw links to the yaml config future work: conda/docker support better integration with runtime_env option once that is working properly </desc> <cmt> wip </cmt> <cmt> wip </cmt>,add an experimental load_package api
121,"<desc> params for data should have been declared as something other than string because selecting from ajax does not quite work. take into account this code below: $('select').select2({ ajax: { data: function (params) { var query = { search: params.term, page: params.page } return query; } } }); there would be no way to access the term from the parameter. i have changed the data parameter to select2option but if this is not correct please let me know. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. </desc> <cmt> data term is innaccessable using typescript </cmt> <cmt> the data term might have been declared wrong, rather than it being a </cmt> <cmt> string, it could be a select2queryoptions than in that case the term is </cmt> <cmt> accessible when loading via ajax. </cmt> <cmt> merge remote-tracking branch 'refs/remotes/definitelytyped/master' </cmt> <cmt> unable to access params term when loading via ajax </cmt> <cmt> when trying to use select2 v4, i was unable to get the term from the </cmt> <cmt> search box as the params was declared as a string </cmt>",data params declared as select2 option rather than string
122,"<desc> commit message: this adds a new network filter for collecting linux-specific tcp stats and publishing them as envoy metrics, with a configurable stat_prefix so that stats can be attributed to a specific listener or cluster. commit message: this adds a new transport socket wrapper for collecting os-level tcp stats and publishing them as envoy metrics, in either the cluster or listener stats namespace (depending on upstream or downstream use). this allows attributing the tcp stats to specific listeners and clusters. risk level: low testing: added unit and integration tests; manually tested to make sure results look sane. docs changes: added docs for new stats and transport socket release notes: added platform specific features: currently only supports linux; other platform support can be added as needed fixes #17617 </desc> <cmt> network filter: new filter for linux-specific tcp network stats </cmt> <cmt> add support for floating point values to histograms. </cmt> <cmt> this is useful for things like percents, which should be in the range 0.0-1.0. </cmt> <cmt> support upstream network filter </cmt> <cmt> fixes </cmt> <iss> add way to get more detailed os level network stats as envoy metrics </iss>",add transport socket wrapper to collect os-level tcp stats and export as envoy metrics
123,"<desc> this is basically an extension of pr 23906 (fix tests for ansi terminals). see for further context (tl;dr is that certain flutter tool tests assert on error output, but this will vary if you run the test from a terminal with ansi colors--the fix mocks the stdout without ansi support). this extends the fix for new tests added since then. related issues no issue opened, but an extension of pr 23906 (fix tests for ansi terminals). before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. my pr includes tests for all changed/updated/fixed behaviors (see test coverage). i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). no, this is not a breaking change. </desc> <cmt> have tests that log error messages use fakeplatform that does not support ansi color, to fix tests from color terms </cmt> <cmt> add the override to the other tests too, in case someone copy & pastes them in the future for a test involving an error message </cmt>",fix more tests for ansi terminals
124,"<desc> address some comments from @davidungar on the recent astscope adoption within the statement checker. </desc> <cmt> simplify astscopeimpl::lookupfallthroughsourceanddest. </cmt> <cmt> [statement checker] simplify findbreakorcontinuestmttarget. </cmt> <cmt> [statement checker] simplify checkunknownattrrestrictions(). </cmt> <cmt> this routine can compute the fallthrough destination on its own. when </cmt> <cmt> it does, we start correctly checking @unknown cases in function </cmt> <cmt> builders, so update and expand the test accordingly. </cmt>",code cleanups for recent astscope adoption
125,"<desc> deprecations? spec compliancy? tests added/pass? fixed tickets fixes #4073, closes #4071 doc pr backport changes from #5422 into master (for release within 6.x). add nointerop option to babel-plugin-transform-es2015-modules-commonjs. document strict option to es2015-modules-commonjs document new nointerop option to es2015-modules-commonjs reference es2015-modules-commonjs options from es2015-modules-amd </desc> <cmt> add nointerop option to babel-plugin-transform-es2015-modules-commonjs. </cmt> <cmt> the intent of this option is to toggle module interop behavior. when true </cmt> <cmt> no interoprequirexxx helper invocations will be emitted. </cmt> <cmt> (cherry picked from commit 0d1edb9811694d25df2ef75a1e8de773624ec6b8) </cmt> <cmt> add docs for strict and nointerop with es2015-modules-commonjs. </cmt> <cmt> (cherry picked from commit 23de276718eda141b7a02934851256462e6b762e) </cmt> <iss> strict option on modules-commonjs enables strict mode js and also strict modules (t7083) </iss> <iss> modules-commonjs and modules-amd with strict:true still uses interoprequire (t7085) </iss>",backport nointerop flag for modules to 6.x.
126,"<desc> instead of finding and compiling all .coffee/.cson files in script/copy-files-to-bundle, we now tell gyp how to do this for us. it works like this: rakefile invokes the new script/generate-sources-gypi script to generate sources.gypi. this file lists all the .coffee/.cson files in the src, static, and vendor directories, as well as a new compiled_sources_dir variable that specifies where the compiled versions of the files should be placed. atom.gyp includes sources.gypi. atom.gyp has a new target, generated_sources, which contains all the .coffee/.cson files, and uses two rules to tell gyp how to compile them. the rules invoke the new script/compile-coffee and script/compile-cson files once for each file. gyp generates one makefile for each rule to actually perform the compilation. script/copy-files-to-bundle now takes the compiled_sources_dir variable as an argument, and copies files both from there and from the repository into the resources directory. by putting the compilation into a different target, we can do it in parallel with compiling/linking our binaries. and gyp automatically runs make using -j$(sysctl -n hw.ncpu), so compilation of .coffee/.cson files happens in parallel, too. these changes reduce clean build time on my macbook pro from 55 seconds to 31 seconds. </desc> <cmt> replace ## in package-generator templates with __ </cmt> <cmt> this is a workaround for </cmt> <cmt> < </cmt> <cmt> a future change will cause gyp to generate makefiles to compile </cmt> <cmt> .coffee/.cson files to .js/.json. makefiles use # as the comment </cmt> <cmt> character, and gyp isn't smart enough to escape the #. so now we don't </cmt> <cmt> use # in filenames to work around this bug. </cmt> <cmt> use gyp's rules functionality to compile .coffee/.cson files </cmt> <cmt> instead of finding and compiling all .coffee/.cson files in </cmt> <cmt> script/copy-files-to-bundle, we now tell gyp how to do this for us. it </cmt> <cmt> works like this: </cmt> <cmt> 1. rakefile invokes the new script/generate-sources-gypi script to </cmt> <cmt> generate sources.gypi. this file lists all the .coffee/.cson files in </cmt> <cmt> the src, static, and vendor directories, as well as a new </cmt> <cmt> compiled_sources_dir variable that specifies where the compiled </cmt> <cmt> versions of the files should be placed. </cmt> <cmt> 2. atom.gyp includes sources.gypi. </cmt> <cmt> 3. atom.gyp has a new target, generated_sources, which contains all the </cmt> <cmt> .coffee/.cson files, and uses two rules to tell gyp how to compile </cmt> <cmt> them. the rules invoke the new script/compile-coffee and </cmt> <cmt> script/compile-cson files once for each file. </cmt> <cmt> 4. gyp generates one makefile for each rule to actually perform the </cmt> <cmt> compilation. </cmt> <cmt> 5. script/copy-files-to-bundle now takes the compiled_sources_dir </cmt> <cmt> variable as an argument, and copies files both from there and from </cmt> <cmt> the repository into the resources directory. </cmt> <cmt> by putting the compilation into a different target, we can do it in </cmt> <cmt> parallel with compiling/linking our binaries. and gyp automatically runs </cmt> <cmt> make using -j$(sysctl -n hw.ncpu), so compilation of .coffee/.cson files </cmt> <cmt> happens in parallel, too. </cmt> <cmt> these changes reduce clean build time on my macbook pro from 55 seconds </cmt> <cmt> to 46 seconds. </cmt> <cmt> only source /opt/github/env.sh if needed </cmt> <cmt> if node is already in path and functional, we don't need to spend a </cmt> <cmt> bunch of time running all of boxen's setup scripts. </cmt> <cmt> this reduces clean build time on my macbook pro from 46 seconds to 31 </cmt> <cmt> seconds. </cmt>",speed up clean builds by compiling .coffee/.cson files in parallel
127,<desc> tack a newline onto the end of all json access log lines low every json unit test will now check to see that there is one (and only one) newline in a log line none none fixes #5018 </desc> <cmt> log a newline after each json access log line </cmt> <cmt> formatting </cmt>,add newline between json log lines
128,<desc> added static red escape green wasd/arrows most qmk animations/effects are included. keys in the 2nd/function layer light up if they have a use. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> updating my fork </cmt> <cmt> very shortened version of the endgame keymap </cmt> <cmt> fixed pictures </cmt> <cmt> fixed link </cmt> <cmt> fixed link </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix files </cmt> <cmt> add green rgb </cmt> <cmt> fixed green rgb </cmt>,pulled some functionality from the engame keymap for the drop ctrl
129,"<desc> update miles2go userspace c functions and #defines add a prime_e keyboard synced to this version of the userspace updates. cleanups in the babblepaste library - now has callback functions for babble_modeswitch_kb/user that are called when the babble mode changes. this makes it easier to have per-keyboard led indicators. added new feature to swap 2-3 keys when the mode changes, so that the most ergonomic position for cut & paste can be preserved across oses. </desc> <cmt> initial user directory </cmt> <cmt> fix missing endif in vi mode </cmt> <cmt> fix includes per drashna and a few typos. i have not tested the userspace keymap, it is just there to help keep the user space and keymap in sync </cmt> <cmt> move babblepaste docs to md format </cmt> <cmt> clean up block quotes </cmt> <cmt> til clang-format - miles2go userspace </cmt> <cmt> keymap tweaking </cmt> <cmt> prime e keymap, clean up macros  in user dir </cmt> <cmt> refined primee keymap, added better kb and user functions for babblepaste, typo fixes for chrome, added modkey swap based on babble mode. </cmt> <cmt> key reorder </cmt> <cmt> swap two keys </cmt>","miles2go userspace  update, add functions for babblepaste library, add prime_e keybard keymap"
130,"<desc> this pull request address issue 2077 #2077 chrome is in the process of strengthening extension security and are making changes to the way extensions work.   these changes move all inline javascript from viewer.html into viewer.js.  the manifest is updated to the new version 2 format.  inline javascript in pdfhandler.html moved to new file pdfhandler.js. these changes allow the extension to load and operate without extension security policy warnings or errors in chrome dev channel and chrome canary. </desc> <cmt> changes to allow chrome extension to load </cmt> <cmt> changes to remove inline scripts, update manifest version, fix make.js </cmt> <cmt> so compatibility.js isn't included for chrome. due to new chrome </cmt> <cmt> extension changes outlined at </cmt> <cmt>  </cmt> <cmt> added copyright </cmt> <cmt> remove added inline.js file </cmt> <cmt> moved inline javascript function to viewer.js rather than create a new </cmt> <cmt> file </cmt>",updates to reenable chrome extension
131,"<desc> description: updates the radiotherm module version to 2.0.0 and changes how errors from the tstat are handled to be in line with the change in api in radiothermm 2.0.0. checklist: local tests pass with tox. your pr cannot be merged unless tests pass new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> radiotherm: bump version to 2.0.0 </cmt> <cmt> radiotherm: change handling of transient errors from tstat </cmt> <cmt> radiotherm 2.0.0 now throws an exception when a transient error is </cmt> <cmt> detected, instead of returning -1 for the field where the error was </cmt> <cmt> detected. this change supports handling the exception. </cmt>",update radiotherm to 2.0.0 and handle change in tstat error detection
132,"<desc> updated openmp minimum required version to 3.0. this is to enable signed and unsigned integers in the for-loop variables. exclude ""build"" directory from doxygen's search path added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines </desc> <cmt> exclude 'build' directory from doxygen </cmt> <cmt> bump openmp version to 3.0 </cmt> <cmt> openmp >= v3.0 supports signed and unsigned for loop variables </cmt>",update openmp version & doxygen path fix
133,"<desc> i also get crashes when the fling is still being run but the view is gone. the patch not tested in production yet, extra tests in the fling runnable may be necessary this is the kinf of crash i get: java.lang.illegalstateexception: imageview no longer exists. you should not use this photoviewattacher any more. at uk.co.senab.photoview.photoviewattacher.getimageview(photoviewattacher.java:226) at uk.co.senab.photoview.photoviewattacher$flingrunnable.run(photoviewattacher.java:909) at android.os.handler.handlecallback(handler.java:615) at android.os.handler.dispatchmessage(handler.java:92) at android.os.looper.loop(looper.java:137) at android.app.activitythread.main(activitythread.java:4898) at java.lang.reflect.method.invokenative(native method) at java.lang.reflect.method.invoke(method.java:511) at com.android.internal.os.zygoteinit$methodandargscaller.run(zygoteinit.java:1006) at com.android.internal.os.zygoteinit.main(zygoteinit.java:773) at dalvik.system.nativestart.main(native method) </desc> <cmt> the posted fling runnable may also be executed when it shouldn't </cmt> <cmt> the post(runnable) may remain as a crash in photoviewattacher sometimes occur after the cancel </cmt>",crash in photoviewattacher after the view is gone
134,<desc> using a keymap file in ~/.atom will make it more obvious how to edit keymaps. we can also document the file so users can discover how to edit keymaps without having to search through docs. </desc> <cmt> load user-keymap.cson instead of keymaps dir </cmt> <cmt> update docs </cmt>,use ~/.atom/keymap.cson file instead of ~/atom/keymaps directory
135,"<desc> hi, i created a simple helm chart to easily install superset in kubernetes. this helm chart is created by helm v2.9.0 and tested in kubernetes v1.9.3 install with helm: helm upgrade --install superset ./install/helm/superset it should start to install superset into ""default"" namespace in kubernetes the image used in this helm chart comes from: </desc> <cmt> add helm chart to install superset in kubernetes </cmt> <cmt> set resources into unlimited </cmt> <cmt> add descriptions to chart.yaml </cmt>",install superset in kubernetes with helm chart
136,"<desc> this fixes #1151. adding the angle bracket include lines didn't actually help with this, but it's probably better to write them like that anyway. </desc> <cmt> made external header includes use angle brackets </cmt> <cmt> removed pedantic flag from php build </cmt> <cmt> updated scripts with php 5.6's build location </cmt> <cmt> fixed scripts again for php 5.5 </cmt> <iss> make the php library compile on php 5.6 </iss>",make php library work with php 5.6
137,"<desc> our jvm ergonomics extract max heap size from jdk printflagsfinal output. on jdk 8, there is a system-dependent bug where memory sizes are cast to 32-bit integers. on affected systems (namely, windows), when 1/4 of physical memory is more than the maximum integer value, the output of printflagsfinal will be inaccurate. in the pathological case, where the max heap size would be a multiple of 4g, the test will fail. the practical effect of this bug, beyond test failures, is that we may set maxdirectmemorysize to an incorrect value on windows. this commit adds a warning about this situation during startup. additionally, we had been testing whether a user had passed a value for maxdirectmemorysize by parsing the output of ""java -xx:printflagsfinal -version"". if maxdirectmemorysize equals zero, we set it to half of max heap. the problem is that on windows with jdk 8, a jdk bug incorrectly truncates values over 4g and returns multiples of 4g as zero. in order to always respect the user-defined settings, we need to check our input to see if an ""-xx:maxdirectmemorysize"" value has been passed. finally, even if a user has set maxdirectmemorysize, they aren't future-proof for this jdk bug. with this change, we issue a general warning for the windows/jdk8 issue, and a specific warning if maxdirectmemorysize is unset. </desc> <cmt> warn when maxdirectmemorysize may be incorrect (windows/jdk8 only issue) (#48365) </cmt> <cmt> our jvm ergonomics extract max heap size from jdk printflagsfinal output. </cmt> <cmt> on jdk 8, there is a system-dependent bug where memory sizes are cast to </cmt> <cmt> 32-bit integers. on affected systems (namely, windows), when 1/4 of physical </cmt> <cmt> memory is more than the maximum integer value, the output of printflagsfinal </cmt> <cmt> will be inaccurate. in the pathological case, where the max heap size would </cmt> <cmt> be a multiple of 4g, the test will fail. </cmt> <cmt> the practical effect of this bug, beyond test failures, is that we may set </cmt> <cmt> maxdirectmemorysize to an incorrect value on windows. this commit adds a </cmt> <cmt> warning about this situation during startup. </cmt> <cmt> don't drop user's maxdirectmemorysize flag on jdk8/windows (#48657) </cmt> <cmt> * always pass user-specified maxdirectmemorysize </cmt> <cmt> we had been testing whether a user had passed a value for </cmt> <cmt> maxdirectmemorysize by parsing the output of ""java -xx:printflagsfinal </cmt> <cmt> -version"". if maxdirectmemorysize equals zero, we set it to half of max </cmt> <cmt> heap. the problem is that on windows with jdk 8, a jdk bug incorrectly </cmt> <cmt> truncates values over 4g and returns multiples of 4g as zero. in order </cmt> <cmt> to always respect the user-defined settings, we need to check our input </cmt> <cmt> to see if an ""-xx:maxdirectmemorysize"" value has been passed. </cmt> <cmt> * always warn for windows/jdk8 ergo issue </cmt> <cmt> even if a user has set maxdirectmemorysize, they aren't future-proof for </cmt> <cmt> this jdk bug. with this change, we issue a general warning for the </cmt> <cmt> windows/jdk8 issue, and a specific warning if maxdirectmemorysize is </cmt> <cmt> unset. </cmt>",add warnings for potential ergonomics failures for jdk8/windows
138,"<desc> sentient has various flow control strategies, all these strategies are based on sentinel internal statistics. the real-time statistics are also useful for system monitoring. unfortunately, sentinel does not provide an extension to obtain these data directly. this pr provides an extension to sentinel internal statistics. as discussed in #211, standardizing sentinel metrics and monitoring is necessary, but we can't expect sentinel to do this. sentinel should not care about the metric implementation, that is in which format the data is stored or in which way the metric is exposed.  that is why metricextension is relevant. in the latter version, it may be necessary to refactor metricwriter to obey the metricextension pattern. none add metricextension interface and related spi classes as an extension to sentinel internal statistics. this extension provides callbacks when a request passes rule checking, blocked by flow control, successfully end or exception occurred. accompanied by these events, response time and current thread number will be recorded too. run test cases. </desc> <cmt> add sentinel metricextension, which provides extension to sentinel internal statistics. </cmt> <cmt> add variable length parameter of metricextension, and refine java doc. </cmt> <cmt> refine metricextension methods and add test cases. </cmt>",[feature]add metric extension to sentinel internal statistics
139,"<desc> hello, to all member of this community! after a long time of commenting, watching, reading and learning from issues posted here it's time for me to propose the following patches/commits. it's been a long time since i wanted to search a possible solution to this recurrent issue and here's my proposition. basically, since i consider that many encoding issues are because upstream maintainer does not convert/encode the domains which rely on idn homograph attack, i decided to read all line and convert/encode all domain using str.encode('idna') (i do not change original structure). because my main objective was to fix @notdavid's protocol which is the only one i was able to reproduce, i introduced beautifulsoup() to do the decoding of the downloaded data before we read each line and encode/decode. about the tests before anything, sorry for adding the fix tests issues commits but i wanted to fix those before submitting my pr. you can find the tests i used as the reference to committing those change at  please note that i have to submit an issue to upstream but if you see the following or related when runing the tests under python >= 3 it's not a local issue. /home/travis/miniconda3/envs/hosts/lib/python3.5/site-packages/bs4/builder/_lxml.py:250: deprecationwarning: inspect.getargspec() is deprecated, use inspect.signature() instead about requirements*.txt this submission also introduces requirements.txt files which i generally use to install dependencies with pip install -r requirements.txt (i'm almost everytime under virtualenv). as i did not get an answer (cf) i took the initiative to includes them anyway. please note that the requirements*.txt files were generated by pipreqs. so to quote my commit message please note that this patch also introduces domain_to_idna() which is in charge of converting a domain in a line into idna and/or utf-8 format. also, note the introduction of beautifulsoup() which helps us to decode data from the downloaded url. fixes (issue(s)/protocol(s) i was able to reproduce): #514 (comment) possible fix of (issue(s)/protocol(s) i wasn't able to reproduce): #514 (comment) #494 (comment) #420 (comment) #372 (comment) #382 (comment) footnote(s) sorry for the typo or bad english structure in my commits, code or this description but english is still a language i learn. so i'm open to any pieces of advice and others around my english, coding style or other cheers, nissar. </desc> <cmt> review of get_file_by_url() </cmt> <cmt> please note that this patch also introduce </cmt> <cmt> which is in charge of converting a domain in a line into </cmt> <cmt> idna and/or utf-8 format. </cmt> <cmt> also note the introduction of beautifulsoup() which helps </cmt> <cmt> us to decode data from the downloaded url. </cmt> <cmt> fixes (issue(s)/protocol(s) i was able to reproduce): </cmt> <cmt> * </cmt> <cmt> possible fix of (issue(s)/protocol(s) i wasn't able to reproduce): </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> introduction of requirements.txt </cmt> <cmt> please note that those file can be used to install </cmt> <cmt> dependencies with 'pip install -r requirements.txt' </cmt> <cmt> fix test issue. </cmt> <cmt> this patch fix </cmt> <cmt> review typo + fix test issue. </cmt> <cmt> this patch fix </cmt> <cmt> fix tests issue </cmt> <cmt> this patch fix </cmt> <cmt> fix tests issue </cmt> <cmt> this patch fix </cmt> <cmt> please also note that i introduced that patch because </cmt> <cmt> we do not directly use lxml but it is required by </cmt> <cmt> beautifulsup() to parse the html. </cmt> <cmt> fix tests issue. </cmt> <cmt> this patch fix </cmt> <cmt> fix tests issues. </cmt> <cmt> this patch fixes: </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> fix tests issues. </cmt> <cmt> this patch introduce the installation of dependencies needed my the main commit. </cmt> <cmt> this patch fixes: </cmt> <cmt> * </cmt> <cmt> * </cmt>",possible fix of the encoding and/or downlaod issue(s)
140,"<desc> linear advance is often used on multi-extruder setups where each extruder uses a different material. obviously the material properties therefore differ so a different k factor will be required for each extruder. this also allows the use of linadv on one extruder but entirely disabling on others, this is useful for hybrid direct-bowden drives where too high a k factor on the direct drive unit can ruin the print. this pr adds individual k factors and their required setters on the lcd menus. </desc> <cmt> added individual k factor support for multi-extruder systems. </cmt> <cmt> fixed ultralcd multi linear advance k support </cmt> <cmt> added k factor lcd setters </cmt> <cmt> formatting corrections (i hope) </cmt>",extruder-distinct linear advance k factors
141,"<desc> currently the base64 fetch will prefer to read from local cache if the url is known, or do a remote fetch if the url is unknown. it does not do an in-flight check which means the same url could be scheduled and fetched multiple times, as long as one has not completed. this applies to remote fetch and local cache fetches. this pr introduces two caches (separate commits): an in flight cache containing any request that has not resolved a resolved cache, containing the payload of resolved requests the function will now prefer to return the data sync, from the resolved cache. if the url is not known there then it will check the in flight cache. this cache may contain the promise if it is still in flight, or if the request rejected (it will not retry). if that cache doesn't have it then the disk cache is checked. if the disk cache has it then read it and return it. otherwise do a remote fetch and return it. in both fetch cases, the read promise is stored in the in flight cache and when it resolves, it is removed from the in flight cache and its payload added to the resolved cache. in the real world i stumbled on a customer where the site was triggering 245.000 base64 image requests (these are only debounced by the nodejs default limits and, to some degree, by the query concurrency count). it turned out that there were actually only 5.000 unique urls, so 240.000 requests were redundant. while testing that same site we encountered curious inconsistent delays that tracked back to this function. </desc> <cmt> perf(gatsby-source-contentful): add inflight check for base64 fetches </cmt> <cmt> add resolved map to return data sync when possible </cmt>",prevent redundant fs/remote fetches for base64
142,"<desc> fixes #20431 </desc> <cmt> [table] add role attr when component prop is set </cmt> <cmt> [tablebody]add role attr when component prop is set </cmt> <cmt> [tablefooter] add role when component prop is set </cmt> <cmt> [tablehead] add role when component prop is set </cmt> <cmt> [tablerow] add role when component prop is set </cmt> <cmt> [tablecell] add role when component prop is set </cmt> <iss> add role=""..."" to table family components when component=""..."" is specified </iss>",add role if the default role of elements can't be used
143,<desc> dry up spots where we use the same pattern to get from an inputstream to a bytesreferences </desc> <cmt> dry up reading inputstream to bytesreference </cmt> <cmt> * dry up spots where we use the same pattern to get from an inputstream to a bytesreferences </cmt> <cmt> fix import </cmt>,dry up inputstream to bytesreference
144,"<desc> please check the patches for the bcm2835-ctl that convert chipvol back to db, fix the cange compare and limit the max volume to 4db. with this patch alsamixer works with the raspberry pi. </desc> <cmt> bcm2835-ctl: fix alsamixer control. </cmt> <cmt> alsamixer read the volume for the screen controller so we had to </cmt> <cmt> scale the chipvol back to db for reading. </cmt> <cmt> bcm2835-ctl: limit maximal volume to 4db. </cmt> <cmt> it makes no sense to set 23.04db as maximum volume since around 3db it start to cliping. so with 4db the alsamixer is much better to control. (86% is 0db) </cmt>",patches for bcm2835ctl that make alsamixer useable
145,<desc> this is the backport of master merged pr r: @aheise </desc> <cmt> [flink-21407][doc][formats] add formats to datastream connectors doc </cmt> <cmt> [flink-21407][doc][formats] move haddop input and output formats to hadoop.md formats page </cmt> <cmt> [flink-21407][doc][formats] update hadoop doc </cmt> <cmt> [flink-21407][doc][formats] drop old formats </cmt> <cmt> [flink-21407] bump microsoft-hadoop-azure version </cmt> <cmt> [flink-21407][doc][formats] split dataset connectors page into different formats and create a formats sub-folder like in table api doc </cmt>,add formats to datastream connectors doc. backport to release 1.14
146,"<desc> rails 5.0.1 introduced a bug (#27582), which was fixed by #25877. however, the fix was only merged to master. there doesn't appear to be an easy way for me to workaround this bug, so it would be great if it could be merged into 5-0-stable as well. </desc> <cmt> delegate to scope rather than merge! for collection proxy </cmt> <cmt> merge! association.scope(nullify: false) is expensive but most methods </cmt> <cmt> do not need the merge. </cmt> <cmt> cache target scope for collection proxy </cmt> <cmt> no need to cache collection proxies separately </cmt> <cmt> because merging the association scope was removed. </cmt> <cmt> define respond_to_missing? instead of respond_to? </cmt>","backport ""delegate to scope rather than merge! for collection proxy"""
147,"<desc> what did you implement added documentation for mock integrations, regarding aws api gateway events. closes #5960 how can we verify it reading the documentation, added a simple mock example. write and run all tests write documentation enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> added mock integration example to documentation </cmt> <cmt> prettified mock example </cmt> <iss> doc request: working example of mock integration </iss>",added mock integration documentation example
148,"<desc> fix led indicators. they are inverted currently. e.g. capslock is off, led is on. led indicators opposite. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> led fix </cmt>",aeboards ext65 - fix led indicators
149,"<desc> fixes #55399, fixes #54100 when trying to resolve a macro, rustdoc first tries to load it from the resolver to see whether it's a macros 2.0 macro, so it can return that def before looking for any other kind of macro. however, this becomes a problem when you try to load proc-macros: since you can't use a proc-macro inside its own crate, this lookup also fails when attempting to link to it. however, we have a hint that this lookup will fail: macros which are actually procmacrostubs will fail the lookup, so we can use that information to skip loading the macro. rustdoc will then happily check resolve.all_macros, which will return a usable def that we can link to. </desc> <cmt> don't call get_macro on proc-macro stubs </cmt> <cmt> add intra-doc link test to proc-macro test </cmt> <iss> compiler panics when documenting sub-crate with links to types of super-crate on latest nightly </iss> <iss> links in doc comments to proc_macro_attribute functions cause rustdoc panic </iss>",fix ice from loading proc-macro stubs
150,"<desc> points: 9s of availability with example of 99.9 and 99.99 percentage difference in availability with components in sequence or parallel </desc> <cmt> added information about availability, quantification and sequence vs parallel changes </cmt> <cmt> update readme.md </cmt>",add availability in numbers section
151,"<desc> like i did with easeljs, i made the intentation consistent in preloadjs and tweenjs a number of function signature fixes in easeljs, preloadjs, and tweenjs </desc> <cmt> preloadjs: converted inconsistent intentation to spaces (like easeljs). </cmt> <cmt> preloadjs: loadfile() and loadmanifest() second argument should be optional </cmt> <cmt> preloadjs: removed unnecessary overload of getresult() on loadqueue </cmt> <cmt> tweenjs: converted inconsistent intentation to spaces (like easeljs). </cmt> <cmt> tweenjs: fixed signature of static get() on tween </cmt> <cmt> easeljs: fixed signature of static extractframe() on spritesheetutils </cmt>",createjs function signature fixes and intentation consistency
152,"<desc> fixes #1119 . the implementation is in the form of a tweak to the serial tree learner and so should work with every derived tree learner, though i've only tested in serial. </desc> <cmt> add configuration parameters for cegb. </cmt> <cmt> add skeleton cegb tree learner </cmt> <cmt> like the original cegb version, this inherits from serialtreelearner. </cmt> <cmt> currently, it changes nothing from the original. </cmt> <cmt> track features used in cegb tree learner. </cmt> <cmt> pull cegb tradeoff and coupled feature penalty from config. </cmt> <cmt> implement finding best splits for cegb </cmt> <cmt> this is heavily based on the serial version, but just adds using the coupled penalties. </cmt> <cmt> set proper defaults for cegb parameters. </cmt> <cmt> ensure sanity checks don't switch off cegb. </cmt> <cmt> implement per-data-point feature penalties in cegb. </cmt> <cmt> implement split penalty and remove unused parameters. </cmt> <cmt> merge changes from cegb tree learner into serial tree learner </cmt> <cmt> represent features_used_in_data by a bitset, to reduce the memory overhead of cegb, and add sanity checks for the lengths of the penalty vectors. </cmt> <cmt> fix bug where cegb would incorrectly penalise a previously used feature </cmt> <cmt> the tree learner did not update the gains of previously computed leaf splits when splitting a leaf elsewhere in the tree. </cmt> <cmt> this caused it to prefer new features due to incorrectly penalising splitting on previously used features. </cmt> <cmt> document cegb parameters and add them to the appropriate section. </cmt> <iss> adding cost effective gradient boosting to lightgbm </iss>",add cost effective gradient boosting
153,"<desc> yarn start works to serve components i renamed connecttostreamlit() -> withstreamlitconnection() </desc> <cmt> component template: run the dev server on :3001 </cmt> <cmt> allow serving components from url </cmt> <cmt> connecttostreamlit -> withstreamlitconnection </cmt> <cmt> always send our most recent render arguments when we get a component_ready message </cmt> <cmt> fix typo </cmt> <cmt> don't throw an exception if the same component is registered multiple times. </cmt> <cmt> whoops, didn't mean to leave that in </cmt>",allow serving components from a url
154,"<desc> remove testing targets that were not tested during final release. </desc> <cmt> disable the gpu on cpu tests as they were added for 2.1 </cmt> <cmt> remove //tensorflow/tools/... from linux builds. </cmt> <cmt> these were not tested in 1.15 on the release of 1.15.0, so no need to </cmt> <cmt> have them green on 1.15.1. </cmt> <cmt> remove //tensorflow/tools/... from the test targets. </cmt> <cmt> not tested on 1.15.0 release, no need to test now. </cmt> <cmt> disable test that times out on mac non pip builds </cmt>",attempt 4 at fixing release builds
155,<desc> in preparation for re-writing the operator decl lookup logic. </desc> <cmt> [sema] factor out lookupprecedencegroupforrelation </cmt> <cmt> and handle a cycle specially rather than defaulting </cmt> <cmt> to nullptr and doing another lookup to check. </cmt> <cmt> [ast] collapse two arrays into one </cmt> <cmt> store an array of located<identifier> instead of </cmt> <cmt> an array of identifiers and sourcelocs on </cmt> <cmt> operatordecl. this allows us to cleanup </cmt> <cmt> operatorprecedencegrouprequest a little. </cmt> <cmt> [sema] remove some dead code </cmt> <cmt> the parser should ensure that we never encounter </cmt> <cmt> this case. </cmt>,a couple of cleanups around operator and precedence groups
156,"<desc> this pr refactors the data structures used for shortcut remaps. earlier a vector of keys was used, however this had many issues w.r.t constraining the order of keys in the ui, constraining the type of keys used in the shortcut and supporting left/right versions of modifiers. this pr adds a shortcut class instead which contains function wrappers for all shortcut key related logic, while maintaining most of the actual remap logic in dllmain.cpp pr checklist applies to #6 cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments added a shortcut class, which stores all the modifiers and the action key associated with the shortcut. it also contains member functions for converting to virtual key codes, converting to string, and other remapping logic functions. added a remapshortcut class. earlier the std::map used was std:map<vector, pair<vector, bool>>. to clean this up, it is now std:map<shortcut, remapshortcut> where remapshortcut consists of a shortcut (the target shortcut), a bool variable (for checking if the shortcut was invoked), and a modifierkey value to check which windows key was pressed. the last is required to handle shortcut remaps which can work for either win key (there is no virtual key code for a common win key like that which exists for ctrl, alt, shift). this value is used to remember which win key was pressed when the shortcut was invoked. it is kept in this remapshortcut class and not in the shortcut class itself since the key object in an std::map must be const and cannot be modified. the shortcut class now allows all modifiers to have displayable name based on whether it was left or right (example lctrl or rctrl) and a common one as well (ctrl). common versions of all modifiers have been implemented. a user can now use ctrl+a rather than lctrl+a specifically. this is however not yet accessible on the ui since the detect key window won't show that according to the spec. by making the common ctrl key work on the backend this allows the drop down ui work for shortcuts. a decodekey function has been added in shortcut class which converts the key code to the key name. this currently only shows a name for modifier keys since those are fixed. this function would have to be moved out later since it isn't specific for shortcuts. this will be done when the keyboard unicode mapping code is integrated. rctrl and ralt have not yet been handled correctly (to be done in another pr). the changes should improve performance a bit for remapping since fixed size objects are now used instead of dynamic vectors. validation steps performed build and run with different types of shortcuts. rctrl, ctrl, ralt, and alt have issues, all other cases are handled. </desc> <cmt> added unique lock mutexes for thread safety </cmt> <cmt> fixed a bug in detect key logic </cmt> <cmt> changed dword to word </cmt> <cmt> added early unlock statements to fix issue with shortcut guide </cmt> <cmt> fixed type conversion warnings </cmt> <cmt> migrated detect shortcut window to use shortcut class </cmt> <cmt> made changes in apply button logic </cmt> <cmt> revert thread safety changes </cmt> <cmt> refactored code works on the ui side </cmt> <cmt> refactored remapping code to use new shortcut class </cmt> <cmt> refactored to setkeyevent function </cmt> <cmt> moved function to cpp file and added more comments </cmt> <cmt> synced changes from feature branch </cmt>",refactor shortcut remaps to distinguish modifiers and action keys
157,<desc> includes the following prs plus a bump to beta .2 #32032 #32039 #32041 #32164 </desc> <cmt> truncate i8-s to i1-s when loading constants </cmt> <cmt> fixes #30891 </cmt> <cmt> clean up check_pat_enum </cmt> <cmt> don't treat unit patterns as wildcard patterns </cmt> <cmt> fixes #32004 </cmt> <cmt> remove wrong assert in check_match </cmt> <cmt> the assert was invalidated by pr #31020 </cmt> <cmt> fixes #31561 </cmt> <cmt> do not report errors from regionck if other errors were already </cmt> <cmt> reported during the lifetime of this inferencer. fixes #30580. </cmt> <cmt> add comment explaining purpose of test </cmt> <cmt> bump beta to .2 </cmt>,merge in beta-accepted into beta
158,"<desc> what does this fix? the --entity argument for configuring the wandblogger is currently unused. this pr fixes that, including for resumed runs, fixes a bug for run resuming, and adds a docstring to the wandblogger class. how has this been tested? the core fix, to entity setting for non-resumed runs, is tested in this repro colab, and the new tagging is used in this artifact produced by that colab. the other fixes, including resumption based on the new tags, have not been directly tested, since i don't have a good setup for testing resumption and ddp. @ayushexel could you check these? deep dive projects in weights & biases are organized under entities, which may be organizations, teams, or individual users. a user may sometimes wish to log to their personal entity (e.g. glenn-jocher) or to their team entity (e.g. ultralytics). the --entity cli argument to train.py is intended to allow users to set the entity to which they are logging. it does not do so currently, and this pr fixes that. in addition, the handling of entities in resumed runs (and in ddp sub-processes during resumed runs) was implicit -- it was assumed that the entity of the provided run was the same as the user. this has been corrected in the pr, and resumed runs are now logged to the original entity, not the user's entity. separately, this surfaced an issue with the resumption of runs -- in train.py, models are given the alias last, while in the code for resumption it is assumed that they have alias latest. the former is a yolov5 convention and the latter is a wandb convention. for backwards compatibility and completeness, this pr applies both aliases, but could be amended to use just one or the other. finally, this commit adds extra docstrings to wandb_utils: at the module level and to wandblogger. </desc> <cmt> adds latest tag to match wandb defaults </cmt> <cmt> adds entity handling, 'last' tag </cmt>",improves docs and handling of entities and resuming by wandblogger
159,"<desc> the history vector passed down through lookup was only used for the selfdc and iscascading computations, both of which are now gone. members of the active clause of an ifconfigdecl are visited as part of their parent, so we don't have to walk into ifconfigdecls at all. the parameterlistscope is only used as a parent for default argument initializer scopes, and doesn't bind any names, so it can be a sibling rather a parent of the functionbodyscope, which simplifies some source range computations. </desc> <cmt> astscope: functionbodyscope should not be nested inside parameterlistscope </cmt> <cmt> astscope: remove expandifconfigclauses() </cmt> <cmt> we're always guaranteed to visit the elements of the active clause </cmt> <cmt> as members of the parent ast node. </cmt> <cmt> astscope: remove shouldthisnodebescopedwhenfoundinsourcefilebracestmtortype() </cmt> <cmt> astscope: remove 'history' vector </cmt>",clean up ifconfigdecl handling and a couple of other things
160,"<desc> added a section to the inkwell documentation highlighting that widget transitions within an inkwell widget may cause clipping or unpleasant rippling effects. related issues fixes #5211 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> added inkwell docs on transitions causing clipping </cmt> <cmt> remove analysis benchmark file </cmt> <cmt> clarified header </cmt> <iss> inkwell doesn't work well in animatedcontainer. </iss>",add inkwell docs on transitions and ink splash clipping
161,"<desc> this pr improves the placeholder type annotations for the main numpy namespace, namelly to provide something a bit more oncrete than just plain any. the improvements can be divided into four general categories: miscelanous objects (e.g. scalartype): have been fully annotated. classes (e.g. iinfo): have been annotated as type[any]. python-based functions (e.g. angle): have been replaced with proper (unannotated) functions, constructed with the help of inspect.signature. c-based functions (e.g. arange): have been annotated as callable[..., any] as we can't (ab)use inspect.signature here. applying similar improvements to the various other namespaces is considered beyond the scope of this pr and reserved for future work. </desc> <cmt> enh: improve placeholder annotation for non-function objects </cmt> <cmt> e.g. types and instances </cmt> <cmt> enh: improve placeholder annotations for python-based functions </cmt> <cmt> enh: improve placeholder annotations for c-based functions </cmt> <cmt> enh: annotate a few previously missing ufuncs as such </cmt> <cmt> dep: remove all references to numarray from the namespace </cmt> <cmt> it has been deprecated and removed for quite some time </cmt>",improve the placeholder annotations for the main numpy namespace
162,<desc> ref:  closes: #84532 the release-1.17 branch has been created. this pr adds rules for 1.17 and removes the 1.13 ones as it isn't supported anymore. /hold until it is confirmed that it is safe to remove the 1.13 rules /assign @sttts @dims / does this pr introduce a user-facing change?: </desc> <cmt> publishing: remove 1.13 rules </cmt> <cmt> publishing: add 1.17 rules </cmt> <iss> update publishing-bot for release-1.17 </iss>,add rules for 1.17 and remove for 1.13
163,<desc> case 2. improvement to existing type definition. source reference:   fixes #10212 </desc> <cmt> update from original </cmt> <cmt> angularjs - added optional interceptorfn and expensivechecks parameters to iparseservice </cmt> <iss> angularjs iparseservice doesn't support the interceptorfn and expensivechecks params </iss>,angularjs - additional params for $parse service
164,"<desc> problem: we need to deploy jenkins on openshift using helm. solution we need to add annotation to service account so that openshift can correctly route to service. a sample annotation looks like this serviceaccounts.openshift.io/oauth-redirectreference.jenkins: >- {""kind"":""oauthredirectreference"",""apiversion"":""v1"",""reference"":{""kind"":""route"",""name"": ""route-name"" }} what this pr does? add option to specify annotations for service account. dco signed </desc> <cmt> sync upstream </cmt> <cmt> fix configmap of keycloak </cmt> <cmt> merge helm/charts master into stakater/charts master </cmt>",add support for service account annotations in jenkins
165,"<desc> recently used files in db4s were previously displayed at the bottom of the file menu. however, i've implemented this idea because i thought it would be better to create a menu called recent files in the file menu, and access the recent files in it and delete the list if necessary. and also, i'm ready to listen to any advice. this is because i'm not sure about the qt framework and i'm afraid about requesting this pr without knowing the atmosphere of the db4s team to see if it is okay to send a contribution to the implementation of the function. i wait for your valuable advice or feedback. thanks! known bugs after opening the file, it is not added to the recent files list (but added normally when the db4s is restarted) i cross-validated with the nightly build (release on july 27, 2020) to confirm that is is a problem in my code. md5 : e1d4952fd91625403c7a57ca7be3e252 sha256 : 53739c57b44c02fea06758eb6e95be12598c54da5f9700c52d48ff64d8ca90ba test environment macos catalina 10.15.6 homebrew 2.4.9 </desc> <cmt> add a new menu item to the list of recent files in the file menu </cmt> <cmt> declare method prototype that delete recent file list </cmt> <cmt> implement method that delete recent file list </cmt> <cmt> declare a method prototype to handle the newly added menu item </cmt> <cmt> declare a method prototype to handle the newly added menu item. </cmt> <cmt> and delete divider(qaction *recentseparatoract) because that is no longer used. </cmt> <cmt> implement method that delete recent file list </cmt> <cmt> implement method that delete recent file list by newly added menu item. </cmt> <cmt> and delete divider(qaction *recentseparatoract) because that is no longer used. </cmt>",move recent files item to new context menu and add clear recent file function
166,"<desc> closes #3852 fix running tests in chrome and firefox when cypress is installed in a read-only location the addon installation need write access to background.js, while copying from read-only location retain the non-writable permission. older implementation on #5579 without any test. has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> fix(server): add tests for eaccess on extension install </cmt> <cmt> fix(server): fix eacces error on extension install </cmt> <iss> after upgrading to 3.2.0 specs won't run on chrome or chromium only on electron browser </iss>",fix eacces on extension installation if copied from read-only location
167,<desc> close #3926 </desc> <cmt> properly handles getting document stylesheets when no document </cmt> <cmt> - instead have the document be a default object when undefined </cmt> <cmt> - wrote test to handle undefined document </cmt> <cmt> properly handle runnable being undefined when creating a log </cmt> <iss> assertions run outside of a test should be handled properly in cypress (not throw internal errors) </iss>,fix assertions running outside of test to not throw err
168,"<desc> preallocate support for hashed/sparse_hashed dictionaries detailed description / documentation draft: it was initially implemented in #15454, but was reverted in #21948 (due to higher memory usage). this implementation differs from the initial, since now there is separate attribute to enable preallocation, before it was done automatically, but this has problems with duplicates in the source. plus this implementation does not uses dynamic_cast, instead it extends idictionarysource interface. benchmarks name type duration elements bytes prealloc win graph_hashed hashed 702.099 2.28 billion 128.00 gib graph_hashed_preallocate hashed 509.606 2.28 billion 128.00 gib 27% graph_sparsehashed sparsehashed 3562.452 2.28 billion 21.21 gib graph_sparsehashed_preallocate sparsehashed 2747.515 2.28 billion 21.21 gib 30% cc: @kitaisreal </desc> <cmt> drop unused getdictionaryconfigurationfromast.h </cmt> <cmt> attach background thread for dictionary reload to the reload query </cmt>",reimplement preallocate for hashed/sparse_hashed dictionaries
169,<desc> this pull request removes unsupported cocos2d-x image formats from the winrt wic converter (we use this native code to decode png files). </desc> <cmt> unsupported cocos2d-x image formats removed or updated </cmt> <cmt> unsupported cocos2d-x image formats removed or updated </cmt>,winrt unsupported cocos2d-x image formats removed or updated
170,<desc> overview this pr adds two new examples to the transform examples. both of them show how to use top_metrics in transforms. preview bytes example email and name example </desc> <cmt> [docs] adds top_metrics aggs examples to transform examples. </cmt> <cmt> [docs] minor edits. </cmt>,adds top_metrics aggs examples to transform docs
171,"<desc> small fix to normalize behavior for invalid values for the win.setopacity(). for example: win.setopacity(100) or win.setopacity(-100). current behavior with invalid values windows: win.setopacity(opacity): supposed to normalize the [0,1] opacity values to 255. however, for invalid values, passing in opacity * 255 leads to unexpected behavior. win.getopacity(): retrieves the invalid opacity value that was previously passed in. macos: win.setopacity(opacity): bounds opacity value to the [0,1] range (i.e. (opacity < 0) -> (opacity = 0) and (opacity > 1) -> (opacity = 1)) win.getopacity(): retrieves the invalid opacity value that was previously passed in. linux (unsupported): win.setopacity(opacity): takes no action on the actual window opacity, but stores the opacity value. win.getopacity(): retrieves the previously stored opacity value. proposed behavior macos/windows: win.setopacity(opacity): bounds opacity value to the [0,1] range win.getopacity(): retrieves the bounded opacity value. linux: win.setopacity(opacity):  takes no action. win.getopacity(): always returns 1. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: normalized out-of-bound value behavior for the setopacity() api in browserwindow. </desc> <cmt> fix: define behavior for out-of-bounds setopacity </cmt> <cmt> fix linux issue </cmt> <cmt> fix getopacity behaviour </cmt> <cmt> wrong variable </cmt>",normalize behavior of win.setopacity() for invalid number values across operating systems
172,"<desc> closes two issues. </desc> <cmt> update news </cmt> <cmt> dhcp: make sure we can deal with a single trailing nul byte in the hostname </cmt> <cmt> fixes #1337 </cmt> <cmt> journal: make sure to set mhd_use_pipe_for_shutdown for libmicrohttpd servers </cmt> <cmt> this makes sure libmicrohttpd won't call shutdown() on our listening </cmt> <cmt> sockets, which make sure socket activation and re-activation will work </cmt> <cmt> cleanly. </cmt> <cmt> see: </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> fixes #1286 </cmt>","dhcp and journal remoting fix, as well as news update"
173,<desc> two small changes we need for workflows: a note about not necessarily needing graphql or gatsby image on the new api doc instructions for adding new recipe categories </desc> <cmt> docs(images): add note about not needing graphql </cmt> <cmt> add recipe header instructions </cmt>,image and recipe docs updates
174,"<desc> this completes the set of changes required to make the mac build equal to the linux build, if the mac-specific instructions in install are followed. the tests now all build (except for the pubsub test which is also currently broken on linux) note that this has required a ""substantial"" change to server/server.cc , but this is entirely moving a large block of code around because the compiler on my mac expected a full (not forward) declaration of syncrequest before it could deal with the exception handling for a std::list template. </desc> <cmt> do not need a mac-specific cpu header yet as there are no cpu-specific features </cmt> <cmt> in use yet </cmt> <cmt> some compilers expect class syncrequest to be declared fully and not just </cmt> <cmt> forward-declared before the constructor for server because this is needed </cmt> <cmt> to manage exception handling for the class std::list that is templated </cmt> <cmt> on syncrequest </cmt> <cmt> include typecasts so that int and size_t are not compared (since their </cmt> <cmt> signs don't match) </cmt> <cmt> more typecasts to avoid sign-comparison problems on expect_eq </cmt>",mac build is now ready
175,"<desc> hey @jwasham  these were missing links in c++ section under programming language resources , i have looked on the web and added the best resources in them. please review if they are helpful to the users. </desc> <cmt> added links to c++ </cmt> <cmt> updated compilation link </cmt>",links added to c++ in coding-interview-university/programming-language-resources.md
176,"<desc> see </desc> <cmt> change <yandex> to <clickhouse> in configs </cmt> <cmt> change repository url in docs </cmt> <cmt> change doker hub url </cmt> <cmt> changed substitution path name </cmt> <cmt> change docker org name </cmt> <cmt> change alpine dockerfile </cmt> <cmt> change website url, part 1 </cmt> <cmt> edit some mentions on the website </cmt>",replace <yandex> to <clickhouse> in configs and more.
177,<desc> ref #19555 this prevents the on_percentage_changed from being sent out constantly even if the value has not been changed if the slider is being touched. </desc> <cmt> sync from master </cmt> <cmt> only send the on_percentage_changed if and only if the percentage value has actually changed. </cmt>,only send on_percentage_changed when value has changed
178,"<desc> for operators, which performance is limited by global memory bandwidth, it is important to issue the widest possible loads, as it ensures that the bandwidth is fully utilized. currently in mxnet we use vectorized loads and stores only for half_t type for a few operators (some elementwise binary operators and elementwise_sum). unfortunately, the way it was done makes some assumptions about mxnet's ndarrays which do not hold true for all cases. failure 1: import mxnet as mx ctx=mx.gpu() a = mx.nd.array([1,2,3,4], dtype='float16', ctx=ctx) b = mx.nd.array([1,2,3,4], dtype='float16', ctx=ctx) c = a[1:3] d = b[1:3] mx.nd.elemwise_add(c, d, out=c) results in error: check failed: e == cudasuccess: cuda: misaligned address failure 2: import mxnet as mx ctx=mx.gpu() a = mx.nd.array([1,2,3,4], dtype='float16', ctx=ctx) b = mx.nd.array([1,2,3,4], dtype='float16', ctx=ctx) print(a) c = a[0:3] d = b[0:3] mx.nd.elemwise_add(c, d, out=c) mx.nd.waitall() print(c) print(a) gives: <ndarray 4 @gpu(0)> <ndarray 3 @gpu(0)> <ndarray 4 @gpu(0)> which is a silent data corruption (the last element of a should not have been changed). it was not noticed before because a + b for ndarrays launches the broadcast_add instead of elemwise_add (and is not vectorized), whereas in the symbolic execution slices give new allocations, which do not exhibit those issues. this pr: fixes those issues introduces helpers for handling vectorization (for all types, not only half_t) increases performance of vectorized kernels introduces vectorization for all binary/unary/binary with scalar ops (wip) introduces vectorization for broadcast ops @eric-haibin-lin @sxjscience @haojin2 please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) code is well-documented: for new c++ functions in header files, their functionalities and arguments are documented. to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change properly handle vectorized loads and stores in elementwise kernels handle vectorized loads and stores in elementwise broadcast kernels </desc> <cmt> vectorized loads for binary elemwise kernel </cmt> <cmt> more generalization </cmt> <cmt> add backwardusenone </cmt> <cmt> remove the unused _backward_add op </cmt> <cmt> add vectorized backwardusein </cmt> <cmt> extending vectorization to more binary ops, binary ops with scalar and </cmt> <cmt> unary ops </cmt> <cmt> handling elementwisesum </cmt> <cmt> get rid of half2 in mshadow </cmt>",fix and optimize handling of vectorized memory accesses
179,<desc> adds a section on how to configure bitbucket pipelines to cache .next/cache on consecutive builds. </desc> <cmt> update no-cache.md: add bitbucket pipelines </cmt> <cmt> add section on how to setup caching for bitbucket pipelines </cmt> <cmt> update no-cache.md </cmt> <cmt> change wording of referencing the next cache in bitbucket pipeline </cmt>,add bitbucket pipelines to errors/no-cache.md
180,"<desc> tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> tst: collect/split </cmt> <cmt> tst/ref: split/better names </cmt> <cmt> misplaced setitme test </cmt> <cmt> misplaced formerly-ix tests </cmt> <cmt> collecting indexing tests by method </cmt>",collect indexing tests by method
181,<desc> currently if you type to search in colorschemecontrol it crashes the whole page. test plan added a cypress test requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix: colorschemecontrol should not be creatableselect </cmt> <cmt> currently if you type to search in colorschemecontrol it crashes the </cmt> <cmt> whole page. </cmt> <cmt> make it possible to filter by label </cmt>,colorschemecontrol should not use creatableselect
182,"<desc> some improvements for ios bitcode support suggested by alex over at getditto/rust-bitcode#9. r? @alexcrichton this improves rust's bitcode generation so that provided you have a compatible llvm version, rust targeting ios should work out of the box when compiled into bitcode-enabled apps, and when submitted to the app store. i've tested these changes using xcode 11.4.1 and apple's vendored llvm, tag swift-5.2.3-release. force aarch64-apple-ios and aarch64-apple-tvos targets to always emit full bitcode sections, even when cargo is trying to optimise by invoking rustc with -cembed-bitcode=no. since apple recommends bitcode on ios and requires it on tvos it is likely that this is what developers intend. currently you need to override the codegen options with rustflags, which is far from obvious. provide an llvm cmdline in the target spec. apple's bitcode verification process looks for some arguments. for rust modules to be accepted we must pretend they were produced similarly. a suitable default is provided in targetoptions for ios, copied directly from the a clang equivalent section. in the context of apple platforms, the predominant purpose of bitcode is app store submissions, so simulator and 32-bit targets are not relevant. i'm hoping that the cmdline strings will not be a maintenance burden to keep up-to-date. if the event of any future incompatibilities, hopefully a custom target config would offer enough flexibility to work around it. it's impossible to say for sure. due to unrelated build errors i haven't been able to build and test a full tvos toolchain. i've stopped short of providing a similar bitcode_llvm_cmdline until i can actually test it. </desc> <cmt> force embed-bitcode on non-simulator ios/tvos targets </cmt> <cmt> at this time apple recommends bitcode be included for ios apps, and </cmt> <cmt> requires it for tvos. it is unlikely that a developer would want to </cmt> <cmt> disable bitcode when building for these targets, yet by default it will </cmt> <cmt> not be generated. this presents a papercut for developers on those </cmt> <cmt> platforms. </cmt> <cmt> introduces a new targetoption boolean key for specific triples to </cmt> <cmt> indicate that bitcode should be generated, even if cargo attempts to </cmt> <cmt> optimise with -cembed-bitcode=no. </cmt> <cmt> provide configurable llvm cmdline section via target spec </cmt> <cmt> the app store performs certain sanity checks on bitcode, including that </cmt> <cmt> an acceptable set of command line arguments was used when compiling a </cmt> <cmt> given module. for rust code to be distributed on the app store with </cmt> <cmt> bitcode rustc must pretend to have the same command line arguments. </cmt>",improve bitcode generation for apple platforms
183,"<desc> resolves #2099. for get block to pretty print the action data struct in transactions it must have the abi for the struct. if a contract is updated with new abi, it must therefore keep the old abi around so that get block can display it. otherwise get block will just print the hex version of the action data struct. this pr adds a check for unknown type and reverts back to hexdata of the action data. also added the eosio.bios abi to eosio.system abi so that when eosio.system replaces eosio.bios users can still see the structs of blocks that contain eosio.bios abi. </desc> <cmt> add check for unknown type </cmt> <cmt> remove issue 2099 special check </cmt> <cmt> add check for unknown type </cmt> <cmt> remove issue 2099 special check </cmt> <cmt> add bios actions/structs so get blocks with these structs provides pretty print output </cmt>",get block display of old structs
184,<desc> fixes #16535 this pr enables testing the os x staticbuild. exclude 3 tests: test_extensions.test_subgraph and test_extensions.test_custom_op as they are unsupported for staticbuild. test_gluon_data.test_recordimage_dataset_with_data_loader_multiworker as it times out on github actions (maybe too many workers) </desc> <cmt> remove travis and appveyor config </cmt> <cmt> update codeowners </cmt> <cmt> run python unittests after build </cmt> <iss> ci travis time out </iss>,run python unittests on os x with github actions
185,"<desc> ios-deploy relies on lldb.framework, which relies on /usr/bin/python and the 'six' module that's installed on the system. however, it appears to use the first version of python on path, rather than explicitly specifying the system install.  if a user has a custom install of python (e.g., via homebrew or macports) ahead of the system python on their path, lldb.framework will pick up that version instead. if the user hasn't installed the 'six' module, ios-deploy will fail with a relatively cryptic error message. this patch pushes /usr/bin to the front of path for the duration of the ios-deploy run to avoid this scenario. this patch also removes checks for package six. neither flutter nor any of its direct dependencies/tooling relies on package six. ios-deploy depends on lldb.framework (included with xcode), which relies on a python script that imports this package but uses whichever python is at the front of the path. flutter now invokes ios-deploy with a path with /usr/bin forced to the front in order to avoid this problem. we could have retained the check out of paranoia, but this seems unnecessary since it's entirely possible lldb.framework may one day drop this dependency, in which case i'd expect the base system install of python would likely drop it as well. </desc> <cmt> push /usr/bin to front of path for xcodebuild runs </cmt> <cmt> ios-deploy relies on lldb.framework, which relies on /usr/bin/python and </cmt> <cmt> the 'six' module that's installed on the system. however, it appears to </cmt> <cmt> use the first version of python on path, rather than explicitly </cmt> <cmt> specifying the system install.  if a user has a custom install of python </cmt> <cmt> (e.g., via homebrew or macports) ahead of the system python on their </cmt> <cmt> path, lldb.framework will pick up that version instead. if the user </cmt> <cmt> hasn't installed the 'six' module, ios-deploy will fail with a </cmt> <cmt> relatively cryptic error message. </cmt> <cmt> this patch pushes /usr/bin to the front of path for the duration of the </cmt> <cmt> ios-deploy run to avoid this scenario. </cmt> <cmt> eliminate checks for package six </cmt> <cmt> neither flutter nor any of its direct dependencies/tooling relies on </cmt> <cmt> package six. ios-deploy depends on lldb.framework (included with xcode), </cmt> <cmt> which relies on a python script that imports this package but uses </cmt> <cmt> whichever python is at the front of the path. flutter now invokes </cmt> <cmt> ios-deploy with a path with /usr/bin forced to the front in order to </cmt> <cmt> avoid this problem. </cmt> <cmt> we could have retained the check out of paranoia, but this seems </cmt> <cmt> unnecessary since it's entirely possible lldb.framework may one day drop </cmt> <cmt> this dependency, in which case, i'd expect the base system install of </cmt> <cmt> python would likely drop it as well. </cmt>",push /usr/bin to front of path for ios-deploy runs
186,"<desc> what: i have changed ""main"" to main. below the 'main' section, in the 'master' section, master is used, not ""master"". </desc> <cmt> change "" to </cmt> <cmt> as done in the description of master </cmt> <cmt> "" to  in de </cmt> <cmt> "" to  in pt </cmt> <cmt> "" to  in ru </cmt>",add proper markdown to 'main'
187,"<desc> ensure always passing common variables (device name, dev finder) log listener commands forgot to pass this related issues #57044 ran script locally to verify function didn't break the current process. this is a bash script to run tests from the sdk against fuchsia. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> [fuchsia] pass dev-finder to dump logs on test reboot </cmt> <cmt> refactor fuchsia_ctl to function </cmt>",refactor fuchsia_ctl use to a function
188,"<desc> now all cparse types using in whole radare/libr. function type integrated with old. it builds ok, but will not work. not yet for merge, mostly for review. but, if want fix some issues by yourself - feel free to merge :) </desc> <cmt> cparse integration stage 2, added calling conventions, changed variables/functions to use new types system </cmt> <cmt> types cleanups </cmt> <cmt> deep integration of complex types - build fixed </cmt>",second step of cparse integration
189,"<desc> new features apis add basic cost model, it uses executor to run program and profile it to get op time. this is an early basic version, we will add more functions in the future. </desc> <cmt> init commit of cost model </cmt> <cmt> add class costdata </cmt> <cmt> add pybind </cmt> <cmt> fix compile bugs </cmt> <cmt> experimental pr on costmodel </cmt>",basic pr on cost model
190,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. </desc> <cmt> added electron-notify </cmt> <cmt> wrong module name </cmt> <cmt> added inotification and iconfiguration to electron notify </cmt> <cmt> return voids </cmt> <cmt> fix syntax issues </cmt>,added type definition for electron-notify and mock-require
191,"<desc> none. this is a doc fix. the criterion.impurity_improvement() defined in sklearn.tree._criterion.pyx is marked as a ""placeholder method"", but i think it is not, since it has its own implementation. alhough class friedmanmse does overrides it later, but still it is not simply a placeholder method. none </desc> <cmt> doc fix a description of method </cmt> <cmt> doc fix a description of method </cmt>",a doc fix of the description of criterion.impurity_improvement()
192,"<desc> description: dark sky and open weather map both displayed pressure in hpa for imperial unit system, although front end displayed inhg as units. this pr checks unit system and converts to inhg if necessary. related issue (if applicable): fixes #19968, #16818 and #22079. related to architecture #132, although for wind speed. pull request in home-assistant.io with documentation (if applicable): na example entry for configuration.yaml (if applicable): weather: - platform: darksky api_key: !secret darksky_key - platform: openweathermap api_key: !secret owm_key checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> fix pressure in imperial units </cmt> <cmt> add test </cmt> <cmt> test valid units </cmt> <cmt> change volume to pressure </cmt> <cmt> lint </cmt> <iss> openweathermap displays pressure in hectopascals but states inhg </iss>",fix pressure in dark sky and openweathermap and add pressure utility
193,"<desc> this almost completes the job for #16440. the idea is that even if we do not know whether some closure type c implements fn or fnmut (etc), we still know its argument and return types. so if we see an obligation c : fn(_0), we can unify _0 with those argument types while still considering the obligation ambiguous and unsatisfied. this helps to make a lot of progress with type inference even before closure kind inference is done. as part of this pr, the explicit : syntax is removed from the ast and completely ignored. we still infer the closure kind based on the expected type if that is available. there are several reasons for this. first, deciding the closure kind earlier is always better, as it allows us to make more progress. second, this retains a (admittedly obscure) way for users to manually specify the closure kind, which is useful for writing tests if nothing else. finally, there are still some cases where inference can fail, so it may be useful to have this manual override. (the expectation is that we will eventually revisit an explicit syntax for specifying the closure kind, but it will not be : and may be some sort of generalization of the || syntax to handle other traits as well.) this commit does not quite fix #16640 because a snapshot is still needed to enable the obsolete syntax errors for explicit &mut: and friends. r? @eddyb as he reviewed the prior patch in this direction </desc> <cmt> allow closure arguments types to unify even if we can't fully resolve </cmt> <cmt> a trait obligation. partial fix for #16440 -- closure return types are </cmt> <cmt> not handled yet. </cmt> <cmt> teach project to unify the return type even if a precise match is not </cmt> <cmt> possible.  there is some amount of duplication as a result (similar to </cmt> <cmt> select) -- i am not happy about this but not sure how to fix it </cmt> <cmt> without deeper rewrites. </cmt> <cmt> update compile-fail tests to use the expected type to force the </cmt> <cmt> closure kind, thereby detecting what happens if there are </cmt> <cmt> mismatches. simply removing the : annotations caused most of these </cmt> <cmt> tests to pass or produce other errors, because the inference would </cmt> <cmt> convert the closure into a more appropriate kind. (the ability to </cmt> <cmt> override the inference by using the expected type is an important </cmt> <cmt> backdoor partly for this reason.) </cmt> <cmt> remove the explicit closure kind syntax from the parser and ast; </cmt> <cmt> upgrade the inference based on expected type so that it is able to </cmt> <cmt> infer the fn kind in isolation even if the full signature is not </cmt> <cmt> available (and we could perhaps do better still in some cases, such as </cmt> <cmt> extracting just the types of the arguments but not the return value). </cmt> <iss> closure kind inference: infer whether a closure is `fn`, `fnmut`, etc </iss>","unify closure argument/return types even if kind is not known, deprecate explicit : syntax"
194,<desc> added coletiv studio to the contributor showcase page and sites page </desc> <cmt> add coletiv to the sites.yml </cmt> <cmt> add coletiv to the creators website </cmt> <cmt> chenged coletiv type to agency </cmt> <cmt> revert creators unintended change </cmt>,add coletiv to contributor showcase and sites page
195,"<desc> fixes #18006 runtime-tested by me on latest master, on android and macos. fix confirmed working by issue submitter @sualfred @phunkyfish do you have some time for a code review? </desc> <cmt> [pvr] display reminder dialog only after gui is ready. </cmt> <cmt> [servicemanager] init pvr manager after login, not already on login screen. </cmt> <iss> [pvr] reminder feature: stuck at startup.xml </iss>",show reminder dialogs only when gui is fully initialized / user has logged in
196,"<desc> this pr adds automatic search space conversion from tune configs for these algorithms: bohb dragonfly nevergrad skopt zoopt (sigopt still missing). #10591 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> added bohb search space converter </cmt> <cmt> doc update </cmt> <cmt> added zoopt search space conversion </cmt> <cmt> added dragonfly search </cmt> <cmt> added skopt </cmt> <cmt> added nevergrad + example </cmt> <cmt> updated skopt example </cmt> <cmt> updated zoopt example </cmt> <cmt> updated dragonfly example </cmt> <cmt> updated bohb example </cmt>",add algorithms for search space conversion
197,"<desc> this commit adds initial support for the accept-language-parser module which is currently at version 1.4.1 i am not in any way related to the module. the current maintainer seems to be @matteofigus. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> [accept-language-parser] add accept-language-parser </cmt> <cmt> this commit adds initial support for the accept-language-parser module which is currently at version 1.4.1 </cmt> <cmt> i am not in any way related to the module. </cmt> <cmt> [accept-language-header] confirm to dtslint </cmt>",add new types for accept-language-parser
198,"<desc> this patch provides a basic implementation of tgoto(), and an implementation of the @ (ich) escape sequence. this not only removes a crash in bash when invoking readline through ^r, but also appears to be enough to make it function as-expected. </desc> <cmt> libvt: implement ich sequence. </cmt> <cmt> libc: implement tgoto(). </cmt>",implement tgoto() and @ (ich) escape sequence (bash fixes)
199,"<desc> this pr enables to symbolic trace models without having to specify a fixed batch size and / or sequence length. to specify that an axis should not have a fixed shape, the value should be set to -1: traced = symbolic_trace( model, input_names=[""input_ids"", ""attention_mask"", ""token_type_ids""], batch_size=-1, # means that batch size should be dynamic sequence_length=-1 # means that the sequence length should be dynamic currently, only the following models support dynamic axes: distilbert mobilebert megatronbert electra traced models with dynamic axes cannot be retraced out of the box, to solve this 2 functions are provided: prepare_for_retracing: takes a traced model as input and outputs a model that can be retraced and some information that is needed to get back to dynamic axes restore_after_retracing: takes a retraced model and the information returned by prepare_for_retracing and set the dynamic axes back example: prepared, attributes = prepare_for_retracing(traced) retraced = some_retracing_func(prepared) final_model = restore_after_retracing(retraced, attributes) to make things less tedious, retrace_graph_with is provided: it takes a traced model, and either a tracer or a tracing function and performs the retracing: final_model = retrace_graph_with(traced, func=some_tracing_func) being able to retrace a model is important because that is how quantization can be done for instance. finally, this pr also provides sanity checks that validate that symbolic tracing is available for the model provided to symbolic_trace, and that it can be traced with dynamic axes if the user asks for it. </desc> <cmt> symbolic trace dynamic axes support for bert like models </cmt> <cmt> sanity checks to make sure the model is tracable with torch.fx and if dynamic axes are supported </cmt>",initial support for symbolic tracing with torch.fx allowing dynamic axes
200,"<desc> replaces and closes #7087 (edit: tested) fixes #7073 with solution 6 updates #7068 fixes #7043 (no need for -dnoprintfloat) </desc> <cmt> restore dtostrf+fix when float printing is disabled at link time </cmt> <cmt> fix include file </cmt> <cmt> fix with proposal per review </cmt> <iss> [bug]: rounding values when using string type cast </iss> <iss> dtostrf/print(float) inconsistent value/methods, downstream use </iss>",restore dtostrf when floats are disabled in printf/scanf + round fix
201,"<desc> this pr fixes current issues with tuya serial dimmers and switches. all the commits messages have explanation in detail about each change. the changes are rename tuya_show_dimmer to tuya_disable_dimmer to make name same as the option functionality fix tuya serial switches are detected as dimmers even with setoption65 1 fix tuya dimmer doesn't switch on from hass. these changes are tested by myself on makegood tuya ac dimmer makegood tuya 3 gang switch after these changes go in wiki pages for setoption65 needs to be corrected and new details need to be added to tuya dimmer pages related issue (if applicable): fixes # the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.3.0, 2.4.2 and 2.5.2 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> tuya: rename tuya_show_dimmer to tuya_disable_dimmer to make the option clear. </cmt> <cmt> by default the option is set to 0 in which case the tuya serial will act as dimmer </cmt> <cmt> when its set to 1 tuya serial will disable dimmer functions. </cmt> <cmt> fix: tuya switches are detected as dimmers. </cmt> <cmt> tuya switches are detected as dimmers even after setting setoption65 to 1. </cmt> <cmt> currently setoption65 just hides the dimmer from web ui for tuya switches with setoption65 to 1 but they are advertised as dimmer to hass. </cmt> <cmt> with this change we set light_type to lt_basic (on/off) instead of lt_serial1 (dimmable) when option 65 is set. </cmt> <cmt> tuya fix: dimmer doesn't switch on from hass </cmt> <cmt> tuya serial dimmer doesn't switch on from hass because when powered off, hass sends dimmer command. </cmt> <cmt> internally, dimmer update and power command are sent too quickly to serial out and switch doesn't turn on. </cmt> <cmt> adding a delay fixes things. </cmt>",tuya serial dimmer and switch fixes
202,"<desc> @rocketchat/core closes #3224 this now prevents users from doing actions on messages when they are not in a channel. </desc> <cmt> hide the cog when a user is not in the room. </cmt> <cmt> start of preventing users from interacting with messages when they are not in the room. </cmt> <cmt> prevent the actions from showing up </cmt> <cmt> removed the cog button actions from showing up when the user is not in a room, this way people can't interact with the items when they're not in that room. </cmt> <cmt> prevent the actions in the methods if they aren't in the rooms </cmt> <iss> able to perform message actions on a channel you aren't in </iss>",prevent actions when not in a room
203,"<desc> updated tests with flag introduced in #6959 printing git info to deterministically identify commit the tests are run on. </desc> <cmt> [hotfix] printing remote, branch, commit hash that is being tested </cmt> <cmt> [flink-10678] disabled log checking in tests that fail jobs on purpose </cmt>",disabled log checking in tests that fail jobs on purpose 1.6-e2e
204,"<desc> went through and updated many of the type definitions to correspond with the latest version of fabric js. added new definitions where possible. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> started updating type defs. currently up to path </cmt> <cmt> updated typedefs for shapes </cmt> <cmt> updated some of the definitions </cmt> <cmt> updated canvas and staticcanvas </cmt> <cmt> updated type defs based on findings in test that have been verified and updated tests to ensure they are up to date with the latest definitions based on fabricjs codebase </cmt> <cmt> removed definitions that already existed and were creating conflicts </cmt> <cmt> updated definitions for object and iobjectoptions </cmt> <cmt> ran linter </cmt>",updated fabric js type definitions for fabricjs v2.6.0
205,"<desc> this small project takes entries like time and phone number from cloud firestore collection and sets 5 min prior call reminders for performing a particular tasks it runs as follows takes entries from cloud firestore which includes the time to start a specific task and phone number. with the help of twilio api calls the person on the same phone number as retrieved, 5 min before the task timing to remind them of the task. uses a scheduler to keep the process up and running as new entries may get added to database. </desc> <cmt> added a small project for making reminder calls in python </cmt> <cmt> added a project for reminder calls in python:fixed bugs </cmt> <cmt> bug fixes </cmt> <cmt> added comments </cmt>","added a project for making automated reminder calls in python using cloud firestore, twilio, apschedular"
206,"<desc> sometimes, we get a small pr that has code that's good but testing it means that we have to check out the code locally. this should generate a test-example folder on the docs site for the pr with a built version of video.js from the pr. hopefully, this pr will be the the very first example of it too. </desc> <cmt> build and cleanup example </cmt> <cmt> don't copy over the swf for the build </cmt> <cmt> get css and lang from dist </cmt> <cmt> copy over videojs-flash and the swf </cmt> <cmt> default skipbuild to a falsy value </cmt> <cmt> generate example in netlify when not on master </cmt>",generate a test example on netlify on prs
207,"<desc> fixes #2293 by breaking when encountering an eof in binary_reader::get_string() and binary_reader::get_binary() changes are described in the pull request, or an existing issue is referenced. the test suite compiles and runs without error. code coverage is 100%. test cases can be added by editing the test suite. the source code is amalgamated; that is, after making changes to the sources in the include/nlohmann directory, run make amalgamate to create the single-header file single_include/nlohmann/json.hpp. the whole process is described here. </desc> <cmt> add break to binary_reader::get_binary and get_string </cmt> <cmt> fix: return -> result.push_back </cmt> <cmt> run amalgamate </cmt> <iss> application stalls indefinitely with message byte size 10 </iss>",fix eof for get_binary and get_string
208,"<desc> in _json.c: add a check whether encoder() hasn't returned a string. in test_json/test_speedups.py: add a test to verify that the assertion failure is no more, and that the patch doesn't break anything when encoder() fails. </desc> <cmt> init commit </cmt> <cmt> fix test name </cmt> <cmt> improve patch c code </cmt>","fix an assertion failure in json, in case _json.make_encoder() received a bad encoder() argument"
209,"<desc> currently the entire remote cluster settings infrastructure is designed around the sniff strategy. as we introduce an additional conneciton strategy this infrastructure needs to be modified to support it. this commit modifies the code so that the strategy implementations will tell the service if the connection needs to be torn down and rebuilt. as part of this commit, we will wait 10 seconds for new clusters to connect when they are added through the ""update"" settings infrastructure. </desc> <cmt> wip </cmt> <cmt> work on update logic </cmt> <cmt> changes </cmt> <cmt> wip </cmt> <cmt> fix tests </cmt>",make remote setting updates support diff strategies
210,"<desc> the error message when extending a private constructor shows ""undefined"" when property-access expressions are used in the extends clause. using the fully qualified name of the symbol instead fixes it. fixes #11726. </desc> <cmt> add test </cmt> <cmt> add baselines </cmt> <cmt> use fqn of symbol instead of node text </cmt> <iss> ""cannot extend a class 'undefined'."" when class is declared in a namespace </iss>",use symbol fully-qualified name instead of node text in error message
211,"<desc> removed old table with other projects. updated final text as main readme.md. little changes (imperative vs infinitive in spanish) </desc> <cmt> removed spanish section ""how to keep the repository updated"", as asked by </cmt> <cmt> owner </cmt> <cmt> changed last part of spanish translation, asked by owner. removed old </cmt> <cmt> table, etc. </cmt>",update spanish as main english readme
212,<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description before: after: test plan tests pass closing issues </desc> <cmt> match args name/types from function definition </cmt> <cmt> fix type propagation with mixed stack/reg args </cmt> <cmt> fix/add test </cmt>,match args name/types from function definition ##anal
213,"<desc> this continues the removal of type parameters from createindexrequest.mapping methods started in #50419.  here the removed methods are almost entirely in test code, with the exception of a change to transformindex in the transform plugin. relates to #41059 </desc> <cmt> remove createindexrequest.addmapping(type, string, xcontenttype) </cmt> <cmt> remove type from cir.mapping(xcontentbuilder) </cmt> <cmt> remove type from cir.mapping(map) </cmt> <cmt> tests </cmt>","remove type parameter from createindexrequest.mapping(type, xcontentbuilder)"
214,"<desc> this pr fixes backward of elementwise binary ops against large tensor. tests are also added sample run: ubuntu@ip-172-31-38-169:~/incubator-mxnet$ pytest tests/nightly/test_np_large_array.py::test_subtract /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) ===================================== test session starts ====================================== platform linux -- python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 rootdir: /home/ubuntu/incubator-mxnet, inifile: pytest.ini plugins: remotedata-0.3.2, openfiles-0.4.0, astropy-header-0.1.2, hypothesis-5.8.3, arraydiff-0.3, doctestplus-0.5.0 collected 1 item tests/nightly/test_np_large_array.py .                                                   [100%] ======================================= warnings summary ======================================= tests/nightly/test_np_large_array.py:89 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:89: deprecationwarning: invalid escape sequence \ ''' tests/nightly/test_np_large_array.py:674 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:674: deprecationwarning: invalid escape sequence \ ''' -- docs:  ================================ 1 passed, 2 warnings in 14.77s ============================== @access2rohit @josephevans </desc> <cmt> fix backward </cmt> <cmt> add tests </cmt>",elemwise binary op backward fix
215,<desc> measure the percentage ratio the stream thread spent on processing each task among all assigned active tasks (kip-444). also add unit tests to cover the added metrics in this pr and the previous #8358 also trying to fix the flaky test reported in kafka-5842 </desc> <cmt> first pass </cmt> <cmt> fix unit tests </cmt> <cmt> add unit tests </cmt> <cmt> first pass </cmt> <cmt> should be info </cmt> <cmt> fix unit tests </cmt> <cmt> github comments </cmt> <cmt> rebase </cmt> <cmt> unit tests </cmt>,add active tasks process ratio
216,"<desc> i have followed (at least) the pr section of the contributing guide. this is an attempt to close #21441. i used the second proposed solution from #21441 (comment). there was quite a bit of discussion about the best solution. the motivation for this pull request is described as the third possibility in #21441 (comment). note, when using the proposed solution, i received an error in yarn lint that 103:22  error  expected to return a value at the end of arrow function, so i modified the solution as follows: diff --git a/packages/material-ui/src/select/selectinput.js b/packages/material-ui/src/select/selectinput.js index cce92efcc..6eb7bac63 100644 --- a/packages/material-ui/src/select/selectinput.js +++ b/packages/material-ui/src/select/selectinput.js @@ -113,7 +113,7 @@ const selectinput = react.forwardref(function selectinput(props, ref) { label.removeeventlistener('click', handler); }; } +    return undefined; }, [labelid]); const update = (open, event) => { </desc> <cmt> replace disploynode state with displayref for ref value </cmt> <cmt> add return a value at the end of arrow function </cmt> <iss> [select] focusing component with inputref gives null value despite check </iss>",replace displaynode state with displayref for ref value
217,"<desc> cherrypick request for 4.2.0 (#13558) this pull request combines 3 commits for bazel 4.2.0: 586de95 80feea0 0e65273 together, these update the version of the bazel android tools that the android rules use to version 0.23.0, and updates the minimum version of the android sdk build tools to 30.0.0. </desc> <cmt> change min_build_tools_revision to 30.0.0 </cmt> <cmt> bazel's android tools requires android build tools 30.0.0 or newer. </cmt> <cmt> see </cmt> <cmt> relnotes: the minimum android build tools version for the android rules is now 30.0.0 </cmt> <cmt> piperorigin-revid: 378014192 </cmt> <cmt> update android remote tools to ensure bazel uses the latest android tooling that has been updated to support androidx databinding generation. </cmt> <cmt> updates android remote tooling version to 0.21.0. </cmt> <cmt> also updates list of desugar flags for new desugarer version included in the tools, and in particular remove usages of ""--retarget_core_library_member"", which the updated desugar tool no longer needs. </cmt> <cmt> piperorigin-revid: 363212429 </cmt> <cmt> automated rollback of commit 9a1d428e33bfae1ec5b68250d4732b72346b8b39. </cmt> <cmt> *** reason for rollback *** </cmt> <cmt> downstream projects on bazelci have been updated to not hardcode the buildtools versions: </cmt> <cmt> *** original change description *** </cmt> <cmt> automated rollback of commit b6f87f10ba908821cb71f8147815917829f16ebf. </cmt> <cmt> *** reason for rollback *** </cmt> <cmt> breaks downstream bazel projects because aapt2 needs to be updated in the build images: </cmt> <cmt>  </cmt> <cmt> *** original change description *** </cmt> <cmt> updates android remote tools to 0.23.0 to include update remote android tools to include c3edf13269139d20c84e7e2cbc2fa524b7a9c279. </cmt> <cmt> relnotes: none. </cmt> <cmt> piperorigin-revid: 377971964 </cmt>",cherrypicks for android rules for bazel 4.2.0
218,"<desc> what is include in the pr: linked issue: #9390 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> refactoring </cmt> <cmt> restore layout preview after zones editing cancel </cmt>",update the small layout preview after canceling zone editing.
219,"<desc> after this pr, all the utarray/uthash code will be removed from the plasma store and we can modernize the code some more. </desc> <cmt> temp commit </cmt> <cmt> convert eviction policy to c++ </cmt> <cmt> temp commit </cmt>",convert eviction code to stl
220,"<desc> currently a password textfield (obscuretext = true) will display the last character. this behavior is expected only on mobile. on web and desktop every character should be hidden (even the last character). with this pr the last character of a password will be only displayed on mobile. demo (web) related issues closes #51218 added a test to check, if the last character is hidden on targetplatform.macos, targetplatform.linux, targetplatform.window made the existing obscure test specific to targetplatform.android and targetplatform.ios before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> obscuretext will hide all characters on web and desktop </cmt> <cmt> add comment </cmt> <iss> [web & desktop] hide all characters in a textfield, when obscuretext is true </iss>","hide all characters in a textfield, when obscuretext is true on web & desktop"
221,"<desc> this is related to #27260. currently, basic nio constructs (nio channels, the channel factories, selector event handlers, etc) implement logic that is specific to the tcp transport. for example, niochannel implements the tcpchannel interface. these nio constructs at some point will also need to support other protocols (ex: http). this commit separates the tcptransport logic from the nio building blocks. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> remove imports </cmt> <cmt> wip </cmt> <cmt> wip </cmt>",decouple nio constructs from the tcp transport
222,<desc> new module pull request ansible tower user module ansible tower credential module ansible version ansible 2.3.0 (tower_module 57b3783869) last updated 2017/02/03 13:47:23 (gmt -400) config file = configured module search path = default w/o overrides allows playbook authors to create ansible tower users and credentials. there will be a followup to this pr to add more functionality. initial module was completed and merged in #20355. </desc> <cmt> rename tower config module parameters to avoid conflicts </cmt> <cmt> add ansible tower user module </cmt> <cmt> add ansible tower credential module </cmt>,ansible tower user and credential module
223,"<desc> some of the recent vmware modules like content library, tagging is using vsphere automation sdk. all the new features(apis) from vsphere 6.0 are available only in vsphere automation sdks. documentation update added a documentation section as below: ansible vmware modules leveraging latest vsphere(6.0+) features are using vsphere automation python sdk. the vsphere automation python sdk also have client libraries, documentation and sample code for vmware cloud on aws console apis, nsx vmware cloud on aws integration apis, vmware cloud on aws site recovery apis and nsx-t apis. you can install vsphere automation python sdk using pip: $ pip install --upgrade git+ note: installing vsphere automation python sdk also installs pyvmomi. a separate installation of pyvmomi is not required. </desc> <cmt> update vmware_intro.rst </cmt> <cmt> add vsphere automation python sdk to the requirement section </cmt> <cmt> update vmware_intro.rst </cmt> <cmt> updated requirements section </cmt>",update vmware ansible modules requirements section
224,<desc> i hereby agree to the terms of the cla available at:  fix performance for selects with union caused by wrong limit for the total number of threads. fixes #12030 </desc> <cmt> fix overlimiting the nuber of threads for union. </cmt> <cmt> added test. </cmt> <iss> processors performance downgrade with union & limit </iss>,fix over-limiting the number of threads for union.
225,"<desc> scipy's linalg.svd or linalg.svd return x = u, s, vt. the code uses v instead of vt in various places. it can get confusing when people are checking out how we do pca etc... </desc> <cmt> use vt instead of v </cmt>",mnt use vt instead of v as returned by svd()
226,"<desc> let's try to make the addon build system a bit more user friendly. for the moment, issue an error when the addon config file couldn't be found. i think it would be also convenient that if addon_src_prefix contains the source directory of the addon specified in addons_to_build, then just use it even without config. that makes the bootstrap process for addon devs a bit easier. ping: @notspiff, @wsnipex, @hudokkow, @achimturan </desc> <cmt> [cmake/addons] print more log messages </cmt> <cmt> [cmake/addons] print an error if addons_to_build doesn't match any addon </cmt> <cmt> track if at least one addon has been found. everything else is likely </cmt> <cmt> an error either in addons_to_build or in the directory configuration. </cmt>",small binary-addon build system improvements
227,"<desc> backport of #14483. this gives some fixups, at least the resize, reduceat, and sorting valbuffer (introduced recently, although not sure how buggy it was before) are actual bugs. i have a bunch of changes adding npy_unused in many places, and const, but they are neither quite complete, nor am i sure it is worth the trouble at this time. </desc> <cmt> maint: delete some unused functions </cmt> <cmt> bug: fix occurances where variables are cast to shorter int incorrectly </cmt> <cmt> at least two of these are real issues, but can only occur with very </cmt> <cmt> large arrays for which even a chunk of the array is larger than fits </cmt> <cmt> into c integers. </cmt> <cmt> maint: minor fixes and cleanups </cmt>",some fixes and minor cleanup based on clang analysis
228,"<desc> updating the dynamodb types to reflect the various callback/promise types to be more strongly typed. more advanced functions with various return options such as destroy were left to return any. also, when retrieving a query/scan promise, it nests the results in (what appears to be) a single element array, so the types now account for this anomaly. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test dynamodb. </desc> <cmt> generics on promises and callbacks </cmt> <cmt> tests 'n tweaks </cmt> <cmt> fix linting issues </cmt>",add generics to query/scanning promises and callback results
229,"<desc> this pr adds some checks on the execution of anonymous-statistics.sh script as discussed in #11115. it adds a check on the exit_code of mypclose, a check on fp, and tries to force both curl and wget to output the http response code (and check that too). component name analytics on normal cases, no error should be reported in the log file. if an error is found in either the exit code of mypclose, or an http response other than 200 is produced, it should be printed in the error.log wget's way of producing the http code is hacky... i don't know if we're comfortable forcing them to give us the http response and parsing it... if not, we can only keep the checks on mypopen and fp. </desc> <cmt> check return of execution of anonymous statistics script </cmt> <cmt> break check into two parts </cmt> <iss> netdata doesn't log an error when sending analytics if any </iss>",check return status of execution of anonymous statistics script
230,<desc> bug fix the custom logger example. this example is linked from the documentation in the rllib section. none i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> read logger_config first then prefix </cmt> <cmt> read logger_config first then prefix </cmt>,"read ""logger_config"" first before ""prefix""."
231,"<desc> related #21569 this pr changes the auto-generated pybind functions for dygraph operators, remove maps in function args to improve performance. train ptb for one epoch on v100 gpu place, before: 112.269 after: 107.502 time reduced: -4% the generated pybind functions can be see here. </desc> <cmt> expand parameters, test=develop </cmt> <cmt> support resnet, test=develop </cmt> <cmt> fix resnet, test=develop </cmt> <cmt> support duplicable out, test=develop </cmt> <cmt> support ptb </cmt> <cmt> fix bugs, test=develop </cmt> <cmt> support null input, test=develop </cmt>",feature/expand params in auto-generated pybind functions for dygraph operators
232,"<desc> currently, we aren't using the disabled/readonly props in the actual calendarpicker and its child components. this means that the standalone calendarpicker subcomponent and the staticdatepicker do not work as intended with these props. this change passes those props down and reduces functionality based on the prop. for readonly hover effects still work and different months can be looked at, but the selected date cannot be changed and the view state of the picker cannot be changed. for disabled it works the same way, but the months cannot be changed and all of the css is ""muted"" with no hover effects. i also noticed this was the case with the yearpicker and monthpicker sub components so applied similar changes to them as well. readonly: disabled: addresses #28766 i have followed (at least) the pr section of the contributing guide. </desc> <cmt> passed readonly/disabled into picker components and trigger correct behavior </cmt> <cmt> also fixed the yearpicker and monthpicker sub components </cmt>",fix disabled/readonly for view components
233,"<desc> fmt and hash are pretty straightforward i think. sync is a bit more complex. i thought one or two of the isizes ought to be i32s, but that would require a bunch of casting (the root cause being the lack of atomics other than isize/usize). r? @alexcrichton </desc> <cmt> int audit - libcore::fmt </cmt> <cmt> int audit core::hash </cmt> <cmt> int audit - std::sync </cmt>","int audit core::{hash, fmt}, std::sync"
234,<desc> fixes #9199 the fix simply extends the current sparse input incompatibility check with a callable check. a test is included in test_neighbors.py </desc> <cmt> proposed fix (incl test) for #9199 - fitting a nearestneighbors model fails with sparse input and a callable as metric </cmt> <iss> fitting a nearestneighbors model fails with sparse input and a callable as metric </iss>,fixes #9199 - fitting a nearestneighbors model fails with sparse input and a callable as metric
235,"<desc> backport of #18055 @phunkyfish if you find some time for a review... </desc> <cmt> [pvr] cguiepggridcontainer: update layout early in gui thread, not in timeline refresh thread, for performance and thread safety reasons (fix a race). </cmt> <cmt> [pvr] make cguiepggridcontainer::updatelayout thread-safe; some of the modified members will be read by timeline refresh thread. </cmt>",leia pvr fix epg container race
236,"<desc> detect-to-retrieve cvpr'19 paper: </desc> <cmt> initial feature aggregation code for detect-to-retrieve paper. </cmt> <cmt> piperorigin-revid: 246043144 </cmt> <cmt> add support for asmk/asmk*/r-asmk/r-asmk*. </cmt> <cmt> piperorigin-revid: 247337028 </cmt> <cmt> add datumproto uint32 field, and limit datum_io to uint32 and float32/float64 types. </cmt> <cmt> also, introduce datumpairproto, to be used for asmk variants. functions to read/write in this new format are added and tested. </cmt> <cmt> piperorigin-revid: 247515205 </cmt> <cmt> add batching option to feature aggregation extraction. </cmt> <cmt> piperorigin-revid: 247614627 </cmt> <cmt> script to perform local feature aggregation, with associated configs. </cmt> <cmt> also small edits to the aggregation extractor, for better handling of input features / avoiding oom. </cmt> <cmt> piperorigin-revid: 248150750 </cmt> <cmt> tests to check that aggregation using regions with no local features works. </cmt> <cmt> piperorigin-revid: 248153275 </cmt> <cmt> include new library/proto for aggregation </cmt> <cmt> merged commit includes the following changes: </cmt> <cmt> piperorigin-revid: 248176511 </cmt> <cmt> merged commit includes the following changes: </cmt> <cmt> 248194572  by andre araujo: </cmt> <cmt> change tf.tensor_scatter_nd_add --> tf.compat.v1.tensor_scatter_add to make it compatible with tf 1.x. </cmt> <cmt> -- </cmt> <cmt> piperorigin-revid: 248194572 </cmt> <cmt> functions to parse ground-truth and compute metrics for revisited datasets. </cmt> <cmt> unit tests are added. </cmt> <cmt> piperorigin-revid: 248561575 </cmt> <cmt> small change to argparse bool option, which does not work as expected. </cmt> <cmt> piperorigin-revid: 248805505 </cmt> <cmt> class to compute similarity between aggregated descriptors. </cmt> <cmt> piperorigin-revid: 249102986 </cmt> <cmt> script to perform retrieval and compute metrics. </cmt> <cmt> piperorigin-revid: 249104011 </cmt> <cmt> feature_aggregation_similarity library in delf init </cmt> <cmt> d2r instructions / readme update </cmt> <cmt> small edit to readme </cmt> <cmt> merging </cmt>",code for detect-to-retrieve fully integrated
237,"<desc> ref: #5425 fixes #5371. while looking at #5801, i could have sworn there was something related recently and discovered #5425 was inadvertently closed when the maser (typo) branch was deleted. /cc: @xtuc </desc> <cmt> fix: remove check for super in arrow function </cmt> <cmt> refactor: search parent instead of using state </cmt>",remove check for super calls in arrow function
238,"<desc> useful for sanitizer fuzzer builds. clang doesn't have a -fconcepts switch (i'm guessing it just enables concepts automatically with -std=c++2a, but i haven't checked), and at least the version on my system doesn't understand -wno-deprecated-move, so pass these two flags only to gcc. in return, disable -woverloaded-virtual which fires in many places. fix the handful of -wunused-private-field warnings that clang emitted. -- fixing the -woverloaded-virtual warnings is imho worthwhile too, but i don't feel like doing that right now. </desc> <cmt> libline: removed unused private field m_prompt_metrics </cmt> <cmt> libx86: remove unused private fields m_segment, m_handler </cmt> <cmt> libgemini: remove unused private field m_queued_finish </cmt>",make things build with clang without needing local changes
239,"<desc> while checking out a test repo from .git repository, its index has been unexpectedly lf->crlf converted. while git.git was able to gracefully detect the corruption... $ git status error: bad index file sha1 signature fatal: index file corrupt ...libgit2 was segfaulting. this pr attempts at fixing this, along with a few issues discovered while working in this area. </desc> <cmt> tree-cache: free the tree upon the detection of a corrupted child </cmt> <cmt> tree-cache: zero out the allocated tree children array </cmt> <cmt> tree-cache: don't segfault upon corruption </cmt> <cmt> tree-cache: fix error message typo </cmt> <cmt> index: free the index on git_index_open() failure </cmt>",corrupted index is bad for your health
240,"<desc> hello! this pull request updates the ""deploying with now"" guide to give information about how to deploy with now 2.0. it is a more straight-forward guide than before an holds the most up-to-date information. please let me know if i can edit this guide further in any way. i took example from other guides you have and followed the styleguide as closely as i could. </desc> <cmt> update the now guide to use now v2 </cmt> <cmt> add reference </cmt>","update ""deploying with now"" guide"
241,"<desc> this change adds supports for the concurrent refresh of access tokens as described in #36872 in short it allows subsequent client requests to refresh the same token that come within a predefined window of 60 seconds to be handled as duplicates of the original one and thus receive the same response with the same newly issued access token and refresh token. in order to support that, two new fields are added in the token document. one contains the instant (in epoquemillis) when a given refresh token is refreshed and one that contains a pointer to the token document that stores the new refresh token and access token that was created by the original refresh. a side effect of this change, that was however also a intended enhancement for the token service, is that we needed to stop encrypting the string representation of the usertoken while serializing. ( it was necessary as we correctly used a new iv for every time we encrypted a token in serialization, so subsequent serializations of the same exact usertoken would produce different access token strings) this change also handles the serialization/deserialization bwc logic: in mixed clusters we keep creating tokens in the old format and consume only old format tokens in upgraded clusters, we start creating tokens in the new format but still remain able to consume old format tokens (that could have been created during the rolling upgrade and are still valid) resolves #36872 </desc> <cmt> allow tokens to be reissued in a given time window </cmt> <cmt> concludes work for supporting concurrent refreshes of access tokens in a backwards compatible way </cmt> <cmt> remove debug logging </cmt> <iss> allow token refresh for multiple requests in a small window </iss>",support concurrent refresh of refresh tokens
242,"<desc> this is lots of small changes from the internal fork at databricks. most of them are unrelated to each other, but as they were ""vetted"" and tested in the forked version, it seemed safe to just group them all together. most of them aren't changing functionality but rather extending it. see commit messages for descriptions. </desc> <cmt> set corejs version in .babelrc so jest doesn't complain. </cmt> <cmt> rewrite services/routes in typescript. </cmt> <cmt> add typescript definitions for dialogcomponent. </cmt> <cmt> make image paths more portable </cmt> <cmt> add current route context and hook. </cmt> <cmt> make emptystate more flexible by being able to pass in getsteps function. </cmt> <cmt> rewrite itemslist in typescript. </cmt> <cmt> introduce the possibility to add custom sorters for a column. </cmt> <cmt> rearrange props to be friendly to typescript. </cmt> <cmt> type definitions for notificationapi. </cmt> <cmt> use databricks query editor components for databricks_internal type of query runner. </cmt> <cmt> url escape password in alembic configuration. </cmt> <cmt> compare types in migrations. </cmt>",misc changes to codebase back ported from internal fork
243,"<desc> running integration test against aws set env var test_target=aws_cloud when running an integration test to use actual aws cloud endpoints instead of the localstack instance. useful when writing integration tests to check the behavior against the aws cloud. this will also disable the start of the localstack instance since it wouldn't make much sense anyway. (currently only implemented for pytest fixtures) avoid retries and timeouts while debugging when debugging it's usually fairly annoying when you're stepping through the debugger and suddenly the request either times out or a new request is issued and pulls you into the new request context. to avoid this we can now do the following: set proxy_max_retries=0 to prevent the generic_proxy from retrying to call the backend services set test_disable_retries_and_timeouts=1 (or some other ""truthy"" value) to disable the boto3/botocore retries and timeouts of our test fixtures/clients. if you're using the aws cli to send requests while debugging you can also disable retries and timeouts: add --cli-read-timeout=0 --cli-connect-timeout=0 to the aws cli command. the cli interprets these values as a ""blocking"" call, i.e. it will never timeout. e.g. aws cloudformation list-stacks --cli-read-timeout=0 --cli-connect-timeout=0 set the environment variable aws_max_attempts=1 to avoid any retries from the aws cli example alias for your shell config: aws=""aws_max_attempts=1 aws --cli-read-timeout=0 --cli-connect-timeout=0"" </desc> <cmt> add test_target to target aws cloud for integration tests </cmt> <cmt> allow disabling request retries and timeouts </cmt>",retries & timeouts+ option to run integration test against aws cloud
244,"<desc> the main change here is that instead of (possibly) creating module arguments as tensors, we create them as variables; this is necessary to add scalar tests because there is no way to create a scalar tensor. in legacy_nn we immediately unpack these variables, so there should be no change in behavior there.  in test_nn we operate on variables, so there are some minor changes that should be needed for merging variable and tensor anyway.  there are some minor hacks for dealing with tensors in legacy_nn, but those should be able to go away soon. this also fixes a few issues with criterion tests when scalars are enabled; the hingeembedding tests still fail because of some details of python autograd functions; i'll look to see if it can be easily moved to aten, otherwise we might have to wait for variables and tensors to merged to get it to pass. </desc> <cmt> test_nn working. </cmt> <cmt> fix some incorrect scalar assumptions. </cmt> <cmt> don't use variables when we don't have to. </cmt> <cmt> use variable mixin. </cmt>","run test_nn criterion tests over variables, add a scalar test"
245,<desc> add eager for imagenet. add 2 gpu tests instead of 4 for resnet56. add pass fail for keras tests based on accuracy. next prs will likely create a base class to hold pass/fail logic and add tracking of average examples per second. </desc> <cmt> added pass/fail and eager tests </cmt> <cmt> add eager multi-gpu test. </cmt>,adds eager imagenet/cifar-10 and early pass/fail pattern
246,"<desc> hi, here's a change proposal to allow is= command interpreter eco (theme) settings. additionally, sections with w/x permissions are highlighted, what i feel might be useful feature for security researchers. check the pictures below to better understand the change (eco twilight was used). before the change: after the change: </desc> <cmt> fork sync </cmt> <cmt> repo sync 2 </cmt> <cmt> repo sync </cmt> <cmt> repo sync </cmt> <cmt> forked repo sync from orginal </cmt> <cmt> merging changes from orginal repo </cmt> <cmt> sync from official repo </cmt> <cmt> fix: #11701 dmh* commands dont respect eco settings </cmt> <cmt> r_cons_singleton()->context </cmt> <cmt> pre merge fix </cmt> <cmt> merge issue fix </cmt> <cmt> is= color bug fix and execstack highlighting </cmt>",is= now accepts eco (theme) settings + highlighting of sections with w/x permissions
247,<desc> typescript definition for aws s3 bucket image uploader and microsoft sql node engine </desc> <cmt> create mssql.d.ts </cmt> <cmt> initial creation of mssql database connector for node.js defintion </cmt> <cmt> create mssql-tests.ts </cmt> <cmt> tests for mssql database connector for node.js </cmt> <cmt> create s3-uploader.d.ts </cmt> <cmt> very simple definition of s3-uploader. </cmt> <cmt> create s3-uploader-tests.ts </cmt> <cmt> tests for s3-uploader </cmt> <cmt> create s3-uploader </cmt> <cmt> rename s3-uploader to s3-uploader.d.ts </cmt>,adding aws s3 bucket image uploader and microsoft sql node engine
248,<desc> this resolves the .value is not a valid plugin property error showing up for people in #4227 </desc> <cmt> port babel logic to new custom babel-loader for config injection. </cmt> <cmt> update logic to also support babel.config.js configs. </cmt>,use custom babel loader to avoid using separate babel copies for loader and loader options
249,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> [expo] add typings </cmt> <cmt> [expo] add tests </cmt>",add typings for expo package
250,"<desc> for some users zone settings are reset to default on every restart. the virtual desktop id that is part of the device-id is changed on every restart until the user doesn't create another virtual desktop (even if it was deleted immediately). after the creation of the second vd, their ids are saved in the registry and would be the same on every restart. what is include in the pr: replaced device-id string with a structure. changed virtual desktop update handle. updated obtain of the virtual desktop ids. synchronize virtual desktop ids in app-zone-history and zones-settings maps with current virtual desktop ids. in case if ids are saved in the registry, save them in the settings as it is, otherwise save with the default {00000000-0000-0000-0000-000000000000} id. while using, the default id would be replaced with a current vd id. verify that every restart layouts are the same and not reset with the default priority grid. verify that the newly created virtual desktop has the same layouts as on the previous virtual desktop. after changing the layout on one of several virtual desktops verify that all other stays the same as they were before changes. check this behavior with and without saved virtual desktop ids in the registry. to remove ids from the registry, remove the currentvirtualdesktop from \hkey_current_user\software\microsoft\windows\currentversion\explorer\sessioninfo\1\virtualdesktops virtualdesktopids from \hkey_current_user\software\microsoft\windows\currentversion\explorer\virtualdesktops linked issue: #13069, #3959 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> updated virtual desktop retrieving </cmt> <cmt> save with null-guid </cmt> <cmt> moved guid utils </cmt> <cmt> moved deviceiddata related functions </cmt> <cmt> replaced strings with data structs </cmt> <cmt> default value </cmt> <cmt> clean up </cmt> <cmt> save app zone history with zones settings </cmt> <cmt> compare with null guid </cmt> <cmt> updated tests </cmt> <cmt> refactoring </cmt> <cmt> logs </cmt> <cmt> sync vd ids </cmt> <cmt> logs </cmt> <cmt> refactoring </cmt> <cmt> check virtual desktop id </cmt> <cmt> ondisplaychange call </cmt>",reset zone settings after restart fix.
251,<desc> this pr adds two new data population scenarios and does some related refactoring. both examples were taken from se demo orgs with some small tweaks to fit our scenario. scen 2: a react transaction + python transaction scen 3: python error only </desc> <cmt> adds two more scenarios </cmt> <cmt> more refactoring </cmt> <cmt> merge from master </cmt> <cmt> adds a test for data population </cmt>,data population scenarios 2 and 3
252,"<desc> minor step on the way to de-typescripting react-native-win32 remove rntester.ts, it just redirects to an existing js file. update various places using the redirection provides by rntester.ts. microsoft reviewers: open in codeflow </desc> <cmt> slightly reduce the number of ts files in rnwin32 </cmt> <cmt> change files </cmt>",slightly reduce the number of ts files in react-native-win32
253,"<desc> port #20626 from v1.9.x branch into v1.x branch. also fix another issue with let's encrypt expired ca cert causing failures in openssl when downloading during builds. </desc> <cmt> [v1.9.x] license and ci fixes for 1.9 release (#20626) </cmt> <cmt> * update license to include symlinks in include/dmlc licensed under non-asf-2.0 licenses. </cmt> <cmt> * update ca-certificates package on centos7 due to let's encrypt recent issue (see </cmt> <cmt> * update pdl package before installing pdl::ccs to prevent dependency issue. </cmt> <cmt> * install latest ca-certificates package on aarch64 as well. </cmt> <cmt> * change libtiff download url to http to prevent let's encrypt ca chain issue. </cmt> <cmt> * update dockerfile.build.ubuntu_cpu_jekyll </cmt> <cmt> * use http to download libcurl to avoid let's encrypt intermediate ca cert expiration issue. </cmt> <cmt> * lock down perl pdl version to specific version to prevent test failures. </cmt> <cmt> * no need to source rvm.sh in environment now that we are using a different container. </cmt> <cmt> * update license_header.py tool to trigger error when two licenses are found. </cmt> <cmt> * remove expired ca cert from ubuntu14.04 containers. </cmt> <cmt> * revert ""change libtiff download url to http to prevent let's encrypt ca chain issue."" </cmt> <cmt> this reverts commit 3ae1192b8598e9f68761e196f7ac6d9bee57fbe3. </cmt> <cmt> * revert ""use http to download libcurl to avoid let's encrypt intermediate ca cert expiration issue."" </cmt> <cmt> this reverts commit 92432a66e045c847027daf3eb4da2ef974b796ae. </cmt> <cmt> * back off retry count for windows builds to reduce cost. </cmt> <cmt> * split test_hybrid_static_memory_switching() into 3 tests in order to isolate failures. </cmt> <cmt> * skip mkldnn test, tracking at </cmt> <cmt> * fix lint </cmt> <cmt> * attempt to fix windows build parameters with mkldnn builds - do not use debug builds when linking against mkldnn. </cmt> <cmt> * revert ""update ca-certificates package on centos7 due to let's encrypt recent issue (see </cmt> <cmt> this reverts commit 8b64859589116cb7cea0b42beeaa7d2eb970a0ac. </cmt> <cmt> * add back change after revert. </cmt> <cmt> * revert ""fix lint"" </cmt> <cmt> this reverts commit 34b430c2636d32a2a168774ca0a7cd19ad834e50. </cmt> <cmt> * revert ""skip mkldnn test, tracking at </cmt> <cmt> this reverts commit f45a6e37b9440165d60e49545265277425893663. </cmt> <cmt> * revert ""split test_hybrid_static_memory_switching() into 3 tests in order to isolate failures."" </cmt> <cmt> this reverts commit 23db9bac614cf8a543393840afc45cb05dbb96db. </cmt> <cmt> * revert changing windows build flags. </cmt> <cmt> update openssl package in ubuntu_core.sh (used in ubuntu 16.04 images) to avoid bug triggered by let's encrypt expired ca cert. </cmt>",[v1.x]backport #20626 from v1.9.x branch
254,"<desc> original pull-request #33061 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> native format parsing - integer overflow resizing arrays </cmt> <cmt> addressing review comment </cmt> <cmt> corrections </cmt> <cmt> merge #33024 </cmt>",cherry pick #33061 to 21.8: merge #33024
255,<desc> the dashboard.all() query fetches duplicate rows because of its outer join conditions. this pr adds back a .distinct() construct de-duplicates the resullt set. distinct is called on created_at and slug because a generic distinct() fails when comparing the json fields. closes #5466 before after </desc> <cmt> add test that reproduces issue #5466 </cmt> <cmt> fix: duplicate dashboard rows were returned by dashboard.all() (#5466) </cmt> <iss> the item count dashboards view displayed per page is not correct </iss>,pagination is broken on the dashboard list page
256,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> remove obsolete cloud9 macros, add vscode macros on the keynav layer </cmt> <cmt> add vscode layer and shortcuts </cmt>",dvorak_42_key layouts for atreus and ergodox_ez: add vscode shortcuts
257,"<desc> the pr fixes a couple of issues: the chart filtering pattern from the backend section of netdata.conf wasn't applied to the prometheus web api endpoint. backend and exporting filtering configuration options were mixed up and resulted in an unexpected filtering pattern. fixes #11001 component name backends, exporting engine configuration netdata.conf: enable = yes send charts matching = system.processes exporting.conf: send charts matching = system.ram run nc -l -p 2003, wait for metrics access  you should see: netdata_info{instance=""arch-esxi"",application=""netdata"",version=""v1.30.1-57-g330ba6bfc""} 1 1618933809451 netdata_system_ram_mib_average{chart=""system.ram"",family=""ram"",dimension=""free""} 11795.4220000 1618933806000 netdata_system_ram_mib_average{chart=""system.ram"",family=""ram"",dimension=""used""} 1272.3672000 1618933806000 netdata_system_ram_mib_average{chart=""system.ram"",family=""ram"",dimension=""cached""} 2583.8870000 1618933806000 netdata_system_ram_mib_average{chart=""system.ram"",family=""ram"",dimension=""buffers""} 354.4609000 1618933806000 </desc> <cmt> fix backward compatibility with backends </cmt> <cmt> fix unit tests </cmt> <iss> chart filtering is mixed up if it is configured in the backend section </iss>",backend chart filtering backward compatibility fix
258,<desc> remove unused code in ansible-test. remove obsolete endpoint logic from ansible-test. remove obsolete region selection in ansible-test. remove obsolete port logic in ansible-test. clean up ansible-test remote providers. ansible-test </desc> <cmt> remove unused code in ansible-test. </cmt> <cmt> remove obsolete endpoint logic from ansible-test. </cmt> <cmt> remove obsolete region selection in ansible-test. </cmt> <cmt> remove obsolete port logic in ansible-test. </cmt> <cmt> clean up ansible-test remote providers. </cmt>,cleanup provisioning code in ansible-test.
259,"<desc> for anyone rebasing/merging against this when it lands, you'll need to make setup-git and run pre-commit on the files you changed in your branch. something like pre-commit run --files $(git whatchanged --name-only --pretty="""" master... | sort | uniq). this upgrades pre-commit and its hooks, moves it into a requirements-pre-commit.txt for git hook notifications on updates, and reruns pre-commit on everything. most notably, black's target-version py36 removes u prefixes. flake8 is now run on bin/ and i manually made those fixes. also removes all __future__s (in our case we can remove everything). </desc> <cmt> upgrade pre-commit, remove virtualenv pin </cmt> <cmt> pull pre-commit into a requirements file for future update notifications in git hooks </cmt> <cmt> upgrade pre-commit hooks and move into requirements-pre-commit.txt </cmt> <cmt> black target-version py36 </cmt> <cmt> manually fix file black trips on </cmt> <cmt> (cherry picked from commit 93c6b8cee295eff2429e31b618bbf6f6a94a5e13) </cmt> <cmt> blacken </cmt> <cmt> flake8 bin/ </cmt>",pre-commit upgrade + sweeping rerun + __future__ removals
260,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description i've been testing out the vtable, rtti detection and parsing, i've tried some exotic arches and found that sometimes only some vtables are found, so far we assumed that vtable always have to be in the same section as a vtable, but in some binaries (powerpc one, some rttis were in the .rodata and others were in .sdata) that wasn't the case, i've relaxed the requirement so we only check if the rtti pointer points to an initialized data section which improved the detection. but i don't know how to properly detect such section in radare, i got inspired by the implementation for possible vtable section. i've looked into retdec way and they only seem to check if rtti is a valid pointer somewhere in the binary and then they parse the rtti, if any crucial step of the parsing fails, they take it as an invalid rtti and thus invalid vtable we can maybe try the same approach, that would also help us to not rely on flags for knowing the typeinfoclass, also because in some examples relying on the flags didn't work and we lost more rtti information because of it, because it assumes that anything that doesn't have the flag is the default typeinfo_class </desc> <cmt> changed vtable detection heuristic that rtti must be inside the same section as the vtable </cmt> <cmt> moved to a function </cmt> <cmt> added section </cmt>",change itanium vtable detection heuristic ##anal
261,<desc> this fixes issue related to #4035. corrects references to interfaces defined in angular.d.ts and used in ng-grid from the modlue ng to angular. </desc> <cmt> update ng-grid.d.ts angular references from ng </cmt> <cmt> fixed errors in find ng. ang replace angular.. </cmt> <cmt> update ng-grid-tests.ts angular module </cmt> <cmt> changed references from depreciated ng module to angular module </cmt>,update ng grid angular references
262,<desc> add support for line pattern and line width to the new rendering engine. resolves #1466 have read the contribution guidelines targeted develop branch </desc> <cmt> #1466 handling line styles using the new rendering engine </cmt> <cmt> #1466 fixing notes for state diagrams (beta) </cmt> <iss> add line type beta rendering of flowcharts </iss>,1466 linetypes in beta renderer
263,"<desc> the desired semantics for wait() with duplicate ids are very unclear, so it's best to just check that the passed ids are unique and throw an error if they aren't (this is what we currently do in python). this pr adds that check and then modifies the storeprovider interface to take an unordered_set instead of a vector. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> clean up store provider get </cmt> <cmt> comments </cmt> <cmt> remove unneeded clear()s </cmt> <cmt> fix header comment </cmt> <cmt> update comment </cmt> <cmt> fix timeout </cmt> <cmt> don't modify input object ids </cmt> <cmt> clean up wait() </cmt> <cmt> fix tests </cmt> <cmt> fix tests </cmt> <cmt> add more wait() tests </cmt> <cmt> lint </cmt> <cmt> fix comparisons </cmt> <cmt> lint </cmt> <cmt> add comment about wait semantics </cmt> <cmt> lint </cmt> <cmt> lint </cmt> <cmt> don't modify object_ids in store provider wait() </cmt>",clean up wait() in the core worker
264,"<desc> this pullrequest changes fix typos in the documentation for the class autobuffer. </desc> <cmt> allocate 1000 floats to match the documentation </cmt> <cmt> fix the documentation of autobuffer. by default, the following code </cmt> <cmt> .cpp </cmt> <cmt> cv::autobuffer<float> m; </cmt> <cmt>  </cmt> <cmt> allocates only 264 floats. but the comment in the demonstration code says it allocates 1000 floats, which is </cmt> <cmt> not correct. </cmt> <cmt> fix typo in the comment. </cmt>",fix typos in the documentation for autobuffer.
265,"<desc> relatively simple check to ensure a block can always be created from the mempool </desc> <cmt> fuzz: allow to pass min/max to consumetime </cmt> <cmt> fuzz: use correct variant of consumerandomlengthstring instead of hardcoding a maximum size </cmt> <cmt> this is technically a breaking change. </cmt> <cmt> this allows the fuzz engine to pick the right size, </cmt> <cmt> also larger sizes, if needed. </cmt> <cmt> fuzz: limit mocktime to mtp in tx_pool targets </cmt> <cmt> this is needed for the next commit to generate blocks. </cmt> <cmt> also, apply the same mocking strategies to both targets. </cmt>",create a block template in tx_pool targets
266,"<desc> when we maximize the window, shrink the caption buttons (the min, max, close buttons) down to 32px tall, to be the same height as the tabrowcontrol. this way, the tabs will be flush with the top of the display. closes #2541 i work here i tried for a couple hours this morning to do this as a visualstate. first i tried doing it as one on the tabrow, which i had very little success with. then, i eventually realized that the tabrow wasn't even responsible for the padding there, it was being created by the fact that the caption buttons were too tall. again, i tried to use the existing visualstates they have defined for this, but i couldn't figure out how to do that. i think the visual state solution would be cleaner, so if someone knows how to do that instead, please let me know. maximized/restored the terminal on my display with the taskbar on the bottom maximized/restored the terminal on my display with the taskbar on the top </desc> <cmt> naively attempt to add a visualstate to the tabview </cmt> <cmt> i thought this would be easier. i'm trying to do this the xaml-y way, so i get better at it. </cmt> <cmt> i'm annoyed that both contentpresenter and grid aren't controls, because i thought this would work. </cmt> <cmt> i'm gonna really blow this file up, so i'm stashing this. </cmt> <cmt> this was a dead-end, apparently it can't find the defaulttabviewstyle resource so we'll just do it by hand </cmt> <cmt> cleanup for review </cmt> <iss> do not pad tabs from the top when maximized or fullscreen </iss>",get rid of the padding above the tab row when maximized
267,<desc> backport of  #4975 - against gotham branch !!! @jmarshallnz - here it is - tested and verified working ... </desc> <cmt> [ae/osxsink/coreaudio] - split registration for the devicelist changed callback and registration for the default output device changed callback and move the coreaudio callback registration methods to ccoreaudiodevice and add possibility to suppress the defaultdevicechanged callback for a given time </cmt> <cmt> [osx/coreaudio] - suppress default output device changed callbacks for 2 seconds when setting physical and virtual formats </cmt>,fix possible device changed loop when using passthrough
268,"<desc> description: i have added a feature so that you can manually specify the ip address of a yamaha receiver if the autodiscovery won't work (due to a bug in yamaha's firmware). the underlying rxv library did already support manually specifying the address, so it was mostly reading the config and providing a second add_devices function related issue (if applicable): no related issue, but a feature request by myself in the forums pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#959 example entry for configuration.yaml (if applicable): media_player: platform: yamaha host: 192.168.1.100 name: 'basement receiver' checklist: documentation added/updated in home-assistant.io </desc> <cmt> added the possibility to manually specify a yamaha receiver </cmt> <cmt> added the possibility to manually specify a yamaha avr </cmt>",add the ability to manually specify a yamaha avr via it's ip address
269,"<desc> mostly done with find/replace to compare swift 4 and swift 5 instead of swift 3 and swift 4. there are some interesting changes here because api notes for 4 also apply to 3 unless otherwise specified, and 4.2 is the next version after 4 rather than 5, but everything should still be correct and testing useful stuff. </desc> <cmt> [test] update apinotes tests for swift 3 removal </cmt> <cmt> for the most part, this moves 3/4 tests to 4/5 tests. there are </cmt> <cmt> some interesting changes here because api notes for 4 also apply </cmt> <cmt> to 3 unless otherwise specified, and 4.2 is the next version after </cmt> <cmt> 4 rather than 5, but everything should still be correct and testing </cmt> <cmt> useful stuff. </cmt> <cmt> [test] update serialization tests for swift 3 removal </cmt> <cmt> for the most part, this moves 3/4 tests to 4/5 tests. </cmt> <cmt> [test] update printasobjc test (just one) for swift 3 removal </cmt> <cmt> use swift 4 as the ""old"" version instead of swift 3. </cmt>","update apinotes, serialization, and printasobjc tests for swift 3 removal"
270,"<desc> bug fixes apis cherry-pick of #29579 and #29617 to fix problems. fixes: jit.save without running after jit.load. retry for cublas if gpu allocation fails. </desc> <cmt> [dy2stat] enable jit.save to save without running (#29579) </cmt> <cmt> enable jit.save to save without running. </cmt> <cmt> modify cublashandleholder to fix random unittest failure. test=develop (#29617) </cmt> <cmt> modify cublashandleholder from using paddle_enforce_cuda_success to paddle_retry_cuda_success to fix random unittest failure. we checked that the unittest log showed cuda allocation error at this file, which may due to gpu not enough. we fixed similar failure in the past, so we applied paddle_retry_cuda_success here. </cmt>",cherry-pick of pr#29579 and pr#29617
271,<desc> logical functions correctly handle null arguments: select 0 or null      returns null select 1 and null    returns null select 0 and null   returns 0 select 1 or null      returns 1 this corrects issue  #3834 (incorrect null logic for and/or operations). i hereby agree to the terms of the cla available at:  sql compatibility </desc> <cmt> [wip] basic working version </cmt> <cmt> wip: candidate1 - much less code. several todo's are still there </cmt> <cmt> moving around some code </cmt> <cmt> wip - made code much more compact </cmt> <cmt> wip - fixes and code moving around </cmt> <cmt> minor renamings </cmt> <cmt> fix for consts </cmt> <cmt> fixed column size mismatch in some scenarios </cmt>,correct implementation of ternary logic for and/or
272,"<desc> closes #39147 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry the previous fix only viewed row indexers not column indexers </desc> <cmt> bug: fix regression in loc setitem raising keyerror when enlarging df mit multiindex </cmt> <iss> regr: assigning multiple new columns with loc fails when index is a multiindex </iss>",fix regression in loc setitem raising keyerror when enlarging df with multiindex
273,"<desc> define metadata and chartplugin for all the simple charts. copy thumbnail images to visualization directories and refer to them in metadata. update webpack rules to reduce limit for including image as data url via url-loader from 100kb to 10kb also change the image output format from default [hash].[ext] to [name].[hash:8].[ext] combine webpack rules for gif and jpg this pr does not include nvd3, deck.gl or bignumber yet @williaster @conglei @graceguo-supercat @michellethomas </desc> <cmt> add credit field </cmt> <cmt> change image size limit for url-loader </cmt> <cmt> create chord chartplugin </cmt> <cmt> update config to include original file name in the output </cmt> <cmt> add calendar </cmt> <cmt> add country map </cmt> <cmt> add eventflow </cmt> <cmt> add thumbnails </cmt> <cmt> add eventflow, filterbox, force-directed and heatmap </cmt> <cmt> add histogram, horizon, mapbox, paired t-test, parallel coordinates </cmt> <cmt> create plugins for the rest one-off charts </cmt>",create chart plugins and metadata
274,"<desc> retry of #15201. canary testing branch here: </desc> <cmt> revert ""revert ""py3(django): defer more model imports until after django setup (part 2, take 2) (#15094)"" (#15127)"" </cmt> <cmt> this reverts commit 3b5c3128f85205d9fff05030ab58f4c650339dba. </cmt> <cmt> fix the one import i missed </cmt>","defer more model imports until after django setup (part 2, take 4)"
275,"<desc> this allows platforms to specify dependencies just like components. example code that could be in a platform: dependencies = ['switch', 'history'] this code ensures that the components switch and history will be setup before this platform setup method is called. it will also ensure that this platform will not get loaded if we could not setup any dependency. besides that, i have taken the opportunity to convert some double quoted strings to single quoted. </desc> <cmt> allow platforms to specify dependencies </cmt> <cmt> convert some double to single quotes. </cmt>",allow platforms to specify dependencies.
276,<desc> another attempt at #29879 i tested both true and false in #29879 but i didn't actually check which branch was hit in the pr run so let's focus now. fail with 8fbae13 mui-material.tgz should be uploaded on prs but not size-snapshot.json:  pass: with 55edd01 mui-material.tgz should be uploaded on prs but not size-snapshot.json: </desc> <cmt> [core] fix pr detection pattern </cmt> <cmt> revert later debug pattern </cmt>,fix pr detection pattern in test_bundle_size_monitor
277,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:   increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added definition for options type. removed mtlloader.materials - there is only materialcreator.materials, judging from the source code. </cmt> <cmt> specified several ""any"" types within materialcreator; made a few loadtexture params optional. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>","fixed one error and specified several ""any"" types."
278,<desc> update the version of weex_inspector enable http and websocket inspection in playground </desc> <cmt> * [android] enable network inspector on playground </cmt> <cmt> # conflicts: </cmt> <cmt> #	android/playground/build.gradle </cmt> <cmt> * [android] remove fixme </cmt> <cmt> * [android] add gradle wrapper </cmt> <cmt> + [android] update dependencies </cmt>,+ [android] enable network inspector in playground
279,"<desc> this integrates yahoo's react-intl internationalization and pluralization package into the react-boilerplate. this pr is a first pass at internationalization and integration. we can further this with multi-language support, in-app redux support (so language can be changed on the fly) and other features we deep not too bulky. this pr adds the intlprovider object to the main app.js in both the app and templates folder. it also adds the formattedmessage and formattednumber components to all text and numbers used within the example app and the internals/templates containers/components. react-intl titles each formatted message and number with an id. the id naming scheme i've choosen is similar to that of the constants naming scheme used in the example app and scaffolding with some slight modifications for component thinking and dot notation. the id system is used to build language json files that can be front-loaded in the intlprovider. having all language in json files allows others to mak language support easier. example id use: <formattedmessage id=""boilerplate.components.footer.license.message"" defaultmessage={ this project is licensed under the mit license. } /> some intl id examples: boilerplate.containers.homepage.start_project.header boilerplate.containers.homepage.start_project.message boilerplate.containers.featurepage.features.header boilerplate.components.footer.license.message boilerplate.components.footer.author.message here you can see the full app name being used. the container or component it is picking out. the capitalized exact component name. the text and context that is being referred too. this way, language files can point exactly to the component or container. component pointers are exact names. while other sub-text and sections are lowercase and using underscores. pitfalls: (1) react-intl has a few snags that should be made aware of in the docs. one is that for enzyme testing, template literal spacing, if even slightly incorrect, between what formattedmessage is being tested, will not equal the same text spacing in enzyme. to prevent this, exact spacing should be used, or unused spacing should be removed. otherwise the components wont match in enzyme thus causing an error. (2) another pitfall is that scrollspy among others require the intlprovider object to be wrapped around the mount enzyme tests. i'm less worried about this. but it is a requirement. (3) react-native support, see: formatjs/formatjs#119 -- not sure if this is our concern right now. i think these pitfalls are minor, as i believe the benefits to internationalization outweigh the negatives here. we may want to rename a few components here or id's. and consider the pitfalls that i have found so far. thoughts? </desc> <cmt> react-intl i18n support </cmt> <cmt> import placement fix </cmt>",react-intl i18n internationalization and pluralization integration
280,<desc> related discussion: #57816. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: node.js documentation for node: prefix in cjs and esm. </desc> <cmt> add module aliases for path posix and win32 </cmt> <cmt> update tests for path </cmt>,add missing aliases node:path/posix and node:path/win32
281,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. </desc> <cmt> fix(docs): fix links in /docs/chinese/contributing.md </cmt> <cmt> fix(docs): specify language in links </cmt>",fix link styles in chinese contributing
282,"<desc> more progress towards #6369 </desc> <cmt> kernel: switch biossysfscomponent constructor to ak::stringview </cmt> <cmt> these are constants, they don't need to be dynamically allocated. </cmt> <cmt> another minor step towards removing ak::string from the kernel </cmt> <cmt> and improving oom safety. </cmt> <cmt> kernel: remove duplicate constructor from tty/virtualconsole </cmt> <cmt> this removes some code dupe from the constructors. </cmt> <cmt> by removing this duplicate constructor we can utilize the main </cmt> <cmt> virtualconsole::create factory implementation and call that from the </cmt> <cmt> virtualconsole::create_with_preset_log factory method. </cmt> <cmt> kernel: move tty subsystem to use kstring instead of ak::string </cmt> <cmt> this is minor progress on removing the ak::string api from the kernel </cmt> <cmt> in the interest of improving oom safety. </cmt>",replace more usage of ak::string with kernel::kstring or ak::stringview
283,"<desc> previously, the completion item code in teh ls did something fairly unsafe.  it would cache information about symbols from a previous version of the 'program' (and typechecker), and then attempt to ask questions about those symbols after files had gone through edits the completion details code uses this cached information to try to get the type of the symbol so it can build the display information. this is not something safe to do.  because of the edits, we'll have totally different symbols for this file.  this inconsistancy can lead to situations where the typechecker we use cannot understand what's going on.  this can happen when it goes from a symbol back to the source, and back to some symbol.  this symbol will then not be one it knows about and we'll usually end up with an 'unknown' symbol result. the new approach is to extract out a common core routine for getting completion symbols.  this routine can be called by getcompletionsatposition to get the set of symbols to display.  the routine can also be called with a completion entry name.  in this case, instead of collecting all symbols, it instead searches, but ignores all symbols that don't match that name, and immediately returns the moment it finds the first match. now there is no cached information stored between calls.  we always synchronize, and the ls, program and typechecker are always in a consistent state. testing this out with our own project revealed no performance issue with this approach.  completion entry details are returned just as quickly as before, and we no longer get errant 'any's in the completion entry details. </desc> <cmt> break out completion symbol collection into its own function. </cmt> <cmt> use the same logic for completion entry details that we do for getting completion entries. </cmt> <cmt> remove the active completion session. </cmt>",share code between getcompletionsatposition and getcompletionentrydetails.
284,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): do not pause/resume consumer on subscription at all - otherwise it may get paused indefinitely in some scenarios. detailed description: try to wait until the consumer gets subscription in an infinite loop - assume that it won't get hung. </desc> <cmt> do not pause/resume consumer at all </cmt> <cmt> fix kafka tests </cmt>,fix infinite loop when reading kafka messages
285,"<desc> fixes gh-15984 </desc> <cmt> improved one of the error messages for histogramdd.py as outlined in issue #15984 </cmt> <cmt> added an exception in histogramdd.py to provide more meaningful errors, in response to issue #15984 </cmt> <cmt> new test branch </cmt> <iss> np.histogramdd produces confusing errors when `bins` is a float </iss>",better error message when bins has float value in histogramdd.
286,"<desc> success popup notifications in error case fixed error log for deleted objects in tasks added, handling tasks for not open databases fixed </desc> <cmt> #8893 success popup notifications in error case fixed </cmt> <cmt> #8893 error log for deleted objects in tasks added, handling tasks for not open databases fixed </cmt>",#8893 postgresql tasks errors fixed
287,<desc> this pr implements the bulk of pep 626. adds the new line number table implements the new api and exported functions. modifies the bytecode optimizer to only eliminate bytecodes if it doesn't change the line events that would occur. </desc> <cmt> new line number table format. mostly working. </cmt> <cmt> implement code.co_lines. wip. </cmt> <cmt> change line number format to be more robust for iterators. </cmt> <cmt> mark some bytecodes as articifial. </cmt> <cmt> rename 'nop' as 'pass'. </cmt> <cmt> add code.co_lines() and fix up various tests. </cmt> <cmt> implement api as defined in pep 626. </cmt> <cmt> fix 'off by one' error in line table pointer. </cmt>,partial implementation of pep 626.
288,<desc> these extra warning messages were introduced as a side effect of #617. </desc> <cmt> don't submit the actor destructor tasks when the job is exiting. </cmt> <cmt> don't propagate error messages to the driver when an actor exits intentionally. </cmt>,suppress excess warning messages related to intentional actor deaths.
289,<desc> a witness signature is intended to convey full validation by a node. disallow operation when a node is not fully validating. select one </desc> <cmt> add accessor for controller's trusted producer list </cmt> <cmt> witness_plugin requires full validation </cmt>,ensure witness_plugin only runs with full validation
290,"<desc> ccc info radar: rdar://problem/37253518 explanation: there are two problems with non-determinism: temporary file pathes written into debug info a peephole optimization in silcombine these problems almost always prevent incremental llvm compilation: that means in whole-module mode, all llvm modules are recompiled even if they don't change. risk: low. the changes are small and only affect the command line we store in the debug info +  a fix in silcombine. the generated code should be the same (module non-determinism) scope of issue: can affect build time for whole-module release builds. origination: the issues are there since a long time reviewed by: adrian and jordan testing: recompile a large project in release mode and check if the output object file is not rewritten if there are no source changes. currently we don't have an automated test for this. i'm doing that locally with the stdlib build. </desc> <cmt> debug-info: don't write temporary file names in the debug info. </cmt> <cmt> this would prevent incremental llvm compilation because we would generate different ir on every compiler invocation. </cmt> <cmt> silcombiner: fix a non-determinism in a peephole optimization for load instructions. </cmt>",fix two issues which prevents incremental llvm compilation
291,"<desc> this is split out from #18531 to just touch some rpc methods. description from the main pr: rpcarg names in the rpc help are currently only used for documentation. however, in the future they could be used to teach the server the named arguments. named arguments are currently registered by the crpccommands and duplicate the rpcarg names from the documentation. this redundancy is fragile, and has lead to errors in the past (despite having linters to catch those kind of errors). see section ""bugs found"" for a list of bugs that have been found as a result of the changes here. the changes here add an assert in the crpccommand constructor that the rpcarg names are identical to the ones in the crpccommand. future work here or follow up, makes sense to also assert type of returned univalue? sure, but let's not get ahead of ourselves. i am going to submit any further works as follow-ups, including: removing the crpccommand arguments, now that they are asserted to be equal and thus redundant removing all python regex linters on the args, now that rpcman can be used to generate any output, including the cli.cpp table auto-formatting and sanity checking the rpcexamples with rpcman checking passed-in json in self-check. removing redundant checks checking returned json against documentation to avoid regressions or false documentation compile the rpc documentation at compile-time to ensure it doesn't change at runtime and is completely static bugs found the assert identified issue #18607 the changes itself fixed bug #19250 </desc> <cmt> assert that rpcarg names are equal to crpccommand ones (blockchain) </cmt> <cmt> assert that rpcarg names are equal to crpccommand ones (rawtransaction) </cmt>","assert that rpcarg names are equal to crpccommand ones (blockchain,rawtransaction)"
292,<desc> for #4937 shardingtransactiontypescanner scanner will create proxy automatically if using @shardingtransactiontype annotation in class or method shardingtransactiontypeadvisor this advisor is spring original way to proceed aop which include poinctcut and advice shardingtransactiontypeinterceptor interceptor is a implement of advice which invoke transactiontypeholder class </desc> <cmt> implement sharding transaction type scanner </cmt> <cmt> add unit test </cmt> <cmt> simplify dependencies </cmt>,using shardingtransactiontypescanner to create proxy bean which include transaction type annotation
293,"<desc> this is an alternate version of #32802 -- see that one for context. this version attempts to prevent false positives by doing a syntax walk to see if the checked function is used, as opposed to relying on a heuristic where the function returns a boolean. the first commit is the same for both pr; the second adds filtering that differs. opened as a separate pr by request ( notably, this change flagged a couple things in the compiler itself. commented below for both. </desc> <cmt> flag non-nullable values with call expressions in if statements as errors </cmt> <cmt> only error when testing functions that are not used in the following block </cmt>",flag non-nullable functions in if statements as errors (tree walk version)
294,"<desc> add different strategies to handle lane tracking, with callback on motion: (1)motion arrives earlier (2) motion later (3) motion not found. (4)motion drop (5) image drop. etc </desc> <cmt> perception: enable lane tracking by history. function ok, parameter tuning needed </cmt> <cmt> perception(in progress): lane post processor with history smooth </cmt> <cmt> xperception: enable lane history smooting for lane post processing </cmt> <cmt> modify dag config, move motion service to upper level of the dag </cmt> <cmt> perception: add mutex to motion service. motion service now callback on image/localization. support looping and waiting, sudden drop of frames, etc. </cmt>",major change in motion service/lane tracking. pass stress test.
295,"<desc> this pr is building on top of #6321 by adding the ability to cancel a chunk download. </desc> <cmt> add support sequenceableloader.reevaluatebuffer() for hls </cmt> <cmt> dash implements this feature, extend the feature for hls as well.  first change just drops video samples. </cmt> <cmt> for demuxed audio the audio samples will continue to play out to match the </cmt> <cmt> dropped video, so need to keep indexes in all the sample queues related to a chunk and discard them all. </cmt> <cmt> update to save all sample queue write indexes </cmt> <cmt> finailzed logic to update the samplequeue write positions (first index) to push these into hlsmediachunk when the track is initially created (from the extractor output) and as each new chunk is queued to load (init() callback). </cmt> <cmt> add lots of debuging prints that can come out for the final merge. </cmt> <cmt> code is very close to a clone of chunksamplestream. </cmt> <cmt> remove unused methods, comment cleanup. </cmt>",cancel hls chunk download and discard upstream
296,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the declaration file was almost unusable and required a very minor tweak. originally the test file used a umd import style of import * as ffmpeg from 'fluent-ffmpeg' this type of import would throw an error in node environment thus an import of import ffmpeg = require('fluent-ffmpeg') was required under typescript handbook this library more suited a module library and required an export as namespace options which can be found here now this allows me to do stuff like import ffmpeg = require('fluent-ffmpeg'); class ffmpegadaptor { private ffmpegcommand: ffmpeg.ffmpegcommand; constructor(options) { this.ffmpegcommand = ffmpeg(options) ... .... </desc> <cmt> added hls.js definition </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changed to new tslint format </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixing lint errors </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changed definition structure based on pr comment </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added module library support </cmt>,update fluent-ffmpeg for es6 module library import
297,<desc> fixes #19808 (use fetch_openml with as_frame=false) also update the example to use tsne with square_distances=true (added in #17662). </desc> <cmt> fix use as_frame=false in example </cmt> <cmt> mnt use square_distances=true </cmt> <iss> example: approximate nearest neighbors in tsne </iss>,fix approximate nearest neighbors in tsne example
298,"<desc> checklist for the pandas documentation sprint (ignore this if you are doing an unrelated pr): pr title is ""doc: update the  docstring"" the validation script passes: scripts/validate_docstrings.py <your-function-or-method> the pep8 style check passes: git diff upstream/master -u -- ""*.py"" | flake8 --diff the html version looks good: python doc/make.py --single <your-function-or-method> it has been proofread on language by another sprint participant please include the output of the validation script below between the """" ticks: ################################################################################ ######################### docstring (pandas.index.any) ######################### ################################################################################ return whether any element is true. parameters ---------- *args these parameters will be passed to numpy.any. **kwargs these parameters will be passed to numpy.any. returns ------- any : bool or array_like (if axis is specified) a single element array_like may be converted to bool. see also -------- pandas.index.all : return whether all elements are true. notes ----- not a number (nan), positive infinity and negative infinity evaluate to true because these are not equal to zero. examples -------- >>> index = pd.index([0, 1, 2]) >>> index.any() true >>> index = pd.index([0, 0, 0]) >>> index.any() false ################################################################################ ################################## validation ################################## ################################################################################ errors found: no extended summary found errors in parameters section parameters {'args', 'kwargs'} not documented unknown parameters {'**kwargs', '*args'} parameter ""*args"" has no type parameter ""**kwargs"" has no type ################################################################################ ######################### docstring (pandas.index.all) ######################### ################################################################################ return whether all elements are true. parameters ---------- *args these parameters will be passed to numpy.all. **kwargs these parameters will be passed to numpy.all. returns ------- all : bool or array_like (if axis is specified) a single element array_like may be converted to bool. see also -------- pandas.index.any : return whether any element is true. notes ----- not a number (nan), positive infinity and negative infinity evaluate to true because these are not equal to zero. examples -------- >>> index = pd.index([1, 2, 3]) >>> index.all() true >>> index = pd.index([0, 1, 2]) >>> index.all() false ################################################################################ ################################## validation ################################## ################################################################################ errors found: no extended summary found errors in parameters section parameters {'kwargs', 'args'} not documented unknown parameters {'**kwargs', '*args'} parameter ""*args"" has no type parameter ""**kwargs"" has no type if the validation script still gives errors, but you think there is a good reason to deviate in this case (and there are certainly such cases), please state this explicitly. </desc> <cmt> doc: improved the docstring of pandasindex.all and pandasindex.any. </cmt> <cmt> doc: improved docstring of pandas.index.all and pandas.index.any </cmt> <cmt> doc: improved docstring </cmt>",docstring pandas index all any
299,"<desc> stricter type checking of options whose types cannot be inferred. using unknown instead of any provides significantly better protection against typos and refactoring errors. in yargs-parser it still makes sense to use any, until there is support for inferring more specific types. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. (already exists) </desc> <cmt> updated typings for yargs, inferring the shape of the parsed arguments. </cmt> <cmt> fix lint errors. </cmt> <cmt> use $expecttype, and add more tests. </cmt> <cmt> updated comments. </cmt> <cmt> slight improvement to alias, organize tests more systematically. </cmt> <cmt> fix for count, more tests. </cmt> <cmt> more restructuring of tests. </cmt> <cmt> handle optional vs. required options. </cmt> <cmt> consistently use [key in ... for mapped types. </cmt> <cmt> improve handling of arrays, defaulting to (string | number)[]. </cmt> <cmt> more improvements to array/number/string handling, and use omit to reset types for repeated options. </cmt> <cmt> more precise usage of omit, fix tostring and tonumber. </cmt> <cmt> remove blank line, keeping the alias overloads in one group.. </cmt> <cmt> bump required typescript version in yargs-parser to match yargs, and adapt the arguments type. </cmt> <cmt> use readonlyarray for choices. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> yargs: fall back to unknown for unknown arguments, </cmt> <cmt> and enable demand/demandoption to come before the option definition. still fall back to any in yargs-parser (removing the dependency from yargs-parser on yargs). </cmt> <cmt> more tests for falling back to unknown. </cmt>",fall back to unknown instead of any for unknown options
300,"<desc> see jenkins-60884. this is fix for a nullpointerexception in run.getpreviousbuildsoverthreshold that was introduced by a refactor to add a new run.getbuildsoverthreshold method in revision pr #4259 fix nullpointerexception when getting a list of runs with a status threshold (regression in 2.202) changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue should exist and be labeled as lts-candidate </desc> <cmt> added a null check to getpreviousbuildsoverthreshold. </cmt> <cmt> cleaned up accidental newline. </cmt>",fix npe in run api when using getpreviousbuildsoverthreshold
301,<desc> moved things out of the polar area & radar charts and into the radial linear scale. merged chart.scales into chart.scaleservice for consistency. </desc> <cmt> move some of the radial linear scale functions into the radiallinear scale </cmt> <cmt> merge chart.scales into chart.scaleservice to be consistent </cmt>,move things into the radiallinear scale
302,"<desc> what were changed? install react-hot-loader and configure it to work with babel original index.jsx are renamed to app.jsx and exported as hot module. new index.jsx are thin shells that calls reactdom.render to render <app /> why? hot module replacement for react will enable us to develop the ui faster because when we make changes, the page keeps ui state and only replace the ui code affected by the change instead of reloading the entire page. for example, you open an sql editor, look up a few schema, switch tabs. when you modify code for one button and save, everything stays the same. only the button will be changed. reference installed based on instruction here  from the instruction page note: you can safely install react-hot-loader as a regular dependency instead of a dev dependency as it automatically ensures it is not executed in production and the footprint is minimal. @williaster @graceguo-supercat @xtinec @conglei </desc> <cmt> install react-hot-loader </cmt> <cmt> enable react-hot-reload for explore, dashboard, profile and sqllab </cmt> <cmt> enable hmr for welcome page </cmt> <cmt> enable hmr for welcome page </cmt> <cmt> enable react hot module replacement for addslice </cmt>",enable hot module replacement for react via react-hot-loader
303,"<desc> inspired by @elisehuard's gc talk at euruko, i tried to reduce instances of string in rails code. i haven't done actual performance benchmarks, but number of objectspace.each_object(string).count was significantly decreased on my simple test app. before: 128696 after: 121995 </desc> <cmt> stop to_sing method names </cmt> <cmt> module#methods are symbols in ruby >= 1.9 </cmt> <cmt> symbol responds_to :upcase & :downcase in ruby >= 1.9 </cmt> <cmt> no need to to_s here. both string and symbol can be interpolated into string </cmt>",reduce number of string instance
304,"<desc> this brings the windows build guide closer to a working guide, and re-adds the fedora guide from 1.6. have added build environment pre-requisites (g++, make, automake, etc.) for fedora as well. </desc> <cmt> updated windows build guide with more realistic set of pre-requisites. </cmt> <cmt> updated libboost version listed in windows build guide to match unix guide. </cmt> <cmt> rewrote libboost installation docs for windows to match a more conventional process. </cmt> <cmt> added details of where include and library files should be installed for windows build process. </cmt> <cmt> corrected configuration line for dogecoin to one which is likely to work in a mingw environment. </cmt> <cmt> added ""pkg-config"" to dependencies for ubuntu/debian environments.. </cmt> <cmt> documentation for fedora dependency equivalents. </cmt> <cmt> added build environment pre-requisites for fedora build instructions. </cmt>",update windows and fedora build guides
305,"<desc> fixes #7649 </desc> <cmt> make getregulartypeofobjectliteral recursive </cmt> <cmt> getregulartypeofobjectliteral marks an object literal as non-fresh so </cmt> <cmt> that excess object-property errors will not be reported. it is needed so </cmt> <cmt> that errors aren't reported when checking assignability to intersections </cmt> <cmt> or unions, for example. previously, the function was not recursive, so </cmt> <cmt> nested object literals still erroneously gave the error. now it's </cmt> <cmt> recursive. </cmt> <cmt> test nested object literal assignability to intersection type </cmt>",recursively mark object literals as non-fresh when checking assignability to intersections
306,<desc> this pr is a simplified version of #12939 closes #12438 closes #12695 </desc> <cmt> initial iteration done. </cmt> <cmt> update </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> pending </cmt> <cmt> fix it </cmt> <cmt> skip </cmt> <cmt> fix unit test </cmt> <iss> [new scheduler] fix test_global_gc::test_global_gc_actors </iss> <iss> [new scheduler] implement the resource deadlock warning </iss>,implement resource deadlock detection for new scheduler
307,<desc> wrote module ecs_tag and the integration tests new module pull request ecs_tag implements the boto3 ecs tag_resource() and untag_resource() #51122 </desc> <cmt> fork take three </cmt> <cmt> got screwed accidentally having a conflict file and not the real deal. </cmt> <cmt> reworked. last rebase attempt was a bad experience. </cmt> <cmt> added integrations test for ecs_tag </cmt>,ecs_tag and integration tests for new feature request
308,"<desc> this is a possible alternative solution to what we have been discussing in #25592. this moves the logic into safe_sort, with: adding a check_outofbounds keyword to disable extra checks (otherwise the performance benefit of take_1d is lost) fixing safe_sort to work for eas the check_outofbounds make it a bit more complicated, but without it, we can't benefit of the performance improvement for which take_1d was used originally in factorize. (another solution is to simply decide that this performance improvement is not worth this extra code, and we simply use the current safe_sort (but fixed to work for eas) in factorize) need to add some more tests for the combination of eas with a custom na_sentinel (a case that is currently broken) </desc> <cmt> bug: fix usage of na_sentinel with sort=true in factorize() </cmt> <cmt> fix dtype </cmt> <cmt> attempt to include it in safe_sort </cmt>",handle eas and fast path (no bounds checking) in safe_sort
309,"<desc> this is a copy of pr #19859 into master, instead of tf1.8. / </desc> <cmt> fixes #19858 </cmt> <cmt> adds space handling in the equation parameter similar to the np.einsum function to tf.einsum </cmt> <cmt> add tests for space handling </cmt> <cmt> adds tests for the space handling in the equation parameter of tf.einsum and adjusts the run_test method to ignore the spaces when assigning dimensionality to the random input tensors for the tests. </cmt>",space handling in equation parameter of tf.einsum
310,"<desc> i wanted to add a test case that reproduced the issue @alimpfard fixed in #4359 and ran into two more bugs while doing so. it seems that in most cases the offset calculation errors canceled each other out, because they happened both during reading and writing, thus making it appear like everything worked. </desc> <cmt> ak: fix unsigned integer underflow in duplexmemorystream::write. </cmt> <cmt> ak: fix offset calculation error in duplexmemorystream::write. </cmt>",fix two more bugs in duplexmemorystream.
311,"<desc> i set out to clean up the deprecated shuffles that were causing warnings in aten/native/cuda/embedding.cu and thcunn/lookuptable.cu, and in the process i noticed the existing implementations that did not use presorting (embedding_backward_feature_kernel and cunn_lookuptable_accgradparameterskernelbyfeature) were very inefficient.  they suffered from uncoalesced memory accesses, 32-way divergence if different threads in the warp wrote to the same (colliding) row of the embedding weight matrix, and more intrinsic calls than was necessary to check for such collisions. this pull request replaces those kernels with more efficient implementations that also avoid any deprecated shuffles.  deprecation warnings for these shuffles will no longer appear in the build.  the new implementation is fully deterministic, as required by the old kernel.  it outperforms the old kernel by between 2 and 8x across the range of parameters i tried, with especially significant improvements observed for large embedding sizes and many collisions.  my kernel's blocks do some aggregation of colliding updates in shared memory before writing them out, so it actually performs better in the case of collisions. i may be able to squeeze some more performance out of the kernel in future updates.  currently, the kernel uses int64 where necessary (indexing into the big gradient matrices) but in my profiling tests i played with relaxing that requirement, and observed a speedup of 5%ish in some cases.  if we don't anticipate people using embedding matrices with >2 billion elements, int32 indexing is low-hanging fruit for performance. the kernel launches have also been updated with appropriate arguments. finally, i changed warp_ballot in thcdeviceutils.cuh to return an unsigned int, for consistency with the description of __ballot_sync() in the cuda api. </desc> <cmt> more efficient kernel that avoids deprecated shuffles in embedding.cu and thcunn/lookuptable.cu </cmt> <cmt> using warp_ballot from thcdeviceutils.cuh, also changing warp_ballot to return unsigned </cmt>",more efficient kernels that avoid deprecated shuffles in embedding and lookuptable
312,"<desc> createindexrequest#source(map<string, object>, ... ), which is used when deserializing index creation requests, accidentally accepts mappings that are nested twice under the type key (as described in the bug report #38266). this in turn causes us to be too lenient in parsing typeless mappings. in particular, we accept the following index creation request, even though it should not contain the type key _doc: put index?include_type_name=false { ""mappings"": { ""_doc"": { ""properties"": { ... } } } there is a similar issue for both 'put templates' and 'put mappings' requests as well. this pr makes the minimal changes to detect and reject these typed mappings in requests. it does not address #38266 generally, or attempt a larger refactor around types in these server-side requests, as i think this should be done at a later time. </desc> <cmt> pull metadatamappingservice#ismappingsourcetyped into mapperservice. </cmt> <cmt> make sure to reject typed index creation + template requests when include_type_name is false. </cmt>",make sure to reject mappings with type _doc when include_type_name is false.
313,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> merge </cmt> <cmt> fix $addtoset </cmt>",fix mongo $addtoset and add meteor.absoluteurl.defaultoptions
314,<desc> directives of tengine feature: client_body_postpone_size/client_body_buffers -> t_deprecated (useless for current tengine although configuring these directives) gzip_clear_etag -> t_ngx_gzip_clear_etag resolver_file -> t_ngx_resolver_file </desc> <cmt> added t_ngx_gzip_clear_etag macro for gzip_clear_etag directive </cmt> <cmt> added t_ngx_resolver_file macro for resolver_file </cmt> <cmt> added t_ngx_client_body_postpone_size macro for client_body_postpone_size directive </cmt>,added c macros for tengine feature
315,"<desc> commit message: added emptydata and emptycontinuation frame to upstream flood tests. emptydata test shows headers will still be received if started, both tests use the default limit of 1 empty consecutive frame. risk level: low (tests) testing: tests added. fixes part of #12281 </desc> <cmt> add flood tests </cmt>",add emptydata/continuation to upstream flood tests
316,"<desc> very nice and aligned. </desc> <cmt> libgui: adjust content area and focus rect of tab buttons </cmt> <cmt> this improves the look of tabs and their focus rects. in particular, the </cmt> <cmt> concept of a ""text rect"" is removed, and whatever tab content area is </cmt> <cmt> left over after the icon and close button are added is used as the area </cmt> <cmt> to draw the text into. this approach is simpler than having a separate </cmt> <cmt> text rect. </cmt> <cmt> libgui: bias text towards bottom when tabs at top have uneven spacing </cmt> <cmt> this makes the text on inactive tabs in browser look a lil' bit nicer. </cmt> <cmt> :^) </cmt>",tab bar text/focus rect alignment improvements redux
317,"<desc> fixes #324 . in an effort to support other compilers (#109), this change reworks how precompiled headers are handled.  for toolchains where precompiled headers are not used, there is unnecessary compilation cost because each source file explicity includes the pch, meaning all system headers in the pch were recompiled for each translation unit. this change modifies the project's files so that each translation unit includes a minimal set of dependent headers.  for msvc users, the precompiled headers option is still enabled and the precompiled header is added to each translation unit using the compiler's forced includes option.  the end result is that msvc users still see the same build times, but other toolchains are free to use or not use precompiled headers. risks introduced given that our ci build uses msvc, this change introduces the risk that a system header is added to the pch and the calcmanager project builds correctly, but builds could be broken for other toolsets that don't use pch.  we know we want to add support for clang in our ci build (#211).  it seems reasonable to also compile without precompiled headers there so that we can regression test this setup. rebuild calcmanager project. compile time: ~4.5s. disable precompiled headers, keeping explicit include for pch in each source file. compile time: ~13s. remove explicit pch inclusion and add the appropriate headers to each translation unit to allow the project to compile.  compile time: ~8s. re-enable pch and include it using the forced includes compiler option. msvc compile time: ~4.5s. minor changes delete 'targetver.h'.  i found this while looking around for system headers in the project.  it's unused and unreferenced so let's remove it. </desc> <cmt> calcmanager project compiles without pch, but msvc users will still use pch through forced inclusion of the header. </cmt> <cmt> give guidelines about managing precompiled headers in contributing.md </cmt> <iss> consider reworking how pchs are used </iss>",compile calcmanager project with or without precompiled headers
318,"<desc> backport of #21083 </desc> <cmt> wallet: use existing feerate instead of getting a new one </cmt> <cmt> during each loop of createtransaction, instead of constantly getting a </cmt> <cmt> new feerate, use the feerate that we have already fetched for all </cmt> <cmt> fee calculations. thix fixes a race condition where the feerate required </cmt> <cmt> changes during each iteration of the loop. </cmt> <cmt> this commit changes behavior as the ""fee estimation failed"" error will </cmt> <cmt> now take priority over ""signing transaction failed"". </cmt> <cmt> github-pull: #21083 </cmt> <cmt> rebased-from: 1a6a0b0dfb90f9ebd4b86d7934c6aa5594974f5f </cmt> <cmt> wallet: replace nfeerateneeded with effective_fee </cmt> <cmt> make sure that all fee calculations use the same feerate. </cmt> <cmt> coin_selection_params.effective_fee is the variable we use for all fee </cmt> <cmt> calculations, so get rid of remaining nfeerateneeded usages and just </cmt> <cmt> directly set coin_selection_params.effective_fee. </cmt> <cmt> does not change behavior. </cmt> <cmt> github-pull: #21083 </cmt> <cmt> rebased-from: e2f429e6bbf7098f278c0247b954ecd3ba53cf37 </cmt> <cmt> wallet: move long term feerate setting to createtransaction </cmt> <cmt> instead of setting the long term feerate for each selectcoinsminconf </cmt> <cmt> iteration, set it once during createtransaction and let it be shared </cmt> <cmt> with each selectcoinsminconf through </cmt> <cmt> coin_selection_params.m_long_term_feerate. </cmt> <cmt> does not change behavior. </cmt> <cmt> github-pull: #21083 </cmt> <cmt> rebased-from: 448d04b931f86941903e855f831249ff5ec77485 </cmt> <cmt> wallet: move discard feerate fetching to createtransaction </cmt> <cmt> instead of fetching the discard feerate for each selectcoinsminconf </cmt> <cmt> iteration, fetch and cache it once during createtransaction so that it </cmt> <cmt> is shared for each selectcoinsminconf through </cmt> <cmt> coin_selection_params.m_discard_feerate. </cmt> <cmt> does not change behavior. </cmt> <cmt> github-pull: #21083 </cmt> <cmt> rebased-from: bdd0c2934b7f389ffcfae3b602ee3ecee8581acd </cmt>",avoid requesting fee rates multiple times during coin selection
319,"<desc> description: this fixes the issue and adds a testcase when requesting the jewish calendar sensor to display the holiday name in english. the correct place for this should be in the external hdat library, but for the time being i'm putting it here so it doesn't break the given configuration. related issue (if applicable): fixes #16830 pull request in home-assistant.io with documentation (if applicable): n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass n/a n/a if the code does not interact with devices: </desc> <cmt> add failing testcase for issue #16830 </cmt> <cmt> fix for #16830 </cmt> <iss> jewish calendar sensor error in beta </iss>",fix jewish calendar sensor with language set to english
320,"<desc> tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> perf: avoid ravel in isna with object dtype </cmt> <cmt> perf: avoid potential copy in block.convert </cmt> <cmt> perf: avoid ravel </cmt> <cmt> perf: avoid ravel </cmt>",avoid potential copies in ravel
321,"<desc> a few notes: the new implementation include values with a contextual type we are searching for e.g. interface ifoo { member: number; } var x : ifoo; x = {member: 1}; x = {member: 2}; // search for member should get you ifoo.member, member:1, and mebmer:2 the new implementation should handle string and number named declaration properly, which we did not handle before. e.g. var x = { ""foo"" : 0 }; x[""foo""] = 1; x.foo = 2;  // should see all instances of ""foo"" another difference is now we have one symbol for all merged symbols, to overcome this, we identify a ""meaning"" for each location; the ""meaning"" is a syntactic classification of the location as namespace, value or type access. we now include references that intersect with the original search location. some special handling is needed for constructs that straddle multiple spaces like classes and enums. getscope is meant as an optimization to limit the search scope if possible (e.g. local variables and parameters), i will add this later </desc> <cmt> extract helpers </cmt> <cmt> enbale getreferencesatposition </cmt> <cmt> expose utility functions </cmt> <cmt> enable reference tests </cmt> <cmt> enable some more tests </cmt> <cmt> disable resolution for now </cmt> <cmt> add basic getreferences implementation </cmt> <cmt> add some debug methods </cmt> <cmt> handel getrefrences for labels </cmt> <cmt> add support for getreferences on property string index access </cmt> <cmt> support getreferences on object literals </cmt> <cmt> support getreferences on contextually typed object literal properties </cmt> <cmt> support getreferences on properties and index access wiht numeric and string values </cmt> <cmt> add new test for getreferences on enums </cmt> <cmt> include inherited properties from base classes and interfaces in getreference results </cmt> <cmt> support filtering references based on meaning </cmt> <cmt> updates after merge from master </cmt>",wire getreferences to use the new compiler
322,"<desc> this pr contains four commits with the following purposes: replace an instance of presentional with presentational remove trailing whitespace from two lines replace an instance of devtools with devtools replace one instance each of emphasising, realising, and optimise with their spellings in us english, in line with how similar words are spelled elsewhere in the documentation i think that 1 is the only definite correction. if you don't think that 2, 3, or 4 are changes worth making, i'm happy to remove those commits from the pr. </desc> <cmt> fix typo </cmt> <cmt> remove trailing whitespace </cmt> <cmt> fix capitalization of devtools </cmt> <cmt> standardize to us spelling </cmt>","spelling, capitalization, and whitespace changes"
323,"<desc> fixes #1715 (/bin/sh in autogen.sh) fixes #1672 (little optimization when all classes/qdiscs are enabled) fixes #1712 (allow users to set netdata scheduling policy, priority and nice level) fixes #1714 (browser localstorage permission denied errors) allow users to set process scheduling policy, priority and nice level this pr allows users to set scheduling policy, priority and nice level. scheduling policy in netdata.conf, now there is: process scheduling policy = idle possible values are idle, other (or nice), rr (i.e. round-robin), fifo, batch, keep (or none). policy description idle use cpu only when there is spare - this is lower than nice 19 - this is the default for netdata otherornice this is the default policy for all processes under linux. it provides dynamic priorities based on the nice level of each process. batch this policy is similar to other in that it schedules the thread according to its dynamic priority (based on the nice value).  the difference is that this policy will cause the scheduler to always assume that the thread is cpu-intensive.  consequently, the scheduler will  apply a small scheduling penalty with respect to wakeup behavior, so that this thread is mildly disfavored in scheduling decisions. fifo fifo can be used only with static priorities higher than 0, which means that when a fifo threads becomes runnable, it will always  immediately  preempt  any  currently running  other, batch, or idle thread.  fifo is a simple scheduling algorithm without time slicing. rr a simple enhancement of fifo.  everything described above for fifo also applies to rr, except that each thread is allowed to run only for  a  maximum time  quantum. keepornone do not set scheduling policy, priority or nice level - i.e. keep running with whatever it is set already (e.g. by systemd). for more information see man sched. scheduling priority it can be set only for rr and fifo. once the policy is set to one of these, the following will appear: process scheduling priority = 0 these priorities are usually from 0 to 99. higher numbers make the process more important. nice level it can only be set when the policy is set to other, nice, or batch. the following will appear: process nice level = 19 </desc> <cmt> minor fix for debug statements in apps.plugin </cmt> <cmt> fixed mem.committed duplicate key </cmt> <cmt> fixed typo </cmt> <cmt> do not calculate tc leafs and parents if enabled_all_classes_qdiscs is enabled </cmt> <iss> random data gaps! </iss> <iss> demo crashes if browser has restrictive storage settings </iss> <iss> installer fails: autogen.sh not found </iss>",minor fixes and user configurable process scheduling priority
324,"<desc> this pr is an incremental improvement for the recommendations made in #18993 for the building apps with gatsby workflow. the main changes in this pr are: updating the client data fetching page renamed the title ""client data fetching"" -> ""build time and client runtime data fetching"" updated the example from the one with the rick and morty api at build time and a dog api at runtime to one using data from the github api at build time (for repo name, and url) and runtime (for star counts which change more frequently, essentially is dynamic) modified content to explain advantages of hybrid content and reflect the new name of the doc with both build time and runtime explanations, linking off to existing docs where the build time data stuff happens included the example in the repos example folder and deployed a live version ( added a recipe ""querying data client-side with fetch"" screenshots data fetching page new recipe relates to #18993 </desc> <cmt> first changes </cmt> <cmt> rename doc </cmt> <cmt> add example repo </cmt> <cmt> added recipe and updated guide </cmt>",gatsby for apps - data fetching
325,"<desc> the implementation is straightforward. a couple of notes: in our discussions, we had discussed throwing an error if log_prob got a value outside the distribution's support. this returns -inf instead. i thought that throwing an error does not seem to be a good response for a perfectly valid query. for reference, tensorflow return -inf for uniform but throws an error for bernoulli (scoring [1] with bernoulli([0.0]) for example). we should be consistent with whatever convention we choose. modified sample_n() to use torch.size instead of a tuple (n,). the reason is that tensor.new(tuple) just takes the last dim, as compared to tensor.new(torch.size). not sure if that's expected. cc. @apaszke. in [7]: torch.zeros(2, 2).new((3, 2)).size() out[7]: torch.size([2]) in [8]: torch.zeros(2, 2).new(torch.size((3, 2))).size() out[8]: torch.size([3, 2]) </desc> <cmt> adding the uniform distribution </cmt> <cmt> address comment </cmt>",adding uniform distribution to pytorch
326,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> initial commit for @types/parquetjs </cmt> <cmt> auto formatting changes </cmt> <cmt> fix remaining linter errors </cmt> <cmt> more autoformatting changes </cmt> <cmt> fix linter errors </cmt> <cmt> tsconfig should max standard dt tsconfig </cmt> <cmt> created tests from docs </cmt> <cmt> added optional and nullable fields </cmt>",add new type definitions for parquetjs
327,"<desc> i noticed that typings and documents of createnamespacedhelpers (ref #800) are missing. this pr adds them. in addition, i've refactored mapxxx helpers' typings to declare the namespaced helpers without redundancy. </desc> <cmt> fix(typings): add missing createnamespacedhelpers typings </cmt> <cmt> docs(en): add a description of createnamespacedhelpers </cmt>",add missing typings and docs of createnamespacedhelpers
328,<desc> remove references to us.gcr.io/k8s-artifacts-prod remove references to gcr.io/google-containers part of the vdf (vanity domain flip): kubernetes/release#270 /assign @dims @liggitt cc: @kubernetes/release-engineering @listx there are still some references to cleanup and possibly a few files to regenerate. /hold until we get the all-clear from @listx on friday (7/24) that the vdf is complete does this pr introduce a user-facing change?: </desc> <cmt> [vdf] remove references to us.gcr.io/k8s-artifacts-prod </cmt> <cmt> [vdf] remove references to gcr.io/google-containers </cmt>,normalize container image references to k8s.gcr.io
329,"<desc> fixes bugs #11623 and #11835. alteredslicetag was crashing because it was using a listview component, which requires access to react router to work (which explore view doesn't have). i replaced it with newer tableview to display a table. before: see linked issue after: test plan manually verify that bugs don't occur anymore. has associated issue: closes #11623, #11835 requires db migration. confirm db migration upgrade and downgrade tested. cc: @junlincc @adam-stasiak can you please test it? </desc> <cmt> fix chart name not updating </cmt> <cmt> fix alteredslicetag crashing </cmt>",altered button crashing and title not updating on explore view
330,"<desc> what is this about? this pr defines heading levels in the settings app to make scanning more efficient and accessible. pr checklist applies to #7033 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? the narrator supports this functionality when a visually impaired user would like to skim through the application by reading only it's headings. they can do so by following these steps - enable narrator press caps+space to enable scan mode in the narrator press h to read the headings before this pr we did not have any headings defined, therefore the narrator would just say no headings defined when h is pressed. this pr adds two levels of headings, level1 for the main heading and level2 for the sub-headings within the settings app. validation steps performed how does someone test & validate? follow these steps to validate that headings are defined - enable narrator press caps+space to enable scan mode in the narrator press h to read the headings </desc> <cmt> add shell page headings </cmt> <cmt> add headings for all the ptsettings </cmt> <cmt> add heading level 1 for the heading of each page </cmt> <cmt> resolve merge conflicts </cmt>",define heading levels in settings app
331,"<desc> new module pull request ce_command.py ansible version ansible 2.3.0 config file = /etc/ansible/ansible.cfg configured module search path = ['/home/ansible-2.1.1.0/lib/ansible/modules/core/network/cloudengine', '/home/ansible-2.1.1.0/lib/ansible/module_utils', '/home/ansible-2.1.1.0/lib/ansible/modules', '/home/ansible-2.1.1.0', '/home/ansible-2.1.1.0/lib/ansible/utils/'] task [display device] ********************************************************** task path: /usr1/code/openness/code/current/kvm/intg/test/testcases/test-ce_command.yml:15 using module file /usr/local/lib/python2.7/site-packages/ansible-2.3.0-py2.7.egg/ansible/modules/core/network/cloudengine/ce_command.py <ce_6850> establish local connection for user: root <ce_6850> exec /bin/sh -c '( umask 77 && mkdir -p "" echo $home/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986 "" && echo ansible-tmp-1487042701.29-103196937398986="" echo $home/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986 "" ) && sleep 0' <ce_6850> put /tmp/tmpsr4rqm to /root/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986/ce_command.py <ce_6850> exec /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986/ /root/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986/ce_command.py && sleep 0' <ce_6850> exec /bin/sh -c '/usr/bin/python /root/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986/ce_command.py; rm -rf ""/root/.ansible/tmp/ansible-tmp-1487042701.29-103196937398986/"" > /dev/null 2>&1 && sleep 0' ok: [ce_6850] => { ""changed"": false, ""invocation"": { ""module_args"": { ""auth_pass"": null, ""authorize"": false, ""commands"": [ ""display device"" ], ""host"": ""ce_6850"", ""interval"": 1, ""match"": ""all"", ""password"": ""value_specified_in_no_log_parameter"", ""port"": 12345, ""provider"": null, ""retries"": 10, ""ssh_keyfile"": null, ""timeout"": 10, ""transport"": null, ""use_ssl"": false, ""username"": ""rootdc"", ""validate_certs"": true, ""wait_for"": null }, ""module_name"": ""ce_command"" }, ""stdout"": [ ""device status:\n--------------------------------------------------------------------------------\nslot  card   type                     online   power register     alarm     primary        \n--------------------------------------------------------------------------------\n1     -      ce6850u-48s6q-hi         present  on    registered   normal    master         \n      fan1   fan-060a-b               present  on    registered   normal    na             \n      pwr2   pac-600wb-b              present  on    registered   normal    na             \n--------------------------------------------------------------------------------"" ], ""stdout_lines"": [ [ ""device status:"", ""--------------------------------------------------------------------------------"", ""slot  card   type                     online   power register     alarm     primary        "", ""--------------------------------------------------------------------------------"", ""1     -      ce6850u-48s6q-hi         present  on    registered   normal    master         "", ""      fan1   fan-060a-b               present  on    registered   normal    na             "", ""      pwr2   pac-600wb-b              present  on    registered   normal    na             "", ""--------------------------------------------------------------------------------"" ] ], ""warnings"": [] } </desc> <cmt> update ce_command.py </cmt> <cmt> update ce_command.py </cmt> <cmt> update ce_command </cmt> <cmt> update ce_command </cmt> <cmt> update ce_command.py </cmt> <cmt> update ce_command.py </cmt>",contributing lib/ansible/modules/network/cloudengine/ce_command.py module to manage huawei data center cloudengine
332,<desc> fixes #23496 file type file name published url content aspnetcore/fundamentals/environments.md </desc> <cmt> how to configure services and pipeline </cmt> <cmt> add api links </cmt> <iss> update startup class conventions and method conventions sections of environments article </iss>,6.0 environments - how to configure services and pipeline
333,"<desc> / (@fbuihuu you did the ibm powerv patches, hence please have a look if after my change all is correct) </desc> <cmt> man: slightly extend documentation on difference between id_net_name_onboard and id_net_label_onboard </cmt> <cmt> man: fix documentation of ibm vio device naming </cmt> <cmt> we generate ""v"" in two different ways, and they got mixed up. </cmt> <cmt> udev: use dot_or_dot_dot() where appropriate </cmt>",some net naming scheme documentation fixes
334,"<desc> when user opens atom-shell without providing any app, an instruction would be shown to tell user how to open an app with atom-shell, plus an interface to let user to drag a folder to the window to open an app. </desc> <cmt> show a friendly guide when atom-shell is opened without app. </cmt> <cmt> add some styles. </cmt> <cmt> enable dragging to open an app. </cmt> <cmt> use dialog to report invalid app. </cmt> <cmt> linkify the docs in default_app. </cmt>",provide a friendly interface for opening an app
335,<desc> this introduces the .hide-in-percy class to hide elements in the page on percy screenshots and hide the following elements: user edit page: api key all pages: pace progress bar check percy diff </desc> <cmt> bring back arik's fix </cmt> <cmt> change tests order </cmt>,introduce hide-in-percy and hide diff problematic elements
336,"<desc> the embed button in slice view page will redirect the window to the standalone version of the slice. we made a small change on this and now it will pop a popover for instead. the popover will let user input the width and height they want for the iframe and the iframe tag can be copied from the popover. basically the source link of the iframe is just the standalone link of the slice and unauthorized users will not be able to access. we think that maintaining the view permission is a better way to do that, so the iframe tag is internal and not public. the screenshots below will do a mini-demo. </desc> <cmt> fixed </cmt> <cmt> basic implementation of the iframe embed popover </cmt> <cmt> remove unecessary comments </cmt> <cmt> remove public embed iframe </cmt> <cmt> remove debug print line and public access </cmt> <cmt> remove uncessary extra line and use better text explain </cmt> <cmt> maintain the style of airbnb/master </cmt>",popover to generate iframe html tag when standalone button is clicked
337,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ...and i absolutely did not make a separate pr earlier to use travis as my build runner. </desc> <cmt> added axe-webdriverjs typings </cmt> <cmt> added axe-webdriverjs typings with axe-core@3.0.3 </cmt>",added types for axe webdriverjs
338,"<desc> this pr adds more large tensors tests for numpy operators all tests have been run locally; they either passed or were skipped until a fix is provided sample passing run: ubuntu@ip-172-31-38-169:~/incubator-mxnet$ pytest tests/nightly/test_np_large_array.py::test_identity /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) ===================================== test session starts ====================================== platform linux -- python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 rootdir: /home/ubuntu/incubator-mxnet, inifile: pytest.ini plugins: remotedata-0.3.2, openfiles-0.4.0, astropy-header-0.1.2, hypothesis-5.8.3, arraydiff-0.3, doctestplus-0.5.0 collected 1 item tests/nightly/test_np_large_array.py .                                                   [100%] ======================================= warnings summary ======================================= tests/nightly/test_np_large_array.py:89 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:89: deprecationwarning: invalid escape sequence \ ''' tests/nightly/test_np_large_array.py:1260 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:1260: deprecationwarning: invalid escape sequence \ ''' -- docs:  ================================ 1 passed, 2 warnings in 7.07s ================================ @access2rohit @josephevans could you review? </desc> <cmt> add more tests </cmt> <cmt> add more tests </cmt>",numpy large tensor tests batch 3
339,"<desc> inspired by #39657 and resolving the issue raised in that pr: the problem currently is that we are uploading all segments in a shard sequentially per shard and only parallelize snapshotting across shards but not within shards. this pr adjusts the logic towards parallel segment uploads: instead of starting all shard uploads in parallel and without any order, run segment uploads shard by shard. only acquire index commit when it's actually required (after determining the current state of a shard in the repository, not before that). @davecturner pointed out that going sequentially in determining the segments to upload shard by shard increases the timespan between index commits. this is true for the case pf having more snapshot threads than shards to be snapshotted. on the other hand if there's more shards to be snapshotted on a node than snapshot threads it's the other way around. currently, in this situation once the snapshot thread pool is fully occupied a shard will have to wait for another shard to completely finish its snapshot before taking the index commit (which could be many minutes!) while now the time span between the index commits is likely never more than a few seconds apart (biggest difference between two index commit times is basically equal to the time it takes all the shard folder listing operations to finish) release index commit asap (with this change we generally way reduce the amount of time we hold on to an index commit in cases of uploading multiple shards with multiple segments) </desc> <cmt> startt </cmt> <cmt> simpler </cmt> <cmt> start </cmt> <cmt> fixed tests </cmt>",more efficient ordering of shard upload execution
340,"<desc> this pr updates the page sizes that is displayed at the end of the build to include the chunks that each page depends on. with granularchunks flag, each page might have additional chunks that gets loaded. </desc> <cmt> fixing page sizes displayed during build </cmt> <cmt> adding comments </cmt>",update page sizes displayed on build
341,"<desc> in pull_requests.md commit message: currently we use messageutil::hash(scoped_route_config.key()) in detecting key conflict and scopekey().hash() in some other places, which cause inconsistency and trigger assertion in some circumstances(the added test case). the new implementation will use scopekey().hash() everywhere for consistency. testing: add integration test. </desc> <cmt> add test case </cmt> <cmt> clean up </cmt>",fix hash inconsistency in srds update
342,"<desc> now admin can change user profile picture, from admin -> users setting. closes #12312 closes #12388 closes #8485 </desc> <cmt> fixes #12312 </cmt> <cmt> add privilage for admin to update as much profile images as they want </cmt>",add permission to change other user profile avatar
343,<desc> #2727 i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added boyer moore voting algo </cmt> <cmt> added dutch national flag algo </cmt>,added the dutch national flag algorithm
344,"<desc> added docs for: curveutils shapeutils font skeletonhelper bonus: also added docs for core / group. meant that to be a separate pull request, oops! </desc> <cmt> added curveutils docs </cmt> <cmt> added docs for shapeutils </cmt> <cmt> added docs for extras / core / font </cmt> <cmt> added documentation for skeletonhelper </cmt>",added missing docs from extras
345,"<desc> what is this about? this pr documents the localization pipeline and all the scripts used. in addition to this, the steps for localizing a new project have been added. the docs can be viewed at  pr checklist applies to #7204 cla signed. if not, go over here and sign the cla </desc> <cmt> added localization doc </cmt> <cmt> update </cmt> <cmt> added details for c++ projects </cmt> <cmt> added table of contents </cmt>",add dev docs for localization
346,<desc> fixes #7761. add getschema test for mysql add getschema test for oracle </desc> <cmt> add: add test case for metadataconnectionadaptertest.getschema() by spi (#7761) </cmt> <cmt> refactor: test for oracle (#7761) </cmt> <cmt> add: test get schema for mysql by spi (#7761) </cmt> <cmt> format: format the code (#7761) </cmt> <iss> add test case for metadataconnectionadapter.getschema with spi </iss>,add test case for metadataconnectionadapter getschema by spi
347,<desc> avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes  this pr is wip. </desc> <cmt> update scrivito typings to 1.20 </cmt> <cmt> add adoptui to configure options </cmt>,update typings for scrivito sdk to scrivito version 1.20
348,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. closes  #35824 </desc> <cmt> solution for add-elements-at-a-specific-index-in-a-linked-list.english.md </cmt> <cmt> solution check-if-an-element-is-present-in-a-binary-search-tree.english.md </cmt> <cmt> solution for remove-elements-from-a-linked-list-by-index.english.md </cmt>",added solutions for 3 challenges in english / data-structures
349,"<desc> this pr addresses these issues: #2732 - testing suite should use the code in src directly with secondary support for merged build. #2750 - triangle3 geometry primitive specification #2752 - optimize geometric primitives via optionaltarget parameter #2754 - build three-math.js using math.json </desc> <cmt> add triangle3, add optionaltargets to box2,box3,plane,sphere,ray where possible to reduce gc load, add triangle3 unit tests. </cmt> <cmt> all unit tests pass now for box2, box3 and triangle3.  fix bug in plane.js caught in triangle3 unit tests.  replace raycaster.pointinface3 with triangle3.containspoint, no loss of fps in examples. </cmt> <cmt> rn setpointsandindices -> setfrompointsandindices and add unit test. </cmt> <cmt> triangle3.barycoodinate -> triangle3.barycoordfrompoint. add unit test for barycoordfrompoint.  fix order of components in returned barycoords. </cmt>",triangle3 geometric primitive + raycaster integration + unit tests + gc optimizations of geometry primitives
350,"<desc> related to #2490, #1923. ping @wosi </desc> <cmt> list: range map </cmt> <cmt> range map: use range intersections </cmt> <cmt> range map: consolidate, docs </cmt> <cmt> range map: more tests </cmt> <cmt> range map: refactor </cmt> <cmt> list: first steps </cmt> <cmt> list: render </cmt> <cmt> list: row cache </cmt> <cmt> list: listimpl </cmt> <cmt> list: improve row cache </cmt> <cmt> list: cleanup </cmt> <cmt> list: change range map splice call </cmt> <cmt> list: fix indexin when position is > length </cmt> <cmt> list: add tests </cmt> <cmt> list: more tests </cmt> <cmt> list: use diff on visible range </cmt> <cmt> list: :lipstick: </cmt> <cmt> list: :lipstick: </cmt>",use the list widget in the suggest widget
351,"<desc> we only need to copy libmkldnn.so from 3rparty/mkldnn. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> only copy libmkldnn.so </cmt> <cmt> update jenkins. </cmt>",copy only one libmkldnn file
352,"<desc> background polyglot.js received a version update a year ago which allowed users to change the interpolation setting (v2.3.0). upon updating the types, i found that some other methods which have been altered, so i decided to also include them in this pr. all terminology used in this pr follows the terminology used within the package. question: should i bump the version of the types to v2.3.1 to better indicate that it is compatible with the latest release? i have never attempted such a big jump in versioning so i think it is worth asking before attempting it. pr info add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). polyglot.options.interpolation: here and here new polyglot().extend new polyglot().unset polyglot.transformphrase if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [node-polyglot] update types to match v2.3.1 </cmt> <cmt> [node-polyglot] update tests to match types </cmt> <cmt> [node-polyglot] run prettier on test file </cmt>",add types for new options and static methods from latest release
353,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: sinon stub api stubs support the full api of spies. unfortunately the following methods only supported spies, and didn't compile with stubs: calledbefore calledafter calledimmediatelybefore calledimmediatelyafter </desc> <cmt> added stubs to calledbefore/after </cmt> <cmt> added sinon.sinonstub to union type in </cmt> <cmt> * calledbefore </cmt> <cmt> * calledafter </cmt> <cmt> * calledimmediatelybefore </cmt> <cmt> * calledimmediatelyafter </cmt> <cmt> added tests </cmt>",added sinon.sinonstub to union type in calledbefore/after
354,"<desc> this pr fixes a stack overflow that occurs when calling gettypefacts on a pattern template literal type (such as foo${string}). the pr also adds normalization of template literal types consisting of only ${string} placeholders. such template literal types are now reduced to just string. fixes #41651. </desc> <cmt> normalize ${string} to just string, fix gettypefacts </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <iss> rangeerror: maximum call stack size exceeded with template literal since 4.1.0-dev.20200923 </iss>",fix gettypefacts for pattern template literal types
355,<desc> performance improvement for prediction is roughly 3-4x on our datasets. training data loading was also improved by avoiding memory copy. performance measurements are still in progress. </desc> <cmt> added api changes required for jni performance optimizations (e.g. predict is 3-4x faster) </cmt> <cmt> removed commented variables </cmt>,added additional apis to better support jni on spark
356,<desc> closes #2141 allows one to import / require cypress npm module and get definitions </desc> <cmt> wip: start ts definition for cypress npm module </cmt> <cmt> describe run and open options </cmt> <iss> need to describe type for cypress module api </iss>,add typescript definitions for the cypress npm module
357,"<desc> closes: #19581 simply put, this pr fixes some typos and improves the english at a few places (see the commit). read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> sql prepared statement for mssql </cmt> <cmt> revert ""sql prepared statement for mssql"" </cmt> <cmt> this reverts commit 071760f7b295d9e9d196acaa18b003e3c9b46f0a. </cmt> <cmt> improved doc language </cmt> <iss> miscellaneous documentation typos </iss>",misc. documentation typos and language improvements
358,"<desc> inspired by #14594. so far it's a proof of concept, but i was able to load grpc on unity mac (os x). </desc> <cmt> add experimental script for building the unitypackage </cmt> <cmt> add isunity property </cmt> <cmt> enable loading grpc_csharp_ext as a unity native plugin </cmt> <cmt> script improvements </cmt>",add experimental support for loading grpc_csharp_ext on unity
359,"<desc> files slice.py, dashboard.py, datasource_access_request.py can have updated linting rules: unused-import can be removed changed unused arguments to private (with _ prefix) to remove unused-argument rule several no-member rules can be removed test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> removed disabled pylint rule unused_import from dashboards.py in models module. added missing break in too long line. formatting. </cmt> <cmt> changed datasource_access_request.py in models module: removed disabled pylint rule unused_import, removed no-member disabled rules which aren't needed. formatting </cmt>",updated lint rules in models module
360,"<desc> fix a place where stored_fields was referred to as field. remove claim about being able to detect script fields, as it's no longer true. specify that object fields will be ignored, instead of causing the request to fail. </desc> <cmt> fix a reference to the 'field' option. </cmt> <cmt> remove claim about detecting script fields. </cmt>",small corrections to stored_fields docs.
361,"<desc> i added new public functions for to set padding in listview. void setpadding(float l, float t, float r, float b); void setleftpadding(float l); void settoppadding(float t); void setrightpadding(float r); void setbottompadding(float b); and its getter. float getleftpadding() const; float gettoppadding() const; float getrightpadding() const; float getbottompadding() const; please see uilistviewtest_padding in uilistviewtest. uilistviewtest_paddingvertical uilistviewtest_paddinghorizontal </desc> <cmt> add options to listview for setting padding </cmt> <cmt> add 'setpadding' method test cases. </cmt>",add padding options to listview
362,"<desc> from #3222: @mjtko could you please provide a patch that is basically moving the write manifest to static compiler ? hi @josevalim et al! here is the new pull request. feel free to cherry-pick the changes you want - i've tested each of them in isolation but i think they're all reasonable enough. hope this patch has little enough cleverness for you! ;-) cheers, mark. </desc> <cmt> assets compilation task refactoring </cmt> <cmt> don't munge the environment, let rake do that for us </cmt> <cmt> only execute the nondigest task if needed </cmt> <cmt> only reinvoke if necessary </cmt> <cmt> added comment about why nondigest assets requires a reinvocation </cmt>",assets rake task refactoring work - the sequel
363,"<desc> there is a breaking change in that the fontweight now only handles the css font-weight component. the fontstyle property handles 'italic', 'oblique', values from font-style. this makes the overall consistency cleaner but some code may need to be updated. this does not affect font-weight/font-style as with setstyle({font:..}). fulfills wish: #1370 also fixes overwrite font/size/weight oddities - which may result in different behavior for code that was relying on such. all of the text examples appear to work and modification using the new features (while respecting the change in previous behavior) work better. </desc> <cmt> text - documentation updates </cmt> <cmt> text - font size/weight can be specified as style </cmt> <cmt> fulfills: </cmt> <cmt> this allows fontsize and fontweight to be specified as part of the </cmt> <cmt> style as supplied to the text constructor (and setstyle method). in </cmt> <cmt> addition the fontstyle and fontvariant properties can also be set - </cmt> <cmt> although these are not exposed later. </cmt> <cmt> this also fixes edge cases that could be caused if text#fontsize was </cmt> <cmt> used without text#fontweight, where the applied style defaults would be </cmt> <cmt> overwritten/reset. </cmt>","text - font components can be specified as part of ""style"""
364,"<desc> all that's left now is to actually bind the textures when drawing, at least until we get a shader analyzer and can accurately determine which textures are actually accessed by the shaders. </desc> <cmt> gpu: added more fields to the tic structure. </cmt> <cmt> gpu: added the tsc structure. it contains information about the sampler. </cmt> <cmt> gpu: load the sampler info (tsc) when retrieving active textures. </cmt>",added sampler information structures (tsc)
365,"<desc> since exceptions are ""passed"" may as well return a blank string instead of nothing pip3 install superset ... collecting superset downloading superset-0.15.3.tar.gz (32.4mb) complete output from command python setup.py egg_info: fatal: not a git repository (or any of the parent directories): .git -==--==--==--==--==--==--==--==--==--==--==--==--==--==--==- version: 0.15.3 traceback (most recent call last): file ""<string>"", line 1, in <module> file ""/tmp/pip-build-56ww6v0_/superset/setup.py"", line 27, in <module> print(""git sha: "" + git_sha) typeerror: can't convert 'nonetype' object to str implicitly </desc> <cmt> avoid  py3 error in setup.py </cmt> <cmt> print(""git sha: "" + git_sha) </cmt> <cmt> typeerror: can't convert 'nonetype' object to str implicitly </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",a py3 error setup.py causes pip install to fail for 15.3
366,"<desc> uses a custom string replacement function to ensure that # characters are correctly url encoded to %23, to avoid firefox/ie11 choking on the svg data urls. closes #20956 </desc> <cmt> add str-replace sass function </cmt> <cmt> replace # with %23 in svg data urls with str-replace </cmt>",fix unescaped # in svg data urls
367,"<desc> this fixes compile errors trying to build bitcoin-tx and bitcoin-wallet without libevent, which were reported by luke dashjr in #18465 the fix avoiding bitcoin-tx dependency on libevent just adds a conditional build rule. this is implemented in the first commit (more details in commit description). the fix avoiding bitcoin-wallet dependency on libevent requires minor code changes, because bitcoin-wallet (unlike bitcoin-tx) links against code that calls urldecode / evhttp_uridecode. this fix is implemented in the second commit (again details in the commit description). </desc> <cmt> drop unintended bitcoin-tx dependency on libevent </cmt> <cmt> don't include util/url.cpp to libbitcoin_util.a when libevent isn't available. </cmt> <cmt> this fixes a compile error trying to build bitcoin-tx without libevent reported </cmt> <cmt> by luke dashjr in </cmt> <cmt> fixes #18465 </cmt> <cmt> drop bitcoin-wallet dependency on libevent </cmt> <cmt> don't require urldecode function in wallet code since urldecode implementation </cmt> <cmt> currently uses libevent. just call urldecode indirectly though url_decode </cmt> <cmt> function pointer constant if available. </cmt> <cmt> in bitcoind and bitcoin-qt, url_decode is implemented and used to interpret rpc </cmt> <cmt> wallet requests. in bitcoin-wallet, url_decode is null to avoid depending on </cmt> <cmt> libevent. </cmt>",drop bitcoin-tx and bitcoin-wallet dependencies on libevent
368,"<desc> after reviewed the codebase where there are a lot of new implementations related to livechat pull requests, i noticed that some methods needed improvements and fixes to work as well as expected. important change: we're renaming the livechat routing methods, as described below: from guest pool to manual selection; from least amount to auto selection; in addition: the room model(client side) has been replaced with livechatroom model in some livechat templates, such as visitorinfo and visitoredit.  this change was necessary because the reactivity was not working for livechat managers because the models based on cachedcollection only emit changes to the users who have the related subscription and the livechat managers have permission to access those templates even they don't have that subscription. this is a pr that needs to be merged before the next release -> 2.0.0. </desc> <cmt> fixed some livechat methods and processes. </cmt> <cmt> fixed missing const statement. </cmt> <cmt> removed unused model. </cmt>",new livechat methods and processes
369,"<desc> all buttons in the player use 'mouseup' instead of 'mousedown' event. this player behavior is very useful for accessibility because the user can cancel the action by clicking outside the button area. however, in the player, there is one place that the player uses a 'mousedown' instead of 'mouseup' event. i think that is just a mistake. you can check it by clicking on the video area during the playback. you will see that the playback pauses/resumes after 'mousedown' event but if you click on the play/pause button over the controlbar it uses 'mouseup' event. the wcag 2.1 ""2.5.2 pointer cancellation"" spec. also suggests using ""mouseup"" instead of ""mousedown"" event. i changed ""mousedown' to 'mouseup"" event inside the player. change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) </desc> <cmt> sync with origin branch </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix: changes 'mousedown' to the 'mouseup' event </cmt>",changes 'mousedown' to the 'mouseup' event in the player
370,<desc> mutate workinprogress instead of returning. we started out returning it but we have since started mutating causing ambivalent behavior of what the methods were supposed to do since they're both mutating and returning. we now always mutate and never return anything from perform and complete. </desc> <cmt> remove unnecessary workinprogress line </cmt> <cmt> mutate workinprogress instead of returning </cmt> <cmt> we were ambivalent about this before. </cmt>,don't return from perform/completeunitofwork
371,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. - although there is a new version, that version did not affect what i'm changing now, so i left the version number as is. not sure if that is desired or not. </desc> <cmt> fix and test facetoptions in solr-client. </cmt> <cmt> run prettier. </cmt>",fix and test facetoptions in solr-client. 'prefix' must be optional.
372,"<desc> dreq setup was missing for slave transfers and for some (yet unknown) reason transfer sizes larger than 32k cause repated clicking on i2s soundcards. these changes bring bcm2835-dma in line with bcm2708-dmaengine, but only limit cyclic lite transfers to 32k - other lite transfers can still use 64k-4. see also discussion in #1153 ping  @notro </desc> <cmt> bcm2835-dma: fix dreq not set for slave transfers </cmt> <cmt> set dreq to slave_id if it is not set like in bcm2708-dmaengine. </cmt> <cmt> bcm2835-dma: limit cyclic transfers on lite channels to 32k </cmt> <cmt> transfers larger than 32k cause repeated clicking with i2s soundcards. </cmt> <cmt> the exact reason is yet unknown, so limit to 32k as bcm2708-dmaengine </cmt> <cmt> did as an intermediate fix. </cmt>",fix i2s issues with bcm2835-dma
373,"<desc> as a first probe towards migrating to rq, i'm interested in trying to swap out celery beat and all non-execute-query tasks and replace them with rq. towards #4092 </desc> <cmt> add rq and an rq_worker service </cmt> <cmt> add rq_scheduler and an rq_scheduler service </cmt> <cmt> move beat schedule to periodic_jobs queue </cmt>",replace celery with rq (except for execute_query tasks)
374,<desc> proposal for fix related to 1rst issue of #345 thread.sleep(wait) => thread.sleep((wait/10)*10) (see </desc> <cmt> proposal for fix related to 1rst issue of #345 </cmt> <cmt> => (gettimetowait /10)*10 </cmt> <cmt> (see </cmt> <cmt> proposal for fix related to 1rst issue of #345 </cmt> <cmt> => in configure (newcheckinterval/10)*10 </cmt> <cmt> (see </cmt>,proposal to fix 1rst issue presented in #345
375,"<desc> changed code for data typecasting from python 3 syntax to python 2 in the python 2 section changed typecasting from surface: str surface = str("""") since python 2 doesnt support typecasting with a : bug fix i have submitted the spacy contributor agreement. </desc> <cmt> fixed syntax error in declaring variables with python 2.7 in spacy/lang/ko/__init__.py </cmt> <cmt> fixed syntax error in declaring variables with python 2.7 in spacy/lang/ko/__init__.py </cmt> <cmt> update __init__.py </cmt> <cmt> create veer-bains.md </cmt> <cmt> update __init__.py </cmt> <cmt> fixed syntax errors in variable datatype assignment when calling spacy.blank(""ko"") with python 2.7 </cmt>",fixed syntax error in lang/ko when using python 2
376,"<desc> cherry picked commits from the pr #29081 which was originally applied to master and merged to 1.13.x branch. had to resolve conflicts in commit bfe5cab. $ git cherry-pick e0852be # add selinux policy for centos-7 $ git cherry-pick 09e68fd # add extra docker.te lines from rhel7.3 docker.spec $ git cherry-pick bfe5cab # get rhel7.3 selinux-policy-devel pkg for centos-7 same way to verify pr #29081. update selinux policy for distros based on rhel7.3. </desc> <cmt> add selinux policy for centos-7 </cmt> <cmt> this policy is from commit </cmt> <cmt>  </cmt> <cmt> add extra docker.te lines from rhel7.3 docker.spec </cmt> <cmt> get rhel7.3 selinux-policy-devel pkg for centos-7 </cmt> <cmt> resolved conflict of bringing in this patch originally committed </cmt> <cmt> to the 1.13.x branch. for this patch applied to the 1.12.x branch, </cmt> <cmt> did not keep the photon case statement in generate.sh and did not </cmt> <cmt> update to golang 1.7 in the centos-7/dockerfile. </cmt>",add selinux policy for centos-7 on 1.12.x branch
377,<desc> also added more warnings to the makefile. note: -wundef errors with the opencl headers. that's been fixed upstream but 'git submodule update' sets up an old version. git submodule update --remote pulls the latest. </desc> <cmt> add extra warnings to makefile </cmt> <cmt> fix a bunch of warnings </cmt>,fix a bunch of warnings.
378,<desc> also a start on the release notes </desc> <cmt> enh: upsample existing data on plotting </cmt> <cmt> enh: unified legend for secondary axis </cmt> <cmt> bug: unify legends for when existing data is resampled </cmt> <cmt> enh: unified color cycle for 2nd yaxis </cmt> <cmt> tst: legends and secondary resampling </cmt> <cmt> enh: use asfreq and reset index instead of resample for plotting </cmt> <cmt> minor cleanup in plotting module </cmt> <cmt> doc: getting started on v0.8.1 rls notes </cmt> <cmt> enh: marking right y-axis columns </cmt>,plotting bug fixes and new features
379,"<desc> fix libwebsockets compilation on freebsd, same as osx (this error is actually fixed upstream, waiting for a new release) use prepend instead of append for mbedtls includes (fixes build on freebsd when system-wide mbedtls and/or openssl is installed) closes #16991 </desc> <cmt> fix lws compilation on freebsd, same as osx </cmt> <cmt> this error is actually fixed upstream, waiting for a new release </cmt> <cmt> use prepend instead of append for mbedtls include </cmt> <cmt> fixes build on freebsd when system-wide mbedtls and/or openssl are installed </cmt> <iss> error compiling without builtin_mbedtls=no </iss>",fix mbedtls and websocket on freebsd
380,<desc> this pull request has the initial work for supporting drag and drop behavior in contributed tree enable drag and drop in custom tree views add drag and drop support option in proposed apis e2e wiring of components i'll implement the reparent logic and refresh the tree view in next pull request screen.recording.2021-04-26.at.1.41.48.pm.mov </desc> <cmt> initial implementation </cmt> <cmt> remove unused variables </cmt> <cmt> start wiring of components </cmt> <cmt> expand tree items ondragover </cmt> <cmt> rename parameters in funtion </cmt> <cmt> e2e wiring </cmt> <cmt> update comment in api description </cmt> <cmt> remove logic from setparent </cmt> <cmt> call setparent if function is not undefined </cmt> <iss> add drag and drop for contributed tree views </iss>,initial implementation of drag and drop api
381,"<desc> pre-submission checklist your pull request targets the staging branch of freecodecamp. branch starts with either fix/, feature/, or translate/ (e.g. fix/signin-issue) you have only one commit (if not, squash them into one commit). all new and existing tests pass the command npm test. use git commit --amend to amend any fixes. type of change small bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds new functionality) breaking change (fix or feature that would change existing functionality) add new translation (feature adding new translations) tested changes locally. addressed currently open issue (replace xxxxx with an issue no in next line) </desc> <cmt> fix(seed): clean up seed directory and add open source for go </cmt> <cmt> fix(seed): add in introductory slide challenges </cmt>",cleanup seed files and landing pages.
382,"<desc> this pr introduces control flow analysis for let and var variables that have no type annotation and either no initial value or an initial value of null or undefined. function f(cond: boolean) { let x; if (cond) { x = ""hello""; x;  // string } else { x = 123; x;  // number } return x;  // string | number } function g(cond: boolean) { let y = null; if (cond) { y = ""hello""; } return y;  // string | null } in the example above, x and y implicitly have declared types of any but control flow analysis can determine their actual types at every reference. therefore, no errors are reported even when the example is compiled with --noimplicitany. control flow analysis is unable to determine the actual types of implicit any variables when they are referenced in nested functions. in such cases, the variables will appear to have type any in the nested functions and errors will be reported for the references if --noimplicitany is enabled. function f(cond: boolean) { let x;  // error: variable 'x' implicitly has type 'any' in some locations where its type cannot be determined. if (cond) { x = ""hello""; } else { x = 123; } return x;  // type string | number function bar() { const y = x;  // error: variable 'x' implicitly has an 'any' type. } } in time it is possible that control flow analysis will be able to more accurately determine types of references to outer variables from nested functions in some cases, but given that nested functions are first class objects that can be arbitrarily passed around and called, it is effectively impossible to analyze all such scenarios. </desc> <cmt> improve handling of ++ and -- in control flow analysis </cmt> <cmt> accept new baselines </cmt> <cmt> use control flow analysis for let/var with no type annotation or initializer </cmt> <cmt> unify anytype and autotype when checking for identical declarations </cmt> <cmt> update tests </cmt> <cmt> accept new baselines </cmt> <cmt> control flow typing for variables with null or undefined initializer </cmt> <cmt> accept new baselines </cmt> <cmt> report error on both declaration and reference when cfa can't determine type </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",control flow analysis for implicit any variables
383,<desc> fixed issue causing hashes with the same salt to fail to crack. </desc> <cmt> merge up with master </cmt> <cmt> fixed issue where multiple hashes with the same salt would fail to crack in module/kernel for 9500. remove unused include in module for 9600. </cmt>,fixed bug in mode 9500
384,"<desc> bring the dashboard version with alerts overlays, but without new navbars - netdata/dashboard#252 fix wrapping of long durations in the active-alarms list (badges) fix chart context field in goto_url component name alerts/dashboard </desc> <cmt> update dashboard version which uses alert-highlight </cmt> <cmt> add more space for active-alarms duration (prevent multiline) </cmt> <cmt> fix alarm_chart in goto_url </cmt>",alerts template updates and new dashboard
385,"<desc> fix a crash following the pattern in tcpupstream. the upstream handle should not be created if the newstream returns nullptr, regardless on failure or on immediate success. without the fix, the below backtrace could be detected by the new test case. caught segmentation fault, suspect faulting address 0x0 backtrace (use tools/stack_decode.py to get line numbers): envoy version: 0/1.15.0-dev/redacted/debug/boringssl #0: envoy::signalaction::sighandler() [0x370a8fc] #1: __restore_rt [0x7fa7a8530890] #2: envoy::tcpproxy::filter::ondownstreamevent() [0x317d45d] #3: envoy::tcpproxy::filter::downstreamcallbacks::onevent() [0x3181d1f] #4: envoy::network::connectionimplbase::raiseconnectionevent() [0x329ab11] #5: envoy::network::connectionimpl::raiseevent() [0x328df25] #6: envoy::network::connectionimpl::closesocket() [0x328dd27] #7: envoy::network::connectionimpl::closeconnectionimmediately() [0x328dafa] #8: envoy::network::connectionimpl::close() [0x328d4dc] #9: envoy::tcpproxy::filter::onupstreamevent() [0x317a0f6] #10: envoy::tcpproxy::filter::upstreamcallbacks::onevent() [0x3179f42] #11: envoy::tcpproxy::httpupstream::resetencoder() [0x318e796] #12: envoy::tcpproxy::httpupstream::donewriting() [0x318e984] #13: envoy::tcpproxy::httpupstream::encodedata() [0x318e948] #14: envoy::tcpproxy::filter::ondata() [0x317cfb5] #15: envoy::network::filtermanagerimpl::oncontinuereading() [0x329c065] #16: envoy::network::filtermanagerimpl::onread() [0x329c2c6] #17: envoy::network::connectionimpl::onread() [0x328e6ed] #18: envoy::network::connectionimpl::onreadready() [0x32926ec] #19: envoy::network::connectionimpl::onfileevent() [0x329109b] #20: envoy::network::connectionimpl::connectionimpl()::$_6::operator()() [0x329562e] #21: std::_function_handler<>::_m_invoke() [0x32954f1] #22: std::function<>::operator()() [0x29bb51a] #23: envoy::event::fileeventimpl::assignevents()::$_0::operator()() [0x3285831] #24: envoy::event::fileeventimpl::assignevents()::$_0::__invoke() [0x32855d6] #25: event_persist_closure [0x42b294e] #26: event_process_active_single_queue [0x42b1f88] #27: event_process_active [0x42ac74a] #28: event_base_loop [0x42ab5fc] #29: envoy::event::libeventscheduler::run() [0x33e9c28] #30: envoy::event::dispatcherimpl::run() [0x327e23a] #31: envoy::server::workerimpl::threadroutine() [0x20ed5fd] #32: envoy::server::workerimpl::start()::$_4::operator()() [0x20eec1c] #33: std::_function_handler<>::_m_invoke() [0x20eeadd] #34: std::function<>::operator()() [0x1e41cfe] #35: envoy::thread::threadimplposix::threadimplposix()::$_0::operator()() [0x429b2a2] #36: envoy::thread::threadimplposix::threadimplposix()::$_0::__invoke() [0x429b275] #37: start_thread [0x7fa7a85256db] risk level: low testing: stress test on tcp proxy. </desc> <cmt> tcpproxy: fix crash on http handle empty </cmt> <cmt> fix crash, alternative </cmt>",fix a crash when h2 tunnel is set
386,"<desc> merged master into docs-rebuild to pick up the latest changes. added the redux logo to the main header added sales pitch headers, descriptions, and icons added a section on redux-starter-kit to ""getting started"" tweaked link styles yet again </desc> <cmt> -dprctd react-router-redux +connected-react-router (#3237) </cmt> <cmt> * -dprctd react-router-redux +connected-react-router </cmt> <cmt> removed... </cmt> <cmt> **[reacttraining/react-router-redux]( </cmt> <cmt> keep your state in sync with your router </cmt> <cmt> according to their page:  """"""""redux users: the react-router-redux package is now deprecated."""""""""" </cmt> <cmt> * simplify description </cmt> <cmt> fix wrong anchor in store documentation (#3238) </cmt> <cmt> the anchor wasn't matching the target element so it wasn't scrolling. </cmt> <cmt> fix link. </cmt> <cmt> closes #3240 </cmt> <cmt> removed unnecessary semicolon (#3264) </cmt> <cmt> fit bindactioncreators docs more clearly (#3266) </cmt> <cmt> fix typo - object arguments to object properties </cmt> <cmt> clear words - single function to action creator for bindactioncreatorss first argument </cmt> <cmt> add docs survey link </cmt> <cmt> # conflicts: </cmt> <cmt> #	docs/faq/performance.md </cmt> <cmt> update package-lock.json </cmt> <cmt> disable broken separate codeblock css link </cmt> <cmt> this is already getting imported directly, and the generated </cmt> <cmt> separate link 404s in prod. </cmt> <cmt> tweak header/footer links styles some more </cmt> <cmt> add missing ""sub-apps"" page link </cmt> <cmt> add starter kit mentions to ""getting started"" </cmt> <cmt> add main logo sales pitch blocks </cmt> <cmt> added redux logo next to the main title </cmt> <cmt> removed ""installation"" line </cmt> <cmt> added selling point headers and paragraphs </cmt> <cmt> added some font awesome icons and a copyright link </cmt> <cmt> switch out a couple icons and bump icon sizes </cmt>",rework new docs site landing page
387,<desc> fixes #63378 fixes #57617 fixes the openapi script to wait for the apiserver on shutdown (like all the other scripts do) fixes the apiserver shutdown to not hang forever if the kubernetes service reconciler cannot persist to etcd readds #58474 to make the default the lease reconciler kube-apiserver: the default --endpoint-reconciler-type is now lease. the master-count endpoint reconciler type is deprecated and will be removed in 1.13. </desc> <cmt> apiserver: change default reconciler to leaseendpoint </cmt> <cmt> fixes #57617 </cmt> <cmt> let the kubernetes service reconciler timeout on shutdown </cmt> <cmt> make openapi spec generation wait for the apiserver on shutdown </cmt>,"re-enable lease reconciler, fix shutdown race"
388,"<desc> rdar://problem/31542269 </desc> <cmt> add a convenient class for defining unions whose discriminator </cmt> <cmt> is stored externally. </cmt> <cmt> fix the emission of r-value pointer conversions to delay the </cmt> <cmt> conversions and extend lifetimes over the call. </cmt> <cmt> apply this logic to string-to-pointer conversions as well as </cmt> <cmt> array-to-pointer conversions. </cmt> <cmt> fix the ast verifier to not blow up on optional pointer conversions, </cmt> <cmt> and make sure we silgen them correctly.  there's still an ast bug </cmt> <cmt> here, but i'll fix that in a follow-up patch. </cmt>",fix the semantics of r-value pointer conversions in calls
389,"<desc> if the win_updates action plugin fails to run the module, become doesn't work and so on. this will pick up the failure and return it back to the user instead of hiding it. backport of #38363 win_updates ansible version 2.5 </desc> <cmt> win_updates: handle if module failed to run (#38363) </cmt> <cmt> (cherry picked from commit ccc56e138a1ed4a0bf5663f572fdec03bf89a2f4) </cmt> <cmt> added changelog fragment </cmt>",backport 2.5 handle failure on module load
390,<desc> first stab at adding a key mapping to settings so i can quickly access it instead of using a mouse :-) </desc> <cmt> adding vsconfig file for vs2019 help to prompt for missing components requried. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> adding a keybinding for launching the settings.  suggested fix for #683 </cmt>,adding keymapping for access to settings
391,<desc> re-submitting the pr from #46614. </desc> <cmt> [xla/gpu] re-enable h-loop-fusion to share operands with users. </cmt> <cmt> will add a check in next commit to avoid invoking elementsin() with a tuple </cmt> <cmt> shape operands/users. </cmt> <cmt> [xla/gpu] fix a bug in canshareoperandbufferwithuser(). </cmt> <cmt> elementsin() supports only array shape; avoid it. we don't need to check the </cmt> <cmt> sharing between operands and users for horizontal fusion for non-array shape </cmt> <cmt> anyway. </cmt>,h fusion sharing opnd with user upstream again
392,"<desc> currently, solvepnpransac is always using epnp as the ransac kernel, while p3p and ap3p should be able to do the same thing with fewer points (4 instead of 5 for epnp). </desc> <cmt> add paper info </cmt> <cmt> allow p3p and ap3p being ransac kernel </cmt>",enable p3p and ap3p in solvepnpransac
393,"<desc> this pr is related to issue #14216 change assert_raises and assert_raises_regex to : with pytest.raises(.....) this is a part of data umbrella's sprint that was held in february 2021. </desc> <cmt> tst replace assert_raises* by pytest.raises in sklearn/linear_model/tests/test_coordinate_descent.py, test_logistic.py, test_passive_aggressive.py, test_perceptron.py, test_ransac.py, test_ridge.py, test_sag.py, test_sgd.py </cmt> <cmt> tst replace assert_raises* by pytest.raises in sklearn/linear_model/tests/test_coordinate_descent.py, test_logistic.py, test_passive_aggressive.py, test_perceptron.py, test_ransac.py, test_ridge.py, test_sag.py, test_sgd.py: fixed the test issues </cmt> <cmt> fixed pytest errors </cmt>",tst replace assert_raise_* by pytest.raises in linear_model module #19399
394,"<desc> this pr refactors much of the multiple runtime code for simplification and commonality. *sbrk is moved entirely to the wasm side. *the multiple code/info structs are removed. *the wasm_cache is nearly entirely removed (it's a hold over from threaded compilation and before we learned of vmem pressue). *wasm_interface global accessor removed for binaryen case; there is still something similar for wavm sadly *runtimes are configurable via options *ctest runs both runtimes *binaryen is now default *33mb memory is back. </desc> <cmt> remove requirement to call check_wasm_opcode_dispositions() explictly </cmt> <cmt> use a static class initilizer to make sure check_wasm_opcode_dispositions() is always called and never removed by accident </cmt> <cmt> double check mutable_global_wast execution </cmt> <cmt> be a little more parnoid on the mutable_global_wast wasm to make sure it really is being run as expected </cmt> <cmt> initial work at allowing wasm runtime to be configurable </cmt> <cmt> (not wired up yet) </cmt> <cmt> configurable wasm runtime for chain_test </cmt> <cmt> make a way to configure the wasm runtime used during chain_test. this small change is probably ""good enough"" since the ci checks will use ctest which has now been instructed to run chain_test twice -- once for each runtime. trying to make chain_test run all its tests twice automatically was tricky and complex </cmt> <cmt> move sbrk to wasm </cmt> <cmt> use the wasm grow_memory opcode instead of implementing a custom sbrk for each runtime </cmt> <cmt> restore 33mib wasm memory limit </cmt> <cmt> refactor multi-wasm-runtime support </cmt> <cmt> refactors much of the multi-wasm-runtime code to remove duplication and global accessors. wavm is currently non functional because of some problems with passing through the non-global apply_context </cmt> <cmt> temporary removal of troublesome unit tests in this branch </cmt> <cmt> some of these unit tests require checktime to work. checktime has been removed from each runtime in favor of a more generic solution </cmt>",refactor multiple wasm runtime code
395,<desc> pointer properties rightbutton and leftbutton are devicebutton objects instead of booleans ( </desc> <cmt> fix pointer leftbutton and rightbutton definitions </cmt> <cmt> pointer properties rightbutton and leftbutton are devicebutton objects instead of booleans ( </cmt> <cmt> update phaser.d.ts </cmt>,fix in typescript definition file: pointer definition
396,<desc> bug fixes others ge reshape grad shape to accelerate the calculation speed but its operators don't support automatic broadcast. this pr broadcast the follow-up tensor shape of the operation. </desc> <cmt> import reduce </cmt> <cmt> fixshape </cmt> <cmt> fixshape </cmt>,fix reshape on ge graph.
397,"<desc> i don't like that the warning tells users to not rely on the default. if we want the user not to rely on the default, we should change it to not have a default instead of 5. i think 5 is a good default and the user can happily rely on it. i have been unhappy about this warning for a while but didn't really have the bandwidth to do something about it. most users will see this warning at some point, i think we should make sure it's friendly and makes sense. </desc> <cmt> be more friendly in the deprecation of cv=3 </cmt> <cmt> add hint on specifying cv </cmt>",be more friendly in the deprecation warning of cv=3
398,"<desc> this pull request resolves a couple of bugs within the machinectl become plugin introduced when it was moved from the hardcoded setup to the modular setup with ansible 2.8. changed a function call to _get_option to get_option to prevent an attributeerror. changed an argument to get_option from ""flags"" to ""become_flags"" to prevent ansible.errors.ansibleerror. become </desc> <cmt> correct get_option function name and change flags to become_flags </cmt> <cmt> remove the '--' from the returned command </cmt>",correct machinectl become plugin function arguments
399,"<desc> adds a timeout for lit tests to help diagnose long running tests. rdar://30453045 </desc> <cmt> [test] time out individual lit tests after 20 minutes. </cmt> <cmt> ...if the python 'psutil' module is installed. </cmt> <cmt> we have no individual tests that take longer than 20 minutes, and </cmt> <cmt> having lit provide the timeout will be a better experience than having </cmt> <cmt> a buildbot kill the whole job. </cmt> <cmt> [test] increasing test timeout to 30 minutes </cmt> <cmt> array tests take longer on the simulator and constantly time out. </cmt> <cmt> the proper solution would be to split the arrays.swift.gyb into </cmt> <cmt> multiple, though. </cmt> <cmt> <rdar://problem/30250367> </cmt> <cmt> increase the test timeout to 50mins </cmt>",add a timeout for lit tests to help diagnose/fail long running tests
400,"<desc> transitions were updated to be color linear, but that's not always what we want. nonlinear and linear both have issues, but people are used to nonlinear, so switch back. maybe we'll switch to cieluv if we stop caring about performance on bad gpus. checked that the transitions still work. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> obs-transitions: nonlinear srgb, fade to color </cmt> <cmt> switch back for now. maybe we want cieluv, but that's expensive. </cmt> <cmt> obs-transitions: nonlinear srgb, fade </cmt> <cmt> switch back for now. maybe we want cieluv, but that's expensive. </cmt> <cmt> obs-transitions: nonlinear srgb, luma wipe </cmt> <cmt> switch back for now. maybe we want cieluv, but that's expensive. </cmt> <cmt> obs-transitions: nonlinear srgb, slide </cmt> <cmt> switch back for now. maybe we want cieluv, but that's expensive. </cmt> <cmt> obs-transitions: nonlinear srgb, swipe </cmt> <cmt> switch back for now. maybe we want cieluv, but that's expensive. </cmt>",switch transition interpolation back to nonlinear srgb
401,"<desc> this patch is intended for issue #521 a new keyword argument dynamic_shape=false is added to these functions in tensorflow.python.image_ops: crop_to_bounding_box pad_to_bounding_box resize_image_with_crop_or_pad _imagedimensions the change is fully backward compatible. the new functionality of resize_image_with_crop_or_pad is tested and worked well. however, the dynamic version of crop_to_bounding_box pad_to_bounding_box is missing many argument checks compared to the static version. keeping both a dynamic and a static version of the same function is quite ugly. maybe we should keep only the dynamic version? todo test cases </desc> <cmt> dynamic shape support improvement </cmt> <cmt> allow resize_image_with_crop_or_pad to work with dynamically shaped image. </cmt> <cmt> fix docs issues </cmt>",dynamically shaped image support for tf.image.resize_image_with_crop_or_pad
402,<desc> this gets green windows master builds publishing to atom/atom releases closes #2444 </desc> <cmt> always pass windows build until flaky specs pass </cmt> <cmt> remove unused variable </cmt> <cmt> zip built app on windows </cmt> <cmt> try 7za </cmt> <cmt> speed up built temporarily by not running specs </cmt> <cmt> use full path </cmt> <cmt> log directory </cmt> <cmt> add a command </cmt> <cmt> renable asset uploading </cmt> <cmt> load atomcredentials on windows </cmt> <cmt> add missing path segment </cmt> <cmt> only log error code </cmt> <cmt> add some logging </cmt> <cmt> remove logging </cmt> <cmt> only publish janky master builds </cmt> <iss> setup ci for windows </iss>,publish builds on windows ci
403,"<desc> i have followed (at least) the pr section of the contributing guide. closes #29362 closes #29446 problem: uncaught typeerror: cannot read properties of null (reading 'clientwidth') at resizeobserver.handleresize code sandbox solution: make the following change at the start of handleresize() in order to prevent cannot read properties of null error. diff --git a/packages/mui-lab/src/masonry/masonry.js b/packages/mui-lab/src/masonry/masonry.js index 73bc1e166d..e127668cd7 100644 --- a/packages/mui-lab/src/masonry/masonry.js +++ b/packages/mui-lab/src/masonry/masonry.js @@ -184,6 +184,9 @@ const masonry = react.forwardref(function masonry(inprops, ref) { react.useeffect(() => { const handleresize = () => { +      if (!masonryref.current || !masonryref.current.firstchild) { +        return; +      } const parentwidth = masonryref.current.clientwidth; const childwidth = masonryref.current.firstchild.clientwidth; const firstchildcomputedstyle = window.getcomputedstyle(masonryref.current.firstchild); code sandbox </desc> <cmt> [masonry] check if child exists to prevent error </cmt> <cmt> [masonry] check if masonry container exists for safety </cmt> <iss> [masonry] initialized with no children results in error </iss> <iss> unmounting 'masonry' component throws type error 'cannot read properties of null (reading 'clientwidth')' </iss>",check if container or child exists to prevent error
404,<desc> fixes #1144 fixes #1145 fixes #1148 fixes #747 possibly fixes #605 several error logs have been minimized or prevented </desc> <cmt> better log management for charts.d.plugin - fixes #1144 </cmt> <cmt> uniform logging from all scripts </cmt> <cmt> unified logging for all plugins </cmt> <iss> disk space utilization for mount is incorrect </iss> <iss> disk space reporting for mounted disks without a block device </iss> <iss> nut.chart.sh </iss> <iss> include runtime dependencies in rpm spec file </iss> <iss> disk space health monitoring false criticals </iss>,unified error logging; disk stats and virtual and remote disks
405,"<desc> as an alternative to #869, this updates git_message_prettify in two ways: this computes the prettified message before checking the length of the output buffer so the length check will be exact instead of roughly right. this means if you have a message with a lot of comments, you won't have to include space for them in the output buffer just to pass the estimated length check. the function now returns the number of bytes that are / would be written to the output buffer. in combination with allowing a null output buffer, this means you can use this like snprintf to get the necessary buffer size and do an allocation to insure sufficient space. you can, of course, still use the function the old way and you will get a -1 output if there is insufficient space in the output buffer. </desc> <cmt> check prettify message output buffer after cleanup </cmt> <cmt> this makes the message prettify buffer length check accurate. </cmt> <cmt> make git_message_prettify return bytes written </cmt> <cmt> if you want to be absolutely safe with git_message_prettify, you </cmt> <cmt> can now pass a null pointer for the buffer and get back the number </cmt> <cmt> of bytes that would be copied into the buffer. </cmt> <cmt> this means that an error is a non-negative return code and a </cmt> <cmt> success will be greater than zero from this function. </cmt>",fix message prettify length check
406,<desc> separated out javabean serialization to json string in a separate section </desc> <cmt> final commit </cmt> <cmt> made changes as per last review </cmt> <cmt> moved from core-java to json module </cmt> <cmt> interrupted thread before logging </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> separated out json serialization to java object </cmt>,bael 1269 intro to json java
407,"<desc> fixes #3 makes the precision 12 digits, from the default 6. </desc> <cmt> increasing ascii serialization precision for floats/doubles </cmt> <cmt> scanf doesn't take precision width </cmt> <iss> serialization fails for double values when format = 'ascii' </iss>","format specifier fix for ascii mode, doubled the precision"
408,"<desc> i've juste install all the things needed to contribute to bootstrap. there wasn't any information in readme.md how to install recess, uglify-js and phantomejs. i thought it would be relevant to provide at least a link. </desc> <cmt> links to recess repo </cmt> <cmt> link to uglify-js repo </cmt> <cmt> link to phantomjs </cmt>","add links to recess, uglify-js & phantomjs in readme"
409,<desc> also added a yarn format command for people who's editors are not cool enough to format for them. microsoft reviewers: open in codeflow </desc> <cmt> add script to format files </cmt> <cmt> updated format for files </cmt> <cmt> more formatting.. </cmt> <cmt> add verify command </cmt> <cmt> verify formatting as part of ci </cmt>,verify format of cpp/h files during ci
410,<desc> part of #12369 depends of merge of #12377 </desc> <cmt> first wave of removal of meteor global </cmt> <cmt> second wave of removal of meteor global </cmt> <cmt> third wave of removal of meteor global </cmt> <cmt> fix tests </cmt> <cmt> remove global variable sha256 </cmt> <cmt> remove global variable webapp </cmt> <cmt> remove global variable ejson </cmt> <cmt> remove global variable email </cmt> <cmt> remove global variable http </cmt> <cmt> remove global variable random </cmt> <cmt> remove global variable reactivedict </cmt> <cmt> remove global variable reactivevar </cmt> <cmt> remove global variable accounts </cmt> <cmt> remove globals variables match and check </cmt> <cmt> remove global variable mongo </cmt> <cmt> remove global variable moment </cmt> <cmt> remove global variable tracker </cmt>,"removal of match, check, moment, tracker and mongo global variables"
411,"<desc> by default, all comments inside script tag and style tag are <!-- and ---> this pull request aims to correct the comment. before <script> <!-- var a = 1; var a = 1; --> </script> <style> a { <!-- font-size: 1;  --> } </style> @foreach (var item in model) { <tr> <td> @html.actionlink(""edit"", ""edit"", new { id = item.id }) | @html.actionlink(""details"", ""details"", new { id = item.id }) | @html.actionlink(""delete"", ""delete"", new { id = item.id }) </td> <td> @item.name </td> <td> @string.format(""{0,g}"", item.joiningdate) </td> </tr> } after <script> // var a = 1; // var a = 1; </script> <style> a { /* font-size: 1;  */ } </style> @foreach (var item in model) { <tr> <td> @html.actionlink(""edit"", ""edit"", new { id = item.id }) | @html.actionlink(""details"", ""details"", new { id = item.id }) | @html.actionlink(""delete"", ""delete"", new { id = item.id }) </td> <td> @item.name </td> <td> @string.format(""{0,g}"", item.joiningdate) </td> </tr> } </desc> <cmt> update cshtml.tmlanguage.json </cmt> <cmt> update package.json </cmt>",correct comment inside script tag and style tag in razor file
412,"<desc> followup on #18128. second part in a series of prs to add dtype-support to the (ufunc-based) ndarray magic methods. most of the newly introduced overloads are based on the respective ufunc's types attribute. note that support for number precision is neglected herein, as this would require knowledge of the arrays and/or array-likes dimensionality (i.e. the identification of 0d + nd operations, which is too difficult). the updated methods in question are: __abs__ __invert__ __pos__ __neg__ __matmul__ __rmatmul__ __mod__ __rmod__ __divmod__ __rdivmod__ __add__ __radd__ __sub__ __rsub__ __mul__ __rmul__ </desc> <cmt> maint: add (covariant) aliases for certain ndarrays </cmt> <cmt> enh: add dtype-support to 15 ufunc-based ndarray magic methods </cmt> <cmt> maint: added a missing overload for ndarray[any],arraylike[object_]->any </cmt> <cmt> the previous pr added support for ndarray[object_],any->any but its inverse was still missing </cmt> <cmt> tst: added new tests for ndarray arithmetic </cmt>",add dtype-support to the ufunc-based ndarray magic methods 2/4
413,<desc> added empty tests for all tables see pr#5107 for context </desc> <cmt> added integration tests target and helper functions to tests table sanity </cmt> <cmt> added uptime sanity check </cmt> <cmt> clang format </cmt> <cmt> # conflicts: </cmt> <cmt> #	osquery/tests/integration/tables/cmakelists.txt </cmt> <cmt> added stubs for all table sanity checks </cmt> <cmt> clang format </cmt>,added stubs for sanity checks
414,"<desc> epe-1551 add test cases for cleos new option --abi-file that was added in pr#10823 to specify one or more local abi files for cleos for serialzation/deserialization offline, which doesn't require nodeos rpc endpoint. select one: select any that apply: </desc> <cmt> remove duplicate function cleos_sign_test() </cmt> <cmt> add test cases for cleos new option --abi-file </cmt>",add tests for cleos new option --abi-file - dev
415,"<desc> types representing object literals or modules have inferable index signatures because their exact set of properties is known. this pr implements the same behavior for types representing enum objects since these also have exact and close ended sets of properties. the enum object type of an enum with at least one numerically valued member has an implicit string index signature of type string | x, where x is a union of the types of all numerically valued members, and an implicit numeric index signature of type string. the enum object type of an enum with only string valued members has an implicit string index signature of type string and no implicit numeric index signature. in the above, x reflects the reverse mapping from strings to numeric enum values included in the generated code that initializes the enum object. fixes #30977 (to the extent we can fix it). </desc> <cmt> implement inferrable index signatures for enum types </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <iss> false positive error report for enum and class instance type missing index signature, thus not assignable to object type with `unknown` values. </iss>",implicit index signatures for enum object types
416,"<desc> remove futures::executor::block_on calls from: cli/resolve_addr.rs - remove dummy future, use sync version fs events ts compiler - replace with dedicated method on sourcefilefetcher to fetch cached filed </desc> <cmt> remove block_on from resolve_addr.rs </cmt> <cmt> remove block_on from ts compiler </cmt>",remove calls to futures::executor::block_on
417,"<desc> besides, did some refactoring of how we fetch and restore comment widgets. </desc> <cmt> pending comment caching in editor comment contribution </cmt> <cmt> focus into the textarea when there is pending comments </cmt> <cmt> reset pending comments when it's being submitted. </cmt> <cmt> delete pending comment cache when comment provider is disposed. </cmt> <cmt> save new comment is hard. </cmt> <cmt> renamge getcomments to recomputecomments </cmt> <cmt> use accessor explictly </cmt> <cmt> comments contribution takes care of comment fetching itself </cmt>",cache pending comments in comment widget
418,"<desc> description: added the prezzibenzina sensor platform. example entry for configuration.yaml (if applicable): sensor: - platform: prezzibenzina station: 1080 fuel_types: ""benzina"" name: ""test"" - platform: prezzibenzina station: 1080 fuel_types: - ""benzina"" - ""gpl"" name: ""test"" checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. documentation pr: home-assistant/home-assistant.io#7843 </desc> <cmt> complete(?) </cmt> <cmt> fixed linting </cmt> <cmt> update requirements </cmt> <cmt> added to coveragerc </cmt>",add prezzibenzina (italian fuel price) sensor
419,"<desc> this pr is to help the release of cran package of lightgbm. it removes visual studio requirement on windows. user may still install lightgbm with visual studio from github using laurae2/lgbdl. mingw should be the default for the following reasons in windows: r expects mingw compilation rtools, mandatory to start compiling packages, uses mingw / gcc rtools is most likely installed than visual studio cran does not use visual studio precompiled dlls for cran are last resort only updates: mingw instead of visual studio by default r readme.md documentation to reflect changes see issue #629. </desc> <cmt> change vs -> mingw for cran </cmt> <cmt> documentation to switch to mingw by default </cmt>",fallback to mingw when vs build fails
420,<desc> fix issue where column name is not quoted correctly #2010 fix issue when handling single quote in comment string fix issue when trying to edit adapter and udf scripts </desc> <cmt> fix comment handling </cmt> <cmt> fix view and edit of script objects </cmt>,fix comment handling and edit/view of scripting objects
421,"<desc> on my machine the build time was reduced from several minutes to a minute. it's partially due to gulp and newer packages, and also due to skipping some redundant steps. </desc> <cmt> switch to gulp from grunt </cmt> <cmt> support for embeds in multi-org </cmt>",switch to gulp from grunt for faster builds
422,"<desc> stores executable file permissions in git, rather than setting them in the makefile. doesn't dirty the git repo when running tests with the makefile. n/a to reproduce the original issue, run some tests. i used: make tests-single-local-docker test_target=mks_robin_stm32 #20433 </desc> <cmt> set executable bit in git, rather than in makefile </cmt> <cmt> add +x permissions for test-related files </cmt>",do not change file permissions when running tests
423,"<desc> i noticed we were missing borrow scopes while testing opaque values. i spent a lot of time trying to refactor the code but ended up creating more complexity. so this is just a simple ""hack"" that michael pointed me toward. it's not too ugly and will be cleaned up once we introduce sil destructure. </desc> <cmt> support printing sil at silgen errors. </cmt> <cmt> guard some silgen code with useloweredaddresses. </cmt> <cmt> update a sil test case. </cmt> <cmt> [sil-opaque-values] fix sil ownership in reabstraction thunks. </cmt> <cmt> emit a borrow scope whenever exploding tuples in to a list of arguments. </cmt> <cmt> i spent a lot of time attempting to refactor the reabstraction thunk generation </cmt> <cmt> code with code that handles rvalue. however, there is a subtle difference in how </cmt> <cmt> tuples are handled when they are packed into a single ""rvalue"" as opposed to a </cmt> <cmt> list of arguments. </cmt> <cmt> eventually, i ditched that effort because of subtle complexity and fell back on </cmt> <cmt> michael's suggestion of handling the extra thunk-sepcific work inside </cmt> <cmt> scope.poppreservingvalues. this will just go away though once we have the </cmt> <cmt> 'destructure' instruction. </cmt> <cmt> update an opaque values reabstraction test case. </cmt> <cmt> enable ownership and filecheck the reabstract-thunk silgen test case. </cmt>",sil ownership and reabstraction thunks.
424,"<desc> closes #10785 the change adds a fallback to use the original id property of imported object when handling relations, this was ignored previously. the main change here was around beforeimport method in the importer base class, so that id property substitution is trackable. </desc> <cmt> fixed import for tag without a slug that belongs to a post </cmt> <cmt> closes #10785 </cmt> <cmt> - the behavior for tags will now be similar to posts' one described in the docs </cmt> <cmt> - ""the only strictly required field when importing posts is the title. ghost will automatically generate slugs and set every other field to the default or empty."" </cmt> <cmt> - the breaking change was introduced with: </cmt> <cmt> - added originalidmap to the importer base class to track id </cmt> <cmt> substitution so it can be used when dealing with relational resource </cmt> <cmt> updates </cmt> <cmt> - removed explicit use of 'this.stripproperties(['id']);' in </cmt> <cmt> beforeimport of base class because we need to assign and remove the id </cmt> <cmt> property in the same place to track this change </cmt> <cmt> - only callingi 'this.stripproperties(['id']);' in </cmt> <cmt> settings/trusted_domain imports as the method wont be called otherwise </cmt> <cmt> - expanded regression tests with new supported import case </cmt> <cmt> added slug generation check to the test </cmt> <iss> importer: multiple relationships not handled if objects don't have slugs </iss>",fixed import for tags without slugs belonging to a post
425,<desc> test case code added for classes of databasecommunicationenginefactorytest and proxyjdbcexecutepreparecallbacktest </desc> <cmt> code style error correction and improved coverage for insertvaluecontext#setvalue </cmt> <cmt> sync into forked dev </cmt> <cmt> test case added for packages of projection.engine  and statement </cmt> <cmt> dev-improvedcoverage-preprocessor </cmt> <cmt> testcase added </cmt> <cmt> test case added for tablemetas and tablemetadata </cmt> <cmt> sync forked </cmt> <cmt> # conflicts: </cmt> <cmt> #	sharding-core/sharding-core-common/src/test/java/org/apache/shardingsphere/core/metadata/table/tablemetastest.java </cmt> <cmt> test case added for proxyjdbcexecutepreparecallback and databasecommunicationenginefactory </cmt>,improved coverage for package of proxy
426,"<desc> these commits edit the keyboard metadata so the given dimensions in the api are correct, according to the layout data. checking was prompted by a report from @i5ar in #4098. for reference: #4098 (comment) #4098 (comment) notes i have a table of the keyboard maintainers whose boards are affected by this that i can post, if necessary. i consider this a minor change, but you never really know. didn't want to spam out a whole bunch of notifications. please squash and merge when acceptable. </desc> <cmt> fix ergodone keyboard dimensions in info.json </cmt> <cmt> fix handwired/prime_exl keyboard dimensions in info.json </cmt> <cmt> fix kbdfans kbd4x keyboard dimensions in info.json </cmt> <cmt> fix handwired/not_so_minidox keyboard dimensions in info.json </cmt> <cmt> fix canoe keyboard dimensions in info.json </cmt> <cmt> fix clueboard cluecard keyboard dimensions in info.json </cmt> <cmt> fix corne (crkbd) keyboard dimensions in info.json </cmt> <cmt> fix gergo keyboard dimensions in info.json </cmt> <cmt> fix handwired/frenchdev keyboard dimensions in info.json </cmt> <cmt> fix handwired/ortho5x13 keyboard dimensions in info.json </cmt> <cmt> fix handwired/promethium keyboard dimensions in info.json </cmt> <cmt> fix speedo keyboard dimensions in info.json </cmt> <cmt> fix xd87 keyboard dimensions in info.json </cmt> <cmt> fix ergodox ez keyboard dimensions in info.json </cmt> <cmt> fix ergodox infinity keyboard dimensions in info.json </cmt> <cmt> fix keeb.io iris keyboard dimensions in info.json </cmt> <cmt> fix orthodox keyboard dimensions in info.json (all revisions) </cmt> <cmt> fix qwertyydox keyboard dimensions in info.json </cmt> <cmt> fix handwired/tradestation keyboard dimensions in info.json </cmt>",fix incorrect keyboard dimensions in configurator api data
427,"<desc> clamav helm chart. clamav is the open source standard for mail gateway scanning software. developed by cisco talos. clamav is developed by a cisco - talos. i am not affiliated with that company, but i will open an issue on their github tracker to make them aware of this pr and see if they have input or interest in co-maintaining. this helm chart uses the mailu docker image, it is the community accepted image for clamav with more than 1m pulls and up to date (updated 13 hrs ago at the time of this pr) mailu this chart is in production for a couple of weeks with no issues. it's a very simple and clean chart with some work to-do like custom configs. dco signed </desc> <cmt> clamav helm chart </cmt> <cmt> readme.md </cmt> <cmt> chart mantainers and owners details </cmt> <cmt> update chart description </cmt> <cmt> update readme with author information </cmt> <cmt> update readme with memory and virus updates details </cmt>",clamav opensource antivirus by cisco - talos.
428,"<desc> this way, the file is easier to understand, and there is a logical separation that is missing in txt files. </desc> <cmt> changed from text to markdown </cmt> <cmt> updated markdown syntax </cmt> <cmt> added header </cmt>",converted the text file to a markdown file
429,"<desc> please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> add prefer sparse, prefer dense </cmt> <cmt> remove prefer dense </cmt> <cmt> fix test </cmt>","elemwise_mul(row_sparse, dense) = row_sparse on cpu"
430,<desc> added a decorate option for the homeassistant component in the configuration file. decorate works similar to the visibility option. example: homeassistant: decorate: entity_id:  also subscribed the isy994 component to the stop event from the ha core to clean up its update threads. </desc> <cmt> added decorate option to configuration file to allow a user to set custom images for different entities. </cmt> <cmt> subscribed isy994 component to event_homeassistant_stop event to clean itself up before quitting. </cmt> <cmt> updated a comment in the entity class. </cmt>,"state decorating, isy component update"
431,"<desc> instead of having average utilization of gpus for each node, this pr adds entries for each gpu's utilization independently. in addition, this pr adds information about to which gpu each worker is assigned. this enables a workflow where, for example, a user sees that one of their gpus is underutilized, then looks to see which worker is attached to that gpu, allowing them to link the underutilization to a specific worker, then to an actor or task. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> first shot at detailed gpu breakout </cmt> <cmt> gram and gpu entries look good, time to test on cluster </cmt> <cmt> lint </cmt>",worker <> gpu mapping information in dashboard
432,"<desc> this now better follows the spec. it's pretty rare to run into modern websites that have unnecessary whitespace in their css, but i came across both of these on a site that was using an old version of mediawiki. </desc> <cmt> libweb: allow whitespace inside css attribute selectors </cmt> <cmt> noticed this while checking some mediawiki-based sites. it's not </cmt> <cmt> obvious, but the spec does allow this, by not mentioning it in this list </cmt> <cmt> of places whitespace is forbidden: </cmt> <cmt>  </cmt> <cmt> libweb: allow whitespace when parsing ""!important"" in css </cmt> <cmt> this accounts for cases like: </cmt> <cmt> css </cmt> <cmt> .foo { </cmt> <cmt> color: blue ! important ; </cmt> <cmt> } </cmt> <cmt>  </cmt> <cmt> that's rare now that minifying is so popular, but does appear on some </cmt> <cmt> websites. </cmt> <cmt> i've added spec comments to consume_a_declaration() while i was at it. </cmt>",allow whitespace in css attribute selectors and !important
433,"<desc> fixes #12519 edit: @mhegazy pointed out that (1) rest of an untyped binding pattern isn't really any since it's definitely not a function (2) adding an index signature results in a more straightforward fix. so the current version adds an index signature to the structurally inferred type of an untyped binding pattern. </desc> <cmt> rest in an untyped binding pattern should be any </cmt> <cmt> test that rest of untyped binding pattern is any </cmt> <iss> object rest destructuring parameter defaults to empty object, causing errors when untyped </iss>",rest of untyped binding pattern is { [s: string]: any }
434,"<desc> when a stream is cancelled or failed, creating corresponding error object is only to be done in op_complete. doing so for op_recv_message and op_recv_initial_metadata creates problem in the upper layers. </desc> <cmt> bug fix </cmt> <cmt> test fix </cmt>",fix cronet_transport.c failure handling bug
435,"<desc> a continuation of issue #7605 something has changed in react fiber which might have something to do with unstable_rendersubtreeintocontainer which popover (and rendertolayer inside of it) uses to render itself inside a container which initiated the click / opening event. it might also have something to do with mounting order, as popover tries to render itself inside of one of its child elements. to ensure that the child layer is created correctly before attempting to render, a timeout is set at 1ms inside popover's componentdidmount before rendering the popover inside the layer. it's a quick fix, but at least it works. from what i can gather in my projects, this should be the last step in making pre-v1 compatible with react fiber. in this pull request as well: changed the tests for [menu] to be in line with the previous pull request #7624 pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: ""[component] fix leaky abstraction"". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( </desc> <cmt> replaced all occurances of ontouchtap with onclick </cmt> <cmt> changed tests to use 'click' event, and seem to all be passing. </cmt> <cmt> [eslint] alphabetically ordered onclick in props for code quality </cmt> <cmt> [popover] added 1ms timeout to render popover to ensure placement is created correctly, after [rendertolayer] has completed it's render </cmt> <cmt> resolved merge conflict </cmt> <cmt> [popover] removed unused development prop on [rendertolayer] </cmt> <cmt> [popover] fixed tests to be inline with the new behaviour (waiting for layout to be setup correctly). also fixed [menu] tests to work with recent ontouchtap -> onclick changes. </cmt>",fixed bug where popover renders relative to screen
436,<desc> add and edit unit tests for check_point ansible modules this commit adds several missing unit tests for the check_point ansible modules. test_cp_mgmt_network.py test_cp_mgmt_address_range.py test_cp_mgmt_address_range_facts.py check_point </desc> <cmt> commit network and address_range </cmt> <cmt> remove test_cp_mgmt_network from ignore.txt </cmt>,network and address range tests
437,<desc> users can be mistaken by some board documentation stating to use 9600bauds. flash upload speed at 9600bauds doesn't work with esptool.py. (ref) (+ minor cosmetics update in host emulation makefile) </desc> <cmt> emulation on host: disable coverage when not in ci </cmt> <cmt> disable 9600bauds for flash upload serial speed (esptool.py won't work) </cmt>,disable 9600bauds in menu for flash upload serial speed
438,"<desc> risk level: low (tools only, but my python is pretty terrible =p) testing: manual testing that new additions fail check_format docs changes: n/a release notes: n/a </desc> <cmt> adding owners check to format script </cmt>",check_format verification that we add owners for new extensions
439,"<desc> this pr includes #6461 fix #6455 fix #6340 close #6385 close #6461 </desc> <cmt> do not alter json in docker save </cmt> <cmt> docker-dco-1.1-signed-off-by: victor vieux <vieux@docker.com> (github: vieux) </cmt> <cmt> improve test </cmt> <cmt> docker-dco-1.1-signed-off-by: victor vieux <vieux@docker.com> (github: vieux) </cmt> <cmt> add a test using the flags </cmt> <cmt> docker-dco-1.1-signed-off-by: victor vieux <vieux@docker.com> (github: vieux) </cmt> <iss> `docker load` clears `dockerversion` </iss> <iss> docker save: does not preserve the ""json"" </iss>",raw json for docker save
440,"<desc> fixes #12670 </desc> <cmt> fix(common): i18nselectpipe selects other case on default </cmt> <cmt> fix(compiler): use the other case by default in icu messages </cmt> <cmt> refactor: cleanup icu message syntax </cmt> <iss> i18n' select && i18nselectpipe support of ""other"" </iss>","make ""other"" case the default"
441,<desc> structured the layout for operators and added a documentation that proposes the layout for operators that will get rendered in the html. </desc> <cmt> updating the design doc of fluid </cmt> <cmt> organizing the operator documentation </cmt>,adding a proposal for operator documentation.
442,"<desc> no masking is done in the original evaluation code, so the resulting perplexity is always something like 1.0. in this pr a simple fix is proposed, using just the same masked scheme as in a training code. </desc> <cmt> evaluation code fixed. </cmt> <cmt> evaluation fixed. </cmt>",fix for mlm evaluation in run_lm_finetuning.py
443,"<desc> just like #13770: git checkout -b merge_jan6 and git merge origin types-2.0, then fix merge conflicts. </desc> <cmt> added export, tests to chart.js </cmt> <cmt> fixes #12525 </cmt> <cmt> adding export as namespace </cmt> <cmt> changed charttype, timeunit, scaletype, corrected timescale.displayformats </cmt> <cmt> export types as namespace </cmt> <cmt> so that it can be accessed via reference -> chart, reference -> chart.chart, import ... from, import ... = require() </cmt> <cmt> [lodash] add type guards to isnull, isundefined, isnil </cmt> <cmt> [lodash] add type guards to isnull, isundefined, isnil </cmt> <cmt> update ldapjs 1.0.1 (#13049) </cmt> <cmt> * update ldapjs type definition to be compatible with ldapjs 1.0.1 </cmt> <cmt> * update header </cmt> <cmt> * add missing property for connected </cmt> <cmt> * fix signatures and missing methods to @types/ldapjs </cmt> <cmt> * fix signature for mandatory parameter </cmt> <cmt> ldap: clean up header (#13802) </cmt> <cmt> add missing walk() method to fs-extra (#13070) </cmt> <cmt> * add walk() to fs-extra </cmt> <cmt> * fix some indentation in fs-extra </cmt> <cmt> fs-extra: make walkeventemitter extend readablestream (#13803) </cmt> <cmt> sync svg attributes to react 15 (#13101) </cmt> <cmt> * sync svg attributes to react 15 </cmt> <cmt> * remove old/new distinction and alphabetize list </cmt> <cmt> add missing methods and properties to kendo ui's gantt module (#13331) </cmt> <cmt> * add missing method to gantt module </cmt> <cmt> * remove duplicate identifier </cmt> <cmt> * replace ""string | number | object"" type to ""any"" </cmt> <cmt> * add ""noimplicitthis"" to tsconfig.json </cmt> <cmt> * revert ""add ""noimplicitthis"" to tsconfig.json"" </cmt> <cmt> this reverts commit 12423790ccb9b722081984fd65c73bd942a78aba. </cmt> <cmt> [types-2.0] add d3-hexbin (#12089) </cmt> <cmt> * add d3-hexbin </cmt> <cmt> add </cmt> <cmt> * fix typo </cmt> <cmt> * delete unnecessary comments </cmt> <cmt> * update after review </cmt> <cmt> use generics to control type-safety. </cmt> <cmt> * update tests </cmt> <cmt> * update fix argument name </cmt>",merge more from types-2.0 to master
444,<desc> this pr adds necessary tests to ensure that the bug #16995 won't happen again. we are testing that the rules in the generated css corresponds with the correct expected css depending on the order of the properties defined on the box component closes #16995 </desc> <cmt> added test case </cmt> <cmt> added sx prop test </cmt> <iss> [system] bordercolor not respected anymore </iss>,make sure system properties are in the same order when generating css
445,"<desc> this pr includes several bug fixes (most of which don't show up until you try to do character filtering) and also adds support for filtering by 'charset' ('character set' in windows, or 'code page' more generally).  with this addition, i've re-enabled the 'advanced view' and have added quite a bit of the functionality.  i have disabled most of the non-working controls. add back the advanced view, and hook up a decent amount of the ui add 'unicode' and 'all' to the resources for localization implement filtering by 'charset' fix a bug that caused the 'help' button to be left enabled fix several minor drawing issues fix a regression i introduced with the previous pr where it was possible for a user to incorrectly select the next row when dragging their mouse to the far right of the map i'd like to continue to improve character map over the coming days.  i've picked this application as a way to learn more about reactos and win32 programming before trying my hand at more complicated topics.  i'd like to finish up the 'advanced view' within the next week or so. for a future pr: add 'search for' functionality add unicode search functionality improve rect invalidation to avoid drawing errors screenshot possible issues i'm not sure if i like the way code pages are baked into the header file.  if i enumerate them all there are way too many, so i thing we do need to have a select few that can be used in character map.  any suggestions? i'm not 100% sure of my usage of multibytetowidechar, and would be curious if someone can double check it.  the docs i have read suggest this could be a security issue, so i would like to make sure i am using it properly. i saw an access violation once in reactos (but never when running in windows).  i haven't been able to reproduce it, and am unsure if it was caused by my code, or by something else.  something to watch out for! </desc> <cmt> [charmap] resize the window slightly when compiled with remove_advanced to avoid deadspace at the bottom of the window </cmt> <cmt> [charmap] skip over the non-printable characters by starting with character ' ' + 1 </cmt> <cmt> [charmap] instead of iterating over every cell, simply compute the cell x and y using the cellsize </cmt> <cmt> modify behaviour of charmap to allow large character render on mouse move, only hiding the larger character on double click. </cmt> <cmt> # conflicts: </cmt> <cmt> #	base/applications/charmap/map.c </cmt> <cmt> [charmap] simplify math for moving window to be on desktop </cmt> <cmt> added fixme to highlight this doesn't work well on multi-monitor setups </cmt> <cmt> changed xpos and ypos to long since negative numbers are valid on multi-monitor setups </cmt> <cmt> [charmap] do not draw invalid glyphs on the map (can happen when switching fonts or filtering existing font) </cmt> <cmt> do not allow mouse-over of invalid glyphs </cmt> <cmt> [charmap] fix bug that caused the help button to remain enabled as it was being modified before it was even created </cmt> <cmt> [charmap] do a better job at finding the correct glyph under the mouse </cmt> <cmt> ensure the active cell is cleared correctly </cmt> <cmt> do not try to copy a character to the output if there is no active cell selected </cmt> <cmt> [charmap] populate the advanced portion of the screen with several built-in code pages (the list is hardcoded so that we don't enumerate everything) </cmt> <cmt> add some new resourced for localization of 'all' and 'unicode'.  the actual code page names are already localized by getcpinfoexw </cmt> <cmt> [charmap] add functionality to filter the character map by a code page (called a character set in this program) </cmt> <cmt> [charmap] invalidate the rect around the previously active cell to ensure it gets redrawn as inactive </cmt>",functionality improvements and bug fixes
446,"<desc> this pull request ports #5096 to wpfterminalcontrol, bringing it in line with the selection mechanics in terminal. it also introduces double- and triple-click selection and makes sure we clear the selection when we resize. please read #5096 for more details. this code is, largely, copy-and-pasted from termcontrol with some updates to use std::chrono and til::point. i love til::point. a lot. lots of manual selection. </desc> <cmt> wpf: clear selection on resize </cmt> <cmt> wpf: port selection changes from termcontrol in #5096 </cmt> <cmt> wpf: port word and line selection from termcontrol </cmt>","port selection changes from termcontrol, add multi-click selection"
447,"<desc> hello, i have created 2 new envars. redash_ldap_use_ssl : this envar determines the use of ssl or not, giving value to use_ssl parameter. default is false redash_ldap_auth_method:  this envar determines the authentication method(simple or anonymous). default is simple </desc> <cmt> add two new envars. redash_ldap_use_ssl which determines if the connection will use ssl and ldap_auth_bind which determines if the binding is simple or anonymous </cmt> <cmt> add use_ssl paremeter </cmt>",ldap authentication. create two envars redash_ldap_use_ssl and redash_ldap_auth_bind
448,"<desc> we faced with the nasty race condition. see #32526 internalengine.failontragic method has thrown assertionerror. if you carefully look at if branches in this method, you will spot that its only possible, if either lucene indexwriter has closed from inside or translog, has closed from inside, but tragedy exception is not set. for now, let us concentrate on the translog class. we found out that there are two methods in translog - namely rollgeneration and trimoperations that are closing translog in case of exception without tragedy exception being set. this pull request fixes these 2 methods. to fix it, i've decided to pull tragedyexception from translogwriter up-to translog class, because in these 2 methods indexwriter could be innocent, but still translog needs to be closed. also to protect us in the future and make sure close method is never called from inside translog special assertion examining stack trace is added. since we're still targeting java 8 for runtime - no stackwalker api is used in the implementation. </desc> <cmt> move tragedy exception from translogwriter to translog </cmt> <cmt> close new readers </cmt> <cmt> call closeontragicevent regardless of cas result </cmt> <cmt> assert that close is not called from inside translog </cmt>",all translog inner closes should happen after tragedy exception is set
449,"<desc> historyjs interface changed pushstate: added queue arg (optional), return type replacestate: added queue arg (optional), return type getstate: added friendly, create args (optional) added method getstateid method getstatebyid method settitle method clearqueue method clearallintervals method getrooturl field emulated histroystate interface added field hashedurl field cleanurl </desc> <cmt> historyjs: </cmt> <cmt> changed: </cmt> <cmt> * pushstate: added queue arg (optional) </cmt> <cmt> * replacestate: added queue arg (optional) </cmt> <cmt> * getstate: added friendly, create args (optional) </cmt> <cmt> added: </cmt> <cmt> * method getstateid </cmt> <cmt> * method getstatebyid </cmt> <cmt> * method settitle </cmt> <cmt> * method clearqueue </cmt> <cmt> * method clearallintervals </cmt> <cmt> * method getrooturl </cmt> <cmt> * field emulated </cmt> <cmt> histroystate: </cmt> <cmt> added: </cmt> <cmt> * field hashedurl </cmt> <cmt> * field cleanurl </cmt> <cmt> history.js: added missed return types </cmt>","added missed methods, arguments and fields"
450,"<desc> changes and additions for the official repo release on wednesday. </desc> <cmt> adding first draft of official repo guidelines </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> revisions based on feedback. </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> format and typo fixes </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> more format fixes. </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> more format wrestling. </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> fix formatting, change to markdown block for long </cmt> <cmt> fix formatting, change to markdown block for long </cmt> <cmt> fixes a couple small typos </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/docker-hub/official_repos.md </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> adding new dockerfile best practices doc, and links thereto. </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt> <cmt> typo and formatting fixes. copy edits. </cmt> <cmt> docker-dco-1.1-signed-off-by: fred lifton <fred.lifton@docker.com> (github: fredlf) </cmt>",docs for official repo release
451,"<desc> reset_smoothing() to immediately set the camera2d's position to the destination point where it is smoothing to. this has only an effect if smoothing is enabled. align() to align the camera's position to the tracked node. (e.g. if anchor mode is set to drag_center, it will center the node). this function does not reset smoothing, so if you want to realign the camera immediately, you have to call align() and reset_smoothing() afterwards. </desc> <cmt> add reset_smoothing() for immediately fixing the camera to the destination location </cmt> <cmt> add align() to realign the camera2d to its tracked node </cmt> <cmt> align() will center the tracked node if anchor mode is set to drag_center, otherwise the camera is set to the node's position </cmt>",add new camera2d alignment functions
452,"<desc> in high traffic scenarios /tmp/oeis files could be overwritten now each instance has it's own unique /tmp/oeis_$random that is deleted on application close bibliographies are cleaner. one link per contributor. </desc> <cmt> added links in bibliography </cmt> <cmt> process sigle letter commands (chmod +x) </cmt> <cmt> added permission string to single letter chmod </cmt> <cmt> added permission number to sigle letter chmod </cmt> <cmt> added comments, fixed blank table on hiphen error </cmt> <cmt> bibliography sources should be names (ignore and consolidate different dates with same name) with links </cmt> <cmt> new tmp dirs for each instance + self cleanup (avoid collision) </cmt>","better bibliography, fixed high traffic collision bug"
453,<cmt> bpo-11594: add test to ensure line-endings are respected </cmt> <cmt> bpo-11594: ensure line-endings are respected when using lib2to3 </cmt> <cmt> bpo-11594: simplify test that ensures line-endings are respected </cmt> <cmt> bpo-11594: ensure test file is writable </cmt> <cmt> bpo-11594: remove unnecessary blank line </cmt>,ensure line-endings are respected when using 2to3
454,"<desc> issue: - discussion: #13737 when running with --smoke-test, currently no manager cache is used, created or cleared. however, sometimes it's beneficial to be able to prepare (generate) a cached manager without actually starting storybook, for example when preparing a docker image with embedded manager cache. this change makes --smoke-test cache the manager it built like normal, but won't use or clear any cache it finds as was intended in #13266. is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no </desc> <cmt> cache built manager but don't use or clear any cache when running smoke test </cmt> <cmt> don't open browser when running smoke test </cmt>","generate manager cache in smoke test, but don't use/clear any cache"
455,<desc> this patch adds our own opencl kernel code for elliptic curve multiplication by a scalar/tweak: opencl/inc_ecc_secp256k1.cl the affected hash types for now are: -m 21700 = electrum wallet (salt-type 4) and -m 21800 = electrum wallet (salt-type 5) with this code we can perform everything on gpu (opencl/cuda) without the need of external libs and/or hook code. this should (and does) improve speed by a lot (but of course be aware that secp256k1 by pieter wuille is already among the most optimized codes for ecc operations on the secp256k1 curve). the main multiplication code point_mul () was highly optimized by using some precomputed buffers (coordinates) by the host code... and it is also not meant to be used in security critical environment that are at risk of timing/side-channel attacks (non-constant time). shout out go also to several online resources and in particular to micro-ecc ( thank you this is also in relation to #1806 where electrum 4/5 were requested as feature requests </desc> <cmt> electrum 4/5: improve speed (rm hook) </cmt> <cmt> electrum 4/5: rm secp256k1 dependency </cmt>,improve speed by removing hook
456,"<desc> the ray dashboard docs already go quite in depth, so this section is quite short, but please let me know if there's something worth adding here. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add small section on dashboard </cmt> <cmt> fix link description </cmt>",add small dashboard section under serve monitoring
457,"<desc> scheme validation has been implemented for listeners and the network filters. in addition, the network filters have been split into h/cc to improve testability. next pr will provide schema validation for  http connection manager filter. </desc> <cmt> test </cmt> <cmt> test </cmt> <cmt> schema </cmt>",json schema support and schema validation
458,<desc> fixes issue: #1915 (partially) replaces the header file <bits/stdc++.h> with direct standard header files for portability and compatibility. </desc> <cmt> removed <bits/stdc++.h> </cmt> <cmt> math.h -> cmath </cmt> <cmt> removed <bits/stdc++.h> </cmt> <cmt> removed <bits/stdc++.h> </cmt> <cmt> removed <bits/stdc++.h> </cmt> <cmt> removed <bits/stdc++.h> </cmt>,removed <bits/stdc++.h> in sorting and search folders
459,<desc> since implicit serialization of many objects without many=true is no longer valid (afair it was depraceted in 2.3.*) paginationserializer  should use this flag to serialize each of it's pages. without this fix page serialization will fall if these conditions are met: pagination serializer has custom object_serializer_class meta opt custom object_serializer_class has any fields list (or any other iterable with len atribute) was passed to paginator. in result it is then impossible to serialize objects that are not models with pagination. </desc> <cmt> add custom pagination test that covers case with custom object serializer class </cmt> <cmt> use explicit many=true for object_serializer instantiation in paginationserializer and add catch dummy 'many' kwarg on defaultobjectserializer </cmt>,use explicit many=true in paginationserializer on object_serializer instantiation
460,"<desc> in this change we cherry pick three approved pr and one partial non-approved pr that is required for others. pr #4980 implemented support for native module std::weak_ptr. pr #4986 fix reactinstance error state to avoid crashes. pr #4953 (not aprroved) reactnotificationservice to allow communication between native modules - we only bring changes for reactdispatcher required by other prs in this batch, not the ireactnotificationservice itself. pr #5007 add uidispatcher property to reactinstancesettings and ireactcontext microsoft reviewers: open in codeflow </desc> <cmt> implemented support for native module std::weak_ptr (#4980) </cmt> <cmt> (cherry picked from commit c23d3de53f16d39df07f2b19591cacc5336e6ac4) </cmt> <cmt> # conflicts: </cmt> <cmt> #	packages/microsoft-reactnative-sampleapps/windows/samplelibrarycpp/samplemodulecpp.h </cmt> <cmt> fix reactinstance error state to avoid crashes (#4986) </cmt> <cmt> * fix reactinstance error state to avoid crashes </cmt> <cmt> * change files </cmt> <cmt> * clean m_redboxcontent after redbox closing </cmt> <cmt> (cherry picked from commit 05779f28e8f734bd1aa7e1814d888be4eb179366) </cmt> <cmt> reactnotificationservice to allow communication between native modules (#4953) </cmt> <cmt> only picking up changes required for reactdispatcher. </cmt> <cmt> (cherry picked from commit baba475929e6d32eadd3302252fe7ea77788c5fa) </cmt> <cmt> add uidispatcher property to reactinstancesettings and ireactcontext (#5007) </cmt> <cmt> * add uidispatcher property to reactinstancesettings and ireactcontext </cmt> <cmt> * change files </cmt> <cmt> * fix reactwindows-desktop.sln compilation </cmt> <cmt> * address pr feedback for the getcurrentuithreadqueue </cmt> <cmt> * remove uidispatcher setting from playground project </cmt> <cmt> (cherry picked from commit 7236d61e5736083eec1992df73183c400c787306) </cmt> <cmt> # conflicts: </cmt> <cmt> #	packages/playground/windows/playground-win32/playground-win32.cpp </cmt> <cmt> #	vnext/desktop/react.windows.desktop.vcxproj.filters </cmt> <cmt> #	vnext/microsoft.reactnative.cxx.unittests/reactcontexttest.cpp </cmt> <cmt> #	vnext/microsoft.reactnative.cxx.unittests/reactmodulebuildermock.h </cmt> <cmt> #	vnext/microsoft.reactnative.cxx/reactcontext.h </cmt> <cmt> #	vnext/microsoft.reactnative.managed.unittests/reactmodulebuildermock.cs </cmt> <cmt> #	vnext/microsoft.reactnative/ireactcontext.cpp </cmt> <cmt> #	vnext/microsoft.reactnative/ireactcontext.h </cmt> <cmt> #	vnext/microsoft.reactnative/ireactcontext.idl </cmt> <cmt> #	vnext/microsoft.reactnative/reactinstancesettings.h </cmt> <cmt> #	vnext/microsoft.reactnative/reactinstancesettings.idl </cmt>",cherry pick api changes for 0.62
461,"<desc> first off i noticed the pygooglechart dependency which was not documented so i added some view code which only uses it if the package is installed, otherwise the views will not fail. i also patched up the readme to include the dependencies which are postgresql, django>=1.2 (for external db logging), and pygooglechart (which i made optional). also when trying to test the example project i saw that the app itself was not added to the path, which i corrected to point to the app in the current checkout. i also saw a 'paging' app and i have no idea where that is coming from. where can i get 'paging' and what does it do? im trying to get this into a good shape enough so that i can clone the repo, cd to example_project, and get the project up and running so i can see the error reporting. the postgres only approach is the hardest thing to overcome in my opinion, but i can see that it is necessary to do some high performance analytics on the errors. </desc> <cmt> removed pygooglechart necessity, but still uses it if installed </cmt> <cmt> added requirements and some rst niceties </cmt> <cmt> added '..' to path so sentry app is easily found </cmt>",small fixes to get example_project working
462,"<desc> description: many tests don't do anything with stats, but they have to create an isolatedstatsstore. this just adds an entry-point to create a simple api without a stats-store. switch tests to use this variant that don't otherwise do anything with stats. risk level: low testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> add 0-arg createapifortest() and use it where the stats are not otherwise used. </cmt> <cmt> add a way to create test apis without specifying stats_store, and use </cmt> <cmt> this in places where the test doesn't do anything else with stats. </cmt>",add createapifortest variant that doesnt require making a stats store.
463,"<desc> as the title says, this automatically inserts a space after selecting a word from the autocomplete dropdown. the only downside i see here is when autocompleting a table name, where the user wants to specify table.column in a query, since it force them to erase the space. we can optionally not add the space after table completions, but i think the inconsistency is bad. </desc> <cmt> insert space after auto complete </cmt> <cmt> fix autocomplete with space </cmt>",insert a space after auto complete
464,"<desc> added single threaded web server option (disabled by default). this web server has the limit of about 1000 concurrent sockets (a limitation of select()). updated the multi-threaded web server (the default) to use poll() instead of select(). this web server can now handle any number of sockets, but it spawns a thread per socket, so ulimit -n has to be set properly for this to scale. the lockless design of the multi-threaded web server allows about 10.000 queries/second per core before seeing any cpu congestion. fixes #459 to prevent logs on the console, when no errors are encountered. errors will still log on the console. installer now installs systemd service (and the uninstaller removes it) when the installer is run as root. installer now restarts netdata using the service command if available. if falls back to the previous behavior if netdata cannot be started the official way. </desc> <cmt> string comparison with hash in web requests </cmt> <cmt> added single threaded web server </cmt> <cmt> fixed dead clients logging; added protection against invalid file descriptors in select() </cmt> <cmt> faster single threaded web server implementation </cmt> <cmt> faster multi-threads web server </cmt> <cmt> multithreaded web server using poll() </cmt> <cmt> code cleanup for web_client </cmt> <iss> netdata starts logging before opening the log files and writes to stderr </iss>","multi-threaded web server using poll(), added single threaded web server (using select())"
465,"<desc> this pr adds a monitoringindextemplateregistry to the monitoring plugin which automatically installs all monitoring templates locally when the plugin is initialized. exporters have been updated to no longer attempt installation of the monitoring templates, and instead will wait for the templates to become available before setting themselves as started. some older functionality related to templates has been removed as well, such as the expectation that version 6 monitoring templates are installed, as well as the setting that controls their installation (xpack.monitoring.exporters.<exporter>.index.template.create_legacy_templates). </desc> <cmt> add a template registry to install monitoring templates. </cmt> <cmt> update monitoring templates to accept the new substitution variable names. </cmt> <cmt> correctly format logstash template name </cmt> <cmt> add some additional utilities to the template registry </cmt> <cmt> this allows it to better replace the monitoringtemplateutils class. </cmt> <cmt> remove the creation of legacy templates from httpexporter </cmt> <cmt> make localexporter wait for templates instead of adding them when missing. </cmt> <cmt> update template name uses away from monitoringtemplateutils. </cmt> <cmt> allow templatehttpresource to wait for template installation. </cmt> <cmt> only install templates if there is a template source given (for now) </cmt> <cmt> wait for local exporter to become ready during cleaner tests. </cmt> <cmt> only target .monitoring indices when asserting index count, since readying the local exporter will create a watcher index that trips up the test. </cmt> <cmt> update httpexporterit with new template logic. </cmt> <cmt> no longer assumes that templates will be installed by the exporter. </cmt> <cmt> update httpexporterresourcetests with new template logic. </cmt> <cmt> no longer assumes that templates will be installed by the exporter. added some additional trace logging lines to aid in debugging these tests. </cmt> <cmt> remove old templates from httpexportertests </cmt> <cmt> remove uses of monitoringtemplateutils in favor of the new template registry. </cmt> <cmt> remove old template methods from monitoringtemplateutils </cmt> <cmt> remove old template installation methods from templatehttpresource </cmt> <cmt> fix test </cmt>",automatically install monitoring templates at plugin initialization
466,"<desc> this pull request is a backport to 6.x of the close index api refactoring. it cherry-picks the following commits from master: 3ca885e [close index api] add transportshardcloseaction for pre-closing verifications (#36249) 8e5dd20 [close index api] refactor metadataindexstateservice (#36354) 7372529 [tests] reduce randomization in closewhilerelocatingshardsit (#36694) 103c4d4 [close index api] mark unavailable shard copy as stale during verification (#36755) 1959388 [close index api] propagate tasks ids between freeze, close and verify(#36630) e149b08 [close index api] add unique uuid to clusterblock (#36775) dc371ef [tests] fix reopenwhileclosingit with correct min num shards the serialization logic changes were adapted during the cherry picks. the following two commits were needed to adapt the change to 6.x: ef6ae69 [close index api] adapt metadataindexstateservicetests after merge 21b7653 [tests] adapt closeindexit tests for 6.x </desc> <cmt> [close index api] add transportshardcloseaction for pre-closing verifications (#36249) </cmt> <cmt> this pull request adds the transportshardcloseaction which is a </cmt> <cmt> transport replication action that acquires all index shard permits for </cmt> <cmt> its execution. this action will be used in the future by the </cmt> <cmt> metadataindexstateservice in a new index closing process, where </cmt> <cmt> we need to execute some sanity checks before closing an index. </cmt> <cmt> the action executes the following verifications on the primary and replicas: </cmt> <cmt> * there is no other on going operation active on the shard </cmt> <cmt> * the data node holding the shard knows that the index is blocked for writes </cmt> <cmt> * the shard's max sequence number is equal to the global checkpoint </cmt> <cmt> when the verifications are done and successful, the shard is flushed. </cmt> <cmt> relates #33888 </cmt> <cmt> [close index api] refactor metadataindexstateservice (#36354) </cmt> <cmt> the commit changes how indices are closed in the metadataindexstateservice. </cmt> <cmt> it now uses a 3 steps process where writes are blocked on indices to be closed, </cmt> <cmt> then some verifications are done on shards using the transportverifyshardbeforecloseaction </cmt> <cmt> added in #36249, and finally indices states are moved to close and their routing </cmt> <cmt> tables removed. </cmt> <cmt> the closing process also takes care of using the pre-7.0 way to close indices if the </cmt> <cmt> cluster contains mixed version of nodes and a node does not support the transportverifyshardbeforecloseaction. it also closes unassigned indices. </cmt> <cmt> related to #33888 </cmt> <cmt> [close index api] adapt metadataindexstateservicetests after merge </cmt> <cmt> [tests] reduce randomization in closewhilerelocatingshardsit (#36694) </cmt> <cmt> [close index api] mark unavailable shard copy as stale during verification (#36755) </cmt> <cmt> this pull request modifies the transportverifyshardbeforecloseaction so that </cmt> <cmt> it marks unavailable shards as stale. </cmt> <cmt> [close index api] propagate tasks ids between freeze, close and verify shard actions (#36630) </cmt> <cmt> this pull request changes the freeze index and close index actions so </cmt> <cmt> that these actions always requires a task. the task's id is then propagated </cmt> <cmt> from the freeze action to the close action, and then to the verify shard action. </cmt> <cmt> this way it is possible to track which freeze task initiates the closing of an index, </cmt> <cmt> and which consecutive verifiy shard are executed for the index closing. </cmt> <cmt> [close index api] add unique uuid to clusterblock (#36775) </cmt> <cmt> this commit adds a unique id to cluster blocks, so that they can be uniquely </cmt> <cmt> identified if needed. this is important for the close index api where multiple </cmt> <cmt> concurrent closing requests can be executed at the same time. by adding a </cmt> <cmt> uuid to the cluster block, we can generate unique ""closing block"" that can </cmt> <cmt> later be verified on shards and then checked again from the cluster state </cmt> <cmt> before closing the index. when the verification on shard is done, the closing </cmt> <cmt> block is replaced by the regular index_closed_block instance. </cmt> <cmt> if something goes wrong, calling the open index api will remove the block. </cmt> <cmt> related to #33888 </cmt> <cmt> [tests] fix reopenwhileclosingit with correct min num shards </cmt> <cmt> the test intercepts transportverifyshardbeforecloseaction shard </cmt> <cmt> requests, so it needs a minimum of 2 primary shards on 2 different </cmt> <cmt> nodes to correctly intercepts requests. </cmt> <cmt> [tests] adapt closeindexit tests for 6.x </cmt>",backport the close index api refactoring to 6.x
467,<desc> partially fixes: #28342 </desc> <cmt> remove jquery references in toast docs </cmt> <cmt> remove jquery references in browsers-devices docs </cmt> <cmt> remove jquery references from tooltip docs </cmt> <cmt> remove util references from our docs </cmt> <iss> remaining to do after the jquery removal </iss>,continuing to remove jquery references to our doc
468,"<desc> adds via support to the noxary x268. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> update usb descriptors </cmt> <cmt> update default keymap for readability </cmt> <cmt> update readme description </cmt> <cmt> update rules.mk build options, enable bootmagic and mousekey </cmt> <cmt> add commented modern led code </cmt> <cmt> add via keymap </cmt> <cmt> update default keymap readme.md layout image </cmt>",add via support to noxary x268
469,"<desc> this relies on electron-archive/brightray@bbb9287. chrome 45 already has excellent support of high dpi on linux, this pr removes our dpi handling code and relies on chromium to setting up high dpi configurations. fixes #1150, fixes #2523. </desc> <cmt> linux: fix pressing alt not showing menubar </cmt> <cmt> linux: enable force showing menubar </cmt> <cmt> this is for debugging purpose. </cmt> <cmt> linux: no longer needs to manually read dpi settings </cmt> <cmt> it is now done in brightray by reading the value from gtk+. </cmt> <iss> linux/hidpi scaling when gnome set to autodetect </iss> <iss> native menus large on high dpi linux </iss>",do not manually read dpi settings on linux
470,"<desc> what do these changes do? in the internal apis for better or worse there are a lot of abstract classes. this can result in code being hard to understand unless you know there is a method being overriden. this pr adds an @abstractmethod and @override decorators for documentation purposes (think of them as similar to adding a comment that a method is abstract or is overriding something. the override(cls) decorator also checks that the target class actually has the method to help catch simple mistakes. also, it moves around methods around to more consistently order by {overrides, abstract methods, private methods} for readability </desc> <cmt> wip </cmt> <cmt> file </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> misc </cmt>",better document which methods are abstract and which ones are overrides
471,"<desc> fixes #19014 it turned out to be a minor indexing issue with _slice_assign and _slice_assign_scalar. i also added tests test result: ubuntu@ip-172-31-38-169:~/incubator-mxnet$ pytest tests/nightly/test_np_large_array.py::test_slice_assign /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) ============================================ test session starts ============================================= platform linux -- python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 rootdir: /home/ubuntu/incubator-mxnet, inifile: pytest.ini plugins: remotedata-0.3.2, openfiles-0.4.0, astropy-header-0.1.2, hypothesis-5.8.3, arraydiff-0.3, doctestplus-0.5.0 collected 1 item tests/nightly/test_np_large_array.py     .                                                                 [100%] ============================================== warnings summary ============================================== tests/nightly/test_np_large_array.py:89 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:89: deprecationwarning: invalid escape sequence \ ''' tests/nightly/test_np_large_array.py:580 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:580: deprecationwarning: invalid escape sequence \ ''' -- docs:  ======================================= 1 passed, 2 warnings in 43.86s ===================================== </desc> <cmt> fix </cmt> <cmt> fix assign_slice </cmt> <cmt> add tests </cmt> <iss> cannot modify elements in large tensors where index > int_max </iss>",_slice_assign and _slice_assign_scalar large tensor fix
472,"<desc> built on #45 generalized arrays and slices, print/eval supports arrays and slices of all types. </desc> <cmt> support for uint and boolean types </cmt> <cmt> adding support for reading function pointers and mapping them to function names </cmt> <cmt> genericized array reading </cmt> <cmt> genericized slice reading </cmt>",better handling of arrays and slices
473,"<desc> for #5696. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> move client.identity package to auth.ram.identity. </cmt> <cmt> move signutil to ram.utils. </cmt> <cmt> add shutdown for auth plugin. </cmt> <cmt> move spasadapter to new package. </cmt>",move and repackage some ram class to ram package.
474,<desc> enable the psram. add odroidgo build variant to platformio override the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc4 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> odroid has 4mb psram </cmt> <cmt> add missing odroid go </cmt>,odroid go has 4mb psram
475,"<desc> there are two commits in this pr -- the first guards only against a special case of add_child inside _enter_tree, while the second one guards against all cases. because of this, this pr is going to break some projects (and maybe animationplayer/tween/joint2d as well, who knows..). but, the first commit fixes a buggy behavior, so it can (and maybe should) be backported to 2.x. </desc> <cmt> guard agains duplicate calling of _ready when instanced in _enter_tree </cmt> <cmt> fixes #6005 </cmt> <cmt> do not emit notification_ready more than once (breaking change) </cmt> <cmt> currently, there is no notification with the old behaviour, so probably breaks all cpp code relying on that notification as well. </cmt>",do not enter _ready twice
476,<desc> i recently added the sentraq number pad kit keyboard and placed it in a vendor subdirectory to help clean up the keyboards directory. i have now moved the existing sentraq boards into the new vendor subdirectory and made necessary changes to get them to build and updated their build instructions in readme.mds. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> moving sentraq keyboards to sentraq subdirectory. </cmt> <cmt> updating readme markdown to correct make commands. </cmt> <cmt> updating s60_x references to point to the new vendor subdirectory. </cmt>,move the other sentraq keyboards into the sentraq vendor directory
477,"<desc> i hereby agree to the terms of the cla available at:  fix error cannot capture column for higher-order functions with tuple(lowcardinality) argument. fixes #9766 </desc> <cmt> try fix labda tuple(lc) argument. </cmt> <cmt> try fix labda tuple(lc) argument. </cmt> <cmt> added test. </cmt> <iss> problem with array(tuple(lowcardinality(string), int32)) </iss>",fix arraymap with tuple(lowcardinality) argument
478,"<desc> in preparation for #7691. </desc> <cmt> test-routing-policy-rule: split out fd assignment from assert_se </cmt> <cmt> it's ugly that parentheses need to be used. let's just split it out. </cmt> <cmt> incidentally, this will make coverity happy, because it doesn't grok </cmt> <cmt> assert_se(). </cmt> <cmt> coverity: don't use (void)0 under coverity </cmt> <cmt> i'm not sure why this is needed, but apparrently coverity doesn't like </cmt> <cmt> (void)0. with this change, coverity can (almost) build systemd: </cmt> <cmt> cflags='-d_float128=""long double""' meson cov-build -dman=false && \ </cmt> <cmt> ccache_disable=1 coverity_unsupported=1 cov-build --dir cov-int ninja -c cov-build </cmt> <cmt> patch originially by marek cermak <macermak@redhat.com>. </cmt>",two small workarounds to help coverity
479,"<desc> i hereby agree to the terms of the cla available at:  changelog category: the second iteration of fixing broken links in documentation. ru zh fa fr ja </desc> <cmt> enbaskakova-docsup-652 (#101) </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> * update docs/en/sql_reference/aggregate_functions/combinators.md </cmt> <cmt> * update docs/en/sql_reference/aggregate_functions/combinators.md </cmt> <cmt> * update docs/en/sql_reference/aggregate_functions/combinators.md </cmt> <cmt> * update docs/en/sql_reference/aggregate_functions/combinators.md </cmt> <cmt> * update docs/en/sql_reference/aggregate_functions/combinators.md </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> * ""docs(ornull&ordefault): functions 'ornull&ordefault' have been edited"" </cmt> <cmt> revert ""enbaskakova-docsup-652 (#101)"" (#107) </cmt> <cmt> this reverts commit 639fee7610f28e421d14e535b7def3f466e7efca. </cmt> <cmt> clickhousedocs-624: fixed en </cmt>",fixing links to nowhere 2
480,"<desc> fixes #2113 more simplifications that those in commit 29f55d5 are possible now, but one of them depends on #2109, so i'll do them later (#2487). they also won't break the api so they aren't required to happen for beta. </desc> <cmt> separate grxforwardingwriter, delete the protocol </cmt> <cmt> id<grxwriter> -> grxwriter * in the runtime </cmt> <cmt> id<grxwriter> -> grxwriter * in the tests </cmt> <cmt> codegen grxwriter* instead of id<grxwriter> </cmt> <cmt> subclass grxwriter instead of conforming to protocol </cmt> <cmt> remove grxwriter wrappers that are now unnecessary </cmt> <cmt> with grxwriter a subclass of all writers, we can map the requestswriter directly </cmt> <cmt> without a dumb wrapper, and return grximmediatewriter objects where grxwriter is </cmt> <cmt> expected. </cmt>",subclass grxwriter instead of conforming to its protocol
481,<desc> this pr adds multi cell selection in the ui through mouse and remove unused api. </desc> <cmt> multi selection in notebook </cmt> <cmt> cut keyboard shortcut support mutli selection </cmt> <cmt> fix build </cmt> <cmt> minimal changes </cmt> <cmt> we should only use comm object to communicate. </cmt> <cmt> transient metadata should be used to control the content change and dirty state. </cmt> <cmt> fix tests. </cmt>,multi selection for notebook cells
482,"<desc> bug fixes others function get_api_md5 may use the alias name as the map's key. it causes some in-sub-module's alias name detected as the changed api.  so update the get_api_md5's logic, use the api' real name as the key. bug found in #31946 </desc> <cmt> get_api_md5 should prefer use the real name rather than the alias names </cmt> <cmt> case for argspec style. update the unittests </cmt> <cmt> test=document_fix </cmt>","update get_api_md5, using the real api name as the map's key"
483,<desc> this should be merged after #8221 i manually tested and perf is comparable with the previous mode. closes #7821 </desc> <cmt> try enabling exec api </cmt> <cmt> fix </cmt> <cmt> disable for sync batch mode </cmt> <cmt> enable fake batch testing </cmt> <cmt> wip </cmt> <cmt> fix fake sapmler </cmt> <cmt> support agg </cmt> <cmt> refactor </cmt> <cmt> updatec </cmt> <cmt> comments </cmt> <cmt> update </cmt> <cmt> split into files </cmt> <cmt> broadcast </cmt> <iss> is it possible to use the policy server/client structure with apex-dqn in [rllib]? </iss>,distributed exec workflow for impala
484,<desc> this pr adds two necessary verifications on received parameters: it checks the validity of the parameter's data type: if the declared data type is resolved to an es or java type; it checks if the returned converter is non-null (i.e. a conversion is possible) and generates an appropriate exception otherwise. </desc> <cmt> add more checks around parameter conversions </cmt> <cmt> this commit adds two necessary verifications on received parameters: </cmt> <cmt> - it checks the validity of the parameter's data type: if the declared </cmt> <cmt> data type is resolved to an es or java type; </cmt> <cmt> - it checks if the returned converter is non-null (i.e. a conversion is </cmt> <cmt> possible) and generates an appropriate exception otherwise. </cmt>,supplement input checks on received request parameters
485,<desc> keeps the function tables up to date. </desc> <cmt> service/erpt: update function table </cmt> <cmt> updates the function table according to information provided by </cmt> <cmt> switchbrew. </cmt> <cmt> service/usb: update function table </cmt> <cmt> updates the function table for iclientepsession based off information </cmt> <cmt> provided by switchbrew. </cmt>,update function tables for erpt:c and usb's iclientepsession
486,<desc> my code follows the code style of this project. i have read the contributing document. </desc> <cmt> added rgblight controls to planck keymap </cmt> <cmt> fixed knight ridder offset to face me </cmt> <cmt> no oled for crkbd 'till fixed </cmt> <cmt> fixed rgb effect name </cmt>,"keymap, fixed rgb effect name and deactivate oled"
487,"<desc> fixes #3464 </desc> <cmt> added test case for invalid generic type constraints </cmt> <cmt> fix crash with unmet generic type constraints </cmt> <cmt> it looks like 93dbcf006f3855c20f02e587970add1744cf32d1 didn't completely change </cmt> <cmt> ""(<callexpression>node).typearguments"" to ""typearguments"". </cmt> <cmt> closes #3464 </cmt>",fix crash with unmet generic constraints
488,"<desc> this is part of ongoing effort to reduce the amount of extra build metadata that's provided from outside of bazel build file. (ideally all the metadata would be extracted from the bazel build - but now we provide quite a bit of extra info through the _build_extra_metadata dictionary). deps_linkage was added here #23335 but since then, the number of targets in makefile was reduced quite a bit and all the targets there are now actually using deps_linkage=static and the flag is no longer useful. </desc> <cmt> regenerate to fix sanity </cmt> <cmt> makefile template always assumes deps_linkage=static </cmt> <cmt> stop setting no-longer-used deps_linkage field in build_autogenerated.yaml </cmt>","simplify build.yaml's  ""deps_linkage"" logic"
489,"<desc> backport of pr #9729 to 2.0 select one </desc> <cmt> update default code_as_wasm to true to match documentation </cmt> <cmt> update description for abi_json_to_bin, abi_bin_to_json, get_code, and get_abi </cmt> <cmt> fix wrong schemata reference in chain swagger file :doc </cmt> <cmt> separate documentation from code changes </cmt>",update some chain_api_plugin descriptions - 2.0
490,"<desc> this pr fixes two bugs in the controller dialog, one is a bug that was introduced by #10910, and one is a preexisting bug that was uncovered by #10910. also included are logging and code style improvements. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) broken out from #10630 </desc> <cmt> [controller dialog] fix not refreshing config if multiple controllers are attached </cmt> <cmt> [controller dialog] fix unable to cancel capture with a or b for non-default profiles </cmt> <cmt> [controller dialog] add debug logging </cmt> <cmt> [controller dialog] improve code style by removing early returns </cmt>",controller dialog fixes and code improvements
491,"<desc> description: this pr adds the device_info to the base class of homematic ip devices. as expected all homematicip-hw-devices are created as ha-devices, and their functionality (switch, sensor) is grouped under one ha-device. currently devices based on binary_sensors that are based on homematic security groups (rooms/zones, that aggregate the state of smoke detectors, water detectors, shutter contacts, ...) are not created. why ? i am not 100% sure but it feels wrong. ;-) unclear to me are the following points: - for what kind of non-physical device should devices be created? - should the excluded binary_sensors also be created as devices in ha? ~~ ~~  -> that means: create all devices and let the user decide which to use. this is the result of the feedback in the comments. no ha-devices are created for groups. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> add device_info to device </cmt> <cmt> added checks </cmt>",add device_info to enable ha-devices for homematic ip
492,"<desc> when exception is thrown because of port already in use in net_plugin::plugin_startup, the plugin_shutdown was not called which can lead to issues with destruction of the net_plugin_impl. ensure plugin_shutdown is called even when plugin_startup doesn't complete in net_plugin and producer_plugin. changed the fc_elog to elog of port in use so it will always be logged regardless of net_plugin_impl logging settings. resolves #7909 </desc> <cmt> fix problem with keepalive timer sometimes causing a crash on exit because plugin_shutdown not called. moved the creation of keepalive timer to after acceptor bind which can easily fail if port already in use. changed fc_elog to elog for port already in use so that it is always logged regardless of net_plugin_impl logger setting. also move the setup of logger to start of plugin_startup since logging is used within the method. </cmt> <cmt> make sure plugin_shutdown is called in case of exception in plugin_startup to ensure proper shutdown on exception </cmt>",fix intermittent crash on exit when port already in use - develop
493,<desc> i think we don't need two practically identical shell scripts ./vsts-ci/setup.sh and .travis/setup.sh. i've merged them into one scripts with the help of some env. variables and if statements and moved to .ci folder. the next pr will contain merging of test.sh scripts. </desc> <cmt> reorganized ci files </cmt> <cmt> merged scripts into one </cmt>,merged ci setup scripts into one
494,<desc> updated links for side-by-side and web root references fixes #10559 </desc> <cmt> just updated sxs link per issue 10559 </cmt> <cmt> updates for side by side and web root references </cmt> <iss> introduction to asp.net core clean up </iss>,updates for side-by-side and web root references
495,"<desc> this should solve #2065. it also postpones pty creation until we know that we actually need it (for sudo). </desc> <cmt> only allocate a pty when sudo is used </cmt> <cmt> postpone the paramiko.channel.get_pty until we know sudo is used. if </cmt> <cmt> sudo is not used, then we do not need a pty. in fact, the paramiko docs </cmt> <cmt> explicitly state that it's not desirable to allocate a pty for a simple </cmt> <cmt> exec_command. </cmt> <cmt> initialise pty from calling environment </cmt> <cmt> if we need to acquire a pty for sudo's use, then it should really </cmt> <cmt> inherit the capabilities of the calling environment. this is what </cmt> <cmt> openssh does, and so it makes sense to copy this behaviour for the </cmt> <cmt> paramiko connection type. </cmt> <cmt> closes: #2065 </cmt>",initialise paramiko pty from caller environment
496,"<desc> fix an old todo to optimize the start argument for deque.index().   in the search for the starting block/index pair, make bounding jumps one block at a time rather than a single index at a time. </desc> <cmt> initially, bound one block at a time </cmt> <cmt> fix indentation </cmt>",minor performance tweak for deque.index() with a start argument
497,<desc> replace sortlistitem and createlistitem for listitem using fuselage's option components. </desc> <cmt> replace userdropdown divider using option.divider </cmt> <cmt> remove unused divider import on userdropdown </cmt> <cmt> implement fuselage component dropdown on useravatarbutton </cmt> <cmt> fix review </cmt> <cmt> adjust userdropdown width for mobile </cmt> <cmt> dropdown component on sortlist </cmt> <cmt> dropdown component on sortlist </cmt> <cmt> dropdown component on createroomlist </cmt> <cmt> fix lint error </cmt> <cmt> apply optiontitle on createroomlist dropdown </cmt> <cmt> apply optiontitle on sortlist dropdown </cmt> <cmt> apply option components on createroomlistitem dropdown </cmt> <cmt> apply option components on sortlistitem </cmt> <cmt> replace createlistitem and sortlistitem with component listitem </cmt> <cmt> fix indentation </cmt>,replace sortlistitem and createlistitem with listitem
498,<desc> fixes #97701 </desc> <cmt> allow to run css language server headless </cmt> <cmt> [css] remove path completion (now provided by service) </cmt> <cmt> [css] update service </cmt> <cmt> run webpack in code-dev </cmt> <cmt> adopt ls service/client that has common & node </cmt> <cmt> add client/server browser parts </cmt> <cmt> unused import </cmt> <cmt> web: nls for package.json </cmt> <cmt> adopt new languageserver node modules </cmt> <cmt> [css] path completion in web </cmt> <cmt> add textencoder to runtime </cmt> <iss> investigate running the 'css language features extension' in yarn web </iss>,css language server for web
499,"<desc> fixed issues #517 and #950 . http proxy endpoints can now be specified like this in s-function.json: ""endpoints"": [ ... ""type"": ""http"", ""uri"": "" ""targetmethod"": ""get"", ... ] the creation of http will bail out if uri or targetmethod are missing. all other endpoint properties continue to work as expected. </desc> <cmt> issue #950 - added support for proxy integrations </cmt> <cmt> fixed bug introduced with mock integration. </cmt>",950 added apig proxy support
500,<desc> after the client detects a leader change we need to check the offset of the current leader for truncation. todo expand on this. </desc> <cmt> kafka-7747 [wip]; check for truncation after leader changes </cmt> <cmt> wip </cmt> <cmt> after-merge cleanup </cmt>,kafka-7747 check for truncation after leader changes
501,<desc> abandoned #162 code revived and added. added file name matches file name guidelines pr title follows semantic commit guidelines </desc> <cmt> rename existing code as sol3 </cmt> <cmt> added naive implementation for problem 5 </cmt> <cmt> added a solution for euler problem 5 with easy improvements </cmt> <cmt> rename new files </cmt> <cmt> code formatting </cmt> <cmt> update documentations </cmt> <cmt> fix docs </cmt> <cmt> updating directory.md </cmt>,project euler problem 5 - #162
502,"<desc> added feature to allow tabbar's labelpadding to be configurable from tabbartheme. goldens for new tests are found here. rewrote the tests to use coordinates for tabbartheme's labelpadding property. there is no longer a need for the golden files. related issues fixes #28775 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. my pr includes tests for all changed/updated/fixed behaviors (see test coverage). i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). no, this is not a breaking change. </desc> <cmt> update tabbartheme to set labelpadding parameter </cmt> <cmt> remove constants.dart import in tab_bar_theme.dart </cmt> <cmt> added tests for tab bar theme label padding implementation </cmt> <iss> make tabbar's tab label padding theme able </iss>",implement labelpadding configuration in tabbartheme
503,<desc> also fixed a couple of linter errors. ps: please excuse gif quality. if anybody has a good way of recording gifs from the browser i'd love to know! </desc> <cmt> added morph target animation support </cmt> <cmt> added support for animated morph targets </cmt> <cmt> select correct morph target from morh dictionary for each track </cmt> <cmt> simplify morph target parsing </cmt>,fbxloader added support for animated morph targets
504,"<desc> several commits that simplify serialization in mostly trivial ways, mainly by removing serialization's ad-hoc copy of an existing helper function. no intended functionality change. </desc> <cmt> [serialization] remove superfluous helper function </cmt> <cmt> no functionality change (based on where it was used) </cmt> <cmt> [serialization] use existing logic to print a hierarchical module name </cmt> <cmt> no intended functionality change. </cmt> <cmt> [serialization] remove a hack around serializing 'final' </cmt> <cmt> we used to track final-ness separately from finalattr, but </cmt> <cmt> serialization didn't know how to handle that, so we synthesized a fake </cmt> <cmt> finalattr. however, final-ness (finality, i guess) is always kept in </cmt> <cmt> sync with finalattr now, so this check is no longer necessary. </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] minor cleanups, no functionality change </cmt> <cmt> - use optional::getvalueor instead of a handrolled version. </cmt> <cmt> - use swift::reversed for reverse iteration instead of reversing a </cmt> <cmt> buffer mutably. </cmt> <cmt> - use stringref::withnullasempty instead of checking both kinds of </cmt> <cmt> empty string </cmt>",remove several unnecessary bits of helper logic
505,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> add ros with intro </cmt> <cmt> update ros guide </cmt>",add robot operating system (ros) to guide
506,"<desc> following the discovery in #4039 i searched the code for further locations of where we use this pattern and removed them all. i also restored the lint rule to prevent future cases. we should probably use <button type=""link"" ...> in the future instead of <a> tags in such cases, but didn't want to work around the styling issues so kept things as is. </desc> <cmt> fix: remove inline script to avoid csp violation </cmt> <cmt> closes #4039. </cmt> <cmt> restore eslint rule that prevents javascript href attributes. </cmt> <cmt> remove all inline script links. </cmt>",prevent csp violations by not having script urls
507,"<desc> new article for the third and grove website launch also updates the drupal preview article for accuracy </desc> <cmt> added post for launch article, updated drupal preview post for accuracy </cmt> <cmt> reverted folder name change </cmt> <cmt> rm random letters from md conversion </cmt>",building the new third and grove website in gatsby
508,"<desc> new features apis this pr restores #26676. previous pr was reverted because it caused some unit test failure, but the ci system hasn't reported it. now tests listed below should work fine: test_analyzer_capi_gpu test_activation_op </desc> <cmt> add mkldnn bfloat16 option to c-api </cmt> <cmt> add test for bfloat16 gpu </cmt> <cmt> change coverage test </cmt> <cmt> repair capi_gpu test </cmt>","restore ""add mkldnn bfloat16 option to c-api """
509,"<desc> ported all manager changes from 2.4 fixed manager build (visibility issues) added 3.0.0 to supported library list (and 2.4.10 - 2.4.11) android examples try to load opencv 3.0.0 note: mechanism for loading both library versions (2.4 and 3.0) is not implemented yet note: built with ndk r8e, gcc-4.4.3 toolchains </desc> <cmt> ported from 2.4 </cmt> <cmt> opencv manager: support 3.0.0 library </cmt> <cmt> reverted unneeded change </cmt>",android build for master branch
510,"<desc> update of pvr client addons did only work if the shared library name and or path to the shared library did not change during update, which is usually not the case as most (if not all?) shared libraries for pvr client addons have the version number in it's name. this pr contains two commits. first commit is specific for macos/ios, second commit is platform independent. first commit fixes a crash that occured on macos while updating a pvr client addon. due to the bug fixed by this pr, addon manager tried to load the old, already deleted shared library. this failed and led to a crash in caddondll::loaddll() ( second commit fixes the actual addon update bug. fix is in pvr code, addon manager is not affected. fix has been runtime tested on latest master on macos and latest krypton on linux. @jalle19 for review? </desc> <cmt> [application][macos] add support for 'special://xbmcaltbinaddons/'. fixes crash in caddondll::loaddll() when updating a binary addon if shared library name changed between versions (e.g. version name contained in shared lib name). </cmt> <cmt> [pvr] fix pvr client addon update. </cmt>",fix update of pvr client addons
511,"<desc> this provides a rax module to create or delete instances in rackspace's public cloud. it also provides a rax inventory plugin to discover hosts within the cloud as well. both make use of pyrax, the official python sdk for working with the rackspace public cloud. </desc> <cmt> initial commit of rax library </cmt> <cmt> this library provides functionality for the rackspace public cloud by </cmt> <cmt> way of the official pyrax sdk ( </cmt> <cmt> this time only the cloudservers service is functional. instances can be </cmt> <cmt> created or deleted. idempotency is provided on matching instances with </cmt> <cmt> the same name, flavor, image, and metadata values within a given </cmt> <cmt> region. </cmt> <cmt> pyrax usage does require a credentials file written out to hold username </cmt> <cmt> and api key.  see pyrax documentation for details </cmt> <cmt> ( </cmt> <cmt> initial commit of rax inventory plugin </cmt> <cmt> the rax inventory plugin provides a way to discovery inventory in the </cmt> <cmt> rackspace public cloud by way of pyrax, the official sdk. grouping will </cmt> <cmt> be done if a group:name is found in the instance metadata. when a single </cmt> <cmt> host is queried all the instance details are returned with a rax_ </cmt> <cmt> prefix. </cmt> <cmt> because inventory plugins cannot take extra arguments, env variables </cmt> <cmt> must be set to point to the pyrax compatible credentials file and the </cmt> <cmt> region to query against. </cmt>",provide functionality to work with rackspace's public cloud
512,"<desc> description: need to install all requirements_test.txt for e.g. docstring tests to take effect, and to have desired versions of things. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> fix azure ci flake8 deps </cmt> <cmt> docstyle fixes </cmt>","azure flake8 dep, docstring fixes"
513,"<desc> since the flag defaulted to on, it was being passed to the compiler increasing code size. not severe since this command is currently only used for benchmarking </desc> <cmt> [flutter_tools] dont configure track-widget-creation in build aot mode </cmt> <cmt> plumb flag </cmt>",ensure --track-widget-creation is not enabled for build aot
514,"<desc> from epe-486 and auto-311, i was asked to add testing checkboxes to the pull request template for eosio: this benefits blockchain by encouraging developers to consider test cases while writing pull requests and submitting new contributions. this benefits automation by providing a convenient programmatic way to detect, track, notify, or act upon changes to the ci system or test framework(s), like we do with the other check boxes. more broadly, we all stand to benefit from a culture more focused on testing. the new template has been manually pasted into this pull request so you can see what it looks like, but github will not present the new template to users until it is merged to this repository's default branch: you must create templates on the repository's default branch. templates created in other branches are not available for collaborators to use. see the pull request templates heading on the about issue and pull request templates page of github's documentation for more information. see also pull request 9662 -- eos:develop pull request 9663 -- eos:blockvault pull request 9664 -- eos:develop-boxed pull request 9665 -- eos:release/2.0.x pull request 9666 -- eos:release/1.8.x select one: pull request template. select any that apply: none. none. none. none. </desc> <cmt> add ""testing changes"" section to the pull request template </cmt> <cmt> whitespace </cmt> <cmt> add italic emphasis on selection quantity </cmt> <cmt> colon </cmt>","add ""testing changes"" section to pull request template"
515,"<desc> this pr adds the apm configuration index to the list of system indices in the kibana plugin, making it accessible through the _kibana endpoint and giving it the same access privileges as the other kibana system indices. instead of duplicating the java rest tests for this new index, i parameterized the tests for the different index patterns that the kibana plugin has to handle. please let me know if this is overkill or undesirable, and i will be happy to back out the change and do something else for the java rest test. </desc> <cmt> add apm index to kibana system indices </cmt> <cmt> parameterize kibana system index tests by index name </cmt>",add apm configuration index to kibana system indices
516,"<desc> equivalent tweaks to vcio as #2823 provides for vc-mem. adds compat_ioctl handling as ioctl_mbox_property changes due to char* being of a different size. tested with </desc> <cmt> char: vcio: add compat ioctl handling </cmt> <cmt> there was no compat ioctl handler, so 32 bit userspace on a </cmt> <cmt> 64 bit kernel failed as ioctl_mbox_property used the size </cmt> <cmt> of char*. </cmt> <cmt> char: vcio: fail probe if rpi_firmware is not found. </cmt> <cmt> device tree is now the only supported config mechanism, therefore </cmt> <cmt> uncomment the block of code that fails the probe if the </cmt> <cmt> firmware node can't be found. </cmt>",vcio 64bit kernel/32bit user compat ioctl handling.
517,"<desc> fixes #9424 fixes #9480 fixes #9522 fixes #9529 this pr fixes some errors that ebpf.plugin was stopping some times(memory leak), we decided to use the same approach that apps.plugin is using to clean its link list. i am also converting the error call to info call for the users do not have the wrong impression that there is a bug when files related to kernel are not loaded. component name plugin there are two possible ways to test this pr: review kernel-collector fist 1 - review the pr, because it will force @thiagoftsm to create a new release that will simplify your life. 2 - install this pr. 3 - remove the file /etc/netdata/ebpf.conf or change the parameter ebpf load mode to entry. 4 - start netdata 5 - stop netdata 6 - confirm that /sys/kernel/debug/tracing/kprobe_events was cleaned. 7 - confirm tha you have info message instead error messages associated to ebpf.plugin. 8 - create the file ./edit-config ebpf.conf or change the parameter ebpf load mode to return. 9 - start netdata again 10 - stop netdata. 11 - repeat steps 6 and 7. extracting files 1 - download  shared libraries 2 - install this pr using ./netdata-installer.sh --dont-start-it 3 - extract the shared libraries inside /usr/libexec/netdata/plugins.d. 4 - remove the file /etc/netdata/ebpf.conf or change the parameter ebpf load mode to entry. 5 - start netdata 6 - stop netdata 7 - confirm that /sys/kernel/debug/tracing/kprobe_events was cleaned. 8 - confirm tha you have info message instead error messages associated to ebpf.plugin. 9 - create the file ./edit-config ebpf.conf or change the parameter ebpf load mode to return. 10 - start netdata again 11 - stop netdata. 12 - repeat steps 7 and 8. </desc> <cmt> network_viewer_basis: adjust new probes and adjust probes to be removed </cmt> <cmt> when collector is running in entry mode </cmt> <cmt> network_viewer_basis: fix memory leak, while we do not bring bpf_get_next_key </cmt> <cmt> for ebpf process thread, we will use the same approach that apps.plugin is using to clean all_pids variable </cmt> <cmt> network_viewer_basis: convert error messages in info messages </cmt> <iss> convert calls from error to info inside ebpf.plugin </iss> <iss> kernelcare and netdata conflicts with kprobe events </iss> <iss> can't get apache logs to show up </iss> <iss> ebpf.plugin segfault </iss>",fix potential memory leak in ebpf.plugin
518,<desc> working towards a complete osx boot status table/set of tables. we'll need multiple tables and a combination of data to determine boot state. </desc> <cmt> iokit_registry table </cmt> <cmt> acpi tables for osx </cmt>,osx iokit registry and acpi table data
519,"<desc> i hereby agree to the terms of the cla available at:  changelog category: documentation for #18554, #21710, #21711 </desc> <cmt> db engine </cmt> <cmt> table engine and function </cmt> <cmt> dictionary </cmt> <cmt> updates for readme and master fixes </cmt> <cmt> fixes </cmt> <cmt> links in index.md files </cmt>","documented postgresql engines, function and dictionary"
520,<desc> list both individual and archived files in /files/ endpoint. downloadable archived artifacts delete archived artifacts disallow put for archived artifacts in release file details endpoint. apply changes to org endpoint (which is almost a copy of the project release files endpoint) this pr requires: #26729 #26717 </desc> <cmt> do not list or count release archive as artifact </cmt> <cmt> feat: archived-artifacts endpoint </cmt> <cmt> fix: count both archived and individual artifacts </cmt>,list archived artifacts in files endpoint
521,"<desc> related issue = #2502 by default, on windows, taichi outputs taichi_cpp_tests.exe in somewhere like build\relwithdebinfo\, which is hard to find. this pr moves it to bin\, which is in the path and we can run taichi_cpp_tests everywhere. </desc> <cmt> [misc] place ""taichi_cpp_tests"" in ""bin"" folder </cmt> <cmt> restrict to windows and add docs </cmt> <cmt> minor fix </cmt>","output ""taichi_cpp_tests.exe"" to the ""bin"" folder on windows"
522,"<desc> this pr introduces three localized fixes to improve the near-miss warnings for declarations that are similar to @objc optional requirements: don't warn if the declaration satisfied any @objc protocol requirement don't warn if it's already an override of something tighten up the heuristics so we warn less resolves rdar://problem/27348369, rdar://problem/28524237, rdar://problem/26380688 </desc> <cmt> if a member is a witness to any @objc requirement, don't call it a near miss. </cmt> <cmt> when @objc inference was extended to look at the conformances of </cmt> <cmt> superclasses, the code that diagnosed near misses was not similarly </cmt> <cmt> updated, so we could end up producing a near-miss diagnostic on a </cmt> <cmt> declaration that was already a witness to another protocol. use the </cmt> <cmt> same witness-finding logic that we use for @objc inference so this </cmt> <cmt> doesn't happen again. </cmt> <cmt> fixes the rest of rdar://problem/27348369 </cmt> <cmt> (cherry picked from commit 5267c6a269e7caf6baf1f6cb313c01c00da5e010) </cmt> <cmt> don't complain about near misses for declarations that are overrides. </cmt> <cmt> an overriding declaration doesn't have a choice about its signature, </cmt> <cmt> because the signature is dictated by the overridden </cmt> <cmt> declaration. therefore, don't produce a warning for it. </cmt> <cmt> fixes rdar://problem/28524237. </cmt> <cmt> (cherry picked from commit da2a7cef4628a7811806363d2c9e04a3aa29dd0a) </cmt> <cmt> tighten up @objc optional near-miss detection heuristics. </cmt> <cmt> the @objc optional requirement near-miss heuristics were too </cmt> <cmt> permissive, and could occasionally produce ridiculous results that </cmt> <cmt> were nowhere close to a ""near"" miss. make the diagnostics more </cmt> <cmt> conservative, and fix an issue with an errant sentinel value. </cmt> <cmt> fixes rdar://problem/26380688. </cmt> <cmt> (cherry picked from commit 77942d37d58e7f029f959aa5bfb79f66c73247a4) </cmt>",qoi improvements for @objc optional near-miss warnings
523,"<desc> now that the terminal is doing a better job of actually marking which lines were and were not wrapped, we're not always copying lines as ""wrapped"" when they should be. we're more correctly marking lines as not wrapped, when previously we'd leave them marked wrapped. the real problem is here in the scrollframe method - we'd manually newline the cursor to make the terminal's viewport shift down to a new line. if we had to scroll the viewport for a wrapped line, this would cause the terminal to mark that line as broken, because conpty would emit an extra \n that didn't actually exist. this more correctly implements scrollframe. now, well move where we ""thought"" the cursor was, so when we get to the next paintbufferline, if the cursor needs to newline for the next line, it'll newline, but if we're in the middle of a wrapped line, we'll just keep printing the wrapped line. a couple follow up bugs were found to be caused by the same bad logic. see #5039 and #5161 for more details on the investigations there. #4741 rwr, which probably made this worse #5122, which i branched off of #1245, #357 - a pair of other conpty wrapped lines bugs #5228 - a followup issue for this pr closes #5113 closes #5180 (by fixing decrst 25) closes #5039 closes #5161 (by ensuring we only removespaces on the actual bottom line) i work here checked the cases from #1245, #357 to validate that they still work added more and more tests for these scenarios, and then i added more the entire team played with this in selfhost builds </desc> <cmt> add tracing for circling and scrolling operations. fix improper invalidation within adjustcursorposition routine in the subsection about scrolling down at the bottom with a set of margins enabled. </cmt> <cmt> pr feedback applied. don't bother making string if no one is listening to etw. change the scroll member variable to a til::point and math that directly (and add the operators and related tests to til::point). </cmt> <cmt> more tracing is always good </cmt> <cmt> (cherry picked from commit d972b5e07a8f5586dab988043a3ced9c03762714) </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/renderer/vt/xtermengine.cpp </cmt> <cmt> #	src/renderer/vt/invalidate.cpp </cmt> <cmt> so this works but i think it will break the eol backspace test </cmt> <cmt> this can't possibly be right... can it? </cmt> <cmt> mysteriously the existing tests all basically pass </cmt> <cmt> this is a simple test for the case that already worked </cmt> <cmt> this test failure helps explain that this doesn't work </cmt> <cmt> the test fails validating the second wrapped terminal line. </cmt> <cmt> i think the problem comes from us manually placing the cursor on the last line </cmt> <cmt> of the buffer. when we write the next 20 'a's, the first one gets written on </cmt> <cmt> the last cell of the first row, and that's bad. </cmt> <cmt> i'm going to see if i can't get rid of that call (the movecursor in </cmt> <cmt> paintcursor) for this case. that seems like the cause of all this mess. </cmt> <cmt> this all wroks far to shockingly well </cmt> <cmt> add a test for this case </cmt> <cmt> todo: this proves that the scrolling during a frame with other text </cmt> <cmt> breaks this scenario. we're going to try and special-case the scrolling </cmt> <cmt> thing to _only_ when </cmt> <cmt> * the invalid area is the bottom line, and </cmt> <cmt> * the line wrapped </cmt> <cmt> so in that case, we'll be sure that the next text will cause us to move </cmt> <cmt> the viewport down a line appropriately </cmt> <cmt> i've got a crazy theory that rendering bottom-up _might_ fix this </cmt> <cmt> this fixes this test, but maybe the test was always broken? </cmt> <cmt> i'm honestly shocked that this seems to work </cmt> <cmt> cleanup for review, but i have to wait for #5122 to merge first </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/cascadia/unittests_terminalcore/conptyroundtriptests.cpp </cmt> <cmt> #	src/host/ut_host/conptyoutputtests.cpp </cmt> <cmt> #	src/renderer/vt/xtermengine.cpp </cmt> <cmt> #	src/renderer/vt/math.cpp </cmt> <cmt> fix the test @miniksa wrote for #5122 </cmt> <cmt> it was unhappy with the exact line lengths and this change </cmt> <iss> clear-host fails to clear the first line </iss> <iss> terminal breaks copied text at window line wraps, even when the text has no new-line characters </iss> <iss> scrolling down in vim scrolls up duplicated vim status lines </iss> <iss> neovim cursor flickers from block to bar running in ms terminal under tmux </iss>",fix copying wrapped lines by implementing better scrolling
524,"<desc> this pr fixes a problem with hot-reloading of page query results. before this pr updated queries were not executed after extraction and were only executed on a subsequent update of the page component. the correct flow for query running is: extract queries from updated components enqueue extracted queries for execution execute dirty queries (including enqueued extracted queries) but we had this instead: extract queries from updated components execute dirty queries (including enqueued extracted queries) enqueue extracted queries for execution the culprit is settimeout here which triggers enqueuing too late: gatsby/packages/gatsby/src/redux/machines/page-component.ts lines 132 to 139 961f3d5 runpagecomponentqueries: (context): void => { const queryutil = require(../../query) // wait a bit as calling this function immediately triggers // an action call which redux squawks about. settimeout(() => { queryutil.enqueueextractedpagecomponent(context.componentpath) }, 0) }, so when we run calculatingdirtyqueries it doesn't yet include extracted queries. fixes #26580 </desc> <cmt> add failing e2e test </cmt> <cmt> fix(gatsby): wait for extracted query enqueuing before running it </cmt> <iss> hot reload doesn't re-run page query until i save twice </iss>",wait for extracted query enqueuing before running queries
525,"<desc> i hereby agree to the terms of the cla available at:  fix possible crash while using wrong type for prewhere. fixes #12053, #12060 </desc> <cmt> check type of filter for prewhere. </cmt> <cmt> check type of filter for prewhere. </cmt> <cmt> check type of filter for prewhere. </cmt> <cmt> check type of filter for prewhere. </cmt> <cmt> added test. </cmt> <iss> segmentation fault storages/mergetree/mergetreebaseselectprocessor.cpp:261: db::mergetreebaseselectprocessor::mergetreebaseselectprocessor </iss>",check wrong type for filter.
526,"<desc> tests not yet all passing, but basically looking good. logic is cleaner. in particular because conneg happens in the view, we don't need to awkwardly deal with the notacceptable exception having to be dealt with at the time of rendering the response. easier to override conneg behavior for users. easier to override exception behaviour. all exceptions dealt with in single place now. easy to use different code paths for different formats (eg serialize differently for different media types.) eg if self.renderer.format == 'json' ... inside apiview </desc> <cmt> moved content negotiation out of response.  nicer exception handling now. </cmt> <cmt> simplify content_negotiation slightly </cmt> <cmt> cleaner content negotiation.  occurs after permissions.  optional 'force' flag. </cmt>",content negotiation logic out of response and into view
527,"<desc> check again that the following files are up to date. docs/proton_c_conversion.md docs/other_vscode.md docs/feature_swap_hands.md docs/faq_general.md docs/feature_userspace.md docs/config_options.md my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> updated docs/ja/proton_c_conversion.md original tag. </cmt> <cmt> updated docs/ja/other_vscode.md original tag. </cmt> <cmt> updated docs/ja/feature_swap_hands.md original tag. </cmt> <cmt> updated docs/ja/faq_general.md original tag. </cmt> <cmt> updated docs/ja/feature_userspace.md original tag. </cmt> <cmt> updated git co docs/ja/config_options.md original tag. </cmt>",change original tags of japanese translations
528,"<desc> i'm a co-author of the uuid npm module which is being used in some places within the code base of ghost. i'm currently trying to understand real-world use cases of time-based uuids (""v1 uuids""). i found three occurrences where v1 uuids were being used instead of v4 uuids and i was wondering if any of these cases really require the semantically much more complex v1 uuids or whether we could live equally well with purely random v4 uuids? at least the test suite still passes after my changes, so apparently this doesn't seem to introduce any known regressions. i'd be really curious to understand the motivation for choosing v1 over v4 uuids in the first place, so any feedback on this would be highly appreciated! </desc> <cmt> swapped v1 with v4 uuid as requestid when logging </cmt> <cmt> no issue </cmt> <cmt> v1 uuid are based on current time and the hardware mac address of the </cmt> <cmt> machine where they are being generated. as such they have much more </cmt> <cmt> complex semantics than v4 uuids which are simply randomly generated. </cmt> <cmt> unless there's a specific requirement for the special semantics of v1 </cmt> <cmt> uuids it is simpler and less error prone to simply go for v4 uuids </cmt> <cmt> whenever just a unique identifier is needed. </cmt> <cmt> swapped v1 with v4 uuid when creating a temporary contentfolder </cmt> <cmt> no issue </cmt> <cmt> v1 uuid are based on current time and the hardware mac address of the </cmt> <cmt> machine where they are being generated. as such they have much more </cmt> <cmt> complex semantics than v4 uuids which are simply randomly generated. </cmt> <cmt> unless there's a specific requirement for the special semantics of v1 </cmt> <cmt> uuids it is simpler and less error prone to simply go for v4 uuids </cmt> <cmt> whenever just a unique identifier is needed. </cmt> <cmt> swapped v1 with v4 uuid when creating a temporary exportfolder </cmt> <cmt> no issue </cmt> <cmt> v1 uuid are based on current time and the hardware mac address of the </cmt> <cmt> machine where they are being generated. as such they have much more </cmt> <cmt> complex semantics than v4 uuids which are simply randomly generated. </cmt> <cmt> unless there's a specific requirement for the special semantics of v1 </cmt> <cmt> uuids it is simpler and less error prone to simply go for v4 uuids </cmt> <cmt> whenever just a unique identifier is needed. </cmt>",use v4 instead of v1 uuids
529,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <elrumordelaluz/reactour@v1.17.0...v1.18.0> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [reactour] add interface change due to 1.18 </cmt> <cmt> update version in definitions and fix lint error </cmt>",upgrade reactour type from  v1.17 to v1.18
530,<desc> memory consumed by bitmap aggregate functions now is taken into account for memory limits. this closes #26555. note: it is implemented in quite hacky way: c does not require implicit function declarations; it also depends on linking order. </desc> <cmt> attempt to add memory tracking to roaringbitmaps </cmt> <cmt> add missing file </cmt> <cmt> advancements </cmt> <cmt> improve performance </cmt> <iss> memory tracking issue in groupbitmapstate ? </iss>,track memory consumed by roaring bitmaps.
531,"<desc> object pinning will evict objects based on the current ref count. if object pinning is off, each plasma store evicts objects independently in lru order. this pr modifies the behavior when object_pinning_enabled is off so that we trigger gc at all worker nodes before we fallback to lru so that we favor evicting unreachable objects over objects still in use. todo: upgrade to plasma once this pr is merged. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> add a test for lru fallback </cmt> <cmt> update error message </cmt> <cmt> upgrade arrow to master </cmt> <cmt> integrate with arrow </cmt> <cmt> revert ""bazel mirrors (#7385)"" </cmt> <cmt> this reverts commit 44aded527215dfa884c13faef3b97cd3bd401555. </cmt> <cmt> don't lru evict </cmt>",option to fallback to lru on outofmemory
532,"<desc> merge nginx changes between 1.2.5 and 1.2.6 change cpu affinity to 'off' as default update cpu affinity log, so that nginx will write down 'cpuset_setaffinity' rather than 'sched_setaffinity' in freebsd </desc> <cmt> merge nginx changes between 1.2.5 and 1.2.6 </cmt> <cmt> change cpu affinity to 'off' as default </cmt> <cmt> update cpu affinity log, so that nginx will write down 'cpuset_setaffinity' rather than 'sched_setaffinity' in freebsd </cmt>",merge changes between 1.2.5 and 1.2.6
533,"<desc> let's put limits on everything, in particular if it can be influenced from outside via dhcp or ra </desc> <cmt> networkd: enforce a limit on the number of statically assigned addresses/routes/fdb entries </cmt> <cmt> we should put a limit on everything, hence also on these resources. </cmt> <cmt> sd-netlink: fix sd_netlink_inc_rcvbuf() prototype </cmt> <cmt> drop weird ""const"" usage, and use size_t for sizes. </cmt> <cmt> networkd: drop weird ""const"" usage in function parameters </cmt> <cmt> we generally only use ""const"" to constify the destination of pointers, but not </cmt> <cmt> the pointers themselves, as they are copied anyway during c function </cmt> <cmt> invocation. hence, drop this usage of ""const"". </cmt> <cmt> networkd: also enforce limit on total number of address/routes </cmt> <cmt> this covers the address/routers acquire dynamically. </cmt> <cmt> networkd: constify more things </cmt>",put limits on addresses and routers per link and per network
534,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> created simple type definitions for ""node-tlv"" </cmt> <cmt> removed disabling of rules </cmt> <cmt> added disable-next-line </cmt>","created type definitions for ""node-tlv"""
535,"<desc> this pr implements a new installation flow for sentry apps that can start on the website of a third party. the third-party website can expose a link of the following format:  if the user is a member of a single organization, we automatically assume they want to install the integration on that org and don't show an org select: if the user is in multiple orgs, we show a dropdown to pick the org before we render more information about the app: once the user selects an org, we load the full information about that org and show the full integration install view: note there are a number of error scenarios which are covered: user does not have access to sentry app or sentry app doesn't exist (user sees the default 404 page) sentry app is internal sentry app already installed sentry app is an unpublished integration for a different org than is selected user does not have permission to install app see more details here </desc> <cmt> temp checkin </cmt> <cmt> update </cmt> <cmt> update </cmt>",feat(app-platform) 3rd party initiated installation
536,"<desc> description: this pr removes password authentication from the automatic device tracker. it has been disabled from the automatic api. breaking change: automatic has disabled password authentication on their api. home assistant will now use oauth2 to authenticate accounts. the following steps must be taken to transition your setup: log in to your automatic developer account. in the automatic developer apps manager, specify the oauth redirect url in the developer page. this should be configured to <home-assistant-url>/api/automatic/callback. (example:  remove username/password from your automatic device tracker configuration in configuration.yaml. if you have authorized your account for scope:current_location, add current_location: true to your automatic device tracker configuration in configuration.yaml. when you restart home assistant, click on the automatic configure link in the configurator card, and follow the instructions to authorize home assistant. note: automatic's api is currently not correctly authorizing with refresh tokens, so step 4 currently needs to be performed after every restart. pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3187 </desc> <cmt> remove now disabled password auth from automatic </cmt> <cmt> fallback to configurator more permissively </cmt>",automatic device tracker remove password
537,"<desc> fixes #39694 this was actually more interesting to fix than you may think, because it didn't repro in the test harness. turn out that's because the test harness calls emit, and then getpreemitdiagnostics, which is different from the ls or command line compiler - namely, it captures an error added by the emitresolver (which shouldn't be adding new errors in the first place)! so once i realized this, i added some new test infrastructure to figure out when this happens and report it (by getting the diagnostics twice - once before emit and once after). that then exposed a crash that wasn't captured by our test harness but would have happened on the command line (accessing a parent pointer in a place where it may not have been bound), which i fixed, and exposed two existing tests where similar emitresolver-added-error behavior is occurring. in one case, the order we checked controlled which declarations we actually recorded duplicate identifier errors on, because we were only scanning for them on one ""side"" of the conflicting declarations. in the other, we were explicitly only looking for flag conflicts on the ""first"" declaration bound to a symbol, but that meant that if checking started in a file other than the one that declaration was in, we'd fail to capture any errors for the conflict. </desc> <cmt> modify test harness so it can report underlying issue, fix small parent pointer issue </cmt> <cmt> fix underlying export asignment check issue and fix lints </cmt> <iss> no compilation error for `export default whatever` </iss>",fix lack of error on default export of nonexistant name
538,"<desc> the unit test is just a best guess, would be great if somebody could test it before merging. </desc> <cmt> qt: use locale-specific number formatting </cmt> <cmt> - change bitcoinamountfield to use locale-specific number format </cmt> <cmt> - change bitcoinunits to show and parse locale-specific numbers </cmt> <cmt> - if a language/territory is selected in options, this is set as default </cmt> <cmt> locale (overrides system locale). </cmt> <cmt> fixes #3887 </cmt> <cmt> (cherry picked from commit </cmt> <cmt> laanwj/bitcoin@db0b8f3a2e96bc7c7aff95c9ade65be33dd27209, </cmt> <cmt> bitcoin/bitcoin#3893) </cmt> <cmt> qt: add tests for bitcoin units parsing/formatting </cmt> <cmt> tests various locales, as well as variants with and without </cmt> <cmt> decimals group separators. </cmt> <cmt> (cherry picked from commit </cmt> <cmt> laanwj/bitcoin@9ce31063b8c7e2ecac4087f2487d1c4da5abe29d, </cmt> <cmt> bitcoin/bitcoin#3893) </cmt> <cmt> use system local for formatting instead of selected locale </cmt>",1.7 number format according to system local
539,"<desc> with this, using lexicalpath to canonicalize (local) paths is considered deprecated: please let the kernel deal with it, as it can handle things like symlinks (and other filesystem magic) properly. lexicalpath is still useful for things like getting an extension of a file. </desc> <cmt> userland: port sleep(1) to core::argsparser </cmt> <cmt> libc: remove endless loop after abort() call </cmt> <cmt> we (rightfully) mark abort() noreturn, so the loop just gets compiled out. </cmt> <cmt> libc: mark _exit() as noreturn </cmt> <cmt> we already do this for exit(). </cmt> <cmt> libc: ensure abort() doesn't return </cmt> <cmt> it's not enough to send ourselves a sigabrt, as it may be ignored or handled </cmt> <cmt> differently. we really, really want abort() to never return, as that will mess </cmt> <cmt> up the assumptions of the calling code big time. so, if raise(sigabrt) returns, </cmt> <cmt> kill ourselves with sigkill, and if that somehow returns too, call _exit(). </cmt> <cmt> an alternative approach, which glibc apparently follows, is to reset sigabrt </cmt> <cmt> disposition to its default value and then send sigabrt to yourself a second </cmt> <cmt> time. that would also work, but i believe sigkill + _exit() to be a simpler </cmt> <cmt> approach that is less likely to break in extremely weird situations. </cmt> <cmt> note that this only guarantees that abort() never returns, not that the process </cmt> <cmt> actually gets killed. it's still possible to install a sigabrt handler that </cmt> <cmt> simply never returns (such as by longjmp'ing out, endlessly looping, or exec'ing </cmt> <cmt> another image). that is a legitimate use case we want to support; at the same </cmt> <cmt> time most software doesn't use that functionality and would benefit from hard </cmt> <cmt> guarantees that abort() terminates the program. the following commit is going to </cmt> <cmt> introduce means for ensuring sigabrt handler is never reset to something </cmt> <cmt> unexpected. </cmt> <cmt> kernel: introduce ""sigaction"" pledge </cmt> <cmt> you now have to pledge ""sigaction"" to change signal handlers/dispositions. this </cmt> <cmt> is to prevent malicious code from messing with assertions (and segmentation </cmt> <cmt> faults), which are normally expected to instantly terminate the process but can </cmt> <cmt> do other things if you change signal disposition for them. </cmt> <cmt> userland et al: pledge sigaction when needed </cmt> <cmt> * in some cases, we can first call sigaction()/signal(), then *not* pledge </cmt> <cmt> sigaction. </cmt> <cmt> * in other cases, we pledge sigaction at first, call sigaction()/signal() </cmt> <cmt> second, then pledge again, this time without sigaction. </cmt> <cmt> * in yet other cases, we keep the sigaction pledge. i suppose these could all be </cmt> <cmt> migrated to drop it or not pledge it at all, if somebody is interested in </cmt> <cmt> doing that. </cmt> <cmt> base: document the sigaction promise </cmt> <cmt> also add a few generic words about pledge(). </cmt>","almost reliable abort(), sigaction hardening, and lexicalpath"
540,"<desc> the regression #41138 which is caused by #39929 is happened due to using cast_type (:encrypted) with prev_decorator (serialize in store). since multiple decorations (:encrypted on store on the original attribute) were never officially supported, it was just a coincidence that it worked, but i don't want to break that in exchange of allowing to ommit a type on subclasses. imo, even if a type on subclasses can be ommited, i'd not recommend to ommit the type on subclasses for devs. # app/models/post.rb class post < activerecord::base attribute :x, :integer # app/models/special_post.rb class specialpost < post # :integer can be ommited, but it is less obvious. attribute :x, default: 42 # i'd recommend to not ommit the :integer for devs. attribute :x, :integer, default: 42 it is a similar point of view with 94ba417#r41923157. fixes #41138. </desc> <cmt> add a regression test for decorated type with type_for_attribute </cmt> <cmt> it is a regression test for #41138. </cmt> <cmt> revert ""merge pull request #39929 from jonathanhefner/decorate-original-attribute-type"" </cmt> <cmt> this reverts commit 79d0c17c654033279565f301545c418af68db597, reversing </cmt> <cmt> changes made to bc828f74dffc79fdfea0a905219c08b00beb4d47. </cmt> <cmt> fixes #41138. </cmt> <iss> regression when redefining a store attribute with a new type </iss>",fix decorated type with type_for_attribute on the serialized attribute
541,"<desc> this merge request solves issue #49362. it installs python3-dnf, unless python2 is used. the previous situation preferred python2-dnf over python3-dnf, causing an issue on systems with both python2 and python3. dnf most details can be found in #49362. i would like to be able to test against fedora 30, but did not find out how integration works well enough. </desc> <cmt> create python3and2 </cmt> <cmt> adding tests to see if dnf still works when python-2 and python-3 are installed. </cmt> <cmt> update main.yml </cmt> <cmt> include the tests that run on python 2 and python 3, based on the package manager. </cmt> <cmt> update dnf.py </cmt> <cmt> use python3-dnf by default, otherwise python2-dnf. </cmt>",install python3-dnf preferably over python2-dnf.
542,"<desc> closes #43480 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> call to_numeric before get_numeric_data </cmt> <cmt> this converts numeric objects to numeric types before discarding non-numeric types. </cmt> <cmt> add test for groupby with object </cmt> <cmt> linting </cmt> <iss> bug: dataframegroupby.boxplot with subplots=false fails for object columns </iss>",fix dataframegroupby.boxplot with subplots=false fails for object columns
543,<desc> commit message: replace exceptions with enum state|bool|optional (as appropriate) in proxy protocol listener extension. risk level: low testing: pre-existing unit and integration tests docs changes: n/a release notes: n/a platform specific features: n/a fixes: #11044 @asraa can you please take a look when you get a chance? </desc> <cmt> replace envoyexception with state enum or similar as appropriate </cmt> <cmt> spelling </cmt> <cmt> const for state var </cmt> <iss> proxy protocol listener uses exceptions on the data plane </iss>,clean up exceptions in proxy protocol listener
544,"<desc> the endpoint for verifying the one time key that was sent to the user. two endpoints added, a get for clickable link and post for copy and paste of code. after verifying, the one-time-key will be stored in django sessions for authenticating the user with their sso provider in a later ticket. user will then be redirected to the login page. </desc> <cmt> feat(auth): reuse existing user profile for unknown identity </cmt> <cmt> when a user supplies unrecognized sso credentials associated with an </cmt> <cmt> email address for an existing user profile, offer them a chance to link </cmt> <cmt> their identity to that profile instead of automatically provisioning a </cmt> <cmt> new profile. </cmt> <cmt> introduce a feature flag. the feature is incomplete and will hit </cmt> <cmt> unimplemented code if the flag is set. </cmt> <cmt> feat(idp-migrations): one-time account validation keys </cmt> <cmt> added test for creating verification key </cmt> <cmt> uncomment raise notimplementederror and set feature flag to false </cmt> <cmt> typing to send_confirm_email </cmt> <cmt> removed some comments and white space </cmt> <cmt> changed verification from uuid4 to default_validation_hash and removed auth:one-time-key prefix from email </cmt> <cmt> feat(idp-migration): verify user and store key in django session </cmt> <cmt> changes based on pr reviews </cmt>",verified one-time-key and stored key in django sessions
545,"<desc> this pr is improved version of #9346 with all suggestions applied (see discussion). </desc> <cmt> print nicer error message when missing meteor package is imported </cmt> <cmt> revert ""print nicer error message when missing meteor package is imported"" </cmt> <cmt> this reverts commit 1574eb18fe400a5c99703afa204565484e72b1c1. </cmt> <cmt> throw exception with better error message when missing meteor package is required </cmt>",print nicer error message for missing meteor package
546,<desc> types of changes bug fix (non-breaking change fixing an issue) new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. </desc> <cmt> fix typo </cmt> <cmt> fix typo </cmt> <cmt> fix typos </cmt>,fix small typos in spacy 101 usage document
547,"<desc> this is the 2nd of an n part series of prs to split tslib into independent modules. at the moment there is a big chunk of code at the bottom of tslib that looks like it was pasted in from somewhere else.  the header for that section of the file reads # don't even ask.  so i won't. the new tslibs.strptime only used in one place: array_strptime is called in tools.datetimes.  other than that, nothing needs to be exposed, and nothing else in tslib relies on it. the one function from tslib that strptime does need is _check_dts_bounds.  this (mostly) moves that up to datetime.pxd, which both tslib and strptime already import anyway. this is mostly a copy/paste of the existing functions+classes.  i cleaned up a couple of places where variables used camelcase. tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> separate out strptime.pyx </cmt> <cmt> whitespace fixup </cmt>",separate out strptime.pyx from tslib
548,"<desc> eosio's code currently assumes that both wabt and wavm wasm runtimes will be built and available. this hasn't been much of a problem except for interfering with unsupported win32 builds where our wavm fork is non functional. looking forward to 2.0 though, there will be more diversity in what platforms different runtimes support. it's currently looking like: runtime platforms operational on wabt anywhere wavm 64-bit, posix (linux & macos) eos-vm interpreter posix (linux & macos) eos-vm jit x86-64, posix (linux & macos) eos-vm oc x86-64, linux only this pr adds some initial basic scaffolding to support central definition of what runtimes are supported. frankly i don't care much for this approach as it just dumps some #ifdefs around which i'd rather not do. however there are aspects that make something cleaner more challenging: the way we've constructed the intrinsic registration, that we need parts of the wavm intrinsics even when not using wavm (because we use the wavm ""linker"" for validation), and some runtimes like eos-vm oc have additional runtime options. there is a functional issue where if you unittests/unit_test -- --unsupported-runtime all the tests simply fail instead of unit_test stopping early. but ctest is properly set up only register runtimes that are enabled. if anyone wants to take a go at a better approach before 2.0, no beef here. as part of the above effort, this pr also makes wavm's runtime enabled only on non-win32 builds. you can experiment with this on any platform by manually changing the if() in the cmakelists, and see that wavm is not allowed as a runtime nor does it show up in ctest </desc> <cmt> move isa() out of wavm's runtime.cpp since linking needs that </cmt> <cmt> remove global/table/memory intrinsic support </cmt> <cmt> decouple wavm runtime from being a required component in eosio </cmt> <cmt> minor cleanup to optional runtime support </cmt>",decouple wavm runtime from being required & initial support for platform specific wasm runtimes
549,"<desc> summary: the reason why the cookie state information is lost is that when a response is received, the query library does not process max-age=0. it was decided to report the problem to the requests community and implement a temporary solution. done: fix issue #998 add test for issue run make test-all make psf/requests#5743 </desc> <cmt> fix issue: #998 </cmt> <cmt> add test for issue: #998 </cmt> <cmt> add yourself to the authors, issue: #998 </cmt>",will not expire/delete cookie from session when set-cookie only sets max-age=0 without expires
550,<desc> added some examples of good and bad exception types for #1852.  it is just showing the throwing side.  i think showing the catching as well makes the examples too long and the rule itself is just about the types. </desc> <cmt> e.14 </cmt> <cmt> clean-up </cmt> <cmt> add final </cmt> <cmt> added words to dictionary </cmt> <cmt> cleanup </cmt>,e.14 exception type examples for #1852
551,"<desc> we have seen unexpected crashes in office when using the memory map-based jsi buffer, when trying to create the prepared script file handle: std::unique_ptr<void, decltype(&closehandle)> filehandle{ createfile2(filename, generic_read, file_share_read, open_existing, nullptr /* pcreateexparams */), &closehandle}; if (filehandle.get() == invalid_handle_value) { to mitigate this, the feature will be scaled back and require the consumer to set the jsi.memorymappedscriptstore runtime option to enable it. microsoft reviewers: open in codeflow </desc> <cmt> condition using memory mapped buffer to runtime option jsi.memorymappedscriptstore </cmt> <cmt> change files </cmt>",add jsi.memorymappedscriptstore runtime option to control usage of memorymappedbuffer
552,"<desc> i tried to incorporate the changes @danielrosenwasser made in his pr. the defininitions now pass both tests. you had a lot of structure in your definitions that wasn't present in my code. i copied your code for the animations. there is still some functionality missing in my definitions file: for example the parsecommands interface for path parsing. how did you create that ? it is not really documented and the source code of snap is hard to read. i couldn't say wether the parsed commands are numbers or strings. that being said, i think the two versions are now comparable. it is probably a matter of taste which structure is preferable. therefore it would be great if you could issue your pr again. you seem to have a deeper understanding of snap than me (see parsedcommands) and the users would probably profit from this. </desc> <cmt> i compared my definitions with the pr from daniel rosenwasser and tried to incorporate his improvements </cmt> <cmt> aligning to the tests of daniel rosenwasser </cmt>",aligning to the pr of daniel rosenwasser
553,<desc> this pr fixes the two separate issues reported in #26163. fixes #26163. </desc> <cmt> correct apparent type for homomorphic mapped types applied to array types </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <iss> mapped tuple types don't infer as arrays in generics </iss>,fix mapped array type constraint
554,"<desc> proposed fix for #7525 that still keeps the possibility to load from ""file://"". </desc> <cmt> added property ignorehttpstatus. when set, the 'load' event handler will not check http status or readystate. should only be used when xhrloader fetch data from a non-http source (e.g. local file system, file://). </cmt> <cmt> added ignorehttpstatus to documentation. </cmt>",added property ignorehttpstatus to be able to load from non-http source (i.e. file://)
555,"<desc> this pr seeks to remove all firmware filesize changes from all board-level and default keymap rules.mk files.  this first round is only keyboards starting with a number, or 'a' - 'f'. the idea here is to reduce blindly copy-pasting outmoded conventions into new firmware submissions (and, by extension, prevents qmk collaborators from having to request such amendments going forward). removed parenthetical reference to firmware filesize changes in rules.mk at the keyboard and default keymap level for any boards/vendors starting with [0-9a-f]. for the most part i avoided rev.* and v[0-9] files at this time because that is all over the place and would probably be best handled in a final, sweeping and comprehensive breaking change. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> removed reference to firmware size in 0-9,a-f board-level and default keymap 'rules.mk' files </cmt> <cmt> correct some 'rules.mk' in boards buried under vendor folders </cmt>","trim firmware sizes from default rules.mk, part 1"
556,<desc> it should be possible to configure ldap and using admin.existingsecret variable. fixes #17551 dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> stable/grafana: add ldap.enabled value to enable ldap </cmt> <cmt> update chart version </cmt> <iss> [stable/grafana] cannot use ldap when admin.existingsecret is set </iss>,enable ldap when using admin.existingsecret
557,<desc> fixes #548  and #850 </desc> <cmt> all the identifiers need to be escaped to make sure compiler doesnt confuse __nonunderscore character incorrectly </cmt> <cmt> fixes #548 </cmt> <cmt> fix the completion entry for __proto </cmt> <cmt> fixes #850 </cmt> <iss> [typebaselines] __proto__ property not respected in object literal </iss>,fix services and compiler to handle __proto
558,"<desc> added xboxvmp driver to system32/drivers directory added required registry entries for it made it compatible with current videoprt driver, specified vendor id and device id explicitly in videoportgetaccessranges() call fixed a bug in videoprt driver - reserved bit field was uninitialized in pcislotnumber variable, so halgetbusdata() call failed in this case (important: this might fix some other video driver issues!) tested and confirmed that driver doesn't interfere with vga/vbe on normal pc installations. jira issue: core-16317 please add to xbox boot milestone. </desc> <cmt> [xboxvmp] add xbox video miniport driver </cmt> <cmt> also make xboxvmp driver compatible with video port driver, specify </cmt> <cmt> vendor id and device id explicitly in videoportgetaccessranges() call </cmt> <cmt> core-16317 </cmt> <cmt> [videoprt] fix uninitialized reserved bit field in pcislotnumber </cmt> <cmt> core-16317 </cmt>",add xbox video miniport driver and fix a bug
559,"<desc> in dao.py file following rules doesn't have to be disabled: disable=too-many-locals, too-many-branches, too-many-statements. changed broad exception in utils.py to keyerror. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> removed not needed disabled pylint rules from set_dash_metadata: </cmt> <cmt> - disable=too-many-locals, </cmt> <cmt> - too-many-branches, </cmt> <cmt> - too-many-statements </cmt> <cmt> changed broad exception to keyerror. </cmt>",changes a pylint check in dashboard module
560,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: git diff of 4.0.0 and changelog of 4.0.0 i tried to separate each change into individual commits to better organize all the changes made in this release. </desc> <cmt> rename safe functions </cmt> <cmt> fix load return type </cmt> <cmt> update schemas </cmt> <cmt> add dump options </cmt> <cmt> restructure schema </cmt> <cmt> fix whitespace </cmt> <cmt> add name </cmt> <cmt> update tests </cmt> <cmt> update type </cmt> <cmt> prettier </cmt> <cmt> additional test </cmt>,update types for 4.0 release
561,"<desc> this commit rewrites initialisation of the ""shared queue"" and in effect prevents from double execution of ""core/core.js"" and ""core/error.js"". previously both of these files were executed every time a ""jsruntime"" was created. that lead to a situation where one copy of each script was included in the snapshot and then another copy would be executed after loading the snapshot. effectively ""jsruntime::shared_init"" was removed; instead execution of those scripts and actual initialisation of shared queue was split into two helper functions: ""jsruntime::js_init"" and ""jsruntime::share_queue_init"". additionally stale todo comments were removed. </desc> <cmt> remove opstate::default </cmt>","simplify deno.core initialisation, remove stale todo"
562,"<desc> i am dealing with a lot of short sentences. for disambiguation, it is sometimes needed to also include the neighbor sentences. i changed the predict method of nel to include n_sents neighbour sentences when generating the vector for the model. there was no change to the training needed, since training ignores sentence scopes. enhancement i have submitted the spacy contributor agreement. my changes don't require a change to the documentation, or if they do, i've added all required information. (it probably needs some description.) </desc> <cmt> added setting for neighbour sentence in nel </cmt> <cmt> added spacy contributor agreement </cmt>",added parameter to nel to take n sentences into account
563,<desc> description: add tests for media_player add unsubscribe method to unload checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> add tests for media_player </cmt> <cmt> remove ps4/media_player.py </cmt> <cmt> add unsubscribe method to unload </cmt>,add ps4 tests for media player
564,<desc> backport of #15636 to 1.13 </desc> <cmt> [flink-22239][jdbc] pool connections in jdbc xa sink </cmt> <cmt> some databases like postgresql and mysql allow at most </cmt> <cmt> one xa transaction per connection. using new connection </cmt> <cmt> for each transaction (and pooling) allows to overcome </cmt> <cmt> this limitation. </cmt> <cmt> [flink-22239][jdbc] rollback xa transactions on recovery </cmt> <cmt> leaving transactions not rolled back may lead to new </cmt> <cmt> transactions being blocked by the old ones. </cmt> <cmt> [flink-22239][tests] test jdbc xa sink against postgresql </cmt>,support exactly-once (sink) for pgsql and mysql
565,"<desc> fixes: #4473 adaptec_raid fix: check if arcconf is available before sudo checks disable python modules which use sudo by default  (adaptec_raid, megacli, samba) update readme component name python.d modules: adaptec_raid megacli samba </desc> <cmt> adaptec_raid: check if arcconf is available first </cmt> <cmt> adaptec_raid: disable by default and update docs </cmt> <cmt> megacli: disable by default and update docs </cmt> <cmt> samba: disable by default and update docs </cmt> <cmt> samba megacli adaptec readme fix </cmt> <iss> logcheck security alert: netdata : command not allowed ; tty=unknown ; pwd=/etc/netdata ; user=root ; command=validate </iss>",disable python sudo modules by default
566,<desc> todo: review socket code adapt https pr into this write tests for sockets configurations write tests for https configurations </desc> <cmt> add https capabilities to dev server by adding https in nuxt config. </cmt> <cmt> the parameter could be true or options from </cmt> <cmt> fix(package.json): upgrade vue-loader from 13.7.0 to ^13.7.2 for prettier issue (#3385) </cmt> <cmt> chore(release): upgrade nuxt from 1.4.0 to 1.4.1 </cmt> <cmt> fix: upgrade vue for fixing ssr vulnerability </cmt> <cmt> 1.4.2 </cmt> <cmt> add options in cli to enable unix sockets </cmt> <cmt> fix: conflicts </cmt>,builtin support of https and unix sockets
567,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> multi-valued headers and query string prarameters </cmt>",multi-value headers and query params in api gateway and authorizer events
568,"<desc> fixes #6023 this pr looks scary but there's (almost) no new code, simply lines moving around. the exception to the no-new-code is the addition of some methods to the coreinterface api (see core_codegen_interface.h and core_codegen.{h,cc}). </desc> <cmt> removed codegen/alloc.h </cmt> <cmt> removed codegen/byte_buffer.h </cmt> <cmt> removed codegen/time.h </cmt> <cmt> removed codegen/log.h </cmt> <cmt> removed codegen/slice_buffer.h and scrubbed codegen/slice.h </cmt> <cmt> scrubbed codegen/sync.h </cmt>",removed references to public apis from codegen/
569,<desc> use a perception blocking estimate function to skip side pass stop onto reverse lane when front view of adv is clear </desc> <cmt> planning: add isperceptionblock check function for side pass onto reverse lane </cmt> <cmt> planning: code side pass config deprecation </cmt>,add perception blocking estimate function for side pass stop
570,"<desc> at fastcomments we've recently launched our react plugin, and have been testing it with gatsby (which you can see here). i've included the link to the example usage as part of this change. i thought it would be helpful to add fastcomments to the list of supported solutions. :) </desc> <cmt> adding fastcomments to list embedded comment solutions </cmt> <cmt> includes link to examples. </cmt> <cmt> better link name </cmt>",adding fastcomments to comments doc
571,"<desc> hey @robbyrussell, this one is based on cabal plugin. used the default list of available stack commands: available commands: build                    build the project(s) in this directory/configuration install                  build executables and install to a user path test                     build and test the project(s) in this directory/configuration bench                    build and benchmark the project(s) in this directory/configuration haddock                  generate haddocks for the project(s) in this directory/configuration new                      create a brand new project init                     initialize a stack project based on one or more cabal packages solver                   use a dependency solver to try and determine missing extra-deps setup                    get the appropriate ghc for your project path                     print out handy path information unpack                   unpack one or more packages locally update                   update the package index upgrade                  upgrade to the latest stack (experimental) upload                   upload a package to hackage dot                      visualize your project's dependency graph using graphviz dot exec                     execute a command ghc                      run ghc ghci                     run ghci in the context of project(s) ide                      run ide-backend-client with the correct arguments runghc                   run runghc clean                    clean the local packages docker                   subcommands specific to docker use will look something like that: cheers! </desc> <cmt> add simple stack commands list </cmt> <cmt> remove unnecessary sandbox fn </cmt>",add haskell stack commands list
572,"<desc> this pr adds support for locking as proposed in nuxt/rfcs#23 i was not sure about the usefulness of locking when running nuxt dev, but will add it if you think it should also support it. </desc> <cmt> feat: lock project during build/generate </cmt> <cmt> chore: fix tests </cmt> <cmt> fix: also release lockpath from lockpaths set </cmt> <cmt> fix: remove merge issue </cmt>",lock project during build or generate
573,"<desc> following up on a suggestion by @charris in #9229 . adds an equal_nan kwarg that toggles whether nan's are considered equivalent when compared (default is false, which is the current behavior). this kwarg is consistent with that of related functions like isclose and allclose. this would close at least part of #9229, though there is other discussion in that issue about np.testing.assert_array_equal. </desc> <cmt> enh: add equal_nan kwarg to array_equal. </cmt> <cmt> match the corresponding kwarg and behavior from related functions </cmt> <cmt> like allclose. </cmt> <cmt> tst: add tests for array_equal equal_nan kwarg </cmt> <cmt> doc: added documentation for equal_nan kwarg. </cmt>",add equal_nan keyword argument to array_equal
574,"<desc> removed the installation and running of mypy from .github/workflows/lint_python.yml. this was done as pyright is now being used for type checking (as per contributing.md) and already has a functional test which is limited to specified files. the mypy test is then redundant, and incredibly inefficient due to checking everything. removing mypy from ci testing shaves ~11 minutes off. unless i'm mistaken and mypy is used in testing for some other reason that i'm not seeing. at the very least, if mypy must be used in test, i think it should use a more proper configuration to limit what it searches to a reasonable time (just as the pyright test does). </desc> <cmt> test actions </cmt> <cmt> removed mypy check and un-indent </cmt> <cmt> re-indent </cmt> <cmt> deleted test comment </cmt>",removed mypy from ci tests
575,"<desc> towards: #3020 in linear_models such as lasso there is an option to select normalize=true. however, if fit_intercept is set to false this won't have any effect. towards depreciating normalize in linear_models altogether we want to give a user an option to first normalize using standardscaler and then call the linear_model. this tests make sure that the two options will give the same results and the same .coef_ (event though .intercept_ might differ) the tests are done for both the sparse and the dense datasets </desc> <cmt> started working on the test to check if the pipeline: standardscaler-> linear_model(normalize=false) gives the same result as linear_model(normalize=true) </cmt> <cmt> updated assert statement </cmt>",tst check equivalence normalize/standardscaler and dense/sparse in linear models
576,"<desc> this is an update to pull request #423, to move exception classes out of wrappers.py </desc> <cmt> on json requests, the json response should have content-type: application/json and the body of the response should be a json object. </cmt> <cmt> move jsonhttpexception and jsonbadrequest to new module flask.exceptions. </cmt>","add new exceptions module, to implement jsonhttpexception and jsonbadrequest."
577,"<desc> this is the master version of #19601.  there isn't much different in layernormalization implementation between v1.x and master. all changes have test coverage; already covered by unittest for layer normalization. copy marian optimized cpu layernorm implementation and adapt to mxnet. refactor dispatch of optimized versions using bool return value. remove mkl call see #19601 for benchmarks. </desc> <cmt> layer normalization code from marian </cmt> <cmt> remove mkl version of layernorm. </cmt> <cmt> experiment with omp_num_threads=4, times in s, c5.12xlarge </cmt> <cmt> |batchxchanne| new code | mkl      | </cmt> <cmt> |    1x   32 | 0.0000288| 0.0000278| </cmt> <cmt> |  128x   32 | 0.0000308| 0.0000311| </cmt> <cmt> | 2560x   32 | 0.0000712| 0.0000672| </cmt> <cmt> | 4096x   32 | 0.0000946| 0.0000910| </cmt> <cmt> | 8192x   32 | 0.0001597| 0.0001523| </cmt> <cmt> |16384x   32 | 0.0002905| 0.0002619| </cmt> <cmt> |    1x   64 | 0.0000264| 0.0000256| </cmt> <cmt> |  128x   64 | 0.0000339| 0.0000330| </cmt> <cmt> | 2560x   64 | 0.0000829| 0.0000972| </cmt> <cmt> | 4096x   64 | 0.0001137| 0.0001356| </cmt> <cmt> | 8192x   64 | 0.0002027| 0.0002435| </cmt> <cmt> |16384x   64 | 0.0003715| 0.0004639| </cmt> <cmt> |    1x  128 | 0.0000262| 0.0000263| </cmt> <cmt> |  128x  128 | 0.0000325| 0.0000389| </cmt> <cmt> | 2560x  128 | 0.0001074| 0.0001580| </cmt> <cmt> | 4096x  128 | 0.0001505| 0.0002336| </cmt> <cmt> | 8192x  128 | 0.0002861| 0.0004481| </cmt> <cmt> |16384x  128 | 0.0005648| 0.0008613| </cmt> <cmt> |    1x  256 | 0.0000273| 0.0000276| </cmt> <cmt> |  128x  256 | 0.0000390| 0.0000431| </cmt> <cmt> | 2560x  256 | 0.0001533| 0.0002811| </cmt> <cmt> | 4096x  256 | 0.0002258| 0.0004300| </cmt> <cmt> | 8192x  256 | 0.0004300| 0.0008464| </cmt> <cmt> |16384x  256 | 0.0010436| 0.0017613| </cmt> <cmt> |    1x  512 | 0.0000256| 0.0000302| </cmt> <cmt> |  128x  512 | 0.0000408| 0.0000551| </cmt> <cmt> | 2560x  512 | 0.0002444| 0.0005225| </cmt> <cmt> | 4096x  512 | 0.0003828| 0.0008147| </cmt> <cmt> | 8192x  512 | 0.0008832| 0.0017192| </cmt> <cmt> |16384x  512 | 0.0058463| 0.0074497| </cmt> <cmt> |    1x  768 | 0.0000252| 0.0000308| </cmt> <cmt> |  128x  768 | 0.0000450| 0.0000676| </cmt> <cmt> | 2560x  768 | 0.0003440| 0.0007719| </cmt> <cmt> | 4096x  768 | 0.0005890| 0.0013346| </cmt> <cmt> | 8192x  768 | 0.0014946| 0.0026145| </cmt> <cmt> |16384x  768 | 0.0089495| 0.0113557| </cmt> <cmt> |    1x 1024 | 0.0000285| 0.0000308| </cmt> <cmt> |  128x 1024 | 0.0000487| 0.0000786| </cmt> <cmt> | 2560x 1024 | 0.0004614| 0.0010190| </cmt> <cmt> | 4096x 1024 | 0.0008083| 0.0017376| </cmt> <cmt> | 8192x 1024 | 0.0059020| 0.0075588| </cmt> <cmt> |16384x 1024 | 0.0116553| 0.0146855| </cmt> <cmt> benchmark program </cmt> <cmt> python </cmt> <cmt> import mxnet as mx </cmt> <cmt> import time </cmt> <cmt> def time_procedure(shape, count): </cmt> <cmt> data = mx.nd.random_uniform(shape=shape, low=-1.0, high = 1.0) </cmt> <cmt> factors = mx.nd.random_uniform(shape=(shape[-1],)) </cmt> <cmt> mx.nd.waitall() </cmt> <cmt> begin = time.time() </cmt> <cmt> for i in range(0, count): </cmt> <cmt> out = mx.nd.layernorm(data, factors, factors) </cmt> <cmt> mx.nd.waitall() </cmt> <cmt> return (time.time() - begin) / count </cmt> <cmt> count = 200 </cmt> <cmt> for channel in [32, 64, 128, 256, 512, 768, 1024]: </cmt> <cmt> for batch in [1, 128, 2560, 4096, 8192, 16384]: </cmt> <cmt> s = (batch, channel) </cmt> <cmt> timing = time_procedure(s, count) </cmt> <cmt> print(""{:5d}x{:5d} | {:.7f}"".format(s[0], s[1], timing)) </cmt> <cmt>  </cmt>",layer normalization code from marian for cpu
578,<desc> request to add completed keymaps for the terminus_mini custom handwired 4x12 ortholinear keyboard and the divergejm layout (an application of the terminus_mini default layout) for the nyquist split  5x12 ortholinear keyboard. </desc> <cmt> first commit of the terminus_mini firmware and the divergejm version of the nyquist firmware </cmt> <cmt> fix terminus_mini & nyquist/divergejm readme files </cmt> <cmt> previously an outdated copy of the default readme. updated to match the  nyquist/divergejm format (divergejm is a split 5x12 implementation of the terminus_mini layout) </cmt>,add terminus_mini keyboard and nyquist/divergejm layout
579,"<desc> breaking change: description: creation of a new sensor class in enocean component to support hoppe window handle (position sensor) related issue (if applicable): n/a pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#11499 example entry for configuration.yaml (if applicable): sensor: - name: patio_door_enocean_19ad1dc platform: enocean id: [0xde,0xed,0xbe,0xff] device_class: windowhandle checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> added support for somfy rts wireless power socket and </cmt> <cmt> somfy temperature sensore thermos wirefree io </cmt> <cmt> added code formatting fixes for commit 5faaf9c </cmt> <cmt> added support for rollershutterrtscomponent from somfy </cmt> <cmt> added support for rts roller shutter in set_cover_position </cmt> <cmt> deleted old files for merge </cmt> <cmt> added support for enocean window handle fa 10 00 (hoppe) </cmt>",add support for enocean window handle fa 10 00 (hoppe)
580,"<desc> this pr actually contains two changes: leverage on the topology_optimization config to ""adjust"" the topology internally to reuse the source topic. fixed a long dangling bug that whenever source topic is reused as changelog topic, write the checkpoint file for the consumed offset, this is done by union the ackedoffset from the producer, plus the consumed offset from the consumer, note we will priori ackedoffset since the same topic may show up in both (think about repartition topic), by doing this the consumed offset from source topics can be treated as checkpointed offset when reuse happens. added a few unit and integration tests with / wo  the reusing, and make sure the restoration, standby task, and internal topic creation behaviors are all correct. </desc> <cmt> add adjust logic </cmt> <cmt> add unit tests for the change </cmt> <cmt> remove imports </cmt>",reuse source based on config
581,"<desc> the graceful-fs has its own way of wrapping around fs module, which bypasses our monkey-patching on it, this pr fixes it by providing fake fs.js source code to graceful-fs. fixes #1078. </desc> <cmt> spec: test graceful-fs </cmt> <cmt> enable wrap arbitrary fs object </cmt> <cmt> redirect process.binding('natives').fs to global fs object </cmt> <cmt> spec: graceful-fs should not touch global fs object </cmt> <cmt> don't touch global fs object in graceful-fs </cmt> <cmt> fix string escaping </cmt> <iss> graceful-fs is not compatible with asar archives </iss>",make asar support work with graceful-fs
582,"<desc> this is a workaround to fix weak linking of frameworks that define types with availability, but then define extensions of those types without availability. this can come up if the framework itself is built with a newer deployment target than the client that uses the framework. since the type checker only enforces that an extension has availability if the extension is less available than the deployment target, we were failing to weak link the members of the extension in this case. this is not a perfect fix; ideally such frameworks should be built with -require-explicit-availability, and all reported warnings fixed by adding explicit availability. however, it allows clients to weak link when using existing swiftinterface files that have already shipped in the mean time, and it should not cause any problems once the frameworks are properly annotated in the future. fixes rdar://problem/58490723. </desc> <cmt> sema: improve -require-explicit-availability diagnostic phrasing </cmt> <cmt> driver: actually pass -require-explicit-availability{,-target} to frontend jobs </cmt> <cmt> unless you do this, the flag has no effect when used with the driver; </cmt> <cmt> it only worked in conjunction with -xfrontend. </cmt> <cmt> noticed while working on <rdar://problem/58490723>. </cmt> <cmt> ast: weak-link declarations in extensions of weak-linked types </cmt> <cmt> this is a workaround to fix weak linking of frameworks that define </cmt> <cmt> types with availability, but then define extensions of those types </cmt> <cmt> without availability. </cmt> <cmt> this can come up if the framework itself is built with a newer </cmt> <cmt> deployment target than the client that uses the framework. since the </cmt> <cmt> type checker only enforces that an extension has availability if </cmt> <cmt> the extension is less available than the deployment target, we were </cmt> <cmt> failing to weak link the members of the extension in this case. </cmt> <cmt> this is not a perfect fix; ideally such frameworks should be built </cmt> <cmt> with -require-explicit-availability, and all reported warnings </cmt> <cmt> fixed by adding explicit availability. </cmt> <cmt> however, it allows clients to weak link when using existing </cmt> <cmt> swiftinterface files that have already shipped in the mean time, </cmt> <cmt> and it should not cause any problems once the frameworks are properly </cmt> <cmt> annotated in the future. </cmt> <cmt> fixes <rdar://problem/58490723>. </cmt>",weak-link declarations in extensions of weak-linked types [5.2]
583,"<desc> this pr adds a support for home / end keys in intellisense. i had basically the very same expectaction / feeling as given in #18656. everything is pretty straight-forward except: i wasn't able to locate tests for suggestwidget, listwidget, am i missing something? i don't really know how to trigger details view (from end user perspective) so i couldn't test it. please make sure to check it or provide me an example steps on how to trigger it. i know nothing about mac hotkeys, so the default mapping included only home and end key which are present on windows / linux. </desc> <cmt> added focusfirst / focuslast methods for intellisense dropdown. support for details view/state is yet to come. </cmt> <cmt> added handling for suggestion details view. </cmt>",added support for home/end key in intellisense
584,"<desc> [ x add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  the original @types/engine.io has: * whether to let engine.io handle the options requests. you can also pass a custom function to handle the requests (true) */ handlepreflightrequest?: boolean|((server: server, req: http.incomingmessage, res: http.serverresponse) => void); but in engine.io, this is executed with handlepreflightrequest.call(server, req, res), so server is this not an argument. if ('options' === req.method && 'function' === typeof options.handlepreflightrequest) { options.handlepreflightrequest.call(server, req, res); </desc> <cmt> fixed test </cmt> <cmt> removed server as first arg in handlepreflightrequest </cmt>",engine.io handlepreflightrequest arguments don't match function.
585,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test mongodb.   if the key does not exist for any document in the mongo collection, the command returns an empty array i can't provide the full codebase but the use case is a wrapper around mongo's nodejs package. here is the simplified (still accurate) code: // wrapper export class wrapper<tschema> { private readonly collection: collection<tschema>; constructor( dbcollection: collection<tschema> ) { this.collection = dbcollection; async distinct<key extends keyof withid<tschema>>( field: key, query: filterquery<tschema> = {} ) { return this.collection.distinct(field, query); // use case type user = { nickname?: string _db.users = new wrapper<user>(db.collection(""users"")) // current return type: promise<(string | undefined)[]> // expected return type:  promise<string[]> _db.users.distinct(""nickname"") note this is my first pr here, feel free to provide feedback about the pr and/or the code. </desc> <cmt> mongodb - distinct - add failing test </cmt> <cmt> mongodb - distinct - improve distinct typing </cmt>",handle optional properties case for mongodb 's distinct
586,"<desc> based on #11264 (and #11133) add axis specific driver definitions to determine proper timing parameters like step pulse width, delay after asserting dir level and maximum stepper frequency. the user can use settings in configuration_adv.h to override the parsed driver ic defaults. the new driver definitions are used to determine which tmc or l6470 are in use and need initialization. by default the allegro a4988 drivers are enabled for x, y, z and e0. more on this below. add new tmc macros that work by checking for a certain feature, rather than the dev checking for a list of driver types that support the feature. references to trams removed and will simply be handled by defining the four axis as tmc5130. however this pr doesn't yet move marlin to the library that supports the driver. differentiating between tmc2130 in spi configured mode and standalone mode is done by having two driver definitions; tmc2130 and tmc2130_standalone. the way i see it, the default use case for that driver is in configured mode and using standalone mode is a special case. in standalone mode only the stepper timings are affected and they pretty much act the same as tmc2100 as far as marlin is concerned. updates travis to use the new driver definition method so that they actually are tested. i decided to use the allegro drivers as the default to match what is the most common configuration in the user base. specifying any drivers is not forced but will default to drv8825 configuration, except for dir delay. this could be improved, or force defining at least one driver (unless overriden in _adv.h). i think the main question is if we know the parameters different drivers require, which should be used as the default? i think we should not use 0 delays as there is no driver compatible with such timings. however, this doesn't take into account the natural delay there is no matter what we do. this also leads to a more general configuration change that affects the stepper isr. perhaps we should no longer check if minimum_stepper_pulse is defined, because from hereon it always is, and rather check if the defined pulse width is greater than 20 for example. @ejtagle ? the compile time driver ic macros: axis_driver_type(a, t) check if an axis a has a driver type t associated with it. has_driver(t) check if the user has driver type t in any of the axis enabled. has_trinamic check if any supported trinamic drivers are enabled in any axis. axis_is_tmc(a) check if the specified axis a has a supported trinamic driver enabled. </desc> <cmt> add *_driver_type to example configs </cmt> <cmt> simplify stepper driver config </cmt>",configure stepper drivers per axis
587,"<desc> warning: md5 of file ""pdfs/issue2537.pdf"" does not match file. expected ""f56805a70ed3aa52aae5c16dd335f827"" computed ""dc5ed0e8f3725ac12398990938bf3fcd"" has some bad font warning: file was not downloaded. see ""pdfs/aboutstacks.pdf.error"" file. #926 2 year old, jpeg/smask. code path also tested by testissue3879.pdf or freeculture.pdf warning: file was not downloaded. see ""pdfs/issue2442.pdf.error"" file. just needs new node e.g. 0.10.26 (left issue3666 and issue4436) </desc> <cmt> missing test for #2537 (e4c3b4501dffe5bd) </cmt> <cmt> removs missing test file for #926 </cmt>",fixes tests for #926 and #2537
588,"<desc> fixes #3138 test case added for: tablescontext#findtablename, insertsqlstatementcontext#getgroupedparameters derivedcolumn#isderivedcolumnname </desc> <cmt> code style error correction and improved coverage for insertvaluecontext#setvalue </cmt> <cmt> sync into forked dev </cmt> <cmt> test case added for packages of projection.engine  and statement </cmt> <cmt> test case added for derivedcolumn#isderivedcolumnname </cmt> <cmt> test case added for insertsqlstatementcontext#getgroupedparameters </cmt> <cmt> test case added for tablescontext#findtablename </cmt> <cmt> test case added for tablescontext#findtablename </cmt> <cmt> inline some variable into method invocation lines </cmt> <iss> add more unit test cases for sharding-core-preprocessor module </iss>","for issue #3138,  improved coverage for package of preprocessor"
589,"<desc> fixes for rails 3.2. see pull request into 3-1-stable for more info: #5647 </desc> <cmt> adds a test that breaks im when using #select </cmt> <cmt> do not add record to identity map if the record doesn't have values for all the columns, so we don't get 'missingattributeerror' later when trying to access other fields of the same record. </cmt> <cmt> refactor the checking of the attributes of the record in identitymap#add, so it's more readable </cmt> <cmt> refactor instantiate method in base, so we remove nesting if's which make the code harder to read. minor changes to contain_all_columns in identitymap. </cmt> <cmt> conflicts: </cmt> <cmt> activerecord/lib/active_record/base.rb </cmt>",fixing identity map when using find select in rails 3.2
590,"<desc> fya @nikic the remaining legacy text encodings supported by mbstring which do not have adequate tests are: euc-jp-2004, iso-2022-kr, gb18030, and big5. then we have base64, html entities, qprint, and uuencode. i would like to suggest that we deprecate the use of mbstring to convert to/from html entities or uuencode... i think there are other built-in functions to handle those. </desc> <cmt> fix conversion of hz text (and add test suite) </cmt> <cmt> - treat truncated multi-byte characters as an error. </cmt> <cmt> - don't allow ascii control characters to appear in the middle of a </cmt> <cmt> multi-byte character. </cmt> <cmt> - handle ~ escapes according to the hz standard (rfc 1843). </cmt> <cmt> - treat unrecognized ~ escapes as an error. </cmt> <cmt> - multi-byte characters (between ~{ ~} escapes) are gb2312, not cp936. </cmt> <cmt> (cp936 is an extended version from microsoft, but the rfc does not </cmt> <cmt> state that this extended version of gb should be used.) </cmt> <cmt> fix conversion of cp936 text (and add test suite) </cmt> <cmt> - treat truncated multi-byte characters as an error. </cmt> <cmt> - don't allow ascii control characters to appear in the middle of a </cmt> <cmt> multi-byte character. </cmt> <cmt> - adjust some mappings to match recommendations in conversion table </cmt> <cmt> from unicode consortium. </cmt> <cmt> remove table generation scripts which have not been used for years </cmt> <cmt> fix conversion of euc-kr text (and add test suite) </cmt> <cmt> - treat truncated multi-byte characters as an error. </cmt> <cmt> - don't allow ascii control characters to appear in the middle of a </cmt> <cmt> multi-byte character. </cmt> <cmt> - there was also a bug whereby some unrecognized unicode codepoints </cmt> <cmt> would be passed through to the output unchanged when converting </cmt> <cmt> unicode to euc-kr. </cmt> <cmt> fix conversion of euc-cn text (and add test suite) </cmt> <cmt> - flag truncated multi-byte characters as erroneous. </cmt> <cmt> - don't allow ascii control characters to appear in the middle of a </cmt> <cmt> multi-byte character. </cmt> <cmt> - there was a bug whereby some unrecognized unicode codepoints would be </cmt> <cmt> passed through unchanged to the output when converting unicode to </cmt> <cmt> euc-cn. </cmt> <cmt> - stick to the original euc-cn standard, rather than cp936 (an extended </cmt> <cmt> version invented by ms). </cmt>",major overhaul of mbstring (part 8)
591,"<desc> add or edit tests to reflect the change. (run with npm test.) avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. i tried my best to keep backwards compatibility with existing types. the new @deprecated annotations will annoy those that use tslint's deprecation rule (as is intended). unfortunately, there does not seem to be any way to use apply an interface to a class' constructor. it's also not acceptable, to the compiler, to depend on a class' generic arguments in a static method, when that is exactly the correct thing to use in this instance. i tried to make it slightly safer to use by providing a type for the static method, but i'm not sure if there is a good way to express this correctly in typescript. it's also not possible to have mutually-exclusive methods. the mere presence of either of the two new lifecycle methods will prevent all of the @deprecated lifecycle methods from being invoked at runtime, which i did my best to document in the jsdoc comments. </desc> <cmt> add new lifecycle events to react (16.3) </cmt> <cmt> add tests, fix lint </cmt> <cmt> bump version </cmt>",add new react 16.3 lifecycle events
592,<desc> just doing some small cleanups before i fix a bug here. </desc> <cmt> [silgen] use early exits and invert an if condition to reduce indentation. </cmt> <cmt> [silgen] eliminate another level of indentation by inverting an if statement and using a continue. </cmt>,remove some unnecessary indentation from silgenpattern::emitswitchstmt
593,"<desc> moving from mouse_event to sendinput using absolute mouse positioning. </desc> <cmt> getting changes </cmt> <cmt> merge remote-tracking branch 'octalmage/master' </cmt> <cmt> pulling changes </cmt> <cmt> merge remote-tracking branch 'refs/remotes/octalmage/master' </cmt> <cmt> merging with origin </cmt> <cmt> test fix for node 0.8 failing. </cmt> <cmt> this was suggested by someone. just checking it out. </cmt> <cmt> catchup </cmt> <cmt> catchup </cmt> <cmt> migrate to sendinput for mouse movement </cmt> <cmt> since mouse_event is deprecated we are moving to sendinput. </cmt> <cmt> migrate to sendinput for mouse movement </cmt> <cmt> revert ""test fix for node 0.8 failing."" </cmt> <cmt> this reverts commit eb18a1fc388d51a4f7050d3dd20a72ee8973bc30. </cmt>",migrate to sendinput from mouse_event
594,"<desc> this fixes the hwdb syntax error in issue #4728 and adds a test that makes sure that this doesn't happen again. the first commit  was my attempt to fix hwdb/parse_hwdb.py. it's by far not sufficient, so i leave pyparsing uninstalled for now to continue to skip that test, but i think it doesn't hurt to keep that one fix. </desc> <cmt> hwdb/parse_hwdb.py: open files with utf-8 mode </cmt> <cmt> pyparsing uses the system locale by default, which in the case of 'c' (in lots </cmt> <cmt> of build environment) will fail with a unicodedecodeerror. explicitly open it </cmt> <cmt> with utf-8 encoding to guard against this. </cmt> <cmt> hwdb: fix syntax error in 60-keyboard.hwdb </cmt> <cmt> fixes #4728 </cmt> <cmt> tests: add hwdb parsing test </cmt> <cmt> this calls the built ""systemd-hwdb update"" on the source tree's hwdb/ in a </cmt> <cmt> temporary directory and verifies that there are no error messages. </cmt>",fix hwdb syntax error and add test for it
595,"<desc> for example, i want to use request.async and save cookies to session: import requests from requests import async s = requests.session() async.map([async.get(' print 'cookies:', s.cookies cookies are empty. it's because when session.request() is called with return_response=false, it returns request without updating session cookies sessions.py#l234 so, i think we can solve it by moving cookies saving logic to request._build_response(). or maybe there is more suitable place? </desc> <cmt> test if cookies are saving to session when session.request is called with return_response=false </cmt> <cmt> test async requests with session cookies </cmt> <cmt> move session cookie saving from session.request() to  request._build_response() </cmt>",session cookies not saved when session.request is called with return_response=false
596,"<desc> added new keyboard to the boardsource folder as well as my map with more features enabled. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> microdox keyboard workidng </cmt> <cmt> updated readme </cmt> <cmt> cleaned up for pr </cmt>",add microdox keyboard to boardsource folder
597,"<desc> i saw the bundle property in the controller class, and it doesn't seem to be used at all, so i went ahead and made use of it along with adding a controller name and action property </desc> <cmt> bundle property wasn't being used, so i made use of it as well as adding the controllers name and action being called. </cmt> <cmt> update laravel/routing/controller.php </cmt>",controller property bundle ( and some additions )
598,<desc> this replaces the utarray and utlist c library implementation for the local scheduler's task queue with an implementation using the c++ stl. </desc> <cmt> switch to using c++ lists for task queues </cmt> <cmt> init and free methods for taskqueueentry </cmt> <cmt> switch from utarray to c++ vector for taskqueueentry </cmt>,implement local scheduler task queues using c++ data structures
599,"<desc> removes references to the kbfirmware json to qmk parser from boards where i was able to verify the layout data is correct. any remaining references are for boards where i wish to make further updates. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> remove refs: exclusive/e85/soldered </cmt> <cmt> remove refs: handwired/bigmac </cmt> <cmt> remove refs: handwired/boss566y/redragon_vara </cmt> <cmt> remove refs: handwired/marauder </cmt> <cmt> remove refs: id67 </cmt> <cmt> remove refs: kprepublic/bm60rgb </cmt> <cmt> remove refs: playkbtw/helen80 </cmt> <cmt> remove refs: sam/sg81m </cmt> <cmt> remove refs: sawnsprojects/satxri6key </cmt> <cmt> remove refs: yncognito/batpad </cmt>",remove references to kbfirmware json parser
600,"<desc> more than a simple rewrite, as we're using fuselage, our component toolkit. we introduce virtual lists and the search field. how to test or reproduce before after types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> prepare code to reuse </cmt> <cmt> contextual bar discussions list moved to react </cmt>",rewrite contextual bar discussion list in react
601,"<desc> thanks to the suggestion from frantisek and dimitri in #16414 the issue with dm-verity in the qemu images was solved, so adding coverage for the dm-verity features and options recently added to the ci integration tests. </desc> <cmt> test: exercise systemd-dissect --mount in test-50-dissect </cmt> <cmt> test: exercise systemd-dissect with gpt and verity in test-50-dissect </cmt> <cmt> test: pre-assemble minimal image for test-50-dissect at build time </cmt> <cmt> easier than in the limited vm environment </cmt> <cmt> test: exercise rootimage, roothash and rootverity in test-50-dissect </cmt> <cmt> run with both the single-filesystem image and the gpt image </cmt>",expand test-50-dissect to cover dm-verity features
602,"<desc> implements this jira ticket which makes simd vectors differentiable. also here is a link to the swift forums where some of this was discussed. see the forum post for any context regarding the changes. there is also the change to the -=/+= operator. as background, we need simd to conform to the additivearithmetic  protocol which already provides a conditional definition of the -= and += operator. so to avoid the ""dual default conditional definition protocol"" issue, i removed the default implementation in simd for now on our branch, but we will fix it when we pitch it to get it merged into master. also, i had to remove @_alwaysemitintoclient from sum() due to a bug (filed as tf-545). and finally, there are custom vjps that i defined that don't actually need to be defined, as the body of the original methods define methods that i already marked as differentiable. but the bug tf-547 is blocking me on that. </desc> <cmt> initial broken version. </cmt> <cmt> add vectorview. </cmt> <cmt> wip while waiting for swift forums answer. </cmt> <cmt> wip: removed from additivearithmetic, kept in cimd. </cmt> <cmt> remove += from simd protocol, move it to struct simdn. </cmt> <cmt> have simdn conform to differentiable. </cmt>",conditionally conform simd types to differentiable
603,<desc> this pr introduces trtoptimizationpass to run tensorrt conversion automatically as an optimization pass at the time of running and also adds necessary components to integrate tensorrt memory allocation into tensorflow memory systems. </desc> <cmt> introducing trtoptimizationpass </cmt> <cmt> use tf allocator for allocating tensorrt memory </cmt> <cmt> fix an issue in build_pip_package.sh </cmt> <cmt> clang-format and version fix </cmt>,optimization pass and memory allocator integration
604,"<desc> providing first pull request for personal keymap and readme. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> merging recent changes </cmt> <cmt> personal keymap and readme to go along with it. </cmt>",personal keymap for dztech dz60rgb plus readme.md
605,<desc> related issue: -- adds support for setting the number of blur samples in the separable blur passes when using vsm shadow maps. previously a fixed count of 8 samples was being used which is more than needed to get a good blur in some cases and a lot less than needed in others. with this pr the user can set the amount of blur samples using the blursamples field: directionallight.shadow.blursamples = 10; radius dev 4 samples 8 samples 16 samples 2 16 </desc> <cmt> remove unneeded dir light add call </cmt> <cmt> add support for blur iterations to vsm shadows </cmt> <cmt> add samples options to vsm example </cmt> <cmt> add folders </cmt> <cmt> docs update </cmt> <cmt> support blursamples === 1.0 </cmt> <cmt> fix early out </cmt>,add support for setting the number of blur samples
606,"<desc> continuation of #48536 dependds on #49319 basically an api cleanup of #48536 related issues #32143 fixes #44510 b/144232910 #48305 fixes #48775 i added the following tests: tests for new provider, new method on image cache (containskey), image behavior in a scrolling list. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: flutter/website#3622 </desc> <cmt> recommenddeferredloading </cmt> <cmt> newline </cmt> <cmt> another test </cmt> <cmt> typo </cmt> <cmt> start </cmt> <iss> high images ram consumption </iss> <iss> how to stop image load when scrolling list ? </iss>",defer image decoding when scrolling fast
607,"<desc> closes #12067 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry simplifies index.__new__ a bit </desc> <cmt> enh: allow start=range_object in rangeindex.__new__ </cmt> <cmt> whatsnew </cmt> <iss> api: should the rangeindex constructor accept start=range_index? </iss>",allow start=range_object in rangeindex constructor
608,<desc> $ mypy --strict data_structures/binary_tree/treap.py data_structures/binary_tree/lazy_segment_tree.py data_structures/binary_tree/binary_search_tree_recursive.py success: no issues found in 3 source files related issue: #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> fix mypy: data_structures:binary_tree </cmt> <cmt> mypy --strict for binary_trees in data_structures </cmt>,add/fix type annotations for binary trees in data structures
609,"<desc> improve warnings and errors handling in stats respect warningsfilter for warnings count include child compilation warnings and errors in count show hint for child compilation errors and warnings add config.ignorewarnings deprecate stats.warningsfilter refactoring yes no, only deprecation stats.warningsfilter is deprecated ignorewarnings is the new option regexp {module?: regexp, file?: regexp, message?: regexp} function(webpackerror, compilation): boolean </desc> <cmt> improve warnings and errors handling in stats </cmt> <cmt> respect warningsfilter for warnings count </cmt> <cmt> include child compilation warnings and errors in count </cmt> <cmt> show hint for child compilation errors and warnings </cmt> <cmt> add config.ignorewarnings </cmt> <cmt> deprecate stats.warningsfilter </cmt>",deprecate stats.warningsfilter in favor of ignorewarnings
610,"<desc> following the implementation template used in methods map and _filter, use  the contiguousarray internally in default implementations of  droplast, prefix and suffix. this is converted into an array on return in a constant time. in addition to increased consistency of the internal implementation, this noticeably improves the performance of these methods for unfoldsequence benchmark variants in the unoptimized build. this pr is based on discussion in #20221 (review) and was split off from an experiment in #20758. </desc> <cmt> [stdlib] gardening: ringbuffer position index </cmt> <cmt> [stdlib] droplast, prefix, suffix: contiguousarray </cmt> <cmt> nano-optimization: </cmt> <cmt> following the template used in methods map and _filter, internally use contiguousarray before converting to an array on return. </cmt>","use contiguousarray internally in sequence droplast, prefix, suffix"
611,"<desc> fixes #84841 fixes #86753 some queries are not built to accept types with inference variables, which can lead to ices. these queries probably ought to be converted to canonical form, but as a quick workaround, we can return conservative results in the case that inference variables are found. we should file a follow-up issue (and update the fixmes...) to do the proper refactoring.  r? @oli-obk </desc> <cmt> add test case </cmt> <cmt> introduce helper function </cmt> <cmt> remove unused option </cmt> <cmt> allow inference vars in  type_implements_trait </cmt> <cmt> be conservative in has_significant_drop </cmt> <iss> internal compiler error with async, const generics, and ?-operator </iss> <iss> ice when running `cargo +nightly fix --edition` on tokio </iss>",ignore inference variables in certain queries
612,"<desc> index can be use in tickformat function. hence added it as optional parameter. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> added index as optional parameter </cmt> <cmt> index can be use in tickformat function. hence added it as optional parameter. </cmt> <cmt> index updated </cmt> <cmt> added author </cmt> <cmt> updated the version </cmt>",d3 v3 (added index as optional parameter in interface axis tickformat)
613,"<desc> this pr is one of a series that aims to improve this integration  make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, ""[airflow-xxx] my airflow pr""  in case you are fixing a typo in the documentation you can prepend your commit with [airflow-xxx], code changes always need a jira issue. in case you are proposing a fundamental code change, you need to create an airflow improvement proposal (aip). in case you are adding a dependency, check if the license complies with the asf 3rd party license policy. here are some details about my pr, including screenshots of any ui changes: my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release </desc> <cmt> [airflow-yyy] use parameterized in dataflow hook tests </cmt> <cmt> [airflow-yyy] move dataflow tests to other class </cmt> <cmt> [airflow-yyy] add tests when job starts without an custom interpreter </cmt> <cmt> [airflow-yyy] add dataflow tests with various job statuses </cmt>",add more tests for dataflow integration
614,<desc> docs-translations-detail-guide custom_quantum_functions.md flashing.md getting_started_build_tools.md getting_started_vagrant.md getting_started_make_guide.md keymap.md my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add detail-guide part </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt> <cmt> some updates for easy reading </cmt>,add japanese translation (detail guide part)
615,"<desc> improved defaults for scroll view primary-ness vertical scroll views default to primary:true. horizontal scroll views default to primary:false. if a scroll view is primary and it got a non-null inherited primary scroll controller, it introduces a primary scroll controller inherited with a value of null for its descendants. scrollcontroller now multiplexes writes to all registered positions; reads of position continue to assert that only one position is registered. </desc> <cmt> improved defaults for scroll view primary-ness </cmt> <cmt> * vertical scroll views default to primary:true. </cmt> <cmt> * horizontal scroll views default to primary:false. </cmt> <cmt> * if a scroll view is primary and it got a non-null inherited primary </cmt> <cmt> scroll controller, it introduces a primary scroll controller inherited </cmt> <cmt> with a value of null for its descendants. </cmt> <cmt> scrollcontroller now multiplexes writes to all registered positions; </cmt> <cmt> reads of position continue to assert that only one position is </cmt> <cmt> registered. </cmt> <cmt> broadcast scroll position writes to all positions </cmt> <cmt> reads still require only a single position. </cmt> <cmt> add primaryscrollcontroller.none constructor </cmt> <cmt> insert a null primaryscrollcontroller under a primary scrollable </cmt>",better defaulting for scroll view primary-ness
616,"<desc> this pr adds a disabled by default flag to the silverifier called ""enforcesilownership"". when the flag is enabled, the silverifier will verify that sil ownership contraints are followed by the ir. today it just means that unqualified loads/stores are banned from the ir. rdar://28685236 </desc> <cmt> [semantic-arc] add {store,load}ownershipqualifierenums and add them to loadinst, storeinst. </cmt> <cmt> this is a nfc change since the constructors of loadinst, storeinst always set </cmt> <cmt> the ownership qualifiers to unqualified by default. there are no external users </cmt> <cmt> to loadinst, storeinst of this code. </cmt> <cmt> rdar://28685236 </cmt> <cmt> [semantic-arc] teach sil how to print/parse ownership qualified load, store instructions. </cmt> <cmt> rdar://28685236 </cmt> <cmt> [semantic-arc] implement sil serialization support for ownership qualified store and load. </cmt> <cmt> rdar://28685236 </cmt>",enforce sil ownership sil verifier
617,"<desc> add information for isp flashing the atmega32a (on a jj40) steps/procedure confirmed for ""just the bootloader file"" and ""advanced/production techniques"" in the ""flashing your bootloader/production file"" section, the qmk toolbox portion does not work, but don't know if putting a warning there is necessary (the atmega32a is kind of an edge case - probably would be more confusing for most and is better left out?). this pr is related to #4914 </desc> <cmt> update isp flashing page </cmt> <cmt> update isp flashing page </cmt>",isp flashing guide - atmega32a info
618,"<desc> having an abstract class that the rest of the graphics implementations extend from allows us to keep implementations clean while adding the option of adding useful common methods to it. the following methods have been added to graphics that are implemented on abstractgraphics: void clear(float r, float g, float b, float a) void clear(color color) float getbackbufferscale () the most important change has been to iosgraphics that has required a bit of refactoring not to extend nsobject but it's a positive change. there are also several other minor improvements (documentation, code style, etc...) that made sense to include. tested on android, ios and desktop (lwjgl2). </desc> <cmt> create base abstractgraphics class </cmt> <cmt> added gdx.gwt.xml entry </cmt>",add an abstract graphics class
619,"<desc> cfg_cflags is only used for jemalloc we grew an extra set of flags for jemalloc (cfg_jemalloc_cflags) in addition to cfg_cflags this kills of cfg_cflags and keeps the more specific and less confusing cfg_jemalloc_cflags additionally, pass cfg_jemalloc_cflags to jemalloc's configure slightly differently so things work when people use --sysroot in their cflags. </desc> <cmt> cfg_cflags is only used for jemalloc, rename all uses to cfg_jemalloc_cflags </cmt> <cmt> i386-apple-ios already used cfg_jemalloc_cflags, so merge that one </cmt> <cmt> mk/rt/jemalloc: pass cfg_gccish_cflags inside cc instead of passing cfg_cflags in extra_cflags </cmt> <cmt> - cfg_cflags is gone (it was previously only used by jemalloc anyhow). </cmt> <cmt> - cfg_jemalloc_cflags may contain flags needed for the compiler to </cmt> <cmt> function (produce a binary output). </cmt> <cmt> - jemalloc's configure runs $(cc) without extra_cflags, and (without </cmt> <cmt> this change) will fail if any flags are required for cc to work. </cmt>",remove cfg_cflags in favor of cfg_jemalloc_cflags_flags
620,"<desc> this adds fixes for the nullok changes made across the api. the changes these fix are expected to be widely breaking, so providing fixes will be immensely helpful to users. proposing for cherry pick.  migration guide lists and links to all associated changes: flutter/website#4921 part of #74908 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test exempt. i updated/added relevant documentation (doc comments with ///). i signed the cla. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> mediaq </cmt> <cmt> add generics </cmt> <cmt> nav </cmt> <cmt> scaffoldmessenger </cmt> <cmt> scaffold </cmt> <cmt> router </cmt> <cmt> localizations </cmt> <cmt> focus, focusordertraversal, focusordergroup </cmt> <cmt> actions and shortcuts </cmt> <cmt> animatedlist and sliveranimatedlist </cmt> <cmt> cupertino fixes </cmt>",add fixes for nullok changes
621,<desc> i hereby agree to the terms of the cla available at:  short description (up to few sentences): fix bug with when table contains only tuple columns or columns with complex paths. fixes 7541. </desc> <cmt> fix bug when table contains only tuple columns </cmt> <cmt> add tests </cmt> <iss> data loss when use a tuple as the primary key </iss>,fix only tuple columns in table.
622,<desc> includes fixes for mac osx build issues - 461 </desc> <cmt> changes to address arrow-826 and arrow-444 </cmt> <cmt> changes to address arrow-826 and arrow-444 </cmt> <cmt> ignoring cmake-build-debug </cmt> <cmt> additional idea ignore files </cmt> <cmt> additional idea ignore files </cmt> <cmt> remove arrow ipc and arrow io libraries </cmt> <cmt> add boost dependencies </cmt> <cmt> fix arrow origin and remove submodule </cmt>,fixes mac osx installation error
623,"<desc> this patch changes the adaptive concurrency filter's minrtt measurement behavior to additionally trigger a minrtt calculation if there have been 5 consecutive concurrency limit updates at the minimum concurrency. previous minrtt behavior is still maintained, but the new condition resets the timer on the minrtt calculation. the minrtt convergence times should be improved for little to no observable differences in filter behavior. risk level: low testing: unit tests docs changes: yes release notes: yes </desc> <cmt> adaptive concurrency: trigger minrtt calculation after consecutively setting lowest concurrency </cmt> <cmt> docs </cmt> <cmt> version hist </cmt>",trigger minrtt calculation outside interval
624,"<desc> this starts a split up of test-util.c (which had the same problem as util.c, too unwieldy). also minor cleanup (sorting .gitignore, removing some unneeded include statements). retested that everything works with a ./autogen.sh c && make && make check && make distcheck from a clean tree. </desc> <cmt> build-sys: keep .gitignore sorted </cmt> <cmt> let's try to keep it that way! :-) </cmt> <cmt> test-extract-word: move extract-word tests into their own test case </cmt> <cmt> tests for the functions defined in src/basic/extract-word.c. </cmt> <cmt> tested that make check still passes as expected. </cmt> <cmt> test-parse-util: move parse-util tests into their own test case </cmt> <cmt> tests for the functions defined in src/basic/parse-util.c. reorder them </cmt> <cmt> to match the order in which the functions are defined in the source </cmt> <cmt> file. adjusted the list of include files to remove the ones no longer </cmt> <cmt> needed in test-util.c. </cmt> <cmt> tested that make check still passes as expected. also checked the </cmt> <cmt> number of lines removed from test-util.c matches the expected, as an </cmt> <cmt> additional verification that no tests were dropped or duplicated in the </cmt> <cmt> move. </cmt>",move tests for extract-word and parse-util into separate test cases
625,"<desc> this pull request resolves several ie problems caused by doctype (jenkins-5335). </desc> <cmt> fix rendering problem in http proxy configuration page. </cmt> <cmt> - if rendered in ie7 standard mode, whole cells are gray when mouse hovers. </cmt> <cmt> - if rendered in ie8 and ie9 standard mode, there are glitchy lines on each </cmt> <cmt> cell. </cmt> <cmt> tables of system properties and environment variables are also 'bigtable' </cmt> <cmt> no borders on table cells in plugin manager </cmt> <cmt> - ie 7 standard </cmt> <cmt> - ie quirks </cmt>",fix rendering problems for ie standard mode
626,"<desc> missing export for the backported win32 platformcolor function, to give access to system colors such as those provided by high contrast themes. microsoft reviewers: open in codeflow </desc> <cmt> export platformcolor function that returns a system color object </cmt> <cmt> change files </cmt>",export win32 platformcolor function for system colors access
627,"<desc> the new operator helps to remove .shape calls in gluon and will make blocks hybridizable. more description here: dmlc/gluon-nlp#789 @eric-haibin-lin please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> add contrib.arange_like operator </cmt> <cmt> add parameter to template </cmt> <cmt> conflicts: </cmt> <cmt> src/operator/tensor/init_op.cc </cmt> <cmt> src/operator/tensor/init_op.h </cmt>",add a new arange_like operator to contrib
628,"<desc> this pr relates to #1038. basically what we are doing here is switching to ie11 on windows 7, which oddly greens the problematic empty node test that is currently not passing on ie11 windows 10 on sauce labs for no apparent reason. locally all ie11 versions work, windows 10 included. it must be some env bug in sauce labs. this pr also changes the way we connect to sauce labs, now leveraging the tunnel created by travis sauce connect addon. now sending all the relevant info (tunneldentifier, buildnumber, etc). this should fix the errors we saw on #1089. the base code of this pr was tested in sauce-test branch, logs from travis ( finally, this pr prepares the ground for #1124, which aims to test multiple node versions on travis. please let me know if this looks good </desc> <cmt> use travis sauce connect addon to connect to sauce labs </cmt> <cmt> set windows 7 as platform for testing ie11 on sauce labs </cmt> <cmt> use allow_saucelabs env variable to control sauce labs availability </cmt> <cmt> run karma sauce tests only once in case of multiple node versions being used on travis </cmt>",fixing master build on travis
629,"<desc> coverage was not calculated for direct response entries, only route entries. this change now marks those types of routes as covered. risk level: low testing: added in route_tests.sh docs changes: n/a release notes: included fixes #8438 </desc> <cmt> temp </cmt> <cmt> update test for coverage fail case, consolidate report functions </cmt> <cmt> formatting </cmt> <cmt> private helper functions, restore extensions </cmt> <cmt> format </cmt> <cmt> revert changes to build and tests </cmt> <cmt> remove redundant comment </cmt> <cmt> version history </cmt> <iss> coverage not calculated for routes with redirects or direct response </iss>",add coverage reporting for direct response entries
630,<desc> resolves remaining items from #11435. commits are atomic. </desc> <cmt> build script creates git tag </cmt> <cmt> build script post instructions print better relative paths </cmt> <cmt> pre-release (<1.0) version numbers also include pre-release suffix (eg '-beta.0') </cmt> <cmt> post-npm-publish step properly handles minor rev comparison check </cmt> <cmt> release script also updates @next tag when publishing @latest </cmt>,release script follow-up work after 16.1.0-beta release
631,"<desc> adds an implementation of hot restart for that web that refreshes the page. wires up the web hot runner to use the webkit inspection protocol to refresh, close, and listen to page events. refactors some of the web workflow apis and adds tests. adds devicelab tests (expected to fail until we install chrome) to test this workflow end to end. unrelated fixes #33767 </desc> <cmt> wire up real restart </cmt> <cmt> use page.reload </cmt> <cmt> add real-ish web restart </cmt> <cmt> add dependency </cmt> <cmt> dont lose previous fixes </cmt> <cmt> update chrome.dart </cmt> <cmt> remove dart:convert import </cmt> <cmt> fix chrome detection </cmt> <cmt> address comments </cmt> <cmt> add devicelab testing for web </cmt> <cmt> squashed commit of the following: </cmt> <cmt> commit edc8a73b963e7e5504c5397d567f3321f0f2d3d9 </cmt> <cmt> author: jonahwilliams <jonahwilliams@google.com> </cmt> <cmt> date:   fri may 31 20:42:12 2019 -0700 </cmt> <cmt> add forgotten headers </cmt> <cmt> commit eadb04575d8f3baedcda670e3c04dfc5e6e9f59c </cmt> <cmt> author: jonahwilliams <jonahwilliams@google.com> </cmt> <cmt> date:   fri may 31 20:29:59 2019 -0700 </cmt> <cmt> dont support running web without chrome </cmt> <cmt> commit a07516ce137824fa296beb0d1fec769afdbd879b </cmt> <cmt> author: jonahwilliams <jonahwilliams@google.com> </cmt> <cmt> date:   fri may 31 20:25:43 2019 -0700 </cmt> <cmt> cleanup web workflow and rename targetplatform to web </cmt> <cmt> update packages and build </cmt> <iss> weird unexplained bump in consumer dependency count </iss>","add a real-er web restart, doctor, workflow"
632,<desc> att ref #1875 </desc> <cmt> add an example to define loss function in python </cmt> <cmt> fix lint errors </cmt> <cmt> test python loss on gpu </cmt> <cmt> fix lstm example evaluation refactoring </cmt> <cmt> make the lstm example backward compatible with saved checkpoints (#1875) </cmt> <cmt> update ipython notebook </cmt>,backward compatibility with saved lstm checkpoints demo-ed at gtc
633,<desc> adds a unit test to verify that a wasm is rejected when the function body size is too large. updated several exceptions to be more specific. </desc> <cmt> add test for function body code size </cmt> <cmt> fix whitespace </cmt>,function body code size test
634,"<desc> the parent used to be the enumdecl itself. when enumelementdecls were refactored to themselves be declcontexts we never updated this part. it's not really important right now, but my validatedecl() request-ification changes require that the parent declcontext of a paramdecl is correctly set. </desc> <cmt> ast: correctly set parent declcontext of paramdecls in enumelementdecls </cmt> <cmt> when an enumelementdecl is parsed, we create the parameter list before </cmt> <cmt> creating the enumelementdecl itself, so we have to re-parent those </cmt> <cmt> paramdecls just like we do for functions and subscripts. </cmt> <cmt> ast: remove unused enumdecl::getelement() method </cmt>",correctly set the parent declcontext of paramdecls in enumelementdecls
635,"<desc> drupal test change: after change to use createnodeid in #5130 jsonapi id is no longer used as node id (it was moved to drupal_id), so i just removed that part of test and renamed the test package.json updates: both gatsby-source-wordpress and gatsby-source-drupal have dependency gatsby-source-filesystem@^2.0.0-alpha.8 (which was published 1 day ago) but yarn resolves that (i guess because of carret) to 2.0.0-alpha.f98688ee (which was published 2 months ago). this change should hopefully point to latest alpha. </desc> <cmt> update drupal test </cmt> <cmt> drupal/wordpress change filesystem version to next to avoid problematic resolutions with alpha versions </cmt>",drupal test fix + drupal/wordpress dependency change
636,<desc> it also restores v1 error formatting after: error building static html for pages failed see our docs page on debugging html builds for help  10 |     <div> 11 |       <h1>hi people</h1> > 12 |       { notanobject.errorthrower } |                     ^ 13 |     </div> 14 |   ) 15 | } webpackerror: typeerror: cannot read property 'errorthrower' of undefined - index.js:12 indexpage lib/src/pages/index.js:12:21 - react-dom-server.node.production.min.js:26 d - react-dom-server.node.production.min.js:28 wa - react-dom-server.node.production.min.js:33 a../node_modules/react-dom/cjs/react-dom-server.node.production.min.js.a.render before: error building static html for pages failed see our docs page on debugging html builds for help  typeerror: cannot read property 'errorthrower' of undefined - render-page.js:26262 indexpage d:/dev/blog-v2/public/render-page.js:26262:179 - render-page.js:22314 d d:/dev/blog-v2/public/render-page.js:22314:492 - render-page.js:22316 wa d:/dev/blog-v2/public/render-page.js:22316:493 - render-page.js:22321 a../node_modules/react-dom/cjs/react-dom-server.node.production.min.js.a.render d:/dev/blog-v2/public/render-page.js:22321:48 closes #5301 </desc> <cmt> use new babel-code-frame api </cmt> <cmt> stop build after errors in build-html stage and display nicely formatted error message </cmt> <iss> [v2] errors in build-html don't stop build </iss>,stop builds on errors in built-html step
637,"<desc> this contain fixes, with some cherry-picking from master and some backport from 3-0-stable. all the test passed. </desc> <cmt> fragment caching needs to operate on the pure output, not the </cmt> <cmt> safebuffer. </cmt> <cmt> fix simple_format helper to work correctly with the new safebuffer rule. </cmt> <cmt> this has been ported from 3-0-stable [ed3796434af6069ced6a641293cf88eef3b284da] </cmt> <cmt> adapt [823aa223efbac6ad4d31ea33402892267bb77cb4] to make sure we perform cloning before manipulation only on outputbuffer. </cmt> <cmt> after the fragment rendering, builder returns the string object instead of actionview::outputbuffer. somehow the same procedure which was in [823aa223efbac6ad4d31ea33402892267bb77cb4] does not play nice with the string, and result in the fragment got lost. </cmt> <cmt> add proper fix to mail_to helper. </cmt> <cmt> * fix the problem on manipulating on the activesupport::safebuffer </cmt> <cmt> * make sure that we run escape_javascript on the string, to avoid unexpected behavior. </cmt>",fix failing actionpack tests on 3-1-stable
638,"<desc> after gh-20354, i enabled a small whitelist of linting rules on the backport, which found several unused imports, unused variables and unnecessary ""else"" clauses (i am on the fence about this as a general rule, but in this case i think it helps readability to drop them). </desc> <cmt> remove unused imports in zoneinfo </cmt> <cmt> remove unused variables in zoneinfo </cmt> <cmt> remove else after raise </cmt>",further de-linting of zoneinfo module
639,"<desc> added integration tests for tensorflow implementation of the albert model fixes #9956 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> sync </cmt> <cmt> sync </cmt> <cmt> integration test added for tf mpnet </cmt> <iss> [good first issue] mpnet tensorflow integration tests </iss>",added integration tests for tensorflow implementation of the mpnet model
640,"<desc> at the moment, cucumber definition types only allow to add a custom world without any parameter type -> setworldconstructor(world: () => void): void; var {definesupportcode} = require('cucumber'); var seleniumwebdriver = require('selenium-webdriver'); function customworld() { this.driver = new seleniumwebdriver.builder() .forbrowser('firefox') .build(); // returns a promise that resolves to the element this.waitforelement = function(locator) { var condition = seleniumwebdriver.until.elementlocated(locator); return this.driver.wait(condition) definesupportcode(function({setworldconstructor}) { setworldconstructor(customworld) }); so with this change type -> setworldconstructor(world: (() => void) | ({})): void; it will be possible to do: var {definesupportcode} = require('cucumber'); var seleniumwebdriver = require('selenium-webdriver'); function customworld({attach, parameters}) { this.attach = attach; this.parameters = parameters; this.driver = new seleniumwebdriver.builder() .forbrowser('firefox') .build(); // returns a promise that resolves to the element this.waitforelement = function(locator) { var condition = seleniumwebdriver.until.elementlocated(locator); return this.driver.wait(condition) definesupportcode(function({setworldconstructor}) { setworldconstructor(customworld) }); this change will allow to use attach() in custom world, without losing the possibility of add a screenshot error, p.e, on json output. make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> update types, in order to allow to reuse params and/or attach in a new </cmt> <cmt> custom world </cmt>",use params and/or attach method from default world in a new custom world
641,"<desc> anal.cpp.abi is set to msvc automatically for pe more commands and better help message av, avr and avra can be canceled with ctrl+c support for msvc x86_64 which is a bit different compared to 32bit #6851 </desc> <cmt> set anal.cpp.abi to msvc for pe </cmt> <cmt> add better help for av </cmt> <cmt> split avr into avr and avra </cmt> <cmt> make av, avr and avra breakable </cmt> <cmt> add rtti struct specific print functions </cmt> <cmt> rtti: support msvc x86_64 </cmt>",even more vtables and rtti
642,<desc> i have followed (at least) the pr section of the contributing guide. the type definition for svgicon included color: ... | default assuming the proptypes are correct i updated the type definition to not include default. copied the documentation into the type definitions changed the signature so the proptypes are automatically generated. side effect: resolves #17275 the shaperendering prop isn't used directly so i updated generateproptypes to check for a @document flag </desc> <cmt> generateproptypes - check jsdoc for document tag </cmt> <cmt> svgicon </cmt> <cmt> docs:api </cmt> <iss> ts2589 error throws in ts3.6 if svgicon component being wrapped with styled-components </iss>,fix color type definition including default
643,"<desc> another piece of #37. there were quite a few sites that worked fine by looking at the http status (as opposed to depending on the exact error text).  so, i converted them to the more robust method.  and, i added them to the tests. </desc> <cmt> convert canva to the more robust response url detection method.  add to tests to ensure that it is covered. </cmt> <cmt> convert academia.edu to use the status code detection method. the site gives a clean 404 error. </cmt> <cmt> add test methods for http status detection method as well. </cmt> <cmt> convert angellist to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert blip.fm to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert bandcamp to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert behance to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert buzzfeed to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert codecademy to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert codementor to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> convert designspiration to use the status code detection method. the site gives a clean 404 error.  add to tests. </cmt> <cmt> add test methods for error message detection method as well.  add dribbble to tests. </cmt>",add more tests for sites
644,"<desc> this pr: introduces chakraobjectref, an raii wrapper for jsrefs. replaces chakrapropertyidvalue, chakrastringvalue, chakraobjectvalue, and chakraweakrefvalue with a new class chakrapointervalue, which is implemented on top of chakraobjectref. fix property id comparison for chakraruntime. temporarily disables weak ref semantics for chakracore based runtime. this functionality will be re-enabled in a future pr. microsoft reviewers: open in codeflow </desc> <cmt> add chakraobjectref. </cmt> <cmt> add some chakraobjectref helper functions. </cmt> <cmt> add more chakraobjectref helpers. </cmt> <cmt> introduce chakrapointervalue and reimplement many runtime functions with it. </cmt> <cmt> make chakrajsiruntime_core.cpp build. </cmt> <cmt> fix desktop build. </cmt> <cmt> bug fixes. </cmt> <cmt> fix universal build. </cmt> <cmt> change files </cmt>",introduce chakraobjectref and refactor chakraruntime
645,"<desc> beta backport of pr #86212 </desc> <cmt> revert pr 81473 to resolve (on mainline) issues 81626 and 81658. </cmt> <cmt> revert ""add missing brace"" </cmt> <cmt> this reverts commit 85ad773049536d7fed9a94ae0ac74f97135c8655. </cmt> <cmt> revert ""simplify base_expr"" </cmt> <cmt> this reverts commit 899aae465eb4ef295dc1eeb2603f744568e0768c. </cmt> <cmt> revert ""warn write-only fields"" </cmt> <cmt> this reverts commit d3c69a4c0dd98af2611b7553d1a65afef6a6ccb0. </cmt> <cmt> allow some temporarily dead code. </cmt> <cmt> i expect thi8s method to come back very soon; noise of removing them to satisfy lint seems wrong. </cmt>",beta targetted revert 81473 warn write only fields
646,<cmt> add nofile and nproc ulimit settings to the openrc init script </cmt> <cmt> docker-dco-1.1-signed-off-by: andrew page <admwiggin@gmail.com> (github: tianon) </cmt> <cmt> add nofile and nproc ulimit settings to the sysv init script </cmt> <cmt> docker-dco-1.1-signed-off-by: andrew page <admwiggin@gmail.com> (github: tianon) </cmt>,add nofile and nproc ulimit settings to openrc and sysvinit
647,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add types missing from v1.5.0 </cmt> <cmt> update version number in header </cmt>","add types missing from v1.5.0, disassembler, batch and verifier"
648,"<desc> this pr adds two more asserts that i am using to validate some assumptions in the pass before i fix it for the strong control equivalence issues in between copies. </desc> <cmt> [pmo] expand an assert that validates that we never handleprimitivevalues when promoting takes. </cmt> <cmt> the key thing to note here is that when we are processing a take, we validate </cmt> <cmt> that at all destroy points we have a fully available value. so we should never </cmt> <cmt> hit this code path which is correct. this assert just makes the assumption </cmt> <cmt> clearer in the small when reading code locally in handleprimitivevalue. </cmt> <cmt> [pmo] add an assert that when using silssaupdater in ossa, we only have singular values if the underlying type is either trivial or we have a take. </cmt> <cmt> the reason why this is true is that we will be inserting new copy_values for </cmt> <cmt> each available value implying that we can never have such a singular value. </cmt> <cmt> i also added two test cases that show that we have a singular value with the </cmt> <cmt> trivial type and that works. </cmt>",add a few more asserts before i fix strong control equivalence issues
649,"<desc> oss fuzz exposed a bug in the ldm that was fixed in #2362 - this pr adds a test case for the specific failure: compressing with ldm + opt parser in streaming mode with a flush that contains a small, uncompressible block, followed by another compression. test plan: verified that this test will fail on versions of zstd prior to #2362, but passes after that pr was merged. spot-checked to make sure we have the exact same issue (rawseqstore::posinsequence fails to advance fully). </desc> <cmt> add test to fuzzer.c </cmt> <cmt> move test to appropriate location </cmt>",add a test case for ldm + opt parser with small uncompressible block
650,"<desc> as discussed with @k-fish, this pr adds a new vitalwidgetmetrics widget that is functionally identical with vitalwidget but displays unsampled data fetched from metrics api. work on metrics api is still in progress, so the server returns dummy data. everything is feature flagged behind a metrics-performance-ui flag and the metricsswitch needs to be turned on. kapture.2021-11-30.at.10.05.30.mp4 </desc> <cmt> feat(ui): add metrics based web vitals widget </cmt> <cmt> cleanup </cmt> <cmt> add test coverage </cmt>",add metrics based web vitals widget [ingest-542]
651,<desc> checklist closing issues: #16576 i wrote some lines in the radare2book contents of test/scripts have been moved into test/bins/src. also fixed broken tests as pointed out in this comment. </desc> <cmt> removed test/scripts and fixed paths in broken tests </cmt> <cmt> update branch </cmt>,move test/scripts into test/bins/src and fix broken tests
652,"<desc> fixes emergency parser support for stm32f1 when using usb composite serial and adds emergency parser support when using usb serial. board using stm32f1. (tested using bigtreetech skr mini-e3 v1.2 with both usb composite serial and usb serial.) adds support for emergency parser when using usb serial and fixes support for usb composite serial. the original changes (#19279, #19281) do not work (for me). the function marlincompositeserial.peek() return multiple times the same character in: marlin/marlin/src/hal/stm32f1/msc_sd.cpp line 48 5ee1087 emergency_parser.update(marlincompositeserial.emergency_state, marlincompositeserial.peek()); use skr mini-e3 v1.2 example config #define emergency_parser for usb composite serial: #define use_usb_composite original implementation: #19279, #19281, related issues: #19623 </desc> <cmt> fix stm32f1 usbcompositeserial emergency parser </cmt> <cmt> added emergency parser to usb serial </cmt>",fix emergency parser for stm32f1
653,"<desc> make bazel build //java:ray_java_pkg generate maven deps so that users can develop java code using maven lint bazel i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> lint </cmt> <cmt> gen_maven_deps for ray_java_pkg </cmt>",fix building java with maven
654,<desc> see #2268. i updated ext/calendar/calendar.c in a separate commit just in case i screwed up the encoding again. it doesn't look like i did though. :) </desc> <cmt> update copyright headers to 2017 </cmt> <cmt> update copyright header to 2017 in calendar.c </cmt>,update copyright years to 2017 (php 7.0)
655,"<desc> the main portion of this change replaces callnode, bracenode, and dotnode with accessnode as all three were just behaving as a binarynode parent for their respective child nodes which included a prefix node and the method call, brace access, or dot access. this change also renames a bunch of variable names for nodes with the prefix ""ir"" for consistency and to differentiate them from user nodes which is helpful since both are present in many cases for the user tree to ir tree conversion. </desc> <cmt> move bootstrap injection into the the ir tree builder phase </cmt> <cmt> move scriptclassinfo out of walker and remove unncessary injection </cmt> <cmt> phases </cmt> <cmt> add accessnode in place of ecall, ebrace, and edot </cmt> <cmt> response to pr comments </cmt>",add an accessnode to the ir tree as a binary parent
656,"<desc> hi there guys, lots of changes in the last weeks in the repo! great work. i've improved the search in the sense that i've added backwards search on pressing ""n"". i've also refactored some code in the search functionality, and i've managed to keep it reasonably simple. i thought of adding something similar to ""/"" but that would search backwards (perhaps "">""? in an english keyboard it sort-of makes sense.), but i decided that as long as the functionality is there, we can enable it in the future if we want to. cheers, pedro </desc> <cmt> add basic backwards search </cmt> <cmt> add multi-line support </cmt> <cmt> add multi-line support to backwards search </cmt> <cmt> add docs </cmt> <cmt> fix the wrapping on backward searches </cmt> <cmt> add helpful messages on wrap </cmt>",improve search to also search backwards.
657,"<desc> addresses #25726 this adds a nullable slug field to gatsby-plugin-mdx. this can be used as a path for createfilenode or in unified routes. however, the slug does not translate to a working path out of the box. in addition, it will be null or no-op for mdx nodes that aren't sourced from the file system. some examples of behavior: assuming gatsby-source-filesystem is configured for both the pages directory and the content directory. src/pages/about.md => about src/pages/index.mdx =>  src/content/example.md => example src/content/example/something.md => example/something at the moment this adds a slug field to the schema. this should get overwritten by existing sites that extend the schema and add a slug, but it's worth considering whether we want to bikeshed the name at all. though it's likely the most obvious choice. </desc> <cmt> initial slug query </cmt> <cmt> initial commit for slug, behavior not ideal </cmt> <cmt> initial commit, not ideal behavior </cmt>",add built in slug for gatsby-plugin-mdx
658,"<desc> some users have requested the ability to not use ephemeral volumes (local instance storage), but this also highlighted the fact that we likely fail to start on instance types with no instance storage (e.g. the c4 class instances). confirming this fix, and then going to confirm that e.g. c4 is broken.  if so this will be a cherry-pick candidate. </desc> <cmt> aws: don't error if there are no ephemeral disks </cmt> <cmt> format-disks used to run with non-strict bash semantics, but this changed in </cmt> <cmt> 1.2 as we now merge it into the gce script, so pipefail and errexit are both </cmt> <cmt> set. </cmt> <cmt> however, the way we list the ephemeral disks, by piping to grep, would cause an </cmt> <cmt> exit code of 2 if there were no ephemeral disks. </cmt> <cmt> tolerate failure here by add || true.  the metadata service call is unlikely </cmt> <cmt> to fail, so we continue to ignore that possibility. </cmt> <cmt> aws kube-up: allow block_device_mappings_base to be empty </cmt> <cmt> we rename it to ephemeral_block_device_mappings, and we also change the value </cmt> <cmt> so that it starts with a ,, instead of always inserting a comma before it. </cmt> <cmt> in this way the value can be empty. </cmt> <cmt> also, if the user sets the (currently experimental) kube_aws_storage </cmt> <cmt> environment variable to be ""ebs"", then we will not mount any instance storage </cmt> <cmt> which will cause the machines to use ebs storage instead. </cmt>",tolerate a lack of ephemeral volumes
659,"<desc> related issue = #2193 this pr replaces asttransformerpreprocess with stmtbuilder and exprbuilder. this pr doesn't modify the behavior (and the code) of the other 2 passes in transformer.py. detailed changeset: move all members of the class asttransformerpreprocess to buildercontext. these members should be context instead of members of a pass. move scopeguard, parse_stmt, parse_expr to ast_builder_utils.py. rename all functions in asttransformerpreprocess from visit_xxx to build_xxx and move them to expr_builder.py and stmt_builder.py. remove all generic_visit in asttransformerpreprocess in transformer.py. since we need to know if it's a statement or an expr before building the subtree of ast, we cannot use a general generic_visit. the invocations of this function is rewritten as build_expr, build_exprs, build_stmt, build_stmts. note that build_exprs and build_stmts create a variable_scope. also note that i do not use a list comprehension in these two functions because with will not work properly otherwise. note that build_module does not use build_stmts, just like its not using generic_visit before this pr. this is because if we create a variable_scope associated with the statement list (python list here), the parameters passed into the taichi kernel will be deleted when destructing the variable scope. fix some missing fields required by the python ast but not required when executing it (compiling taichi). (otherwise the ast may not be printed properly.) throw exception if we encounter an ast node without corresponding builder (e.g., if build_name is not implemented in exprbuilder and we invoke build_expr with a name node as the parameter). throw taichisyntaxerror if the python keyword global/nonlocal is used or when a python set (including set comprehension) is used. add many builder functions which look trivial and in fact unnecessary if we use visit_xxx before this pr. i think there's a benefit of writing these functions explicitly -- they show which features in python are supported in taichi, and throw exceptions when users use features in python that are not considered by taichi developers, which may or may not be supported. note: not supported both before and after this pr: a = f'aaa{123}' (ast.joinedstr, together with ast.formattedvalue) b = a[1:2] (ast.slice) b = (n**2 for n in aa if n>5 if n<10) (ast.generatorexp) a = lambda x, y: x + y (ast.lambda) (probably incorrectly) supported before this pr but unsupported after this pr: (b): ti.i32 = 1 (ast.annassign) yield a and yield from a (ast.yield and ast.yieldfrom) {1, 2, 3} and {x for x in numbers} (ast.set and ast.setcomp) class foo: ... (ast.classdef) def foo() (ast.functiondef) in a kernel not supported but did not throw syntax error before this pr: ast.asyncfunctiondef, ast.await, ast.asyncfor, ast.asyncwith do not throw syntax error before this pr. they are not considered in this pr. global and nonlocal throw taichisyntaxerror after this pr. they may crash later before this pr. </desc> <cmt> exprbuilder: subscript, call, name, compare, constant </cmt> <cmt> exprbuilder: ifexp, unaryop, boolop, binop </cmt> <cmt> stmtbuilder: augassign, assert </cmt>",split transformer.py into stmtbuilder and exprbuilder (stage 1)
660,"<desc> miscellaneous symbols 2605, 2606, 2610-2612, 2614, 2616, 2617, 262d, 262e, 2639-263b, 2640, 2660-2667, 2669-266f, 267a, 267e-2689, 2690-2693, 2698, 2699, 26a2, 26b2, 26bf, 26c6, 26c8-26cd, 26cf, 26d0, 26d2-26e1, 26e8, 26f5, 26f6, 26f8-26fb, 26fd  dingbats 2705, 2708, 2709, 2713-2716, 274c-2753, 2755-2757, 275b-2761, 276c-2775, 2795-2797, 27a8  miscellaneous symbols and pictographs  1f510, 1f511, 1f520-1f522, 1f5a8, 1f5b6, 1f5b8, 1f5d6-1f5db, 1f5f4, 1f5f5, 1f5f8, 1f5f9 cjk symbols and punctuation 3014-3015  specials adjusted: fffd  geometric shapes adjusted: 25a0-25b1  coverage: </desc> <cmt> base: adjust some glyphs in font katica regular 10 </cmt> <cmt> adjust glyphs to the fonts ""new"" 10p max width. </cmt> <cmt> specials: </cmt> <cmt> fffd </cmt> <cmt> geometric shapes: </cmt> <cmt> 25a0-25b1 </cmt> <cmt> base: add miscellaneous symbols to font katica regular 10 </cmt> <cmt> 2605, 2606, 2610-2612, 2614, 2616, 2617, 262d, 262e, </cmt> <cmt> 2639-263b, 2640, 2660-2667, 2669-266f, 267a, 267e-2689, </cmt> <cmt> 2690-2693, 2698, 2699, 26a2, 26b2, 26bf, 26c6, 26c8-26cd, </cmt> <cmt> 26cf, 26d0, 26d2-26e1, 26e8, 26f5, 26f6, 26f8-26fb, 26fd </cmt> <cmt>  </cmt> <cmt> base: add dingbats to font katica regular 10 </cmt> <cmt> 2705, 2708, 2709, 2713-2716, 274c-2753, 2755-2757, 275b-2761, </cmt> <cmt> 276c-2775, 2795-2797, 27a8 </cmt> <cmt>  </cmt> <cmt> base: add cjk symbols and punctuation to font katica regular 10 </cmt> <cmt> 3014-3015 </cmt> <cmt>  </cmt> <cmt> base: add misc. symbols and pictographs to font katica regular 10 </cmt> <cmt>  </cmt> <cmt> 1f510, 1f511, 1f520-1f522, 1f5a8, 1f5b6, 1f5b8, 1f5d6-1f5db, 1f5f4, </cmt> <cmt> 1f5f5, 1f5f8, 1f5f9 </cmt>",add symbols to font katica regular 10
661,"<desc> the two syscalls are quite similar and almost identical (the main difference is the musl/linux syscall returns negative for an error, or otherwise the value is the bytes written, while in wasi there is an out param for the latter). by using wasi's, we can be more compatible with wasi, and as a bonus it's not variadic like musl's so it's actually a little smaller. add wasi.h. fix asmfs debug logging (strings split into parts with ""a"" ""b"" were broken, due to some preprocessor issue i didn't investigate). remove some extra syscall_debug testing that was very specific to writev (as we move more to wasi that will matter less and less anyhow, as that option is specifically for musl - it translates the numeric syscall ids into the string names). </desc> <cmt> fix sqlite test </cmt> <cmt> the _callback function being included in export_functions but it is </cmt> <cmt> a static function which is not exportable with the wasm backend. </cmt> <cmt> since this is never used simply remove it from the list. </cmt> <cmt> revert ""fix sqlite test"" </cmt> <cmt> this reverts commit dbe1523bfaab40e97be30a26047c642c6d303adb which </cmt> <cmt> was mistakenly committed to master. </cmt> <cmt> use wasi's fd_write </cmt> <cmt> fix fastcomp </cmt> <cmt> fastcomp fix </cmt> <cmt> fix </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> comment [ci skip] </cmt> <cmt> fix pthreads [ci skip] </cmt> <cmt> text </cmt> <cmt> fixes </cmt> <cmt> fix </cmt>",switch from musl's writev syscall to wasi's
662,<desc> poc: start deprecating build_policy() (policy_template.py) as a means to sub-class torchpolicy to build custom policies. build_policy is still used by most algos in rllib (this is only a poc). this pr only implements the ppo torch policy as a direct sub-class of torchpolicy. add loss method to policy api. todos: prove that sub-classing can solve right order of mix-in initializations + loss initializations. try to get rid of confusing mix-ins entirely. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip </cmt> <cmt> wip. </cmt>,deprecate build_policy (policy template) for torch only; ppotorchpolicy
663,"<desc> closes #25311 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> doc: file obj for to_csv must be newline='' </cmt> <cmt> no universal newline for wrapped compression file obj </cmt> <cmt> fixup </cmt> <iss> dataframe to_csv line_terminator inconsistency when using compression </iss>",to_csv line endings with compression
664,"<desc> this pr updates the databricks api version from 2.0 to 2.1. of the nine available endpoints in the databrickshook, these seven are not in use and do not map to any operators. the remaining two endpoints map to a single operator each and the request structure is either unchanged or compatible when moving from version 2.0 to 2.1 according to this doc </desc> <cmt> change api version from 2.0 to 2.1 </cmt> <cmt> add updating entry. </cmt> <iss> use job api 2.1 version for databricks provider hooks and </iss>",update databricks api from 2.0 to 2.1
665,"<desc> cherry-pick of #31098 for 5.3. fixes a bug were we were indenting within a multi-line string when we shouldn't have been. the checks for walking into an ast node or not were based on their end source loc, which is the start of their last token. if that token was a multi-line string and line being indented was within it, we we wouldn't walk into the node, and so never set the flag to indicate we were attempting to indent within a string. we weren't handling unresolvedspecializeexpr when determining if an expression was 'outdenting' or not, so we ended up indenting the filter call below when we shouldn't have: let x = foo< int, string, >() .filter { $0 > 10 } it's now handled correctly. fixes up listaligner (and the code using it) to handle trailing indentation targets in many more cases. this makes the as-you-type indentation more consistent with select-and-reindent-after-you're-done indentation. hitting enter after a comma in an incomplete list, or after an empty list that requires at least one element now give the correct indentation in many more cases (including guard/if/while conditions, and enum case elements). a few lists still don't handle trailing indentation targets properly, though, because the parser drops them from the ast when incomplete or empty. resolves rdar://problem/62061741 </desc> <cmt> [sourcekit/codeformat] update hasoutdent check to handle specialization ranges < > </cmt> <cmt> they were missed before, so < > that should trigger outdenting weren't. e.g. </cmt> <cmt> let x = foo< </cmt> <cmt> int, string, int </cmt> <cmt> >() </cmt> <cmt> .count // indented becase we didn't process the < > brackets previously. </cmt> <cmt> [sourcekit/codeformat] get 'trailing' indentation to work in more places and fix a bug where multi-line string indentation was modified. </cmt> <cmt> e.g. if/guard condition patterns are column-aligned, but hitting enter after </cmt> <cmt> the ',' below wasn't column-aligning the next empty line: </cmt> <cmt> guard let x = optional(42), </cmt> <cmt> // no indentation added here after enter </cmt> <cmt> also the istargetcontext() check takes a start and end token location, but </cmt> <cmt> wasn't accounting for the end location pointing a multiline string, so we </cmt> <cmt> weren't walking into such nodes. this meant we didn't realise the target </cmt> <cmt> location was within a multiline string in some cases, and we ended up </cmt> <cmt> interfering with whitespace in its content. </cmt>","indentation fixes for multi-line string, unresolvedspecializeexpr, and trailing target handling"
666,"<desc> the number of lines to move upon scroll up scroll down can be defined in scrollup and scrolldown commands (parameter is called ""rowstoscroll""). if the number are not provided, use the system default (the one we are using for mouse scrolls), rather than 1 line. manual testing added custom bindings for scroll commands with different values, verified they and the default appear and behave as expected checked that invalid values are not allowed closes #5078 </desc> <cmt> 5078: use system settings when scrolling </cmt> <cmt> 5078: add command line parameters support </cmt> <iss> specify number of lines for scollup and scrolldown commands (+ follow system setting?) </iss>",add rowstoscroll to scrollup/down w/ fallback to system default
667,<desc> make the feature flag toggleable with the env var ray_enable_new_scheduler=1 fix the race conditions in worker block/unblocking that cause test hangs in test_many_fractional_resources due to double un-blocks (lost cpus). add ci builds with the env var set to avoid future regressions. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip </cmt> <cmt> add flag </cmt> <cmt> wip </cmt> <cmt> update </cmt>,pass test_basic and add ci builds with flag on
668,"<desc> hi i've changed the ""cmake/tinkbuildrules.cmake"" and the documentation, so now you should be able to have more control over the compilation flag, that was giving problems with abseil in the linker. </desc> <cmt> added logic to support compile with different c++ version more organically </cmt> <cmt> fixed not breaking line </cmt>",now should be compiling with c++ 17 and not getting linker errors
669,"<desc> this adds a new option --enable-man to configure, so manpages can be installed via make install. this option defaults to yes, but opt out of the manpage installation is possible by running ./configure --disable-man (or --enable-man=no) as the license situation of the contrib/debian manpages is that most of them are gpl it was not 100% clear if they can be included here, also they are incomplete anyway so i let help2man create a few manpages from the 0.13.0 binaries and included them. the script used to generate them has also been added to contrib/devtools. this targets #7626 but was also briefly discussed in #8568 </desc> <cmt> add script to generate manpages with help2man </cmt> <cmt> add gen-manpages.sh description to readme.md </cmt> <cmt> add autogenerated manpages by help2man </cmt> <cmt> add doc/man/makefile.am to include manpages </cmt> <cmt> add doc/man to subdir if configure flag --enable-man is set </cmt> <cmt> add conditional for --enable-man, default is yes </cmt>","install manpages via make install, also add some autogenerated manpages"
670,<desc> closes #3561 </desc> <cmt> make gatsby-image more configurable </cmt> <cmt> added a new prop imgstyle which is now spread into default styles of img element. </cmt> <cmt> fix noscript img style </cmt> <cmt> add imgstyle prop to gatsby-image doc </cmt> <cmt> remove unnecessary \ for escaping | </cmt> <cmt> make eslint happy :smile: </cmt>,make gatsby image more configurable
671,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add http-auth type </cmt> <cmt> fix for dtslint </cmt>",add new type definition for http-auth
672,"<desc> original pull-request #14203 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix issue #14202 </cmt> <cmt> testcase for issue 14202 </cmt> <cmt> fix issue #14202 </cmt>",cherry pick #14203 to 20.7: fix issue #14202
673,"<desc> fixes t-1106. fixes saving a file containing a url dependency. this previously uses the wrong specifier since we changed to allow multiple dependencies with the same specifier in the same file. fixes adding a url or async dependency in js which previously used a hash reference that wasn't replaced. now we just use the bundle id as the hash reference in development to begin with so there's nothing to replace and it works in hmr. ensures added/changed runtimes are included in the list of changedassets returned by core. prevents the page from being reloaded when adding/updating a url dependency in js. for example, now if you add or modify an image it will be reloaded in place without reloading the whole page. this is done by adding a cache busting query param based on the current date to the url runtime when hmr is enabled. if a changed asset is only depended on by runtimes, then we skip sending the original file over hmr (as that would cause the page to be reloaded), and instead mark the runtime as ""changed"" which will cause it to be re-executed and the timestamp in the query param to be updated. also prevented the image optimizer from running in development which was kinda slow. note: inline bundles are still broken with hmr, but that's a much bigger issue so i didn't tackle it yet. </desc> <cmt> fix specifiers of async and url dependencies to match packager </cmt> <cmt> use real hash as hash reference in development </cmt> <cmt> send changed runtimes over hmr as well </cmt> <cmt> prevent reloading the page when adding and updating url dependencies in js </cmt> <cmt> prevent the image optimizer from running in development </cmt>",hmr fixes for url dependencies
674,"<desc> fixes #15208 bug we currently use our own logic to determine if a ts project contains too many files. the actual ts server may use different criteria for determining this. for ts 2.1.3+, listen for languageserviceenabled events from the ts server instead. </desc> <cmt> initial work on large proejct warnings </cmt> <cmt> update to use projectname from ts </cmt> <cmt> use event to clean up code </cmt> <cmt> remove unused interface </cmt> <cmt> revert a few testing changes </cmt> <iss> improve large project warning for js/ts projects </iss>",consume languageserviceenabled events from ts
675,<desc> option to probe_y_first which may be more convenient proper handling of points outside the (bilinear) probe region make sure g29 sets planner position add debug to double-touch (could also add averaging) bed level report shows 0-based indices universal function to enable/disable bed leveling add option to set xy grid size separately in g29 </desc> <cmt> use stepper.get_axis_position_degrees </cmt> <cmt> double-touch debugging </cmt> <cmt> augment planner/stepper getters/setters </cmt> <cmt> standard function to turn bed leveling on/off </cmt> <cmt> g30 will only disable bed leveling </cmt> <cmt> patch up bilinear_z_offset </cmt> <cmt> patch print_bed_level numbering </cmt> <cmt> use updated position methods </cmt>,fix up abl - add probe_y_first option
676,<desc> convert_nodes.cc add convertresize i.e. resize op converter. map it to nvinfer1::iresizelayer. support conversion for resizebilinear and resizenearestneighbor op. convert_nodes_test.cc unit test for convertresize converter. </desc> <cmt> add resize converter for bilinear and nearest neighbor resize </cmt> <cmt> resize layer converter and corresponding unit tests </cmt> <cmt> merge and resolve from upstream </cmt> <cmt> fix incorrect version change for convertnms </cmt>,add tftrt resize op converter
677,<desc> folders of the style npm-10200-49dae08c are filling up our ci machines so delete them all each time a ci build runs since they are leftovers from previous builds and are never reused or needed again. </desc> <cmt> delete temp npm folders at beginning of ci build </cmt> <cmt> deletedfolder -> deletedfolders </cmt>,clean up npm temp folders on ci
678,"<desc> there are no much content changes. after most chinese version files have been committed, the hyperlinks which link to these files should be revised. </desc> <cmt> committed a file into the wrong directory on june 9 </cmt> <cmt> this is a stupid mistake, i found that there missed one chinese version file that i committed yesterday, finally i realized that it was in the wrong directory. the fact that it isn't in the right place can cause a real problem, because all pictures can not be shown. so please merge this modification. </cmt> <cmt> merge from source </cmt> <cmt> create coordination_cn.md </cmt> <cmt> 4 new pictures for coordination_cn.md </cmt> <cmt> create coordination_cn.md </cmt> <cmt> update coordination_cn.md </cmt> <cmt> merge from source </cmt> <cmt> update apollo_3.0_technical_tutorial_cn.md </cmt> <cmt> update apollo_3_0_quick_start_cn.md </cmt> <cmt> update dreamview_usage_table_cn.md </cmt> <cmt> update readme_cn.md </cmt> <cmt> update readme_cn.md </cmt> <cmt> update apollo_3_0_hardware_system_installation_guide_cn.md </cmt> <cmt> update readme_cn.md </cmt> <cmt> update apollo_3.0_technical_tutorial_cn.md </cmt>",revise hyperlinks labled by chinese link to chinese version docs
679,"<desc> closes [5162] enables the tag processing by replacing the template tag raw i have reviewed my changes in staging. (look for the deploy-to-heroku link in your pull request, then click view deployment) for content changes, i have reviewed the localization checklist for content changes, i have reviewed the content style guide for github docs. i have added a description and/or a video demo of the changes below (eg. a ""before and after video"") </desc> <cmt> merge from fork </cmt> <cmt> enable tag processing </cmt> <iss> [improvement] unresolved variable showing in example </iss>",fix the unresolved variable showing in configuration-options-for-dependency-updates.md
680,<desc> this is part of the de-forking effort.  react-native doesn't publish integrationtests and we use them.  the solution for now is to copy these into react-native-windows. i've copied the current set of files from the microsoft fork.  we'll need to diff/merge these when we upgrade to latest react-native.  this is being tracked as part of an ask on facebook to publish rntester. microsoft reviewers: open in codeflow </desc> <cmt> copy integrationtests from fork </cmt> <cmt> change files </cmt>,copy integrationtests from msft fork
681,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> tickformatter is optional </cmt> <cmt> bump version number </cmt>",recharts - tickformatter is optional for polar axis
682,<desc> addresses #20308 this pr ensures multitasklassocv is compatible with numpydoc: remove multitasklassocv from docstring_ignore_list. verify that all tests are passing. change docstrings to maintain consistency. </desc> <cmt> remove multitasklassocv from docstring_ignore_list </cmt> <cmt> fix numpydocs from multitasklassocv </cmt> <cmt> fix numpydocs from multitasklassocv </cmt>,doc ensures that multitasklassocv passes numpydoc validation
683,"<desc> cc: @vladima note: don't mind the changes duplicated from transforms-fixasync, that's the branch from which i started this change. </desc> <cmt> fixed multiline block for async functions </cmt> <cmt> fix async method with super </cmt> <cmt> elides functions with invalid bodies. </cmt> <cmt> fixes elision of import declarations in es6 modules. </cmt>",fixes es6 import elision for transformers
684,"<desc> this moves appstate and deviceinfo to use spec files and the public native module apis. deviceinfo was a little tricky, since it has to return constants that are only able to be created on the ui thread.  so i had to split most of the logic into deviceinfoholder which is init'd on the ui thread.  this is similar to how android seems to do this - although they have to use a global since they don't have the propertybag. microsoft reviewers: open in codeflow </desc> <cmt> move more native modules to spec files </cmt> <cmt> move device info init to object created on ui thread. </cmt>",move appstate and deviceinfo to use module spec files
685,<desc> add resources added practical python: an immersive python course by nina zakharenko added mongodb cheat sheet by mongodb it's well organized and beginner-friendly course. mongodb cheat sheet comes in handy for quick revision over commands. this course is free and doesn't even require signing up. this is the free content provided by the mongodb organization itself. cheat sheet read our contributing guidelines </desc> <cmt> added practical python: an immersive python course </cmt> <cmt> added mongodb cheat sheet </cmt> <cmt> ordered alphabetically </cmt>,add practical python course & mongodb cheat sheet
686,"<desc> changes the eeprom define to reflect the proper chip used. fix eeprom chip my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> valor fix </cmt> <cmt> change eeprom </cmt> <cmt> fix up eeprom </cmt>",valor frl tkl update - eeprom change
687,<desc> it adds the ability to specify a subpath with each entry in extravolumemounts this will allow configs and plugins to live in the same volume for example. dco signed </desc> <cmt> documented the feature on the readme </cmt> <cmt> and bump the chart version </cmt> <cmt> added subpath in extravolumemounts </cmt> <cmt> chart version bump </cmt>,feature/add subpath to grafana custom volumes
688,"<desc> this fixes the jenkins builds, which are now failing because we're running a submodule update, which is triggering #2426 this pr fixes #2426. </desc> <cmt> remove gloo subtree, in preparation for gloo submodule addition. </cmt> <cmt> add gloo submodule. </cmt> <cmt> we make gloo a submodule because it contains submodules itself, and </cmt> <cmt> git cannot handle subtrees with nested submodules. </cmt> <cmt> fixes </cmt> <iss> gloo subtree has submodule, which causes submodule init to fail </iss>",turn gloo into a submodule
689,"<desc> this pr enables some of the screenshot tests for web. also increase the timeout to reduce flakiness of tests. </desc> <cmt> make golden test timeout longer, some tests are flaky if the timeout is too short </cmt> <cmt> enable some golden tests for web </cmt>",enable web for some of the golden tests
690,"<desc> i added a new layout and a keymap for the dz60 board. i could not find another layout which matches my hardware configuration of the dz60 board, so i created a new one. i think the dz60 layout is also a good addition for the qmk configurator tool. i was missing it in the webui. i tested the new layout and keymap by compiling and flashing in to my keyboard. everything worked fine, without any error. this is the keymap i'm adding with this pr: my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added new iso key layout with dedicated arrow keys, single space key and </cmt> <cmt> single backspace key for dz60 board. also added a keymap for this </cmt> <cmt> layout. </cmt> <cmt> added readme.md file for dz60 iso_de_arrow_0x544d keymap. </cmt> <cmt> update readme.md </cmt> <cmt> added layer enum to iso_de_arrow_0x544d keymap. </cmt>",dz60 - iso de arrow keymap + layout
691,"<desc> why #97567 there are some issues with the virtual list that this navigation model addresses: not all settings are rendered on the page, and as a result, screen reader users cannot use browse mode to navigate settings. (for example, you can press h or shift + h to go to the next or previous heading on the page) when users jump from one category to the other, it's not clear that they are in another category. (example tabbing from the last setting in ""commonly used"" to the first setting in ""text editor"") it's a really long list, and users can get lost in this list how this control fixes things: all settings are rendered on the page. (currently, the page size is 20) only the settings related to a particular category are rendered, so users can't jump to another category. it's paginated, and there are only 20 settings per page for now. this control could only be enabled when in screen reader mode, or under a setting, but maintaining two kinds of control is harder than one. this is why i want to merge this in insiders for all users and gather feedback for this change. (both a11y related and non-a11y related feedback) gifs </desc> <cmt> hack a non-virtual settings editor </cmt> <cmt> reuse templates </cmt> <cmt> dont use focus sinks </cmt> <cmt> set role to form on settings list </cmt> <cmt> fix more actions button visibility </cmt> <cmt> set heading on setting title </cmt> <cmt> fix scrollbar </cmt> <cmt> restore search </cmt> <cmt> use pagination </cmt> <cmt> refresh list correctly </cmt> <cmt> add a group heading </cmt> <cmt> css polish </cmt> <cmt> plug the leak </cmt> <cmt> rename settingstree to settingslist </cmt> <cmt> fix markdown links </cmt> <cmt> pull out css from the class </cmt> <cmt> sync toc selection with settingslist </cmt>",use paginated non virtual list in settings editor
692,<desc> description: related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> bump pywemo to 0.4.33 </cmt> <cmt> bump pywemo to 0.4.33 - includes expended port range fix for dimmers </cmt> <cmt> bumped pywemo to 0.4.33 </cmt>,bump pywemo to 0.4.33 (expanded port range fixes dimmers on latest firmware)
693,"<desc> update aws-kotlin-jvm-gradle template upgrade to gradle 6.0 upgrade to java 11 update dependencies to recent versions configure shadowjar task and johnrengelman plugin closes #xxxxx how can we verify it build: ./gradlew clean build deploy: ./gradlew deploy if you want to check using an api gateway use the following as serverless.yaml and follow the output url to trigger the function: provider: name: aws runtime: java11 package: artifact: build/libs/hello-dev-all.jar functions: hello: handler: com.serverless.handler events: - http: path: users/create method: get is this ready for review?: yes is it a breaking change?: no, it is a change in the template section, not in the framework itself </desc> <cmt> update to gradle version 6 and start using plugins block in build.gradle </cmt> <cmt> update shadow plugin johnrengelman </cmt> <cmt> run shadowjar after build </cmt> <cmt> update to java11 </cmt> <cmt> add readme </cmt> <cmt> update dependencies </cmt> <cmt> update aws java bom </cmt> <cmt> update repositories block </cmt>",update aws-kotlin-jvm-gradle template to gradle 6 and java 11
694,"<desc> closes #36286 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> added example for natural sort </cmt> <cmt> argument instead of function </cmt> <iss> enh: allow sort_values to use the natural sort order </iss>",example for natural sort using key argument
695,<desc> removes bwc for token invalidation removes bwc invalidation logic from the tokenservice removes bwc serialization for invalidatetokenresponse objects as old nodes in supported mixed clusters during upgrade will be 6.7 and thus will know of the new format removes the created field from the tokensinvalidationresult and the invalidatetokenresponse as it is no longer useful in > 7.0 resolves: #36727 </desc> <cmt> removes bwc for token invalidation </cmt> <cmt> - removes bwc invalidation logic from the tokenservice </cmt> <cmt> - removes bwc serialization for invalidatetokenresponse objects as </cmt> <cmt> olf nodes in supported mixed clusters during upgade will be 6.7 and </cmt> <cmt> thus will know of the new format </cmt> <cmt> - removes the created field from the invalidatetokenresponse as it </cmt> <cmt> is no longer useful in > 7.0 </cmt> <cmt> do not check for invalidated token documents anymore </cmt> <cmt> fix tests to mock get requests for invalidation </cmt> <cmt> merge getandvalidatetoken with decodeandvalidatetoken </cmt> <cmt> define document id </cmt> <cmt> fix test </cmt> <cmt> remove created field from rest tests </cmt>,remove bwc logic for token invalidation
696,"<desc> includes work by @dlbuckley and @anayini from the following prs: #19532 #20715 </desc> <cmt> added codable conformance for range, closedrange, partialrangeupto, partialrangethrough and partialrangefrom </cmt> <cmt> (cherry picked from commit c45cdb7b7b4286b4e8bd8dad0615a5799799c013) </cmt> <cmt> [sr-7076] make contiguousarray codable </cmt> <cmt> implements encodable and decodable for contiguousarray. </cmt> <cmt> (cherry picked from commit 300124460fe76b02d6b1bf23bea85712565938f6) </cmt>",add codable conformance to range types
697,"<desc> this patch makes syssetup status dialog look like a msgina status dialog. it makes user feel like it's a system dialog. user won't pay as much attention to the rotating line, as it was with a contrasting progress bar, so user's waiting will be much calmer. here is almost the same dialog from win 2k/xp: but it lacks for a progress-showing control, since reactos is not so stable. it also shows a branding logo, which is noticeable and memorable for a user. screenshot: youtube video </desc> <cmt> [syssetup] add msgina-like resources </cmt> <cmt> [syssetup] add bitmaps functionality, remove progress bar </cmt> <cmt> [syssetup] update resources </cmt>",make status dialog look like msgina status dialog
698,<desc> add a parallel_num argument that allows users to specify the num of workers to parallel in zoopt. zoopt package supports grid type as of v0.4.1. this pr fixes some known bugs and supports the latest ray and zoopt. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> update zoopt </cmt> <cmt> add grid type test for zoopt </cmt> <cmt> update zoopt </cmt> <cmt> update zoopt format </cmt> <cmt> script format </cmt>,update zoopt to better support the latest ray
699,"<desc> the responses returned from list_versions, create_function, create_alias, update_alias and update_function_code did not match the corresponding responses returned by aws. this has been fixed in this pr. </desc> <cmt> made create_function response match that of aws. </cmt> <cmt> made list_versions response match that of aws. </cmt> <cmt> made update_function_code response match that of aws. </cmt>",lambda responses match the corresponding aws responses
700,"<desc> in order to do this, i also removed the optimization such that once enforced checkpoint is set to true, we always checkpoint unless the state stores are not initialized at all (i.e. the snapshot is null). </desc> <cmt> enforce post commit on task corruption </cmt> <cmt> update unit test </cmt>",overwrite checkpoint in task corruption to remove corrupted partitions
701,"<desc> i agree to contribute to the project under opencv (bsd) license. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work the feature is a sample and will be documented separately, planned for posting on ""opencv.org"". same applies to the ""related work"". force_builders=custom,custom win,custom mac build_image:custom=ubuntu-openvino-2019r3.0:16.04 build_image:custom win=openvino-2019r3.0 build_image:custom mac=openvino-2019r3.0 test_modules:custom=gapi test_modules:custom win=gapi test_modules:custom mac=gapi buildworker:custom=linux-1 test_opencl:custom=on test_bigdata:custom=1 test_filter:custom=* build_gapi_standalone:linux x64=ade-0.1.1f build_gapi_standalone:win64=ade-0.1.1f build_gapi_standalone:mac=ade-0.1.1f build_gapi_standalone:linux x64 debug=ade-0.1.1f build_gapi_standalone:custom win=ade-0.1.1f </desc> <cmt> g-api/samples: added a simple ""privacy masking camera"" sample </cmt> <cmt> the main idea is to host this code for an opencv.org blog post only </cmt> <cmt> g-api/samples: modified privacy masking camera code to look better for the post </cmt>","add ""privacy masking camera"" sample for the upcoming posting"
702,"<desc> corresponds to reactivex/rxjava#3986 this adds a reset() method to androidschedulers, with the main benefit being improved testing support. this does slightly tweak the internal api of androidschedulers to use a getinstance() approach to allow lazy init. this way we don't have to replace the singleton instance during reset() and allow it to lazily re-evaluate upon next usage. otherwise, if you change your scheduler hook, you'd always have to make sure you set it before you call schedulers.reset(). </desc> <cmt> add androidschedulers.reset() for better testability. </cmt> <cmt> use atomicreference approach </cmt>",add androidschedulers.reset() for better testing support
703,"<desc> closes #5471, closes  #5458. </desc> <cmt> identify code that needs to be pulled out of/removed from compat.py </cmt> <cmt> extract modern code from get_names_and_managers in compat.py and remove compat code </cmt> <cmt> extract modern code from is_authenticated() in compat.py and remove. </cmt> <cmt> extract modern code from is_anonymous() in compat.py and remove </cmt> <cmt> extract modern code from get_related_model() from compat.py and remove </cmt> <cmt> extract modern code from value_from_object() in compat.py and remove </cmt> <cmt> update postgres compat </cmt> <cmt> jsonfield now always available. </cmt> <cmt> remove decimalvalidator compat </cmt> <iss> remove django 1.8 and 1.9 compatibility code. </iss>",remove django 1.8 & 1.9 compatibility code
704,"<desc> various improvements to time picker and time range filter: defer rendering of time range filter to first visibility like other filters. this extra logic is required since the time range filter doesn't have a regular query like other filters. make ""clear all"" work again. avoid debounced time range evaluation request if the time range is unchanged. will remove the double request on first render and also avoid re-requesting if the time range is changed back to its original value during debounce. improvements affect native time range filter, explore view and filter box where time picker is used. timerange-after.mp4 timerange-before.mp4 has associated issue: closes #15288 includes db migration (follow approval process in sip-59) </desc> <cmt> fix time range default value </cmt> <cmt> defer time filter rendering to inview event </cmt> <cmt> avoid double fetching of time ranges </cmt> <iss> [native filters] out-of-scope time range filters are triggered multiple times </iss>",improve time range filter performance
705,"<desc> backport of #40742 this commit introduces the .security-tokens and .security-tokens-7 alias-index pair. because index snapshotting is at the index level granularity (ie you cannot snapshot a subset of an index) snapshoting .security had the undesirable effect of storing ephemeral security tokens. the changes herein address this issue by moving tokens ""seamlessly"" (without user intervention) to another index, so that a ""security backup"" (ie snapshot of .security) would not be bloated by ephemeral data. there is no change in field mappings, but the tokens mappings have been copy-pasted in a dedicated mapping file. the rolling upgrade situation is trappy. this is because newly created tokens (creation or refresh) should be usable by both versions in the rolling upgrade situation. a big part of the change is due to this. for example, token docs will be generated in the .security index, until all nodes have been upgraded. another situation is when we have to refresh a token that was generated by the previous version; in this case the ""superseding"" doc will be in the new index. i have yet to include this cases in the tests, but i plan to! i will drop comments about newly added tests. obsoletes #37236 relates #34454 </desc> <cmt> security tokens moved to a new separate index (#40742) </cmt> <cmt> this commit introduces the .security-tokens and .security-tokens-7 </cmt> <cmt> alias-index pair. because index snapshotting is at the index level granularity </cmt> <cmt> (ie you cannot snapshot a subset of an index) snapshoting .security had </cmt> <cmt> the undesirable effect of storing ephemeral security tokens. the changes </cmt> <cmt> herein address this issue by moving tokens ""seamlessly"" (without user </cmt> <cmt> intervention) to another index, so that a ""security backup"" (ie snapshot of </cmt> <cmt> .security) would not be bloated by ephemeral data. </cmt>",backport security tokens moved to a new separate index
706,"<desc> use the entire appbartheme from the showsearch delegate for the search pages appbar theme, rather than just a select set of fields. a user could use an inheritedtheme to accomplish a similar task: 2e01eef , but this is a fix to an existing api that is broken. related issues closes #33176 i added the following tests: in search_test.dart: 'delegate appbartheme is applied to the appbar color on the search page' 'delegate appbartheme is applied to the enabledborder of the textfield on the search page' before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> wrap appbar in theme </cmt> <cmt> formatting </cmt> <iss> unable to remove border from search widget input text. </iss>",show search app bar theme
707,"<desc> speeds up tests/www and tests/api_connexion by 64% and 37%, respectively. this was accomplished by removing slow and unnecessary initialization steps from test setups, as well as mocking slow login methods. on production tests/www has been reduced from 9:32 to 2:99. tests/api_connextion is down from 10:22 to 6:08. profiling this pr is based on considerable profiling using pytest-profiling and the pytest --durations argument. both tools were invaluable in determining the slowest test functions. slow initialization whenever create_app is called, multiple sub-modules are initialized, including permission roles, the old api, new api, logging, error handling, etc. most of these are not relevant for many of the tests. this pr removes unnecessary initialization. slow login login functionality currently depends on hash functions to hash passwords. by mocking the password hashing functionality in we can sidestep this slowdown. approaches analyzed but not used adding indexes to fab permissions tables. fab queries roles and permissions on unindexed name columns. surprisingly, adding indexes didn't result in a meaningful test speedup. caching api_connexion rendering. the init_api_connexion method is the slowest initialization method, but is required for all api_connexion methods. it looks like the jinja rendering is the slowest part. i investigated storing the rendered api in an intermediate state in a separate file, but this wasn't feasible. if we want more speedups in the future, caching the api_connexion app, much like we cache the current flask app, is likely the biggest win. </desc> <cmt> blah. </cmt>",speed up www and api_connexion tests
708,"<desc> backport #18934 to v1.x please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> fix leakyrelu behaviour on empty input </cmt> <cmt> remove duplicated declarations </cmt>",backport of fix leakyrelu behaviour on empty input (#18934)
709,<desc> updated disabled pylint rules in files in the root of project. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> pylint rule: not necesary unused-import in extensions.py. autofomatted </cmt> <cmt> pylint rule: not necesary unused-import in jinja_context.py. autofomatted </cmt> <cmt> pylint rule: not necesary no-value-for-parameter in stats_logger.py. autofomatted </cmt> <cmt> pylint rule: not necesary no-member in viz.py </cmt> <cmt> pylint rule: not necesary no-member in viz_sip38.py </cmt>,pylint fixes in files in project's root
710,"<desc> fixes #110352 when opening a folder or workspace with a schema that is not file or vscode-remote but from a file system provider, we must also pass along the remoteautority of the current window. that way the new window will be opened on the same remote. the extension that provides the file system provider might only be installed on that remote. the change also affects the recent history, as the remoteautority also needs to be stored there. there are also small changes to the menu code as the open recent menu entries also need the remoteautority. </desc> <cmt> open window with authority </cmt> <iss> opening a folder with custom scheme does not work (remote, desktop) </iss>",pass along remote authority when opening window on folders with custom scheme
711,"<desc> while debugging normals during geometry creation i noticed that arrowhelper wasn't able to point downwards (0,-1,0).  this pr fixes this issue and also optimizes arrowhelper based on a suggestions from @westlangley here: #2845 (comment) tested lights in /editor/index.html and the /examples that referenced arrowhelper directly.  seems to all works. </desc> <cmt> fix arrowhelper so that it can deal with normals pointing down [0,-1,0] via creating a unit test (makebasis). </cmt> <cmt> optimization of arrowhelper.setdirection suggested by @westlangley </cmt> <cmt> cleanup arrowhelper gc usage, switch matrix->quat. </cmt> <cmt> remove unnecessary matrix4 unit tests. </cmt>",fix arrowhelper so it can point downwards (+ some optimization)
712,"<desc> see issue #1087 includes changes for pr #1085 </desc> <cmt> fix encoding for files created for building package (issue #1027) </cmt> <cmt> this is minimal set of modifications, which fixed the problem. </cmt> <cmt> there are still more places, where files are open in text mode </cmt> <cmt> without explicit encoding, thus possibly failing on systems not using </cmt> <cmt> utf-8 console encoding. </cmt> <cmt> test_api.py use explicit encoding for files. </cmt> <cmt> get-poetry.py: fix explicit (utf-8) encoding for files open in text mode </cmt> <cmt> tests: fix explicit (utf-8) encoding for files open in text mode </cmt> <cmt> poetry init: use explicit utf-8 for created pyproject.toml </cmt> <cmt> installed: use explicit utf-8 for text files </cmt> <cmt> layouts: use explicit utf-8 for open text files </cmt> <cmt> spdx: explicit utf-8 for open text files </cmt> <cmt> pypi_repository: explicit utf-8 for open text files </cmt> <cmt> explicit utf-8 for json </cmt> <cmt> explicit utf-8 for metadata </cmt> <cmt> explicit utf-8 for requires.txt </cmt>",review of (explicit) encoding for files being created in text mode
713,"<desc> hi all, i have implemented entropy based clustering metrics from the following paper: v-measure: a conditional entropy-based external cluster evaluation measure by andrew rosenberg and julia hirschberg, 2007  test coverage is 100%, some existing clustering examples have been updated to use the new metrics, i wrote a short summary of the paper in the clustering documentation emphasizing the pros and cons and pep8 is happy. </desc> <cmt> started work on homogeneity, completeness and v-measure as clustering metrics </cmt> <cmt> working implementation of v-measure, still needs doc and updated clustering examples </cmt> <cmt> use v-measure metrics in k-means example </cmt> <cmt> illustrate clustering metrics on affinity propagation example </cmt> <cmt> 100% test coverage for the new clustering metrics </cmt> <cmt> more tests </cmt> <cmt> add more documentation for the new metrics </cmt>","v-measure, homogeneity and completeness clustering metrics"
714,"<desc> this pr implements sequence classification for tf transfoxl model. tftransfoxlforsequenceclassification uses the last token in order to do the classification, as other causal models (e.g. gpt-1 ,gpt-2) do. fixes #7623 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. @lysandrejik @jplu </desc> <cmt> sync </cmt> <cmt> tf transfoxl seq classification </cmt> <iss> implement pytorch and/or tensorflow sequence classification architectures for causal language models </iss>",added tf transfoxl sequence classification
715,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [bootstrap] false is valid for interval in carousel </cmt> <cmt> [bootstrap] keep consistant spacing </cmt>",false is valid for interval option in carousel
716,"<desc> fix serialization using simpler attributeruler.patterns property apply patterns in the order they were added bug fix. i have submitted the spacy contributor agreement. </desc> <cmt> serialize attributeruler.patterns </cmt> <cmt> serialize attributeruler.patterns instead of the individual lists to </cmt> <cmt> simplify the serialized and so that patterns are reloaded exactly as </cmt> <cmt> they were originally provided (preserving _attrs_unnormed). </cmt> <cmt> sort the attributeruler matches by rule order </cmt> <cmt> sort the returned matches by rule order (the match_id) so that the </cmt> <cmt> rules are applied in the order they were added. this is necessary, for </cmt> <cmt> instance, if the attributeruler is used for the tag map and later </cmt> <cmt> rules require pos tags. </cmt>",fix attributeruler serialization and rule ordering
717,"<desc> sometimes it can be convenient to allow values (categories) in the transform of ordinalencoder that were not present in the fit data set. for example, a machine learning method, which is able of setting such an unknown sample of the corresponding feature to a neutral value (i.e. non-informative), could use the information from all other features of the sample and still output a prediction (instead of no prediction at all). closes #13488 closes #15108 closes #16959 closes #14534 closes #12045 closes #13897 </desc> <cmt> allow unknowns in ordinal encoder </cmt> <cmt> change parameter name and map unknowns to -2 </cmt> <iss> handle error policy in ordinalencoder </iss>",fea allow unknowns in ordinalencoder transform
718,<desc> redesign metrics and filters controls according to design in  before: after: test plan requires db migration. confirm db migration upgrade and downgrade tested. cc: @villebro @junlincc </desc> <cmt> redesign metrics control </cmt> <cmt> redesign filters control </cmt> <cmt> bugfixes </cmt> <cmt> fix unit tests </cmt>,metrics and filters controls redesign
719,"<desc> this pr adds a functionality to export metrics through a prometheus endpoint from reporter.py. dynamic metric registration we should register metrics definition inside python processes. to avoid having duplicated metrics definition to cpp, a python metric agent registers metrics definition dynamically when it receives them from cpp processes. to avoid always updating description and units, we follow the logic below. at first, cpp processes always post description and units. a metrics agent registers metrics if it's never seen it before. a metric agent replies to cpp processes that it doesn't need to know any metric description after the registration. if a metric agent receives metrics in which it doesn't have description and units information, it replies to cpp processes that it needs description and units in the following report. this is useful when 1. new metrics are added to cpp processes (e.g., application level metrics) 2. metrics agent restarts and lose all registered metric definition. prometheus exporter the latest release of opencensus prometheus exporter is not compatible to opencensus library. we ported the whole file instead. limitation although we register units information, it is not actually exported to prometheus because prometheus supports units information only for openmetrics standard. we should probably always add units to tags, but it is not addressed in this pr. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> in progres. </cmt> <cmt> in progress 2. </cmt> <cmt> in progress. </cmt> <cmt> use opencensus instead. in progress. </cmt> <cmt> in progress with opencensus. </cmt> <cmt> initial iteration done. </cmt> <cmt> minor fix. </cmt> <cmt> add metrics registry </cmt> <cmt> in progress with new impl. </cmt> <cmt> complete v0. </cmt>",basic metrics infrastructure (metrics agent + prometheus exporter)
720,"<desc> this pr is to add the support for fullyconnected and some element-wise (including activation/square/sqrt/exp/abs/clip) ops fusion. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change @pengzhao-intel @taolv @zhennanqin </desc> <cmt> enable fc fusion with more eltwise ops </cmt> <cmt> refactor codes </cmt> <cmt> add test cases for fc fusion pattern </cmt> <cmt> cleanup codes </cmt>",[mkldnn]support fullyconnected and element-wise ops fusion
721,"<desc> currently we don't allow retrieving metadata fields through the fields option in search but throw an error on this case. in  #78828 we started to enable this for ""_id"" if the field is explicitely requested. this pr adds _ignored and _routing metadata fields which are also internally handled as stored fields to the list of fields that can be explicitely retrieved. relates to  #75836 </desc> <cmt> adding _ignore fetching to fields api </cmt> <cmt> adding _routing fetching to fields api </cmt> <cmt> wip _source </cmt> <cmt> revert ""wip _source"" </cmt> <cmt> this reverts commit 8964620c146618e7ca814d67e83e2399a22b4394. </cmt> <cmt> fix fieldfetchertests </cmt>",add _ignored and _routing metatada fields to fields api
722,"<desc> snprintf is considered to be the ""safe"" alternative to sprintf, as it is easier to programatically guarantee that no writes outside the destination buffer happen, and that the result is always zero-terminated: output bytes beyond the n-1st shall be discarded instead of being written to the array, and a null byte is written at the end of the bytes actually written into the array. this pr does several things that are all centered on snprintf and sprintf themselves, and do not touch printf_internal at all: demonstrate a surprising bug in snprintf itself. yup, that single handful of lines. fix that bug, making sure that all existing usages are good. move the kernel from sprintf to snprintf. all current usages of sprintf are ""obviously"" correct, but making sprintf unavailable encourages good hygiene in the future. use snprintf a bit more in userland. (bonus fixes: tiny typo, outdated comment.) edit: i intend to do similar ""switching away"" from strcpy and strcmp. however, these are a bit more work; hence different prs. </desc> <cmt> libc: demonstrate off-by-one in current snprintf </cmt> <cmt> the function whose main selling point is that there always is a </cmt> <cmt> nul-terminator ... missed the nul-terminator. </cmt> <cmt> libc: fix off-by-one in snprintf() </cmt> <cmt> snprintf is supposed to *always* nul-terminate its output, so it has to write one </cmt> <cmt> output byte fewer. </cmt> <cmt> and yes, i *did* check all existing usages; this shouldn't break anything. </cmt> <cmt> ak+kernel: support snprintf </cmt> <cmt> in contrast to sprintf, which might overflow the given buffer. </cmt> <cmt> i feel bad about the code duplication, but that is a pre-existing issue. </cmt>","demonstrate and fix bug, replace sprintf() in kernel"
723,"<desc> formalize the ownership contract between code generation, the llvm modules it generates, and the llvmcontext those modules are allocated in. previously, the context to generate code in was under caller control. in practice, most callers passed around the global context. with david's patch, irgenmodule now allocates and destroys the context itself after code generation has completed. this was mostly harmless. mostly. the first place this disrupted was orcjit, which needed ownership of the context the generated module was allocated in. this necessitated the introduction of a new move-only type that manages the lifetime of the module-context pairs used by irgenmodule. i've called it swift::generatedmodule. its api contract is simple: the module and context live and die together, and ownership of a generatedmodule is exclusive by construction. there are also a very limited set of ownership transfer operations on a generatedmodule value. generatedmodule::intothreadsafecontext consumes a generatedmodule and produces an orc::threadsafemodule suitable for use by the jit. the remaining release operation mirrors the release operation on std::unique_ptr, except it consumes the generatedmodule value in the process. this supports the second part of the story: the second place this disrupted was the legacy integrated repl. the repl generates a fresh module for each ""line"", links the generated modules together, then passes them to its executionengine. the llvm linker has never handled linking modules allocated in separate contexts. thus, the repl used to just allocate everything into swift's ad-hoc global context. given that it is no longer under caller control, one solution would be to clone the module into the global context and link that. however, cloning llvm modules across contexts is also not a first-class operation. instead, introduce an egregious hack that round-trips the module through one of llvm's serialization paths. i have chosen the ir printer, but the bitcode printer would work equally well. we need to delete the integrated repl. the third place this disrupted was lldb. there, it seems like they just need to extract the module and context in order to form an irexecutionunit, so i've cleaned them up under that assumption. the clang repl code seems built in a very similar manner, which gives me some hope. in theory, this patchset is nfc, but given the linker hack in the repl - and that llvm does not test round-tripping at a semantic level very well - i am not confident in that claim. even if we don't wind up going through with the parts of this patch that sequester the ownership of the llvm context, i can still break off the little cleanup pieces from this patchset - there's some const-qualification and other little mechanical improvements that would be nice to have. </desc> <cmt> allocate llvmcontext in irgenmodule. </cmt> <cmt> [nfc] give irgenmodule exclusive ownership of an llvmcontext object </cmt> <cmt> [gardening] const-qualify some llvm::module references </cmt> <cmt> [nfc] introduce generatedmodule </cmt> <cmt> swift::generatedmodule encapsulates an llvm::module, llvm::llvmcontext </cmt> <cmt> pair that must live and die together. it has  convenient accessors for </cmt> <cmt> projecting the module and context components. the meat of this type is </cmt> <cmt> the two conversion functions, which transfer ownership of either the </cmt> <cmt> module component to the caller or the module and context to orcjit. </cmt> <cmt> this is because orc enforces an ownership contract that is distinct from </cmt> <cmt> llvm's rather wild ownership story for modules and their associated </cmt> <cmt> contexts. see </cmt> <cmt> sequester the repl's linking machinery </cmt> <cmt> all of this is in service of working around a pile of deficiencies in llvm's module linker, and llvmcontext abstractions. and because we're just gonna scrap this code soon anyways, it's probably not worth the effort to push on these bugs to block the broader cleanup here. </cmt> <cmt> the llvm linker currently does not support linking modules allocated in different contexts. this appears to be motivated in part by llvm's lack of a facility to clone a module from one context to another. this, in turn, appears to be motivated in part by llvmcontext's lack of a robust notion of identity - which makes it harder than it needs to be to detect the mismatch. </cmt> <cmt> however, it is not impossible to clone a module across contexts. we need to get creative and round-trip the module through some serialization layer. out of convenience, that layer is currently textual ir, though bitcode would work equally well. </cmt> <cmt> given that it is no longer under the caller's control which llvmcontext we generate code in, put all the above together to arrive at an egregious hack that clones the module into the llvmcontext the repl expects. </cmt>",give irgenmodule ownership of its llvmcontext
724,<desc> fixes issue: #4701 added solution to meetup problem in c++. </desc> <cmt> strwn codechef challenge in c++ </cmt> <cmt> adding newsch problem and solution </cmt> <cmt> adding newsch problem and solution </cmt> <cmt> adding bacrep problem and solution </cmt> <cmt> problem and solution for hill jumping in c++ </cmt> <cmt> solution to codechef problem in c++ </cmt> <cmt> meetup problem and solution in c++ </cmt>,solution to meetup codechef problem in c++
725,"<desc> op(warpctc) error message enhancement for both c++ and python, and provide unittest. op(add_position_encoding) error message enhancement for both c++ and python, and provide unittest. op(scaled_dot_product_attention) error message enhancement for python, and provide unittest. </desc> <cmt> enhance add_position_encoding error message, test=develop </cmt> <cmt> enhance warpctc & scaled_dot_product_attention error message, test=develop </cmt>","op(warpctc, add_position_encoding, scaled_dot_product_attention) error message enhancement"
726,"<desc> this pull request contains our proposed fix for #15341.  we are essentially protecting calls that modify the socket registry using a mutex lock. </desc> <cmt> created new mutex, ""socketregistrylock,"" to be used as a lock to protect the socket registry. </cmt> <cmt> wrapped all calls to ""closesocketbyconnection"" and ""tracksocketusedbyconnection"" in ""websocket_to_posix_proxy.cpp"" with ""lock_mutex(&socketregistrylock)""/""unlock_mutex(&socketregistrylock)"" pairs. </cmt> <cmt> this fixes emscripten bug #15341 in our testing. </cmt> <cmt> created new mutex, ""socketregistrylock,"" to be used as a lock to protect the socket registry. </cmt> <cmt> wrapped all calls to ""closesocketbyconnection"" and ""tracksocketusedbyconnection"" in ""websocket_to_posix_proxy.cpp"" with ""lock_mutex(&socketregistrylock)""/""unlock_mutex(&socketregistrylock)"" pairs. </cmt>",proposed fix for race condition in websocket_to_posix_proxy (#15341)
727,"<desc> as far as i am aware, all other instances of the link should be derived/created for doc/man/etc. </desc> <cmt> fixed link to cachedir spec in docs to address #4140 </cmt> <cmt> fixed link to cachedir spec in fs helper to address #4140 </cmt>",fixed links to cachedir spec in docs and code to address #4140
728,"<desc> cherry-pick of #8359 to swift-3.1-branch, correcting the code that emits dependencies when using bridging pch. note: depends on matching clang change apple/swift-clang#77 rdar://31486869 </desc> <cmt> [clangimporter] collect deps via subclass of clang::dependencycollector. </cmt> <cmt> [dependencies] sort external file dependencies by more-stable order. </cmt> <cmt> [dependencies] address review comments. </cmt>",rdar 31486869 corrected bridging pch dependencies swift 3.1 branch
729,"<desc> based on #67866 updated in community.general in ansible-collections/community.general#113 fix for cve-2020-1746 module options that circumvent ansible's option handling were disallowed in:  additionally, this particular usage can be insecure if bind_pw is set this way as the password could end up in a logfile or displayed on stdout. backport of ansible-collections/community.general#113 lib/ansible/modules/net_tools/ldap/ldap_entry.py lib/ansible/modules/net_tools/ldap/_ldap_attr.py </desc> <cmt> remove the params module option from ldap_attr and ldap_entry </cmt> <cmt> module options that circumvent ansible's option handling were disallowed </cmt> <cmt> in: </cmt> <cmt>  </cmt> <cmt> additionally, this particular usage can be insecure if bind_pw is set </cmt> <cmt> this way as the password could end up in a logfile or displayed on </cmt> <cmt> stdout. </cmt> <cmt> fixes cve-2020-1746 </cmt> <cmt> (cherry picked from commit 0ff609f1bc5e391fa25710b9a0baaf669f347eb1) </cmt> <cmt> fix formatting for option names </cmt> <cmt> fix fail_json </cmt>",cve-2020-1746 - remove the params module option from ldap_attr and ldap_entry
730,"<desc> this pull request extends the scope of #1796 and #1812. if the user decides to rely on a manual call to bpf_probe_read, we don't try to rewrite its last argument. this is needed as the rewriter starts to recognize and rewrite more and more dereferences. in particular, it fixes #1823's builds. </desc> <cmt> skip all dereferences inside bpf_probe_read calls </cmt> <cmt> if the user decides to rely on a manual call to bpf_probe_read, we </cmt> <cmt> don't try to rewrite its last argument.  this is needed as the </cmt> <cmt> rewriter starts to recognize and rewrite more and more dereferences. </cmt> <cmt> tools: fix dereferences following 1a765a17 </cmt>",skip dereferences inside bpf_probe_reads calls
731,<desc> this is a backport of #61207 per the discussion in compiler steering meeting r? @centril </desc> <cmt> allow lifetime elision in pin<&(mut) self> </cmt> <cmt> remove query for .pin_type() </cmt> <cmt> make is_self_ty a method on selfvisitor </cmt> <cmt> use set1<region> instead of option<region> </cmt>,"emergency backport of ""arbitrary self types lifetime elision 2"""
732,"<desc> we avoided adding kwargs for a long time in order to encourage people to statically register their environment definitions. however, over time we've found a few important use-cases for kwargs, such as: runtime-specific objects, such as which gpu to run the environment on parametrized environments, which can have an infinite number of meaningful variants the latter breaks the invariant that the environment id alone determines the semantics of the environment, but it's an advanced use-case and such users should be able to manage this on their own. this pr also exports the register method so people can register their own environments more easily. </desc> <cmt> support kwargs in gym.make </cmt> <cmt> we avoided adding kwargs for a long time in order to encourage people </cmt> <cmt> to statically register their environment definitions. however, over </cmt> <cmt> time we've found a few important use-cases for kwargs, such as: </cmt> <cmt> - runtime-specific objects, such as which gpu to run the environment </cmt> <cmt> on </cmt> <cmt> - parametrized environments, which can have an infinite number of meaningful </cmt> <cmt> variants </cmt> <cmt> the latter breaks the invariant that the environment id alone </cmt> <cmt> determines the semantics of the environment, but it's an advanced </cmt> <cmt> use-case and such users should be able to manage this on their own. </cmt> <cmt> export the register method so it's easier for external users to register environments </cmt>",support kwargs in gym.make and export register
733,"<desc> fixes #7994 this pr aims to more heavily promote our database engine across our documentation, and reduce the number of artifacts in various docs that referred to older databases as though they were the current default/de-facto way of increasing metrics retention. component name docs/ database/ database/engine </desc> <cmt> fixes to docs home and readme </cmt> <cmt> edit conf-guide and getting-started </cmt> <cmt> add dbengine settings to map </cmt> <cmt> fix tutorial and step-by-step </cmt> <cmt> fix artifacts of old memory mode types </cmt> <cmt> a few tweaks </cmt> <cmt> push a little harder on readme </cmt> <iss> docs: emphasize db engine and promote long-term metrics storage </iss>",promote db engine/long-term metrics storage more heavily
734,<desc> @sentry/nextjs support has changed as it now supports version from 10.0.8 also meaning they support next.js 12 make sure the linting passes by running yarn lint </desc> <cmt> docs: updating sentry example readme </cmt> <cmt> docs: changing text </cmt>,update sentry example readme to mention next.js 12 support
735,<desc> description: @balloob this was what you where talking about a couple of weeks back right? checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> dont enable daylight sensor by default </cmt> <cmt> fix tests </cmt>,deconz - disable daylight sensor by default
736,"<desc> this pr adds support for ue 4.25 while attempting to remain backwards compatible. changes: (primarily targeting linux) block vr plugins to avoid stdlibc++ incompatibilities. set default settings in blockseditor.target.cs (recommended in ue 4.24, possibly enforced in 4.25), otherwise the engine complains during build. fmodulemanager include file explicitly required in 4.25? removed unnecessary 4.15.build/target.cs files building and packaging tested with ue 4.25 and 4.24 on linux. </desc> <cmt> block vr plugins, add fmodulemanager include for 4.25 compat </cmt> <cmt> enforce default settings for non-custom settings, remove legacy build.cs files </cmt>",add support for unreal engine 4.25
737,"<desc> relates to #27891 creates a sub-set build of typescript which is only the require(""typescript"") api. this means that folks who build tools which use typescript under the hood can rely on this smaller dependency. todo: get the current package and extract it to a subfolder, which the script can work on rm -rf tmp/package; npm pack; tar -xvzf typescript-3.7.0.tgz -c tmp; rm typescript-3.7.0.tgz; ./bin/tsc scripts/configuretscbuild.ts; node scripts/configuretscbuild.js tmp/package/package.json make the deploy process also ship the additional package add additional automated tests of the dependency test this build on a few repos i've tested moving some medium projects like danger-js and tsd to use this module in their imports and it's worked, but the projects need to be up to date as it's the 3.7.0 build. </desc> <cmt> add a command for stripping the dependency down </cmt> <cmt> improve the gitignore / npm ignore </cmt> <cmt> more work on generating a small typescript build </cmt>",creates a smaller build of typescript which just has the language services
738,<desc> updated python samples in continuation of #5790 added missing __doc__ strings to examples adapted _doc.py for py2/py3 compatibility added .gitignore for tmp files created by examples added _tutorials_url.txt with link to opencv python tutorials expanded calibrate.py: calculate and save undistorted images based on calibration the changed files in this pull request run with python 2.7.11 and python 3.4.3 on windows x64 with opencv 3.0.0. </desc> <cmt> adapted for py2/py3 compatibility </cmt> <cmt> added .gitignore for tmp files created by examples </cmt> <cmt> added docstring to python files </cmt>,added missing docstrings to python samples
739,"<desc> this pr adds the togglepanezoom action, which can be used to make a pane expand to fill the entire contents of the window. closes #996 i work here requires documentation to be updated for discussion do we like the zoom icon in the tab? do we like the borders on all sides? alternate options discussed: borders on no sides borders only on the sides that the pane normally would have had (as if the border was zoomed as well dotted-line borders zoomed in and out a bunch. tried closing panes while zoomed. tried splitting panes while zoomed. etc. </desc> <cmt> this is a prototype for #996, pane zooming. there's some odd edge cases, but it works _pretty_ well </cmt> <cmt> add a border on all sides when zoomed </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/cascadia/terminalapp/tab.cpp </cmt> <cmt> this works shockingly well </cmt> <cmt> add a zoom icon too </cmt> <cmt> cleanup for review </cmt> <iss> the user should be able to zoom a pane </iss>",add a togglepanezoom action for zooming a pane
740,<desc> added events and errors that trigger when a user leaves a room. that way it can communicate with the apps-engine by the ipreroomuserleave and ipostroomuserleave event interfaces. complements rocketchat/rocket.chat.apps-engine#387 </desc> <cmt> add pre/post user leave to app listeners </cmt> <cmt> add events and errors when user leaves a room </cmt>,new event interfaces for pre/post user leaving a room
741,"<desc> review url this is the new spaservices doc which is intended to serve as a reference rather than an end-to-end tutorial. the goal is to focus on what spaservices offers to developers creating spas with asp.net core. please review. </desc> <cmt> initial commit for revised spaservices doc </cmt> <cmt> add tag helpers text and code </cmt> <cmt> add screenshot of global postlist variable </cmt> <cmt> restore tag helpers code sample to original state </cmt> <cmt> adjust tag helpers heading styles </cmt> <cmt> add webpack dev middleware code and text </cmt> <cmt> reorganize headings and start to hmr content </cmt> <cmt> hmr changes </cmt> <cmt> additional tweaks to content </cmt> <cmt> add hmr screenshot and finish spaservices prereqs section </cmt> <cmt> start to project creation content for .net core cli </cmt> <cmt> add karma / jasmine testing content </cmt> <cmt> more minor tweaks </cmt> <cmt> refine existing content </cmt> <cmt> remove unused tag helper from index view </cmt> <cmt> update toc </cmt> <cmt> start publishing section of content </cmt> <cmt> finish writing publishing section of content </cmt> <cmt> remove original, unused images </cmt> <cmt> replace future tense usage </cmt>",add spaservices with asp.net core doc
742,"<desc> knockout: ko.subscribable don't provide read/write functionality, so it moved into ko.observable and ko.computed knockout.rx: typing for rxjs binding to knockoutjs </desc> <cmt> added knockout.rx definitions </cmt> <cmt> rxjs-knockout binding < </cmt> <cmt> removed read and write functions from subscribable </cmt> <cmt> read/write defined only in observable and computed </cmt> <cmt> knockout.rx: added toobservablewithreplylatest </cmt> <cmt> added description for the knockout.rx definition </cmt> <cmt> knockout.rx: added ts compiler parameters for tests </cmt>",minor changes in knockout; added knockout.rx definitions
743,"<desc> explanation: introducing the global key path subscript operation introduced an ambiguity bug for code that tried to reference functions named subscript (using backtick quoted identifiers). this is fixed more deeply on master by #9989; this is a focused compatibility fix for 4.0. scope: source compatibility regression; impacts ability to use appkit because nstext has a -subscript: action. issue: sr-5513 | rdar://problem/33413614 risk: low, targeted bug fix testing: swift ci, example from jira </desc> <cmt> sema: avoid asking for the secondtype of constraints that don't have them. </cmt> <cmt> assertions tripped while trying to reproduce sr-5513. </cmt> <cmt> sema: only consider key path application for member lookup for subscriptexprs. </cmt> <cmt> interactions with the rest of the type checker cause use of functions named subscript with backtick-quotes to become ambiguous. this is more fully and robustly solved in master by #9989, but that's too invasive a change for 4.0, and we need a spot fix to prevent source compatibility regressions such as sr-5513. </cmt>",don't consider keypathapplication operations when looking up non-subscriptexprs.
744,"<desc> the output of saved_model_cli.py was a bit hard to read, so i added some indentation to make the variable/graph information easier to take in at a glance. before: metagraphdef with tag-set: 'serve' contains the following signaturedefs: signature_def['classify_x2_to_y3']: the given savedmodel signaturedef contains the following input(s): inputs['inputs'] tensor_info: dtype: dt_float shape: (-1, 1) name: x2:0 the given savedmodel signaturedef contains the following output(s): outputs['scores'] tensor_info: dtype: dt_float shape: (-1, 1) name: y3:0 method name is: tensorflow/serving/classify after: metagraphdef with tag-set: 'serve' contains the following signaturedefs: signature_def['classify_x2_to_y3']: the given savedmodel signaturedef contains the following input(s): inputs['inputs'] tensor_info: dtype: dt_float shape: (-1, 1) name: x2:0 the given savedmodel signaturedef contains the following output(s): outputs['scores'] tensor_info: dtype: dt_float shape: (-1, 1) name: y3:0 method name is: tensorflow/serving/classify i updated the documentation and unit tests accordingly. i also fixed the formatting of some of the ""usage"" messages in saved_model_cli.py. </desc> <cmt> fix spacing in output of saved_model_cli.py </cmt> <cmt> fixed a problem with the merge. </cmt> <cmt> fixing out-of-date canned output in regression test </cmt> <cmt> pylint issues </cmt>",clean up output formatting of saved_model_cli.py
745,<desc> this is a slight improvement of the common tests. actually more should be refactored but i think this at least gives more meaningful errors. </desc> <cmt> enh use nostests yield construct for better error reporting in common tests. </cmt> <cmt> enh give yielded tests nicer names </cmt>,mrg use yield to generate common tests.
746,"<desc> this pr reverts changes that were merged in #14971 which are unsafe and were experimentally pushed by @elevatebart. ns-resize and ew-resize doesn't work for us because: col-resize is a standard for 2 dimensional resize which is used everywhere it is breaking the current iframe ""covering"" which shows the col-resize. borders are required for bigger resizer event handling are also this pr renames app.tsx to runnerct.tsx for search-ability. screen.recording.2021-02-09.at.12.30.36.mov </desc> <cmt> revert unnecessary changes </cmt> <cmt> chnage runner ct core component name to be searchable </cmt>",revert changes from resizer pr
747,<desc> cherry-picks kubernetes/kube-openapi#64 and kubernetes/kube-openapi#67 fixes bugs that make apiserver panic when aggregating valid but not well formed openapi spec (with empty paths/definitions) release note: fixes bugs that make apiserver panic when aggregating valid but not well formed openapi spec / /sig api-machinery </desc> <cmt> cherrypick kube-openapi changes </cmt> <cmt> bump godep against kube-openapi/release-1.10 branch </cmt> <cmt> generated </cmt>,manual cherrypick of kube-openapi changes for release-1.10
748,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add support for resolvesthis() to the sinonstub definition </cmt> <cmt> whitespace complaints with lint </cmt>,add resolves this to sinon stub
749,<desc> hey! i've fully translated the entire document into russian. i think it would be handy for russian-speaking developer community. i've also added link to the russian version in other versions. thank you </desc> <cmt> meta & basics sections are translated into russian </cmt> <cmt> couple of fixes to first 2 sections </cmt> <cmt> everyday use section is updated </cmt> <cmt> last 3 sections translated </cmt> <cmt> halfway through file processing section </cmt> <cmt> file processing finished & macos section corrected </cmt> <cmt> one liners translated </cmt> <cmt> first version of russian translation </cmt> <cmt> add links to russian translation everywhere </cmt>,russian version of the art of command line
750,"<desc> sqlite3 on macos platforms is only used by localstorage.h see comments: /** local storage support for the js bindings.*/ /** initializes the database. if path is null, it will create an in-memory db. */ void cc_dll localstorageinit( const std::string& fullpath = """"); only cocos2djs libs need to depend sqlite3, not cocos2d core libs </desc> <cmt> fix cmkae dumplicate include dir in macos </cmt> <cmt> reduce outer effect when fix js-tests sqlite link error </cmt> <cmt> improve fix dumplicate include-dir </cmt> <cmt> sqlite3 use error </cmt>",fix cmake use sqlite3 error on macos
751,"<desc> a rename from router to mesh has occurred, so i'm doing a straightforward swap. additionally, i've found that using a single static scope value makes concurrent test runs impossible. this fixes that. manual run. i will trigger runs of the other k8s interop tests once i have lgtm. grpc/core/master/linux/psm-security grpc/core/master/linux/grpc_xds_k8s_lb grpc/core/master/linux/grpc_xds_url_map </desc> <cmt> add unique suffix to scope </cmt> <cmt> actually add suffix </cmt> <cmt> switch from router to mesh </cmt> <cmt> yapf </cmt>",switch router to mesh and add unique string to scope
752,"<desc> no-issue this includes updates to the member-api module, which allow us to create members after receiving payment from stripe. </desc> <cmt> passed appinfo to members-api stripe instance </cmt> <cmt> no-issue </cmt> <cmt> updated member.plans to member.stripe.subscriptions </cmt> <cmt> no-issue </cmt> <cmt> this is to support the new format in which stripe information is </cmt> <cmt> returned from the members-api module. </cmt> <cmt> allowed checkout flow to be started without member </cmt> <cmt> no-issue </cmt> <cmt> this will allow non-logged in members to start the stripe checkout flow, </cmt> <cmt> which will result in a webhook being sent </cmt> <cmt> updated members api to use middleware exposed </cmt> <cmt> no-issue </cmt> <cmt> wired up the members webhook handler endpoint </cmt> <cmt> no-issue </cmt> <cmt> passed the set/get metadata methods to members-api </cmt> <cmt> no-issue </cmt>",allowed for member to be created from stripe checkout
753,"<desc> reverts the ip allocator portions of #83422, adds unit test covering #86497 scenario fixes #86497 does this pr introduce a user-facing change?: fixes v1.17.0 regression in --service-cluster-ip-range handling with ipv4 ranges larger than 65536 ip addresses </desc> <cmt> revert ""remove ipallocator in favor of k/utils net package"" </cmt> <cmt> this reverts commit f984b4c7a27889234d3c863a99ba2bcef44bb345. </cmt> <cmt> add unit test for extended ipv4 service ip range </cmt> <iss> service is not within the service cidr please recreate </iss>",restore ipallocator ipv4 range handling
754,"<desc> this pr adds (invariant) aliases for commonly used dtype-like objects, similar to what #18050 has done for array-likes. note that the aliases introduced herein are currently unused (beyond their introduction). this will change once we start adding dtype-support to the ufuncs, something that's on the to-do list for after the ufunc-based ndarray magic methods have been wrapped up (xref #18128 and #18228). secondly, it performs a small follow-up on #13578, i.e. objects with the .dtype attribute are now only considered dtype-like if aforementioned attribute returns a np.dtype instance. examples example usage of the new _dtypelike<x> aliases in annotating a simplified version of np.bitwise_or. from __future__ import annotations from typing import any, overload import numpy as np import numpy.typing as npt @overload def bitwise_or( __x1: npt._arraylikebool_co, __x2: npt._arraylikebool_co, *, dtype: npt._dtypelikebool | none = ..., ) -> np.ndarray[any, np.dtype[np.bool_]]: ... @overload def bitwise_or( __x1: npt._arraylikeuint_co, __x2: npt._arraylikeuint_co, *, dtype: npt._dtypelikeuint | none = ..., ) -> np.ndarray[any, np.dtype[np.unsignedinteger[any]]: ... @overload def bitwise_or( __x1: npt._arraylikeint_co, __x2: npt._arraylikeint_co, *, dtype: npt._dtypelikeint | none = ..., ) -> np.ndarray[any, np.dtype[np.signedinteger[any]]: ... </desc> <cmt> maint: ensure that the _supportsdtype protocol can only take dtypes; not arbitrary dtype-like objects </cmt> <cmt> xref </cmt> <cmt> enh: added aliases for commonly used dtype-like objects </cmt>",add aliases for commonly used dtype-like objects
755,"<desc> added the code used in the article, as well as scripts to compile c++ files and make native lib in linux, windows and macos </desc> <cmt> bael-1546: java 8 math additions </cmt> <cmt> applied feedback to unit tests </cmt> <cmt> bael-1546 added missing test annotations </cmt> <cmt> merge upstream to my fork </cmt> <cmt> added code for bael-1637 </cmt> <cmt> added script for windows c++ code compile </cmt>",guide to jni(java native interface)
756,"<desc> addresses  the few remaining cases left to ordinary json.stringify were left because of one of the following: stringifying an object made inline, so we know it can't be circular using additional formatting on json.stringify, which the safestringify function doesn't yet incorporate. </desc> <cmt> removing further calls to unguarded stringify when input data is unknown or to be displayed </cmt> <cmt> updating one more react component </cmt>",removing additional unguarded calls to json.stringify
757,"<desc> fix ""yarn enoent"" in windows throw when no files matches fix gitignore not working on windows </desc> <cmt> fix ""yarn enoent"" in windows </cmt> <cmt> throw when no files matches </cmt> <cmt> fix gitignore not working on windows </cmt> <cmt> revert process.env not being forwarded </cmt>",fix various issues with the new cli on windows
758,"<desc> the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. this adds definitions to add additional layers such as traffic through googlemutant. the arguments passed through to google maps vary but seem to either be an object or none. </desc> <cmt> addgooglelayer and removegooglelayer </cmt> <cmt> prettier </cmt>",add googlelayer methods to googlemutant interface
759,"<desc> fab tooltip was only appearing when the icon widget inside of the fab was long pressed, but not when the edge of the button was long pressed. fixed by moving tooltip addition to after the rawmaterialbutton creation, so that the tooltip wraps the whole button. had to merge semantics to keep the semantics information. added unit test for long press outside of the icon. closes #20051 </desc> <cmt> [fab] updated tooltip touch target. </cmt> <cmt> remove ""new"" keyword </cmt> <cmt> [fab] updated tooltip touch target. </cmt> <cmt> 'long press' in test instead of tap </cmt> <cmt> ""long press button edge"" </cmt> <cmt> remove new </cmt> <cmt> remove new </cmt> <iss> tooltips do not always show up when long pressing an fab </iss>",fix 20051 fab tooltip touch target
760,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>.  hemantnegi/jquery.sumoselect@400aa23#diff-a8a3fec48519f9a9f49beb8643b8a3e6e7db21a283a471110290d95144711d2br734-r758 </desc> <cmt> feat: add max options </cmt> <cmt> feat: add renderli options </cmt> <cmt> feat: add removeall methods </cmt> <cmt> feat: add find methods </cmt> <cmt> feat: match it to the library package versions </cmt>,"add types of max, renderli, removeall, find in sumoselect"
761,<desc> add callouts to the docs to make people aware that: bootstrap does not support third-party js libraries. bootstrap only supports less.js for less compilation. this pull request addresses #8288 and #8289. @mdo i'm not sure if this is what you had in mind - wording is of course adjustable :). </desc> <cmt> add callout to docs: 3rd-party libs not supported </cmt> <cmt> add callout to docs: less compiler support </cmt>,add new callouts to docs
762,<desc> fixes #1010 </desc> <cmt> add eaze to list of companies using standard </cmt> <cmt> add ctrl alt deseat to list companies using standard </cmt> <cmt> fix github rendering issue </cmt> <iss> add eaze to the list of users </iss>,add eaze and ctrl alt deseat to list of companies using standard
763,"<desc> a few cleanup and tighten screws: when a processor is closed (due to topology-closure), we should not allow processing more records. let all built-in processors to extend from abstractprocessor. remove duplicated override functions. </desc> <cmt> first commit </cmt> <cmt> major fixes </cmt> <cmt> flush cache before commit </cmt> <cmt> suppression buffer needs to be flushed too </cmt> <cmt> rebased on trunk </cmt> <cmt> github comments </cmt> <cmt> re-order commit and suspend </cmt> <cmt> forbid process after closing </cmt>",follow-up; forbid process after closed
764,"<desc> i felt like the model validation topic needed to explain better the link between validation attributes, tag helpers, jquery unobtrusive validation, and the jquery validate plugin.  these technologies interact in complex ways, and i found myself having to dig all around the internet to understand these interactions while developing my own apps.  it would've been nice to have a high-level introduction (with links) in the asp.net core docs themselves. fixes #4750 suggested reviewers: @rachelappel @rick-anderson @isaac2004 @guardrex @v-anpasi </desc> <cmt> added more details on remote validation to the mvc model validation page </cmt> <cmt> described the attribute -> tag helper -> jquery unobtrusive validation -> jquery validate flow for client-side validation in a little more detail. </cmt>",added references to jquery validate plugins in the model validation topic
765,"<desc> goal: improve user experience / reduce confusions. original pr (master branch): #48578 this pr logs a warning message to the tensorflow customers in the following cases when onednn optimization does not support int8 inference/training: (1) stock tensorflow, with onednn optimizations enabled (in this case, int8 is not supported at all. (2) intel optimized tensorflow (aka, build with --config=mkl): in this case, the warning message reminds the user to set a proper environment variable before running int8 inference/training. </desc> <cmt> add a warning message for build/setting which does not support int8 </cmt> <cmt> coding style fix and minor changes of warning message per review suggestion </cmt> <cmt> fix warning message </cmt>",log a warning message when int8 is not supported
766,"<desc> this pr isn't ready for pulling yet. having a pr makes it a bit easier on github to see and test the changes. i accidentally included #2474 into this pr as well. this adds optional support for java arrays instead of buffers to the gl20 interface. leaving it up to the backend on how to translate between the java array and the opengl call. this removes the sometimes unneeded copy from java array to buffer and back. only added the most obvious methods (genbuffer, uniformfv, etc). i've tested the implementation of lwjgl and android (e.g. by running skeletontest, probably needs more testing though). i did implement, but haven't tested gwt yet. haven't looked at the robovm and jglfw implementation yet. </desc> <cmt> add protected mesh constructor and move invalidate to vertexdata </cmt> <cmt> add gl20 method not requiring an intbuffer/floatbuffer </cmt> <cmt> implement method without intbuffer/floatbuffer arguments for lwjgl </cmt> <cmt> implement gwtgl20 methods not requiring a floatbuffer or intbuffer </cmt> <cmt> add android backend, still need to add to jni though </cmt> <cmt> update shaderprogram#setuniformmatrix </cmt> <cmt> looks like count is ignored in lwjgl uniformmatrix </cmt> <cmt> add android jni gl implementation and some minor lwjgl changes (mostly formatting) </cmt>",add critical arrays to gl interface
767,"<desc> this is related to #27802. this commit adds a jar called elasticsearch-nio that contains the base nio classes that will be used for the tcp nio transport and eventually the http nio transport. the jar does not depend on elasticsearch:core, so all references to core have been removed. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> a few cleanups </cmt>",add elasticsearch-nio jar for base nio classes
768,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description previously, the search failed if the key was in between two blocks. the search functions have also been integrated like other search function and are not anymore special cases in do_string_search function. test plan one test have been added. closing issues none. ... </desc> <cmt> fix search of key between two blocks </cmt> <cmt> update search for private key search </cmt> <cmt> update crypto key search to find keys between blocks </cmt>",update crypto key search to find keys between blocks ##search
769,"<desc> visually improved the read me file, so it looks more appealing to (new) users: added hero image at the top with the new powertoys logo added screenshots for all modules added keyboard manager and powertoys run (@crutkas proper descriptions are still needed there) for version 0.18. i'm using  to align the text correctly with the images. using the  html tag to make sure that the text can float to the right next to the image. added 3 'shortcuts' after the project description (download / release notes / contribution references #2766 pr checklist applies to #2766 cla signed. if not, go over here and sign the cla </desc> <cmt> adding screenshots and hero image </cmt> <cmt> added screenshots and kbm + launcher descriptions </cmt> <cmt> commented out 0.18 features (kbm + launcher) </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> updated contribution link </cmt> <cmt> linebreak added </cmt>",adding hero-image (including new icon) and module screenshots
770,<desc> fixes some issues brought up after this pr (#31215) was already merged.  also fixes issues related to indices options where they should be parameters rather than part of the request body. </desc> <cmt> follow up for snapshotcreate rest client code based on pr feedback. </cmt> <cmt> fix parameters for indicesoptions. </cmt> <cmt> fix documentation. </cmt>,clean up snapshot create rest api
771,"<desc> in #618 (specifically commit d91c934), ocsp updater thread has started to access environ during its boot-up phase.  however at the same time main thread is trying to unset server_starter_port environment variable. this has caused a race condition issue that is easy to be observed on freebsd. </desc> <cmt> do not expect environ to be unchanged </cmt> <cmt> unsetenv server_starter_port before applying configurators, that invokes ocsp updater threads that need to iterate over environ in h2o_spawnp </cmt>",fix race condition in environ access
772,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> sync fork </cmt> <cmt> update fork </cmt> <cmt> update fork </cmt> <cmt> reupload </cmt> <cmt> update fork </cmt> <cmt> sync fork </cmt> <cmt> include mypy instructions </cmt> <cmt> delete file </cmt>,include mypy instructions in contributing.md
773,<desc> cherry-pick: #24996 #24970 </desc> <cmt> [tests] update the parseableinterface tests to use make-old.py due to nondeterministic timestamp issue with touch </cmt> <cmt> fix type in inputs path </cmt> <cmt> [tests] update the parseableinterface tests to use make-old.py due to nondeterministic timestamp issue with touch </cmt>,5.1 6/12 update parseableinterface tests
774,"<desc> changed mac os x, os x for new macos name (edit) fixes #4308 </desc> <cmt> changed for new name as ""macos""  (issue #4308) </cmt> <cmt> updated macos name </cmt> <cmt> update macos name </cmt> <cmt> updated macos name </cmt> <cmt> update for new macos name </cmt> <iss> mac os x, os x  macos </iss>",updated with new macos name (#4308)
775,"<desc> it allows for 3d attention mask in t5 model (modeling_t5.py) with an accompanying test. fixes #9643 this is a clean version for an earlier pr #10903. this is a solution for allowing the 3d attention mask in the t5 model by making it broadcastable. it is based on what is used in bert. members/contributors which may be interested in your pr. </desc> <cmt> add 3d attention mask to t5 model (#9643) </cmt> <cmt> added code for 3d attention mask in t5 model. similar to bert model. </cmt> <cmt> add test for 3d attention mask </cmt> <cmt> added test for 3d attention mask: test_decoder_model_past_with_3d_attn_mask() </cmt> <cmt> 3d attention mask of the shape [batch_size, seq_length, seq_length] both for </cmt> <cmt> attention mask and decoder attention mask. test is passing. </cmt> <iss> [feature request] add 3d attention mask for t5model </iss>",add 3d attention mask to t5 model (2) (#9643)
776,"<desc> please refer to the individual commit messages for additional details. </desc> <cmt> add a size getter, to dict instances, to provide an easier way of checking the number of entries </cmt> <cmt> this removes the need to manually call dict.getkeys() and check its length. </cmt> <cmt> add a getrawvalues method, to dict instances, to provide an easier way of getting all *raw* values </cmt> <cmt> when the old dict.getall() method was removed, it was replaced with a dict.getkeys() call and dict.get(...) calls (in a loop). </cmt> <cmt> while this pattern obviously makes a lot of sense in many cases, there's some instances where we actually want the *raw* dict values (i.e. refs where applicable). in those cases, dict.getraw(...) calls are instead used within the loop. however, by introducing a new dict.getrawvalues() method we can reduce the number of (strictly unnecessary) function calls by simply getting the *raw* dict values directly. </cmt> <cmt> remove unnecessary duplication in the addchildren helper function (used by the objectloader) </cmt> <cmt> besides being fewer lines of code overall, this also avoids *one* node instanceof dict check for both of the dict/stream-cases. </cmt>","add a new size getter and getrawvalues method, to dict instances, to simplify some code"
777,"<desc> i hereby agree to the terms of the cla available at:  continue #6620 category: </desc> <cmt> translate database engine documentation, update table engine documentation. </cmt> <cmt> translate database engine documentation, update table engine documentation. </cmt>",translate database engine documentation(zh)
778,"<desc> when creating a local vserver peer accept is not required, accept is only required if the peer is a remote vserver. this change fix a bug where a local peer would call the accept function and fail. na_ontap_vserver_peer.py </desc> <cmt> revert ""changes to cluster"" </cmt> <cmt> this reverts commit 33ee1b71e4bc8435fb315762a871f8c4cb6c5f80. </cmt> <cmt> revert ""revert ""changes to cluster"""" </cmt> <cmt> this reverts commit f1104a37b42886aebb4d2b2ab27c91c96d97858a. </cmt> <cmt> revert ""changes to cluster"" </cmt> <cmt> this reverts commit 33ee1b71e4bc8435fb315762a871f8c4cb6c5f80. </cmt> <cmt> revert ""revert ""changes to cluster"""" </cmt> <cmt> this reverts commit f1104a37b42886aebb4d2b2ab27c91c96d97858a. </cmt> <cmt> revert ""documentation changes"" </cmt> <cmt> this reverts commit 02c369d0414fdff492d90865c903bdade3174261. </cmt> <cmt> fix bug </cmt> <cmt> revert ""revert ""documentation changes"""" </cmt> <cmt> this reverts commit 496b91bebe407b36ca2c98ba6215dfb04153c8d1. </cmt>",fix bug when setting up a local vserver peer
779,<desc> adds support for the kbdpad mkii numpad. adds the kbdpad mkii my code follows the code style of this project. i have read the contributing document. </desc> <cmt> build some testing keymaps </cmt> <cmt> match naming convention to 8x </cmt> <cmt> add configurator json </cmt>,add support for kbdpad mkii
780,"<desc> when using the latest definitions for massive, using the following sample from the massive docs: db.query( 'select * from tests where id > ${something}', {something: 1} ).then(tests => { // all tests matching the criteria }); produces the following error: argument of type '{ something: string; }' is not assignable to parameter of type 'string[]'. object literal may only specify known properties, and 'something' does not exist in type 'string[]'. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add 'any' type signature to params on database.query to allow named sql parameters </cmt> <cmt> switch to object instead of any, per best practices </cmt>",allow named parameters to be passed to database.query
781,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix mapprops definition </cmt> <cmt> test mapprops fix </cmt> <cmt> fix lowlevelstylefunctionarguments definition </cmt> <cmt> test lowlevelstylefunctionarguments fix </cmt>",fix definitions for mapprops and lowlevelstylefunctionarguments
782,<desc> add integration test: trigger java lambda through sns issue fixed: #2968 pro:unable to trigger lambda through sns </desc> <cmt> change kinesis consumer timestamp format to unix timestamp (#2835) </cmt> <cmt> release v0.11.4 </cmt> <cmt> support int/str types for dynamodb globalsecondaryindex in cf templates (#2828) </cmt> <cmt>  conflicts: </cmt> <cmt> 	tests/integration/test_cloudformation.py </cmt> <cmt> fix cloudformation issue with api gw http_proxy integration. </cmt> <cmt> * fix uri value in integration object before sending to moto backend </cmt> <cmt> * add integration test </cmt> <cmt> issue fixed: </cmt> <cmt> #2930 localstack deployment fails with api gw http_proxy integration. </cmt> <cmt> add integration test: </cmt> <cmt> * trigger java lambda through sns </cmt> <cmt> issue fixed: </cmt> <cmt> #2968 pro:unable to trigger lambda through sns </cmt>,test lambda trigger java lambda by sns
783,"<desc> updated the painless loader to first look for classes that are already loaded as part of the definition initialization through the whitelist.  this allows for modules/plugins to whitelist custom classes without forcing painless to have a direct relationship with the module's/plugin's classloader. this also removes the singleton of definition, so now there will be one definition per compiler.  however, the standard whitelist files singleton still exists out of convenience for now for testing.  this should be cleaned up later in a different pr. @rjernst this will be difficult to properly test until we integrate directly with spi. </desc> <cmt> added definition to classloader. </cmt> <cmt> removal of static definition. </cmt>",modify loader to load classes directly from definition
784,"<desc> if use_v8 is set (desktop), then default to using v8 instead of the pre-jsi chakra executor. microsoft reviewers: open in codeflow </desc> <cmt> use v8 by default for desktop (if enabled) </cmt> <cmt> change files </cmt>",use v8 by default in desktop (if enabled)
785,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> mocha: allow string as a timeout option </cmt> <cmt> source: </cmt> <cmt>  </cmt> <cmt> update mocha-tests.ts </cmt>",add string for timeout option
786,<desc> apis that have been renamed or moved re-gained their old apis but as deprecated: task.rundetached -> detached group.add -> group.spawn task.withcancellationhandler -> withtaskcancellationhandler task.withgroup -> withtaskgroup / withthrowingtaskgroup </desc> <cmt> [concurrency] add deprecated shim for rundetached </cmt> <cmt> [concurrency] add deprecated shim for task.withgroup </cmt> <cmt> [concurrency] shim for deprecated task.withcancellationhandler </cmt>,"add 'deprecated' shims for removed ""old"" task apis to ease migration"
787,<desc> fix some docs pages that didn't document an objects full inheritance chain. fix #16345 </desc> <cmt> update camera and extras inheritance docs </cmt> <cmt> update geometry inheritance docs </cmt> <cmt> update remaining issues </cmt> <iss> consistently document class inheritance </iss>,consistently document full object inheritance
788,"<desc> next.js links can accept parsed url objects, this pr makes sure the material ui wrapper in the example can accept these as well. i have followed (at least) the pr section of the contributing guide. </desc> <cmt> make sure links can accept url objects </cmt> <cmt> just like next.js links can. </cmt> <cmt> accidental delete </cmt>",make sure next.js links can accept url objects as href
789,"<desc> adding my personal keymap for the plaid, and while doing so, clarified the led instructions for the default as well.  apologies for the two-things-at-once pull request, but it was not until i drafted the readme for my keymap that i realized the default could really use a tune up. none my code follows the code style of this project. i have read the contributing document. </desc> <cmt> adding led support for plaid </cmt> <cmt> adding led support for plaid </cmt> <cmt> plaid led </cmt> <cmt> update readme.md </cmt> <cmt> fixing bad markdown </cmt> <cmt> adding my personal keymap </cmt> <cmt> updating upstream, fixing readme formatting for plaid defaul </cmt> <cmt> clarifying led instructions / formatting </cmt>",adding personal keymap / clarifying default keymap readme
790,"<desc> in #34177 we converted the actioncable js package from coffeescript to es2015. the conversion was largely automated by decaffeinate, and then looked over manually to make it more idiomatic. looking again after some time away, i found a few more non-idiomatic artifacts from the coffeescript conversion that could be simplified, and i've addressed them in this pr: simplify actioncable.createconsumer by using default argument simplify actioncable.getconfig, connection#getprotocol, and connection#close by relying on the implicit undefined return value (instead of explicitly returning undefined) simplify this.isactive() && this.websocket into this.isactive() in connection#close. we can do this because isactive() can only return true if this.websocket is truthy. (we can't have an active connection without having instantiated a websocket. this is confirmed in the code: connection#isactive calls connection#isstate which calls connection#getstate, which checks if this.websocket is truthy and returns null otherwise.) </desc> <cmt> simplify actioncable.createconsumer by using default argument </cmt> <cmt> simplify actioncable.getconfig, connection#getprotocol, and connection#close </cmt> <cmt> by relying on the implicit undefined return value </cmt> <cmt> simplify this.isactive() && this.websocket into this.isactive() </cmt> <cmt> in connection#close. we can do this because isactive() can only </cmt> <cmt> return true if this.websocket is truthy. (we can't have an active </cmt> <cmt> connection without having instantiated a websocket. this is confirmed </cmt> <cmt> in the code: connection#isactive calls connection#isstate which calls </cmt> <cmt> connection#getstate, which checks if this.websocket is truthy and </cmt> <cmt> returns null otherwise.) </cmt>",clean up actioncable js a bit more after the coffeescript conversion
791,"<desc> the word cloud chart options and the addevent / fireevent apis are used in my library ngx-highcharts. it is nice to have them static type supported in definitelytyped/highcharts. thank you. highcharts official documents:    add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: (see description above) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add the missing typings required by @howtimeflies/ngx-highcharts </cmt> <cmt> add tests for the new added typings. </cmt>",add support for word cloud chart and adding/firing events dynamically
792,"<desc> with this pr we use control flow analysis of this.xxx assignments in constructors to determine the types of properties that have no type annotations or initializers. in .ts files we perform control flow analysis for properties declared with no type annotation or initializer when in noimplicitany mode. in .js files we perform control flow analysis for properties declared with no jsdoc type annotation or initializer, and properties with no explicit declaration but at least one this.xxx assignment in the constructor. in the following example, control flow analysis determines the type of x to be string | number based on the this.x assignments in the constructor: // compile with --noimplicitany class c { x;  // string | number constructor(b: boolean) { if (b) { this.x = 'hello'; } else { this.x = 42; } } } in .js files we would previously determine the type of a property with no explicit declaration from local analysis of all this.xxx assignments seen in the constructor and methods of the class. this analysis is less precise than control flow analysis, but we still use it as a fallback. with the increased precision of control flow analysis we now correctly discover properties that are conditionally (as opposed to definitely) initialized in constructors. we're also able to handle assignments of values that depend on previous assignment to the same property, as well as other scenarios that previously were deemed circular. the baseline changes are mostly because constructor declared properties are now considered to have type any when they are assignment targets in the constructor body. this an effect of how cfa auto-typing works. fixes #37900. </desc> <cmt> use cfa to determine types of properties declared by this.xxx assignments </cmt> <cmt> accept new baselines </cmt> <iss> this-property assignments should use autotype to get control flow narrowing </iss>",control flow for constructor initialized properties
793,<desc> install should dedupe dependencies avoiding conflicts 5 - tests scenario fixed in #67 update scenario that we are going to use in fbsource/react-native. checks that everything gets cleaned up correctly. and currently fails. </desc> <cmt> added unit test for fixed #67 issue </cmt> <cmt> added update scenario </cmt>,added new e2e tests for install commands
794,"<desc> i have followed (at least) the pr section of the contributing guide. see the original issue for a little background. here is a demo of the changes, the important bit is how well things line up on the rightmost column when using components with implicit heights while not having to know said height in advance. closes #21008 </desc> <cmt> get width / height from children when passed to skeleton </cmt> <cmt> add fullwidth prop to skeleton </cmt> <cmt> api docs </cmt> <cmt> demos </cmt> <cmt> drop fullwidth in favor of accepting width / height </cmt> <cmt> fix warning in skeleton demo </cmt> <iss> [skeleton] allow children to influence height </iss>",allow children to influence width and height
795,<desc> i've add button-story-with-args code snippets to what-a-story.md documentation for html framework. code snippets contain javascript and typescript versions of button-story-with-args snippet. it's possible to test by using frontpage repo  with a link to docs in current branch. follow the instructions from preview your work documentation to start frontpage server open in browser </desc> <cmt> add button-story-with-args.js snippet for html framework </cmt> <cmt> add button-story-with-args.ts snippet for html framework </cmt>,button story with args snippets for html framework
796,"<desc> adds support for tty in the composefile v3 format, used it docker stack deploy --compose-file . / this bumps compose-file to 8cff34df885ef07824138236bc4d27d359888b17. </desc> <cmt> update compose-file to 8cff34df885ef07824138236bc4d27d359888b17 </cmt> <cmt> add support for tty in composefile v3 </cmt>",add support for tty in compose to swarm
797,"<desc> bpo-30776: reduce regrtest -r false positives (#2422) bpo-30764: regrtest: add --fail-env-changed option (#2402) bpo-30523: regrtest --list-cases --match (#2401) </desc> <cmt> bpo-30523: regrtest --list-cases --match (#2401) </cmt> <cmt> * regrtest --list-cases now supports --match and --match-file options. </cmt> <cmt> example: ./python -m test --list-cases -m filetests test_os </cmt> <cmt> * --list-cases now also sets support.verbose to false to prevent </cmt> <cmt> messages to stdout when loading test modules. </cmt> <cmt> * add support._match_test() private function. </cmt> <cmt> (cherry picked from commit ace56d583664f855d89d1219ece7c21c2fddcf30) </cmt> <cmt> bpo-30764: regrtest: add --fail-env-changed option (#2402) </cmt> <cmt> * bpo-30764: regrtest: change exit code on failure </cmt> <cmt> * exit code 2 if failed tests (""bad"") </cmt> <cmt> * exit code 3 if interrupted </cmt> <cmt> * bpo-30764: regrtest: add --fail-env-changed option </cmt> <cmt> if the option is set, mark a test as failed if it alters the </cmt> <cmt> environment, for example if it creates a file without removing it. </cmt> <cmt> (cherry picked from commit 63f54c68936d648c70ca411661e4208329edcf26) </cmt> <cmt> bpo-30776: reduce regrtest -r false positives (#2422) </cmt> <cmt> * change the regrtest --huntrleaks checker to decide if a test file </cmt> <cmt> leaks or not. require that each run leaks at least 1 reference. </cmt> <cmt> * warmup runs are now completely ignored: ignored in the checker test </cmt> <cmt> and not used anymore to compute the sum. </cmt> <cmt> * add an unit test for a reference leak. </cmt> <cmt> example of reference differences previously considered a failure </cmt> <cmt> (leak) and now considered as success (success, no leak): </cmt> <cmt> [3, 0, 0] </cmt> <cmt> [0, 1, 0] </cmt> <cmt> [8, -8, 1] </cmt> <cmt> (cherry picked from commit 48b5c422ffb03affb00c184b9a99e5537be92732) </cmt>","bpo-30523, bpo-30764, bpo-30776: sync regrtest from master"
798,<desc> summary updates v2 migration guide with a section about potential conflicts with root level .babelrc configuration files discussed here here advised on the approach here </desc> <cmt> section for babel and jest </cmt> <cmt> update language </cmt>,update v2 migration docs about babel configuration
799,"<desc> the refactor to the spacy._ml.tok2vec function is too risky for a point release, so for v2.2.2 we should keep the old implementation and have the new behind a feature flag. i have submitted the spacy contributor agreement. </desc> <cmt> add back pre-2.2.2 tok2vec </cmt> <cmt> add simple tok2vec tests </cmt> <cmt> add simple tok2vec tests </cmt> <cmt> reformat </cmt> <cmt> fix characterembed in new tok2vec </cmt> <cmt> fix legacy tok2vec </cmt> <cmt> resolve circular imports </cmt>",put tok2vec refactor behind feature flag
800,"<desc> there's a minor issue: if the user sets ti_use_unified_memory=0 and then use ti.init(use_unified_memory=false), taichi will report an error saying use_unified_memory is not recognized. this pr fixes that, and adds a warning in this case: </desc> <cmt> fix ti.init </cmt> <cmt> warn when overriding </cmt> <cmt> format </cmt>",fix ti.init argument parsing when corresponding environment variable presents
801,<desc> i would like to add my keymap to the main repository. i've added some features not present in any of the available keymaps and believe that it offers some great additions. </desc> <cmt> add personal keymap for pearl 40% </cmt> <cmt> updating readme and adding keymap image </cmt> <cmt> updated readme </cmt> <cmt> force make to use python 3 </cmt> <cmt> cleanup keymap </cmt> <cmt> updated keymap image </cmt> <cmt> update readme for new keymap image </cmt> <cmt> reverting atmega32a_program </cmt>,add cijanzen pearl 40% keymap
802,"<desc> called with from paddle.v2.fluid import debuger print debuger.pprint_program_codes(framework.default_main_program().desc) it is easy to customize the debug information for a specific operator, just add a new handler into the op_repr_handlers. the code sample adds a handler for fill_constant, and it looks like aval = 1. [shape=[1]] // block-0  parent--1 // variables tensor tmp_19 (tensor(type=float32, shape=[1l])) tensor tmp_17 (tensor(type=float32, shape=[1l])) tensor tmp_15 (tensor(type=float32, shape=[1l])) tensor tmp_14 (tensor(type=float32, shape=[1l])) tensor tmp_6 (tensor(type=float32, shape=[1l])) tensor tmp_5 (tensor(type=float32, shape=[1l])) tensor tmp_3 (tensor(type=float32, shape=[1l])) tensor tmp_2 (tensor(type=float32, shape=[1l])) tensor tmp_0 (tensor(type=float32, shape=[1l])) tensor moment_8 (tensor(type=float32, shape=[32l, 32l])) tensor moment_7 (tensor(type=float32, shape=[1l, 224l])) tensor tmp_9 (tensor(type=float32, shape=[1l])) tensor moment_6 (tensor(type=float32, shape=[30000l, 16l])) tensor tmp_13 (tensor(type=float32, shape=[1l])) tensor moment_4 (tensor(type=float32, shape=[32l, 30000l])) tensor tmp_12 (tensor(type=float32, shape=[1l])) tensor moment_2 (tensor(type=float32, shape=[32l, 128l])) tensor tmp_11 (tensor(type=float32, shape=[1l])) tensor tmp_18 (tensor(type=float32, shape=[1l])) tensor moment_5 (tensor(type=float32, shape=[16l, 128l])) tensor tmp_7 (tensor(type=float32, shape=[1l])) tensor moment_3 (tensor(type=float32, shape=[128l])) tensor lstm_0.tmp_3 (tensor(type=float32, shape=[-1l, 32l])) tensor tmp_4 (tensor(type=float32, shape=[1l])) tensor dynamic_rnn_0.tmp_0 (tensor(type=bool, shape=[1l])) tensor lstm_0.tmp_2 (tensor(type=float32, shape=[-1l, 128l])) lodtensor lstm_0.tmp_1 (level=1, tensor(type=float32, shape=[-1l, 32l])) lodtensor embedding_1.tmp_0 (level=1, tensor(type=float32, shape=[-1l, 16l])) lodtensor target_language_next_word (level=1, tensor(type=int64, shape=[-1l, 1l])) tensor tmp_8 (tensor(type=float32, shape=[1l])) lodtensor embedding_0.tmp_0 (level=1, tensor(type=float32, shape=[-1l, 16l])) tensor tmp_1 (tensor(type=float32, shape=[1l])) tensor vemb (tensor(type=float32, shape=[30000l, 16l])) lodtensor fc_0.tmp_1 (level=1, tensor(type=float32, shape=[-1l, 128l])) lodtensor target_language_word (level=1, tensor(type=int64, shape=[-1l, 1l])) tensor moment_1 (tensor(type=float32, shape=[30000l])) tensor fc_0.w_0 (tensor(type=float32, shape=[16l, 128l])) tensor sequence_pool_0.tmp_1 (tensor(type=float32, shape=[])) tensor moment_0 (tensor(type=float32, shape=[32l])) tensor cross_entropy_0.tmp_0 (tensor(type=float32, shape=[-1l, 1l])) tensor lstm_0.b_0 (tensor(type=float32, shape=[1l, 224l])) lodtensor src_word_id (level=1, tensor(type=int64, shape=[-1l, 1l])) tensor lod_rank_table_0 (tensor(type=bool, shape=[])) tensor fc_2.b_0 (tensor(type=float32, shape=[30000l])) tensor fc_0.b_0 (tensor(type=float32, shape=[128l])) tensor tmp_10 (tensor(type=float32, shape=[1l])) tensor fc_1.b_0 (tensor(type=float32, shape=[32l])) lodtensor fc_0.tmp_0 (level=1, tensor(type=float32, shape=[-1l, 128l])) tensor _generated_var_0 (tensor(type=bool, shape=[])) lodtensor fc_0.tmp_2 (level=1, tensor(type=float32, shape=[-1l, 128l])) tensor fill_constant_1.tmp_0 (tensor(type=int64, shape=[1l])) tensor lstm_0.w_0 (tensor(type=float32, shape=[32l, 128l])) tensor tmp_16 (tensor(type=float32, shape=[1l])) tensor dynamic_rnn_mem_array_0 (tensor(type=bool, shape=[])) tensor mean_0.tmp_0 (tensor(type=float32, shape=[1l])) tensor dynamic_rnn_max_seq_len_0 (tensor(type=int64, shape=[1l])) tensor dynamic_rnn_input_array_0 (tensor(type=bool, shape=[])) tensor fill_constant_0.tmp_0 (tensor(type=int64, shape=[1l])) tensor array_to_lod_tensor_0.tmp_0 (tensor(type=float32, shape=[-1l, 30000l])) tensor fc_1.w_0 (tensor(type=float32, shape=[16l, 32l])) tensor fc_1.w_1 (tensor(type=float32, shape=[32l, 32l])) tensor fc_2.w_0 (tensor(type=float32, shape=[32l, 30000l])) tensor moment_9 (tensor(type=float32, shape=[16l, 32l])) tensor dynamic_rnn_0_output_array_fc_2.tmp_2_0 (tensor(type=bool, shape=[])) tensor learning_rate_0 (tensor(type=float32, shape=[1l])) tensor sequence_pool_0.tmp_0 (tensor(type=float32, shape=[-1l, 32l])) lodtensor lstm_0.tmp_0 (level=1, tensor(type=float32, shape=[-1l, 32l])) // operators embedding_0.tmp_0 = lookup_table(ids=src_word_id, w=vemb) [{padding_idx=-1,is_sparse=true}] fc_0.tmp_0 = mul(x=embedding_0.tmp_0, y=fc_0.w_0) [{y_num_col_dims=1,x_num_col_dims=1}] fc_0.tmp_1 = elementwise_add(x=fc_0.tmp_0, y=fc_0.b_0) [{axis=1}] fc_0.tmp_2 = tanh(x=fc_0.tmp_1) [{}] lstm_0.tmp_3, lstm_0.tmp_2, lstm_0.tmp_1, lstm_0.tmp_0 = lstm(bias=lstm_0.b_0, c0=[], h0=[], input=fc_0.tmp_2, weight=lstm_0.w_0) [{candidate_activation=tanh,use_peepholes=true,is_reverse=false,gate_activation=s igmoid,cell_activation=tanh}] sequence_pool_0.tmp_1, sequence_pool_0.tmp_0 = sequence_pool(x=lstm_0.tmp_0) [{pooltype=last}] embedding_1.tmp_0 = lookup_table(ids=target_language_word, w=vemb) [{padding_idx=-1,is_sparse=true}] fill_constant_0.tmp_0 = 0.0 [shape=[1]] fill_constant_1.tmp_0 = 0.0 [shape=[1]] lod_rank_table_0 = lod_rank_table(x=embedding_1.tmp_0) [{level=0}] dynamic_rnn_max_seq_len_0 = max_sequence_len(ranktable=lod_rank_table_0) [{}] dynamic_rnn_0.tmp_0 = less_than(x=fill_constant_1.tmp_0, y=dynamic_rnn_max_seq_len_0) [{axis=-1}] dynamic_rnn_input_array_0 = lod_tensor_to_array(ranktable=lod_rank_table_0, x=embedding_1.tmp_0) [{}] dynamic_rnn_mem_array_0 = write_to_array(i=fill_constant_0.tmp_0, x=sequence_pool_0.tmp_0) [{}] fill_constant_1.tmp_0', u'dynamic_rnn_input_array_0', u'fc_2.w_0', u'dynamic_rnn_mem_array_0', u'dynamic_rnn_max_seq_len_0', u'fc_1.b_0', u'lod_rank_table_0', u'fc_2.b_0']) [{sub_block=1}] array_to_lod_tensor_0.tmp_0 = array_to_lod_tensor(ranktable=lod_rank_table_0, x=dynamic_rnn_0_output_array_fc_2.tmp_2_0) [{}] cross_entropy_0.tmp_0 = cross_entropy(label=target_language_next_word, x=array_to_lod_tensor_0.tmp_0) [{soft_label=false}] mean_0.tmp_0 = mean(x=cross_entropy_0.tmp_0) [{}] tmp_0 = 1.0 [shape=[1]] tmp_1 = elementwise_mul(x=learning_rate_0, y=tmp_0) [{axis=-1}] tmp_2 = 1.0 [shape=[1]] tmp_3 = elementwise_mul(x=learning_rate_0, y=tmp_2) [{axis=-1}] tmp_4 = 1.0 [shape=[1]] tmp_5 = elementwise_mul(x=learning_rate_0, y=tmp_4) [{axis=-1}] tmp_6 = 1.0 [shape=[1]] tmp_7 = elementwise_mul(x=learning_rate_0, y=tmp_6) [{axis=-1}] tmp_8 = 1.0 [shape=[1]] tmp_9 = elementwise_mul(x=learning_rate_0, y=tmp_8) [{axis=-1}] tmp_10 = 1.0 [shape=[1]] tmp_11 = elementwise_mul(x=learning_rate_0, y=tmp_10) [{axis=-1}] tmp_12 = 1.0 [shape=[1]] tmp_13 = elementwise_mul(x=learning_rate_0, y=tmp_12) [{axis=-1}] tmp_14 = 1.0 [shape=[1]] tmp_15 = elementwise_mul(x=learning_rate_0, y=tmp_14) [{axis=-1}] tmp_16 = 1.0 [shape=[1]] tmp_17 = elementwise_mul(x=learning_rate_0, y=tmp_16) [{axis=-1}] tmp_18 = 1.0 [shape=[1]] tmp_19 = elementwise_mul(x=learning_rate_0, y=tmp_18) [{axis=-1}] </desc> <cmt> add debug codes </cmt> <cmt> improve </cmt>",debug/format protobuf to human-readable codes
803,"<desc> arm (automatic resource management) the purpose of these commits is to move away from relying on the garbage collector to call finalize on the various objects of the rocks java api in order to free the underlying c++ objects and memory. instead we will require users of the java api to explicitly free the java objects, by calling close; to this end we have implemented java.lang.autocloseable throughout the api, which allows the user to make use of java 7's try-with-resources. along the way, improvements have also been made around the java/c++ jni bridge with respect to object creation/initialization and destruction. these changes require thorough testing as the synchronization of object cleanup has been changed. </desc> <cmt> improve the speed and synchronization around the construction of java/jni objects </cmt> <cmt> improve javadoc </cmt> <cmt> pass by pointer from/to java from jni not by object </cmt> <cmt> remove unnessecary java.util.list expense in jni </cmt> <cmt> fix a memory leak of slice objects from org.rocksdb.wbwirocksiterator#entry1 </cmt>",arm for the java api
804,"<desc> when calling .all() or .some(<count>) before with complex types, it would default to the .all(): promise<never> definition, and likewise for .some(). this change fixes those issues, bringing them in line with the implementations of .each(), .map(), and the like. example of previous (incorrect) behavior: import promise from ""bluebird"" const p1: promise<array<foo | null>> = promise.resolve([]); const p2 = p1.all();  // here p2 has type promise<never> example of fixed behavior: import promise from ""bluebird"" const p1: promise<array<foo | null>> = promise.resolve([]); const p2 = p1.all();  // here p2 has type promise<(foo | null)[]> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [bluebird] update tests </cmt> <cmt> update types for .all() and .some() </cmt>",fix typings for .all() and .some()
805,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation we currently added to presto support for estimating the number of bytes scanned (trinodb/trino#806), and we'd like to surface that information to sql lab users before they actually run a query. this pr extends the db specs with an allows_cost_estimate attribute and associated methods, allowing pre-execution costs to be computed from dbs that support it. in order to use it, the feature flag estimate_query_cost must be enabled, and it needs to be explicitly turned on for each database that supports query cost estimation. when all those conditions are met, a new button will show up in sql lab, allowing users to run cost estimates for the whole query or for the selected sql. dbs where the feature is not supported or not enabled are unmodified: here's a presto db: waiting for results: the result: and how errors (timeout, syntax errors) are surfaced: test plan tested with a presto cluster that supports query cost estimation, running version 0.319 and with the feature enabled via extra: { ""version"": ""0.319"", ""cost_estimate_enabled"": true, ""metadata_params"": {}, ""engine_params"": { ""connect_args"": { ""protocol"":""https"", ""source"":""superset"" } }, ""metadata_cache_timeout"": {""schema_cache_timeout"": 86400, ""table_cache_timeout"": 86400}, ""default_schemas"": [""core"", ""default""] } additionally, i tested: lowering the presto version removes the button. other dbs don't show the button. turning off the feature flag removes the button. requires db migration. confirm db migration upgrade and downgrade tested. reviewers @etr2460 @mistercrunch </desc> <cmt> wip </cmt> <cmt> basic functionality working </cmt> <cmt> enable per db </cmt> <cmt> show error message </cmt>",allow users to estimate query cost before executing it
806,<desc> allows mirrored duplication on idex systems and changes default mode to what has been most tested. </desc> <cmt> initial mirrored mode support </cmt> <cmt> as derived from formbot / vivedino for their trex 3 idex machines. </cmt> <cmt> initial mirrored mode support </cmt> <cmt> as derived from formbot / vivedino for their trex 3 idex machines. </cmt> <cmt> initial mirrored mode support </cmt> <cmt> as derived from formbot / vivedino for their trex 3 idex machines. </cmt> <cmt> initial mirrored mode support </cmt> <cmt> as derived from formbot / vivedino for their trex 3 idex machines. </cmt>,idex mirror mode based on formbot / vivedino symetric mode
807,<desc> add a versionadded directive to the note about profile being a context manager. remove extra paragraph from news entry. add an entry to whatsnew for 3.8. </desc> <cmt> bpo-29235: add versionadded note to cprofile docs. </cmt> <cmt> doc: remove extra paragraph from news entry. </cmt> <cmt> xref: </cmt> <cmt> doc: add whatsnew entry for bpo-29235. </cmt>,update document for profiler's context manager
808,"<desc> currently, there is a race condition where a task's arguments can get evicted after the task is dispatched but before the worker has gotten the arguments from the object store. this can lead to a deadlock if there are too many requests to pull other objects in the node's queue. this fixes the race condition by having the raylet pin the dependencies while a task lease is granted. closes #12663. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> tmp </cmt> <cmt> pin task args </cmt> <cmt> unit tests </cmt> <iss> [object spilling] thrashing when there are large number of dependencies for many tasks </iss>",pin arguments during task execution
809,"<desc> add or edit tests to reflect the change. (run with npm test.) - no tests yet, wanted to discuss the change first follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). - ran tsc and got no problems... it failed running tslint, it failed to assert the path definitelytyped/types/xxx - even though i have that folder structure... potentially a casing issue? provide a url to documentation or source code which provides context for the suggested changes: <> - the documentation hasn't changed, my change just suggests that the typings can be tighter. increase the version number in the header if appropriate. - no version change if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. i've added generic type inference to the spy and stub calls. the key line for the spy is this: interface sinonspystatic { /** * creates an anonymous function that records arguments, this value, exceptions and return values for all calls. */ (): sinonspy; /** * spies on the provided function */ (func: function): sinonspy; /** * creates a spy for object.method and replaces the original method with the spy. * an exception is thrown if the property is not already a function. * the spy acts exactly like the original method in all cases. * the original method can be restored by calling object.method.restore(). * the returned spy is the function object which replaced the original method. spy === object.method. */ <t, k extends keyof t>(obj: t, method: k): t[k] extends ( ...args: infer u ) => infer v ? sinonspy<u, v> : sinonspy; basically, we can infer the types of the arguments of the function being stubbed and the return type of that function. then we can use this within the spy/stub api such that, when you are accessing the arguments/return of a stub/spy you get type safety. i haven't added tests yet, wanted to make sure people thought it was a good idea before i bothered. if we do think it's a good idea then i'll add them </desc> <cmt> add some generic type inference to sinon stubs and spies </cmt> <cmt> correct callsfake typing and add author </cmt>",@types/sinon - add type inference for stub/spy arguments and return types
810,"<desc> this is a follow up of #7160. changes: use memoryview() with size == file size, see #7160 (comment) release intermediate (sliced) memoryview immediately replace ""osx"" occurrences with ""macos"" add some unittests for copyfileobj() update doc </desc> <cmt> bpo-33671: release sub-memoryview resources immediately </cmt> <cmt> rename osx to macos </cmt> <cmt> add unit tests for copyfileobj </cmt> <cmt> remove _copybinfileobj() implementation </cmt> <cmt> ...as it's considerably slower for smaller files; e.g. with a 8mib file: </cmt> <cmt> --- original </cmt> <cmt> ~/svn/cpython {33671-release-memoryview}$ ./python  -m timeit -s ""import </cmt> <cmt> shutil; f1 = open('f1', 'rb'); f2 = open('f2', 'wb')"" </cmt> <cmt> ""shutil.copyfileobj(f1, f2)"" </cmt> <cmt> 200000 loops, best of 5: 1.64 usec per loop </cmt> <cmt> --- _copybinfileobj() </cmt> <cmt> ~/svn/cpython {33671-release-memoryview}$ ./python  -m timeit -s ""import </cmt> <cmt> shutil; f1 = open('f1', 'rb'); f2 = open('f2', 'wb')"" </cmt> <cmt> ""shutil.copyfileobj(f1, f2)"" </cmt> <cmt> 100000 loops, best of 5: 3.3 usec per loop </cmt> <cmt> update doc </cmt> <cmt> update doc </cmt> <cmt> update doc </cmt> <cmt> update doc </cmt> <cmt> update doc </cmt>",use memoryview() with dynamic size on windows
811,"<desc> update: mac os 10.3 is supported in ci. fixed unit test error in coreml to mxnet converter and add it to ci. this pr will also resolve issue #11841 added unit test for mxnet to coreml converter. it can run on macos 10.2 and beyond. the small test only converts mxnet model to coreml model without running inference to verify. for model inference mac os 10.3 is required. please feel free to remove inapplicable items for your pr. unit tests are added for small changes to verify correctness (e.g. adding a new operator) code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change test_converter_no_pred these tests can only run on mac os 10.2 and beyond. </desc> <cmt> add unittest to coreml converter </cmt> <cmt> add unittest to coreml converter </cmt>",add unit test for mxnet to coreml converter
812,"<desc> cherrypicked from #2243 with a minor fix. ensures that the pid error derivative is computed correctly as difference of previous and current errors, in order to fix instability of current implementation (see #2243 for discussion). </desc> <cmt> updated pid derivative action </cmt> <cmt> issue #2221 </cmt> <cmt> fixed sign in pid derivative calculation </cmt> <cmt> fix indentation </cmt>",fix pid error derivative calculation
813,"<desc> we have long running dashboard queries (2-3 minutes) which were getting tripped up by the 60 second timeout with 504 gateway timeout. i modified the dockerfile to keep the default 60 second timeout on gunicorn, but allow gunicorn_timeout env to override. i also modified the values.yml to provide the needed placeholders to implementing a longer timeout at gunicorn, superset_webserver_timeout, and the nginx proxy timeout. note: this change is non-disruptive, no end user will be impacted unless they turn on settings in the values.yaml. run a query on a dashboard that takes longer than 60 seconds, watch it time out. apply patch, enable new helm lines, do same query, watch it work. includes db migration (follow approval process in sip-59) </desc> <cmt> allow timeout override, but keep default if unset </cmt> <cmt> add template placeholder values for timeout change </cmt>",make webserver query timeout adjustable
814,<desc> clean up the todo the read-only protobuf::repeatedfield can be viewed as span in listener/filterchain risk level: low. it's internal implementation detail of filter chain. existing test. filterchain benchmark test doesn't complain in trivial case. but i didn't extend the test to embrace huge server names and protocol set. </desc> <cmt> filterchain: use span </cmt> <cmt> remove todo line </cmt>,use span to avoid construct vector
815,"<desc> description: note: i am new to python and ha. the code is not complete yet but i am hoping to get some advice on what i have got so far. google assistant now has an api to request a sync of devices. this pr is to implement a new service in the google assistant component which sends the ""request_sync"" command to google. this is a breaking change as it introduces two new mandatory configuration values for the component related issue (if applicable): not applicable pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3807 example entry for configuration.yaml (if applicable): google_assistant: project_id: someproject-2d0b8 client_id: [long url safe random string] access_token: [a different long url safe random string] agent_user_id: [string to identify user preferably email address] homegraph_api_key: [api key obtained from google] checklist: documentation added/updated in home-assistant.github.io if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> initial commit for request_sync functionality </cmt> <cmt> fixes for tox results </cmt>",google assistant request sync service
816,"<desc> @daohu527 @jackfu123 without this pr, running mainboard -d modules/planning/dag/planning.dag will complains: intel mkl error: /usr/local/lib/libmkl_avx2.so: undefined symbol: mkl_sparse_optimize_bsr_trsm_i8. intel mkl fatal error: cannot load libmkl_avx2.so or libmkl_def.so. </desc> <cmt> docker: add missing dependencies for dreamview </cmt> <cmt> cyber: bugfix for sharedlibrary's dlopen operations </cmt> <cmt> or else, running ""mainboard -d modules/planning/dag/planning.dag"" </cmt> <cmt> will complains: </cmt> <cmt> intel mkl error: /usr/local/lib/libmkl_avx2.so: undefined symbol: mkl_sparse_optimize_bsr_trsm_i8. </cmt> <cmt> intel mkl fatal error: cannot load libmkl_avx2.so or libmkl_def.so. </cmt>",bugfix for dlopen operations in sharedlibrary impl
817,"<desc> this pr updates the odbc configuration documentation to update it with regards to: steps required to to connect to elastic's cloud (the usage of the cloud id parameter); various toggles added under the misc tab. closes #51826. </desc> <cmt> refresh snapshots with latest look </cmt> <cmt> add new snapshots with the connection editor to reflect the latest ui. </cmt> <cmt> document the effect of the late added params </cmt> <cmt> add details about the cloud id setting, as well as those on the misc </cmt> <cmt> tab. </cmt> <iss> sql: update odbc documentation on cloud usage </iss>","update odbc docs, cover cloud id, latest params"
818,"<desc> this pr changes the name of the index template v2 classes to ""composable templates"", it also ensures there are no mentions of ""v2"" in the documentation or error/warning messages. v1 templates are referred to as ""legacy"" templates. resolves #56609 </desc> <cmt> no more v1/v2 </cmt> <cmt> rename all *v2 java classes to composablething </cmt> <iss> consistent naming for the new index templates </iss>",rename template v2 classes to composabletemplate
819,"<desc> fix #5544. notice that ""ofsorted"" methods can't use const. they want to sort the vector. </desc> <cmt> pull from google/flatbuffers </cmt> <cmt> fix c/c++ create<type>direct with sorted vectors </cmt> <cmt> if a struct has a key the vector has to be sorted. to sort the vector </cmt> <cmt> you can't use ""const"". </cmt> <iss> array of table is not sorted if create<type>direct() is used </iss>",#5544 fix of array of table is not sorted if create<type>direct() is used
820,"<desc> the role attribute defines the action of the menu item, by using it users no longer need to manually write the behavior of standard menu items, and also fixed some menu items not working exactly the same with native ones (closes #2331). also specifying special menus doesn't require hard-coding menu's name any more (closes #2348). also document the behavior that current menu item and window are passed when calling the click function (closes #935). </desc> <cmt> add role property for menuitem </cmt> <cmt> assign actions for roles on windows and linux </cmt> <cmt> unify the menu of default app </cmt> <cmt> docs: the ""role"" attribute of menuitem </cmt> <iss> menuitem: click() should forward browser event </iss> <iss> cut, copy, paste not working in dialogs under mac </iss> <iss> label names of special menus 'services', 'windows' and 'help' are hardcoded </iss>","add ""role"" attribute for menuitem"
821,"<desc> add missing parameters: forcelanguage (in service and filter since v2.9) defaulttranslationtext (in service even before v2.9) </desc> <cmt> pull latest changes from head </cmt> <cmt> add new angular 1.5.9 methods to $compileprovider </cmt> <cmt> add new methods available in angular 1.5.9: onchangesttl(), commentdirectivesenabled() and cssclassdirectivesenabled() </cmt> <cmt> add jsdoc to angular 1.59 new methods of $compileprovider </cmt> <cmt> jsdoc for onchangesttl(), commentdirectivesenabled() and cssclassdirectivesenabled() methods. </cmt> <cmt> expand $compileprovider jsdoc </cmt> <cmt> urls added to jsdoc of angular 1.5.9 new methods . </cmt> <cmt> pull latest changes from head </cmt> <cmt> pull latest changes from head </cmt> <cmt> add missing parameters defaulttranslationtext and forcelanguage in $translate service and filter </cmt> <cmt> add missing parameters: </cmt> <cmt> - forcelanguage (in service and filter since v 2.9) </cmt> <cmt> - defaulttranslationtext (in service) </cmt>",add missing parameters in $translate service and filter
822,"<desc> in the previous custom series. we can't do transition across different types of shapes. for example, we can't animate from a sector to a rectangle. in this pr, we bring the ability to do smooth shape morphing across different shapes. it's heavily based on the new add function in zrender  an example of the transition between map, bar, bubble and pie(these are all implemented by custom series.) the transition between hexagon and circle in hexbin example. the transition between different svg paths. usage are there any api changes? we add a boolean property called morph in the returned element option in renderitem. with it enabled, the shape will be morphed from the previous shape smoothly when the type is changed. for example: // render as rectangle at first time. renderitem(params, api) { return { type: 'rect' .... } } // change to a circle. renderitem(params, api) { return { type: 'circle', // enable morphing from the previous rectangle. morph: true .... } } </desc> <cmt> feat(custom): add shapemorphing option in renderitem returns. </cmt> <cmt> fix(custom): fix other props transition when shape morphing </cmt>",bring shape morphing ability in custom series
823,"<desc> this pr tries to address some of the weird interactions with pointer pressed events when the terminal isn't in focus. here's the four things that have changed as part of this pr; this pr will allow the user to be able to make a selection with a click-drag without having to first perform a single click on a tab/pane to bring it to focus. another weird bug that's fixed in this pr is where trying to make a selection on an unfocused tab when it already has a selection active will simply extend the existing selection instead of making a new one. not related to the issue that his pr closes: a right click will now focus the tab/pane. i've made sure that we still have the existing functionality where a single click on an unfocused tab/pane does not make a single-cell selection and just focuses the tab/pane. closes #4282 cla signed. if not, go over here and sign the cla played around with all sorts of selection when in-focus and out of focus with multiple panes and tabs. unit tests still pass as well. </desc> <cmt> inconsistencies seem to be consistent </cmt> <cmt> removing a debugging code oops </cmt> <cmt> making the focus setting more local </cmt> <cmt> simplifying </cmt> <iss> behaviour of click-and-drag text selection depends inconsistently on prior pane and application focus state </iss>",fix click-drag selection on an unfocused terminal
824,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see </desc> <cmt> add group key </cmt> <cmt> version </cmt>,add group key to object
825,"<desc> this uses our object literal parser to parse the json text. new api called parsejsontext and return jsonsourcefile - syntax tree there is also api converttojson that converts jsonsourcefile to json new api called parsejsonsourcefileconfigfilecontent that takes this jsonsourcefile to convert to actual parsedcommandline and convert the jsonsourcefile to json in one shot so there are error locations for the invalid json options in the tsconfig.json as part of this change i had to refactor code a little bit so that parser can be included with minimal changes into the jstypingsinstaller jsonsourcefile is stored as configfile in compileroptions so the options related diagnostics can be reported in the actual tsconfig file config file names are included in project files, and getsemanticdiagnostic on the config file returns the project errors and options diagnostics in that file </desc> <cmt> parse json using our own parser </cmt> <cmt> reorganize functions so commandline parser can include parser. </cmt> <cmt> this fixes build of typings installer </cmt> <cmt> keep the original api and add new api that handles the jsonnode </cmt> <cmt> also handle the jsonnode when converting to parsedcommandline </cmt>",use parser to parse tsconfig json instead of using json.parse
826,"<desc> while reading through the doc for plugins, i saw that the introduction statement for the second paragraph could be a bit more detailed  related to #19277 </desc> <cmt> docs(what-you-dont-need-plugins-for): grammar change to aid readability. also added hyperlink to styled-component </cmt> <cmt> docs(what-you-dont-need-plugins-for): grammar change to aid readability </cmt>",what-you-dont-need-plugins-for: grammar change to aid readability
827,"<desc> user can call native function if user  realize the function wxextendcallnativeprotocol <template> <div class=""wrapper"" @click=""update""> <image :src=""logourl"" class=""logo""></image> <text class=""title"">hello {{target}}</text> </div> </template> <style scoped> .wrapper {align-items: center; margin-top: 120px;} .title {font-size: 48px;} .logo {width: 360px; height: 82px;} </style> <script> var modal = weex.requiremodule('modal') module.exports = { data: { logourl: ' target: 'world' }, methods: { update: function (e) { this.target = 'weex' console.log('target:', this.target) var dict = extendcallnative({ 'classname':'test' }) modal.toast({ 'message': dict['value'], 'duration': 1000 }) } } } </script> </desc> <cmt> + [ios] support extend call native for third part </cmt> <cmt> + [ios] add extend call native </cmt> <cmt> # conflicts: </cmt> <cmt> #	ios/playground/weexdemo.xcodeproj/project.pbxproj </cmt> <cmt> #	ios/sdk/weexsdk/sources/bridge/wxjscorebridge.m </cmt> <cmt> + [ios] update native logic </cmt>",+ [ios] support call native directly
828,"<desc> enclosed a pull request to add signature help support to the typescript server. i tried to follow the style i found in the existing code (e.g. expose the language service api, no extra abstraction). there is one thing i left open: i don't know the meaning of applicablespan in signaturehelpitems. can someone of you fill in the comment. thanks dirk </desc> <cmt> add signaturehelp support to typescript server </cmt> <cmt> mark new interfaces with export </cmt>",add signature help to typescript server
829,"<desc> i could not break the pr further down. hopefully the algorithm outline presented here helps. algorithm outline (note that exiting blocks are inside the loop and exit blocks are outside the loop. therefore, an exit edge is from an exiting block to an exit block.) this pr takes care of transforming the loop such that the common post dominator of all exit blocks is the new exit block for the loop.  this is one of the several transformations needed to eliminate undef from sese loops. consider the following snippet: while(...) { if (...) { ... break; } } recall that the blocks within if do not belong to the while loop in the sil ir. the transformation implemented in this pr has the effect of moving the blocks back into the loop. step 1. transform loop.  (see ensuresingleexitblock) let nearestcommonpd be the  nearest common post-dominator block of all the exit blocks. move all the blocks reachable from exiting blocks to the nearestcommonpd inside the loop. (it is not always possible to move all reachable blocks without cloning some of the them.  see notes below.) let exitblocks be the set of exit blocks for the loop  after the above transformation. step 2. connect exiting blocks to a new latch and unify loop arguments. (see patchedges) (only changes related to exit arguments are shown here.) let exitargs be the union of the arguments of all exitblocks. for each exitarg in exitargs, add an appropriate argument to the new header block. let p0, p1, ..pn be the new arguments corresponding to exit arguments a0, a1, a2, ..., an. for a exit edge br exit_i(x, y) -> exit_i(a2, a3), change the source to br new_latch(p0, p1, x, y, p4, ..., pn) notes. if a block is not dominated by the header of the loop, we cannot move it into the loop in step 1. for such cases, we will need to clone the block before moving it into the loop. i will send out a separate pr for that purpose. </desc> <cmt> move blocks into the loop as much as possible in common cases. </cmt> <cmt> managing arguments </cmt> <cmt> split edges into exit blocks that do not dominate the header of loop. </cmt> <cmt> updated the tests </cmt> <cmt> guarded new code with a flag. </cmt>",transform loops to have single exit block in non-cloning case.
830,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> add loopback remote hooks definitely types </cmt> <cmt> add loopback remote hooks definitely types </cmt> <cmt> add loopback remote hooks definitely types </cmt> <cmt> add loopback remote hooks definitely types </cmt>",add looback remeted hook definitelytyped
831,"<desc> closes #15079 xref:  #11053, #28177 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix by in hist </cmt> <iss> dataframe.plot.box ignores by argument </iss>",fix by in dataframe.plot.hist and dataframe.plot.box
832,"<desc> description: the remove() method did not leave the free-list in a coherent state. this was triggered by tests, but not detected, because sanitycheck() did not verify the coherence of the free-list. risk level: low //test/... fixes #2407 </desc> <cmt> fix sharedmemoryhashset::remove which messed up the free list, and improve sanitycheck </cmt> <cmt> the removal logic didn't produce a coherent free-list.  this was </cmt> <cmt> indirectly tested, but the corrupt free-list wasn't detected by </cmt> <cmt> the sanitycheck. </cmt> <cmt> in addition the hash distribution prevented a multi-cell bucket from </cmt> <cmt> exhibiting any problem. </cmt> <cmt> test with both zero-hash and a real hash function. </cmt> <cmt> format fixups </cmt>",fix sharedmemoryhashset removal problem and make sanitycheck catch such issues
833,"<desc> this pr adds the ability to resolve module and type reference directives in the project direct file with its own options (eg project structure of a -> b -> c, while resolving modules/type reference directives in b we will use b's config file options to resolve it rather than using a's config file options) fixes #27200 </desc> <cmt> resolve project references transitively </cmt> <cmt> use resolution options of project reference if the file is from the project reference </cmt> <cmt> handle caching of module resolution depending on project references </cmt> <cmt> fix the filebyname cache when program is used completely which breaks the getsourcefile not return redirected file by its name </cmt> <cmt> verify that own config change in module resolution gets reflected </cmt> <cmt> handle resolution caching when referenced tsconfig changes </cmt> <cmt> verify errors on transitively referenced files </cmt> <cmt> test transitive references in folders side by side so that later we can add tsserver tests as well </cmt> <cmt> add tests for project updates with tsserver </cmt> <iss> should project references check for transitive references to do the declaration file include check </iss>","resolve modules, type reference directives in context of referenced file"
834,<desc> pull requests converts the following patterns to java 11: converter cqrs dao data-bus data-locality data-mapper data-transfer-object decorator delegation dependency-injection dirty-flag double-buffer double-checked-locking double-dispatch </desc> <cmt> moves converter pattern to java 11 </cmt> <cmt> moves cqrs pattern to java 11 </cmt> <cmt> moves dao pattern to java 11 </cmt> <cmt> moves data-bus pattern to java 11 </cmt> <cmt> moves data-locality pattern to java 11 </cmt> <cmt> moves data-mapper pattern to java 11 </cmt> <cmt> moves data-transfer-object pattern to java 11 </cmt> <cmt> moves decorator pattern to java 11 </cmt> <cmt> moves delegation pattern to java 11 </cmt> <cmt> moves dependency-injection to java 11 </cmt> <cmt> moves dirty-flag to java 11 </cmt> <cmt> moves double-buffer to java 11 </cmt> <cmt> moves double-checked-locking to java 11 </cmt> <cmt> moves double-dispatch to java 11 </cmt>,java 11 migrate c-d (remaining)
835,"<desc> this lines up the final pieces needed to remove typechecker::validatetype, so the last commit does just that. we can now start the process of fixing up typechecktype to not return the null type in earnest. </desc> <cmt> replace resolvecustomattrtype with a request </cmt> <cmt> strip implementsattr of its typeloc </cmt> <cmt> strip typeeraserattr of its typeloc </cmt> <cmt> delete typechecker::validatetype </cmt> <cmt> inline it into its final user: swift::performtypelocchecking </cmt>",strip attributes of their typelocs
836,"<desc> updated regex in parser to correctly handle comments in class diagrams.  also updated flowchart parser to remove unused elements for comments, as well as modifying the regex to match resolves #1073 </desc> <cmt> develop </cmt> <cmt> initial checkin </cmt> <cmt> update class diagrams to handle comments </cmt> <cmt> updated regex in parser to correctly handle comments in class diagrams.  also updated flowchart parser to remove unused elements for comments, as well as modifying the regex to match </cmt>",bug/1073 comments in class diagrams
837,"<desc> there are no functional or text changes with this pr. i'm just cleaning up the logic for printhostinginstructions to make it more readable and remove some duplication. the only minor logic change is that i replaced a couple hard-coded literals ('build') with variables (buildfolder). the main printhostinginstructions method is now purely logic. it calls three other functions printbasemessage, printdeployinstructions, and printstaticserverinstructions; which contain the console statements with minimal logic. </desc> <cmt> replacing literal 'build' with buildfolder variable </cmt> <cmt> cleaning up the printhostinginstructions a bit </cmt>",cleaning up printhostinginstructions a bit
838,"<desc> fixes #5518 rather than implement our own host name parsing, i leveraged the url package that is already used elsewhere in the project. moved resolve_hosts out of flags.rs following the pattern of resolve_addr implemented bare port parsing extended tests started by jinliming2 a host could be a host:port combination, an ipaddr or a bare port such as :8080 this pr is my refactoring of #5520 which seems to have stalled out a bit. </desc> <cmt> moved resolve_hosts.rs out of flags.rs following the pattern of resolve_addr </cmt> <cmt> implemented bare port parsing. </cmt> <cmt> rewrote resolve_hosts to utilize url, ipaddr or bareport parsing </cmt> <cmt> added tests </cmt> <iss> --allow-net doesn't support ipv6 address. </iss>",added ipv6 parsing for --allow-net cli parameters
839,"<desc> we started missing data when our # of intervals became large (primarily on 14d view) due to default snuba row limit being 1000. this increases limit to max of 10,000 which will make overall orgstats queries work. for orgs with large # of active projects (> ~600) still need to modify things a bit for the project queries. math on this: the theoretical maximum amount of rows per time interval of datacategory+outcome is 24 (6 x 4). 10000 / 24 = 416 so maximum # of projects is limited to ~416, and in practice, probably like 600 since it's a theoretical max and not every hour of every combo will be filled in. this still isn't great as our largest users have over 1000 projects. solutions for solving project table problem: re-query when datacategory is changed on the page, and this increases # of projects we can display from 416 to 625 (still have 4 seperate categories as errors technically have 4). if we do an optimization query side to combine row categories as error, we can increase that number from 625 to 2500 when client-side pagination is implemented, could fetch new project totals when page changes </desc> <cmt> bump row limits on query up to 10k </cmt> <cmt> remove logging vars </cmt>",bump up query limit to max of 10k
840,"<desc> historically we have loaded ssl objects (such as sslcontext, ssliosessionstrategy) by passing in the ssl settings, constructing a new ssl configuration from those settings and then looking for a cached object that matches those settings. the primary issue with this approach is that it requires a fully configured settings object to be available any time the ssl context needs to be loaded. if the settings include securesettings (such as passwords for keys or keystores) then this is not true, and the cached ssl object cannot be loaded at runtime. this commit introduces an alternative approach of naming every cached ssl configuration, so that it is possible to load the ssl context for a named configuration (such as ""xpack.http.ssl""). this means that the calling code does not need to have ongoing access to the secure settings that were used to load the configuration. this change also allows monitoring exporters to use ssl passwords from secure settings, however an exporter that uses a secure ssl setting (e.g. truststore.secure_password) may not have its ssl settings updated dynamically (this is prevented by a settings validator). exporters without secure settings can continue to be defined and updated dynamically. backport of: c662565 edbea73 6f2b7dc </desc> <cmt> access ssl contexts using names instead of settings (#30953) </cmt> <cmt> historically we have loaded ssl objects (such as sslcontext, </cmt> <cmt> ssliosessionstrategy) by passing in the ssl settings, constructing a </cmt> <cmt> new ssl configuration from those settings and then looking for a </cmt> <cmt> cached object that matches those settings. </cmt> <cmt> the primary issue with this approach is that it requires a fully </cmt> <cmt> configured settings object to be available any time the ssl context </cmt> <cmt> needs to be loaded. if the settings include securesettings (such as </cmt> <cmt> passwords for keys or keystores) then this is not true, and the cached </cmt> <cmt> ssl object cannot be loaded at runtime. </cmt> <cmt> this commit introduces an alternative approach of naming every cached </cmt> <cmt> ssl configuration, so that it is possible to load the ssl context for </cmt> <cmt> a named configuration (such as ""xpack.http.ssl""). this means that the </cmt> <cmt> calling code does not need to have ongoing access to the secure </cmt> <cmt> settings that were used to load the configuration. </cmt> <cmt> this change also allows monitoring exporters to use ssl passwords </cmt> <cmt> from secure settings, however an exporter that uses a secure ssl setting </cmt> <cmt> (e.g. truststore.secure_password) may not have its ssl settings updated </cmt> <cmt> dynamically (this is prevented by a settings validator). </cmt> <cmt> exporters without secure settings can continue to be defined and updated </cmt> <cmt> dynamically. </cmt> <cmt> fix broken openldap vagrant qa test </cmt> <cmt> this was broken due to c662565 but the problem didn't get detected as </cmt> <cmt> ci builds typically don't run vagrant tests </cmt> <cmt> fix ad / vagrant based tests for #30953 </cmt> <cmt> these tests were creating a ssl service that was not aware of the </cmt> <cmt> realm that they were trying to test. </cmt> <cmt> this no longer works. </cmt>",backport ssl context names (#30953) to 6.x
841,<desc> changes: fix links /docs/content-and-data/refreshing-content -> /docs/refreshing-content/ link text match the doc title with upercased content #26106 add refresh content docs #19267 add link checker for gatsby docs </desc> <cmt> update repo </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> fix 404 </cmt>,page environment variables -> 404 on link
842,"<desc> fix wrong usage of rowsparsepull in sparse lr example update csr_matrix / row_sparse_array interface like scipy misc doc updates passed code style checking (make lint) for user-facing api changes, api doc string has been updated. to my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change intersting edge cases to note here </desc> <cmt> fix rowsparsepull usage in the example </cmt> <cmt> update csr_matrix interface </cmt> <cmt> update rowsparse tutorials </cmt> <cmt> update csr/rsp constructor code&doc </cmt> <cmt> doc & bug fixes </cmt> <cmt> fix empty </cmt> <cmt> bug fix for desnity=0 </cmt>",scipy style sparse ndarray constructor and misc sparse fixes
843,<desc> changed escape key to grave escape and flipped the position of the up and down arrows on the default keymap. flipped up and down arrows swapped esc for gesc fixed double period keys to comma and period on default map my code follows the code style of this project. i have read the contributing document. </desc> <cmt> changed esc to grave escape on default map </cmt> <cmt> flipped up and down arrows on default </cmt>,edit to default funky40 keymap
844,"<desc> reverts #63797 per discussion with @jberkus and @mwielgus the scope of the follow-ups required in #64286 was not well understood when the api pr was merged, and we are now past code freeze for 1.11 this can be reopened against 1.12 </desc> <cmt> revert ""add vertical pod autoscaling api to the autoscaling group."" </cmt> <cmt> this reverts commit 3f92d3fcda583dd6ac872400609d21dcfa7fb643. </cmt> <cmt> revert ""auto-generated code for the vertical pod autoscaler api."" </cmt> <cmt> this reverts commit da65f30e2aca4ca8177fcf27e95909e2883b6e20. </cmt> <cmt> revert ""add validation code for the vertical pod autoscaler api."" </cmt> <cmt> this reverts commit 390cfec6172fb3efdb5e13b96dcf942bc7bf2124. </cmt>",add vertical pod autoscaler to autoscaling/v2beta1
845,<desc> type: refactor description: at the moment the thread selector component does not seem to be very user-friendly. this pr applies some improvements in the component. before: after feedback is welcome :) </desc> <cmt> refactor(thread): re-design thread component </cmt> <cmt> refactor(thread): wip </cmt> <cmt> refactor(thread): added improvements </cmt>,improvements in the thread selector component
846,"<desc> updated the changes from #413 to only add power on/power off to the lcd menu if ps_on_pin > -1 and make them mergeable. also update languages.h to include all the missing strings for most languages (the most common one is the init_sd one). </desc> <cmt> toggle menu for psu from lcd pannel </cmt> <cmt> from the prepare menu, accessible when is not printing, you have the </cmt> <cmt> possibility to turn off the psu when is on et vice versa. </cmt> <cmt> from the host, you can turn off or turn on the psu then the menu is </cmt> <cmt> updated accordingly. </cmt> <cmt> from the lcd message, the printer status is reported ready or off </cmt> <cmt> respectively when the psu is on or off. </cmt> <cmt> turn off power supply off-load </cmt> <cmt> disable the high current output and wait a little before to turn off, </cmt> <cmt> because the interrupting capacity of the psu is unknown. </cmt> <cmt> could be a function if needed by other. </cmt> <cmt> no bed config for ramps </cmt> <cmt> the motherboard 35 is a config without bed with this pins setting : </cmt> <cmt> d8 extruder </cmt> <cmt> d9 fan </cmt> <cmt> d10 controller fan </cmt> <cmt> conflicts: </cmt> <cmt> marlin/configuration.h </cmt> <cmt> marlin/marlin_main.cpp </cmt> <cmt> marlin/language.h </cmt> <cmt> marlin/pins.h </cmt> <cmt> marlin/ultralcd.cpp </cmt> <cmt> merge github.com:erikzalm/marlin into marlin_v1 </cmt> <cmt> conflicts: </cmt> <cmt> marlin/language.h </cmt> <cmt> run marlin/language.h through dos2unix </cmt> <cmt> update language.h so that all languages compile </cmt> <cmt> some strings still need translation, but at least everything compiles. </cmt> <cmt> uniformly reindent language.h </cmt> <cmt> only display poweron/poweroff if ps_on_pin > -1 </cmt>","update #413 for merging, fix languages.h"
847,<desc> hi. i added 3 small fixes. two of them are spelling corrections and the other one is an outdated comment we can't dispose addcommand anymore... it can create confusion . </desc> <cmt> spelling fixed on the website playground. </cmt> <cmt> update old information on the website playground </cmt>,small update on the website playground
848,<desc> the default healthcheck interval used by kube2iam is 30s and if a single probe fails the container is killed because the configured interval is 5s for 3 fails -> 15s dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> allow to customise livenessprobe parameters </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> bump chart version </cmt> <cmt> document variables in the readme </cmt>,allow to customize liveness probe configuration
849,<desc> move uigraphicsendimagecontext() to override enddrawcontext: fix issue that image's frame can not be changed remove the overflow:hidden limit for border-x-x-radius on image </desc> <cmt> * [ios] move uigraphicsendimagecontext() to override enddrawcontext: </cmt> <cmt> * [ios] fix issue that image's frame can not be changed </cmt> <cmt> * [ios] remove the overflow:hidden limit for border-x-x-radius on image component </cmt>,some bug fixes for compositing and image component
850,"<desc> the ssh credentials api is ifdeffed, please remove it from the .h </desc> <cmt> make ssh apis present even without ssh support </cmt> <cmt> the ssh apis will just return an error code and state that the </cmt> <cmt> library was built without ssh support if they are called in </cmt> <cmt> that case. </cmt> <cmt> lots of ssh credential stuff can be left on </cmt> <cmt> much of the ssh credential creation api can be left enabled even </cmt> <cmt> on platforms with no ssh support.  we really just have to give an </cmt> <cmt> error when you attempt to open the ssh connection. </cmt>",api should not be ifdeffed
851,"<desc> the multiversion unit test is fixed to resolve occasional test failures, which mainly occurred at three checking points: nodes are not in sync before preactivation after the testing cluster is launched. to fix this, arenodesinsync method adds a waiting time when checking if nodes are in sync. 1st node should contain preactivate feature after the 1st node tries to activate preactivate feature. the fix adds retries to activate the feature and then check its status. 1st node should be out of sync with the rest nodes after the 1st node has activated the preactivate feature. this is fixed by not resuming (and then re-pausing) all nodes until the sync check is finished. thank @brianjohnson5972 for the help. select one: select any that apply: </desc> <cmt> initial fix </cmt> <cmt> test rounds for buildkite </cmt> <cmt> fix cicd script format for testing </cmt> <cmt> fix eof indent for testing </cmt> <cmt> fix the checking on preactivate feature and nodes sync </cmt> <cmt> change the sequence of checking and resume in arenodesinsync </cmt> <cmt> fix arenodesinsync checking </cmt> <cmt> only call nodehasblocks when headblocknums length is not 1 </cmt> <cmt> fix arenodesinsync, 1st node feature checking, and formatting </cmt> <cmt> fix typo </cmt> <cmt> clean up getblock implementation </cmt>",fix multiversion test failure - merge 2.1.x
852,"<desc> this builds the ci fuzzers with the intended clang version. it also allows users to set the clang version locally, in case they need to. it also switches the ci fuzzers to use an optimized sanitizer build, to do something oss-fuzz doesn't and get more done in the short time the ci fuzzer runs. </desc> <cmt> actually set the clang version in ci fuzz </cmt> <cmt> build sanitizer fuzzers with optimization -o3 </cmt> <cmt> quick check should use the debug friendly fuzzer build </cmt>",fuzz with the intended clang version
853,"<desc> fix lambda integration test. risk level: low testing: unit/integration tests docs changes: n/a release notes: n/a </desc> <cmt> filter: add last data frame to decoding buffer </cmt> <cmt> test: fix integration test timing out </cmt> <cmt> the lambda integration test is timing out because it's attempting to </cmt> <cmt> fetch the aws creds using the default provider. the default provider </cmt> <cmt> checks the environment variables and falls-back to querying ec2 instance </cmt> <cmt> metadata. since the ci does not have the environment variables, nor does </cmt> <cmt> it run on ec2, the provider spends 5s before it times out. </cmt> <cmt> the fix is to simply set environment variables. the values of the </cmt> <cmt> variables does not matter since we never actually send the request to </cmt> <cmt> aws. </cmt>",aws lambda integration test fix
854,"<desc> fixes #13912. adjust the use database authority judgment authoritychecker#check add the verification of schema authority </desc> <cmt> fix use database can still succeed without permission, and permission check is incomplete when querying. </cmt> <cmt> reformat. </cmt> <cmt> reformat. </cmt> <cmt> when verifying sql type permissions, add schema verification. </cmt> <cmt> drop database adds permission verification. </cmt> <cmt> adjust the class name. </cmt> <iss> query with schema name does not check user's privileges. </iss>",fix #13912  permission verification exception
855,<desc> i lacked documentation for the return when it could not find a match. the reason i have added two tests are for two reasons: to assert that documentation is on the same page as the actual code. as a regression test of future code changes. this is the second iteration of #1146. the only difference between this pull request and the old one is that i've removed the overly pedantic examples. </desc> <cmt> tests when findwhere can't find anything </cmt> <cmt> document findwhere when it can't find anything </cmt>,improved documentation and tests (2nd)
856,"<desc> partial backport of #20414 and #20424 without renaming shipped texturepacker fixes cross-compiling issues on debian and other unix like systems built 20.0 + 19,3 cross for armhf on amd64 and natively for amd64 it is developer change bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> accept renamed texturepacker and jsonschemabuilder </cmt> <cmt> ... to kodi-texturepacker and kodi-jsonschemabuilder. </cmt> <cmt> these names are less generic and will less likely cause conflicts </cmt> <cmt> in /usr/bin. </cmt> <cmt> this change only makes cmake buildsystem recognize texturepacker and </cmt> <cmt> jsonschemabuilder built under names from nexus but does not rename </cmt> <cmt> anything that is shipped to end users! </cmt> <cmt> fix ""*-executable_notfound"" if absolute path to file specified </cmt> <cmt> fixes broken handling of with_* cmake configuration options: </cmt> <cmt> * find_program expects directory in paths and hints while </cmt> <cmt> with_* option is an absolute path to file. </cmt> <cmt> * paths in find_program is the last resort option which </cmt> <cmt> declares hardcoded guesses utilized after all cached </cmt> <cmt> paths, then directories specified by hints. </cmt> <cmt> this commit splits the full pathname to directory and filename </cmt> <cmt> then ""searches"" the filename in the directory, confirming file </cmt> <cmt> exists there and is executable. </cmt> <cmt> split texturepacker executed during build and shipped </cmt> <cmt> before this commit, shippable texturepacker is not built at all if: </cmt> <cmt> * the pre-built texturepacker is supplied by -dwith_texturepacker </cmt> <cmt> * build is kodi_dependsbuild </cmt> <cmt> * building for windows </cmt> <cmt> this breaks generation of kodi-tools-texturepacker package on linux </cmt> <cmt> and freebsd if cross-compiling. </cmt> <cmt> the new commit separates installable and executable texturepackers. </cmt> <cmt> executable texturepacker is executed on all platforms, but it can </cmt> <cmt> be overriden by a binary specified by kodi_dependsbuild or </cmt> <cmt> with_texturepacker options on non-depends build. </cmt> <cmt> installable texturepacker is shipped only on linux and freebsd </cmt> <cmt> platforms, and is executed only if the build is not a cross-compilation </cmt> <cmt> and the executable texturepacker not overridden by one of the options </cmt> <cmt> above. </cmt> <cmt> if external texturepacker is specified with_texturepacker but its </cmt> <cmt> executable file can not be found, a warning is raised and the module </cmt> <cmt> falls back to build internal texturepacker if it can be executed </cmt> <cmt> during the build. </cmt>",texturepacker and jsonschemabuilder finders fixes
857,"<desc> cherry-pick of #24969 to swift-5.1-branch reviewed by @benlangmuir rdar://problem/47169238 </desc> <cmt> [codecompletion] suggest 'file', 'line', et al. after # </cmt> <cmt> rdar://problem/47169238 </cmt> <cmt> (cherry picked from commit 83084e2b5f9c8e1816195d853f351f60203a9373) </cmt> <cmt> [codecompletion] use completionlookup.currmodule instance property </cmt> <cmt> (cherry picked from commit 3c957de1c9e3228e6857d95d364d530a59fee264) </cmt> <cmt> [codecompletion] suggest #selector and #keypath after # only if applicable </cmt> <cmt> also, add type annotation, and make it typerelation[identical]. </cmt> <cmt> 'exprspecific' is too strong. </cmt> <cmt> (cherry picked from commit e2a4621b145f84f4776a33a438aacfcb10b2b475) </cmt> <cmt> [codecompletion] added test case for polymorphic type keywords </cmt> <cmt> (cherry picked from commit c0014838cabbe1e50145db7d887af2e85d13f869) </cmt>","'#file', '#line', et al. after '#'"
858,"<desc> description: upgrade to pysonos 0.0.7 to make discovery work with multiple ""households"". a household is the name sonos uses for one mesh of speakers (a household can have several groups but a group can only contain speakers from one household). before this pr, a random household would be picked up by discovery and remaining households could not be controlled. since the version bump is a tiny change, i included a separate commit that renames away from ""device"". i find this name confusing now that home assistant has the device registry. related issue (if applicable): fixes #20412 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> remove confusing device naming </cmt> <cmt> add discovery of multiple households </cmt> <iss> sonos integration randomly picks one (of two) sonos devices </iss>",add sonos discovery of multiple households
859,"<desc> rename linux folder to linux, res folder (in tests project) and resource(in helloworld project)to resources. modify bada, qnx and linux project settings of which ide depend on eclipse to keep independence when a new port is added. update ios project configures for ios, and modify xcode4's template. move extensions folder to the root of cocos2dx. add the author name of ccnotificationcenter. add extensionstest, and set notificationcentertest as a child item of it. </desc> <cmt> issue #972: move extensions folder to cocos2dx </cmt> <cmt> rename resource(in hellolua and helloworld project) and res(in tests project) to resources. </cmt> <cmt> test ok on win32 and android </cmt> <cmt> remove .settings folder </cmt> <cmt> modify marmalade project setting </cmt> <cmt> 1.modify some project setting for bada </cmt> <cmt> 2.rename some files </cmt> <cmt> rename include file name from uppercase to lowercase for linux platform </cmt> <cmt> modify bada 2.0 project setting </cmt> <cmt> move library to platform folders </cmt> <cmt> refactor folder </cmt> <cmt> refactor folders for qnx </cmt> <cmt> update bada and qnx project settings </cmt> <cmt> update linux project configure </cmt> <cmt> update ios project configures for ios, and modify xcode4's template </cmt>",refactor some folder and modify project configures for all platforms
860,"<desc> _py_encodelocaleraw, which is private by name, undocumented, and wasn't exported in python3.dll, is moved to a private header. _py_hashsecret_initialized, again private by name, undocumented, and not exported in python3.dll, is excluded with py_limited_api. pymarshal_* and pymember_*one functions, declared in private headers and not exported in python3.dll, are removed from doc/data/stable_abi.dat. pymem_calloc which was exported in python3dll.c, is moved to public headers where it joins its other pymem_* friends. only the last change is documented in the blurb; others are not user-visible. (nothing uses doc/data/stable_abi.dat yet.) </desc> <cmt> move _py_encodelocaleraw to the private header </cmt> <cmt> this symbol is not part of the limited api, and was even missing </cmt> <cmt> in python's stable abi dll. </cmt> <cmt> don't define _py_hashsecret_initialized in limited api </cmt> <cmt> the underscore means it's not public api. </cmt> <cmt> it was also not exported in the windows stable abi library. </cmt> <cmt> remove pymarshal_* and pymember_{get,set}one functions from the limited api </cmt> <cmt> these functions are not declared with py_limited_api. </cmt> <cmt> except for functions that take file*, they remain in the stable abi. </cmt> <cmt> include pymem_calloc in the limited api </cmt> <cmt> add blurb </cmt>",pep-652: clean up the stable abi/limited api
861,"<desc> splits caps into caps_a, caps_c, caps_u, caps_sc, caps_ss, and caps_su. stubs getalbumcontentsfilelistforapplication (#2720) as it is used in super smash bros. ultimate world of light. the crash following this is unrelated. this command is also used when taking a snapshot. however, it calls savescreenshotex0 in caps:su next and crashes due to it also being unimplemented. </desc> <cmt> organize capture services into individual files </cmt> <cmt> stub getalbumcontentsfilelistforapplication </cmt>",split capture services into individual files and stub getalbumcontentsfilelistforapplication
862,"<desc> this pr add standardized serialization to all the tokenizers (bert, gpt, gpt-2, transformer-xl) through a tokenizer.save_vocabulary(path) method. also add a serialization method to all the configuration classes: config.to_json_file(file_path) added clean examples for serialization best practices in readme and examples. also fixes transformer-xl ""split on punctation"" bug mentioned in #466. </desc> <cmt> add serialization semantics to tokenizers - fix transfo-xl tokenizer </cmt> <cmt> added tokenizers serialization tests </cmt>","better serialization for tokenizer and config classes (bert, gpt, gpt-2 and transformer-xl)"
863,"<desc> fixes: #2722 @charlier if you  get the chance you can use our pika-distribution (one of the pr-checks) to see if it works locally for you. </desc> <cmt> avoid assigning to dom-node.style, this is readonly in ie11 and other old browsers which results in an exception </cmt> <cmt> remove unused var </cmt> <iss> ie11 throws errors when using the style attribute </iss>",avoid assigning to readonly style
864,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes: future states increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> ui-router-extras - added tslint.json </cmt> <cmt> ui-router-extras </cmt> <cmt> added type definitions for future states </cmt>",updated type definitions for 'ui-router-extras'
865,"<desc> ... in client-gen, informer-gen, lister-gen. follow-up of #54950. before this pr, the generated code was broken for internal types and for group package names that were no valid go identifiers. this pr completes the separation in the following sense: groupnames are domain-like logical name for the group. only the first segment is used as default for goname pkgname is the directory name. all packages in client, informer, lister re-use this for packages. goname is the go identifier (camelcase) used to reference the group, e.g. in the interface names, in the clientsets etc. moreover it is used for package import aliases. note: this pr does not change the generated code in kubernetes, only the examples in k8s.io/code-generator. fix code-generators to produce correct code when groupname, packagename and/or goname differ. </desc> <cmt> code-generator: fix multiple internal groups in generate-internal-groups.sh </cmt> <cmt> code-generator: complete pkgname, groupname, goname separation </cmt> <cmt> - groupnames are domain-like logical name for the group. only the </cmt> <cmt> first segment is used as default for goname </cmt> <cmt> - pkgname is the directory name. all packages in client, informer, lister </cmt> <cmt> re-use this for packages. </cmt> <cmt> - goname is the go identifier (camelcase) used to reference the group, e.g. </cmt> <cmt> in the interface names, in the clientsets etc. moreover it is used </cmt> <cmt> for package import aliases. </cmt> <cmt> the goname defaults to the first segment of the groupname. </cmt>","complete pkgname, groupname, goname seperation"
866,"<desc> closes  when #17000 is merged, this pr will make this code valid and work // @ts-check const { defineconfig } = require(""cypress""); const cracoconfig = require('./craco.config.js') const setupcracodevserver = require(""@cypress/react/plugins/craco""); module.exports = defineconfig({ component: { testfiles: ""src/**/*.test.{js,ts,jsx,tsx}"", componentfolder: ""src"", devserver(devserverconfig){ return setupcracodevserver(devserverconfig, cracoconfig) } } }) it also will make nextjs installs easier // cypress.congig.js const { defineconfig } = require(""cypress""); const { devserver } = require(""@cypress/react/plugins/next""); module.exports = defineconfig({ component: { testfiles: ""src/**/*.test.{js,ts,jsx,tsx}"", devserver } }) changelog of this pr created the wrap-devserver function used wrap-devserver in all the npm/react/plugins/xxxx/index.js added typings for those index.js files checked the types definition by using them examples by using @ts-check </desc> <cmt> refactor: vite-dev-server use resolveddevserverconfig </cmt> <cmt> feat: allow suage of plugins in new syntax </cmt> <cmt> add types to plugins </cmt> <cmt> examples checks </cmt> <cmt> fix types comments on craco </cmt>",allow usage of @react/plugins with cypress.config.js
867,"<desc> we need to add openssl to the list of private dependencies regardless of whether we want it for sha-1 or tls. during #4398 the rules got changed so we only add it when we want it as the sha-1 implementation, rather than if we searched for openssl and found it. this means that choosing sha1dc (or using a newer version where this is the default) would no longer indicate to those including us as a static archive that they need to link against the openssl package. this takes care of the second part of #4466 and we should again be able to include the library in bindings. </desc> <cmt> cmake: treat libgit2_pc_requires as a list </cmt> <cmt> it is indeed a list of dependencies for those which include the static archive. </cmt> <cmt> this is in preparation for adding two possible places where we might add openssl </cmt> <cmt> as a dependency. </cmt> <cmt> cmake: add openssl to the private deps list when it's the tls implementation </cmt> <cmt> we might want openssl to be the implementation for sha-1 and/or tls. if we only </cmt> <cmt> want it for tls (e.g. we're building with the collision-detecting sha-1 </cmt> <cmt> implementation) then we did not indicate this to the systems including us a </cmt> <cmt> static library. </cmt> <cmt> add openssl to the list also during the tls decision to make sure we say we </cmt> <cmt> should link to it if we use it for tls. </cmt>",make sure to include 'openssl' as a dep when building statically with sha1dc
868,<desc> reverts gh-14458 and instead fixes the actual incorrect code. this fixes a regression in 1.17 and does not result in a change in behavior of the legacy random code. </desc> <cmt> maint: random: revert gh-14458. </cmt> <cmt> bug: random: fix the mistaken duplicate line. fixes gh-14557. </cmt>,random: revert gh-14458 and refix gh-14557.
869,"<desc> similar in spirit to #5460. includes a semi-related cosmetic change so the ra_cap_fragcoord check looks like all the others. no idea if hdr peak detection actually works in dumb mode. </desc> <cmt> vo_gpu: check for hdr peak detection in dumb mode too </cmt> <cmt> similar spirit to edb4970ca8b9. check_gl_features() has a confusing </cmt> <cmt> early-return. this also adds compute_hdr_peak to the list of options </cmt> <cmt> that is copied to the dumb-mode options struct, since it seems to make a </cmt> <cmt> difference. otherwise it would be impossible to disable hdr peak </cmt> <cmt> detection in dumb mode. </cmt> <cmt> vo_gpu: use a variable for the ra_cap_fragcoord flag </cmt> <cmt> this is just a cosmetic change. now the ra_cap_fragcoord check looks </cmt> <cmt> like all the others. </cmt>",fix hdr peak detection check in dumb mode
870,"<desc> whew, that took a while. the compressed ellpack buffers are written to disk now. i haven't changed the gpu_hist updater to handle multiple pages yet. will work on that next. part of #4357. @ramitchell @trivialfis @sriramch </desc> <cmt> add ellpack source </cmt> <cmt> add placeholders </cmt>",write ellpack pages to disk
871,"<desc> a follow-up of #319 . this multi-part pr tries to implement as much new service names as possible without adding / stubbing new services. most of these are taken from switchbrew -  sorry, the previous pr was busted by a bad rebase, so i properly rebased it this time. </desc> <cmt> update fork </cmt> <cmt> updated acc with more service names </cmt> <cmt> updated svc with more service names </cmt> <cmt> updated set with more service names </cmt> <cmt> updated sockets with more service names </cmt> <cmt> updated spl with more service names </cmt> <cmt> updated time with more service names </cmt> <cmt> updated vi with more service names </cmt>",various service name fixes - part 2 (rebased)
872,"<desc> this applies to the producer, consumer, admin client, connect worker and inter broker communication. clientdnslookup.default has been deprecated and a warning will be logged if it's explicitly set in a client config. </desc> <cmt> make use.all.dns.ips as the default behaviour fir client.dns.lookup configuration </cmt> <cmt> added use_first_dns_ips option for client.dns.lookup configuration </cmt>",set use_all_dns_ips as the new default for client.dns.lookup (kip-602)
873,<desc> fixes #1045 now it'll show the displayname is react-dev-tools properly. </desc> <cmt> using styled-jsx for with-jest example. </cmt> <cmt> set the displayname of the wraped components. </cmt> <cmt> otherwise it won't get the correct displayname if the </cmt> <cmt> original component doesn't provide it by using it's function name. </cmt>,set displayname properly when patching react locally.
874,<desc> fixes #7406. thanks @franjohn21 for providing such a detailed investigation! reviewers: @gaearon @jimfb </desc> <cmt> corrected reactchildrenmutationwarninghook's name </cmt> <cmt> changed oncomponenthasmounted to onmountcomponent </cmt> <cmt> and get element from reactcomponenttreehook instead of keeping an internal store </cmt>,fix memory leak in reactchildrenmutationwarninghook for ssr
875,"<desc> removes painless type in favor of java class from locals, variables, params, and scriptinfo. </desc> <cmt> replace painless type with java class in locals, variable, and parameter. </cmt> <cmt> replace painless type with java class in scriptclassinfo. </cmt>","remove painless type from locals, variables, params, and scriptinfo"
876,"<desc> commit message: adds iterate() functionality for stats scopes. this makes it possible to robustly find a stat by string in prod code, even if the caller does not know whether some segments of the name were created via statnamedynamicstorage, so a new stats::utility api is added to encapsulate the lookup and caching of stats by string. note that the existing deprecated counterfromstatname only works for fully symbolic names. additional description: this can potentially enable a hierarchal stats exploration admin interface (though we'd need to be able to iterate over sub-scopes too). risk level: low -- these new capabilities are tested, but not called from prod code yet. they may prove useful at google and in nighthawk, per the referenced bug. testing: //test/... docs changes: n/a release notes: n/a fixes: #11799 </desc> <cmt> initial checkin for stats::scope::iterate() methods. </cmt> <cmt> add basic tests for counters. </cmt> <iss> stats: need mechanism for finding a stat by name in production code </iss>","add iterate methods for scope, and a lazy find-from-string implementation."
877,"<desc> prevents messages like the following when using runtime envs: /users/yic/miniconda3/envs/py37/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: futurewarning: not all ray cli dependencies were found. in ray 1.4+, the ray cli, autoscaler, and dashboard will only be usable via pip install 'ray[default]'. please update your install command. these messsages currently appear because only ray is injected. based off of #16267. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add get_release_wheel_url() </cmt> <cmt> inject ray[default] instead of ray </cmt>",inject ray[default] into pip dependencies
878,"<desc> 1.18 backport of #94112 fixed a bug where improper storage and comparison of endpoints led to excessive api traffic from the endpoints controller </desc> <cmt> remove headlessservice label in endpoints controller before comparing </cmt> <cmt> do not mutate endpoints in the apiserver </cmt> <cmt> the endpoints api handler was using the canonicalize() method to </cmt> <cmt> reorder the endpoints, however, due to differences with the </cmt> <cmt> endpoint controller repacksubsets(), the controller was considering </cmt> <cmt> the endpoints different despite they were not, generating unnecessary </cmt> <cmt> updates evert resync period. </cmt>",remove canonicalization of endpoints by endpoints controller for better comparison
879,"<desc> when add an armature data info, need set info for each armature data. this pr is to fixed info bug </desc> <cmt> fix bug: did not addarmature to the relativedata </cmt> <cmt> fix bug: did not addarmaturefileinfo to the relativedata </cmt>",fixed add relative data bug
880,"<desc> still doesn't compile in arm64 due to missing libraries in arm64 mode, but at least cocos2d compiles file. also this patch enables a very important flag in xcode: 64-to-32-bit conversion warning. there are more than 200 warnings because of this issue. and if we don't fix those warnings we could have serious bugs. ( i already fixed some of them ) </desc> <cmt> arm64 support </cmt> <cmt> disables  arm64 for the moment </cmt> <cmt> enables more warnings in xcode project </cmt> <cmt> removes hungarian notation </cmt> <cmt> from ccactionmanager and fixes some 64-bit issues. </cmt> <cmt> fixes some compiler warnings </cmt> <cmt> the warnings are related to: </cmt> <cmt> * 64-to-32-bit conversion </cmt> <cmt> * shadow variables </cmt>",project is 64-bit arm friendly
881,"<desc> #42689 removed an ""unwanted"" copy, but i actually added this on purpose. this is to ensure we store contiguous 1d arrays by default, which is important for performance reasons. </desc> <cmt> revert ""bug: arraymanager construction unwanted copy (#42689)"" </cmt> <cmt> this reverts commit cb3b4e4a0e9ae350b6e1dc2e42f27ec9fd23cdb7. </cmt> <cmt> add comment and test </cmt>",ensure we store contiguous arrays in dataframe(ndarray) for arraymanager
882,"<desc> add livenessprobe, readinessprobe, startupprobe spis in dubbo-qos add bootstarp impl for readinessprobe, startupprobe add provider register check for readinessprobe </desc> <cmt> feat: add port modification of metadataservice, add serviceintance metadata fetch interface to metadataservice </cmt> <cmt> fix: remove unnecessary wrap </cmt> <cmt> style: pretty warn message when port not specified in consumer side </cmt> <cmt> fix: remove reconnect method of metadataservice </cmt> <cmt> fix: add subscribed_service_names_key support </cmt> <cmt> feat: add http code support for qos-http </cmt> <cmt> feat: modify ready to startup indicate </cmt> <cmt> feat: introduce k8s probe </cmt> <cmt> feat: polish comment </cmt>",add life cycle probe in dubbo-qos
883,<desc> the install documentation had out of date info for the deep learning amis. removed links to old marketplace dlamis. replaced with general documentation link. </desc> <cmt> changed url references from dmlc to apache/incubator-mxnet </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> updated dlami info </cmt>,install docs - update info about dlami
884,"<desc> e. g. let b: box<foo> = box::from_raw(p); instead of let b: box<foo> = mem::transmute(p); patch also changes closure release code in src/libstd/sys/unix/thread.rs when pthread_create failed. raw pointer was transmuted to box of fnonce() instead of thunk. this code was probably never executed, because pthread_create rarely fails. (and there are two more patches in pr: fix typo in doc and mark from_raw and into_raw functions inline.) </desc> <cmt> boxed: fix typo in doc </cmt> <cmt> boxed: mark from_raw and into_raw functions inline </cmt> <cmt> use boxed functions instead of transmute </cmt> <cmt> ... to convert between box and raw pointers. e. g. use </cmt> <cmt>  </cmt> <cmt> let b: box<foo> = box::from_raw(p); </cmt> <cmt>  </cmt> <cmt> instead of </cmt> <cmt>  </cmt> <cmt> let b: box<foo> = mem::transmute(p); </cmt> <cmt>  </cmt> <cmt> patch also changes closure release code in src/libstd/sys/unix/thread.rs </cmt> <cmt> when pthread_create failed. raw pointer was transmuted to box of </cmt> <cmt> fnonce() instead of thunk. this code was probably never executed, </cmt> <cmt> because pthread_create rarely fails in practice. </cmt>",use boxed functions instead of transmute in the standard libraries
885,"<desc> adds support for the put lifecycle policy api to the high level rest client. converts existing ilm integration tests to use the new hlrc put api instead of the llrc. as a prerequisite for this change, the lifecycle pojos moved from protocol to client.indexlifecycle, following the new hlrc code structure. </desc> <cmt> move lifecycle objects from protcol to core </cmt> <cmt> required for implementation of put and get lifecycle apis in the </cmt> <cmt> high-level rest client. </cmt> <cmt> hlrc: add put lifecycle api to the hlrc </cmt> <cmt> use hlrc put for ilm integration tests </cmt> <cmt> align put api code with changes in delete api </cmt>",add put lifecycle policy api to hlrc
886,<desc> this refactors the buildsteps scripts for windows to easily add x64. the scripts in tools/buildsteps are architecture independent and are not allowed to be called directly. they get called by architecture dependant scripts which are located in subdirectories. add windows x64 without duplication many lines of code. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [cleanup][windows] buildsetup: remove leftover from vs2010 </cmt> <cmt> [buildsteps][windows] remove unused files </cmt> <cmt> [buildsteps][windows] prepare-env </cmt> <cmt> [buildsteps][windows] download </cmt> <cmt> [buildsteps][windows] make-mingwlibs </cmt> <cmt> [buildsteps][windows] bootstrap-addons </cmt> <cmt> [buildsteps][windows] make-addons </cmt>,refactor to add x64 easily
887,"<desc> this pull request fixes the doumented signature of four ufunc methods: ufunc.reduce & .reduceat have a parameter which is incorrectly labeled as a (should be array). ufunc.at & .outer have a number of positional-only parameters which are currently not marked as such. examples >>> import numpy as np >>> np.__version__ '1.20.0.dev0+c04bb88' >>> ar = np.arange(5) # should be array; not a >>> np.add.reduce(a=ar) traceback (most recent call last): ... typeerror: reduce() missing required argument 'array' (pos 1) # should be array; not a >>> np.add.reduceat(a=ar, indices=[0, 1]) traceback (most recent call last): ... typeerror: reduceat() missing required argument 'array' (pos 1) # doesn't take keyword arguments >>> np.add.at(a=ar, indices=0, b=1) traceback (most recent call last): ... typeerror: at() takes no keyword arguments # the error is not as clear as with at(), # but in the end it doesn't seem to accept keyword arguments either >>> np.add.outer(a=ar, b=ar) traceback (most recent call last): ... typeerror: exactly two arguments expected </desc> <cmt> doc: clarify that a number of ufunc-related parameters are positional-only </cmt> <cmt> doc: fixed an incorrect parameter name </cmt> <cmt> a' should be array in np.ufunc.reduce() </cmt> <cmt> doc: fixed an incorrect parameter name in ufunc.reduceat </cmt> <cmt> doc: replace all leftover references to a with array </cmt> <cmt> doc: replace two more leftover references to a with array </cmt>",fix the documented signatures of four ufunc methods
888,<desc> recent change to set a fixed width for rootview in e2e fixes the inconsistency for width in ci vs local -- closes #7589. microsoft reviewers: open in codeflow </desc> <cmt> take out hardcoded width </cmt> <cmt> updated snapshots </cmt> <iss> visual tests: width value for some elements differs in ci vs. locally </iss>,snapshot update accounting for fix in width inconsistency.
889,"<desc> switch all of the relevant failurediagnostic apis to use typednode instead of expr * and refactor diagnostic implementations to avoid relying on anchors being expressions where possible. since failurediagnostic is the biggest user of constraintlocator this refactoring enables to transition locator from being anchored only on expressions. </desc> <cmt> [diagnostics] provide anchors on demand instead of storing in failurediagnostic </cmt> <cmt> this decouples failurediagnostic from expression. </cmt> <cmt> [diagnostics] switch get{raw}anchor to return typednode </cmt> <cmt> in preparation to anchor constraintlocator from typednode </cmt> <cmt> let's refactor diagnostics (which is the biggest user of locators) </cmt> <cmt> to support typednode instead of expr *. </cmt> <cmt> [diagnostics] switch getconstraintlocator variants to accept typednode </cmt> <cmt> [diagnostics] switch getcontextualtype* to use typednode </cmt> <cmt> [diagnostics] switch gettype to use typednode </cmt> <cmt> [diagnostics] resolve const-ness problems introduced by typednode </cmt> <cmt> since typednode elements are all marked as const diagnostics </cmt> <cmt> need to get some of the apis adjusted to support passing const expr *. </cmt> <cmt> [diagnostics] add helper functions to work with anchors - {castto, getas, is}expr </cmt> <cmt> [diagnostics] adjust getcallinfo to accept typednode instead of expression </cmt>",refactor failurediagnostic to operate on typednode
890,"<desc> cleanup from gh-17304 which pinned pylexer pygments. also numpydoc is stable. so remove the submodule dependency and add it to the regular doc build dependencies. we copied in some of the documentation, i refactored that to be a link instead. </desc> <cmt> doc, bld: fix templated c highlighting </cmt> <cmt> doc, bld: update doc build dependencies, remove as numpydoc submodule </cmt>",update lexer highlighting and make numpydocs a regular dependency.
891,"<desc> reduce context switching cost by optimizing thread model on the consumer side. threading model for handling responses sync call, i/o -> biz thread async call, i/o -> shared pool -> biz thread introduced executorrepository, need to be further improved later. xxxxx follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> introduce executor manager </cmt> <cmt> consumer thread model </cmt> <cmt> optimize consumer side thread model </cmt>",reduce context switching cost by optimizing thread model on consumer side.
892,"<desc> closes #26962 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> resetting path in azure-pipeline.md </cmt> <cmt> resetting path in azure-pipeline.md </cmt> <cmt> add miniconda path to docs </cmt> <cmt> fix syntax error in posix </cmt> <cmt> fix posix block error </cmt> <cmt> fix missing braces around home </cmt> <cmt> reorder path setting in posix </cmt> <cmt> reorder path setting in posix </cmt> <cmt> undo doc generation </cmt> <iss> ci: fix azure pipelines problem with path </iss>",fix miniconda path issue #26962
893,"<desc> gophercloud now supports auto reauth for both identity api v2.0 and v3. stop authentication per request, reauth only if token is expired. </desc> <cmt> update gophercloud to latest </cmt> <cmt> use auto reauth when access token is expired </cmt>",update gophercloud to head and reenable auto reauth
894,<desc> reference issue #8676 the changes here fixes the oneclasssvm predict method. the method used to return float and now returns integer types. small changes to the test are also included. if any further testing or documentation is required please let me know. </desc> <cmt> added predict method to class oneclasssvm </cmt> <cmt> - this method overrides the default behaviour to only return integer class values. </cmt> <cmt> test for the change in oneclasssvm predict method </cmt> <cmt> - small addition to test that the predicted result is integer </cmt>,oneclasssvm predict now returns int
895,"<desc> description: it appears that ci (bazel & envoy projects) has diverged in its memory behavior from our development environment behavior, so we need to rely on expect_le rather than expect_eq for tracking memory usage. otherwise we inherit a boatload of maintenance and determinism hassle trying to keep ci and dev builds working. risk level: low testing: //test/... finished (default build).   --config libc++ running now in parallel. docs changes: n/a release notes: n/a fixes: #7196 </desc> <cmt> use approximate memory thresholds to allow for variances in stl, etc. </cmt> <iss> stats_integration_test failing on bazel ci </iss>",use expect_le to measure memory consumption to allow for differing versions of stl etc
896,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> cleanup part of lint error ""no-unnecessary-generics"" </cmt> <cmt> cleanup lint error: adjacent-overload-signatures </cmt> <cmt> arguments array to iterable(bluebird not support arraylike) </cmt> <cmt> delete already resolved todo </cmt> <cmt> [wip] cleanup lint-errors: void-return </cmt> <cmt> cleanup lint error: no-unnecessary-callback-wrapper </cmt> <cmt> cleanup ignore lint error: no-void-expression </cmt> <cmt> clean self </cmt> <cmt> enable noimplicitthis </cmt> <cmt> enable strictfunctiontypes </cmt>",cleanup ignore lint error and enable strintfunctiontypes and noimplicitthis
897,"<desc> this was reported by @milhousevh using his texture cache script: ./texturecache.py stress-test thumbnail 452 0.25 999 10 which stress tests the jpeg->texture code. on current master this occasionally hangs or crashes. also if gpu memory is insufficient such that the error handling code is invoked we may not free the partially allocated resources. with the patches, the stress test failures no longer occur. </desc> <cmt> [rbp] restructure the egl context and display variables </cmt> <cmt> using a global for context that gets set by the first run of the </cmt> <cmt> texture thread is risky if the first function call happens directly </cmt> <cmt> (if it's in a suitable thread so bypasses the texture thread). </cmt> <cmt> [rbp] use generic texture queue for alloc/destroy </cmt> <cmt> this avoids a subtle bug where one thread calls tex->sync.set() </cmt> <cmt> and another calls tex->sync.wait(); delete tex; </cmt> <cmt> the set can cause a task switch before the set call exits. </cmt> <cmt> if the freed tex structure is overwritted before the first thread </cmt> <cmt> is switched back to, it can crash or hang. </cmt> <cmt> [rbp] fix leaks in the failure handling of jpeg decode to texture </cmt> <cmt> there are a couple of cases where memory could be leaked after an allocation failure </cmt> <cmt> when decoding jpegs to textures. </cmt>",fixes for hangs and leaks in jpeg->texture code
898,"<desc> this pr adds complete jsdoc comments to the following d3 module definitions: d3-selection d3-transition refer to #11366. it also includes fixes and enhancements to these definitions. some changes to move towards complete validation for strictnullchecks with respect to some method signatures some signature changes in d3-transition a more restrictive return type for interpolators returned by tween factories passed into attr, style the signatures for top-level transition(...) have been updated. tests have been updated where necessary. for details see the commit messages. </desc> <cmt> d3-selection </cmt> <cmt> * [chore]: completed jsdoc comments </cmt> <cmt> * [chore]: removed outdated comments </cmt> <cmt> * [enhancement]: added some explicit setter signatures, where using the setter with null as a value clears the set attribute, style, property </cmt> <cmt> * [enhancement]: added explicit possible null return value for touch(...) if touch cannot, be found for the fiven identifier </cmt> <cmt> d3-transition and d3-selection </cmt> <cmt> * **[chore](d3-selection)**: added jsdoc comments for selection<...> interface and param priority to style(...) </cmt> <cmt> * **[enhancement](d3-selection)**: started adding some | null for strict null checking.  in valuefn passed into attr, style, text, html. clarifying the ability to clear the respective property when null is returned. also added | null to node() return type. </cmt> <cmt> * **[chore](d3-transition)**: added jsdoc comments. </cmt> <cmt> * **[enhancement/fix](d3-transition)**: updated signatures for attrtween(...) and styletween(...) to align them with curent api doc. added getter, remover and reduced permissible return type for interpolator to string. added getter signature for tween(...) </cmt> <cmt> * **[enhancement](d3-transition)**: added | null in preparation of strict null checking support to valuefn return types for attr, style, and text. same with return type for node(). </cmt> <cmt> * [breaking](d3-transition): return type of interpolators returned by tween factories in attr and style has been reduced to string as per api doc. (one test was adjusted accordingly) </cmt> <cmt> d3-transition </cmt> <cmt> * [breaking](d3-transition): fixed signatures for top-level transition method. the generics have been updated, as only the datum type in the returned transition needs to be typed. the rest is pre-determined based on a document root selection. </cmt> <cmt> * **[fix](d3-transition)**: when using an existing transition as an argument, the transition type is not constrained for the argument. </cmt> <cmt> * adjusted affected tests. </cmt> <cmt> d3-transition </cmt> <cmt> * [chore](d3-transition): updated patch version of reference module to 1.0.2 </cmt>",d3-selection and d3-transition jsdoc comments and fixes
899,"<desc> remove __declspec(dllexport) from the definition and add template instantiation declaration (aka extern) in format.h i'm not sure the added position is correct, please check if it's okey. </desc> <cmt> clang keeps complain it ignores __declspec(dllexport) </cmt> <cmt> clang keeps complain it ignores __declspec(dllexport) in format.cc's instantiation of ""detail::basic_data<void>;"" </cmt> <cmt>  </cmt> <cmt> c:/users/user/appdata/roaming/fmt-master/src/format.cc:58:17: warning: 'dllexport' attribute ignored on explicit instantiation definition [-wignored-attributes] </cmt> <cmt> template struct fmt_instantiation_def_api detail::basic_data<void>; </cmt> <cmt> ^ </cmt> <cmt> c:/users/user/appdata/roaming/fmt-master/include\fmt/core.h:228:37: note: expanded from macro 'fmt_instantiation_def_api' </cmt> <cmt> #  define fmt_instantiation_def_api fmt_api </cmt> <cmt> ^ </cmt> <cmt> c:/users/user/appdata/roaming/fmt-master/include\fmt/core.h:210:32: note: expanded from macro 'fmt_api' </cmt> <cmt> #    define fmt_api __declspec(dllexport) </cmt> <cmt> ^ </cmt> <cmt> 1 warning generated. </cmt> <cmt>  </cmt> <cmt> i guess we have to make an explicit instantiation definition of basic_data<void> in format.cc (without __declspec(dllexport) ) </cmt> <cmt> and make an explicit instantiation declaration (aka extern template) in format.h instead </cmt> <cmt> add the template instantiation declaration </cmt> <cmt> add the template instantiation **declaration** of basic_data<void> </cmt> <cmt> the the template instantiation **definition** is in format.cc </cmt>",clang keeps complain it ignores __declspec(dllexport) of basic_data<void> template instantitation definition in format.cc
900,<desc> issue: #14114 updated the reactfastrefreshplugin config per experiments with @ndelangen @mrmckeb self-merging @tooppaaa untested. what we did by hand: install cra (4.0+) install sb see 'ws://localhost:3085/_content/ws' failed: error during websocket handshake: unexpected response code: 404 patch this fix by hand see error fixed </desc> <cmt> react fast refresh: fix socket connection error </cmt> <cmt> fix test timeout </cmt>,fix fast refresh socket connection error
901,"<desc> closes #36031 closes #32761 closes #10319 xref #11645 (fixes the issue expect the 0, will add an additional pr about the doc) closes #13254 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry i implemented the kahan summation as suggested by @jreback. i used the variable names from </desc> <cmt> implement kahan summation for rolling mean </cmt> <cmt>  conflicts: </cmt> <cmt> 	doc/source/whatsnew/v1.2.0.rst </cmt> <cmt> 	pandas/core/arrays/datetimelike.py </cmt> <iss> rolling_mean returns small negative value on series with non-negative values </iss> <iss> perf/compat: use kahan summation in .rolling(..).sum() </iss> <iss> rolling mean on a time-based period with one data point does not return the exact mean </iss> <iss> bug: mean of zeros turn out to be non-zero </iss>",implement kahan summation for rolling().mean() to avoid numerical issues
902,"<desc> seperate rpccontext to servercontext, clientattachment, serverattachment and servicecontext. servicecontext: using to pass environment parameters in the whole invocation. for example, remotingapplicationname, remoteaddress, etc. {@link rpcservicecontext} clientattachment, serverattachment and servicecontext are using to transfer attachments. imaging a situation like this, a is calling b, and b will call c, after that, b wants to return some attachments back to a. clientattachment is using to pass attachments to next hop as a consumer. ( a --> b , in a side) serverattachment is using to fetch attachments from previous hop as a provider. ( a --> b , in b side) servercontext is using to return some attachments back to client as a provider. ( a <-- b , in b side) add penetrateattachmentselector spi if user not want attachments pass always. serverattachment will pass to next hop in default. if one or more penetrateattachmentselector spi has been configured, dubbo will only as those has been selected attachment. </desc> <cmt> separate rpccontext </cmt> <cmt> compatible with old version </cmt> <cmt> fix direct invoker not work </cmt> <cmt> fix get logic </cmt>",seperate rpccontext to client and server
903,"<desc> reversing a binary tree is an often asked interview question, and has become a meme in certain circles due to it's popularity. this implementation recursively reverses a binary tree. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines notes: this is my first real pr, i'd be happy to make any changes as needed. </desc> <cmt> create reverse_binary_tree.cpp </cmt> <cmt> added documentation </cmt> <cmt> added documentation for the level_order_traversal() function, and implemented a print() function to display the tree to stdout </cmt> <cmt> added documentation </cmt> <cmt> renamed tests to test </cmt> <cmt> fixed issue with incorrect using statement </cmt> <cmt> updating directory.md </cmt> <cmt> clang-format and clang-tidy fixes for fb86292d </cmt> <cmt> added test cases </cmt>",add reverse a binary tree implementation
904,<desc> this should be clean and ready to be merged. i have checked out tmp.sqlite from both repo and history (.sqlite files are now ignored by git) and refactored dbhandler class into the righteous dbhandler. let me know if anything else has to be addressed. </desc> <cmt> added initial protobuf definitions </cmt> <cmt> added protobuf methods; implemented initial db logic </cmt> <cmt> hooking the view to load from new db handler </cmt> <cmt> fixed a bug in protobuf loading -> no return </cmt> <cmt> new explicit parsing httpflow into proto native object. viceversa not yet implemented. </cmt> <cmt> fixed bugs in parsing httpflow objects </cmt> <cmt> improved parsing mechanism for better readability </cmt> <cmt> refactored naming strategy </cmt> <cmt> completed untested version of object loading </cmt> <cmt> loads yields now an http object </cmt> <cmt> new protobuf loads has almost the same result of flowreader stream </cmt> <cmt> bug fix </cmt> <cmt> more bug fixes in db class </cmt> <cmt> timestamps are now double instead of float </cmt> <cmt> view can load from both io interfaces </cmt> <cmt> updated exceptions in view load </cmt> <cmt> removed test code from view </cmt>,shifting to protobuf serialization - cleaned
905,"<desc> description: another in a series of prs to save statnames at construction time, for lock-free-in-hot-path creation of scoped stats at request-time. this one captures the rate-limiting related stats, which occur in two different filters. this pr also adds a formatting check to avoid direct calls to create counters, gauges, and histograms by name. because there are still some remaining offenders, a whitelist is added with comments/todos to remove from this list until they are gone. this is another step toward resolving #4196 and enabling submission of #4980. risk level: low testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> add symbol name interning </cmt> <cmt> get both ratelimit filters to intern their stat-names on startup. </cmt>",use counterfromstatname for ratelimit filters
906,"<desc> i loved the pixel shaders in #7058, but that pr needed a bit of polish to be ready for ingestion. this pr is almost exactly that pr, with some small changes. it adds a new pre-profile setting ""experimental.pixelshaderpath"", which lets the user set a pixel shader to use with the terminal. changed from #7058: it does not add any built-in shaders. changed from #7058: it will override experimental.retroterminaleffect it adds a bunch of sample shaders in samples/shaders. included: a nop shader as a base to build from. an ""invert"" shader that inverts the colors, as a simple example an ""grayscale"" shader that converts all colors to grayscale, as a simple example an ""raster bars"" shader that draws some colored bars on the screen with a drop shadow, as a more involved example the original retro terminal effects, as a more involved example it also includes a broken shader, as an example of what heppens when the shader fails to compile changed from #7058: it does not add the ""retroii"" shader we were all worried about. when a shader fails to be found or fails to compile, we'll display an error dialog to the user with a relevant error message. changed from #7058: originally, #7058 would display ""error bars"" on the screen. i've removed that, and had the terminal disable the shader entirely then. renames the toggleretroeffect action to toggleshadereffect. (toggleretroeffect is now an alias to toggleshadereffect). this action will turn the shader or the retro effects on/off. toggleshadereffect works the way you'd expect it to, but the mental math on how is a little weird. the logic is basically: useshader = shadereffectsenabled ? (pixelshaderprovided ? pixelshader : (retroeffectenabled ? retroeffect : null ) : null and toggleshadereffect toggles shadereffectsenabled. if you've got both a shader and retro enabled, toggleshadereffect will toggle between the shader on/off. if you've got a shader and retro disabled, toggleshadereffect will toggle between the shader on/off. references #6191 references #7058 closes #7013 closes #3930 ""add setting to retro terminal shader to control blur radius, color"" closes #3929 ""add setting to retro terminal shader to enable drawing scanlines"" - at this point, just roll your own version of the shader. </desc> <cmt> implemented support for user provided pixel shaders </cmt> <cmt> awesome things can be done with pixel shaders that can spice up </cmt> <cmt> the terminal such as retro looks, fractals, raytracers or star </cmt> <cmt> scroller backgrounds. </cmt> <cmt> this commit adds the capability for the user to create their </cmt> <cmt> own pixel shader effects. </cmt> <cmt> in addition a new retro effect has been added as built-in pixel </cmt> <cmt> shader: </cmt> <cmt> ""experimental.pixelshadereffect"": ""retroii"" </cmt> <cmt> the existing retro effect is possible to enable as well: </cmt> <cmt> ""experimental.pixelshadereffect"": ""retro"" </cmt> <cmt> in order to for a user to create their own pixel shader effects </cmt> <cmt> specify a path rather than a built-in effect: </cmt> <cmt> ""experimental.pixelshadereffect"" : ""c:\\temp\\retroiii.hlsl"" </cmt> <cmt> note: the escaping of paths is needed to construct a valid json string. </cmt> <cmt> error handling is changed so that if the shader fails to load for any </cmt> <cmt> reason the exception is logged normally and it defaults to an error </cmt> <cmt> shader showing the user a pattern that indicates that a pixel shader </cmt> <cmt> effect was attempted but didn't work out. </cmt> <cmt> example shaders are provided under: samples/pixelshaders/ </cmt> <cmt> a new command has been added: toggleterminaleffects </cmt> <cmt> this command turns on and off configured terminal effects, if no </cmt> <cmt> terminal effects are configured this command does nothing. </cmt> <cmt> the existing command: toggleretroeffect </cmt> <cmt> is changed to have the same semantices as the new command. this is a </cmt> <cmt> change in behaviour that was discussed with the maintainers. </cmt> <cmt> the retroii pixel shader relies on a ray-sphere intersection function </cmt> <cmt> developed by inigo quilez and released with the mit license. </cmt> <cmt> for an example of the ray-sphere function in action: </cmt> <cmt>  </cmt> <cmt> use a dialog to surface the error rather than a specific shader </cmt> <cmt> make the pixel shader higher prededence than the retro effect </cmt> <cmt> add the action back </cmt> <cmt> i can't believe that's all i missed from the review </cmt> <iss> add setting to retro terminal shader to enable drawing scanlines </iss> <iss> add setting to retro terminal shader to control blur radius, color </iss> <iss> feature request: allow background image to be pixel/fragment shader specified by me </iss>","implement user-specified pixel shaders, redux"
907,<desc> description: this library update contains better connection management and error responses checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> added error handling for sense api timeouts </cmt> <cmt> moved imports in function </cmt> <cmt> moved imports to more appropriate function </cmt> <cmt> change exception to custom package version </cmt> <cmt> updated sense_energy library to 0.4.2 </cmt>,upgrade sense library to 0.4.2
908,<desc> add detection for openbsd in configure script patch taken from downstream:  add detection for haiku in configure script patch taken from downstream:  use case statement for host os detection </desc> <cmt> add detection for openbsd in configure script </cmt> <cmt> patch taken from downstream: </cmt> <cmt>  </cmt> <cmt> add detection for haiku in configure script </cmt> <cmt> patch taken from downstream: </cmt> <cmt>  </cmt>,add detection for various os
909,"<desc> the feature has been stable for 3 releases, shouldn't still be marked provisional. </desc> <cmt> doc: change nep 18 status to final </cmt> <cmt> doc: remove ""provisional"" from neps overview if no neps have that status </cmt>",make nep 18 status final
910,<desc> currently it is unclear as to the fact that pcs is turned off when the dsu has been unplugged. this aims to address that by turning off the pcs switch in the car settings. must be used with commaai/opendbc#452 </desc> <cmt> display pcs off in car settings when dsu is unplugged </cmt> <cmt> update opendbc </cmt>,display pcs off when dsu is unplugged and no sdsu is found
911,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> allow undefined bind parameters </cmt> <cmt> upgrading oracledbto 4.1 </cmt> <cmt> update version number </cmt> <cmt> fix tsconfig typo </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> make dbobject generic </cmt> <cmt> increase min ts version to 3.5 </cmt>,@types/oracledb - make dbobject class generic
912,<desc> fix duplicate connection check by using node_id instead of p2p_address. new net_version dup_node_id_goaway created for this pr. issue introduced by: #10006 #10786 select one: select any that apply: </desc> <cmt> update last_handshake_recv before dup check </cmt> <cmt> updated dup check logging </cmt> <cmt> additional dup check logging </cmt> <cmt> use node_id instead of p2p_address </cmt> <cmt> clean up logging </cmt> <cmt> remove unneeded logging </cmt> <cmt> update comment </cmt> <cmt> add dup_node_id_goaway net_version </cmt>,use node_id for duplicate connection resolution - 2.2
913,"<desc> these changes match #1137 note : separate to my changes here, there are compilation errors in generated android projects due to an incorrect icon file. there are compilation errors in hellolua - i think due to the lua bindings not being updated correctly. since these issues are not related to my changes i am submitting them for merge. the above bugs need to be fixed separately. </desc> <cmt> quoted use of bash variables </cmt> <cmt> cleaner build scripts </cmt> <cmt> cleaner template for build_native.sh </cmt> <cmt> * used by projects generated with create-android-project.sh </cmt>",further clean up of android build scripts and template
914,"<desc> initial sister pr for #9825 (already merged) new sister pr #9921 adds how to start local testnet with consensus only file docs/01_nodeos/02_usage/03_development-environment/10_local-single-node-testnet-consensus.md was added, the rest of the changes are necessary to make room for it in the existing documentation. resolves #7180 </desc> <cmt> [docs] dev branch - add how to: local testnet with consensus </cmt> <cmt> update the link to bios boot sequence tutorial </cmt>",add how to local testnet with consensus
915,"<desc> this removes some of the easier instances of mutable fields where the explicit self can just become &mut self along with removing some unsafe blocks which aren't necessary any more now that purity is gone. most of #4568 is done, except for one case where it looks like it has to do with it being a const vector. removing the unsafe block yields: /users/alex/code/rust2/src/libcore/vec.rs:1755:12: 1755:16 error: illegal borrow unless pure: creating immutable alias to const vec content /users/alex/code/rust2/src/libcore/vec.rs:1755         for self.each |e| { ^~~~ /users/alex/code/rust2/src/libcore/vec.rs:1757:8: 1757:9 note: impure due to access to impure function /users/alex/code/rust2/src/libcore/vec.rs:1757         } ^ error: aborting due to previous error i also didn't delve too much into removing mutable fields with cell or transmute and friends. </desc> <cmt> removing some mutable fields in libstd </cmt> <cmt> removing no longer needed unsafe blocks </cmt>",removing some mutable fields and unsafe blocks
916,<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description the binary in the testbins repo makes r2 take forever to load and eventually run out of memory or crash. fixing this bug results in a null deref when deintializing the rbinobject. this pr fixes both bugs. the 3rd commit fixes a null deref when loading machos without segments test plan see radareorg/radare2-testbins#28 closing issues one from clusterfuzz </desc> <cmt> fix null deref in quit when loading corrupted machos ##bin </cmt> <cmt> fix dos on corrupted macho executable ##bin </cmt> <cmt> fix clusterfuzz-testcase-minimized-ia_fuzz-5704628234092544.uu </cmt>,macho dos (dont squash this pr)
917,"<desc> fixes: #1405 </desc> <cmt> [i1405] [view] allow move-top on filter change. </cmt> <cmt> bash </cmt> <cmt> rofi -show drun -inputchange-movetop true </cmt> <cmt>  </cmt> <cmt> or </cmt> <cmt> css </cmt> <cmt> configuration { </cmt> <cmt> inputchange { </cmt> <cmt> movetop: true; </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt>  </cmt> <cmt> issue: #1405 </cmt> <cmt> [i1405] use keyboard actions instead of one option. </cmt> <cmt> css </cmt> <cmt> inputchange { </cmt> <cmt> action: ""kb-row-first""; </cmt> <cmt> } </cmt> <cmt>  </cmt> <cmt> [i1405] remove some duplicate code. </cmt> <cmt> [i1405] add to manpage, cleanup code. </cmt> <iss> [request] move selection to best match when refining search </iss>",allow action to be taken on input change.
918,"<desc> before the patch, a value of 9.99 in a float column came out of mysqli as 9.9998998641968. this is because it would naively cast a 4-byte float into php's internal 8-byte double. to fix this, with gcc we use the built-in decimal support to ""up-convert"" the 4-byte float to a 8-byte double. when that is not available, we fall back to converting the float to a string and then converting the string to a double. this mimics what mysql does. </desc> <cmt> patch for bug #67839 (mysqli does not handle 4-byte floats correctly) </cmt> <cmt> before the patch, a value of 9.99 in a float column came out of mysqli </cmt> <cmt> as 9.9998998641968. this is because it would naively cast a 4-byte float </cmt> <cmt> into php's internal 8-byte double. </cmt> <cmt> to fix this, with gcc we use the built-in decimal support to ""up-convert"" </cmt> <cmt> the 4-byte float to a 8-byte double. </cmt> <cmt> when that is not available, we fall back to converting the float </cmt> <cmt> to a string and then converting the string to a double. this mimics </cmt> <cmt> what mysql does. </cmt> <cmt> fix failing tests </cmt>",fix for bug 67839 (mysqli does not handle 4-byte floats correctly)
919,"<desc> this adds (optional) support for using udev to the v4l2 plugin, which allows the source to detect when a device disconnects/reconnects so it can stop/restart the capture accordingly. this is currently optional and will be automatically build when udev/libudev is found, but can be disabled by setting disable_udev with cmake. </desc> <cmt> add cmake module for finding udev. </cmt> <cmt> this adds a cmake module to find udev/libudev for linux. </cmt> <cmt> add udev helper library to v4l2 plugin. </cmt> <cmt> this adds a small helper library to the v4l2 plugin that uses udev to </cmt> <cmt> get events for v4l2 devices. </cmt> <cmt> use udev events in the v4l2 plugin. </cmt> <cmt> this adds code to set up the udev monitoring library and use the events </cmt> <cmt> to detect connects/disconnects of devices. </cmt> <cmt> when the currently used device is disconnected the plugin will stop </cmt> <cmt> recording and clean up, so that the device node is freed up. </cmt> <cmt> on reconnection of the device the plugin will use the event to </cmt> <cmt> automatically start the capture again. </cmt> <cmt> fix left open file descriptor in v4l2 plugin. </cmt>",add udev support to v4l2 plugin.
920,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> added declarations for 'linq4js' </cmt> <cmt> fixed lint </cmt> <cmt> fixed version </cmt> <cmt> fixed tsconfig.json </cmt> <cmt> tsconfig.json fix 2 </cmt> <cmt> small changes in function definition </cmt> <cmt> updated typings to version 2.1.6 of linq4js </cmt>",updated linq4js typings to version 2.1.6 of linq4js
921,<desc> performance existing tests no nothing </desc> <cmt> extract snapshotoptimization into separate class </cmt> <cmt> dry code a little bit </cmt> <cmt> apply snapshot optimization for all snapshot entries </cmt> <cmt> only create shared snapshots for 3 or more shared entries </cmt> <cmt> add logging </cmt> <cmt> lazyset do not check for duplicate lazysets in addall </cmt> <cmt> avoid merging lazysets from factory results </cmt> <cmt> more snapshot statistics </cmt> <cmt> create a class for snapshot for faster access and smaller serialization </cmt> <cmt> store cache dependencies inside of snapshot to reduce cache size </cmt> <cmt> split cache into smaller parts </cmt> <cmt> fix unneeded store in progressplugin </cmt> <cmt> make original source in cachedsource lazy </cmt> <cmt> reduce number of small buffers in binarymiddleware </cmt> <cmt> improve compilerpath </cmt> <cmt> reset progress reporter outside of hooks </cmt> <cmt> update stats snpashots </cmt>,persistent caching performance improvements and logging for large builds
922,<desc> rename cypress-gatsby => gatsby-cypress to keep it in sync with other packages #branding create redirect for cypress-gatsby as somehow it's indexed by google make gatsby-cypress public follow up is to actually change relative imports into package imports </desc> <cmt> rename cypress-gatsby into gatsby-cypress </cmt> <cmt> make gatsby-cypress public </cmt> <cmt> add redirect to keep seo in tact </cmt>,make our cypress config public
923,"<desc> the code to make sure that type parameters are in scope for instantiation previously ignored type parameters created by @template.  now it correctly says that they are in scope. fixes #15177, which showed that functions returned from a generic function were not instantiated. turns out this was because the type parameters were not recognised as in scope, so the instantiation algorithm skipped them. </desc> <cmt> type params introduced by @template are in scope </cmt> <cmt> the test to make sure that type parameters are in scope for </cmt> <cmt> instantiation previously ignored type parameters created by @template. </cmt> <cmt> now it correctly says that they are in scope. </cmt> <cmt> returned generic function is instantiated correctly </cmt>",jsdoc @template in scope as type parameter
924,"<desc> fixes: #17727 </desc> <cmt> core: align path inotify mask table a bit </cmt> <cmt> core: log about all errors in path_spec_watch() </cmt> <cmt> so far we logged about most, but not all errors. adding log to all </cmt> <cmt> errors. </cmt> <cmt> core: optimize loop in path_spec_fd_event() </cmt> <cmt> let's avoid the whole loop if it can never match </cmt> <cmt> core: watch paths with symlinks in .path units </cmt> <cmt> when watching paths that contain symlinks in some element we so far </cmt> <cmt> always only watched the inode they are pointing to, not the symlink </cmt> <cmt> inode itself. let's fix that and always watch both. we do this by simply </cmt> <cmt> installing the inotify watch once with and once without in_dont_follow. </cmt> <cmt> for non-symlink inodes this just overrides the same watch twice (where </cmt> <cmt> the second one replaces the first), which is has no effect effectively. </cmt> <cmt> for symlinks it means we'll watch both source and destination. </cmt> <cmt> fixes: #17727 </cmt> <iss> .path units with pathchanged= should recognize atomic symlink replacement, but doesn't </iss>",teach .path units to notice events on paths with components that are symlinks
925,<desc> this is a quick and dirty pass to get ha working with launchd on os x. this allows users to install ha as a service to have it run in the background as well as start on boot. </desc> <cmt> launchd script for loading ha at boot and background on os x </cmt> <cmt> install/uninstall scripts for os x </cmt>,launchd script for starting at boot and backgrounding on os x
926,"<desc> add support for preparedstatement-like of passing values to a sql query. the query string will use question mark placeholders (?) for any values that will be passed in through a new params request parameter: post /_sql?format=txt { ""query"": ""select year(release_date) as year from library where page_count > ? and author = ? group by year having count(*) > ?"", ""params"": [300, ""frank herbert"", 0] } addresses #42916. </desc> <cmt> add support for rest preparedstatement-like query parameters </cmt>",add support for passing query parameters in rest api calls
927,"<desc> moved libtool options out of the makefile into configure, added some explanation on the libtool library version numbers, made sure -no-undefined is set only for win32. </desc> <cmt> fix trailing whitespace </cmt> <cmt> move extra libtool options into configure </cmt> <cmt> this should allow to keep the libtool options all in one place and at </cmt> <cmt> the same time define different options depending on the host. </cmt> <cmt> made sure that -no-undefined is set only on win32. although no side </cmt> <cmt> effects on linux and osx have been observed so far, it's probably better </cmt> <cmt> to play it safe; it does not seem to be needed/does not seem to matter on *nix, </cmt> <cmt> only required for win32. </cmt>",move libtool options to configure script in order to allow per system settings
928,"<desc> forgive the messy commits, i'm still very new with github. i'm submitting my keymaps for the planck, preonic, and atreus keyboards. of note, the atreus is based on the ""gerb"" layout, with dvorak as the main keymap. i've added in the persistent layers, similar to how the planck and preonic work. </desc> <cmt> adding my own keymaps to the following keyboards: </cmt> <cmt> planck, preonic, atreus, ergodox </cmt> <cmt> delete dvorak.png </cmt> <cmt> not reflective of my layout. </cmt> <cmt> delete readme.md </cmt> <cmt> file cleanup, removing file that doesn't apply to my layout. </cmt> <cmt> delete old_keymap.c </cmt> <cmt> file cleanup </cmt> <cmt> delete readme.md </cmt> <cmt> file clean up. </cmt> <cmt> delete readme.md </cmt> <cmt> file cleanup </cmt> <cmt> delete keymap.c </cmt> <cmt> file cleanup </cmt>",submitting my keymaps to the repository
929,"<desc> first commit fixes this (when searching issues with ""browse other issues with this challenge"" button): second commit fixes gist's title: link to an example gist. finally, third commit closes #4831. 1st is not related with 2nd and 3rd (logically), therefore three commits, i can squash last two, if you want. </desc> <cmt> fix issue search query </cmt> <cmt> remove a hash symbol from split method </cmt> <cmt> fix not working gist sharing </cmt>",fix gist sharing and some other issues
930,"<desc> this pr fixes #93961. explanation the uri class holds different information in the path property when the file was opened through a unc location. for this fix i used the property fspath instead of path in the ondidclickpreviewlink handler. for a local file the uri class holds: where as for a unc opened file the uri class holds: here is an excerpt from uri.ts: foo://example.com:8042/over/there?name=ferret#nose \_/   \______________/\_________/ \_________/ \__/ |           |            |            |        | scheme     authority       path        query   fragment |   _____________________|__ / \ /                        \ urn:example:animal:ferret:nose test the issue and the fix: to test this issue create two md files (see below this list). open the readme.md file with an unc path like ""\\server\sharedfolder\readme.md"". open the preview of the markdown file readme.md. in the preview window, click on the relative link to test.md link. the test.md file should open in the preview. without the fix, an error message is being shown. test files readme.md: here's a link: [relative link to test.md](test.md) test.md: this is the test markdown file </desc> <cmt> fix #93691 </cmt> <cmt> fix #93961 </cmt> <iss> markdown preview of relative links drops 'host' from path </iss>",fix to 'markdown preview of relative links drops 'host' from path'
931,<desc> this pr partially resolves issue #84513 of updating the standard library part. i haven't found any remaining doctest examples which are using iterators over e.g. &i32 instead of just i32 in the standard library. can anyone point me to them if there's remaining any? thanks! r? @m-ou-se </desc> <cmt> replace intoiter::new with intoiterator::into_iter in std </cmt> <cmt> update expressions where we can use array's intoiterator implementation </cmt>,update standard library for intoiterator implementation of arrays
932,"<desc> array, typedarray, map and set methods that are specced to return the this-object now return this instead of explicit type. added an overload for es6 string.normalize's that has form parameter as union of the allowed string literals. tests/cases/compiler/implementarrayinterface started failing until i updated it, since it is now an error to implement array methods with old callback that accepted t[]. breaking change? jake runtests passes. based on #7664. since @mhegazy asked for the change to the callbacks to accept this be reverted, and since master split es6.d.ts into multiple files, it was cleaner to just rebase the change onto master than do reverts and merges. to preserve the comments on the diff of that pr i decided to make a new pr. note that, as mentioned above, tests/cases/compiler/implementarrayinterface still requires changes to compile (since sort now returns this instead of t[]). i'm not sure i see the value of not taking the callback changes since it's still a breaking change for custom array<t> implementations. </desc> <cmt> {map, weakmap}.set and {set, weakset}.add return this. </cmt> <cmt> {array, typedarray}.{copywithin, fill, sort} return this. </cmt> <cmt> add string literal union type overload for string.normalize parameter. </cmt> <cmt> update tests and baselines. </cmt>",this-related changes + new string.normalize overload
933,"<desc> description as part of #4913 this pr adds details on storage costs taken from populus gotchas list. checklist code compiles correctly all tests are passing new tests have been created which fail without the change (if possible) readme / documentation was extended, if necessary changelog entry (if change is visible to the user) used meaningful commit messages </desc> <cmt> adding populus gotcha covering storage costs </cmt> <cmt> add mention of initialisation cost of storage </cmt>",add details to storage costs
934,"<desc> confirmed working with aravis-0.8 and my pixelink usb 3 vision protocol camera. aravis updated its api to make most function calls take in gobject data to write errors to (in addition to returning error codes); opencv doesn't use gobject, so we just don't pass a pointer to a gobject. additionally, i removed a deprecated function call. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to related work </desc> <cmt> updated aravis backend to support aravis-0.8 </cmt> <cmt> bugfix for aravis-0.8 support </cmt>",updated to modern version of aravis usb 3 vision protocol library
935,"<desc> it was not easy to make cmakes work. brew can help with 3rd party libraries. you can test this by executing ""cocos new..."" and opening project in clion. brew tap homebrew/versions brew install glfw3 freetype chipmunk protobuf webp please notice that default demo ""helloworldscene"" searches resources within project executable dir. but resources are copied into ""resources"" directory. p.s. ios not tested due to certificates problem. but on mac everything works. </desc> <cmt> update cmakelists.txt </cmt> <cmt> added ios/mac </cmt> <cmt> cmake fix for template projects </cmt> <cmt> revert default settings </cmt> <cmt> small fix </cmt> <cmt> small comment fix </cmt>",cmakes support for mac os x & ios
936,"<desc> add hyundai elantra hybrid 2021 car support major issues left to resolve car harness (hyundai a) is incompatible, but some sanding with a dremel would make it work: requires hyundai ""a2"" keying, which isn't available in the comma shop yet minor issues left to resolve - remote start sometimes causes c2 to not recognize the car (reboot resolves the issue) test route added to test_routes.py </desc> <cmt> add support for hyundai elantra hev 2021 </cmt> <cmt> add car to readme. adjust tuning params. </cmt> <cmt> adjust weight </cmt>",2021 hyundai elantra hybrid port
937,"<desc> this pr refers to pr #3023 but with the base branch changed to develop. it addresses issue #2679 and also includes the fix of pr #2980 looked into the french model and analysed where most time was lost rewrote the compilation of _infixes_exc to avoid compilation of redundant patterns (from 270k to 100k) added new regular expressions to catch common tokens removed all redundant cases from the exception list, cutting it down from 34k lines to 16k added a few additional unit tests results loading the fr_core_news_sm model on my system goes down on average from 12-13s to 8-9s compared to 1s for en_core_web_sm loading french() (incl import) on my system goes down on average from 5.0-5.2s to 3.1-3.3s compared to 0.09-0.1s for english() speed enhancement i have submitted the spacy contributor agreement. </desc> <cmt> merge changes of pr 3023 into develop branch instead of master </cmt> <cmt> further deletions from exception list according to pr 3023 </cmt>",french regular expressions instead of extensive exceptions list (on develop)
938,"<desc> this pr improves inference to union and intersection types containing multiple naked type variables. previously we would make no inferences to such union and intersection types (for unrelated historical reasons that no longer apply). we now make the the proper inferences: declare function f1<t, u>(x: t | u): t | u; declare function f2<t, u>(x: t & u): t & u; let x1: string = f1('a'); let x2: string = f2('a'); previously both assignments were errors because we'd infer {} for t and u. fixes #29815. </desc> <cmt> make inferences to union types containing multiple naked type variables </cmt> <cmt> accept new baselines </cmt> <cmt> update test </cmt> <cmt> accept new baselines </cmt> <cmt> add regression tests </cmt> <cmt> accept new baselines </cmt>",improve inference to union and intersection types
939,<desc> addresses #20308 fixes numpydoc errors on rfecv functions. #dataumbrella sprint cc. @jaglima </desc> <cmt> starting doc review rfecv regressor </cmt> <cmt> added final comma in invese_transformation at _base.py </cmt> <cmt> added final comma in selectormixin summary at _base.py </cmt> <cmt> added returns section in _rfe.py </cmt> <cmt> added returns section in _rfe .py </cmt> <cmt> fixed sessions order on __init__ function in _rfe .py </cmt> <cmt> added docstring to property .classes_ in  _rfe .py </cmt>,doc ensures that rfecv passes numpydoc validation
940,"<desc> sometimes it's useful to skip publishing one or more packages. in the past, we've done this by temporarily editing the local package.json to mark it as a ""private"" package, but this is kind of janky. the release script should support this since it can add some additional automated checks to make sure we don't publish something invalid. release flow step 1: prepare canary in this case, we still prepare all of the packages. (this greatly simplifies the following script steps.) for the packages we plan to ""skip"" as part of publishing, we just confirm the already published version numbers. step 2: publish filtered set of packages when it is time to publish, we can specify one or more packages as ""skipped"". the updated script will confirm that we really want to skip them, and ensure that doing so wouldn't leave us in an invalid state (depending on something that hasn't already been released). note that this is still an advanced technique and something that should be done carefully and with consideration. error handling guard against typos guard against publishing a dependency on an unpublished version </desc> <cmt> updated build estimate time </cmt> <cmt> initial pass at adding skippackages filter </cmt> <cmt> cleaned up publish checks; removed skip filter from prepare </cmt> <cmt> improved prepare stable with skippackages param </cmt>",release script supports publishing a subset of packages
941,"<desc> import taichi as ti x = ti.vector.field(2, float, (32, 32)) @ti.kernel def render(): for i in ti.grouped(x): x[i] = (i - 16) / 16 gui = ti.gui() while gui.running: render() gui.arrow_field(x.to_numpy() / 16, color=0x66ccff) gui.show() import taichi as ti x = ti.field(float, (32, 32)) @ti.kernel def render(): for i in ti.grouped(x): x[i] = ((i - 16).norm() - 8) / 8 gui = ti.gui() while gui.running: render() _ = x.to_numpy() * 4 gui.point_field(_, color=0xffcc66) gui.point_field(-_, color=0xcc66ff) gui.show() </desc> <cmt> tmp </cmt> <cmt> clear </cmt>",support gui.arrow_field() and gui.point_field() for small resolution vector / scalar field visualization
942,"<desc> this adds a wait before the unregister_code16 in tap dances, so that it respects the tap code delay for media key compatibility. also, this moves the tap code delay defines to action.h, so that they're picked up most everywhere, rather than just in action.c, in case they're not actually defined. fixes #5262  and  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add  support to tap dances </cmt> <cmt> move default tap code defines to header file </cmt> <iss> media keys don't work in action_tap_dance_double on preonic/rev3 </iss>",apply tap_code_delay to tap dance key sequences
943,"<desc> related issue: -- adds a ""flat colors"" option to the ldrawloader example to better match the rendering style used in official lego instruction manuals. live demo:  default flat colors instruction manual comparing to the instruction manuals again it definitely looks like the instruction manual rendering is a bit more stylized with subtle lighting and uses an orthographic camera but i think the flat materials suit the instruction book look more closely. it seems this is also how at least one of the ldraw editor tools, leocad, renders the models. </desc> <cmt> add support for flat colors to ldraw demo </cmt> <cmt> comment </cmt> <cmt> improve colore representation </cmt>",demonstrate loading flat colors to match instruction booklet style
944,"<desc> project: emberjs_require. fixed the failed testcases on views. here we should check the function ""compile"" but the result of compile. now wrapped a function to fix it. </desc> <cmt> fixed the failure testcases. wrap the template compile with a function. </cmt>",fixed the failed testcases on views in project emberjs_require.
945,"<desc> this pr: objects contained in object layers generated by tiled use orthogonal positioning even when the map is isometric. in the pictures below, note that a has {x:128, y:128} and b has {x:256, y:128} - the y is the same, as one would expect in an orthogonal grid (but not in an isometric one). the current way to position sprites on createfromobjects uses that position provided by tiled and applies an origin offset over it - leading to issues as described here. this pr converts the sprites' position from cartesian to isometric before applying the offset, positioning elements over the grid as expected. </desc> <cmt> change positioning for isometric object layer from tiled </cmt> <cmt> revert ""update copy-to-examples.js"" </cmt> <cmt> this reverts commit d844f48e870e9b9c95104aa164fa4c2826252442. </cmt> <cmt> revert ""revert ""update copy-to-examples.js"""" </cmt> <cmt> this reverts commit 0bec01304791dbf6a0ae4a32391b5317a4fff138. </cmt> <cmt> revert ""change positioning for isometric object layer from tiled"" </cmt> <cmt> this reverts commit 33f242a2e08de52eb462268e84a3f8afa2d3406a. </cmt> <cmt> change positioning for isometric object layer from tiled </cmt> <cmt> linting </cmt>",fix rendering of tiled object layers on isometric maps
946,<desc> this is a quick fix that will make it a little easier for potential contributors who are new to github to learn how the site works. </desc> <cmt> updating my fork with the original </cmt> <cmt> linked how to make a pull requests in readme </cmt> <cmt> this makes it easier for users new to github to learn how to make a pull request. </cmt>,linked a github tutorial regarding pull requests in readme
947,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> types for overload-protection </cmt> <cmt> prettier formatting </cmt>","new types for package ""overload-protection"""
948,"<desc> this avoids having them on the right-hand-side in deps_info, which means that in reverse_deps=all mode we do not include that function and all the gl code it calls. instead, the callers are just more c functions that the linker does the right thing. </desc> <cmt> move emscripten_getprocaddress calls into c </cmt> <cmt> fix </cmt> <cmt> undo </cmt> <cmt> revert </cmt>",move emscripten_getprocaddress callers into c
949,"<desc> description: fixes the inclusion of secrets.yml when using the ""include_dir_named"" directive. related issue (if applicable): fixes #22926 pull request in home-assistant.io with documentation (if applicable):  n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to requirements in the manifest ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> ignore secrets.yaml in include_dir_named include </cmt> <cmt> updating test for include_dir_named secrets ignore </cmt> <iss> include_dir_named does not ignore secrets.yaml files </iss>",ignore secrets.yaml when using include_dir_named
950,"<desc> currently when the serverfactorycontext is passed to bootstrap extensions, it is only partially initialized. specifically, attempting to access the cluster manager will cause a nullptr access (and hence a crash) this pr splits the creation and initialized to 2 seperate fucntions. early creation is required to not break the default_socket_interface feature. once created, the extension will receive the serverfactorycontext in a different callback (the newly added serverinitialized), once they are fully initialized. fix a crash that happens when bootstrap extensions perform http calls. risk level: low (small bug-fix) testing: unit tests updated; tested manually with the changes as well. docs changes: n/a release notes: n/a fixes #14420 </desc> <cmt> initial fix </cmt> <cmt> unit test; format fix </cmt> <cmt> fix comments </cmt> <iss> npe when wasm bootstrap extension makes http calls. </iss>",fix a crash on http callout
951,"<desc> i think i'm doing this right now. adding my custom handwire to the qmk docs for the configurator 5x17 ortholinear qwerty split with a macro/num pad in the middle file added: /keyboards/handwired/bigmac my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> adding bigmac handwired by taylore101 </cmt> <cmt> adding bigmac handwired by taylore101 </cmt>","adding ""bigmac"" 5x17 handwired by taylore101"
952,"<desc> x11 do not support transparent images itself. so the clip mask was calculated in this code. x11 clipmask support only bit transparency. another negative side is a bad performace on big transparent images. but it work fast with opaque images. original opengl render: xlib without transparency: and final xlib variant with bit transparency: it's not good enough to use in games, semi-transparent images. but pretty good for ui icons, i think. </desc> <cmt> fix panel clipping </cmt> <cmt> layout->bounds cannot be used (loc 16615) since we modify it up here: </cmt> <cmt> layout->bounds.x += panel_padding.x;  (16471) </cmt> <cmt> layout->bounds.w -= 2*panel_padding.x; (16472) </cmt> <cmt> because of it there was no ability to nk_draw_image attached to window's edge. there alway was empty lines of right and left. </cmt> <cmt> this code breaks the other's code. popups, for example. my paddings are 10px. to show popup at (20,20) without this patch i must use nk_rect(10, 20, .... with this patch i must use nk_rect(20, 20, ..., not depending on paddings. i think (20,20) is a correct constant for (20,20) coordinate. </cmt> <cmt> return global clipping back </cmt> <cmt> stb_image with bit transparency </cmt> <cmt> x11 do not support transparent images itself. so the clip mask is calculating in this code. x11 clipmask support only bit transparency. </cmt> <cmt> fix stb_image path </cmt>",stb_image support with bit transparency
953,"<desc> in the react types, the definition of react.component is react.component<p = {}, s = {}, ss = never>, meaning that type-wise, props defaults to {}, state defaults to {}, and snapshot defaults to never.  snapshot is used as the return value of the new react getsnapshotbeforeupdate lifecycle method, whose return type is ss | null. what that means, however, is that unless the third generic type parameter is overridden, the return value of getsnapshotbeforeupdate is resolved to never | null, which is resolved to null.  this causes an issue where any components that do define getsnapshotbeforeupdate are unable to be used by something expecting a react.component, because getsnapshotbeforeupdate returns something other than null. this pr changes the default to be ss = any, which allows other libraries to do things like the following: const func = (comp: react.component<any>) => {...} there are many third-party libraries that do something similar, which i believe necessitates this change.  additionally, at the moment it is not possible to even use a component that uses the new lifecycle method as it is not considered to be a valid jsx component type (for the same reason, see #24820). i have added several test cases to catch actually using components that contain getsnapshotbeforeupdate, using them with react.createelement, and using the new lifecycle method on purecomponent, which previously did not accept the ss type param. fixes #24820.  see #24820 for more context.  replaces #24985. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add getsnapshotbeforeupdate test for react.createelement </cmt> <cmt> add test for using component with new lifecycles </cmt> <cmt> add test for pure component with new lifecycle methods </cmt> <iss> react: unable to use getsnapshotbeforeupdate </iss>",change default type value of snapshot to any
954,<desc> related issue (if applicable): fixes #11047 wiegand 26/34 missed some key press if they are press at normal speed note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> fix #11047 wiegand 26/34 missed some key press </cmt> <iss> wiegand 26/34 missed some key press if they are press at normal speed </iss>,fix #11047wiegand 26/34 missed some key press if they are press at normal speed
955,"<desc> there are multiple failing tests during ci only happened for hbase2. the potential reason might be some race conditions while running the ci on azure. this pr adds some additional checks and explicitly method calls to make sure the result has been fetched before doing the assertions. local checks haven been done multiple times and none failing test happened. add check of row count after insert use miniclusterwithclientresource as a classrule this change is a trivial rework / test case improvement. the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) </desc> <cmt> [flink-24077][hbase/it] add check of row count after insert and wait explicitly for job to finish. </cmt> <cmt> (cherry picked from commit 7976be0f8675a8753a5bb7e7a44dda6b4a347247) </cmt> <cmt> [flink-24077][hbase/it] use miniclusterwithclientresource as @classrule. </cmt> <cmt> while using tableenvironment in the itcase, a flink minicluster will be started/stopped automatically in the background. since the shutdown of the minicluster will be called asynchronously, collectresultfetcher will get data lost sometimes based on race conditions and the unchecked runtimeexception java.lang.illegalstateexception will be thrown that we were not aware of. </cmt> <cmt> the solution is to control the lifecycle of the minicluster manually in this test. the miniclusterwithclientresource could be a good fit in this case. </cmt> <cmt> (cherry picked from commit fca04c3aaf6346d61cf9fe022a7ac77ab4d66c91) </cmt>",fix flaky tests backport to 1.14
956,"<desc> (plus minor heading/prose tweak). see  reason for removing the <span> (rather than removing the aria-label) is that we seem to be favoring the latter in other parts of the docs. / </desc> <cmt> remove redundant .sr-only text for close buttons </cmt> <cmt> since aria-label is used, it's not necessary anymore. </cmt> <cmt> add ""keyboard users"" to heading for sr-only-focusable </cmt>","remove redundant <span class=""sr-only"">...</span> for close buttons"
957,"<desc> this pr contains updates required to make tf r2.1 work with newer rocm versions (r2.1 branch currently supports rocm 3.7) this pr has two commits right now, but that is expected to grow by the time we get around to merging this pr.  please see individual commit messages for details on the changes being made @mihaimaruseac as with the prior prs, it is understood that this pr will be merged along with the next patch to r2.1, whenever that happens to be. / </desc> <cmt> updating rocm_configure.bzl to pull in llvm 12.0 headers (for rocm 3.9) </cmt> <cmt> fix for tf build failure with rocm 3.9 (error: call to 'min' is ambiguous) </cmt> <cmt> when building tf with rocm 3.9, we are running into the following compile error </cmt> <cmt>  </cmt> <cmt> in file included from tensorflow/core/kernels/reduction_ops_half_mean_sum.cu.cc:20: </cmt> <cmt> ./tensorflow/core/kernels/reduction_gpu_kernels.cu.h:430:9: error: call to 'min' is ambiguous </cmt> <cmt> min(blockdim.y, num_rows - blockidx.y * blockdim.y); </cmt> <cmt> ^~~ </cmt> <cmt> /opt/rocm-3.9.0-3805/llvm/lib/clang/12.0.0/include/__clang_hip_math.h:1183:23: note: candidate function </cmt> <cmt> __device__ inline int min(int __arg1, int __arg2) { </cmt> <cmt> ^ </cmt> <cmt> /opt/rocm-3.9.0-3805/llvm/lib/clang/12.0.0/include/__clang_hip_math.h:1197:14: note: candidate function </cmt> <cmt> inline float min(float __x, float __y) { return fminf(__x, __y); } </cmt> <cmt> ^ </cmt> <cmt> /opt/rocm-3.9.0-3805/llvm/lib/clang/12.0.0/include/__clang_hip_math.h:1200:15: note: candidate function </cmt> <cmt> inline double min(double __x, double __y) { return fmin(__x, __y); } </cmt> <cmt> ^ </cmt> <cmt> 1 error generated when compiling for gfx803. </cmt> <cmt>  </cmt> <cmt> the build error seems to be because rocm 3.9 uses llvm header files from llvm/lib/clang/12.0.0/include (rocm 3.8 uses the 11.0.0 version). 12.0.0 has a new __clang_hip_math.h file, which is not present in 11.0.0. this file has the min function overloaded for the float and double types. </cmt> <cmt> the first argument in the call to min (which leads to the error) is blockdim.y which has a uint type, and hence the compiler gets confused as to which overloaded type to resole to. previously (i.e. rocm 3.8 and before) there was only one option (int), with rocm 3.9 there are three (int, float, and double) and hence the error. </cmt> <cmt> the ""fix"" is to explicitly cast the first argument to int to remove the ambiguity (the second argument is already an int type). </cmt>",porting changes to support newer rocm versions to r2.1
958,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. </desc> <cmt> merge remote-tracking branch 'refs/remotes/definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'remotes/definitelytyped/master' </cmt> <cmt> corrected missing return types to prevent noimplicitany errors. </cmt>,corrected missing return types to fix noimplicitany errors.
959,"<desc> used stringbuilder for the variable password instead of string as it was being modified with every iteration. i have read contributing.md. this pr only changes one algorithm file.  to ease review, please open separate prs for separate algorithms. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> update readme.md </cmt> <cmt> update passwordgen.java </cmt>",string to stringbuilder in others/passwordgen.java
960,<desc> description: filter properties of interfaces that do not support properties_proactively_reported from being included in the changereports. this pr also properly sets properties_proactively_reported to true on a few interfaces that were inadvertently benefiting from the bug. related issue (if applicable): fixes #30603 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: </desc> <cmt> fix change report properties. </cmt> <cmt> fix change report properties. </cmt> <iss> alexa chagereports are including non-proactivelyreported interface properties in reports </iss>,fix alexa changereports filter non-proactively_reported_properties
961,"<desc> i spent some time optimizing the frame rate at which i am able to obtain images through the api, by just requesting images in a loop in python. unsurprisingly, it turned out that when getting uncompressed images the frame rate is higher than getting compressed images. also unsurprisingly, it turned out that the frame rate is higher when not rendering the actual main viewport that is displayed on the screen, which can be disabled by running the command show rendering in the unreal console. so, this pr adds a setting that allows to disable the rendering of the main viewport in the same way, for cases where it is not needed and instead a high frame rate of images to be obtained through the api is desirable. in that case it also makes sure that the graphics pipeline is flushed after every frame has been drawn, because otherwise the api image request only gets scheduled to execute only after every other frame has actually been rendered. this effectively doubles the frame rate. to test these tweaks i set up a particular scene in the neighbourhood environment at which i was getting about 18 fps when rendered onscreen. when running my python loop to get images through the api, images were coming in at about 3 fps, then with main viewport rendering disabled around 7 fps and with the pipeline flush tweak about 12 fps. given that the on-screen framerate i observed was 18 fps there might be more improvements possible, but this seems like a good start and fairly low-hanging fruit. i also realized that the loop that copies the image into the results after it was captured took about 10ms on my machine for a 512x512 image. i have optimized this so that it takes less than 1ms, but did this did not improve the total frame rate, probably because the gpu was already busy rendering the next frame at this point. i still thought it's a worthwhile contribution, though. would it make more sense to use a new viewmode enumerat instead of a boolean ""mainviewportvisible"" setting for this? although the view mode already has a ""nodisplay"" setting that seems to do something different, so it might be confusing. </desc> <cmt> add a setting to disable main viewport rendering </cmt> <cmt> this frees up cycles to render the subwindows or serve images </cmt> <cmt> through the api. </cmt> <cmt> flush render queue after draw if main viewport is not visible </cmt> <cmt> this allows the api to capture every single frame. otherwise, after an api </cmt> <cmt> image request is received, it would wait until after both the current frame and </cmt> <cmt> the subsequent frames are finished rendering, effectively only capturing </cmt> <cmt> every other frame when an api user captures pictures in a loop. when flushing </cmt> <cmt> the render queue after the viewport has been drawn, the render request is executed </cmt> <cmt> once the current frame is available. </cmt> <cmt> only enable this behavior when main viewport drawing is disabled. this makes </cmt> <cmt> sure we don't adversely affect main viewport drawing performance by adding more </cmt> <cmt> otherwise unneeded synchronization. </cmt> <cmt> optimize image copying loop after capturing an image </cmt> <cmt> this improves the runtime of this loop from about 10ms to less than 1ms </cmt> <cmt> on my computer. </cmt> <cmt> when repeatedly obtaining images through the api in a loop, this image </cmt> <cmt> copying does not seem to be in the critical path (probably because the gpu </cmt> <cmt> already starts rendering the next frame while the copy is going on), but </cmt> <cmt> it seems to be some low-hanging fruit nonetheless. </cmt>",add setting to disable rendering of main viewport
962,<desc> this pull-request adds overflow checking on enum values that are being returned from an interface function. this solves a bullet point in #1344 (comment) </desc> <cmt> test: add tests about returning invalid enum values from interface functions </cmt> <cmt> codegen: overflow checking also during conversion from enums </cmt>,invalid enum as external ret
963,"<desc> what did you implement: added support for specifying the aws api gateway log level to be used. i also updated the sample aws serverless.yml.md file to include the log format option as that was missing when that feature was added. this is an enhancement to api gateway logs as part of #6094. how did you implement it: users can now customize the log level by setting the provider.logs.restapi.level optional setting in serverless.yml to either info (default value) or error: provider: name: aws logs: restapi: level: error an error will be thrown if something other than info or error is provided. i updated updatestage.js to use the user-provided log level if available, otherwise it falls back to the default info as before. how can we verify it: create a serverless project and set provider.logs.restapi.level to either info or error and run a deploy. set to something to cause an invalid value error. todos: write tests and confirm existing functionality is not broken. write documentation ensure there are no lint errors. ensure introduced changes match prettier formatting. make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> added log.level setting to customize aws api gateway log level </cmt> <cmt> updated aws serverless.yml reference to include logs.level and format documentation </cmt> <cmt> updated formatting </cmt>",aws api gateway customize log level
964,"<desc> the purpose of this pr is to partially implement chrome.* api to make the react devtools extension work. close #915. close #2598. </desc> <cmt> gethostforpath => generatehostforpath </cmt> <cmt> the original name implies no side effect, but is is not true. </cmt> <cmt> cleanup chrome-extension.js after the coffe2es transfer </cmt> <cmt> store the original manifest file </cmt> <cmt> add simple support for background page </cmt> <cmt> make sure chrome.devtools.inspectedwindow.tabid is set </cmt>",implement partial chrome.* api for devtools extension
965,<desc> original pr: this pr caused this bug. fix: deprecate old isintegraltype and add overload which takes a boolean flag which tells if torch.bool should be included in integral types or not. testing: added extra test cases tested via running unit tests locally. </desc> <cmt> fixed bool in isintegraltype bug </cmt> <cmt> added deprecation message </cmt> <cmt> resolved pr comments </cmt> <cmt> update for review comments. </cmt> <cmt> get rid of tab. </cmt>,fixed bool in isintegraltype bug (plus review comments)
966,<desc> add mmkv support for python on posix platforms </desc> <cmt> dont check process mode on open() failure </cmt> <cmt> make exception more clear about checking multi_process_mode </cmt> <cmt> tidy exception msg </cmt> <cmt> prepare for python bind on posix platform </cmt> <cmt> python bind on posix platform almost done </cmt> <cmt> add python test </cmt> <cmt> add unit test for python </cmt> <cmt> tidy </cmt> <cmt> dry </cmt> <cmt> add unit test for the same mmapid </cmt> <cmt> add callback handler for python </cmt> <cmt> tidy </cmt> <cmt> add example for multi-process instance </cmt> <cmt> add python install & support python 2.x </cmt> <cmt> ad license for pybind11 </cmt> <cmt> support root on linux </cmt>,mmkv for python (on posix)
967,"<desc> closes #6407 closes #19001 cypress will throw an error when a user attempts to set these 'non-writable' config values using cypress.config. the following were identified as properties that could be updated during test time: animationdistancethreshold baseurl blockhosts defaultcommandtimeout env exectimeout experimentalsessionsupport includeshadowdom keystrokedelay numtestskeptinmemory pageloadtimeout redirectionlimit requesttimeout responsetimeout retries screenshotonrunfailure scrollbehavior slowtestthreshold tasktimeout viewportheight viewportwidth waitforanimations the following were identified as read-only properties for per test config: autoopen (internal) browsers chromewebsecurity clientcertificates clientroute (internal) component componentfolder configfile (internal) devserverpublicpathroute (internal) downloadsfolder e2e exit experimentalfetchpolyfill experimentalinteractiverunevents experimentalsourcerewriting experimentalstudio fileserverfolder fixturesfolder hosts ignoretestfiles integrationfolder isinteractive istextterminal modifyobstructivecode morgan (internal) namespace (internal) nodeversion pluginsfile port projectid reporter reporteroptions reporterroute (internal) resolvednodepath resolvednodeversion socketid (internal) socketiocookie (internal) socketioroute (internal) supportfile testfiles trashassetsbeforeruns useragent video videocompression videouploadonpasses videosfolder watchforfilechanges xhrroute (internal) trying to set read-only config in test configuration: trying to set read-only config within test with cypress.config(): have tests been added/updated? (added config package unit tests, need to add integration test still) has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? cypress-io/cypress-documentation#4252 have api changes been updated in the type definitions? </desc> <cmt> add readonly prop </cmt> <cmt> remove read only </cmt> <cmt> verify config options </cmt> <cmt> format </cmt> <cmt> fix verify merge conflicts </cmt> <iss> warn when writing to 'read only' properties of `config` </iss> <iss> typescript for runtime properties still missing? </iss>",throw when writing to 'read only' properties of config
968,"<desc> relay block on pre_accepted_block signal for trusted producer or light validation. </desc> <cmt> relay block as soon as block header is validated for light validation and trusted producer </cmt> <cmt> add new light_validation_mode method since skip_auth_check requires pending </cmt> <cmt> revert ""add new light_validation_mode method since skip_auth_check requires pending"" </cmt> <cmt> this reverts commit 7ad5cbd3844eba02035621155bb862f2a6979e49. </cmt> <cmt> add is_trusted_producer method </cmt> <cmt> use is_trusted_producer for if on_pre_accepted_block should bcast block. always broadcast block on accepted block. </cmt>",relay block on accepted header - 1.8
969,"<desc> have you signed the contributor license agreement? have you followed the contributor guidelines? if submitting code, have you built your formula locally prior to submission with gradle check? if submitting code, have you checked that your submission is for an os that we support? if you are submitting this code for a class then read our policy for that. </desc> <cmt> added new coldfusion open source libraries </cmt> <cmt> added new coldfusion open source libraries </cmt> <cmt> update index.asciidoc </cmt>",addition of new native coldfusion (cfml) library.
970,"<desc> down-leveling a namespace to es involved an optimization within individual files to avoid emitting multiple var declarations by grabbing the namespace's symbol's name and checking whether a prior symbol with a given name already had a var declaration emitted. however, the check was not conservative enough to account for synthetic nodes that don't have symbols. with this pr, we unconditionally emit the var declaration for namespaces that have no symbols. with this pr, we just use local identifiers to keep track of declarations in the current scope. fixes #17596. </desc> <cmt> added failing test for a before-transform that indirectly replaces a namespace declaration. </cmt> <cmt> accepted baselines. </cmt> <cmt> made the first-declaration check conservative in the typescript transform. </cmt> <cmt> accepted baselines. </cmt>",fix emit for leading 'var' declarations for synthesized namespaces
971,<desc> description: added support for device tracking for the bt smart hub router (uk). might it be sensible to collect this with the bt_home_hub_5 component in some way - perhaps to share a page on home-assistant.io ? pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#6528 example entry for configuration.yaml (if applicable): # example configuration.yaml entry device_tracker: - platform: bt_smarthub host: 192.168.1.254 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> support for bt smarthub router device tracking </cmt> <cmt> update requirements_all.txt for bt_smarthub device tracker </cmt> <cmt> added bt_smarthub.py exclusion </cmt> <cmt> update .coveragerc </cmt>,add device tracking for the bt smart hub router
972,"<desc> fixes #19497. fixes #16147. this fix implement solution discussed in #16147: inlier_mask_subset = residuals_subset <= residual_threshold that replace the current < this make the code work also with perfect horizontal lines (see #19497). basically i suggest to change the definition of what is an inlier respectivly to residual_threshold. exactly on the threshold, i suggest to say it is an inlier and not an outliner. this make a couple of ""normal cases"" work: horizontal line #19497 (currently we say all the point on a line are outlier!) and other examples described in #16147 unfortunately this patch make a test fail, but we can keep it with the following modification. the test construct an example where there is no inlier. it is based on the fact when residual_threshold =0 an exception is always thrown. to do this in a clean way we should construct here a real example where there is no inlier. such an example is not easy to find. i suggest to construct a more simple test as before : set the residual_threshold to an other corner value that make always the comparison fail : a nan i also implement the test described in #19497 (horizontal lines) </desc> <cmt> bugfix ransac - residual threshold calculation #16147 </cmt> <cmt> ransac test </cmt> <cmt> add new test for horizontal line </cmt> <cmt> adapt no inliner test with a synonym </cmt> <iss> ransac - residual threshold calculation </iss> <iss> ransac - perfect horizontal line generate an exception </iss>",fix adjust inliner criterion in ransacregressor
973,"<desc> fixes #3196 i ran some tests with a simulated super-high-latency/low-bandwidth connection, and didn't run into any issues. </desc> <cmt> decrease tornado websocket_ping_interval to 1s </cmt> <cmt> add some more detailed comments </cmt> <iss> change websocket ping time to 1s to improve connection resilience? </iss>",decrease tornado websocket ping_interval to 1s
974,<desc> there are still few regular enums lurking around in services layer like tokenclass or matchkind - existing code uses reverse mapping. since these enums are small - we can keep them. diff in size between lkg (compiler that support const enums) and bootstrapped compiler (with const enums inlined) - ~46 kb </desc> <cmt> update lkg </cmt> <cmt> use const enums in compiler </cmt>,convert majority of enums in compiler to const enums
975,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: koa-ratelimit/index.js include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> updates koa-ratelimit arg types </cmt> <cmt> options object now includes types for whitelist and blacklist options. </cmt> <cmt> updates tests for koa-ratelimit </cmt> <cmt> tests for whitelist and blacklist options. </cmt>",adds optional arguments blacklist and whitelist to koa-ratelimit type definitions
976,"<desc> responding to r_investcantreadgood on the #help channel of qmk discord. kbd19x qmk port had the space+b disabled due to bootmagic being set to no. fixes implemented: bootmagic set to lite use pragma once in kbd19x h file found a compile issue when compiling default keymap. realized led functions were not properly externed in the .c file. lots of space left, might as well turn on mousekeys. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> set bootmagic from no to lite and put in a note in the readme </cmt> <cmt> use pragma once </cmt> <cmt> discovered a compile error when testing with default keymap. the inlined led functions need to be externed in the .c file </cmt> <cmt> might as well turn on mouse keys as well </cmt>",kbd19x bootmagic enable (lite) and other fixes
977,"<desc> this optimizes the is_ascii function for [u8] and str. i've been surprised this wasn't done for a while, so i just did it. benchmarks comparing before/after look like: test ascii::long_readonly::is_ascii_slice_iter_all              ... bench:         174 ns/iter (+/- 79) = 40172 mb/s test ascii::long_readonly::is_ascii_slice_libcore               ... bench:          16 ns/iter (+/- 5) = 436875 mb/s test ascii::medium_readonly::is_ascii_slice_iter_all            ... bench:          12 ns/iter (+/- 3) = 2666 mb/s test ascii::medium_readonly::is_ascii_slice_libcore             ... bench:           2 ns/iter (+/- 0) = 16000 mb/s test ascii::short_readonly::is_ascii_slice_iter_all             ... bench:           3 ns/iter (+/- 0) = 2333 mb/s test ascii::short_readonly::is_ascii_slice_libcore              ... bench:           4 ns/iter (+/- 0) = 1750 mb/s (taken on a x86_64 macbook 2.9 ghz intel core i9 with 6 cores) where is_ascii_slice_iter_all is the old version, and is_ascii_slice_libcore is the new. i tried to document the code well, so hopefully it's understandable. it has fairly exhaustive tests ensuring size/align doesn't get violated -- because miri doesn't really help a lot for this sort of code right now, i tried to debug_assert all the safety invariants i'm depending on. (of course, none of them are required for correctness or soundness -- just allows us to test that this sort of pointer manipulation is sound and such). anyway, thanks. let me know if you have questions/desired changes. </desc> <cmt> optimize is_ascii for &str and &[u8] </cmt> <cmt> avoid vec! allocation in is_ascii_slice_* benches </cmt>",optimize is_ascii for str and [u8].
978,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. this pr updates the type definition for the options object so that it conforms with version 4.5 of newman.  the options object is documented here:  newman api reference list of changes: adding string[] type to folder option: see here removing nocolor option (isn't documented in the newman api reference) adding color option with type of 'on' | 'off' | 'auto': here and then here adding two new options workingdir and insecurefileread: see here and review the newman api reference </desc> <cmt> fixing newman types. </cmt> <cmt> update version number. </cmt> <cmt> fixing linting issue. </cmt> <cmt> adding a test for newman. </cmt>",updates for newman version 4.5
979,"<desc> if you are familiar with the latest oap core, you will know, we register id for the endpoint. but this design has the following issues the register has low performance as it can't be run in parral even we have clustering oap. even worse, in the cluster mode, the register is slower the id is designed as an integer, it could be run out in some time. we don't have good idea to restore or extend it. endpoint including the parameter(such as, inside the uri) is always an issue, and could only be improved in the agent plugin, but never could be fixed. the new changes are use endpointtraffic to replace endpointinventory. endpointtraffic is a manual metrics, not a register inventory. id register would not happen, and service_id + base64(endpoint name) will be used as the entity id. endpointtraffic also keeps the time series feature like all other metrics, so it could be removed by ttl. endpointrelation follows the changes of endpointinevntory removal. it keeps the source-service_id + base64(source endpoint name) and dest-service_id + base64(dest endpoint name). the endpoint_traffic looks like this the endpoint* metrics, such as endpoint_sla. it is wider than before, because of entity_id format changed. </desc> <cmt> finish step one, source and entity changed. </cmt> <cmt> step 2, finish the basic and core dao changes. </cmt> <cmt> step 3. change all source codes of backend, and make project compiling successfully. </cmt> <cmt> make startup successful and persistence works. </cmt>",remove endpoint register and endpoint inventory
980,<desc> description: this change makes two features of the feedreader component configurable: the scan interval that determines how often the feed is updated is now configurable. the default is 1 hour which is slightly different to the previous behaviour where the update interval was fixed to the top of the clock every hour. the number of max entries extracted from the feed is now configurable. the default is 20 which is the previous behaviour. related issue (if applicable): n/a pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#5382 example entry for configuration.yaml (if applicable): feedreader: urls: -  -  -  scan_interval: minutes: 30 max_entries: 50 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io if the code does not interact with devices: </desc> <cmt> make scan interval configurable </cmt> <cmt> make max entries configurable </cmt>,feedreader configurable update interval and max entries
981,"<desc> nodejs does not define the variable window so we were creating it using this form var window = window || {}.  this works in chrome and firefox but in ie10, window is const. @mrdoob suggested that instead of using window we rely self which is creatable in ie10. i also check on self to see if the the functions settimeout and cleartimeout exist in order to set up the backwards compatibility shims (these functions do not exist on self in nodejs, thus these shims are not created.) i also changed 'window' to 'self' in three.clock and pulled it out into a three.clock.now function. </desc> <cmt> replace 'window' with 'self' in src/three.js for both nodejs and ie10 compatibility. </cmt> <cmt> 'window' to 'self' in npm header. </cmt>",npm package cleanup for ie10 and nodejs
982,<desc> this pr does two things: enables rla comments on prs (needed after the switch to gha in rla). switches github actions as the ci authorized to upload non-macos builds. note that docker/llvm caches will likely be busted. r? @mark-simulacrum </desc> <cmt> ci: allow rla to pick the right pr number </cmt> <cmt> ci: upload non-macos from gha instead of azure pipelines </cmt>,upload builds from gha instead of azure pipelines
983,"<desc> current readme shows a broken docs build icon because the job has been removed, fixing and adding a table to know what build is what. previous new </desc> <cmt> updating readme to fix broken status </cmt> <cmt> current readme shows a broken docs build icon because the job has been removed, fixing and adding a table to know what build is what. </cmt> <cmt> add mxnet logo </cmt>",updating readme to fix broken docs status
984,<desc> this is basically an un-revert of #12003 (reverted in #12159). </desc> <cmt> add _pyinterpreterstate_getmainmodule(). </cmt> <cmt> use pyinterpreterstate_getid(). </cmt> <cmt> fix memory leaks. </cmt> <cmt> move _pycrossinterpreterdata (and functions) to the public api. </cmt> <cmt> add _pyinterpreterid_type and helpers to public api. </cmt> <cmt> initialize the id refcount in _pyinterpreterstate_getidobject(). </cmt> <cmt> fix interpreterid intialization. </cmt> <cmt> fix the makefile. </cmt> <cmt> make a function static. </cmt> <cmt> do not call pytype_ready() twice. </cmt> <cmt> fix the windows build. </cmt> <cmt> _pycrossinterpreterdata_register_class -> _pycrossinterpreterdata_registerclass. </cmt> <cmt> clarify a comment. </cmt> <cmt> add the c++ guard. </cmt> <cmt> only destroy interpreters (by id refcount) when created by the module. </cmt>,use only public c-api in the_xxsubinterpreters module (adding as necessary).
985,"<desc> and fix up some white space. depends on cloudmade/leaflet#744 since i've renamed the option. </desc> <cmt> fix up whitespace </cmt> <cmt> add markerzoomanimation l.map option documentation. will go rename the option in master, this name is better (matches others) </cmt>",gh-pages-master - add option description for markerzoomanimation
986,"<desc> i hereby agree to the terms of the cla available at:  changelog entry (up to few sentences, required except for non-significant/documentation categories): implement on cluster feature for system reload dictionary detailed description (optional): right now, we cannot reload a dictionary on a distributed environment, so when we have an update from the dictionary source and we try to reload the dictionary, we need to do it instance by instance, who is not really convenient and can put some problems between replicas where the returned rows could be different depending if the dictionary has been reloaded or not. this pr has a goal to implement the on cluster syntax for the command system reload dictionary, in a similar fashion at system reload dictionary on cluster 'cluster' dict_name, where this command will run this command to every shards and replicas of the cluster. </desc> <cmt> add parser </cmt> <cmt> let the command system reload dictionary to use on cluster syntax </cmt> <cmt> add test for on cluster on reload dictionary command </cmt> <cmt> refactor target_table to table for better hemogny </cmt> <cmt> cosmetic </cmt>",implement on cluster syntax when we want to reload a dictionary
987,"<desc> perf tests set settings via set query, and in case of reconnect those settings will not be applied anymore. and clickhouse-driver (python) may implicitly do reconnects (if the ping is failed, i.e. connection has been closed). so fix this by passing settings in the protocol instead of separate set queries (or inplace via settings clause, refs #16619), and now clickhouse-driver will know about settings and will apply them for each query. also configure logging for warning+ (to see possible issues) cc: @akuzm </desc> <cmt> do not use set via <full_query> in perf tests </cmt> <cmt> since if the connection will be closed (by some reason), then the </cmt> <cmt> setting will not be applied after transparent reconnect (since only </cmt> <cmt> native clickhouse-client can do this, since it parses the query, but </cmt> <cmt> perf tests uses python driver). </cmt> <cmt> just use inplace settings clause or <settings>. </cmt> <cmt> force clickhouse-driver >= 1.1.5 for settings-as-strings support for perf-tests image </cmt> <cmt> configure logging for perf test runner </cmt> <cmt> pass settings for perf tests via protocol over set query </cmt> <cmt> thus they will be applied on reconnects, since clickhouse-driver may </cmt> <cmt> implicitly do it if the connection has been failed. </cmt>",cleanup settings handling in perf tests
988,"<desc> issue: #14617 added ids to all preview tools added new filter to preview toolbar that will exclude any and toolbar item that has matching been excluded with configuration or story parameter added toolbar config to addons config that to be able to hide any toolbar item. story parameter scenarios added new stories  for preview.stories.tsx for following scenarios: hide fullscreen hide all default tools configuration scenarios addons.setconfig({ toolbar: { fullscreen: { hidden: true } }, }); results in: addons.setconfig({ toolbar: { title: { hidden: true }, zoom: { hidden: true }, eject: { hidden: true }, copy: { hidden: true }, fullscreen: { hidden: true }, 'storybook/background': { hidden: true }, 'storybook/viewport': { hidden: true },}, }); results in: </desc> <cmt> make it possible to hide toolbar tools with configuration </cmt> <cmt> create story scenarios to exclude toolbar items. can exclude toolbar item with story parameter </cmt>",provide option to hide default toolbar tools
989,<desc> not checking for negative scale values in ccscrollview::getviewrect causes intersectsrect calls in ccscrollview (eg: to check if the touch was within the bounds) to return false. this is because the ccrect being returned has a negative width and height. one may set a negative scale for something like allowing scrolling top to bottom in terms of window coordinates (i.e. y positive downwards). </desc> <cmt> support negative scaling of ccscrollview. </cmt> <cmt> not checking for it in ccscrollview::getviewrect causes intersectsrect calls (eg: to check if the touch was within the bounds) to return false. </cmt>,support negative node scales of ccscrollview
990,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> added react-tag-input </cmt> <cmt> updates </cmt>",add type definitions for react-tag-input
991,"<cmt> silgen: redo test/silgen/enum.swift to not use -parse-stdlib </cmt> <cmt> (mostly) revert ""silgen: tupleshuffleexprs in the rvalue emission path can't have scalar-to-tuple or tuple-to-scalar"" </cmt> <cmt> we use tupleshuffleexpr in rvalue position for enum element payloads, and </cmt> <cmt> it can happen that the source is a scalar if you're calling the enum element </cmt> <cmt> constructor with a trailing closure. </cmt> <cmt> this reverts commit 7960660b7e41d58bf81c755db53318d040d0312d. </cmt> <cmt> fixes < </cmt>",fix enum element constructor call with trailing closure
992,<desc> what did you implement: rebased #2513 closes #2490 how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources change ready for review message below _is this ready for review?:_ yes </desc> <cmt> fixed issue 2490 </cmt> <cmt> fixed conflicts in variables </cmt> <cmt> removed overwrite for file variable </cmt>,fixes file variable fallback if the file doesn't exist
993,"<desc> changelog entry (up to few sentences, required except for non-significant/documentation categories): improved performance of base64 related functions. detailed description (optional): changed the underlying library to turbobase64 because the author can guarantee the best possible performance (powturbo/turbo-base64#2). on a single test on avx machine the difference is not very high. let's wait for performance tests in ci. </desc> <cmt> changed one base64 library to another </cmt> <cmt> switched back to turbobase64 </cmt>",replace base64 library to turbobase64
994,"<desc> hi joseph: requesting you to add two new python libraries: auto_viml for automatically building multiple machine learning models with a single line of code and autoviz, for automatically visualizing any data set of any size with a single call. thanks ram </desc> <cmt> request to add two new python: auto_viml, autoviz </cmt> <cmt> request to add two new python libraries: auto_viml for automatically building multiple machine learning models with a single line of code and autoviz, for automatically visualizing any data set of any size with a single call. </cmt> <cmt> request to add two new python: auto_viml, autoviz </cmt>",request to add to python section: auto_viml and autoviz
995,"<desc> some users of github for mac were observing some odd crashes in the diff code, particularly in the new diff_scan_inside_untracked_dir() routine. i dredged up an old test that i had that took large repositories, rev-walked the history, and picked random oids to checkout. i updated it the test and added doing random diffs as well as random checkouts, and i was able to flush out a number of bugs.  this pr has four commits that fix four separate bugs: the actual crash that users were seeing is fixed in 79ef3be where if the alphabetically last item in a diff (against the working directory) was an untracked directory that only contained ignored items (e.g. ""zobjects/"" only contains ""*.o"" files which are ignored), then we would run the iterator off the end and dereference null. once i figured this out, it was easy to write a test that reproduced the error and put in a fix. when updating an existing blob in checkout, the code was trying to do an ""update in place"" - i.e. it would open the existing file and just overwrite the data with the new content. that doesn't work for symlinks, so when we are doing a safe update to a symlink, i made it so we'll remove the old symlink and create a new one. if a user forgets to commit the .gitmodules file after adding a new submodule, it is possible to create a tree with a submodule (i.e. commit) entry that does not have a corresponding entry in .gitmodules - in the checkout code, the call to git_submodule_lookup would fail when we try to checkout that submodule and we would abort the entire checkout midway through. core git just creates an empty directory in these circumstances and proceeds with the rest of the checkout. i made our checkout code do the same thing. inside git_diff_find_similar depending on the flags that you pass to the original diff call, you may end up with entries that cannot actually be opened for purposes of rename detection. i fixed things so that if a blob or file on disk cannot be opened, instead of generating an error, we just exclude that from the list if valid rename candidates. i'm putting all of these fixes in one pr because i think they should probably all be merged. if there are any that you're nervous about or want changes to, let me know and i'll either drop the bad ones to hurry the good ones in, or fix the problems. thanks! </desc> <cmt> fix diff crash when last item is untracked dir </cmt> <cmt> when the last item in a diff was an untracked directory that only </cmt> <cmt> contained ignored items, the loop to scan the contents would run </cmt> <cmt> off the end of the iterator and dereference a null pointer.  this </cmt> <cmt> includes a test that reproduces the problem and a fix. </cmt> <cmt> remove old symlinks before updating </cmt> <cmt> unlike blob updates, symlink updates cannot be done ""in place"" </cmt> <cmt> writing over an old symlink.  this means that in checkout when we </cmt> <cmt> realize that we can safely update a symlink, we still need to </cmt> <cmt> remove the old one before writing the new. </cmt> <cmt> fix checkout of submodules with no .gitmodules </cmt> <cmt> it is possible for there to be a submodule in a repository with </cmt> <cmt> no .gitmodules file (for example, if the user forgot to commit </cmt> <cmt> the .gitmodules file).  in this case, core git will just create </cmt> <cmt> an empty directory as a placeholder for the submodule but </cmt> <cmt> otherwise ignore it.  we were generating an error and stopping </cmt> <cmt> the checkout.  this makes our behavior match that of core git. </cmt> <cmt> improve robustness of diff rename detection </cmt> <cmt> under some strange circumstances, diffs can end up listing files </cmt> <cmt> that we can't actually open successfully.  instead of aborting </cmt> <cmt> the git_diff_find_similar, this makes it so that those files just </cmt> <cmt> won't be considered as valid rename/copy targets instead. </cmt>",bug fixes for checkout and diff
996,"<desc> still wip.  original issue is #118, is rework of #120. changes from #120 are: uses libmemcached uses inter-thread messaging introduced in #154 </desc> <cmt> add support for async session resumption </cmt> <cmt> implement libmemcached client </cmt> <cmt> it works! (for exmaples/libh2o/simple.c) </cmt>",tls session resumption using memcached (take two)
997,"<desc> (@lfades), i forgot remove package react-facebook-pixel that is not necessary now and update readme doc. </desc> <cmt> different implementation facebook pixel </cmt> <cmt> - allows use events </cmt> <cmt> - does not use external package </cmt> <cmt> - correct implementation according to facebook guide spa pixel </cmt> <cmt> - set pixel code like global and pageview always working </cmt> <cmt> change readme and name folder </cmt> <cmt> change readme </cmt> <cmt> functions events and pageview </cmt> <cmt> example standar event purchase </cmt> <cmt> set base code pixel (global) </cmt> <cmt> component check route change </cmt> <cmt> remove other example pixel </cmt> <cmt> renamed utils to lib </cmt> <cmt> minor format changes </cmt> <cmt> moved example page content to the index page </cmt> <cmt> remove react-facebook-pixel package and update readme </cmt>",remove package and update readme
998,<desc> this pr superseeds #5596 (thanks @memphiz for spotting it and doing half the work) and updates the default value of the webserver username setting from xbmc to kodi. the tricky part is that the settings system contains logic to automatically update the default value of a setting if the current setting value matches the default. that however means that when someone has set the webserver username to xbmc (which is the old default value) but has a non-empty password set (which is not the default value) the username value would be automatically updated to kodi and the password would be left untouched. that would mean that users wouldn't be able to connect to the webserver with their known credentials anymore. therefore we need to catch that case and only update the username from xbmc to kodi if no password is set. this however wasn't possible due to the fact that both the update logic and the default value handling logic was added to the settings library afterwards and they didn't work well together. so i've fixed the settings library behaviour to only update the default value if the setting wasn't updated through an update handler. that allows us to use the update handler written by @memphiz which checks the username and password combination and can therefore force the settings system to not update the default value if the username is xbmc and the password is not empty. </desc> <cmt> settings: fix combination of updated settings and default value handling </cmt> <cmt> [rebrand] - change default username of webserver from xbmc to kodi </cmt>,"change default webserver username from ""xbmc"" to ""kodi"""
999,"<desc> print ""__owned"" and ""__shared"" with leading underscores print the '_effects' attribute with its underscore print normally unprinted attributes when generating a swiftinterface file </desc> <cmt> [ast] print ""__owned"" and ""__shared"" with leading underscores </cmt> <cmt> the type printer was being optimistic about these, but that's a </cmt> <cmt> problem for testing textual interfaces right now. </cmt> <cmt> [moduleinterface] print normally unprinted attributes </cmt> <cmt> we need @_transparent to control mandatory inlining; @_fixed_layout to </cmt> <cmt> control, well, layout; and @_effects to help optimization. we still </cmt> <cmt> don't need the implicitlyunwrappedoptional attribute, and we don't </cmt> <cmt> need access control attributes (because we handle that uniformly). </cmt> <cmt> this also fixes up the printing of the '_effects' attribute to include </cmt> <cmt> its underscore, so that it matches the source spelling. </cmt>",small improvements to ast printing in service of textual interfaces
1000,"<desc> this pr supersedes #2745, starting from there and updating all the links to web-contents that were incorrect because it is now its own file, web-contents.md. </desc> <cmt> update broken link </cmt> <cmt> update links to web-contents.md </cmt>",update documentation links to web-contents
1001,<desc> article link :  added readme and code for cycle in graph using degree of nodes in the graph article </desc> <cmt> create readme.md </cmt> <cmt> create reverse_doubly_linked_list.cpp </cmt> <cmt> delete readme.md </cmt> <cmt> delete reverse_doubly_linked_list.cpp </cmt> <cmt> create readme.md </cmt> <cmt> create detect_cycle_graph_using_degree.cpp </cmt>,added code for cycle in graph using degree of nodes of graph article
1002,<desc> i copied the angularjs example and added persistent local storage via a service in angular that makes use of a library called persistencejs. what do you think? </desc> <cmt> added angularjs-persistencejs example </cmt> <cmt> fixed refresh for asynchronous events </cmt>,new example using angularjs + persistencejs
1003,"<desc> enable hmr for css current webpack settings uses mini-css-extract-plugin for both development and production. this plugin extract css into many small files based on the modules that imports them. however, per the package's readme, it is recommended for production only especially if we want hot module replacement (hmr) for css. to use hmr, we need to use style-loader when in development mode. otherwise, the page will not update after saving css files.  to ensure that style-loader works correctly, i also need to modify the html templates to import theme js entry points. because style-loader injects css code via js that writes <style> tags instead of exporting css files. optimize css output current css output from webpack are not minified. this pr adds optimize-css-assets-webpack-plugin to minify css outputs. the minification reduce css size by ~100kb i have tested building in production and running dev server. both are working fine. @graceguo-supercat @xtinec @hughhhh @conglei @williaster </desc> <cmt> enable hmr for css. use style-loader for development </cmt> <cmt> optimize css output </cmt>",enable css hot module replacement and optimize css output for production
1004,<desc> now a rendertexture can be (re)created from an existing texture or a specific frame within that texture. this allows one to e.g. create and draw gameobjects to rendertexture and later modify it. </desc> <cmt> update rendertexturecreator.js </cmt> <cmt> update rendertexturefactory.js </cmt> <cmt> update rendertexture.js </cmt> <cmt> update rendertexture.js </cmt>,create rendertexture from existing texture/frame
1005,<desc> in pr #14594 general_io_worker/runtime_env_worker is not updated to the new name which will lead to py worker failure. this pr fix this. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix </cmt> <cmt> format </cmt>,fix worker type in python
1006,"<desc> currently the following code doesn't work when callconstructor() is called from swift: inline int increment(int value) { return value + 1; } struct incrementor { int incrementee; incrementor(int value) : incrementee(increment(value)) {} } int callconstructor(int value) { return incrementor(value).incrementee; } the issue is that we don't generate ir for the increment() function when it's only called from a constructor or a method. swift is aware of the existence of increment() and we see it in ir as declare incrementei, however, as we don't to emit a definition, we get the following error: incrementor::incrementor(int): error: undefined reference to 'increment(int)' this pr fixes this by visiting constructors and methods in irgen and calling handletopleveldecl() with all used declarations, which results in emitting definitions for the used declarations. </desc> <cmt> add test </cmt> <cmt> more tests </cmt> <cmt> wip </cmt> <cmt> traverse cxxrecorddecls </cmt> <cmt> tweaks </cmt> <cmt> productionalizing </cmt> <cmt> productionalize </cmt> <cmt> add more tests </cmt> <cmt> add more tests </cmt>",generate ir for decls called from members
1007,"<desc> 5.3 cherry-pick of #33037, minus the last commit which is just a refactor. explanation: fixes a 5.3 regression where we would fail to emit a group of diagnostics for the where clause of a for loop. scope: fixes a 5.3 regression that could allow us to accept invalid code. radar: rdar://65903005 risk: low, this re-enables diagnostic logic that was previously enabled in 5.2. testing: added unit test. reviewer: @xedin. </desc> <cmt> [cs] add solutionapplicationtarget::isforeachstmt </cmt> <cmt> [cs] introduce performsyntacticdiagnosticsfortarget </cmt> <cmt> add a function that deals with invoking syntactic </cmt> <cmt> diagnostics for all the expressions involved in </cmt> <cmt> a solutionapplicationtarget. </cmt> <cmt> resolves sr-13260 </cmt> <cmt> resolves rdar://65903005 </cmt>",emit syntactic diagnostics for for loop where clauses
1008,<desc> the code module uses sys.ps1 if present or sets it to '>>> ' if not. test_code_module now properly tests both behaviors.  ditto for ps2. </desc> <cmt> bpo-31836: make test_code_module pass after test_idle. </cmt> <cmt> test_code_module assume sys.ps1 is initially absent; make it so. </cmt> <cmt> add test that code.interact respects existing sys.ps1. ditto for ps2. </cmt> <cmt> news blurb. </cmt>,"test_code_module now passes with sys.ps1, ps2 set"
1009,"<desc> this pr adds the initial version of a react-based dashboard with a new interface and some additional features (e.g. log and error viewing). the new dashboard will continue to be extended and improved over the coming months. for now, the old dashboard files have been left in place until we're certain that all relevant functionality has been replicated. they can be removed in a separate pr later on. n/a i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> initial commit of new react dashboard </cmt> <cmt> remove unused /api/super_client_table route </cmt> <cmt> fix error timestamps </cmt> <cmt> make the dashboard build files optional during setup </cmt> <cmt> improve web ui test and incorporate it into wheel testing </cmt>",add initial version of new dashboard
1010,"<desc> split off #87234 r? @petrochenkov </desc> <cmt> stop sorting bodies by span. </cmt> <cmt> the definition order is already close to the span order, and only differs </cmt> <cmt> in corner cases. </cmt> <cmt> compute item_generics_num_lifetimes during resolution. </cmt> <cmt> compute all_traits_impls during resolution. </cmt> <cmt> compute proc_macros in resolutions. </cmt>",move global analyses from lowering to resolution
1011,"<desc> closes #42492 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 17038 </cmt> <cmt> revert change </cmt> <cmt> revert change </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add examples in user guide and docstring for box </cmt> <iss> doc: add updated docstring for examples of `by` argument in `df.plot.hist` and `df.plot.box` </iss>",add user_guide examples and docstring example for df.plot.box and df.plot.hist
1012,"<desc> the two main changes are: introduce join_scopes that returns a homogeneous array of relation objects.  this means we can skip doing an is_a? check and building an intermediate array. remove the parameter to join_keys.  this means we can call join_keys on a reflection without context, so we don't have to pass a ""klass"" object everywhere. </desc> <cmt> move join scopes on to the reflection object </cmt> <cmt> scopes can only ever be *not* reflection objects when they are passed in </cmt> <cmt> to the reflection constructor.  given this fact, we can eliminate is_a </cmt> <cmt> checks and an intermediate array object by just asking the reflection </cmt> <cmt> object for join scopes. </cmt> <cmt> ask reflection for klass join reflection </cmt> <cmt> refactor so there is only one joinkeys factory method </cmt> <cmt> join_keys no longer needs a class passed to it </cmt> <cmt> reflections only use their own information to create a join_keys </cmt> <cmt> object.  this means that we can call join_keys on a reflection object </cmt> <cmt> and have it be context-free. </cmt> <cmt> remove unused parameters </cmt>",various refactoring to association scopes and joins
1013,"<desc> set a minimum delay of 10 seconds for the semantic editor requests instead of starting from 0/1 second. this helps prevent us from being throttled by the system if we have multiple crashes in a row, which allows us to keep syntactic requests working. this trades off the minimum time it takes to recover e.g. code-completion after a crash in exchange for keeping our most basic functionality working. rdar://18326221 </desc> <cmt> [sourcekitd] be more aggresive with the semantic editor delay </cmt> <cmt> set a minimum delay of 10 seconds for the semantic editor instead of </cmt> <cmt> starting from 0/1 second.  this helps prevent us from being throttled by </cmt> <cmt> the system if we have multiple crashes in a row, which allows us to keep </cmt> <cmt> syntactic requests working. </cmt> <cmt> rdar://18326221 </cmt> <cmt> [sourcekitd] make code-completion obey the semantic-editor-delay </cmt> <cmt> these are semantic requests and should obey the delay to ensure we don't </cmt> <cmt> trigger too many crashes. </cmt> <cmt> rdar://18326221 </cmt>",be more aggresive with the semantic editor delay to avoid being throttled
1014,"<desc> cherry-pick of a couple of fixes for incremental parsing. skip missing node in getnextnode() #19951 taking missing node into account confuses reusability checking in incremental parsing. rdar://problem/45215049  rdar://problem/45287031  fix syntaxparsingcache::translatetopreeditposition() #20321 if the position is in the region that is inserted by the edits, 'pre-edit' position shouldn't exist. so we cannot reuse the node at the position. rdar://problem/45259469 </desc> <cmt> [incrparse] fix syntaxparsingcache::translatetopreeditposition() </cmt> <cmt> if the position is in the region that is inserted by the edits, </cmt> <cmt> 'pre-edit' position shouldn't exist. so we cannot reuse the node at the </cmt> <cmt> position. </cmt> <cmt> rdar://problem/45259469 </cmt> <cmt>  </cmt> <cmt> [incrparse] skip missing node in getnextnode() </cmt> <cmt> taking missing node into account confuses reusability checking in </cmt> <cmt> incremental parsing. </cmt> <cmt> rdar://problem/45215049 </cmt> <cmt> rdar://problem/45287031 </cmt>",a couple of fixes for incrparse
1015,"<desc> holding 'a' with the left hand enables the media layer. in the media layer, the user can move the mouse with hjkl, just as in vim. the user can also right-click with 'i' and left-click with 'o'. </desc> <cmt> a to toggle l2, hjkl to move mouse </cmt> <cmt> building a row of level switch buttons </cmt> <cmt> make a also toggle media layer </cmt> <cmt> stylistic changes </cmt> <cmt> added readme note about vim-style navigation </cmt> <cmt> added vim-style navigation </cmt>",vim-style navigation for j3rn layout
1016,"<desc> pr intends to add support for higher order gradient for reciprocal, abs. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira-978 issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change higher order gradient for a reciprocal, abs. unit test for the same. </desc> <cmt> add higher order support for reciprocal and abs </cmt> <cmt> add relevant tests </cmt>","higher order gradient support reciprocal, abs."
1017,"<desc> just two typo fixes cla signed. if not, go over here and sign the cla documentation updated. if checked, please file a pull request on our docs repo and link it here: #xxx i clicked ""preview"" on the markdown to make sure it renders ok </desc> <cmt> typo fix </cmt> <cmt> just a tiny typo i noticed </cmt> <cmt> typo - missing space in between sentences </cmt>",fix pixel shader typo in readme
1018,"<desc> in [1] changes were made to ensure that the physical devices were appropriately filtered, but the dev_list which is used to prepare the filter is modified from the original arguments to resolve any symlinks. this results in the existing devices given in the module args to be left out of the filter, resulting in the module trying to add the same device again every time the task is executed. in this pr we change dev_list to be a copy of the module arguments so that we're able to add the given pv list from the module arguments into the filter as well, ensuring that there is idempotence when running the task again. fixes # 47301 backport # 47620 lvg ansible version ansible 2.7.0 config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/mvutcovici/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /bin/ansible python version = 2.7.5 (default, may 31 2018, 09:41:32) [gcc 4.8.5 20150623 (red hat 4.8.5-28)] </desc> <cmt> fix lvg module idempotency </cmt> <cmt> in [1] changes were made to ensure that the physical </cmt> <cmt> devices were appropriately filtered, but the dev_list </cmt> <cmt> which is used to prepare the filter is modified from </cmt> <cmt> the original arguments to resolve any symlinks. this </cmt> <cmt> results in the existing devices given in the module </cmt> <cmt> args to be left out of the filter, resulting </cmt> <cmt> in the module trying to add the same device again </cmt> <cmt> every time the task is executed. </cmt> <cmt> in this pr we change dev_list to be a copy of the </cmt> <cmt> module arguments so that we're able to add the given </cmt> <cmt> pv list from the module arguments into the filter </cmt> <cmt> as well, ensuring that there is idempotence when </cmt> <cmt> running the task again. </cmt> <cmt> [1] </cmt> <cmt> (cherry picked from commit 1bae00b5d26816b3298e2363a5d1c3fe9f945865) </cmt> <cmt> add lvg module idempotence test </cmt> <cmt> to ensure that the lvg module is tested for idempotency, </cmt> <cmt> we add a basic integration test. </cmt> <cmt> support for macos and freebsd are skipped because the </cmt> <cmt> module does not currently support those platforms. </cmt> <cmt> (cherry picked from commit 204b40f70648c0c58bc5714928d9eb6bcd0f47d8) </cmt>",fix lvg module idempotency (stable-2.7)
1019,"<desc> i have issues with this approach - would like to discuss.  primary issue is that i could not get the previous tests passing with this implementation.  meaning, this implementation is intentionally gimped. </desc> <cmt> fix for conditional in src/lib/units/offset.js:164 - i interpreted this is as simply not catching  being a falsy (but assumedly valid) time zone modifier (_tzm?) of 0 </cmt> <cmt> added comment as requested in: </cmt> <cmt> update for  check, </cmt> <cmt> added helper 'isnumeric' to test values for validity in setters </cmt> <cmt> added new line in helper file </cmt> <cmt> added semicolon to helper </cmt> <cmt> removed unwarranted spaces, changed illegal quotes </cmt> <cmt> changed setter check behavior to use isnan() for checking whether an input is a valid value </cmt>",ignore nan values in setters
1020,"<desc> in obmalloc, set address_bits to pointer_bits, rather than to 48.  that is safer in the case that the kernel gives user-space virtual addresses that span a range greater than 48 bits. </desc> <cmt> for obmalloc, set address_bits to pointer_bits. </cmt> <cmt> add blurb. </cmt>",obmalloc radix use 64 addr bits
1021,"<desc> checks an item on #41648 and #41693 currently styler has the apply and applymap methods to perform conditional styling on the data elements. recent additions to styler.set_table_styles allows styling of index and column headers if the key-labels are directly specified. but this solution cannot work with latex, nor excel output, and is obviously not conditionally applied. this pr adds the mechanics to perform conditional styling on per level index labels follow-ons are: updating latex templates to incorporate the styles. (#41993) updating excel output to incorporate the styles. (#41995) update styler user guide </desc> <cmt> add apply across index </cmt> <cmt> add applymap across index </cmt>",styler.apply_index and styler.applymap_index for conditional formatting of column/index headers
1022,"<desc> this pr fixes a bunch of slow tests. dpr had a few issues, which this pr fixes. there was an issue where the dprreader object was not using token_type_ids, but for some unknown reason the interaction with the underlying tfbertmainlayer that requires those crashed when using the oh-so-terrifying tf.saved_model.save. i chose to add the token_type_ids to that model, as imo an additional feature is not a bad idea, even if it wasn't in the original model. i can imagine a bunch of reasons why users might want to have token_type_ids in that model even though it doesn't exist now. all in all, after an hour of debugging i feel that this is the only way to have the slow tf.saved_model.save test passing on tfdpr. @patrickvonplaten @lhoestq please tell me what you think. </desc> <cmt> ci should install sentencepiece </cmt> <cmt> requiring tf </cmt> <cmt> fixing some tfdpr bugs </cmt>",fix a bunch of slow tests
1023,<desc> relate: #10216 breaking the build because webpackfinal will be called twice if write  not idempotent custom webpack configuration. fix createfinaldefaultconfig call to one time only. </desc> <cmt> refactor: redundant function calls </cmt> <cmt> refactor: refactor when customconfig is null </cmt>,fixed webpackfinal being called twice
1024,<desc> preparing api and scripts to enhance ci check of registered data_type see details in add ci for checking registered data_type of new op add _get_all_register_op_kernels in pybind.cc to return {op_type: op_kernel_info} add check_op_register_type.py to diff pr and dev branch </desc> <cmt> add _get_all_register_op_kernels api test=develop </cmt> <cmt> refine usage of check_op_register_type test=develop </cmt>,add get_all_kernels api of registered data_type in pybind.cc
1025,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  basically: as soon as /oauth/token is called along with the offline_access scope and in the meanwhile it is enabled in the auth0 dashboard the tokenreponse interface will include the refresh_token property which can be used later on in the refreshtoken method or similar ""access_token"": ""access_token"", ""refresh_token"": ""refresh_token"", ""id_token"": ""id_token"", ""scope"": ""some_scopes offline_access"", ""expires_in"": expiration, ""token_type"": ""bearer"" the refreshtoken was returning the tokenresponse in its callback definition but not in its promise definition (i believe it is happening in many other endpoints. it sounds strange to me) </desc> <cmt> feat: add optional refresh_token to tokenresponse </cmt> <cmt> fix: refreshtoken promise response definition </cmt> <cmt> test: update refreshtoken method </cmt>",fix refreshtoken promise response definition and add optional refresh_token to tokenresponse type
1026,"<desc> see jenkins-46523. unixreflection class didn't support java 9+ apis, and java.lang.unixprocess is removed from recent java versions. multi-release jar is probably a way to go, but so far i would like to apply a quick patch. this patch fixes ~100 tests in #3636 rfe: update unix process management logic to support process tree termination in java 11 changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) @jenkinsci/sig-platform </desc> <cmt> [jenkins-46523] - make unixreflection class compatble with java 9+, remover pre-java-8 code </cmt> <cmt> ideally this logic should be replaced by multi-release jar </cmt> <cmt> [jenkins-46523] - findbugs annotations complicate the code here </cmt>","make unixreflection class compatible with java 11, remove pre-java 8 reflection"
1027,"<desc> i hereby agree to the terms of the cla available at:  changelog entry (up to few sentences, required except for non-significant/documentation categories): remove mutation number from part_name by default. </desc> <cmt> add missed test for system.mutations </cmt> <cmt> fix mutation number by default </cmt>",no mutation number by default
1028,<desc> since bitnami/magento:2.2.2-r1 it is possible to configure magento to use an already existing database. this pr makes the required changes in the chart to create the database using the mariadb chart and use it for magento. </desc> <cmt> allow magento helm chart to use an existing database </cmt> <cmt> fix typo </cmt>,allow use of external database
1029,"<desc> get background notifications for long running commands! running a build? a deploy? moving files? anything that takes more than 6 seconds (easily configurable) sends you a slick and unobtrusive system notification: it works with osx notification center (using terminal-notifier), ubuntu's native notify-send, and cygwin: linux windows it supports having a custom message hook (in case you need it to say 'holy smokes batman' for example). there are a few hacks to do the same thing-- often making heavy use of applescript and being very platform-spesefic. this plugin makes a point to run on all three major platforms. </desc> <cmt> add bgnotify plugin, a cross-platform background notifier! </cmt> <cmt> fixed math on linux, removed debug echo. </cmt> <cmt> add cygwin windows support with notifu, add to readme </cmt> <cmt> fix renamed method issue. </cmt> <cmt> add window id fallback for windows. </cmt> <cmt> - maybe someday use getforegroundwindow() from user32.lib ... </cmt>",background notifications on long-running commands
1030,"<desc> this pr changes the dropdown icons from horizontal to vertical for homepage cards, and datasource editor dropdown. screen.recording.2021-07-30.at.1.25.53.pm.mov go to homepage and listviews, and explore to checkout new icon includes db migration (follow approval process in sip-59) </desc> <cmt> change icons </cmt> <cmt> add size </cmt>",change dropdown icons from horizontal to vertical
1031,<desc> description: related issue (if applicable): fixes #21761 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> update location schema </cmt> <cmt> generate a random device id at registration time for later use with device_tracker.see </cmt> <iss> mobile app: report location should only allow location + battery </iss>,update location schema updates & device id generation
1032,"<desc> template of extraenvs is done using with clause, but still referencing .values.extraenvs using .values.extraenvs inside with clause was wrong. it causes the error below. error: render error in ""node-red/templates/deployment.yaml"": template: node-red/templates/deployment.yaml:48:17: executing ""node-red/templates/deployment.yaml"" at <.values.extraenvs>: can't evaluate field values in type []interface {} </desc> <cmt> fix templating error </cmt> <cmt> bump up version of stable/node-red </cmt>",fix for templating error of extraenvs
1033,"<desc> nb: changes the public api, albeit in a backwards-compatible way. especially when copying variables between scopes it's handy to be able to grab sets of variables by scope. this allows the much more succinct: tf.trainable_variables(""myscope"") which is equivalent to: tf.get_collection(tf.graphkeys.trainable_variables, ""myscope"") also fixup a minor unrelated documentation bug. </desc> <cmt> minor documentation fixup. </cmt> <cmt> allow passing optional scope into variable lookup helper functions. </cmt> <cmt> don't alter the current behaviour of eg. tf.trainable_variables(), but </cmt> <cmt> make it prettier to get classes of variables by scope. </cmt>",enable passing scope to variable lookups
1034,"<desc> fixes issue: n/a i recently got a code review on my implementation of problem 37. after making the changes, my code sped up to 1/6th of its original runtime. (0.42ms to 0.07ms). so i have put the changes here as well. the code is also ~70 lines shorter now as well. @iattempt and anyone else - please review this! </desc> <cmt> updated repository </cmt> <cmt> fixed file name + sped up performance </cmt>",updated problem #37 of project euler for better performance
1035,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test node-ipc. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add missing broadcast function to node-ipc </cmt> <cmt> add tests </cmt>,add missing broadcast method to node-ipc
1036,<desc> resolves #5035 thanks a billion to @timneutkens for holding my hand </desc> <cmt> add test for _error on 404 for static export </cmt> <cmt> map _error.js to 404.html </cmt> <iss> export 404.html when running `next export` without `exportpathmap` </iss>,404 routing for static export without exportpathmap
1037,"<desc> purpose update preview image from readme.md file. description instead of a static image, just have a gif file instead. since the demo itself is really short, the total clip length is 30 seconds; i couldn't think of a reason to have people link to another website for just to see a demo. what do you guys think? check out my branch to see how it look => jcs-pr/sherlock </desc> <cmt> add sherlock preview imaage. </cmt> <cmt> update preview link. </cmt> <cmt> fixed img tag syntax. </cmt> <cmt> add width and height attribute. </cmt> <cmt> remove weird text in the gif file. </cmt>",new preview in the readme file.
1038,"<desc> fixes #16828 this commit allows the use of csc matrix without conversion to csr in truncatedsvd.transform. in addition, a benchmark file ""bench_tsvdtransform_csc.py"" is added for evaluating the performance improvement. here is a quick preview of the benchmark. performance comparison input_dimensions with_csr_conversion without_conversion 1000               0.3052s                  0.2708s 2000               1.6780s                  1.7055s 3000               3.9639s                  4.0052s 4000               7.5915s                  7.2595s 5000               12.2266s                 12.1459s 6000               18.1505s                 17.7042s 7000               25.2273s                 25.0626s 8000               33.1733s                 33.2724s 9000               42.9401s                 42.7734s </desc> <cmt> this commit allows csc matrix format in truncatedsvd.transform(x) </cmt> <cmt> in addtion, a benchmark file ""bench_tsvdtransform_csc.py"" for evaluating </cmt> <cmt> the performance improvement. </cmt> <cmt> formating to conform pep8 </cmt> <cmt> conforming with pep8 </cmt> <iss> improve truncatedsvd.transform on sparse csc matrices </iss>","fix ""improve truncatedsvd.transform on sparse csc matrices #16828"""
1039,<desc> removes an unnecessary call to mocha#stubs following up on #33309. replaces calls to mocha#stubs with minitest#stub following up on #33337. </desc> <cmt> remove unnecessary mocha stub </cmt> <cmt> should have been removed in #33309. </cmt> <cmt> replace some more mocha#stub calls with minitest </cmt> <cmt> missed these in preparing #33337 </cmt>,remove/replace some more calls to mocha#stubs
1040,"<desc> this pull request ports the vt mouse code from termcontrol to wpfterminalcontrol. our wpf control is a lot closer to win32 than to xaml, so our mouse event handler looks nothing like the one that we got from xaml. we can pass events through almost directly, because the window message handling in the mouse input code actually came from conhost. it's awesome. neither termcontrol nor conhost pass hover events through when the control isn't focused, so i wired up focus events to make sure we acted the same. just like terminal and conhost, mouse events are suppressed when shift is held. tested with mc, and tested by manually engaging sgr events in an echo terminal. </desc> <cmt> wpf: wire up focus events </cmt> <cmt> wpf: wire up mouse events </cmt>",add support for vt mouse mode
1041,"<desc> this pr adds some failing tests that prove the issue described in #613. underlying cause is related to naive parsing in an old version of postcss-selector-parsing, updating dependencies in #618 will fix. </desc> <cmt> add test for prefixing classes with non-standard characters </cmt> <cmt> add test for creating responsive variants of classes with non-standard characters </cmt>",add failing tests for #613
1042,"<desc> original pull-request #26545 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update entrypoint.sh </cmt> <cmt> we build clickhouse cluster in k8s by clickhouse-operator. </cmt> <cmt> clickhouse-server.log is mounted by emptydir on the path /var/log/clickhouse-server. </cmt> <cmt> it causes the file system error called necessary directory '/var/log/clickhouse-server' isn't owned by user with id '101'   when  clickhouse_do_not_chown is set to true(1). </cmt> <cmt> because emptydir file and dir is owned by root when it started, it has to do the chown cmd. </cmt> <cmt> but it will take a long time to run chown cmd when the cluster has much data (in table data dir), the cluster cannot even restart because of  initialdelayseconds </cmt> <cmt> so chown operation is necessary to check if the file owner and group is owned by user 101. </cmt> <cmt> update entrypoint.sh </cmt> <cmt> update entrypoint.sh </cmt> <cmt> update entrypoint.sh </cmt>",cherry pick #26545 to 21.3: update entrypoint.sh
1043,"<desc> this pr makes the ""data"" volumemount path configurable from values.yaml file instead of the hardcoded value. fixes #23792 </desc> <cmt> updated new image </cmt> <cmt> configurable mount path for data volume </cmt> <cmt> updated chart version </cmt> <iss> [stable/rundeck] paramaterize pvc mount path </iss>","make ""data"" volume configurable from values file."
1044,"<desc> this pr fixes a bug in nameddatetimefunction and nonisodatetimefunction based functions as well as quarter function that made the painless script generated to be incorrect. in case the function was applied on the result of another function (adding an interval to a field's value for example) the painless script associated with the datetime function was not applied on the result of the inner function. fixes #40241. </desc> <cmt> fix issue with painless scripting not being correctly generated when </cmt> <cmt> datetime functions are used for grouping of an interval operation. </cmt> <iss> sql: when grouped by, the day_name function outputs incorrect results </iss>",fix scripting for grouped by datetime functions
1045,"<desc> there's a bug in github.com/docker/libnetwork/ipvs where an address cannot be parsed because the netlink address family attribute is not set (#89520). this bug is only present in old kernels (<3.18). there's a fix for this bug in moby/ipvs v1.0.1, however, we can't cherry-pick that fix for v1.18 since we are still vendoring docker/libnetwork. we also can't fix github.com/docker/libnetwork/ipvs since it was removed in favor of github.com/moby/ipvs and we don't want to update the release branch to use github.com/moby/ipvs since that involves bumping github.com/vishvananda/netlink to v1.1.0 which introduces some significant changes to other components. in order to cherry-pick the bug fix without significant changes to vendored dependencies, this pr: moves vendor/github.com/docker/libnetwork/ipvs -> third_party/forked/ipvs removes github.com/docker/libnetwork from go.mod update imports to k8s.io/kubernetes/third_party/forked/ipvs fix the address family bug based on fixes that went into moby/ipvs@v1.0.1 (moby/ipvs#15 and moby/ipvs#19) some other changes required to get the ipvs e2e presubmit passing since this was only enabled/working starting in v1.19 (#89327 and #89854) original prs to master: #90555 #89327 (fixes ipvs e2e setup) #89854 (fixes failing ipvs e2e tests) fixes #89520 does this pr introduce a user-facing change?: fix ipvs compatiblity issue with older kernels (< 3.18) where the netlink address family attribute is not set </desc> <cmt> move github.com/docker/libnetwork/ipvs to third_party/forked </cmt> <cmt> update pkg/util/ipvs to use third_party/forked/ipvs </cmt> <cmt> remove github.com/docker/libnetwork from go.mod </cmt>",move ipvs lib to third_party/forked and fix address family bug present in old kernels
1046,"<desc> this adds an additional emulatorid to devices so allow clients to match them up (and hide already-running emulators from the ""launch emulator"" list). it's currently only exposed in the daemon, though we may also want to expose this in flutter devices (@mit-mit fyi). @devoncarew @jonahwilliams for android this requires creating a connection to the device and running ""avd name"" (it doesn't work via adb) - see original investigations at #16705 (comment). it's more important now for vs code, as the device selector is showing both devices and emulators, and the dupes are weird. here's how the android console works on a real emulator for reference: dantup-macbookpro:inetutils-1.9 dantup$ telnet/telnet localhost 5554 connected to localhost. escape character is '^]'. android console: authentication required android console: type 'auth <auth_token>' to authenticate android console: you can find your <auth_token> in '/users/dantup/.emulator_console_auth_token' ok avd name danny_nexus ok this still needs tests - i want to be sure we're happy with this before proceeding (and i'm also open to ideas on how best to test this, the only significant code is in connecting to running emulators, and i'm not sure if we have much infrastructure for testing something like that. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read [handling breaking changes]). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add emulatorid to android and ios emulator devices </cmt> <cmt> update docs </cmt>",add emulatorid field to devices in daemon
1047,"<desc> lambda module ansible version ansible 2.3.0 (aws_lambda_empty_env_bugfix 0a42a6fe72) last updated 2017/03/02 13:06:11 (gmt +100) config file = /etc/ansible/ansible.cfg configured module search path = default w/o overrides this adds a test case which demonstrates a bug when creating a new lambda function without giving the environment.  then it fixes the case. bug doesn't yet exist. before: ""msg"": ""parameter validation failed:\ninvalid type for parameter environment.variables, value: none, type: <type 'nonetype'>, valid types: <type 'dict'>"" after: works as normal </desc> <cmt> lambda module - failing test case: shows lambda create mishandles empty environment </cmt> <cmt> lambda module - fix lambda create with empty environment </cmt>",aws lambda empty env bugfix
1048,"<desc> part of #4148 please doublecheck on review </desc> <cmt> move code from borg.helpers.usergroup to borg.platform.posix </cmt> <cmt> remove posix issues and fixup for unsupported methodes </cmt> <cmt> remove unneded code and remarks, added needed except clause </cmt>",remove posix issues and add fixups for unsupported methods. (ex. #4154)
1049,<desc> fixes ansible/ansible-modules-core#2218 add example in documentation for using --user in pip module. no new module argument is needed. pip ansible version devel (ansible 2.4.0) </desc> <cmt> state type of arguments explicitly </cmt> <cmt> add example for --user argument </cmt> <iss> improve documentation and maybe api to support pip --user </iss>,add example for --user in pip module
1050,"<desc> related issue: none i am a new developer trying to develop a 3d viewer with three.js. while reading the korean manual of three.js, i found that the link was broken. so, i fixed the broken link in the korean manual. </desc> <cmt> docs: fixed broken link in manual for korean </cmt> <cmt> docs: fixed broken link in manual for korean </cmt>",fixed broken link in korean manual.
1051,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> support events qualified for multiple conditions. </cmt> <cmt> currently windowfunnel function only take the first qualified condition </cmt> <cmt> into account when operating on one event. this patch extends the </cmt> <cmt> ability. </cmt> <cmt> fixed tests </cmt>,support events qualified for multiple conditions in window funnel
1052,"<desc> as discussed in issue 3167 (#3167), replacing .todense() with .toarray(). need to review in additional detail for any matrix-specific notation/operators/indexing, e.g., matrix mult or sums/means along axis. </desc> <cmt> replacing the non-test .todense() methods with .toarray() </cmt> <cmt> replacing the test .todense() methods with .toarray() </cmt>",issue 3167 to eradicate .todense()
1053,"<desc> as explained in a lot more detail in #67053 this makes const-qualification not ignore the unstable const fns in libcore. r? @oli-obk  (still a bit unsure about the cfgs here, for bootstrapping, does that seem correct ?) fixes #67053. </desc> <cmt> make const-qualif look at more const fns </cmt> <cmt> the unstables ones in libcore, with the unstable feature disabled, were not checked </cmt> <cmt> libcore: rnable 2 unstable const fn features </cmt> <cmt> so that we can bootstrap successfully </cmt> <cmt> add regression test for issue 67053 </cmt> <iss> unstable  `const fn`s in `libcore` can be ignored by const-qualification </iss>",make const-qualification look at more const fns
1054,<desc> fixes #2849 </desc> <cmt> redux visualize modal </cmt> <cmt> redux visualize modal </cmt> <cmt> - apply redux </cmt> <cmt> - add unit test for connect container component </cmt> <cmt> - fix lint error </cmt> <cmt> add unit tests for visuaizemodal </cmt> <cmt> add unit tests for visualizemodal component </cmt> <cmt> # conflicts: </cmt> <cmt> #	superset/assets/javascripts/sqllab/actions.js </cmt> <iss> [js-testing] write more tests for javascripts/sqllab/components/visualizemodal.jsx </iss>,improve visualize modal test coverage
1055,<desc> create a new method to clear pending http requests and http responses in the httpclient. included ways to set a function to filter what needs to be cleaned included some tests on the cpp_tests </desc> <cmt> added functionality to clear pending responses and requests in the http client </cmt> <cmt> responses and requests now are processed in similar way </cmt> <cmt> fix for clearing the http requests </cmt> <cmt> added tests for httpclient::clearresponseandrequestqueue </cmt>,add clear request and responses method to httpclient
1056,<desc> implements #2081 added new tests to exercise this code. also did some refactoring to make the code smaller. </desc> <cmt> add initial implementation of constraint percentage width / height support. added tests for dom sizing methods. </cmt> <cmt> use watchify for incremental test rebuilds </cmt>,allow percentages as the max-width/max-height of the container
1057,"<desc> update aliases on integration tests: enable dpkg_selections test. enable nuage_vspk test. the test fails on centos6. enable vmware_maintenancemode test. enable azure_rm_deployment test. mark aws_waf_web_acl test unsupported. various integration tests ansible version ansible 2.6.0 (update-tests d506d7b57d) last updated 2018/04/03 23:21:17 (gmt -700) config file = none configured module search path = [u'/users/mclay/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/mclay/code/mattclay/ansible/lib/ansible executable location = /users/mclay/code/mattclay/ansible/bin/ansible python version = 2.7.14 (default, mar 22 2018, 11:39:16) [gcc 4.2.1 compatible apple llvm 9.0.0 (clang-900.0.39.2)] </desc> <cmt> enable dpkg_selections test. </cmt> <cmt> enable nuage_vspk test. </cmt> <cmt> enable vmware_maintenancemode test. </cmt> <cmt> enable azure_rm_deployment test. </cmt> <cmt> mark aws_waf_web_acl test unsupported. </cmt>",update aliases on integration tests.
1058,<desc> add support for port security timeout for aci interface policy port security network module aci library : _aci_intf_policy_port_security aci_interface_policy_port_security: host: '{{ inventory_hostname }}' username: '{{ username }}' password: '{{ password }}' port_security: '{{ port_security }}' description: '{{ descr }}' max_end_points: '{{ max_end_points }}' port_security_timeout: '{{ port_security_timeout }}' .   <-- new option added delegate_to: localhost </desc> <cmt> adding support for port security timeout attribute for aci interface policy port security </cmt> <cmt> - feature pull request </cmt> <cmt> network module aci </cmt> <cmt> lib:  _aci_intf_policy_port_security.py </cmt> <cmt> fixing missing quotes </cmt>,adding port security timeout option in interface policy port security
1059,"<desc> just another repr change we could consider for 1.14. before: >>> np.array([true, false]) array([true, false], dtype=bool) after: >>> np.array([true, false]) array([true, false]) the first commit would be useful within np.ma whether or not the second is desirable. </desc> <cmt> maint: add helper function to determine whether to show dtype in repr </cmt> <cmt> enh: don't show boolean dtype, as it is implied </cmt>",don't show the boolean dtype in array_repr
1060,"<desc> hi, this fixes #3643. also, qualities where compared by string value, so in case of qualities ['101', '9'], '9' would be selected as the higher quality. f931e25 fixes that. </desc> <cmt> [tudou] fix #3643 - filter non-number qualities </cmt> <cmt> [tudou] sort qualities by numeric value </cmt> <iss> keyerror: 'k' </iss>",tudou fix #3643 and quality sorting
1061,<desc> fixes a crasher on the tuplecontextualfailure when involving optional tuple type. it also resolves a duplicated diagnostic when it diagnoses the mismatch in ignoreassignmentdestinationtype/contextualmismatch and allowtuplemismatch.  resolves sr-12869. </desc> <cmt> [csfix] adjusting tuple mismatch to handle optionals </cmt> <cmt> [tests] adding regression tests for sr-12869 </cmt> <cmt> [cssimplify] do not record ignoreassignmentdestinationtype or contextual if we already record a tuple mismatch </cmt> <cmt> [csdiagnostics] adjust tuple contextual mismatch diagnostics to handle subscript assign to source </cmt> <cmt> [tests] adjusting sr-12869 test cases for optional mismatches </cmt>,fixes assertion hit on tuplecontextualfailure involving optional tuple type
1062,"<desc> updated createtopicresponse, deletetopicsrequest/response and added some new adminclient methods and classes. now the newly created topic id will be returned in createtopicsresult and found in topicandmetadataconfig, and topics can be deleted by supplying topic ids through deletetopicswithids which will return deletetopicswithidsresult. </desc> <cmt> returns topic id in createtopicsresponse </cmt> <cmt> deletetopicsrequest allows for specifying topic ids </cmt> <cmt> fix some typos, correctly add/remove topic ids in mockadminclient, fix comments </cmt>","add support for returning topic ids on create, supplying topic ids for delete"
1063,"<desc> this completely removes calculate_hashes and moves all test code into fixtures that asserts on hashes. this is the last step before the code can be moved away from the interfaces entirely. </desc> <cmt> tests(grouping): remove outdated test </cmt> <cmt> this test says its important but it tests something that no longer makes </cmt> <cmt> sense.  the http interfaces has not been participating in tests for a </cmt> <cmt> long time now and the original commit that introduced this test suggests </cmt> <cmt> that it played a role once (c272c63f2b4393c0aca8f2342b96bdd3e8964f7e). </cmt> <cmt> i believe it is safe to remove because whatever the bug was, its no </cmt> <cmt> longer important. </cmt> <cmt> feat(grouping): removed some of the new unused grouping code </cmt>",remove some of the now unused grouping code
1064,"<desc> this pr is a first step to refactor and unify the authentication chain. an authenticator interface is extracted for following concrete authenticators (listed in decreasing priority): service token oauth2 token api key realms before runnning the above authenticators, existing authentication from threadcontext is always checked first. after running the authenticators, fallback, anonymous and lookup users are checked more consistently. failed authentication with either oauth2 token or api key now reports the attempted and failed credentials instead of ""missing credentials"". out of the above authenticators, the realmsauthenticator has its own sub-chain. technically, this sub-chain can also be flattend and be part of the main chain. but it's impractical to do so without also changing the existing behaviour. though the change makes sense imo, it adds a lot complexities of the pr. so it is better to be left as future work. a few notes for review: the error reporting for unsuccessful credentials is done with the metadata of elasticsearchsecurityexception. i am not tied to this approach. it is picked because its simplicity and being non-intrusive for keeping the existing behaviours (e.g. auditing). the existing authenticationservicetests still has the most test coverage for the newly extracted classes. i added a few new test classes as well. i can (and probably will) add more, please let me know. the pr is intentionally kept limited to avoid making the review too tricky. it tries to match the existing behaviours as much as possible even though some of them are debatable. i plan to have a few follow-up prs to complete the task. the followings list a few things to work on in the future prs: the logic of null token handling. null token handling includes both fallback and anonymous user. current behaviour is rather odd as it somehow ties to whether a token can be extracted by realms. but it can be argued that fallback user should not be allowed if a token can be extracted by any of the authenticators. indeed, anonymous user effectively works this way though the code makes it a bit harder to follow. runas user. the pr intentionally restricts run-as to realm authenticated users to matching existing users. but this restriction is no longer necessary with the refactoring. unify existing authenticationresult and the new authenticator.result. these two classes share a lot similarity and can be unfied using java generic. i didn't do it because it will touch a lot files just because of the signature change. it's better to be done as its own pr. flatten the realm chain. this will result in behaviour change. for example, currently, only a single realm can extract the authentication token. so if username/password fails to authentication, pki realm will not work even when the connection has valid setup. if the realm chain is falttened and individual realm works the same way as other authentictors, all of them will get a chance to extract its own authentication token. (exactly how this works is still subject to discussion because one can also argue allowing multiple authentication tokens to be extracted is a form of leniency). relates: #75607 </desc> <cmt> working main code. broken tests. </cmt> <cmt> fixed existing tests </cmt> <cmt> add new tests. </cmt>",unify authc chain - 1. authenticator extraction
1065,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> update for draft js 0.9.0 </cmt> <cmt> update tests </cmt>",update definitions for version 0.9.0
1066,"<desc> contact center room info rocket.chat.2.mp4 </desc> <cmt> create new contextualbar </cmt> <cmt> room info new contextual bar, direct room button </cmt> <cmt> show agent and contact and chat history at contacts tab. </cmt> <cmt> inactivity time, queue time and topic fields with some translations. </cmt>",re-design omnichannel room info panel
1067,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added a feature to download images. </cmt> <cmt> minor changes </cmt>,can download the apod image to a specified location on disk.
1068,<desc> brings the concept of extension under deb and extension tests to the web extension host. additions to the workbench embedder api: istaticextension: new property isunderdevelopment iworkbenchconstructionoptions: extensiontestspath the extensiondevelopmentpath is computed based on istaticextension.isunderdevelopment alternative api would be: iworkbenchconstructionoptions staticextensions staticdevextensions extensiontestspath </desc> <cmt> tests in web extension host </cmt> <cmt> add extensiontestspath to iworkbenchconstructionoptions </cmt>,support running extension tests in browser workbench
1069,"<desc> bug fixes apis fix the corner case when the function has argument shape constructed by list with tensor and int like the following case. import paddle import numpy as np size_a = paddle.to_tensor(np.array(1)) paddle.zeros(shape=[size_a, 100], dtype=""float32"") it runs well in pytorch import torch import numpy as np size_a = torch.from_numpy(np.array(1)) torch.zeros(shape=[size_a, 100], dtype=""float32"") </desc> <cmt> fixed corner case in fill_constant </cmt>",fixed corner case in all shape function
1070,"<desc> previously, if you copied a signature from a trait definition such as: fn foo<'a>(&'a bar) -> bool {} and moved it into an impl, there would be an error message: ""unexpected token 'a"" adding to the error message that a pattern is expected should help users to find the actual problem with using a lifetime here. </desc> <cmt> libsyntax: better error for lifetimes in patterns </cmt> <cmt> previously, if you copied a signature from a trait definition such as: </cmt> <cmt>  </cmt> <cmt> fn foo<'a>(&'a bar) -> bool {} </cmt> <cmt>  </cmt> <cmt> and moved it into an impl, there would be an error message: </cmt> <cmt> ""unexpected token 'a"" </cmt> <cmt> adding to the error message that a pattern is expected should help </cmt> <cmt> users to find the actual problem with using a lifetime here. </cmt> <cmt> libsyntax: remove panics from parser::parse_pat_nopanic </cmt> <cmt> libsyntax: consolidate branch to benefit from exhaustive checking instead of unwrapping </cmt>",improve error message for lifetimes in patterns
1071,"<desc> adds a size parameter to splitpane. this takes a float, and specifies the portion of the parent pane that should be used to create the new one. this also adds the param to the split-pane subcommand. examples commandline result wt ; sp -s .25 wt ; sp -s .8 wt ; sp -s .8 ; sp -h -s .3 closes #6298 i work here docs pr: microsoftdocs/terminal#208 i went with size, --size,-s rather than percent, because the arg is the (0,1) version of the size, not the (0%,100%) version. added actions, played with the commandline, ran tests </desc> <cmt> add a size param to splitpane to control the size of the created pane </cmt> <cmt> add to the commandline args too </cmt> <cmt> you know what else everybody likes? tests. have you ever met a person, you say, 'let's add some tests,' they say, 'heck no, i don't like no tests'? </cmt> <iss> `wt.exe` should support `-%,--percent` for setting a pane's size on the commandline </iss>","add size param to splitpane action, split-pane subcommand"
1072,"<desc> change this change better ensures the chain of trust when using a packaged index by: ensuring that the index package does not change family names ensuring that the default source is store signed using signed data from the package to verify the manifest files that we download separately validation new tests are added, but many existing tests also covered the scenarios. microsoft reviewers: open in codeflow </desc> <cmt> ensure package integrity </cmt> <cmt> minor change to ensure that we don't fail things if the windows api fails </cmt> <cmt> add manifest hash to index and verify on retrieval </cmt> <cmt> fix spelling </cmt>",ensure chain of trust with packaged index
1073,<desc> create top level task that covers all s3 3rd party tests to be able to run all of them from a single jenkins job and add more tasks as needed without modifying jenkins. adjust snapshot cli test tool's tests to work with real s3 build adjustment to the cli tool tests also differentiate between real s3 credentials being available or not clean up repo path before testing dedup the logic for asserting path contents by using the correct utility method here that somehow became unused </desc> <cmt> start </cmt> <cmt> create s3 third party test task that covers the s3 cli tool </cmt> <cmt> * create top level task that covers all s3 3rd party tests </cmt> <cmt> * adjust snapshot cli test tool tests to work with real s3 </cmt> <cmt> * build adjustment </cmt> <cmt> * clean up repo path before testing </cmt> <cmt> * dedup the logic for asserting path contents by using the correct utility method here that somehow became unused </cmt>,s3 3rd party test goal
1074,<desc> replace the deprecated predicate option with the new match option. this helps improve the readability of tests without sacrificing the custom logic used in performance tests. </desc> <cmt> ref(tests) remove usage of mockapiclient predicate </cmt> <cmt> replace predicate callables with the new match behavior. this helps </cmt> <cmt> reduce bloat in tests and makes tests more readable. </cmt> <cmt> make request matching more efficient. </cmt> <cmt> don't do comparisons we don't need to as we know the match won't work. </cmt>,ref(tests) replace usage of predicate in mockapiclient
1075,"<desc> bump go.d.plugin version to v0.26.0 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.26.0 </desc> <cmt> packaging: bump go.d version to v0.26.0 </cmt> <cmt> packaging: update go.d checksums </cmt>",update go.d.plugin version to v0.26.0
1076,"<desc> add some test speedups, potentially decrease flakiness decrease network calls include artifacts fix requirementslib bug silently handle empty or nonetype extras fixes #3283 </desc> <cmt> add pyinstaller </cmt> <cmt> silently handle empty or nonetype extras </cmt> <cmt> - fixes #3283 </cmt> <cmt> potentialy speed up tests, decrease network calls"" </cmt>","speed up tests, silently handle empty and nonetype extras"
1077,"<desc> risk level: low bazel --nohome_rc build --jobs 12 --ui_actions_shown 12 @envoy_api_canonical//envoy/... docs/build.sh docs changes: none required release notes: none required comment: will enable addition of api dependencies in follow up to #13340 / </desc> <cmt> dependencies: refactor api dependencies, add remaining pip hashes. </cmt> <cmt> update json in proto and fixup docs requirement.txt </cmt>","refactor api dependencies, fix proto json block, finish pip install hashes"
1078,"<desc> open: no such file or directory that's not a very descriptive error. this pr improves the error message and points out the most likely solution (that the user should recompile the kernel with enable_kernel_coverage_collection=on), as well as fixes systemserver support for this special device. </desc> <cmt> systemserver+kcov-example: make /dev/kcov0 available again </cmt> <cmt> apparently this device entry got lost while converting to devtmpfs. </cmt> <cmt> kcov-example: print helpful error if kcov feature is missing </cmt>","make /dev/kcov0 available again, improve error message if missing"
1079,"<desc> startatzeroenabled should not actually start at zero when there are negative values, as these will be unaccessible in radar charts, when values are drawn below zero, they are actually draw in another x-index as it is a circular chart. so no we handle that correctly in (hopefully) all cases of startatzeroenabled = true/false </desc> <cmt> handle negative values when startatzeroenabled </cmt> <cmt> prevent yaxis in radar charts from bleeding into another x index on the other side </cmt>",fixes for the y axis with negative values
1080,"<desc> there were a lot of simple errors with railties' gem code causing exceptions to be raised when starting a rails 2.3 app with rubygems 1.8.x installed. this fixes those errors. this should also address nearly all deprecations. i still need to work the use of sourceindex out of it, but that can come later. </desc> <cmt> fix stupid emacsisms. just makes things more readable. </cmt> <cmt> fix broken gemdependency#==. you should always check the class! </cmt> <cmt> removed buggy gemdependency#requirement override. overrides should never change the semantics of the parent (returning nil if default). </cmt> <cmt> fixed buggy gem activation. don't pass a dependency to gem, pass the </cmt> <cmt> name and requirement. better, just activate the spec for the </cmt> <cmt> dependency (1.8 only) </cmt> <cmt> removed the bulk of the deprecations by simply not calling refresh. </cmt> <cmt> this may cause problems. i dunno. </cmt> <cmt> the real solution is to get rid of all of this mess and use gem paths properly. </cmt>",fix several of the rubygem issues in rails 2-3-stable.
1081,"<desc> this pr adds the following predefined mapped types to lib.d.ts: // make all properties in t optional type partial<t> = { }; // make all properties in t readonly type readonly<t> = { readonly [p in keyof t]: t[p]; }; // from t pick a set of properties k type pick<t, k extends keyof t> = { } // construct a type with a set of properties k of type t type record<k extends string | number, t> = { } the pr also property implements the identity relation for mapped types. </desc> <cmt> properly handle identity relation for mapped types </cmt> <cmt> add predefined mapped types and revise object.freeze </cmt> <cmt> revise tests </cmt> <cmt> accept new baselines </cmt>",predefined mapped types in lib.d.ts
1082,<desc> i've added a little utility function making it easier to use different interpolation methods on the math vectors. this is an adition to the lerp(...) method which only supports linear interpolation. i used the new method name for clarity and to avoid breaking the api. i've also adapted the vector2dtest a bit to show it works in there as well. </desc> <cmt> added interpolate(...) to vector classes to integrate interpolation types to vectors </cmt> <cmt> added missing comments </cmt>,added vector#interpolate(...) method to integrate different interpolation methods for vectors.
1083,<desc> recordings contained in nested recording folders (and the folders itself) are not displayed any longer in non-flattened recordings window view. regression introduced by #9105 brought up in the forum:  @milhousevh ping </desc> <cmt> [pvr] recordings window: fix nested folders not working in non-flattened view. </cmt> <cmt> [pvr] cpvrrecordingspath: fix url validation </cmt> <cmt> [pvr] cpvrrecordingspath: remove init() memeber function </cmt>,fix recordings in nested folders not displayed
1084,"<desc> in this pull request, i am making the changes proposed by @aaudiber in the review of #31897 related issue: #31698 thanks @aaudiber for the review. </desc> <cmt> remove trailing whitespace </cmt> <cmt> improve explanation of shard </cmt>",improve documentation for dataset shard
1085,"<desc> fix #10472 depended on if we will merge master to release-2.0, i will cherry-pick the change in as appropriate </desc> <cmt> properly emit await expression with yield expression </cmt> <cmt> add tests and update baselines </cmt> <cmt> move parsing await expression into parse unary-expression </cmt>",invalid emitted code for await expression
1086,"<desc> add tests for various sub-modules that modify the options object, verifying that they call previous options </desc> <cmt> verify hooks calls old options </cmt> <cmt> move option spy helper to general test util </cmt> <cmt> add tests verifying debug & devtools call old options </cmt> <cmt> improve compat coverage </cmt> <cmt> skip an untested line </cmt> <cmt> improve coverage of debug </cmt> <cmt> fix linting rules </cmt> <cmt> add test for compat calling old options </cmt> <cmt> use getdisplayname in hook warnings </cmt>",improve code coverage and fix lint warnings
1087,<desc> see #4330 . ensures instance referenced by websocketmodule stays valid. microsoft reviewers: open in codeflow </desc> <cmt> prevent invalid access to websocketmodule::getinstance </cmt> <cmt> clang format </cmt> <cmt> change files </cmt> <cmt> early return if instance cannot be locked </cmt> <cmt> pass weak resource pointer to resource-owned lambdas </cmt>,ensure react instance reference lifetime in websocketmodule
1088,"<desc> my prs clobbered #24855, so i'm rewriting it from master. this fixes a bug when users disabled alerts for all projects in their user settings (before fine-tuning it per project). if ""default"" or ""on"" was selected for the project in fine-tuning, alert notifications would still be sent to issue owners and/or teams that user was part of. fixes wor-140 </desc> <cmt> test that disabled_users_from_project respects project-independent preferences </cmt> <cmt> check both fine-tuning and default notification settings. </cmt>",respect user's notification settings defaults
1089,"<desc> this resolves the off method incorrectly being named on and also fixes all instances of callbacks which lacked the parameters used. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> fix problems in localizejs library typings </cmt> <cmt> this resolves the off method incorrectly being named on and also fixes all instances of callbacks which lacked the parameters used. </cmt>",fix problems with typings (specifically callback parameters)
1090,"<desc> this pr contains a couple fixes for computing the height of block elements when it isn't specified in the css. in particular, on xkcd.com, the two boxes behind the navigation links and logo previously had a computed height of 0. i think formattingcontext::compute_height_for_absolutely_positioned_non_replaced_element needs some more work to be compliant with section 10.6.4 of the height property spec, but now it at least handles rule 5 of that section. before: after: </desc> <cmt> libweb: consider floating children when computing auto-height </cmt> <cmt> the case for computing auto-height of block elements which have block- </cmt> <cmt> level children was erroneously skipping some children: </cmt> <cmt> 1. if the block element itself is absolute or floating, all children </cmt> <cmt> were skipped due to a likely typo (""box"" vs. ""child_box"" inside the </cmt> <cmt> for-each loop). </cmt> <cmt> 2. floating children should only be skipped if the block element's </cmt> <cmt> 'overflow' property computes to 'visible', per section 10.6.3 of the </cmt> <cmt> css height property spec. if the property computes to another value, </cmt> <cmt> section 10.6.7 only indicates that absolutely positioned children </cmt> <cmt> should be skipped. </cmt> <cmt> libweb: compute height of absolutely positioned blocks when possible </cmt> <cmt> section 10.6.4 rule 5 of the css height property spec outlines a method </cmt> <cmt> to compute the height of an absolutely positioned block when the 'top' </cmt> <cmt> and 'bottom' css properties are specified. </cmt>",css auto-height property computation fixes
1091,<desc> watch for changes in type roots and reload the project when that happens. only tested in vs code so far </desc> <cmt> working version </cmt> <cmt> cleanup </cmt> <cmt> fixup </cmt> <cmt> remove unused </cmt> <cmt> always return [] </cmt> <cmt> refactor </cmt> <cmt> cleanup </cmt>,watch for changes in types roots
1092,"<desc> this is fixing a regression from the perf changes in 60aebbe  (where we don't call setlayoutprops on every element in every update anymore). with self layout elements, we clear the width/height when measuring.  in incremental update items are usually still measured but if the values are the same as before, setlayoutprops isn't called now.  this fix puts back whatever width/height was there before the clear to maintain previous layout. alternatively we could mark self measure nodes as always dirty in self measure, in the case where things do update we are doing more work now, but in the incremental case this is probably preferred (and we don't want to generate extra onlayout events) also, updated our yoga debug printing helper to log full info.  i couldn't see the relevant part of the tree in our app i was debugging with the existing ~4k output it was getting truncated at. microsoft reviewers: open in codeflow </desc> <cmt> update yoga logging to display the entire tree, update comments on turning it on for new yoga version </cmt> <cmt> save and restore width in defaultyogaselfmeasurefunc </cmt>",self layout elements not always visible after an update
1093,"<desc> this pr prevents .contains from yielding you a <style> element. note however that if the style is inside the body, then the body will be yielded (same as <script>) closes #2119 pre-merge tasks have tests been added/updated for the changes in this pr? has the original issue been tagged with a release in zenhub? </desc> <cmt> filter out style elements from .contains </cmt> <cmt> formatting </cmt> <iss> cy.contains finds text in invisible tags </iss>",prevent .contains from finding <style> tags
1094,"<desc> yargs treats the --version parameter specially, unless you turn off its built in logic. this fixes the versions parameter, which is currently being ignored. microsoft reviewers: open in codeflow </desc> <cmt> fix version parameter </cmt> <cmt> change files </cmt>",fix version parameter on react-native-windows-init
1095,"<desc> so it's entirely possible that i'm doing this entirely wrong, buuut i noticed that (the apparently deprecated) selectors, used only on os x, don't map completely to their replacements in role. specifically, pasteandmatchstyle and delete don't seem to map to anything. there may be other mappings we're missing here too, which i'd be happy to add. </desc> <cmt> map selectors for delete and pasteandmatchstyle to roles </cmt> <cmt> map webcontents.delete to role </cmt>",map missing selectors to roles
1096,<desc> fixes #13434. upgrade atomikos version to 5.0.8 to eliminate new xaconnection created on registerresource update atomikos version in license remove duplicated atomikos dependencies </desc> <cmt> datasourcewrapper close check </cmt> <cmt> remove duplicated logger appender </cmt> <cmt> upgrade atomikos version to 5.0.8 to eliminate new xaconnection created on registerresource </cmt> <cmt> remove duplicated atomikos dependencies </cmt> <cmt> update atomikos version in license </cmt> <iss> sharding scaling datasource connection is not released when execute check scaling xxxx command </iss>,upgrade atomikos version to eliminate xaconnection createation on registerresource
1097,<desc> fixes source toggle tooltip being shown on small screens ddd71da fixes tooltip being show in front of app bar 750d03a i think this is the simplest solution. determining what the best position should be would be very brittle. this should cover most edge cases. there are only a couple of pixels in which no indication of a tooltip would be visible. </desc> <cmt> [docs] fix demo source tooltip being shown on small screens </cmt> <cmt> [docs] show demo actions tooltip below app bar </cmt>,fix minor issues with demo action tooltips
1098,<desc> i hereby agree to the terms of the cla available at:  detailed description / documentation draft: documentation about disable any right and any full joins by default. added description of the partial_merge_join_optimizations and partial_merge_join_rows_in_right_blocks settings. added description of temporary_files_codec and join_on_disk_max_files_to_merge settings. update clickhouse-copier.md. </desc> <cmt> docsup-203: update by pr#11558. </cmt> <cmt> docsup-2031: update by pr#11242. added temporary_files_codec and join_on_disk_max_files_to_merge settings. </cmt> <cmt> docsup-2031: update by pr#1130 </cmt> <cmt> added description of the partial_merge_join_optimizations and partial_merge_join_rows_in_right_blocks settings. </cmt> <cmt> docsup-2031: update by pr#11065 disable any right and any full joins by default </cmt>,edit and translate pr to russian.
1099,"<desc> this pr is collection of commits required to prepare for the switch to rocm 3.5 (or higher, from the current rocm 3.3 being used by the master branch). starting with rocm 3.5 the underlying compiler used by hipcc will change from hcc to hip-clang. there will be a corresponding change in the hip runtime as well. the idea behind this pr is to make the transition to rocm 3.5+ seamless. / </desc> <cmt> prepping for switch to rocm 3.5+ </cmt> <cmt> starting with rocm 3.5 the underlying compiler used by hipcc will change from hcc to hip-clang. there will be a corresponding change in the hip runtime as well. this commit is part of a series which are intended to make the transition to rocm 3.5+ easier. </cmt> <cmt> this commit adds an alternative lookup path for ld.lld (since its location within the rocm install, will move in rocm 3.5+). </cmt> <cmt> prepping for switch to rocm 3.5+ </cmt> <cmt> starting with rocm 3.5 the underlying compiler used by hipcc will change from hcc to hip-clang. there will be a corresponding change in the hip runtime as well. this commit is part of a series which are intended to make the transition to rocm 3.5+ easier. </cmt> <cmt> the path to the rocdl files changes with rocm 3.5, and hence this change. </cmt> <cmt> the macro tensorflow_compile_is_hip_clang is only true when compiling tf with rocm 3.5 and higher. the macro is a temporary construct to aid with the transition. once the transition is complete, it will removed and the code updated appropriately. </cmt>",prepare for switch to rocm 3.5
1100,"<desc> fixes #15076. adds an argument, pass_through, to the base stacking estimator. this allows for concatenating the original dataset x with the output from all individual estimators for use in training the final_estimator. i added tests but haven't been able to check them throughly. i haven't been able to get even the existing tests to run since calling (even on the master branch) pytest sklearn/ensemble/tests/test_stacking.py returns the below error. _______ error collecting sklearn/ensemble/tests/test_stacking.py _______ importerror while importing test module '.../scikit-learn/sklearn/ensemble/tests/test_stacking.py'. hint: make sure your test modules/packages have valid python names. traceback: sklearn/ensemble/__init__.py:7: in <module> from .forest import randomforestclassifier sklearn/ensemble/forest.py:56: in <module> from ..tree import (decisiontreeclassifier, decisiontreeregressor, sklearn/tree/__init__.py:6: in <module> from .tree import decisiontreeclassifier sklearn/tree/tree.py:44: in <module> from ._tree import _build_pruned_tree_ccp e   importerror: cannot import name '_build_pruned_tree_ccp' i've looked around for a little and am not too sure how to resolve this -- does anyone have any suggestions? </desc> <cmt> add pass through argument </cmt> <cmt> update docstring </cmt> <iss> stacking: add an option to use the original dataset when training final_estimator </iss>",pass original dataset to stacking final estimator
1101,"<desc> the rails testing infrastructure is built on minitest, but there are some rough edges if you want to use the spec dsl. currently its not possible to have a nested describe on a controller test. describe widgetscontroller, :index do describe ""authenticated user"" do it ""is accessible"" do assert_response :success this request makes this possible by adding the ability to resolve constants from the test name. it also includes additional spec registration for mailer, helper, and integration tests. oh, and a bunch of tests too. (all of this code was taken from minitest-rails.) fixes #7748 </desc> <cmt> create activesupport::testing::constantlookup </cmt> <cmt> as::tc::constantlookup walks the test's name to find the constant it is describing. </cmt> <cmt> this additional lookup logic is needed to better support minitest's spec dsl. </cmt> <cmt> support controller tests using spec dsl - fixes #7743 </cmt> <cmt> add tests for controller tests using the minitest spec dsl. </cmt> <cmt> allow strings in the controller test describe blocks </cmt> <cmt> allow controller tests using the spec dsl to match strings. </cmt> <cmt> add test coverage for the register_spec_type calls. </cmt> <cmt> add register_spec_type test coverage </cmt> <cmt> register mailer tests for minitest's spec dsl </cmt> <cmt> support mailer tests using spec dsl </cmt> <cmt> improve how mailer tests to resolve mailers from the test name. </cmt> <cmt> add tests for mailer tests using the minitest spec dsl. </cmt> <cmt> register helper and view tests for minitest's spec dsl </cmt> <cmt> support helper tests using spec dsl </cmt> <cmt> improve how helper tests to resolve the helper class from the test name. </cmt> <cmt> add tests for helper tests using the minitest spec dsl. </cmt> <cmt> register ad::integrationtest for minitest's spec dsl </cmt>",improve support for minitest's spec dsl
1102,"<desc> summary closes #7617 . this pr is an update of #7617. credit goes to @sameermanek for his work. the goal of the pr is to be able to see the metrics and losses in a per-batch basis instead of a per-epoch basis. related issues #6692 pr overview this pr is backward compatible a new argument has been added to the constructor of the tensorboard callback. here is the description that i added in the docs: write_step: 'batch' or 'epoch' or integer. when using 'batch', writes the losses and metrics to tensorboard after each batch. the same applies for 'epoch'. if using an integer, let's say 10000, the callback will write the metrics and losses to tensorboard every 10000 samples. note that writing too frequently to tensorboard can slow down your training. feedback welcome. especially from @fchollet  since the api has been changed. this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> working on improving tensor flow callbacks </cmt> <cmt> adding batch level tensorboard logging (implementing the on_batch_end method to the tensorboard class </cmt> <cmt> interim commit -- added notes. </cmt> <cmt> updating to master </cmt> <cmt> # conflicts: </cmt> <cmt> #	keras/callbacks.py </cmt> <cmt> #	tests/keras/test_callbacks.py </cmt> <cmt> corrected stylistic issues -- brought to compliance w/ pep8 </cmt> <cmt> added the missing argument in the test suite. </cmt>",write to tensorboard every x samples.
1103,"<desc> also should resolve #1384 and removes the intellijannotations </desc> <cmt> add support annotations on public apis, remote intellij annotations </cmt> <cmt> allow null path in invalidate() to match load() </cmt> <cmt> part of #1384 </cmt> <cmt> add missing nullchecks and fix a couple res annotations </cmt> <cmt> finishes #1384 </cmt> <iss> more consistent null input checks </iss>",switch to support annotations on public apis where appropriate
1104,<desc> closes #4506 cleans up the environment variable to be used as file path cypress_install_binary see windows difficulties #4506 (comment) </desc> <cmt> fix: trim and remove double quotes around cypress_install_binary </cmt> <cmt> linting </cmt> <cmt> add one more unit test for dequote </cmt> <iss> cypress not installing using local zip on windows </iss>,clean env variable cypress_install_binary before checking
1105,"<desc> master is ahead of develop, oh joy. </desc> <cmt> update init.cpp </cmt> <cmt> removed semicolon at the end of the -wallet argument in the help message which was preventing everything below it from showing up. </cmt> <cmt> update init.cpp </cmt> <cmt> dogecoin 1.6 </cmt> <cmt> bumping min peer proto version </cmt> <cmt> to ensure post-fork clients don't get hit with old nodes. </cmt> <cmt> update mac version numbers too </cmt> <cmt> plist contains info, yay! </cmt> <cmt> notching back min proto version. </cmt> <cmt> risk for sync issues, will need to update later. </cmt> <cmt> back out caching changes in cwallettx::getamounts </cmt> <cmt> back out caching changes in cwallettx::getamounts (fix #341) </cmt> <cmt> update to reflect static block rewards change </cmt> <cmt> update to reflect static block rewards change </cmt>",why aren't we pulling into develop?
1106,<desc> updated link to .net core windows server hosting to point to 1.1.0. it was referring to 1.0.1. new link was taken from: </desc> <cmt> update aspnet-core-module.md </cmt> <cmt> updated link to .net core windows server hosting to point to 1.1.0. it was referring to 1.0.1. </cmt> <cmt> new link was taken from: </cmt> <cmt>  </cmt> <cmt> updated link to .net core windows server hosting to point to 1.1.0 </cmt>,update link to .net core windows server hosting to point to 1.1.0
1107,"<desc> suppose the lua files was in following structure: foldera/sample.lua and package with zip command as normal zip file. current lualoadchunksfromzip will load it into _g['preload'] as 'foldera/sample.lua', it will fail to be require with require('foldera.sample'). this patch will remove the extension name (.lua & .luac), and replace folder seperator ('/' '') with '.' . so 'foldera/sample.lua' is changed to 'foldera.sample'. </desc> <cmt> support to loading folder structured lua(a.k.a normal zip file) for lualoadchunksfromzip </cmt> <cmt> fix compile error </cmt>",lua load chunks from zip supports folder structured lua
1108,"<desc> fixes #9343 and re-enables the disabled tests. turns out that the thing that was slowing tests was my last-minute change to isfitter() function to make chromosome comparisons deterministic. the change was a lexicographic comparison if length and fitness of both chromosomes were the same. the worst case scenario for this is a huge population of many long identical chromosomes - and that's exactly the case in the affected tests. the comparison was not very heavy on its own but still much heavier than iterating over a string and it's a very common operation. it involved iterating over the chromosome and looking up every step name in a map. my fix is a refactor suggested at some point by @chriseth - making chromosome store the string of abbreviations rather than a vector of optimisation step names. this way the string conversion is now basically free. the re-enabled tests are now back to running in ~1 second (down from ~70 seconds before refactoring). </desc> <cmt> [yul-phaser] chromosome: add stepstogenes() and genestosteps() </cmt> <cmt> [yul-phaser] chromosome: store step abbreviations instead of full names </cmt> <cmt> revert ""[yul-phaser] temporarily disable very slow tests for the classic algorithm"" </cmt> <cmt> this reverts commit b23f7d879009306c294438ef47b216722d8457ea. </cmt> <iss> tests for the classic genetic algorithm in yul-phaser are very slow </iss>",fix slow tests for classic genetic algorithm
1109,<desc> this also reports error when --out is specified and --module isn't specified resulting it to default to commonjs module generation fixes #8182 </desc> <cmt> report error if user specified --out and we are defaulting to commonjs emit </cmt> <cmt> change the tests for typereference directive tests 11 and 12 to use module gen amd so they can emit correctly </cmt> <cmt> fixes #8182 </cmt> <cmt> test case when --out is specified for compiling module but --module isnt specified </cmt>,fix type reference directive tests by adding --module amd
1110,"<desc> right now the page is pretty useless (i know i'm not the only one who agrees), and a faq would definitely be a bit more searchable. this closes #3753 this closes #3630 this closes #3034 this closes #920 this closes #3526 </desc> <cmt> set up initial page with some questions </cmt> <cmt> right now this sets up the new faq/options page with most of the </cmt> <cmt> questions for the how to control the selection. not all of these </cmt> <cmt> questions have answers, most of them weren't moved over, but there are </cmt> <cmt> plans to add detailed answers to all of them. </cmt> <cmt> the questions were aggregated based on common stack overflow and irc </cmt> <cmt> questions, as well as commonly asked things on github. </cmt> <cmt> continue building out the faq </cmt> <cmt> this adds more questions that will eventually get answers. most of these </cmt> <cmt> questions are already answered either in the current documentation or on </cmt> <cmt> stack overflow, so it shouldn't be too difficult to fill out answers for </cmt> <cmt> them. </cmt> <cmt> added section for events </cmt> <cmt> both public jquery events and internal select2 events will be </cmt> <cmt> documented. </cmt>",switch option page to faq in docs
1111,"<desc> this fixes a few race conditions where ray's autoscaler creates a file/dir and then sets permissions on it. in order to avoid exposing the contents of these files the way i think is intended, the permissions need to be set at file creation time. otherwise a well-timed viewer could open a file handle before permissions were set and then read/write after the contents were written to disk. i've run scripts/format.sh to lint the changes in this pr. i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> private keys should have the right permissions from creation </cmt> <cmt> ssh_control_socket's dir should just get created using os (w/ right permissions) </cmt>",fix filesystem permission race conditions
1112,"<desc> me and @calcsam paired for a day on auditing the tags we have on the blog to cut down on topics that are too specific or redundant. the audit of tags happened on this sheet:  we pulled from key marketing messages that have been outlined in narrowing the tags, the goal was to remove 1/3 of the existing tags but we ended up removing or renaming nearly 50% (from 165 tags to 81) screenshots a popular tags section was added to highlight some commonly used tags: tags page (before) tags page (after) and the tag details pages were updated to include a link back to docs for tags that have docs associated with them: tag details </desc> <cmt> fix: updating tags part 1 </cmt> <cmt> fix: updating tags part 2 </cmt> <cmt> fix more duplicates and capitalization </cmt> <cmt> fix: add more tags, hardcode tags </cmt> <cmt> fix: more tag corrections </cmt> <cmt> add cross-links from blog to docs and docs to blog </cmt> <cmt> fix: linting on tag list, fix duplicate keys, move search bar </cmt>",blog tag audit and overhaul
1113,<desc> closes #16972 this pr will add an additional allow value to the iframe used for bbb: display-capture. </desc> <cmt> allow iframe desktop-capture for bbb </cmt> <cmt> [fix] allow iframe desktop-capture for bbb </cmt> <iss> bbb integration doesn't allow desktop sharing </iss>,allow screensharing in bbb iframe
1114,<desc> add longpress event introduction. add example code. </desc> <cmt> merge update from origin repo </cmt> <cmt> * [gitignore] add .ds_store </cmt> <cmt> * [doc] add selected-color and unselected-color to wxc-tabbar </cmt> <cmt> * [doc] add code block forwxc-tabbar attribute </cmt> <cmt> * [doc] add selected-color and unselected-color to wxc-tabbar (#1086) </cmt> <cmt> * [doc] add longpress event to common-event </cmt>,* [doc] add longpress event to common-event.md
1115,<desc> merge release branch back so that version number changes will be reflected in master branch. #478 </desc> <cmt> revised installation.md (#304) </cmt> <cmt> revised contributing.md (#303) </cmt> <cmt> * revised contributing.md </cmt> <cmt> bump version to 1.0.0 </cmt> <cmt> include version_number file into distribution </cmt> <cmt> remove the negative pad test case (#350) </cmt> <cmt> updating error handling to properly handle the case where git is not installed </cmt> <cmt> version bump </cmt> <cmt> bump conda version number to 1.0.1 </cmt>,merge release branch back to master
1116,<desc> babylonjs is a complete javascript framework for building 3d games with html 5 and webgl. </desc> <cmt> new file:   babylonjs/babylon.2.2.d.ts </cmt> <cmt> new file:   babylonjs/babylonjs-tests.ts </cmt> <cmt> delete babylon.2.2.d.ts </cmt> <cmt> new file:   babylonjs/babylon.d.ts </cmt> <cmt> modified:   babylonjs/babylonjs-tests.ts </cmt> <cmt> update babylonjs-tests.ts </cmt>,add type definition file for babylonjs
1117,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): catch up with en doc, update trainslation of fixedstring. fix the given examples of nullable in zh doc. detailed description (optional): </desc> <cmt> fixed the given examples of nullable in zh doc </cmt> <cmt> update trainslation of fixedstring in zh </cmt>",update trainslation of fixedstring and fix the given examples of nullable in zh doc
1118,"<desc> this is a follow-up to pr #4763, specifically to address #4763 (comment). background: latest xgboost now supports survival regression with accelerated failure time model. the aft model involves maximizing a log likelihood, which is in a fraction form. often, the gradient or hessian value would become inf or nan because the denominator would be far too small. a first attempt to eliminate inf/nan was in #4763, where i replace a small denominator with eps = 1e-16 if the denominator is smaller than eps. it certainly eliminates all inf and nan. also, the gradient is capped to a certain level. problem: replacing the denominator with eps = 1e-16 introduces a bad artifact in the behavior of the gradient and hessian function. for example, the following graph visualizes the gradient of the aft loss function as we vary the predicted label from 1e-2 to 1e4: the gradient value abruptly snaps to zero if the predicted label is set to 1e-2. this is unreasonable, because y_pred = 1e-2 is strictly worse prediction than y_pred = 5.88e-2 but the former would have zero gradient and the latter gradient -20. we do not want this kind of sudden breaks in the graph. more generally, we'd like to precisely define the behavior of the gradient and the hessian functions at extreme values, i.e. when prediction (y_pred) is very small or very large. the graph above should be modified as follows: we catch two rabbits with one stone. no sudden jump. both y_pred = 5.88e-2 and y_pred = 1e-2 are identically set to -15. no exploding gradient. gradient is clipped to -15. (if gradient was positive, we'd clip to 15 instead.) here is how we set gradient and hessian values for very small or large y_pred: distribution uncensored label right-censored label left-censored label interval-censored label y_pred=0 y_pred=inf y_pred=0 y_pred=inf y_pred=0 y_pred=inf y_pred=0 y_pred=inf normal gradient -15 15 -15 0 0 15 -15 15 hessian 1/sigma^2 1/sigma^2 1/sigma^2 1e-16 1e-16 1/sigma^2 1/sigma^2 1/sigma^2 logistic gradient -1/sigma 1/sigma -1/sigma 0 0 1/sigma -1/sigma 1/sigma hessian 1e-16 1e-16 1e-16 1e-16 1e-16 1e-16 1e-16 1e-16 extreme gradient -15 1/sigma -15 0 0 1/sigma -15 1/sigma hessian 15 1e-16 15 1e-16 1e-16 1e-16 15 1e-16 where we clipped large gradients to +15 or -15, depending on their sign, and zero hessians are replaced with 1e-16 because xgboost expects all data points to have nonzero hessians. also: fix a few typos in the aft tutorial. add the aft tutorial to </desc> <cmt> robust regularization of aft gradient and hessian </cmt> <cmt> fix aft doc; expose it to tutorial toc </cmt>",implement robust regularization in 'survival:aft' objective
1119,"<desc> this overrides the postgres docker entrypoint to set it up for cdc. setting it up for cdc means: passing ""-c wal_level=logical -c max_replication_slots=1 -c max_wal_senders=1"", to postgres add a line to pg_hba.conf to enable access to the replication slot if it is not there download wal2json binary if the same version is not already present and installs it. none of these step activates replication or cdc so no additional resource is used. only when we start the cdc service that connects to postgres and creates the replication slot and start the process. now it can be merged safely as the first release of wal2json has been published </desc> <cmt> set up postgres for replication streaming </cmt> <cmt> fix lint </cmt>",feat(cdc) configure postgres for cdc on startup installing wal2json
1120,<desc> summary of changes this is part of issue #3. pulled static factory methods out of lottiecomposition into a static inner class. made all fields final and initialized them all in the constructor. this will make it easier for follow up refactors where we'll modularize the parsing logic and make it pluggable. also upgraded the espresso tests to junit 4 so it no longer uses the deprecated activityinstrumentationtestcase2 testing ran ./gradlew recordmode screenshottests and saw no changes to screenshot files. </desc> <cmt> work in progress </cmt> <cmt> add moved classes </cmt> <cmt> merges with master </cmt> <cmt> fix usage of factory methods </cmt> <cmt> update tests to junit 4 </cmt>,pull out lottiecomposition factory methods into inner class
1121,"<desc> first half of #52545. everybody_loops is used by rustdoc to ensure we don't contain erroneous references to platform apis if one of its uses is pulled in by #[doc(cfg)]. however, you can also implement traits for public types inside of functions. this is used by diesel (probably others, but they were the example that was reported) to get around a recent macro hygiene fix, which has caused their crate to fail to document. while this won't make the traits show up in documentation (that step comes later), it will at least allow files to be generated. </desc> <cmt> make everybody_loops keep item declarations </cmt> <cmt> more fixes for everybody_loops </cmt> <cmt> add rustdoc test for everybody_loops fix </cmt> <cmt> preserve order if blocks are between items </cmt>",make everybody_loops preserve item declarations
1122,"<desc> this pr renames the existing libtar to libarchive, adds a new, more compliant, zip parser (compared to our older ""blind"" offset-based one) to it that now also supports extracting compressed files and uses it instead in our unzip utility, as well as adds a new zip output stream (used for archive creation) and adds an accompanying zip utility. </desc> <cmt> libraries: rename libtar to libarchive </cmt> <cmt> this is in preparation for a new implementation of zip archive </cmt> <cmt> extraction and creation. </cmt> <cmt> libarchive: add zip file parser </cmt> <cmt> this is based on the zip specification on pkware's zip specification </cmt> <cmt> ( </cmt> <cmt> be used in the unzip utility and eventually in the zip utility. </cmt> <cmt> unzip: use the new libarchive zip parser </cmt> <cmt> this parser should be a little bit more modern and a little more </cmt> <cmt> resilient to zip files from other operating systems. as a side </cmt> <cmt> effect we now also support extracting zip files that are using </cmt> <cmt> deflate compression (using our own libcompress). </cmt> <cmt> libarchive: implement zipoutputstream for zip archive creation </cmt> <cmt> this output stream can be used to create zip archives, and will </cmt> <cmt> be used in the implementation of the zip utility. </cmt> <cmt> userland: add simple zip utility </cmt> <cmt> this uses the recently added zipoutputstream in libarchive. </cmt> <cmt> base: add man page for zip(1) </cmt>",implement zip archive parser and output stream
1123,"<desc> take shapes from gluonnlp bert base model as an example: shapes = [(64, 512, 1024), (32, 128, 12, 64), (32, 12, 128, 64)] axes = [(0, 2, 1), (0, 2, 1, 3), (0, 2, 1 ,3)] for idx, sh in enumerate(shapes): axis = axes[idx] a = np.random.rand(*sh) x = mx.nd.array(a) tic = time.time() for i in range(100): y = mx.nd.transpose(x, axis) y.wait_to_read() toc = time.time() print(""transpose %s to %s, %f "" %(sh, axis, (toc-tic))) b = np.transpose(a, axis) np.allclose(b, y.asnumpy()) before optimization: transpose (64, 512, 1024) to (0, 2, 1), 1.228018 transpose (32, 128, 12, 64) to (0, 2, 1, 3), 0.069434 transpose (32, 12, 128, 64) to (0, 2, 1, 3), 0.065088 after optimization: transpose (64, 512, 1024) to (0, 2, 1), 0.7996 transpose (32, 128, 12, 64) to (0, 2, 1, 3), 0.0107 transpose (32, 12, 128, 64) to (0, 2, 1, 3), 0.0069 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> add mkldnn transpose </cmt> <cmt> general transpose </cmt> <cmt> support mkldnn format </cmt> <cmt> fix lint </cmt>",optimize transpose operator with mkl-dnn
1124,"<desc> original pull-request #14203 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix issue #14202 </cmt> <cmt> testcase for issue 14202 </cmt> <cmt> fix issue #14202 </cmt>",cherry pick #14203 to 20.5: fix issue #14202
1125,"<desc> i reworked the keymap for the via-enabled firmware so that it would now reflect the layout of the default keymap, with mouse and media keys on the third layer and symbols on the second :) i also changed the product, manufacturer and description ids, the actual manufacturer still remains somewhat mysterious since there is no indication of that on my pcbs either. keymap/layout (update) the original via keymap only had the first layer populated, now all three are populated. my code follows the code style of this project. i have read the contributing document. i have tested the changes and verified that they work and don't break anything ('qmk make hotdox:via' compiles without errors or warnings). </desc> <cmt> added via support for hotdox </cmt> <cmt> just testing to see if mouse and media keys work in via </cmt> <cmt> adjusted keymap to reflect its non-via-enabled counterpart (again) :) </cmt> <cmt> slight changes to the directional mouse keycodes </cmt> <cmt> changed product, manufacturer (still mysterious) and description ids </cmt>",re-added mouse and media keys plus slight changes
1126,"<desc> i added the missing http methods and http status fron the http extension for webdav (rfc 2518 and rfc 3253) please check and  merge, thanks </desc> <cmt> merge remote-tracking branch 'allinurl/master' </cmt> <cmt> fixed typo on gmetrics struct. </cmt> <cmt> add webdav http methods and http status from rfc 2518 and  rfc 3253 </cmt>",add webdav http methods and http status from rfc 2518 and rfc 3253
1127,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. n/a if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" } n/a </desc> <cmt> adds ensure to api interface </cmt> <cmt> add a test </cmt>","add missing ""ensure"" to @types/xmlpoke's api interface"
1128,"<desc> improve path management on init: properly support symlinks for configured paths (e.g. /tmp -> /mnt/tmp) check all configured paths up front and deliver the best exception we can when things are wrong. initialize securitymanager earlier. fix too-loud error logging of natives root check. make bootstrap src/java code package private and src/test code public, rather than the other way around. add some unit tests for this stuff. thank you @mrsolo for reporting symlink issues. </desc> <cmt> improve path management on init: </cmt> <cmt> * properly support symlinks (e.g. /tmp -> /mnt/tmp) </cmt> <cmt> * check all configured paths up front and deliver the best exception we can when things are wrong </cmt> <cmt> * initialize securitymanager earlier </cmt> <cmt> * fix too-loud error logging of natives root check </cmt> <cmt> securitybootstrap -> bootstrapfortesting, and make less things public </cmt> <cmt> properly handle the case where symlinks are supported, but </cmt> <cmt> the user is not a windows administrator (can throw ioe in this case) </cmt>","improve path mgmt on init, better error messages, symlink support"
1129,"<desc> fixes #2627 (wait for #2635 before merging in) </desc> <cmt> refactor: remove ""_proto"" from ""image_proto.py"" </cmt> <cmt> fix name collision of ""image"" </cmt> <cmt> support ""auto"" as the new default for st.image's use_column_width </cmt> <cmt> spec from thiago: </cmt> <cmt> without going so far as completely rethinking how we do sizes, the least we could do is change use_column_width to accept three values: </cmt> <cmt> - 'auto' : sets the image to its natural size, unless its width is greater than the column width. in which case it scales the image to fit the column width. </cmt> <cmt> - true or 'always': sets the image size to fit the column width. </cmt> <cmt> - false or 'never': sets the image to its natural size. </cmt> <cmt> then we'd make 'auto' the default. (the current default is false) </cmt> <cmt> if use_column_width is not set, don't overwrite width </cmt> <cmt> fix test typo </cmt> <cmt> remove right margin on images </cmt> <cmt> upload black square snapshots </cmt> <cmt> fully remove support for format in st.image </cmt> <cmt> fixes #2627 </cmt> <iss> remove st.image format parameter once and for all </iss>",fully remove format param from st.image
1130,<desc> description: adding support for ryobi garage door opener related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#5424 example entry for configuration.yaml (if applicable): cover: - platform: ryobi_gdo username: user@domain.com password: 1kdkdfjk233 device_id: - 12345 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> initial component for ryobi cover </cmt> <cmt> initial component for ryobi cover </cmt>,adding ryobi garage door opener
1131,"<desc> this pr adds sessions to the 3 mobile projects (ios, android. react native) and moves all projects to using the aggregate session endpoint. previously, the 3 mobile projects only had transactions and events while the other 2 projects (react and python) had sessions but were using the single session endpoint. this allows all projects to have a much higher number of sessions in demo mode. grw-144 </desc> <cmt> added transaction for auto login </cmt> <cmt> added ip to transaction </cmt> <cmt> starting to agg sessions </cmt> <cmt> more agg changes </cmt> <cmt> session changes </cmt> <cmt> changes </cmt> <cmt> come back here if you mess up </cmt> <cmt> fixed commit messages, refined sessions </cmt>",adds aggregate sessions to all projects in demo mode
1132,<desc> description: this pr performs some housekeeping in zha. we were using a function to establish some mappings. we don't need to do this now that we can use top level imports. this pr removes the function in favor of direct initialization. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> remove establish_device_mappings </cmt> <cmt> inline init </cmt>,remove zha establish device mappings function
1133,<desc> my submission is formatted according to the guidelines in the contributing guide all changes have been squashed into a single commit </desc> <cmt> added spotsense api information to geocoding section </cmt> <cmt> added spotsense api information to geocoding section </cmt>,added spotsense api information in geocoding section
1134,"<desc> uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design this pr excludes 400 response from azure for inline retries. the reason is that, if we set 400 as retry-able error, the cloud provider may stuck on one operation for days. e.g. if you reference a basic ip in a standard load balancer cluster, the reconcile lb will response something like below: { ""error"": { ""codd"": ""publicipandlbskudonotmatch"", ""message"": ""standard sku load balancer /subscriptions/xxxx/resourcegroups/xxx-group/providers/microsoft.network/loadbalancers/kubernetes cannot reference basic sku publicip /subscriptions/xxx/resourcegroups/xxx-group/providers/microsoft.network/publicipaddresses/a-basic-ip."", ""details"": [] } } since we would always retry on 400, the inline retryer will keep going for days, and this error from azure will not be surfaced to user as an event on svc. it does show up in controller manager logs but it's not super visible. so the proposal here is to not retry on 400 specifically and surface that error immediately. fixes #86686 please let me know if there is a reason we need inline retry on 400. if that's the case we can parse the error code. does this pr introduce a user-facing change?: </desc> <cmt> fix: azure error should not retry on bad reqeust </cmt> <cmt> fix: test failures </cmt> <iss> azure cloud provider retries 400 for long time </iss>",azure cloud provider should not retry on bad request
1135,"<desc> summary note: this might be a good candidate for merging after we release 10.0. given the size of the change, it may not be worth de-stabilizing master with more changes. thoughts? i might need this change to improve #1605, so perhaps it would be worthwhile to get in soon. still investigating. replace component._prevvnode with vnode._children combine fragment and component diffing details replace component._prevvnode with vnode._children previously, _children was a cache for a normalized props.children. with a dom vnode and fragment vnode, you could access the children of the vnodes on the this _children property, but on vnodes for components, you need to go through vnode._component._prevnode. this pr formalizes the concept behind _children. it is now the container for the rendered children of all vnodes. if you think of props.children as input to render functions, _children is the output of the render. and dom vnodes and fragments are just render functions that return props.children. the implementation is a little different (dom vnodes don't have a render function, per se), but this concept applies. combine fragment and component diffing previously, if diff was called with a component, it would call c.render, coerce the result to a single vnode (e.g. convert arrays to a fragment), and then call diff.  however, building on the _children change (and the concept mentioned there), we now instead treat components as always returning arrays, and coerce result of render into a children of vnodes to continue rendering. so, diff always calls diffchildren after diff'ing a vnode, regardless of its type. another way to think about this is that everything is fragment now being able to depend on diffchildren -> diff -> diffchildren for all vnodes allows us to do operations that require knowing the parentvnode in diffchildren without having to special case the diff -> diff situation. for example, there is now only one place where oldvnode matching happens: diffchildren (we can remove some code from the top of diff). further, mounting and unmounting dom only happens in diffchildren as well (if unmounting wasn't recursive, we could inline it). future considerations with this pr, their are only 2 place diff is called: diffchildren and forceupdate. if we can change forceupdate to also enter the diff through diffchildren, then it is conceivable that we could inline diff into diffchildren and make our diff a single function! i think this could give us some good byte savings by sharing more local variables and reducing duplicate structures (e.g. have fewer than 5 try {} catch {} like we currently do). it may reduce the approachability of our code, but perhaps we can mitigate that with a well-defined sectional comment format to make up for the lost function names. either way, i think it might be worth an exploration. breaking change there are some breaking changes in this pr. component refs aren't re-invoked after each render. preact v8 and v10 both re-invoke component refs on every render. this pr changes that behavior so they are only invoked on initial render, when the ref changes, or on unmount. this new behavior appears to match react. per change summary 91f043b only copy _dom from oldvnode to newvnode if necessary (-1 b) 3159b71 replace c._prevvnode with vnode._children (-2 b) b73ab00 call diffchildren after rendering components (-8 b) b09318f copy the oldvnode in forceupdate to prevent side effect modification (+7 b) dc86517 set vnode._dom pointer in diffchildren (+2 b) fe7f20d only remove excessdomchildren after diff'ing dom vnodes (+5 b) 6f06653 remove redundant vnode type checks in diff (-17 b) 40212eb apply refs after unmounting in diffchildren (+25 b) 910f98c combine fragment and component diffing (-60 b) 27116bc remove array coercion from coercetovnode (-8 b) 6b18f6f remove more null checks from diff (-13 b) c0c070e normalize oldvnode to empty_obj once (-2 b) 9d89d10 fix fragment _dom pointers (-10 b) 3470318 flatten top-level fragments returned from render (+21 b) 31036a3 remove unused append in forceupdate (-14 b) total change: -70 b total change: -78 b total change: -57 b total change: -73 b note: individual commit size diffs may not be exact due to drifting caused by merges from master. they are intended to give an estimate of relative cost. </desc> <cmt> only run core tests </cmt> <cmt> only copy _dom from oldvnode to newvnode if necessary (-1 b) </cmt> <cmt> replace c._prevvnode with vnode._children (-2 b) </cmt> <cmt> fix core test teardown helper </cmt> <cmt> call diffchildren after rendering components (-8 b) </cmt> <cmt> copy the oldvnode in forceupdate to prevent side effect modification (+7 b) </cmt> <cmt> set vnode._dom pointer in diffchildren (+2 b) </cmt> <cmt> only remove excessdomchildren after diff'ing dom vnodes (+5 b) </cmt> <cmt> to fix hydration tests </cmt> <cmt> remove redundant vnode type checks in diff (-17 b) </cmt> <cmt> since diffchildren is always called after diff, diffchildren is the only place where vnodes are matched against oldvnodes </cmt> <cmt> add notes and todos to describe goals and intentions of branch </cmt> <cmt> add tests verifying cdu & cdm are invoked after refs are set </cmt> <cmt> wip: attempt to fix refs... </cmt> <cmt> apply refs after unmounting in diffchildren (+25 b) </cmt> <cmt> note: this introduces a breaking change where component refs aren't re-invoked every render </cmt> <cmt> combine fragment and component diffing (-60 b) </cmt> <cmt> update todos </cmt> <cmt> remove array coercion from coercetovnode (-8 b) </cmt> <cmt> this code had 0 code coverage. it appears that tochildarray flattens all nested arrays before they go to coercetovnode as arrays... </cmt> <cmt> remove unused exports </cmt> <cmt> enable all non-core tests </cmt> <cmt> updated notes </cmt> <cmt> add note about failing core test </cmt>",consistently use _children & combine fragment and component diffing (-73 b)
1136,"<desc> import envoy/config/rbac/v2/rbac.proto into grpc c core by adding the proto and its dependencies to gen_upb_api.sh and running said script. this proto is required to implement the cel engine for envoy rbac. @veblush </desc> <cmt> added rbac.proto and dependencies, then ran gen_upb_api.sh </cmt>",import rbac.proto into grpc c core
1137,"<desc> read commit message/description for further info tell me anything if u think something is wrong </desc> <cmt> add test to ar's counter_cache_test.rb </cmt> <cmt> according to </cmt> <cmt>  </cmt> <cmt> 4f02/activerecord/lib/active_record/counter_cache.rb#l14, u can pass </cmt> <cmt> more then one association to the reset_counters method. </cmt> <cmt> fix tests which started to fail due to commit 0123c39f41e2062311b2197e6e230ef8ad67e20e </cmt> <cmt> due to commit 0123c39f41e2062311b2197e6e230ef8ad67e20e, column </cmt> <cmt> topic.unique_replies_count has been added, and these test started to </cmt> <cmt> fail since the tests depends on the topic tables column info. </cmt>",add test to counter cache test.rb
1138,"<desc> forked dactyl_promicro to dactyl_rah and changed the 6x6 layout. updated the default config settings motivation for the new keyboard is to easily utilize qmk configurator  -- no more command line compiling my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added a dactyl promicro with a slightly different 6x6 layout </cmt> <cmt> updated keyboard layout </cmt>",created a new keymap layout for dactyl promicro with a different diode layout and pins
1139,<desc> @tylerlange </desc> <cmt> fix z-wave lock securityexception dvcsmp-1265 </cmt> <cmt> z-wave lock: fix double updated() commands dvcsmp-1265 </cmt> <cmt> implemented toggle() for locks </cmt> <cmt>  </cmt> <cmt> implemented toggle() for locks </cmt> <cmt> z-wave lock: fix security exception dvcsmp-1265 dvcsmp-1059 </cmt> <cmt> merging changes into stage </cmt>,merging changes into prod from staging
1140,"<desc> already fixed in main, this partially backports #8402 / #8428  to 0.65 fixes #8467 microsoft reviewers: open in codeflow </desc> <cmt> lib project will use the app's experimentalfeatures.props </cmt> <cmt> change files </cmt> <iss> 0.65 community module template solution cannot be opened </iss>",use app's experimentalfeatures.props in library project
1141,"<desc> timers use the compositiontarget::rendering event, which is async, and can fire even after its been unregistered.  this would cause random crashes during instance shutdown if there were any outstanding js timers-- so i changed the event handler to use a weak_ptr and verify the object is still around before trying to fire timers. the systrace impl was accessing an object that is supposed to be protected by a mutex outside of the mutex. -- moved the mutex guard to cover the object access. microsoft reviewers: open in codeflow </desc> <cmt> fix crash in timers during instance shutdown </cmt> <cmt> fix crash in systrace </cmt> <cmt> change files </cmt>","fix crash in timers during instance shutdown, and in systrace"
1142,"<desc> i hereby agree to the terms of the cla available at:  closes #9855 </desc> <cmt> improve decimalbinaryoperation specializations </cmt> <cmt> move undec out of decimalbinaryoperation </cmt> <cmt> undo binaryoperationimplbase changes (no effect) </cmt> <cmt> rename binaryoperationimplbase to binaryoperation </cmt> <cmt> test for fixed issue </cmt> <iss> cross join failed with the error 'cannot refer column ""x"" to table' </iss>",add test for fixed issue
1143,"<desc> closes #39410 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> fix assert bug </cmt> <cmt> add tests </cmt> <iss> bug: pd.testing.assert_frame_equal(..., check_exact=true) raises assertionerror when comparing numeric extensiondtypes </iss>",assert_frame_equal always raising assertionerror when comparing extension dtypes
1144,<desc> fixes #6920 small fix in comment for addlatlng method to add second arguments in documentation. </desc> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix addlatlng method comment for documentation. </cmt> <iss> missing second argument in addlatlng method in documentation </iss>,update addlatlng method comment to fix documentation
1145,"<desc> this pr removes the about to be deprecated autmodelwithlmhead class and uses the new automodelforseq2seqlm, automodelforcausallm and automodelformaskedlm for translation, text-generation and fill-mask pipelines respectively. regrading issue #6060 </desc> <cmt> use new automodel classed </cmt> <cmt> make style and quality </cmt>",add new automodel classes in pipeline
1146,"<desc> my bash is terrible, suggestions for improvement welcome. pre-commit now requires a working install of prettier. some background: we've been using prettier for javascript files (mostly libjs test files) for a while now, but it's never been automatically enforced like clang-format is, so it depended on a human reviewer catching inconsistencies - not anymore. </desc> <cmt> base+libjs+libweb: make prettier clean </cmt> <cmt> also use ""// prettier-ignore"" comments where necessary rather than </cmt> <cmt> excluding whole files (via .prettierignore). </cmt> <cmt> meta: set 'pipefail' option correctly in shell scripts </cmt> <cmt> this needs '-o' to work correctly. also update the shebang to bash in </cmt> <cmt> some scripts as shellcheck was complaining about pipefail not being a </cmt> <cmt> posix shell thing otherwise. </cmt> <cmt> meta: update lint-{clang-format,shell-scripts}.sh to take a list of files </cmt> <cmt> this should speed up pre-commit a bit as only files that are staged will </cmt> <cmt> be processed, and clang-format and shellcheck are only invoked once, not </cmt> <cmt> for every file. when no arguments are given (e.g. on ci), it still uses </cmt> <cmt> 'git ls-files'. </cmt> <cmt> meta: add lint-prettier.sh </cmt> <cmt> this is a script similar to the clang-format one to ensure prettier </cmt> <cmt> formatting of most javascript files. </cmt>",enforce prettier formatting for javascript files
1147,"<desc> fixes #12231 added a new metric for regression which is max_error. it  is the worst case error between the predicted value and the true value. >>> from sklearn.metrics import max_error >>> y_true = [3.1, 2.4, 7.6, 1.9] >>> y_pred = [4.1, 2.3, 7.4, 1.7] >>> max_error(y_true, y_pred) 1.0 </desc> <cmt> add max error metric </cmt> <cmt> fix typo </cmt> <iss> add max error metric for regression </iss>",add max_error to the existing set of metrics for regression
1148,<desc> this adds some additional tests for file serving it also fixes a bug in dev mode where haspage would throw an error on an invalid page name instead of returning false </desc> <cmt> test static/ file name encoding </cmt> <cmt> fix static/ file name encoding </cmt> <cmt> add additional file-serving tests </cmt>,add additional file serving tests
1149,"<desc> add rgb matrix support for bastardkb's scylla my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> initial draft of rgb struct </cmt> <cmt> add led_config_t and rgb matrix directives </cmt>",rgb matrix support for scylla
1150,"<desc> this enables e2e test by allowing configuration of report time interval. it also adds a basic e2e test. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> done. </cmt> <cmt> lint. </cmt>",make metrics report time configurable
1151,"<desc> delete lib_ignore of u8g, because skr mini can use lcd12864 now </desc> <cmt> fix bug in stm32f1 write macro </cmt> <cmt> sync from bugfix 2.0.x </cmt> <cmt> sync bugfix 2.0.x </cmt> <cmt> delet lib_ignore u8g for skr mini </cmt> <cmt> update pins_bigtree_skr_mini_v1_1.h </cmt> <cmt> sync bugfix 2.0.x </cmt> <cmt> update pins_bigtree_skr_mini_v1_1.h </cmt>",skr mini can use 128x64 lcd
1152,<desc> this pr adds a confirmation modal before deleting a pagerduty service: i also cleaned up some ts in the tablefield component </desc> <cmt> starting to convert form fields </cmt> <cmt> progress </cmt> <cmt> update </cmt> <cmt> cleanup </cmt> <cmt> move defaultprops back </cmt> <cmt> fix things from pr comments </cmt> <cmt> fix test </cmt> <cmt> add modal </cmt>,add confirmation modal when deleting pagerduty services
1153,"<desc> fixes #248 </desc> <cmt> fix for </cmt> <cmt> undefined is not valid json, make the value null instead. </cmt> <cmt> json.parse(undefined) will throw an exception while json.parse(null) is acceptable. </cmt> <cmt>  </cmt> <cmt> use multi line ternary operator </cmt> <cmt>  </cmt> <iss> ie11 - delete request - content-type => problem </iss>",patch for issue 248 (send null instead of undefined)
1154,"<desc> this separates the objectlosterror into several different errors, all of which result in the object being unreachable: objectlosterror: object has no locations in distributed memory due to node failure ownerdiederror: object's owner died objectreleasederror: object's owner is alive, but the object was already released, probably due to ref counting issue. objectreconstructionfailederror: only thrown if lineage reconstruction is enabled, and an object (or its dependency) failed to be reconstructed. closes #14580. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> define error types, throw error for objectreleased </cmt> <cmt> x </cmt> <cmt> disambiguate object_unreconstructable and object_lost </cmt> <cmt> ownerdiederror </cmt> <cmt> fix test </cmt> <cmt> x </cmt> <cmt> objectreconstructionfailed </cmt> <cmt> objectreconstructionfailed </cmt> <iss> improve the object loss message. </iss>",disambiguate objectlosterrors for better understandability
1155,"<desc> when an alarm happens, we were sending notification for our users, but the notifications were missing an important information that allows to centralize the chart to demonstrate to our users. component name ui closes #5810 </desc> <cmt> linkalarms comments and mapping! </cmt> <cmt> linkalarm buffer svg! </cmt> <cmt> linkalarm </cmt> <cmt> we are not centralizing chart when an alarm happens, because we were not sending </cmt> <cmt> all the necessary parameters to the netdata front end, this commit fix this, but </cmt> <cmt> it is not complete yet, it will be necessary to talk with the netdata specialist </cmt> <iss> links to alarms in notifications should always center the chart on the timeframe </iss>",center the chart on timeframe when an alarm is raised
1156,"<desc> after some research i found function glfwsetwindowicon to set window icons. pros: we can finally set window icon on linux! we can provide few different icons for different resolutions and let glfw select best one. cons: it works only for windows and linux (refer to  question: is tests required? if yes, i probably need some help with it. </desc> <cmt> add glviewimpl::seticon and glviewimpl::setdefaulticon for windows and linux </cmt> <cmt> include ccimage.h only if required </cmt>",add methods to change window icons on windows and linux
1157,"<desc> description: in #7330 @fowles introduced use of the abslhashvalue hook for absl hash containers to provide a default hash mechanism for a data structure. i'm not 100% sure if i prefer to this to using hash functors, as the latter is more standard, but i do think we should either use them when possible, or not use them at all. so this is a straw-man pr to switch the use of hash functors to using abslhashvalue instead in places where it makes sense. i did not apply this transform to places where it doesn't make obvious sense, like hashing of const char* (you might want to hash against the pointer, or you might want case-sensitive vs case-insensitive hashing). risk level: low -- main risk is that we'll have to reintroduce functors if we want to use a hash structure that's not from absl. testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> use implicit absl hashing in a couple of places, rather than explicit template args specifying hasher. </cmt>",absl hash hook in a couple of places rather than hash functors
1158,"<desc> this change merges together the content from na_ontap_broadcast_domain and na_ontap_broadcast_domain_port. we've got a lot of customer feedback on this. before this change, you could create ports while creating a domain in na_ontap_broadcast_domain, and then adding a new port, modify ports, or deleting ports would have to be done in na_ontap_broadcast_domain_ports. na_ontap_broadcast_domain </desc> <cmt> revert ""changes to cluster"" </cmt> <cmt> this reverts commit 33ee1b71e4bc8435fb315762a871f8c4cb6c5f80. </cmt> <cmt> add domain ports in to broadcast domain </cmt>",merging of broadcast domain and broadcast domain port
1159,"<desc> safe_sparse_dot docstring was not accurate regarding dense_output parameter. if only one of them is sparse, it would always return a dense array. i don't think it was an intended behavior anyway since i saw several c = safe_sparse_dot(a, b) c += <a scalar> which would break if the output was sparse. moreover, it's very unlikely that dense @ sparse has many zeros. so i changed the docstring to match the behavior. it did not handle the case when one of the arrays is 3d+ and the other is sparse. when arrays are 1d or 2d, matmul is preferred over dot, and is a little bit faster. i replace dot by @ when applicable. function was untested. </desc> <cmt> fix safe_sparse_dot docstring, add special case for 3d+ arrays, use matmul instead of dot when applicable, add tests </cmt> <cmt> use it in cd for sparse and dense </cmt>",enh safe_sparse_dot work on 3d+ arrays
1160,<desc> link to the issue </desc> <cmt> removed an unnecessary if-statement. </cmt> <cmt> not sure if it had any purpose. maybe to make it more clear? </cmt> <cmt> just a suggestion of something i noticed. </cmt> <cmt> removed an unnecessary if-statement. </cmt> <cmt> merge remote-tracking branch 'origin/dev' </cmt> <cmt> merge remote-tracking branch 'origin/dev' </cmt> <cmt> [issue 1458] allow blob urls when loading audio files </cmt> <cmt> fixing documentation typo </cmt>,support blob urls for audio files
1161,<desc> epoll_cloexec should come from this header and wasn't explicitly included before </desc> <cmt> catching up to head </cmt> <cmt> add sys/epoll.h </cmt> <cmt> epoll_cloexec should come from this header and wasn't explicitly included before </cmt> <cmt> add sys/epoll.h </cmt> <cmt> epoll_cloexec should come from this header and wasn't explicitly included before </cmt>,add sys/epoll.h header to relevant files
1162,"<desc> continues and closes #8297 closes #8266 move still maintained related project from the wiki page to the documentation i have removed some projects from the original pr, because they were no longer maintained (no commits after summer 2017). ping @rth </desc> <cmt> doc: incorporate related projects (except gists) </cmt> <cmt> doc: add gists from wiki page </cmt> <cmt> doc: change order / description of some projects </cmt> <cmt> doc: remove gists and rearrange sklearn-deap </cmt> <cmt> merge with master. </cmt> <cmt> remove not maintained packages. </cmt> <iss> retire third-party-projects wiki page? </iss>",shift projects missing in related_projects from the wiki page
1163,<desc> requires #31822 & #31773 to be merged first. with this pqr workers can access extracted page & static queries. </desc> <cmt> test(gatsby): check if worker can access node created in different process </cmt> <cmt> make timeout longer for workerpool tests </cmt> <cmt> test fixes from other pr </cmt> <cmt> wip: savestateforworkers / loadstateinworker </cmt> <cmt> basic functionality + type fixes </cmt> <cmt> wip (failing tests) </cmt> <cmt> revert child </cmt> <cmt> add redux state func </cmt> <cmt> revert early return changes </cmt> <cmt> initial </cmt>,pqr workers can access page & static queries
1164,"<desc> howbrew has recently removed the possibility to install old versions of packages from github commits. error: calling installation of swig from a github commit url is disabled! use 'brew extract swig' to stable tap on github instead. now one should maintain their own github repo for that. more reading: homebrew/brew#8791  but fortunately i've found swig@3 official formulae. i remember i hadn't got a luck to find it when setup swig building pipeline. @imatiach-msft just wonder, can we eventually migrate to swig 4? how about backward compatibility in this case? </desc> <cmt> update .vsts-ci.yml </cmt> <cmt> update setup.sh </cmt> <cmt> update .vsts-ci.yml </cmt> <cmt> update .vsts-ci.yml </cmt>",update swig installation on macos
1165,"<desc> my original goal was to make libselinux optional in the initramfs by using dlopen() for it. but i started by moving code that refers to libselinux from src/basic/ to src/shared/. this turns out be useful in itself, because the linkage list for libsystemd.so is pruned. using dlopen() for libselinux is still possible, but i'll try to submit that separately, becuase it's less clear that it is worth the trouble. </desc> <cmt> meson: sort file list </cmt> <cmt> at least emacs thinks this is the right way. </cmt> <cmt> basic,shared: move make_mount_point_inode_*() to shared/ </cmt> <cmt> those pull in selinux for labelling, and we should avoid selinux in basic/. </cmt>",drop libselinux dependency from libsystemd
1166,"<desc> closes #21015 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> gh21015 </cmt> <cmt> does not raise error in concatting series with numpy scalar and tuple names </cmt> <cmt> gh21015 </cmt> <cmt> does not raise error in concatting series with numpy scalar and tuple names </cmt> <iss> bug: error in concatting series with numpy scalar / tuple names </iss>",should not raise error in concatenating series with numpy scalar and tuple names (gh21015)
1167,"<desc> this fix responds to issue 43517 where copying the example code does not show how the css should work. the css code i have added means this animation will now work as expected. i have applied this fix to all translations of this question with id 587d78a7367417b2b2512ae0, hence the 6 modified files. and this is my first open source contribution ever! so please let me know if i have done anything wrong, or if this is an invalid solution. thank you. james </desc> <cmt> fix question example code for id: 587d78a7367417b2b2512ae0 </cmt>",css fix for issue #43517: example css code does not demonstrate hover animation
1168,"<desc> this pr contains two changes to swiftlang, the swift layer exposing sourcekit in swift: make each variant keep a strong reference to its sourcekitdresponse context. this is needed because sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was retrieved from (wrapped by sourcekitdresponse) is still alive. expose the new data variant sourcekit apis that were added to support returning the syntax tree in a binary format in swiftlang. pr for master: #20370 </desc> <cmt> [sourcekit] make each variant keep a strong reference to its sourcekitdresponse context </cmt> <cmt> sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was </cmt> <cmt> retrieved from is still alive, so keep a strong reference to sourcekitdresponse </cmt> <cmt> (the swift wrapper of sourcekitd_response_t) in each variant (the swift wrapper </cmt> <cmt> of sourcekitd_variant_t). </cmt> <cmt> [sourcekit] expose the data variant sourcekitd apis in the swiftlang wrapper </cmt> <cmt> these were recently added to support returning the syntaxtree in the bytetree </cmt> <cmt> from sourcekit but were never added in swiftlang (the swift layer wrapping </cmt> <cmt> sourcekit). </cmt>",keep sourcekitd response alive for variant lifetime
1169,"<desc> yes i did. </desc> <cmt> fetching every figure generated by the example scripts. </cmt> <cmt> as requested on the wiki, this script now fetches every figure generated </cmt> <cmt> by the example scripts. if there is only one figure fetched, it will use </cmt> <cmt> the rst instruction 'image', but if there is more than one, it will use </cmt> <cmt> the instruction 'hlist' in the .rst file. </cmt> <cmt> since we changed the name of the figure names, changing the rst files. </cmt> <cmt> in a previous commit, i changed the way the figures files where </cmt> <cmt> generated. each figure file is now similar to plot_example_<n>.png, </cmt> <cmt> where n is the number of the figure. therefore, even if there is only </cmt> <cmt> one figure generated, the name of the file will be plot_example_1.png. </cmt>","completed task ""multiple figures in documentation examples""."
1170,"<desc> built on top of #13137 ideally i should put #if gpr_linux in some files that are common for both linux and windows (like timer_manager, server.cc, iomgr.cc etc) but since gpr_cv_wait does the right thing (if the platform is not linux and the timespec passed is not of type realtime, it will convert to realtime) i am not doing it to keep the code simple. @kpayson64: please review the changes for the poll-cv poller (and reviewing other files is welcome too! cc:@iancoolidge </desc> <cmt> sync_posix: add linux-specific monotonic clock preference </cmt> <cmt> when grpc is running during wall clock acquisition, it's useful </cmt> <cmt> to avoid wall clock references as much as possible. </cmt> <cmt> change the code to use monotonic clocks when calling gpr_cv_wait (condition varialbes in linux support monotonic clock type) </cmt>",use monotonic clock type for gpr_cv_wait
1171,"<desc> all these controls didn't have names assigned, and accessibility insights doesn't like that. their parents did, but the actual focusable elements themselves didn't. so i've just taken the nearby headers for these things and slapped them in as the automation names for these controls. i verified that each of these automated tests in accessibility insights pass again. will do the thing to #11155 but we need confirmation before that can be closed. </desc> <cmt> this fixes the launch size </cmt> <cmt> this fixes the rest of #11155 </cmt>",add automation names to some controls that were missing them
1172,"<desc> prior to this pull request, you would have to use gml playground to receieve auto-completion for gml files. this pr moves gmlautocompleteprovider to libgui, allowing any application to provide gml autocompletion! (in this case, hackstudio) this also adds support for previewing your gml inside of hackstudio. screenshot: </desc> <cmt> libgui+playground: move gmlautocompleteprovider to libgui </cmt> <cmt> hackstudio: add autocompletion for gml files </cmt>",add proper gml support to hackstudio
1173,"<desc> when syscl file was missing, sysctl module was complaining about it and bailing out. this behaviour prevents usage of /etc/sysctl.d directory, present in some distributions. this patch accepts a missing sysctl.conf file so sysctl.d directory can be used. however, it will bail out if the destination directory doesn't exist. </desc> <cmt> removes exception is sysctl file is missing </cmt> <cmt> when syscl file was missing, sysctl module was complaining about it and </cmt> <cmt> bailing out. </cmt> <cmt> this behaviour prevents usage of /etc/sysctl.d directory, present in </cmt> <cmt> some distributions. </cmt> <cmt> this patch accepts a missing sysctl.conf file so sysctl.d directory can </cmt> <cmt> be used. </cmt> <cmt> however, it will bail out if the destination directory doesn't exist. </cmt> <cmt> changed when new sysctl file is created </cmt> <cmt> when destination sysctl file is missing, it is created. </cmt> <cmt> but, for idempotency purposes, the creation process now takes place just before it is used, in the </cmt> <cmt> main code path so an empty file is not left over if the code </cmt> <cmt> module.fail_jsons before the file is really used. </cmt>",better sysctl module file check
1174,"<desc> add a c-api interface, /** * @brief create a gradient machine used for model inference, using config with *        parameters which is generated by paddle merge_model. * @param [out] machine that used for model inference. * @param [in] mergedmodel * @param [in] size * @return paddle_error */ pd_api paddle_error paddle_gradient_machine_create_for_inference_with_parameters( paddle_gradient_machine* machine, void* mergedmodel, uint64_t size); where mergedmodel is generated by paddle merge_model, and it contains config of network and all parameters. </desc> <cmt> refine the error logs. </cmt> <cmt> support to load parameters from buffer in c-api. </cmt> <cmt> refine the comments of c-api function, paddle_arguments_set_frame_shape. </cmt> <cmt> add c-api interface, paddle_gradient_machine_create_for_inference_with_parameters, </cmt> <cmt> to create a gradient machine for inference using merged model with parameters </cmt> <cmt> which is genearted by paddle merge_model. </cmt> <cmt> delete c-api interface, paddle_gradient_machine_load_parameter_from_buffer, and </cmt> <cmt> related codes in paddle core. </cmt>",support to create a gradient machine with merged model in c-api
1175,"<desc> resolves #13230, where multiple viewport meta tags were showing up on the page when one was added to _document.js. this adds a warning similar to the existing warning for using <title> in _document.js, since the viewport is supposed to be handled by next/head. i was thinking, while i'm at it, of adding warnings for all of the <head> elements that should only be handled by next/head. would those be the element types that head.tsx's unique() function checks to filter out duplicates? that is, <title> <base> <meta name=... <meta httpequiv=... <meta charset=... <meta itemprop=... </desc> <cmt> add initial warning </cmt> <cmt> add no-document-viewport-meta error page </cmt> <iss> multiple viewport meta tags </iss>",add warning when viewport meta tag is added to _document.js
1176,"<desc> i made a few adjustments to the code: the map driver now also supports this ;-) in the merge iterator (merges sorted runs from external sort), we now always use the non-reusing code path,    because the reusing code path here implies in all cases additional instances to be held concurrently, and copy between elements, which voids the benefits of reusing elements. for many utility iterators (in test cases), i consolidated the logic between the two variants of the ""next()"" functions (one calls the other, where possible) i eliminated a few copies between elements in the non-reusing parts (where possible) i threw out unused variables in the non-reusing variants (mainly serializers previously used to create instance or copy between instances) threw out some unused types i tried to improve generic type safety (fewer raw types) </desc> <cmt> [flink-1137] enhance mutableobjectiterator with non-reuse next() </cmt> <cmt> this is in preparation for configurable object-reuse mode. we previously </cmt> <cmt> referred to this as mutable object vs. mutable object safe mode or some </cmt> <cmt> such thing. </cmt> <cmt> [flink-1285] make execution mode configurable </cmt> <cmt> [flink-1285] make merge-join aware of object-reuse setting </cmt> <cmt> this closes #259 </cmt> <cmt> [flink-1285] various cleanup of object reusing and non-reusing code. </cmt> <cmt> - the map driver now also supports this </cmt> <cmt> - in the merge iterator (merges sorted runs from external sort), we now always use the non-reusing code path, </cmt> <cmt> because the reusing codepath here implies in all cases additional instances to be held concurrently, and copy </cmt> <cmt> between elements, which voids the benefits of reusing elements. </cmt> <cmt> - for many utility iterators (in test cases), consolidates the logic between the two variants of the ""next()"" </cmt> <cmt> functions (one calls the other, where possible) </cmt> <cmt> - eliminates a few copies between elements in the non-reusing parts (where possible) </cmt> <cmt> - removes unused variables in the non-reusing variants (mainly serializers previously used to create instance </cmt> <cmt> or copy between instances) </cmt> <cmt> - remove some unused types </cmt> <cmt> -  improves generic type safety (fewer raw types) </cmt>",cleanups on top of #259 make execution mode configurable
1177,"<desc> redefine errno values to be consistent with wasi. this will let us avoid needing to convert the values back and forth as we use more wasi apis (which i experiemented with and it adds 1k or so). this is an abi change, which should not be noticeable from user code unless you use errno defines (like eagain) and keep around binaries compiled with an older version that you link against. in that case, you should rebuild them. fix nodefs, which basically just routed the node errno code to ours, which only worked when the underlying system had codes similar to musl - which seems to have been the case on some linuxes. this does make nodefs larger, as it uses the errno lookup table now, i'll look into a way to avoid including it unnecessarily as a followup (would be a breaking change). most of the changes in this pr are test changes, places where we printed raw errno codes. </desc> <cmt> rename </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> make nodefs more robust [ci skip] </cmt> <cmt> errno updates </cmt> <cmt> errno updates </cmt> <cmt> more test fixes </cmt> <cmt> updates </cmt> <cmt> fixes </cmt> <cmt> more fixes </cmt> <cmt> update metadata [ci skip] </cmt>",rename errno constants to use the wasi values
1178,"<desc> this pr fixes #922 - an unstable sort involve python line continuation with \.  the issue describes the problem pretty well. to my knowledge, there should be no situation where black outputs a file formatted with empty lines at the beginning.  by performing this check in the format function, we fix the above issue. note: open to feedback on this solution, threw it together pretty quickly after doing some basic debugging of how black parses lines and whatnot.  open to feedback on it.  also, i'm pretty sure it doesn't break any invariants of the formatter, but would like feedback on that as well. </desc> <cmt> fix unstable format involving beginning backslash + whitespace, add test </cmt> <cmt> add newline to end of test data file </cmt> <iss> black produced different code on the second pass of the formatter: explicit line join in the first line </iss>",fix unstable format involving backslash + whitespace at beginning of file
1179,"<desc> this pr reverts #17620, which caused a significant regression for slices. as discussed with @alexcrichton, all of the public-facing changes of the earlier pr need to be rolled back, and it's not clear that we should move the libraries over to this new notation yet anyway (especially given its feature-gated status). closes #17710 </desc> <cmt> revert ""review and rebasing changes"" </cmt> <cmt> this reverts commit 6e0611a48707a1f5d90aee32a02b2b15957ef25b. </cmt> <cmt> revert ""put slicing syntax behind a feature gate."" </cmt> <cmt> this reverts commit 95cfc35607ccf5f02f02de56a35a9ef50fa23a82. </cmt> <cmt> revert ""remove the _ suffix from slice methods."" </cmt> <cmt> this reverts commit df2f1fa7680a86ba228f004e7de731e91a1df1fe. </cmt> <cmt> revert ""use slice syntax instead of slice_to, etc."" </cmt> <cmt> this reverts commit 40b9f5ded50ac4ce8c9323921ec556ad611af6b7. </cmt> <iss> std::ops::slice is not in the prelude </iss>",revert overloaded slice notation being merged with library slicing
1180,<desc> cherrypicked from: c7f9c3f backport pr for check point unit tests for the following module from pr #62213: test_cp_mgmt_mds_facts.py test_cp_mgmt_network.py test_cp_mgmt_network_facts.py test_cp_mgmt_session_facts.py test_cp_mgmt_threat_indicator.py test_cp_mgmt_threat_indicator_facts.py test_cp_mgmt_threat_layer.py test_cp_mgmt_threat_layer_facts.py test_cp_mgmt_threat_profile.py test_cp_mgmt_threat_profile_facts.py test_cp_mgmt_time.py test_cp_mgmt_time_facts.py test_cp_mgmt_vpn_community_meshed.py test_cp_mgmt_vpn_community_meshed_facts.py test_cp_mgmt_vpn_community_star.py test_cp_mgmt_vpn_community_star_facts.py test_cp_mgmt_wildcard.py test_cp_mgmt_wildcard_facts.py unit tests pr check_point </desc> <cmt> add unit tests for check_point ansible modules (#62213) </cmt> <cmt> * update test_cp_mgmt_network.py </cmt> <cmt> * 17 tests </cmt> <cmt> (cherry picked from commit c7f9c3f27e47885680842ffbdb9d97c56db54f2c) </cmt> <cmt> changelog </cmt>,backport pr for check point unit tests for the following module from pr 62213
1181,"<desc> make sure you have checked all steps below. jira  here are some details about my pr, including screenshots of any ui changes: to have a % appear in the config file, it needs to appear as %%. however the way we were generating the temporary config for airflow run it would loose that escaping and cause a config error. this fixes the way we generate that temp config by using methods built-in to configparser to get the raw values (rather than grubbing around with deepcopy()). i have left this pr as three individual commits as i think it will be easier to review in it's current form. my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. when adding new operators/hooks/sensors, the autoclass documentation generation needs to be added. code quality passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> [airflow-3178] don't mask defaults() function from configparser </cmt> <cmt> configparser (the base class for airflowconfigparser) expects defaults() </cmt> <cmt> to be a function - so when we re-assign it to be a property some of the </cmt> <cmt> methods from configparser no longer work. </cmt> <cmt> [airflow-3178] correctly escape percent signs when creating temp config </cmt> <cmt> otherwise we have a problem when we come to use those values. </cmt> <cmt> [airflow-3178] use os.chmod instead of shelling out </cmt> <cmt> there's no need to run another process for a built in python function. </cmt> <cmt> this also removes a possible race condition that would make temporary </cmt> <cmt> config file be readable by more than the airflow or run-as user </cmt> <cmt> the exact behaviour would depend on the umask we run under, and the </cmt> <cmt> primary group of our user, likely this would mean the file was readably </cmt> <cmt> by members of the airflow group (which in most cases would be just the </cmt> <cmt> airflow user). to remove any such possibility we chmod the file </cmt> <cmt> before we write to it </cmt>",handle percents signs in configs for airflow run
1182,"<desc> this pr is mainly for adding a window for snapshot preview. (in the future, people can click this window to view other snapshots) currently, it only supports showing an image from a file ( path_to_rapps\rapps\rapps\snapshots\ ) and some other fixes are done in this pr too always use rappmgr.cab as the filename when downloading db (otherwise may cause bug when downloading from a specified url) use pathxxx api to operate path delete some unused/obsolete var snapshot url support </desc> <cmt> add one more layer of window </cmt> <cmt> reverse some alignment vs made without my agreement </cmt> <cmt> delete unused var </cmt> <cmt> tabs -> spaces again </cmt> <cmt> delete unused var, using path* api to operate path, etc. </cmt> <cmt> always use rappmgr.cab as file name when downloading db. ignore the url </cmt> <cmt> add snapshot preview window </cmt>",screenshot preview and other trivial fixes
1183,<desc> @desaintmartin @gianrubio for review adds optional labels for cronjob and pod from values.yaml n/a dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> allow additional labels for elasticsearch-curator pod and cronjob </cmt> <cmt> update configuration guide for elasticsearch-curator </cmt> <cmt> fix alignment in readme for elasticsearch-curator </cmt>,additional labels for cronjob and pod
1184,"<desc> this pr fixes a couple of issues around cache misses for a few of our integration tests. in the end these come down to issues with us wiring in inputs that are dynamic, such as file paths, port numbers or fixture urls that change from run to run. </desc> <cmt> ignore dynamic test cluster setting values to improve cacheability </cmt> <cmt> ignore hdfs fixture ports file from test runtime classpath </cmt>",repository plugin test cacheability fixes
1185,<desc> addresses #21350 #dataumbrella this pr ensures sklearn.covariance._empirical_covariance.empirical_covariance is compatible with numpydoc: remove sklearn.covariance._empirical_covariance.empirical_covariance from docstring_ignore_list. verify that all tests are passing. add backticks to bool values. </desc> <cmt> remove empirical_covariance from function_docstring_ignore_list </cmt> <cmt> ensure empirical_covariance passes numpydoc validation </cmt> <cmt> add backticks to bool values in docstring </cmt>,doc ensures that empirical_covariance passes numpydoc validation
1186,"<desc> redux briefly checks that observer received in observe function is a valid object and throw typeerror with useful user message if is not. however, it missed null case, as typeof null === 'object' (well-known js issue) and then failed with the obscure error message cannot read property 'next' of null.  i'm sure that there is no reason to not to show the correct error message in all relevant cases  this pr fixes that inconsistency by throwing typeerror with the same useful message in case of null observer note that this pr is not a breaking change in any way </desc> <cmt> make sure that assumed typeerror would be thrown </cmt> <cmt> check that throwerror would be thrown in case of null observer object </cmt> <cmt> add null check for subscribe method </cmt>","fix missed case in ""observe"" type check"
1187,"<desc> before this, if the search box was open, new selections would not notify automation clients. this was because the uiaengine (responsible for notifying automation clients) would remain disabled. now we're enabling it before the early exit in termcontrol's focushandler will close issue #5421 upon verification verified using nvda. narrator's behavior is not impacted, for some reason. </desc> <cmt> make search box findings accessible </cmt> <cmt> add comment </cmt>",notify uia when search finds something
1188,"<desc> right now the navlink component has this useful classname and style function support to change the styles if the link is active. <navlink to=""."" classname={({ isactive }) => isactive ? activeclassname : inactiveclassname}>content</navlink> <navlink to=""."" style={({ isactive }) => isactive ? activestyles : inactivestyles}>content</navlink> this is really cool, but one use case it doesn't support, but it's really easy to add support for, is what happens if inside the navlink there are two, or more, elements and they need to change styles based on the isactive state, right now it's not really possible to detect that, specially when using utility css. this pr adds support for that, which was also requested on the discussion #8080, copying the example from that discussion, now this is possible: <navlink to=""path""> {({isactive}) => ( <> <icon classname={isactive ? 'text-blue-500' : 'text-gray-500'} /> <span classname={isactive ? 'text-blue-900' : 'text-gray-700'}>link</span> </> )} </navlink> i also updated the docs/api.md to mention and show an example of this and the tests of the navlink component to test this works. </desc> <cmt> allow navlink children to be a function </cmt> <cmt> this allows navlink to work this way </cmt> <cmt> jsx </cmt> <cmt> <navlink to=""/home"" classname={({ isactive }) => isactive ? activeclassnames : inactiveclassnames}> </cmt> <cmt> {({ isactive }) => isactive ? <activenavlinkcontent /> : <inactivenavlinkcontent />} </cmt> <cmt> </navlink> </cmt> <cmt>  </cmt> <cmt> update api docs of navlink </cmt> <cmt> update navlink component </cmt> <cmt> fix test </cmt>",allow navlink to receive a children function
1189,<desc> re-land refactor of android_devices.dart and testing. fixed because i forgot to provide a timeout configuration since it is not on globals. </desc> <cmt> [flutter_tools] remove globals/context for android testing </cmt> <cmt> update android_device_test.dart </cmt> <cmt> update android_device_start_test.dart </cmt> <cmt> fix not calling globals </cmt>,remove globals from android device/testing
1190,"<desc> currently, ast constructor accepts a. empty arguments b. positional arguments, only when it's length is exactly same to number of fields c. keyword arguments.  no check for missing required fields. only (b) is strict.  and it require argument even if matching field is optional. this pull request removes the strict check. missing required field can be detected when compiling ast though. </desc> <cmt> bpo-29622: loosen positional argument check of ast constructor </cmt> <cmt> remove test about argument is not enough </cmt>",make ast constructor accepts less than enough number of positional arguments
1191,"<desc> this pr adds regression tests for the samplingdataset kernel, following the example of the tests for assertnextdataset. @feihugis helped guide me through this task. to allow my tests to create instances of the samplingdataset class, i refactored the samplingdataset class from a single .cc file into a header file and a code file. i also fixed a bug in the dataset's save/restore code that was preventing one of the tests from running. i've broken the refactoring, the tests, and the bug fixes into separate commits. </desc> <cmt> refactor samplingdataset into .cc and .h files </cmt> <cmt> refactor samplingdataset into .cc and .h files </cmt> <cmt> additional refactoring </cmt> <cmt> fix compiler warnings </cmt> <cmt> add tests of samplingdataset </cmt> <cmt> fix bug in save/restore of samplingdataset </cmt> <cmt> fix formatting with clang-format and buildifier </cmt> <cmt> run source files through clang-format </cmt> <cmt> run sampling_dataset_op.[cc|h] through clang-format </cmt> <cmt> run simple_philox.h through clang-format </cmt> <cmt> run test case through clang-format </cmt> <cmt> run build file through buildifier </cmt> <cmt> correct error in merge </cmt> <cmt> fix additional problems from merge </cmt> <cmt> add reference to location of api definition </cmt>",add tests of samplingdataset and fix a bug
1192,"<desc> links to markdown files on readthedocs.io are swallowing the .md extension, causing 404s. example: from readme.md, the text is creating a link to  note that these still lead to github, instead of staying on rtd, which feels a little odd from the user side (but was needed to make links work on pypi in #1397.) edit: it looks like this has been fixed in readthedocs/recommonmark#181, so next release of recommonmark would make these changes moot. </desc> <cmt> fix internal links to work on rtd </cmt> <cmt> note that these still lead to github, instead of staying on rtd. </cmt> <cmt> point links to better anchors </cmt>",fix github markdown links to work on rtd
1193,"<desc> this pr adds support for all the methods in the hooks interface for handsontable. before the change, most of these were simply missing. i've tested and linted it on my end. checklist: follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> add all types for 'hooks' api </cmt> <cmt> fix linting errors. </cmt>",add support for hooks interface
1194,"<desc> closes: #10329 i'm not too sure as to the level of granularity required in verifying the individual fields for each resource. of course i'm happy to amend the changes where requested </desc> <cmt> update first couple of sqs tests to now use runserverless </cmt> <cmt> updated further tests for intrinsic fns getatt, importvalue, join </cmt> <cmt> updated tests for iam statement </cmt> <cmt> moved extraction of cf resources into 'before' hook </cmt> <cmt> removed old tests </cmt> <iss> tests: refactor test/unit/lib/plugins/aws/package/compile/events/sqs.test.js </iss>",update sqs test run serverless
1195,<desc> this is part 2 of #117 change added support to search across multiple sources added store source as one of the default sources if experimental feature is enabled fixed a minor bug where removing a source will always restore default sources validation existing tests passed added new tests to test multiple source search manually tested the test msstore source and community source work together microsoft reviewers: open in codeflow </desc> <cmt> add support for multiple source search </cmt> <cmt> fix minor source remove bug </cmt> <cmt> added tests for multiple source search </cmt>,search across multiple sources and add msstore source
1196,<desc> this change adds support for the 7 different runtime fields contexts to the painless execute api. each context can accept the standard script input (source and params) along with a user-defined document and an index name to pull mappings from. the results depend on the output of the runtime field type. closes #70467 </desc> <cmt> add rt fields to painless execute action </cmt> <cmt> add some tests </cmt> <cmt> finish single node tests </cmt> <cmt> add yaml tests </cmt> <iss> make script contexts for runtime fields available as part of the painless execute api </iss>,add runtime fields contexts to painless execute api
1197,"<desc> 30% keyboard endzone34 keymap improvements. the main purpose is to extend the number of layers for via. and fix bootloader. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add oled function from default keymap. </cmt> <cmt> add config.h for via </cmt> <cmt> change layer count </cmt> <cmt> layer is 8 </cmt> <cmt> fix oled </cmt> <cmt> fix via config </cmt>","update via keymap for ""endzone34"""
1198,"<desc> redo of #72344 after revert in #73503. the original pr did not follow the breaking changes policy. fixes #72343, which should be reopened. sorry about that @justinmc, and thanks for picking this up. should i set up a design document? i'm new to this i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test exempt. i updated/added relevant documentation (doc comments with ///). i signed the cla. design doc: </desc> <cmt> add buildcontext parameter to texteditingcontroller.buildtextspan </cmt> <cmt> add a test for texteditingcontroller.buildtextspan </cmt> <cmt> fix nits </cmt> <iss> pass buildcontext to texteditingcontroller.buildtextspan </iss>","reland ""add buildcontext parameter to texteditingcontroller.buildtextspan"""
1199,"<desc> this simple pr adds two things: complete kwarg passthrough to randomized_svd from truncatedsvd and pca. currently truncatedsvd lacks n_oversamples and power_iteration_normalizer. pca lacks power_iteration_normalizer. these are added to the kwargs for the constructor and passed through to randomized_svd in the appropriate circumstances. the defaults are set to the same defaults of randomized_svd. access to the left singular vectors in the form of pca().u_ and truncatedsvd().u_. these are currently only available by taking pca().transform and dividing by pca().singular_values_. this is a minor pull request and i have documented the changes. these will be very useful for people who need to get more accuracy out of their svds and who need to access the left singular vectors. i have submitted them here as i am currently using workarounds in our downstream code, by explicitly calling randomized_svd rather than truncatedsvd and pca. </desc> <cmt> svd add u_ and randomized args </cmt> <cmt> svd u_ and n_oversamples and power iteration normalizer </cmt> <cmt> tests for u_ </cmt> <cmt> pre-commit fixes </cmt> <cmt> u_ and power_iteration_normalizer for pca. tests </cmt> <cmt> pre-commit checks </cmt> <cmt> updates to tests </cmt> <cmt> updated docs </cmt> <cmt> check_scalar for truncated_svd </cmt> <cmt> updated docs </cmt>",enh add randomized_svd kwargs to decomposition classes
1200,<desc> what did you implement: adding sls package documentation to guides. adding packaging guide to azure provider (was this accidentally removed?) is this ready for review?: yes is it a breaking change?: no </desc> <cmt> adding package documentation for aws and openwhisk </cmt> <cmt> adding azure packaging guide </cmt>,adding guide documentation for 'sls package' command
1201,"<desc> resolves #6542 mongodb throws an exception when inserting json with an empty key name. modify the abi used by mongo_db_plugin so that ""empty_struct_name"" and ""empty_field_name"" is used in place of """". with this change empty key names no longer prevents the transaction_trace, action_trace, etc. from being inserted instead the document will be stored with the field/struct name of empty_field_name / empty_struct_name . example impacted abi on mainnet -- zealbounce11 addbonus inline action call from eoszealbank1 resolvebet { ""name"": ""addbonus"", ""base"": """", ""fields"": [{ ""name"": """", ""type"": ""asset"" } ] } failed before (see #6542) now is inserted as: ... ""act"" : { ""account"" : ""test"", ""name"" : ""addbonus"", ""authorization"" : [ { ""actor"" : ""test"", ""permission"" : ""active"" } ], ""data"" : { ""empty_field_name"" : ""8.0000 eos"" }, ""hex_data"" : ""803801000000000004454f5300000000"" }, ... none documents stored in mongo by mongo_db_plugin which contain empty field/struct names will be stored with the field/struct name of empty_field_name / empty_struct_name . see api changes. </desc> <cmt> add test for empty abi field name </cmt> <cmt> mongo does not like empty json keys </cmt>",fix for mongo empty json keys
1202,"<desc> as #8116 removes wait_to_write when updating comm_buff, it's not safe to pass ndarray* to the callback for row_sparse_pull. now changed to ndarray. removed the usage of mshadow::range in filldnszerosrspimpl since mshadow::range uses float to calculate the tensor shape and is inaccurate for large shapes. added unit test for pulling empty sparse weights removed wrong/misleading comments @bhavinthaker @madjam @rahul003 passed code style checking (make lint) for user-facing api changes, api doc string has been updated. to my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change intersting edge cases to note here </desc> <cmt> remove mshadow::range in init_op.h </cmt> <cmt> add unit test </cmt> <cmt> remove pass by ptr, add unit test for pull empty wieghts </cmt> <cmt> fix range in key partition </cmt> <cmt> remove wrong comment </cmt> <cmt> remove change for partition </cmt>",misc fixes for sparse distributed training
1203,"<desc> yarn works fine on windows subsystem for linux (wsl) apart from a single call to enumerate network interfaces.  if this call fails on wsl, we instead assume that the user has an internet connection and continue. see #753 and #636 for discussion. with this change, the test suite works better on wsl but it still has multiple failures.  i've run the test suite on linux and it passes fine. </desc> <cmt> support unimplemented call in wsl (#753) </cmt> <cmt> yarn works fine on windows subsystem for linux (wsl) apart from a single call </cmt> <cmt> to enumerate network interfaces.  if this call fails on wsl, we instead assume </cmt> <cmt> that the user has an internet connection and continue. </cmt> <cmt> fix a comment which said the opposite of what it meant to say </cmt>",support unimplemented call in windows subsystem for linux
1204,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. fix for #20411 </desc> <cmt> react-virtualized: added missing properties to gridcellrangeprops </cmt> <cmt> react-virtualized: corrected type of overscanindicesgetter in grid.defaultprops </cmt> <cmt> react-virtualized: added name to ""definitions by"" section </cmt>","add missing properties to gridcellrangeprops, fix incorrect type for overscanindicesgetter in grid.defaultprops"
1205,"<desc> currently it is possible for a transient network error to disrupt the start recovery request from the remote to source node. this disruption is racy with the recovery occurring on the source node. it is possible for the source node to finish and clear its recovery. when this occurs, the recovery cannot be reestablished and the ""no two start"" assertion is tripped. this commit fixes this issue by allowing two starts if the finalize request has been received. fixes #57416. </desc> <cmt> wip </cmt> <iss> indexrecoveryit testtransienterrorsduringrecoveryareretried timeout </iss>",fix indexrecoveryit transient error test
1206,"<desc> currently the type of the second argument in slice_like op (shape_from ) needs to be the same as the first argument, even though only its (second argument's) shape is used. this pr relaxes that so slice_like accepts any type for the shape_from argument. please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> relaxing types for slice_like op </cmt> <cmt> added test </cmt>",relaxing type requirements for slice_like op
1207,"<desc> cherry-pick of #25755 into swift-5.1-branch reviewed by @benlangmuir rdar://problem/45219937 </desc> <cmt> [codecompletion] remove completecasestmtdotprefix() completion </cmt> <cmt> now that, normal dot-member completion works at case position. we don't </cmt> <cmt> need to handle it specially. </cmt> <cmt> rdar://problem/45219937 </cmt> <cmt> (cherry picked from commit 588d87b90e2da8c7806a552e74b525bdffbdda65) </cmt> <cmt> [codecompletion] remove gettypecontextenumelementcompletions() </cmt> <cmt> use getunresolvedmembercompletion() instead. </cmt> <cmt> rdar://problem/45219937 </cmt> <cmt> (cherry picked from commit 35f868657462532cf04df197de606d79680dd8d9) </cmt>",use unresolved member completion for case stmt beginning
1208,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). documentation url for suggested changes:  node types for version 8 and onwards provide the processenv interface in their types, however process.env is in use since atleast node version 4. therefore i would like to add this interface to the existing node types for version 4, 6 and 7. i am struggling to figure out whether this is an actual breaking change, the values you can use in process.env are more strict due to the change of the env property in the process interface from any to the new processenv. however, i doubt anyone actually uses a different value in this property. feedback is welcome ofcourse. </desc> <cmt> feat(node 4): add processenv interface </cmt> <cmt> feat(node 6): add processenv interface </cmt> <cmt> feat(node 7): add processenv interface </cmt> <cmt> test(node 4): alter test for processenv </cmt> <cmt> test(node 6): alter test for processenv </cmt> <cmt> test(node 7): alter test for processenv </cmt> <cmt> docs(name): add my name to contributors list </cmt> <cmt> fix(node 6): use processenv in process interface </cmt>","add ""processenv"" interface to types for node versions 4, 6 and 7"
1209,<desc> just add ios resource which i am using from 2 year almost. it is collection one of best quality tutorials for ios. </desc> <cmt> added ray wenderlich free tutorial in ios section </cmt> <cmt> just a spelling change </cmt>,added free resource of ray wenderlich in ios section
1210,"<desc> fixes #4396. this wasn't caused by dropout, but by the handling of python functions in the jit interpreter (implicit conversions of pyobject* to py::object that assume borrowing semantics, yay). while fixing that i also noticed that dropout is unnecessarily cloning the input in eval mode. </desc> <cmt> fix a leak in jit interpreter </cmt> <cmt> improve dropout </cmt> <cmt> previously it would unnecessarily clone the input in eval mode. </cmt> <iss> jit leaks memory in nets with dropout layer </iss>",fix a leak in jit interpreter + improve dropout
1211,"<desc> breaking change: description: at #27367 @martinhjelmare points me to the isort utility that is able to manage all the imports automagically. once #27549 has been merged, another pr is needed to correct all imports on rfxtrx classes. related issue (if applicable): fixes # pull request with documentation for home-assistant.io (if applicable): n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> move imports in rfxtrx component </cmt> <cmt> apply isort rfxtrx classes </cmt> <cmt> apply isort on rfxtrx files </cmt>",apply isort on rfxtrx classes
1212,"<desc> source code for a server and a client application for the baeldung article </desc> <cmt> application source code for the baeldung article ""http put vs post </cmt> <cmt> method in rest api"" </cmt> <cmt> update indention in pom file, update code in address class </cmt> <cmt> update indention </cmt> <cmt> rename application </cmt> <cmt> update pom </cmt> <cmt> source code for article ""connection timeout vs read timeout"" </cmt> <cmt> source code for baeldung article bael-4896 </cmt> <cmt> update code </cmt> <cmt> source code for baeldung article bael-4896 </cmt>","source code for bealdung article ""find ip address of client"""
1213,<desc> spring boot 2.x guide ebook link for need to spring boot users it's published on gitbook read our contributing guidelines </desc> <cmt> fix to mistyping </cmt> <cmt> awk guide subject mistyping as aws </cmt> <cmt> add a ebook link for about springboot </cmt>,add a korean ebook link
1214,"<desc> beta backport of pr #86003 to address issue #84297 </desc> <cmt> revert effects of prs 81167 and 83091. </cmt> <cmt> this is preparation for reverting 81238 for short-term resolution of issue 84297. </cmt> <cmt> revert tests added by pr 81167. </cmt> <cmt> revert prs 81238 and 82967 (which made copy and copy_nonoverlapping intrinsics). </cmt> <cmt> this is to address issue 84297. </cmt> <cmt> revert clippy's path to the copy intrinsics (part of reverting pr 81238). </cmt> <cmt> remove tests that were also added in pr 79684. </cmt> <cmt> change test to use likely/unlikely instead of copy/copy_overlapping. </cmt> <cmt> test was added in pr #84404. </cmt> <cmt> the intent here is: the copy/copy_overlapping intrinsics are going through </cmt> <cmt> some flip-flopping now of ""are they intrinsics or not"". we can achieve the same </cmt> <cmt> effect that the test intended by using likely/unlikely. </cmt> <cmt> regression test for issue 84297. </cmt>",beta targetted make copy/copy_nonoverlapping fn's again
1215,"<desc> a minor enhancement to the pio tools to allow you to disable the compression of .map and .bin files using environment variables. it also allows overriding the final location of the .map and .bin files. for example, to disable the compression of the .map files, put the following in your environment: tasmota_disable_map_gz=1 all of the options are at the top of tasmotapiolib.py. (the top of this page outlines ways to set environment variables:  the code change is tested and works with tasmota core esp32 v.1.0.7.3 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> pio tools environment variable controls </cmt>",python pio tool controls using environment variables
1216,<desc> add open data portal russia associated with: #1922 my submission is formatted according to the guidelines in the contributing guide all changes have been squashed into a single commit </desc> <cmt> remove broken link russian state duma open data </cmt> <cmt> err_connection_timed_out </cmt> <cmt> add open data portal russia </cmt> <cmt>  </cmt>,add open data portal russia and remove duma.gov.ru
1217,<desc> both logging and returning an error is an antipattern. if the caller wants it logged they will log it. and in this case it will be logged twice which is very confusing for debugging. release note: /sig api-machinery </desc> <cmt> let the caller handle the error </cmt> <cmt> both logging and returning an error is an antipattern </cmt> <cmt> re-generate clientsets </cmt>,don't log when error returned
1218,"<desc> #13088 there is 'means_prior_' in bayesian_mixture.py attributes. change from 269    means_prior_ : array-like, shape (n_features,) 270        the prior on the mean distribution (gaussian). 269    mean_prior_ : array-like, shape (n_features,) 270        the prior on the mean distribution (gaussian). , and in test_bayesian_mixture.py change from 121    def test_bayesian_mixture_means_prior_initialisation(): 121    def test_bayesian_mixture_mean_prior_initialisation(): sorry, i erased the branch of local before merge...... #13089 </desc> <cmt> change attribute 'means_prior_' to 'mean_prior' </cmt> <cmt> change 'means_prior_' to 'mean_prior_' in test_bayesian_mixture.py </cmt> <cmt> change from means_prior_ to mean_prior_ </cmt>",change from 'means_prior' to  'mean_prior'
1219,<desc> partially addresses this issue for kbinsdiscretizer class: #15440 </desc> <cmt> applied numpydoc validation for onehotencoder </cmt> <cmt> applied numpydoc validation for ordinalencoder </cmt> <cmt> applied numpydoc validation for ordinalencoder </cmt> <cmt> applied numpydoc validation for kbinsdiscretizer </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> update sklearn/preprocessing/_encoders.py </cmt> <cmt> numpydoc for kbinsdiscretizer </cmt>,doc numpydoc validation for kbinsdiscretizer
1220,"<desc> this pr fixes an issue for which the filter value wasn't resetting when the column was changed. see #16844 dev.seasonalit.mp4 open a chart in explore set a filter change the column of the filter make sure the filter value resets has associated issue: fixes #16844 includes db migration (follow approval process in sip-59) </desc> <cmt> clear filter value onchange </cmt> <cmt> clear filter value on user change action </cmt> <iss> [explore] when changing column of an existing filter, the existing filter value did not changed </iss>",clear filter value when changing columns
1221,"<desc> added neo4j hook and operator. basic functionality added to support creating a bolt and neo4j connection using neo4j driver. connection also supports self signed and trusted ca schemes. added logic to run sql queries. close: #12873 read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> [12873] added hooks and operators for neo4j </cmt> <cmt> [12873] added unit tests for neo4hook, added neo4j depedency to setup.py </cmt> <cmt> added tests and fixed example dag </cmt> <iss> add neo4j provider </iss>",add neo4j hook and operator
1222,"<desc> i want to add both boards to via and need the proper changes integrated into qmk. while i was at it, i took the liberty of changing the default vendorid 0xfeed on all 40percentclub boards to 0x3430 which is already used in the sixpack, nein and mf68's via layouts my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add via keymap for 4x4 and change vendorid on all 40percentclub boards from 0xfeed to 0x3430, which is already used for the mf68, nein and sixpack's via layouts </cmt> <cmt> add via keymap for 40percentclub 5x5 </cmt>",unique vendorid for 40percentclub boards and via keymaps for 4x4 and 5x5
1223,"<desc> this change adds support for including data streams in snapshots. names are provided in indices field (the same way as in other apis), wildcards are supported. if rename pattern is specified it renames both data streams and backing indices. closes #57127 relates to #53100 </desc> <cmt> snapshot-restore working </cmt> <cmt> store data streams in snapshotinfo </cmt> <cmt> store data streams in snapshotinfo </cmt> <iss> add snapshot/restore support for data streams </iss>",add support for snapshot and restore to data streams
1224,"<desc> previously they weren't properly returning the containers at all. while we're at it, introduce a type alias to make relevant function declarations and definitions shorter. </desc> <cmt> input_common/sdl: use a type alias to shorten declaration of getpollers </cmt> <cmt> just makes the definitions a little bit more tidy. </cmt> <cmt> input_common/sdl: correct return values within implementations of getpollers() </cmt> <cmt> in both cases, we weren't actually returning anything, which is </cmt> <cmt> undefined behavior. </cmt>",correct return values within getpollers implementations
1225,"<desc> refactor of geoshape tests to separate geoshape and geopoint as preliminary step prior to implementing #48928 added new methods to avoid duplicate code for mapping creation all existing tests passed post refactor in org.elasticsearch.search.geo.* new placeholder test in geopointshapequerytests is non-failing pending 48928 note commit 24b9535 has been reset by d7f2218 this will be reincorporated as part of 48928 </desc> <cmt> wip subclassing geoshapequerytests.java </cmt> <cmt> wip subclassing geoshapequerytests.java </cmt> <cmt> wip subclassing geoshapequerytests.java </cmt> <cmt> wip writing geopointshapequerytests.java </cmt> <cmt> added failing test testindexpointsfilterrectangle </cmt> <cmt> in class org.elasticsearch.search.geo.geopointshapequerytests </cmt> <cmt> permit geoshapequerybuilder to accept a geo_point -> class_cast_exception raised, see org.elasticsearch.index.query.queryshardcontext.toquery </cmt> <cmt> added @override protected xcontentbuilder createmapping </cmt> <cmt> in geopointshapequerytests </cmt> <cmt> merged upstream including 418edc6 types fixes </cmt> <cmt> repeat refactor post type removal and remove remaining types from geoshapequerytests.java </cmt> <cmt> tidy geopointshapequerytests.java </cmt> <cmt> interim checkin, still failing tests </cmt> <cmt> geoshapequerytests.java passing tests </cmt> <cmt> geoshapequerytests.java extends geoquerytests </cmt> <cmt> refactored + tests passing </cmt> <cmt> refactored + tests passing </cmt> <cmt> reset geoshapequerybuilder.java for future pr </cmt>",refactor geoshape tests to geoshape and geopoint
1226,"<desc> adds a regression test for the same underlying bug as #18515 but using pings. test already passes, but i confirmed it fails if you revert the fix in #18515. also confirmed that this fix alone is sufficient to fix the bug. however, i've kept the previous fix as defense against a future regression, since we've had similar bugs around clearing suspense timers before. the fix is to always set nextknownpendinglevel upon finishing a root, instead of only when it suspends. </desc> <cmt> add another test for #18515 using pings </cmt> <cmt> adds a regression test for the same underlying bug as #18515 but using </cmt> <cmt> pings. </cmt> <cmt> test already passes, but i confirmed it fails if you revert the fix </cmt> <cmt> in #18515. </cmt> <cmt> set nextpendinglevel after commit, too </cmt>",more robust fix for #18515
1227,"<desc> this pr rewrites the settings handler in imageresizer to store the settings in json instead of the default xml config files created by the applicationsettings class. the format of the file has been made to match the json format used by other powertoys so that shifting to the powertoys c++ settings in the future will not be a breaking change. pr checklist applies to #1124 cla signed. if not, go over here and sign the cla tests added/passed detailed description of the pull request / additional comments\ removed the settings.designer.cs autogen file and settings.settings moved all the settings from settings.designer.cs as properties in settings.cs implemented save and reload functions for json file read/writing added thread safety for json file access added tests for reload/save methods and propertychanged behavior added newtonsoft.json.dll to the msi/msix installer fixed dll folder locations in packaginglayout.xml. (earlier set to x64/release which contained the dlls from the test project. changed to x64/release/modules which has the dlls for the correct project). validation steps performed added reload_createsfile_when_filenotfound, save_creates_file, save_json_is_readable_by_reload and reload_raises_propertychanged tests tried without settings.json file and with json file in correct format. tried changing each of the settings in the settings menu. installed with msix and verified functionality. </desc> <cmt> combined settings files </cmt> <cmt> added json settings functionality in powertoys format with thread safety </cmt> <cmt> reverting changes to csproj file </cmt> <cmt> removed settings.settings and designer file and added target sdk tools to fix warning </cmt> <cmt> added newtonsoft json package </cmt> <cmt> added 3 tests </cmt> <cmt> added propertychanged test </cmt> <cmt> removed unused libraries </cmt> <cmt> removed additional allocation statements in test </cmt> <cmt> added comments on test </cmt> <cmt> added one-time setup code </cmt> <cmt> added newtonsoft.json.dll to msi and msix installer </cmt> <cmt> fixed copyright header </cmt>",save imageresizer settings in json format
1228,"<desc> remind user that softmax output is zero-indexed. close #3086 linear regression with multiple outputs. close #2138 </desc> <cmt> [r] softmax output is zero-indexed. close #3086 </cmt> <cmt> [r] add doc for linear regression with multiple outputs. close #2138 </cmt> <iss> multiple output with linearregressionoutput </iss> <iss> in r documentation, remind user that softmax labels are 0 indexed </iss>",doc update for regression and classification
1229,<desc> currently the simple connection strategy only exists in the code. it cannot be configured. this commit moves in the direction of allowing it to be configured. it introduces settings for the addresses and socket count. additionally it introduces new settings for the sniff strategy so that the more generic number of connections and seed node settings can be deprecated. the simple settings are not yet registered as the registration is dependent on follow-up work to validate the settings. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> add resolver test </cmt>,allow simple connection strategy to be configured
1230,<desc> makes it possible to configure cpu and memory requests and limits for jenkins master initcontainers. see #6077 (comment) bumps appversion to reflect the current lts version of jenkins (see  related prs: #6721 </desc> <cmt> [stable/jenkins] uses master request limits also for initcontainers </cmt> <cmt> bump appversion to reflect new jenkins lts release version 2.121.2 </cmt>,allow to specify resource requests and limits on initcontainers
1231,<desc> i've updated some new fluid api documents to paddlepaddle.org: add new apis docs from clip.py and place it under nets replace evaluator by metrics update other newly created apis docs </desc> <cmt> add some new api documentations </cmt>,add new fluid api documents
1232,"<desc> this changes the actions that would attempt to make the managed index read only to check if the managed index is the write index of a data stream before proceeding. the updated actions are shrink, readonly, freeze and forcemerge. relates to #53100 </desc> <cmt> tests: extract getindexonlysettings to the rest driver </cmt> <cmt> ilm: readonly action checks managed index is not the ds write index </cmt> <cmt> ilm: freeze action checks managed index is not the ds write index </cmt> <cmt> ilm: shrink action checks managed index is not the ds write index </cmt> <cmt> ilm: forcemerge action checks managed index is not the ds write index </cmt>",ilm actions check the managed index is not a ds write index
1233,<desc> create new base component based on /lib/list-ctrl.js (which is a common parent for mentioned pages); migrate dashboards list page; migrate queries list page; migrate users list page; error handling <users-list-extra> cleanup. screenshots: </desc> <cmt> refine existing implementation of dashboards/queries/users lists and a common base controller </cmt> <cmt> migrate common list page controller to react and refactor it's logic </cmt> <cmt> migrate dashboard list page to react </cmt> <cmt> migrate queries list page to react </cmt>,migrate dashboards/queries/users list pages to react
1234,"<desc> i tracked down the source of occasional duplicate lines. to prevent jerking to a stop when the target of a mouse wheel event is removed from the dom, i preserve the screen row associated with the latest mouse wheel. there were some situations in which the mousewheelscreenrow wasn't getting cleared or was being set unnecessarily, so i fixed those. i also never preserve a line associated with the mousewheelscreenrow if it's in the rendered row range. it's still possible to set the mousewheelscreenrow without it getting cleared by scrolling up/down at the beginning/end of the file and not actually causing the scroll position to change. i'd like to get a fix in for that before merging this. </desc> <cmt> update the lines and gutter when the mousewheelscreenrow changes </cmt> <cmt> only set the mousewheelscreenrow when scrolling vertically </cmt> <cmt> when we handle a mousewheel event targeting a line or line number, we </cmt> <cmt> assign the mousewheelscreenrow to prevent the removal of the target </cmt> <cmt> node, which interferes with velocity scrolling. </cmt> <cmt> however, the ::mousewheelscreenrow is only cleared 100ms after we stop </cmt> <cmt> scrolling vertically. this means that if we're only scrolling </cmt> <cmt> horizontally, it's never cleared. this causes the line node associated </cmt> <cmt> with this screen row to hang around longer until the mousewheel screen </cmt> <cmt> row is cleared again, which is not what we want. </cmt> <cmt> this commit only assigns the ::mousewheelscreenrow when scrolling </cmt> <cmt> vertically, so we can be sure it will be cleared. </cmt> <cmt> only preserve mousewheelscreenrow if it's out of the rendered row range </cmt> <cmt> fixes #2429, #2443 </cmt> <cmt> otherwise, it's possible to duplicate lines. if a line is in the </cmt> <cmt> rendered row range and it's not in the set of lines returned by the </cmt> <cmt> editor, we should remove it no matter what. line preservation is only </cmt> <cmt> intended for lines that are out of view. </cmt>",fix line duplication in react editor
1235,"<desc> this pr changes jquery.fn.command from a straight on passthrough to something a little more specific. the new signature is command(eventname, selector, options, handler). this signature clarifies usage a bit: unlike on, command takes a single event name. selector and options are optional. the options object can have two keys: data, an object passed through to on. this isn't used very often, but it's there. doc, a string to replace the auto-generated docstring for an event. the doc key is only used to replace the portion of an event name after the :. before: @command ""testing:show-alert"", -> # => ""testing: show alert after: @command ""testing:show-alert"", doc: ""hi!"", -> # => ""testing: hi!"" i also dropped a little tweak in to always change github to github if it's an event namespace. </desc> <cmt> spike optional doc: key for command </cmt> <cmt> this isn't working yet. </cmt> <cmt> actually make doc: work </cmt>",support optional doc strings for commands
1236,"<desc> the main motivation is that transportexceptions are always log at warn level at the moment as the rest status code is 500. this exception might be actually wrapping another exception, therefore if the underlaying exception code is < 500, we should  not be logging them at warn level, e.g taskcancelledexception. relates to #73524 </desc> <cmt> transportexception implements now elasticsearchwrapperexception </cmt> <cmt> better name </cmt>",wrap exception with sendrequesttransportexception instead of transportexception
1237,"<desc> cudnn frontend v0.4 released:  accordingly, this pr does the following things: support vector data type (currently only int8x4); change setdatatype() in operationbuilder to setcomputeprecision() update setalpha/beta which can deduce the datatype from the compute precision instead of given alpha/beta. cc. @nluehr </desc> <cmt> add support of vector type </cmt> <cmt> update setalpha </cmt> <cmt> disable the int8x32 for cudnn frontend </cmt>","support of int8x4, api updates"
1238,"<desc> a bit of a refactor to utils/build.js to better enable this change - each step was split out into its own, separate function. note that this change also ensures that done callback is always called. without a user-provided post-build, the callback was never called. realized that i was never getting that 'done' console log after my builds. also some readme updates to capture what i've learned from inspecting the source. and match the latest api. :0) </desc> <cmt> config.spa to turn off bundle.js build </cmt> <cmt> note that this change also ensures that done callback is always called. </cmt> <cmt> without a user-provided post-build, the callback was never called. </cmt> <cmt> realized that i was never getting that 'done' console log after my </cmt> <cmt> builds. </cmt> <cmt> a few readme updates to capture what i've learned </cmt> <cmt> readme tweak to make it real js, match 0.8.x api </cmt>","config.noproductionjs to turn off bundle.js build, readme updates"
1239,"<desc> add book for react native (react native notes for professionals) this react native notes for professionals book is compiled from stack overflow documentation, the content is written by the beautiful people at stack overflow. it is a simply written book which answers most questions about react native. furthermore the best practice variants are often mentioned. text content is released under creative commons by-sa, see credits at the end of this book whom contributed to the various chapters. images may be copyright of their respective owners unless otherwise specified not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> add book 'react native notes for professionals' </cmt> <cmt> correct alphabetical order </cmt>",add book react native notes for professionals
1240,"<desc> here is a proposition to complexify a bit the client, but this will allow to differentiate stdout and stderr and you don't allocate a tty. you could now do this: $>docker run busybox ls / /error 1> output 2> error what do you think ? </desc> <cmt> improve attach </cmt> <cmt> split stdout and stderr in run if not -t </cmt>",split stdout stderr in docker run if no -t
1241,"<desc> here are a few cherry-picks for the v1.14.1 release. they are going into master separately in the following prs: #31313 enum34, jsoncpp #31316 install_headers #31314 pkg-config </desc> <cmt> systemlibs: unbundle enum34 </cmt> <cmt> systemlibs: jsoncpp: update header symlinks for jsoncpp 1.9 </cmt> <cmt> install_headers: fix paths of generated headers </cmt> <cmt> pkgconfig: generate tensorflow_cc pkg-config entry </cmt>",system libs cherry-picks for v1.14.1
1242,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: npm package (with versions) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> adds types for new version of svg-parser </cmt> <cmt> added whitespace for union types </cmt>",adds types for version 2.0 of svg-parser
1243,<desc> deprecations? spec compliancy? tests added/pass? yes/yes fixed tickets fixes #5503 doc pr </desc> <cmt> allow sharecommentswithsiblings reverse sharing </cmt> <cmt> it will be used to preserve comment ordering when a node is removed </cmt> <cmt> preserve comment order when using path.remove </cmt>,fix path.remove() leading & trailing comments sharing
1244,"<desc> removed task field from taskmigrated; the only caller that encodes a task id from streamtask actually do not throw so we only log it. to handle it on streamthread we just always enforce rebalance (and we would call onpartitionslost to remove all tasks as dirty). added taskcorruptedexception with a set of task-ids. the first scenario of this is the restoreconsumer.poll which throws invalidoffset indicating that the logs are truncated / compacted. to handle it on streamthread we first close the corresponding tasks as dirty (if eos is enabled we would also wipe out the state stores), and then revive them into the created state. also fixed a bug while investigating kafka-9572: when suspending / closing a restoring task we should not commit the new offsets but only updating the checkpoint file. re-enabled the unit test. </desc> <cmt> add timer for update limit offsets </cmt> <cmt> consumer.position invalid offset </cmt> <cmt> add task corrupted logic </cmt> <cmt> re-enable the unit test </cmt>",graceful handling taskmigrated and taskcorrupted
1245,"<desc> this branch actually fixes two inconsistencies for namespace package loaders. namespace packages have inconsistent __loader__ and __spec__.loader.  this inconsistency leads to namespace packages having a valid __loader__ but none for __spec__.loader.  this branch fixes it by ensuring that the two attributes start out the same.  (as always, a user could change one or the other, and no attempt is made by python to keep them in sync.) namespace packages have inconsistent __file__ and __spec__.origin.   here, namespace packages have a __spec__.origin that is the literal string ""namespace"", and they do not have a __file__ attribute.  not only is this inconsistent, i believe it violates the documentation.  the fix here is to set both __spec__.origin and __file__ to none for namespace packages. i suppose it's possible that this will break existing code, but i'd argue that because current behavior runs counter to the documentation and makes no sense given the inconsistencies, it is better to fix them.  i propose this change be applied to 3.7 and 3.6, although if you, my friendly reviewer, disagrees about 3.6, we can talk about it! this isn't a security issue to back porting to 3.5 is off the table. </desc> <cmt> make sure __spec__.loader matches __loader__ for namespace packages </cmt> <cmt> update the documentation </cmt> <cmt> factor out the check for origin and has_location. </cmt> <cmt> also, repair a couple of tests. </cmt>",consistency fixes for namespace loaders
1246,"<desc> in order to support batch inference in onnx,  pr#3853 adding dummy proposal and batch dimension make the code difficult to understand. this pr modifies the test_mixins.py and bbox_head.py to remove all batch-inference-related code and be consistent with the logic before pr#3853. speed comparison with 1080ti model\fps batch parallel(batch1/batch4) fps image by image(batch1/batch4) fps faster-rcnn batch_size 10.1/8.5 10.2/8.5 mask-rcnn 7.5/6.7 7.7/6.7 cascade-rcnn 7.6/6.6 7.5/6.6 cacade-mask-rcnn 5.3/4.9 5.3/4.9 notes when input proposals of batch_nms has shape (0, 4), rpn_head would raise an error max_coordinate = boxes.max() runtimeerror: operation does not have an identity. this pr fix this. closes #5211 </desc> <cmt> [refactor] add simple_test to dense heads </cmt> <cmt> move test methods of rpn </cmt> <cmt> fix assert </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> move fun and add docstr </cmt> <cmt> move parameter position </cmt> <cmt> conflict resolution and merge master branch </cmt> <cmt> add yolact docstr </cmt> <cmt> (1) provide more detailed error information; (2) fix centernet aug error (3) fix point_rend aug error </cmt> <cmt> change to single </cmt> <iss> error while train default faster r-cnn model </iss>",revert the test_mixins to test image by image
1247,"<desc> let's make sure that we find the gpt partition table correctly if the root filesystem is on a luks partition. also see #1167. </desc> <cmt> gpt-auto: try to handle luks root partitions better </cmt> <cmt> if the root file system is located on an encrypted root disk, we'll not </cmt> <cmt> find the gpt partition table for it. let's fix that by following the </cmt> <cmt> slaves/ symlinks in /sys for the device. we only handle devices having </cmt> <cmt> exactly one backing device. </cmt> <cmt> also see: #1167 </cmt> <cmt> gpt-auto: minor simplificatin handling the no-auto gpt flag </cmt> <cmt> let's query the flags only once, and document why we ignore it for the </cmt> <cmt> esp. </cmt> <cmt> systemctl: a number of cleanups regarding error handling in systemctl </cmt>","handle luks root partitions better in gpt-auto, plus other fixes"
1248,"<desc> distributed unit tests for simnet/ctr/text_classification. 2.add batchauc cherry-pick from develop </desc> <cmt> batch auc (#13567) </cmt> <cmt> * add distributed auc </cmt> <cmt> * add attr ""is distributed"" and config it </cmt> <cmt> * add distributed auc </cmt> <cmt> * add batch auc and code format </cmt> <cmt> * code format </cmt> <cmt> * auc optimize </cmt> <cmt> * metric_op optimize </cmt> <cmt> * code clean </cmt> <cmt> * bug fix and code clean </cmt> <cmt> * bug fix and code clean </cmt> <cmt> * code optimize </cmt> <cmt> * code optimize </cmt> <cmt> * api spec update </cmt> <cmt> * comments optimized </cmt> <cmt> * add mutex </cmt> <cmt> * revert: add mutex </cmt> <cmt> * remove distribute metric </cmt> <cmt> * remove distribute metric </cmt> <cmt> * spec modifyed </cmt> <cmt> * add annotation, test=develop </cmt> <cmt> * keep api compatibility </cmt> <cmt> test=develop </cmt> <cmt> add distributed unit tests about text_classification/simnet-bow/ctr (#12812) </cmt> <cmt> * add dist ut for text_classification </cmt> <cmt> * add dist ut for text_classification </cmt> <cmt> * add simnet bow unittest </cmt> <cmt> * add dist ut for simnet bow </cmt> <cmt> * add trainning data url for simnet bow </cmt> <cmt> * add trainning data url for simnet bow </cmt> <cmt> * modify simnet test_reader to train reader </cmt> <cmt> * add test_dist_ctr </cmt> <cmt> * test_dist_ctr can run now </cmt> <cmt> * dense update is good </cmt> <cmt> * add unit test for selected rows </cmt> <cmt> * debug unit test </cmt> <cmt> * fix dist sparse update problem </cmt> <cmt> * constant args at init </cmt> <cmt> * optimize code </cmt> <cmt> * simnet optimize </cmt> <cmt> * fix debugstringex </cmt> <cmt> * optimize sum_op.h </cmt> <cmt> * add scaleopvartypeinference </cmt> <cmt> * clean code </cmt> <cmt> * fix test_dist_transpiler.py </cmt> <cmt> * code optimize </cmt> <cmt> * modify delta </cmt> <cmt> * fix sparse update bug </cmt> <cmt> * dist test use one cpu </cmt> <cmt> * update some data </cmt> <cmt> * remove unused code </cmt> <cmt> * add use cuda config </cmt> <cmt> * unit test fix </cmt> <cmt> * unit test fix </cmt> <cmt> * unit test fix </cmt> <cmt> * unit test fix </cmt> <cmt> * dist_word2vec use cpu </cmt> <cmt> * unit test fix </cmt> <cmt> * unit test fix </cmt> <cmt> * code clean </cmt> <cmt> * code clean </cmt> <cmt> * merge develop </cmt> <cmt> * api spec update </cmt> <cmt> * revert: api spec update </cmt> <cmt> * replace simnet data with fake </cmt> <cmt> * replace simnet data with fake </cmt> <cmt> * update dim </cmt> <cmt> * add batch auc </cmt> <cmt> * code clean </cmt> <cmt> * code clean </cmt> <cmt> * modify print to stderr </cmt> <cmt> * update simnet delta -> 1e-5 </cmt> <cmt> * update run_step </cmt> <cmt> * add use_reader_alloc </cmt> <cmt> * add use_reader_alloc </cmt> <cmt> * add use_reader_alloc </cmt> <cmt> * modify delta </cmt> <cmt> * add use_reader_alloc </cmt> <cmt> * fix stderr write </cmt> <cmt> * python3 compatibility </cmt> <cmt> test=develop </cmt> <cmt> * python3 compatibility, test=develop </cmt> <cmt> * update dist_text_classification.py </cmt> <cmt> * test=develop </cmt>",cherrypick batchauc/distributed ut from develop
1249,<desc> i split one of the long rdbms tutorials into two parts. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. </desc> <cmt> feat: split rdbms tutorial into two parts </cmt> <cmt> fix: update challenges across the rest of the languages </cmt>,add/rename md files for new rdbms tutorials
1250,"<desc> this is pr will guarantee the order of core plugins when you import them. this is a prerequisite for #5102 also, necessary for something @bradlc is working on </desc> <cmt> use export default instead of named exports </cmt> <cmt> i'm a little sad about this change, but it turns out that the order is </cmt> <cmt> not guaranteed for named exports in esm. it was the correct order in our </cmt> <cmt> tests because of babel, but not in native esm. </cmt> <cmt> update imports </cmt>","restructure core plugins, named exports to default export"
1251,"<desc> just some rgb fix as @fauxpark helped to implement, and added minila layout. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fix info about rgb leds on the bottom. </cmt> <cmt> added rgb leds support </cmt> <cmt> added rgb leds config options </cmt>",ymdk/bface - rgb config and minila layout
1252,"<desc> based on the icontrol api and and implemented by the bigsuds python library   this module allows to create and configure a ""monitor"" which is used to check the availability of a pool (managed by the already included bigip_pool module.) this specific modules handles 'tcp' monitors. the module is based on my implementaion of bigip_monitor_http (pr #4621) </desc> <cmt> implement bigip f5 tcp monitor </cmt> <cmt> bigip tcp monitor: add examples </cmt>",introduce big-ip f5 tcp monitor module
1253,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> reworded and expanded the description </cmt> <cmt> renamed the function in the multiple param example </cmt>",write arrow functions with parameters - expanded description
1254,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  n/a increase the version number in the header if appropriate. n/a if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add initiallayout property to tabnavigator in react-navigation </cmt> <cmt> update tests </cmt>",add initiallayout to tabnavigator in react-navigation
1255,"<desc> adds new keymap for muzfuz's preonic, plus a small addition to the current planck layout. </desc> <cmt> adds keymaps for muzfuz </cmt> <cmt> remove unused keys from adjust layer </cmt> <cmt> bring in line with current qmk standards. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> adds preonic and adjusted planck keymaps </cmt>",adds preonic keymap for muzfuz. small planck addition.
1256,"<desc> this pr fixes a bug introduced in #38848 where template errors would be raised on the incorrect line if template annotations were enabled. in order to consolidate the scope of the feature, @tenderlove and i simplified the implementation to just pass a preamble and postamble to erubi. </desc> <cmt> pass preamble/postamble to erubi, reducing coupling </cmt> <cmt> raise errors on correct line with annotations enabled </cmt>",raise template errors on correct line with annotations enabled
1257,"<desc> description: allow for using an adb server instance, such as the hass.io adb addon, with the fire tv component. this is a breaking change, as it removes the get_source configuration option. this includes the changes in #21131. related issue (if applicable): pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#8641 example entry for configuration.yaml (if applicable): media_player: - platform: firetv name: fire tv host: 192.168.0.123 adb_server_ip: 127.0.0.1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> bump firetv to 1.0.8 </cmt> <cmt> update the 'update' function for fire tv </cmt> <cmt> return none for properties when unavailable </cmt> <cmt> remove 'self.adb_lock' attribute </cmt> <cmt> remove threading import </cmt> <cmt> update configuration for fire tv component </cmt>",add adb server functionality to fire tv
1258,<desc> some unused java classes that were in the kotlin-mockito module were simply deleted instead of moved to the mockito module. </desc> <cmt> bael-809: add kotlin mockito supporting code </cmt> <cmt> bael-809: add references to kotlin-mockito library </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> bael-809: move kotlin-mockito to existing kotlin module </cmt> <cmt> some unused java classes that were in the kotlin-mockito </cmt> <cmt> module were simply deleted instead of moved to the mockito </cmt> <cmt> module. </cmt>,moved mockito-kotlin to existing mockito module
1259,<desc> this shortens the dialog and will help issues with it being too tall for small screens. </desc> <cmt> factor out class helpsrctest. </cmt> <cmt> split apart genpage.load_general_cfg. </cmt> <cmt> factor out class helpframe; adjust tests to match. </cmt> <cmt> adjust helpframe framing. </cmt> <cmt> move help extensions to extensions page. </cmt> <cmt> blurb </cmt>,move help extension settings to extensions page of dialog.
1260,"<desc> as @sigprof mentions in #9533, this was broken in #8770. now that unicodemap_index() is called before the unicode input functions, it must use the current modifier state, not the saved state. issue #9533 issue #9405 (partially) my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> fix issue #9533 (sending unicode via xp macro uses a delayed shift state) </cmt> <cmt> don't need to expose unicode_saved_mods anymore </cmt> <cmt> don't forget weak_mods </cmt>",fix issue #9533 - delayed shift state handling
1261,"<desc> add firmware code and documentation for the railroad keyboard. this replaces pr #10412. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> pull from master </cmt> <cmt> pull from master </cmt> <cmt> add the railroad keyboard, rev 0 </cmt>",add the railroad (rev 0)
1262,"<desc> please fill in this template: add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add decode-entities type definitions </cmt> <cmt> update tests </cmt>",add type definitions for decode-entities
1263,"<desc> in an effort to improve the noise-to-signal ratio of our smoke tests, i have explored what would it be to run each smoke test suite in its own --user-data-dir. this will add roughly a minute to each smoke test run but hopefully solve the random failures that are caused by one tests interfering with another. </desc> <cmt> initial commit for isolated smoke tests </cmt> <cmt> do not wait for the explorer view when restarting </cmt> <cmt> debug failed localization test </cmt> <cmt> user data path suffix length </cmt> <cmt> kill server when application exits </cmt> <cmt> do not run yarn install </cmt>",smoke tests - run each suite in its own user-data-dir
1264,"<desc> check transaction count early in submitblock. there is no point in even hashing a submitted block which doesn't have a coinbase transaction. this also results in more useful error reporting on corrupted input. thanks to rawodb for the bug report. </desc> <cmt> make getwitnesscommitmentindex callable on blocks without a coinbase txn. </cmt> <cmt> this isn't actually needed anywhere, but it's less brittle. </cmt> <cmt> check transaction count early in submitblock. </cmt> <cmt> there is no point in even hashing a submitted block which doesn't have </cmt> <cmt> a coinbase transaction. </cmt> <cmt> this also results in more useful error reporting on corrupted input. </cmt> <cmt> thanks to rawodb for the bug report. </cmt> <cmt> add braces to submitblock per current style. </cmt>",better error handling for submitblock
1265,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> add it to notneededpackages.json. </desc> <cmt> fix: incorrect property of token payload object </cmt> <cmt> fix: incorrect property of token payload object </cmt> <cmt> fix: incorrect property of token payload object </cmt>",incorrect token payload property name
1266,<desc> closes #2705 cypress no longer hides output from these commands when npm log level is silent or warn cypress --version cypress version cypress cache path cypress cache list this pr does not refactor the entire log or touch install progress messages like #2706 so the change should be easy to merge no output when running commands. for example from our docker images $ docker run -it --entrypoint=cypress cypress/included:4.2.0 --version ~/git/cypress-docker-images on master after prints versions has the original issue been tagged with a release in zenhub? </desc> <cmt> always log cache path </cmt> <cmt> cache list always logs </cmt> <cmt> cypress version should always log result </cmt> <iss> npm_config_loglevel env variable is silencing too much (--silent) </iss>,do not silence cli commands
1267,"<desc> if a custom component hasn't sent the ""component_ready"" message to its host iframe after a short while, it usually means something's gone wrong. but currently, the user doesn't see anything in this scenario - not even an empty space where their component would otherwise be rendered. with this pr, each componentinstance starts a timer when it loads. if its component hasn't sent the ready message after 3 seconds, the componentinstance shows a warning message with some troubleshooting advice: (the 3 second timeout, and the warning message, both need a product review pass.) this pr also pulls various streamlit url string literals into a urls.ts file (the warning uses several urls, and i wanted to make sure they weren't declared in multiple places). </desc> <cmt> move all our urls into a urls.ts file </cmt> <cmt> show a warning, with troubleshooting tips, when a component doesn't load for a while </cmt> <cmt> reword test declarations </cmt> <cmt> test the component_ready timeout warning </cmt>","""your component isn't loading"" warning"
1268,"<desc> i carefully read the contribution guidelines and agree to them. hey newpipe team, thanks for the great app. as an expat living in china, i really value the ability to download yt videos then play them later without having to stream them over a vpn. one issue i've had though is that the downloads activity is pretty bareboned, and oftentimes i can't even read the full video title. i've enabled a toolbar item in the downloads menu (most of the code was already there) to allow the user to switch between the grid and linear views. in the linear layout, the full video title should be displayed. do let me know if there are any issues - i'm certainly interested in continuing to contribute to newpipe dev in the future. </desc> <cmt> adding switch view button to downloads activity </cmt> <cmt> can now switch between linear and grid layouts in the downloads activity </cmt> <cmt> update linear layout </cmt> <cmt> re-arrange elements and allow the video title to display over multiple lines </cmt>",enable linear layout in downloads activity with full video names
1269,"<desc> based on #4382. makes run_interop_tests.py aware of ""new"" interop tests and adjusts blacklists to only run what is currently implemented. because some interop tests rely on new serverside features (echo metadata etc.), i added notion of test cases unimplemented by given server. </desc> <cmt> implemented more interop tests </cmt> <cmt> implement unimplemented_method interop test </cmt> <cmt> teach interop script about new tests </cmt>",run_interop_tests.py support for new interop tests
1270,<desc> moves all documentation to the website. includes rationale.md move contents and delete /editors directory breaks up usage into many pages. technically a breaking change for /usage.html urls. closes #2825 supersedes #3116 closes #3028 closes #3138 </desc> <cmt> sync readme -> docs/options.md </cmt> <cmt> sync readme -> docs/*.md </cmt> <cmt> misc fixups </cmt> <cmt> remove markdown-toc </cmt> <cmt> remove insert-pragma from toc </cmt> <cmt> never again! </cmt> <cmt> move all docs to ./docs </cmt>,move all docs to website
1271,"<desc> remove minnodeversion and corresponding public getsmallestversion getter method from discoverynodes remove unused discoverynode#removedeadmembers public method remove unused discoverynodes.delta constructor adjust visibility of discoverynodes.delta constructor: it can be private as it gets called by discoverynodes#delta method, which is supposed to be the only way to create a delta </desc> <cmt> remove minnodeversion and corresponding public getsmallestversion getter method from discoverynodes </cmt> <cmt> remove unused discoverynode#removedeadmembers public method </cmt> <cmt> remove unused discoverynodes.delta constructor </cmt> <cmt> adjust visibility of discoverynodes.delta constructor </cmt> <cmt> it can be private as it gets called by discoverynodes#delta method, which is supposed to be the only way to create a delta </cmt>",remove unused bits from discoverynodes
1272,<desc> for #5508. </desc> <cmt> split datasourcenamespacehandler and shardingdatasourcebeandefinitionparser </cmt> <cmt> refactor shardingrulebeandefinitionparser </cmt> <cmt> refactor org.apache.shardingsphere.driver.spring.namespace.parser.rule </cmt> <cmt> add masterslaverulebeandefinitionparser </cmt> <cmt> fix javadoc </cmt> <cmt> add masterslaverulebeandefinitionparsertag </cmt> <cmt> refactor org.apache.shardingsphere.driver.spring.namespace.constants </cmt> <cmt> refactor rulebeandefinitionparser </cmt> <cmt> refactor spring.handlers </cmt> <cmt> refactor xsd </cmt> <cmt> decouple datasource and rules dependencies </cmt> <cmt> rename rule of xsd </cmt>,redesign spring namespace for decouple datasource and rules dependencies
1273,<desc> this pr slightly tweaks the behaviour of str.capitalize so that it puts the first character into titlecase rather than uppercase. this only really changes the result for strings starting with digraphs or ligatures. this my first contribution here so i hope everything is correct! :) i wasn't too sure exactly which part of the documentation needed to be changed so i just put what i assumed was right. </desc> <cmt> apply the patch and modify tests accordingly. </cmt> <cmt> make appropriate changes to the documentation </cmt>,str.capitalize now titlecases the first character instead of uppercasing it
1274,<desc> description: this pr adds group binding functions to the zha device object and it exposes web socket operations that allow them to be leveraged by the front end. it currently works for zha profile devices and i am working on adding support for zll profile devices. pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io </desc> <cmt> initial group binding work </cmt> <cmt> add group cluster binding </cmt>,add zigbee group binding to zha
1275,"<desc> this is a follow-up to pr #1003. the python code in the project is now in fairly good shape pep8-wise. this pr fixes the last violation classes that can be fixed without introducing large diffs that would span many lines of code and hence mess up git blame, etc. after the merge of this pr only six violation classes are left in the code base fixed in this pr: continuation line under-indented for hanging indent (e121) continuation line with same indent as next logical line (e125) missing whitespace after ',' or ':' (e231) at least two spaces before inline comment (e261) too many blank lines (e303) </desc> <cmt> pep8: fix all violations of type ""missing whitespace after ':'"" (e231) </cmt> <cmt> pep8: fix all violations of type ""continuation line with same indent as next logical line"" (e125) </cmt> <cmt> pep8: fix all violations of type ""missing whitespace after ','"" (e231) </cmt> <cmt> pep8: fix violations of type ""continuation line under-indented for hanging indent"" (e121) </cmt> <cmt> add ""noqa"" marker and corresponding todo for pep8 violation that spans many lines </cmt> <cmt> pep8: fix all violations of type ""too many blank lines"" (e303) </cmt> <cmt> pep8: fix all violations of type ""at least two spaces before inline comment"" (e261) </cmt>",fix violations of non-controversial pep8 rules (follow-up)
1276,"<desc> ref #30999 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> adding message check to pytest.raises for test_dtypes.py </cmt> <cmt> found a type-o in one of the error messages and </cmt> <cmt> corrected it. </cmt> <cmt>  conflicts: </cmt> <cmt> 	pandas/tests/dtypes/test_dtypes.py </cmt> <cmt> readding message check to pytest.raises for test_dtypes.py </cmt> <cmt> they got undone due to new commits to pandas. </cmt> <cmt> fixed bare pytest raises in test_indexing.py. </cmt> <cmt> fixed bare pytest raises in test_replace.py </cmt> <cmt> fixed bare pytest raises in test_apply.py </cmt> <cmt> fixed bare pytest raises in test_arithmetic.py </cmt> <cmt> fixed bare pytest raises in test_axis_select_reindex.py </cmt> <cmt> fixed bare pytest raises in test_axis_select_reindex.py </cmt> <cmt> fixed bare pytest raises in test_constructors.py </cmt> <cmt> fixed bare pytest raises in test_dtypes.py.py </cmt> <cmt> fixed bare pytest raises in test_operators.py </cmt> <cmt> fixed bare pytest raises in test_reshape.py </cmt> <cmt>  conflicts: </cmt> <cmt> 	pandas/tests/dtypes/test_dtypes.py </cmt> <cmt> blacked the files before creating pull request </cmt>",avoid bare pytest.raises in multiple files
1277,"<desc> currently, both main.js and router.js templates contain arrow functions. when a user chooses not to select babel or typescript during project creation, the generated code will fail in browsers that don't support arrow functions. since we aim to be compatible with ie 11 out of the box, i added conditionals to the templates for these files to use a normal function instead when neither babel nor typescript plugins are detected. </desc> <cmt> fix(cli-service): es5 compatibility - </cmt> <cmt> don't use arrow function in main.js when not using babel nor typescript. </cmt> <cmt> fix(router): es5 compatibility </cmt> <cmt> use normal function instead of arrow function </cmt> <cmt> in router.js when neither babel nor typescript are used. </cmt>",fix template files for main.js and router when not using a compiler
1278,"<desc> provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> satisfying new full text search tests. </cmt> <cmt> added fulltext test. </cmt>",added fulltext function to parse.query
1279,"<desc> fixes api wording to comply with conventions for api documentation and adds action view interaction with active model. </desc> <cmt> fixes api wording to match api conventions </cmt> <cmt> in activemodel::model api documentation, referrences to rails </cmt> <cmt> components were tagged with fixed-width font and named as if </cmt> <cmt> they were modules.this fixes the inconsistency to match api </cmt> <cmt> documentation conventions. </cmt> <cmt> [ci skip] </cmt> <cmt> add action view to active model api documentation </cmt> <cmt> in rails 4.1, action view was extracted from action pack, but this </cmt> <cmt> change was not reflected in the api documentation of activemodel::model. </cmt> <cmt> this commits makes it explicit in the documentation that active model </cmt> <cmt> also interacts with action view as well as action pack. </cmt> <cmt> [ci skip] </cmt>",fix activemodel::model api documentation [ci skip]
1280,<desc> related issue = #2223 @k-ye </desc> <cmt> [misc] deleted 3 debug messages in codegen_cc.cpp </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> [ir] [transforms] [docs] added assertion that indices won't cause overflow under debug mode. fixed one typo in write_test docs. </cmt> <cmt> update tests/python/test_indices_assert.py to test cpu only </cmt> <cmt> [skip ci] enforce code format </cmt> <cmt> added comment </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> [python] [lang] removed taichi.lang.core. </cmt> <cmt> [python] [lang] replaced usage of taichi.lang.core with taichi.core.util.ti_core. </cmt> <cmt> formated python code </cmt> <cmt> merge with upstream </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> [refactor] unified ti_core usage in python/taichi/misc and python/taichi/main & testing </cmt> <cmt> [refactor] unified ti_core usage in python/taichi/misc and python/taichi/main & testing </cmt>,"unified ti_core usage to _ti_core in python/taichi/misc, python/taichi/main and testing."
1281,"<desc> attempt to fix conda-forge/scikit-learn-feedstock#124 i rather this be const char but there were build errors in the conda-forge build. the error in the build logs are: python3.7/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:234: in __init__ min_samples_leaf, min_gain_to_split, hessians_are_constant) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ >   ??? e   valueerror: buffer dtype mismatch, expected 'const char' but got 'signed char'  (will think about how reproduce this locally when i wake up.) </desc> <cmt> bug fixes cython in splitting </cmt> <cmt> rev revert </cmt>",bug fixes cython code for ppc arch
1282,<desc> as reported in the forum there was a deadlock when stopping playback. problem was that the refclock was about to stop and hold the gfx lock while doing so. at the same time due to refreshrate switching back we tried to init the display link which in return tried to fetch the current gl context. as i figured out this context might return nil (null) if its not queried from the main thread. thats why i altered it to force execution via mainthread in pr #7143. this deadlocked because mainthread was waiting for us to exit the videosync thread while we were stuck waiting for the mainthread to become free. this fixes the issue by using the tracked gl context from windowing instead of querying it ourselfs. fix was reported valid by the bug reporter here:  @fernetmenta iirc you even suggested this in the first place. sry for not having the overview here :/ </desc> <cmt> [windowing/osx] - expose the current nsopenglcontext tracked by windowing to the outside via a getter </cmt> <cmt> [osx/cocoa] - revert 0f32a2f5d4fb1077def8c581098aa4385e8d0a67 (it is prone to deadlocking because it blocks the gui/main thread) and instead trust in the openglcontext which is tracked by windowing. fixes deadlock introduced by pr #7143 </cmt>,fix deadlock when videosync and refreshrate adaption are enabled
1283,<desc> this is the partial backport of #7801 for isengard. </desc> <cmt> filesystem: make pipe:// available even if there's no network interface available </cmt> <cmt> filesystem: make bluray:// available even if there's no network interface available </cmt> <cmt> filesystem: make resource:// available even if there's no network interface available </cmt>,"make pipe://, bluray:// and resource:// available even if there's no network interface available"
1284,<desc> the error message being displayed when either an authorization or authentication error occurs upon cli connection to the es server is confusing and doesn't reflect the underlying cause. this pr addresses this. fix for #33230 </desc> <cmt> different handling for security specific errors in the cli. fix for </cmt>,handle differently security connection related errors in the cli
1285,"<desc> add advanced mysql dump options for expert user. for example,some one only want to dump data structure but not data,the need to give a ""--no-data"" option </desc> <cmt> add advanced mysql dump options for expert user </cmt> <cmt> for example,some one only want to dump data structure but not data,the need to give a ""--no-data"" option </cmt> <cmt> add advanced mysql dump options for expert user </cmt> <cmt> for example,some one only want to dump data structure but not data,the need to give a ""--no-data"" option </cmt>",mysql dump advance option support
1286,"<desc> this pr's goal was to add an option to the opensettings keybinding to open the settings ui in a tab. in order to implement that, a couple of changes had to be made to tab, specifically: introduce a tab interface named itab create/rename two new tab classes that implement itab called settingstab and terminaltab i've also put some todos that i wanted to get some thoughts on - i'll make a follow up pr but perhaps they can be revisited when we flesh out the settings ui more. does a settings ui tab shutdown need to do anything special for cleanup? does a settings ui tab need to have getactivetitle? maybe depending on which page in the ui is open? technically, i can't focus a grid control, so i'll need to figure out what to focus when the tab is selected. the settings ui tab doesn't have a termcontrol, so once focus is moved to that tab, users won't be able to nexttab/prevtab out of it (along with all other keybindings). references #1564, #5915 </desc> <cmt> itab, winrtimplements, now i need the tab changes from master </cmt> <cmt> getting updated with feature </cmt> <cmt> settingstab, building fine, still need hookups to create it </cmt> <cmt> egads it opens a new tab on keybinding pog </cmt> <cmt> give it a fixed font icon, call update title and icon </cmt> <cmt> welp it builds in vs, doesn't want to build in cmd tho so i can't runtests </cmt> <cmt> goin back to good ol' getstrongtabimpl </cmt> <cmt> changing the name to be a bit more descriptive </cmt> <cmt> function name updates, revisiting itab interface </cmt> <cmt> comment updates </cmt> <cmt> runformat </cmt> <cmt> teaching mr bot </cmt> <cmt> cleanups, one tab at a time, switch to existing tab </cmt>",add functionality to open the settings ui tab through opensettings
1287,"<desc> tracking github issue: #3647 issue: apache spark users running xgboost on spark may expect over-the-wire encryption for xgboost based on spark confs, but they will not get it and may never know about the security issue. this pr changes xgboost.traindistributed to check the spark conf spark.ssl.enabled and throw an exception if the user expects encryption over-the-wire. in the error message, this tells the user how to get around this security check at their own risk. the user can tell xgboost-spark to ignore spark.ssl.enabled by setting an xgboost-specific conf in the sparkconf: xgboost.spark.ignoressl. this adds 1 unit test with xgboostclassifier to check this behavior. </desc> <cmt> added test, commented out right now </cmt> <cmt> reinstated test </cmt>",xgboost-spark warning when spark encryption is turned on
1288,<desc> xref #29547 for pandas/util/_print_versions.py pandas/tests/tseries/frequencies/test_to_offset.py </desc> <cmt> replace .format with f-strings </cmt> <cmt> replace .format with f-strings </cmt> <cmt> replace .format with f-strings </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt> <cmt> replace .format with f-strings in files </cmt>,replaced .format with f- strings
1289,<desc> both the following files are in the gpr_base library (see build.yaml) while slice.h and slice_buffer.h are in the grpc_base library. this would cause issues in building binaries that just depend on gpr_base but not on grpc_base src/core/lib/support/string.h src/core/lib/support/tmpfile.h </desc> <cmt> remove redundant includes </cmt> <cmt> remove redundant includes </cmt>,remove redundant includes from string.h and tmpfile.h
1290,<desc> i have followed (at least) the pr section of the contributing guide. the following demos of the icons component were migrated: svgmaterialicons svgiconscolor svgiconssize createsvgicon fontawesomesvgicondemo icons fontawesomeicon fontawesomeiconsize visuallyhidden related to #16947 </desc> <cmt> docs: migrate svgmaterialicons demo to emotion </cmt> <cmt> docs: migrate svgiconscolor demo to emotion </cmt> <cmt> docs: migrate svgiconssize demo to emotion </cmt> <cmt> docs: migrate createsvgicon demo to emotion </cmt> <cmt> docs: migrate fontawesomesvgicon demo to emotion </cmt> <cmt> docs: migrate icons demo to emotion </cmt> <cmt> docs: migrate fontawesomeicon demo to emotion </cmt> <cmt> docs: migrate fontawesomeiconsize demo to emotion </cmt> <cmt> docs: migrate visuallyhidden  demo to emotion </cmt>,migrate icons demos to emotion
1291,"<desc> issue #661 , #768 , #769 handle hashing dicts hash unknown objects using __reduce__ instead of pickling throw unhashabletypeerror when an object is not hashable squash cache warnings update hashing error message </desc> <cmt> wip handle iterables, objects and unhashabletype erro in hashing </cmt> <cmt> black </cmt> <cmt> cleanup </cmt> <cmt> cleanup </cmt> <cmt> unused import </cmt> <cmt> hash list, tuple and dict but not iterables </cmt> <cmt> fix hashing dicts </cmt> <cmt> tests for hashing dict, iterable, user object </cmt> <cmt> black </cmt>",handle caching of dicts and custom objects
1292,"<desc> we had a jvm failure in the yarn tests, that seems extremely rare. before filing a ticket with java, i want to see if we are experiencing this issue again with the latest jdk11, that's why i'm updating the docker image. </desc> <cmt> [flink-20165][ci] update test docker image </cmt> <cmt> relevant version changes: </cmt> <cmt> package						old							new </cmt> <cmt> adoptopenjdk-11-hotspot 	11.0.7+10-2					11.0.9+11.2-3 </cmt> <cmt> openjdk-8-jdk:amd64 		8u242-b08-0ubuntu3~16.04	8u275-b01-0ubuntu1~16.04 </cmt> <cmt> docker.io 					18.09.7-0ubuntu1~16.04.5	18.09.7-0ubuntu1~16.04.6 </cmt> <cmt> [hotfix][yarn] provide .out files in debug logs as well </cmt>",update test docker image & improve yarn logging
1293,"<desc> breaking change: none known. description: uses evohome-async instead of evohome-client, and thus switches from requests to aiohttp. addresses issue #25400, and adds code to handle devices with flat batteries. some minor de-linting. related issue (if applicable): fixes #25400 pull request with documentation for home-assistant.io (if applicable): n/a example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> fully async now (but no convergence yet) </cmt> <cmt> wrap api calls, handle flat battery </cmt> <cmt> tweak timings </cmt> <iss> changes to evohome take minutes to appear in the ui </iss>",change evohome to asyncio client
1294,"<desc> it will pass isolated test (test per file), but somehow created t.datetime :written_on, precision: 6 causes any side effects and ci will be failed only mysql adapter. for example, the failures on attribute_methods_test.rb is due to caching emulate_booleans = false's boolean type, it will be fixed by adding topic.reset_column_information.  but if added topic.reset_column_information, it will cause new failures test_preserving_time_objects_with_time_with_zone_conversion_to_default_timezone_{utc,local} in base_test.rb. so i decided to skip datetime with precision tests for mysql adapter since the adapter has already been removed after 5.0, it is not worth to fix the side effects in 4-2-stable. </desc> <cmt> fix datetime precision support for mysql adapter </cmt> <cmt> don't test datetime with precision for mysql adapter </cmt> <cmt> it will pass isolated test (test per file), but somehow created </cmt> <cmt> t.datetime :written_on, precision: 6 causes any side effects and ci </cmt> <cmt> will be failed only mysql adapter. </cmt> <cmt> so i decided to skip datetime with precision tests for mysql adapter </cmt> <cmt> since the adapter has already been removed after 5.0, it is not worth to </cmt> <cmt> fix the side effects in 4-2-stable. </cmt>",fix datetime with precision for mysql adapter
1295,<desc> description: allow managing which entities are exposed to alexa via the ui. frontend pr: home-assistant/frontend#3269 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: </desc> <cmt> clean up alexa config </cmt> <cmt> cloud: manage alexa entities via ui </cmt>,allow managing alexa entities via ui
1296,"<desc> add error checking for target_type=ip not supported (#38299) including test suite improve module to latest standards elb_target_group ansible version ansible 2.6.0 (devel 1c7b9e66b4) last updated 2018/04/05 12:23:13 (gmt +1000) config file = none configured module search path = [u'/home/will/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/will/src/ansible/lib/ansible executable location = /home/will/src/ansible/bin/ansible python version = 2.7.14 (default, mar 14 2018, 13:36:31) [gcc 7.3.1 20180303 (red hat 7.3.1-5)] </desc> <cmt> add helpful failure message if target_type=ip is not supported </cmt> <cmt> create test case for target_type=ip not supported </cmt> <cmt> update elb_target_group module to latest standards </cmt> <cmt> use ansibleawsmodule </cmt> <cmt> improve exception handling </cmt> <cmt> improve connection handling </cmt>",fail with nice error message if elb target_type=ip not supported
1297,"<desc> i introduced an actions error into the repo sync process a few hours ago. the actions error will be resolved by updating to the latest repo-sync/pull-request action in this manual one-time repo sync. all of the tests are passing. i have reviewed my changes in staging. for content changes, i have reviewed the localization checklist for content changes, i have reviewed the content style guide for github docs. </desc> <cmt> give link checker access to enterpriseserverversions (#16198) </cmt> <cmt> update to latest repo-sync/pull-request to fix bash error (#16203) </cmt>",manual repo sync to fix the actions error
1298,"<desc> this pr fixes #132183 and adds a new api method to replaceall output channel text to improve output channel rendering for extensions that use the output channel for minimal output. cc: @sandy081, @jrieken </desc> <cmt> add replaceall method to outputchannel to improve render flickering for extensions with minimal output contents; associated with </cmt> <iss> api: improved output channel rendering capability for extension developers - way to replace/update the content </iss>",new replaceall api to improve output channel rendering
1299,"<desc> opera 19 has finally added support for the streamsprivate api, and whitelisted the pdf viewer hosted on addons.opera.com with (extension id encfpfilknmenlmjemepncnlbbjlabkc). this feature was developed 5 months ago at  see commit messages for implementation notes. to test the extension in opera 19, follow the following steps: get opera 19 from  build the extension (instructions at  unpack the zip file. start opera, and go to extensions (ctrl + e). click on the button to enable developer mode. click on ""load unpacked extension"". use the file browser to select the directory containing the contents of the extracted zip file (or if you've built yourself: pdf.js/build/chromium). to verify that the new feature works as intended, try to view a pdf file from a ftp site. just google for ""ftp pdf"" and pick any search result that serves a pdf file over ftp:. unfortunately, chromium has not yet responded to the request of getting the extension id whitelisted:  fixes issues: operasoftware#8 / </desc> <cmt> proof of concept using chrome.streamsprivate api </cmt> <cmt> this method captures all application/pdf streams, loads the viewer </cmt> <cmt> and passes the stream to the pdf.js viewer. </cmt> <cmt> this commit shows a proof of concept using the chrome.streamsprivate api. </cmt> <cmt> advantages of new method: </cmt> <cmt> - access to the response body of the original request, thus fewer </cmt> <cmt> network requests. </cmt> <cmt> - pdfs from non-get requests (e.g. post) are now supported. </cmt> <cmt> - ftp files are also supported. </cmt> <cmt> possible improvements: </cmt> <cmt> - use declared content scripts instead of dynamic chrome.tabs.executescript. </cmt> <cmt> this allows the extension to render the viewer in frames when the </cmt> <cmt> extension is disallowed to run executescript for the top url. </cmt> <cmt> - use chrome.declarativewebrequest instead of webrequest, and replace </cmt> <cmt> background page with event page (don't forget to profile the </cmt> <cmt> difference & will the background/event page still work as intended?). </cmt> <cmt> insert dummy content script at every location. </cmt> <cmt> this is needed for propagating the extension's permissions </cmt> <cmt> to the extension's iframe, in the rare event that the pdf is </cmt> <cmt> loaded in a sub frame, and the extension does not have access to the </cmt> <cmt> top frame. for instance, when a http:-pdf file is embedded in a </cmt> <cmt> local file, while ""allow access to local urls"" is disabled. </cmt> <cmt> note: propagating permissions by inserting content scripts is an </cmt> <cmt> undocumented feature ( </cmt> <cmt> whenever it breaks, the issue (cross-domain permissions for xhr) </cmt> <cmt> can be solved by using a content script that gets the blob using </cmt> <cmt> the xmlhttprequest api, followed by postmessage (via transferables) </cmt> <cmt> to efficiently pass the arraybuffer back to the pdf viewer. </cmt> <cmt> use tab-specific stream storage </cmt> <cmt> also: </cmt> <cmt> - use webnavigation.getallframes to find out whether the navigation has </cmt> <cmt> already started. this is (at least) needed for top-level navigation to </cmt> <cmt> a stream. the webnavigation.onerroroccurred event has become obsolete, </cmt> <cmt> and has been removed. </cmt> <cmt> work-around for </cmt> <cmt> when a new incognito session is started, the onexecutemimetypehandler event is </cmt> <cmt> often not dispatched in time. instead, it's triggered in the non-incognito profile. </cmt> <cmt> this commit offers a work-around that allows new incognito instances to view pdf files. </cmt>",chromium extension using streamsprivate api!
1300,"<desc> added my layout for the yd60mq. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> 64 key layout </cmt>",yd60mq add 64 key layout
1301,"<desc> turns out we didn't have a test for previous behaviour, worryingly... </desc> <cmt> rename throwhelper to preconditions and make it public - we'll want to use it from the generated code soon. </cmt> <cmt> additionally, change it to return the value passed, and make it generic with a class constraint. </cmt> <cmt> a separate method doesn't have the class constraint, for more unusual scenarios. </cmt> <cmt> prohibit null values for string/bytes fields in generated code. </cmt> <cmt> generated code for previous commit. </cmt>",throw on null for string/bytes single fields
1302,"<desc> this pr fixes #10565 add the ability to ignore snippets so that they don't appear in intellisense or tab completions. tho, they can still be inserted via ""insert snippet"" and that's also the place at which ignoring is configure. the following gif shows how the dowhile typescript snippet is being ignored </desc> <cmt> add persisted snippet enablement </cmt> <cmt> expose snippet enablement inside ""insert snippet"" picker </cmt> <iss> [snippets] cannot override/disable snippets defined in extensions </iss>",add ability to ignore snippets (from intellisense)
1303,"<desc> make sure we don't list dashboards you only have access to the text widgets in them (fixes #4099). it does mean that if someone creates a dashboard with only a text widget in it, only they will see it listed. doesn't feel like a big issue. appheader: some elements were rendered when they aren't supposed to (like create button or query snippets link). allow using query results apis with execute_query permission (along with view_query). #4099 </desc> <cmt> allow executing query with either view_query or execute_query permissions. </cmt> <cmt> render authheader according to permissions. </cmt> <cmt> don't return dashboards where you only have access to textbox widget. </cmt> <cmt> closes #4099. </cmt> <iss> dashboards list includes dashboards with text widgets where you have no access to any other widgets </iss>",refine permissions usage in redash to allow for guest users
1304,"<desc> awesome project! i stumbled across this when trying to figure out how to keep my someonewhocares.org hosts file up to date. i added a python script that can go out and update these sources and do the merge all at once. all you have to do is run the script and commit the changes. i also added a whitelisting mechanism, that addresses your issue #1. </desc> <cmt> added script to handle updates to hosts sources. </cmt> <cmt> updatehostsfile.py can handle either simply combining local hosts files you have checked in, or it can </cmt> <cmt> go out to the internet to update your source files. it also handles automatically generating a header </cmt> <cmt> and removing duplicates from the list. </cmt> <cmt> new hosts file generated using script. </cmt> <cmt> this commit is the first merged hosts file to utilize the updatehostsfile.py script. </cmt> <cmt> the only working difference is that it pulled in a new someonewhocares.org hosts file. </cmt>",added simple python script to handle automatic updates and merges
1305,"<desc> adding simple definition file for humane.js and adding links to all of the completed projects. </desc> <cmt> quick first pass at the definition of humane.js </cmt> <cmt> adding links to the project websites, adding humane.js </cmt>",adding definition file and linking projects in readme.
1306,"<desc> the commit message contains more information about the eslint changes. </desc> <cmt> update translations </cmt> <cmt> update packages </cmt> <cmt> upgrade to eslint version 6 </cmt> <cmt> this major version bump required two changes: </cmt> <cmt> - the global line in the mobile viewer example should be removed because </cmt> <cmt> the .eslintrc file already defines these globals and with the new </cmt> <cmt> eslint version we otherwise get an error saying ""'pdfjslib' is already </cmt> <cmt> defined as a built-in global variable"". </cmt> <cmt> - the ecma version for the examples must be set to 6 since we're using </cmt> <cmt> modules, otherwise we get an error saying ""sourcetype 'module' is not </cmt> <cmt> supported when ecmaversion < 2015"". it turns out that the previous </cmt> <cmt> version of eslint already used ecma version 6 silently even though </cmt> <cmt> we set 5, see </cmt> <cmt> so in terms of our code nothing really changes. </cmt>",update translations/packages and upgrade to eslint version 6
1307,"<desc> this is a rebased version of #7169. sorry @rajzshkr, i couldn't manage to push to your branch. i'd like to merge this soon (it aleady received two approvals), since it is very likey to have conflicts. fixes #7063 </desc> <cmt> code changes </cmt> <cmt> renamed files </cmt> <iss> test fixtures: rename actual/expected to input/output </iss>",rename actual/expected to input/output in fixtures.
1308,"<desc> a bit of a grab bag. this is all useful for something i'm hacking on every now and then, but it's arguably (minorly) useful in itself, so i'm trying to reduce my local diff a bit :) </desc> <cmt> ak: remove duplicate begin()/end() methods </cmt> <cmt> begin()/end() returning a constitertor already exist further up </cmt> <cmt> in this file. nothing uses these redundant versions, and they are not </cmt> <cmt> callable. </cmt> <cmt> libcore: add an argsparser::add_option() overload for doubles </cmt> <cmt> kernel: update timemanagement::m_epoch_time directly in increment_time_since_boot </cmt>",teach argsparser about options taking doubles; tweak epoch time update; remove unused methods
1309,"<desc> node-integration can be used to control whether the node integration should be enabled in iframes, fixes #168. </desc> <cmt> don't append duplicate arguments to renderer process. </cmt> <cmt> don't pollute process.argv of browser process. </cmt> <cmt> append --iframe-security to renderer process. </cmt> <cmt> add iframe-security support. </cmt> <cmt> rename iframe-security to node-integration. </cmt> <cmt> fix loss of --node-integration token after refresh. </cmt> <cmt> do not use plain string iterals. </cmt> <cmt> fix crash when opening multiple pages at the same time. </cmt> <cmt> add docs on the node-integration setting. </cmt> <cmt> :lipstick: fix cppling warning. </cmt> <iss> non-priveleged iframes </iss>","add ""node-integration"" option to browserwindow"
1310,"<desc> refs #2090. a year ago we have discarded the gtk+ implementation of message box as part of transition to use chromium's aura gui toolkit, because aura doesn't work well with gtk+ together at that time. but now since those issues have been solved, and it is hard to make our custom dialog behave exactly the same with native dialog, i'm now bring back the gtkmessagebox implementation, with a few improvements. </desc> <cmt> seperate linux's implementation of message box </cmt> <cmt> use setgtktransientforaura from libgtk2ui </cmt> <cmt> gtk: implement message box apis </cmt> <cmt> fix focusing message box </cmt> <cmt> gtk: map dialog type to message box type </cmt> <cmt> reuse showmessagebox in showerrorbox </cmt> <cmt> simplify the code </cmt> <cmt> allow ""detail"" to be empty </cmt> <cmt> make ""title"" work </cmt>",use gtkmessagebox for dialog.showmessagebox on linux
1311,"<desc> ray's signal handler may conflict with the signal handler set by jvm. here we avoid calling installfailuresignalhandler during the initialization of a java worker and calling uninstallsignalaction during the exit of jvm. it's possible to fix this by chaining signal handlers, as described here:  i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> fix segmentation fault in java test </cmt> <cmt> update comments </cmt>",fix ut segmentation fault on exit
1312,"<desc> running ilm with trace logging on as follows (see snippet), i was seeing stacktraces logged that i didn't expect to see. since this isn't actually an exceptional case, i added a shortcut to skip the logging. put _cluster/settings { ""transient"": { ""indices.lifecycle.poll_interval"": ""15s"", ""logger.org.elasticsearch.xpack.ilm"": ""debug"", ""logger.org.elasticsearch.xpack.core.ilm"": ""trace"" } } example log output: java.lang.nullpointerexception: cannot invoke ""string.length()"" because ""content"" is null at com.fasterxml.jackson.core.jsonfactory.createparser(jsonfactory.java:1045) ~[jackson-core-2.10.4.jar:2.10.4] at org.elasticsearch.common.xcontent.json.jsonxcontent.createparser(jsonxcontent.java:74) ~[elasticsearch-x-content-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.xpack.core.ilm.phasecachemanagement.readstepkeys(phasecachemanagement.java:230) [x-pack-core-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.xpack.ilm.policystepsregistry.parsestepkeysfromphase(policystepsregistry.java:202) [x-pack-ilm-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.xpack.ilm.indexlifecycletransition.validatetransition(indexlifecycletransition.java:89) [x-pack-ilm-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.xpack.ilm.indexlifecycletransition.moveclusterstatetostep(indexlifecycletransition.java:116) [x-pack-ilm-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.xpack.ilm.executestepsupdatetask.execute(executestepsupdatetask.java:109) [x-pack-ilm-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.clusterstateupdatetask.execute(clusterstateupdatetask.java:48) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.masterservice.executetasks(masterservice.java:750) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.masterservice.calculatetaskoutputs(masterservice.java:366) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.masterservice.runtasks(masterservice.java:229) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.masterservice.access$100(masterservice.java:63) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.masterservice$batcher.run(masterservice.java:161) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.taskbatcher.runifnotprocessed(taskbatcher.java:139) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.cluster.service.taskbatcher$batchedtask.run(taskbatcher.java:177) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.common.util.concurrent.threadcontext$contextpreservingrunnable.run(threadcontext.java:678) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.common.util.concurrent.prioritizedesthreadpoolexecutor$tiebreakingprioritizedrunnable.runandclean(prioritizedesthreadpoolexecutor.java:259) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at org.elasticsearch.common.util.concurrent.prioritizedesthreadpoolexecutor$tiebreakingprioritizedrunnable.run(prioritizedesthreadpoolexecutor.java:222) [elasticsearch-7.16.0-snapshot.jar:7.16.0-snapshot] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1130) [?:?] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:630) [?:?] at java.lang.thread.run(thread.java:831) [?:?] </desc> <cmt> add a passing test </cmt> <cmt> shortcut the case where phasedef is null </cmt> <cmt> for example, when an index is moving into the 'new' phase, this will </cmt> <cmt> avoid us trace logging an exception (since you can't parse null as </cmt> <cmt> json). </cmt>",clean up null handling a little to avoid a stacktrace in the logs
1313,"<desc> added a haskell implementation of the 2d line intersection finding program and the readme file for the package. </desc> <cmt> updating my fork with changes from opengenus/cosmos </cmt> <cmt> merging with upstream </cmt> <cmt> merging upstream opengenus/cosmos with mine to sync the fork. </cmt> <cmt> consumed adichat's merge, updating fork's longest_palindromic_sequence.py file accordingly. </cmt> <cmt> syncing with upstream -- original opengenus/cosmos </cmt> <cmt> syncing upstream opengenus/cosmos with fork. </cmt> <cmt> added 2d line intersection program in haskell and updated the package specific readme. </cmt>",added haskell implementation of the 2d line intersection finding program
1314,"<desc> if you find a typo in the news file, please file a new pr. let's get this pr merged quickly, rather then iterate through a couple of revisions, after all none of this will break the build. </desc> <cmt> editors: only extend line width to 119 for c and xml files </cmt> <cmt> for all other files leave the line width at 79 as before. this is a good idea </cmt> <cmt> since we generally don't want text files such as catalog files, unit files or </cmt> <cmt> readme/news files to be line-broken at 119 since they are regularly browsed on </cmt> <cmt> text terminals. </cmt> <cmt> while we are at it, also add a couple of comments to the various files. </cmt> <cmt> (note that .editorconfig doesn't carry line-width information, simply because </cmt> <cmt> the specification doesn't know the concept.) </cmt> <cmt> news: start putting together a news file for 229 </cmt> <cmt> totally incomplete, but let's get this started. </cmt>","edit config updates, and a new news file"
1315,"<desc> refs #9192 to anyone seeing this go by - i'm about to start some fairly major refactoring work on the url utility. before i do that, i wanted to make sure i had 100% coverage, and understanding of some of the weird cases. the majority of the changes i've made are adding tests, but i was also able to clean up a little bit, remove a few lines or change them to make use of other tools. </desc> <cmt> toward 100% coverage - config.url has default val </cmt> <cmt> missing urlpathforpost tests </cmt> <cmt> urlfor: test api relative path </cmt> <cmt> urlfor: remove unused cors case </cmt> <cmt> urlfor: remove unreachable case </cmt> <cmt> navigation stuff is hairy as fuck </cmt> <cmt> - cleaned up the code a tiny bit, but i think this can be completely rewritten to be way more robust </cmt> <cmt> - added a whole heap more tests </cmt> <cmt> add more tests for edge cases </cmt> <cmt> add missing tests for isssl </cmt> <cmt> undo only </cmt>",increased url utility coverage to 100%
1316,"<desc> fixes #4696 part of the fix for #4139 will leave it for @m-allanson to review look forward to your feedback, thanks. </desc> <cmt> new page an title </cmt> <cmt> add in outline </cmt> <cmt> build tools </cmt> <cmt> node-install </cmt> <cmt> links and preamble </cmt> <cmt> debian too </cmt> <iss> using windows subsystem linux: debian </iss>",add docs page on setting up linux for gatsby
1317,"<desc> @rocketchat/core closes #5226 closed #5176 integrations list new integration new outgoing integration outgoing integration overview outgoing integration advanced settings outgoing integration history list outgoing integration history list item </desc> <cmt> convert the majority of the integrations package to javascript </cmt> <cmt> move the trigger handler to it's own class </cmt> <cmt> start trying to generalize integration items </cmt> <cmt> yay, additional events trigger outgoing webhooks </cmt> <iss> outgoing webhook trigger on file upload </iss> <iss> webhook for new channel created </iss>",enhance outgoing webhooks and add history
1318,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. closes #36749 closes #36691 </desc> <cmt> fix/ make modal more visible and adjust learn tabs on mob </cmt> <cmt> fix: clean up </cmt> <iss> make modals and elements high contrast </iss> <iss> learn tabs on mobile need touch up </iss>",modal a11y and learn tabs on mobile
1319,<desc> this pull request moves the prometheus scraping annotations to the statefulset pods. this is to populate the metrics with pod metadata. dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/rabbitmq-ha] prometheus annotations on pod </cmt> <cmt> [stable/rabbitmq-ha] bump chart version </cmt>,move prometheus annotations to pods
1320,<desc> closes #323. i've abstracted the reset method solution from #337 into separate server + style context functions to make it a little bit more future proof. i've added both integration and unit tests for the new functionality and fixed the context from being shared between unit tests by calling these functions in beforeeach. </desc> <cmt> add resetservercontext function to api for use with ssr </cmt> <cmt> add unit tests for resetservercontext and resetstylecontext </cmt> <iss> way to reset data-react-beautiful-dnd-draggable for server side rendering </iss>,add resetservercontext function for ssr
1321,"<desc> adds jsdocs to the exported types, mostly to explain the generic arguments as well as increase test coverage, making sure the resulting resolver is typed correctly in both single value and array version. also removed an unnessecary union as return type. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add jsdocs + remove unnessecary union return type </cmt> <cmt> add batchfn jsdocs </cmt> <cmt> improve test coverage </cmt> <cmt> clean up jsdocs </cmt>",improve test coverage and add jsdocs
1322,"<desc> typo in property name, should be fixed which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes #7470 </desc> <cmt> additing an option to create extra route for kubernetes service network </cmt> <cmt> bump chart version </cmt> <cmt> bump minor update version </cmt> <cmt> [stable/openvpn] fixing typo in openvpn.ovpn_k8s_svc_subnet value name </cmt> <cmt> resolving conflict </cmt>",fixing typo in  ovpn_k8s_svc_subnet property name
1323,"<desc> there are no functions named distance1() and distance2() in linesegment class from javascript code. so merge functions distance1() and distance2() to distance(). add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> add it to notneededpackages.json. </desc> <cmt> [fix] cannot find linesegment.distance1() or linesegment.distance1() </cmt> <cmt> there are no functions named distance1 and distance2 in linesegment class. </cmt> <cmt> so merge functions distance1 and distance2 to distance. </cmt> <cmt> add test code </cmt>",merge linesegment.distance1() and linesegment.distance2() into linesegment.distance()
1324,"<desc> have you signed the contributor license agreement? something i noticed when trying to see if i could contribute anywhere in the project was that it's kind of hard to get all of the dependencies running in visual studio (at least, if you're like me and try to avoid vs like the plague). this pr adds a .vsconfig file to the root of the repository, which causes visual studio 2019 to automatically prompt you when opening the repo to install any missing workloads (and automatically tells you which ones you need). i tried to keep it to the minimum required, but that's still quite a few things (.net desktop development, c++ development, uwp, the spectre mitigation  libraries, windows sdk 18362 and 19041, etc). you can't list extensions (so the visual studio installer projects extension still has to be installed manually), but this makes it a heck of a lot easier than going back to the installer every time the project won't build for something else. i tested this in a vm and a sandbox, both worked great (i.e. the project built). microsoft reviewers: open in codeflow </desc> <cmt> added vsconfig file. </cmt> <cmt> added a note to readme.md and fixed spelling false-positives. </cmt> <cmt> reverted expect.txt. </cmt>",added vsconfig file to automatically install required workloads.
1325,"<desc> update version to v1.5.0 except clojure package please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> update description </cmt> <cmt> update version to v1.5.0 except for clojure </cmt>",update version to v1.5.0 including clojure package
1326,<desc> in #7501 i made a number of changes to the intellij files. one of them -- moving the .iml file into the .idea directory -- had an unforeseen bad consequence of leading do duplicated .iml files; see flutter/flutter-intellij#689 for details. fixes flutter/flutter-intellij#714 </desc> <cmt> move .iml file back to project root directory </cmt> <cmt> update .iml location in all examples </cmt> <iss> roll back change to project metadata location. </iss>,revert back intellij .iml file to project root
1327,"<desc> added some features and fixed some bugs manimlib/__main__.py: supported debugger launch manimlib/config.py: added --config_file cli flag to load configuration file manually manimlib/mobject/geometry.py: added tip_style to tip_config, there are three styles (0 to 2 from up to down): manimlib/mobject/geometry.py: fixed the default color of tip manimlib/mobject/vector_field.py: fixed a typo (showpassingflash to vshowpassingflash) docs/: docs had been modified for these changes </desc> <cmt> fix a bug in extract_scene.py </cmt> <cmt> it's too old </cmt> <cmt> make ""shaders"" branch work </cmt> <cmt> update shaders branch </cmt> <cmt> add support for debugger launch </cmt> <cmt> update config.py to load config file manually. </cmt> <cmt> fix a wrong function name. </cmt> <cmt> add a custom style to arrowtip. </cmt> <cmt> fix the color of tip </cmt> <cmt> some improvement to tip </cmt> <cmt> rename tip_look to tip_style </cmt> <cmt> set the default of tip_style to 0 </cmt> <cmt> small improvement to config_file </cmt> <cmt> clean .gitignore </cmt> <cmt> update docs </cmt>",added some features including --config_file cli flag and tip_style
1328,"<desc> original pull-request #15667 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> trying to fix race in amqp-cpp </cmt> <cmt> fix cmake </cmt> <cmt> fix race in amqcpp </cmt>",cherry pick #15667 to 20.7: fix race in amqcpp
1329,"<desc> to help with environment predictability, this pr configures vagrant to use qmk_base_container. the process is as follows: vagrant up if using docker directly build a slightly modified qmk_base_container with ssh run container else build debian vm install docker pull qmk_base_container run container patch so that we jump directly to container instead of to vm vagrant ssh running inside qmk_base_container with the predicable toolchain to an new/existing vagrant user, the change is transparent, and should not change the workflow. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> initial conversion of vagrant to use qmkfm/base_container </cmt> <cmt> fix vagrant when using docker provider </cmt>",configure vagrant to use qmk_base_container
1330,"<desc> allow a clickable component's click handler to be passed as a constructor option as a simple alternative to creating a custom component. makes for easier answers to ""how do i create a button questions"". add clickhandler as an option for clickablecomponent all player controls override the handleclick method so are unaffected. change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) </desc> <cmt> add click handler as contructor option </cmt> <cmt> use button in button example, and add click handler to example </cmt>",allow click handler to be specified in clickable component's options
1331,"<desc> creating and killing an actor immediately will have a race condition. canceling lease reply it will leave the worker leak. this pr fixed it. and there is another race condition: task creating canceling task creating reply received this will leave the worker leaked too. closes #17369 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> revert ""revert ""[gcs] fix actor killing race condition (#17456)"" (#17599)"" </cmt> <cmt> this reverts commit 381ffdb6d02d51aa1c3a07e183069d711b69a348. </cmt> <cmt> update </cmt> <cmt> format </cmt> <iss> [core] actor hangs after other actors are killed </iss>",fix actor killing hang due to race condition
1332,"<desc> fixes #9784. the paragraph tm rule was excluding heading-setext alt heading 2 rule, because of a conflict with the separator rule. also added tests to verify the behaviour. </desc> <cmt> moved tm markdown seperator rule below the paragraph </cmt> <cmt> rule to fix the alt heading 2 syntax highlighting. </cmt> <cmt> added the --- seperator to the paragraph rule </cmt> <cmt> to allow heading-setext.2 rule to be recognized </cmt> <iss> markdown syntax highlighting not support alternative header styles </iss>",markdown syntax highlighting to support alternative header styles
1333,"<desc> visualstudio and xcode project files has been broken since merged php request. i've totally misunderstood above file management s travis passes their tests. </desc> <cmt> add missing idl_gen_php.cpp to visualstudio project </cmt> <cmt> also, fix xcode project </cmt>","fix projectfile (visualstudio, xcode) for development"
1334,<desc> now s3 presign feature requires credentials to be set 'test' as aws access key id and aws secret access key id. we have added signature validation and expiration validation of the presign url. pr:  #3092 </desc> <cmt> added presign credentials prerequisites </cmt>,added presign prerequisite in doc
1335,"<desc> add __attribute__((used)) to the git_deprecated macro, otherwise this will be seen as an ""unused const variable"". also, use the enum type in the declaration of deprecated values.  the c standard does not specify whether an enum is a signed or unsigned type.  obviously, any enum that includes negative values must be signed, but if all values are positive then the compiler is free to choose signed or unsigned. thus, we declare the deprecated values as the enum instead of guessing. </desc> <cmt> deprecation: add used attribute </cmt> <cmt> recent gcc enables -wunused-const-variables, which makes output quite </cmt> <cmt> noisy.  disable unused warnings for our deprecated variables. </cmt> <cmt> deprecation: use the enum type in declaration </cmt> <cmt> the c standard does not specify whether an enum is a signed or unsigned </cmt> <cmt> type.  obviously, any enum that includes negative values _must_ be </cmt> <cmt> signed, but if all values are positive then the compiler is free to </cmt> <cmt> choose signed or unsigned. </cmt> <cmt> thus, by changing the type signatures to git_object_t and declaring </cmt> <cmt> the old git_obj_ values as a signed or unsigned int, we risk a </cmt> <cmt> mismatch between what the compiler has chosen for a git_object_t's </cmt> <cmt> type and our type declaration. </cmt> <cmt> thus, we declare the deprecated values as the enum instead of guessing. </cmt>",improve deprecation of old enums
1336,"<desc> a simple addition to npm. it allows the user to toggle npm install & npm uninstall in the command line buffer by hitting f2, f2. users who have contributed to this file: @larson-carter @mcornella @a-h-i @sorin-ionescu @oknowton @hacfi @alexxnica @fabianrios @dimensi0n @athahersirnaik @antouank @a-r-d </desc> <cmt> npm install/uninstall toggle </cmt> <cmt> fixes </cmt> <cmt> updated binkey </cmt> <cmt> style updates </cmt>",toggle npm install / npm uninstall by pressing f2 twice
1337,"<desc> this implements wildcard placement for tasks in a placement group, which will be the default behaviour. the task is allowed to be scheduled in any bundle of the group. this is implemented via a pair of custom resources. for example, suppose we placed bundle 3 of placement group zzz, and the bundle has two cpu resources. then, the resources cpu_group_zzz cpu_group_3_zzz will be created on that node. wildcard tasks will have resource request {""cpu_group_zzz"": n}, while tasks placed in a specific request will have resource request {""cpu_group_zzz"": n, ""cpu_group_3_zzz"": n}. closes #9796 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> fix tests </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> add test </cmt> <cmt> update </cmt> <cmt> update </cmt> <iss> [placement group] should be able to schedule a task on ""any bundle"" </iss>","allow scheduling a task on any bundle (-1, default)"
1338,"<desc> this pr adds the following properties to textspan: mousecursor onenter onexit textspan now implements hittesttarget. owners to textspan are now required to return the proper text span in its hittestchildren, and should no longer manually dispatch events in handleevent. reason: only a hittesttarget can be returned by hittest and be processed as a mouse cursor host. fixes #64769. a previous attempt, #68674, was abandoned in favor of this to avoid breakage. part of #31952. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> move mc mcsession, mcmixin to services </cmt> <cmt> fix compile (atp) </cmt> <cmt> rename and docs </cmt> <cmt> merge mousetracker </cmt> <cmt> improve doc </cmt> <cmt> move systemmousecursors </cmt> <cmt> add mouse properties to textspan </cmt> <iss> add mousecursor property to textspan </iss>","add mousecursor, onenter, and onexit to textspan"
1339,"<desc> revert the backtrace ban bring back the non-related fixed from that patch. change swift_reporterror to only print backtraces in assert builds of the runtime.  but warning() will still print backtraces. </desc> <cmt> revert ""[strip -st] disable runtime stack trace dumping on darwin when asserts are disabled."" </cmt> <cmt> this reverts commit 6bc28ff1c9c75333ceee5986bca775c96d09ebad. </cmt> <cmt> bring back important fixes from the revert of 6bc28ff1c9c75333ceee5986bca775c96d09ebad. </cmt> <cmt> change swift::swift_reporterror to only print the backtrace in assert builds (swift::warning prints backtrace always). </cmt>",revert backtrace ban and start printing backtraces from the runtime again
1340,"<desc> this pr removes the code which was setting the description as the title when the description started with the name. pr checklist applies to #4297, #3746 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx detailed description of the pull request / additional comments the following changes are made in this pr - the code where the description of the app was being set as the title has been removed. tests have been added to validate that the title is always set to the name of the application, irrespective of the description. functions have been added to the iprogram interface, so that they can be mocked and tested. reformatted the tests so that we have one file each for win32 and uwp tests. strings have been localized. validation steps performed added tests all existing tests pass manually validated it </desc> <cmt> added tests to verify that the name is always set as the title and never the description </cmt> <cmt> removed apptype as an argument </cmt> <cmt> refactored code </cmt> <cmt> added comments </cmt> <cmt> localized strings </cmt>",set the name(not the description) as the title of the result
1341,"<desc> what do these changes do? tasks are now written to the gcs as soon as they are submitted to the local raylet, whereas before they were written after being assigned to a worker. this means that tasks are now evicted from the lineage cache as soon as possible, which should reduce the number of tasks that are in the lineage cache and therefore the size of the uncommitted lineage that gets piggy-backed on forwarded tasks. previously, this was causing high task latency (#4359). also, the sustainable throughput should now be about the same as if we were using the gcs alone. this involves several changes: refactor the lineage cache so that each task can only be in either uncommitted or committing state. later, i would like to add a committed state to indicate that a task has been acknowledged by the gcs but can't be evicted yet. during task submission, forwarded tasks are added to the lineage cache as uncommitted and tasks submitted locally are committed immediately. actor execution dependencies are not updated based on execution order. this means that if an actor with multiple handles dies, we will not be able to exactly replay the tasks before the failure. in the future, we can re-enable this by writing tasks to the gcs a second time (upon execution). first pr towards #4359. i will open another pr later that handles the scenario where the raylet where the task was originally submitted fails before it can complete the gcs write. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> refactor lineage cache: </cmt> <cmt> - only use states uncommitted and committing </cmt> <cmt> - flush tasks to the gcs as soon as they are submitted </cmt> <cmt> update unit tests </cmt>",flush lineage cache on task submission instead of execution
1342,"<desc> also: added a currentresult method to navigator. it supplies a result value when a route is popped without an explicit result. added an elevation parameter to card. appbar will now use the enclosing icontheme, if there is one. gc'd the shadow.png asset. much remains to be done: replace networkimages with assetimages. every 3rd row in the home page's product grid should span both columns. the scrolling grids should use lazy layout. support landscape-orientation-specific layouts. right justify the dropdown widget's arrow. the shopping cart should display a simple list of orders. support the actions: empty shopping cart, sort items by name, price. add a drawer. the appbar shouldn't have a drop shadow until content has scrolled underneath. support the dark theme. </desc> <cmt> gallery shrine demo v0.0 </cmt> <cmt> update flutter.yaml </cmt>","version 0.0 of a gallery demo of the material design ""shrine"" app"
1343,"<desc> also implements apache_response_headers(). note that apache_request_headers() is the real name of getallheaders(), the latter is an alias. </desc> <cmt> implemented fr #65917 (getallheaders() is not supported by the built-in...) </cmt> <cmt> - implemented apache_request_headers() and getallheaders() alias in cli server </cmt> <cmt> - implemented apache_response_headers() in cli server using fastcgi code </cmt> <cmt> conflicts: </cmt> <cmt> news </cmt> <cmt> upgrading </cmt> <cmt> rewrote test using tcp instead of </cmt>",implemented fr #65917 (getallheaders() is not supported by the built-in web server)
1344,"<desc> pulling the changes from #14690 into swift-4.1-branch: introduced the customplaygrounddisplayconvertible protocol and unconditionally deprecated playgroundquicklook and customplaygroundquicklookable (and all conformances to those protocols) as part of implementation of se-0198. these are the swift-side changes for rdar://problem/32905293. </desc> <cmt> [stdlib] introduced the customplaygrounddisplayconvertible protocol. </cmt> <cmt> this protocol is intended as a replacement for customplaygroundquicklookable </cmt> <cmt> and playgroundquicklook. it allows a type to return a substitute instance for </cmt> <cmt> use during playground logging. </cmt> <cmt> [stdlib] deprecated playgroundquicklook and customplaygroundquicklookable. </cmt> <cmt> deprecated the playgroundquicklook enum and customplaygroundquicklookable </cmt> <cmt> protocol. these are being targeted for removal in swift 5, so we want to </cmt> <cmt> unconditionally deprecate them now to encourage use of </cmt> <cmt> customplaygrounddisplayconvertible instead. </cmt> <cmt> this commit includes deprecated the various customplaygroundquicklookable </cmt> <cmt> conformances across the standard library and overlay libraries. </cmt> <cmt> [stdlib] updated the doc comments for playgroundquicklook/customplaygroundquicklookable. </cmt> <cmt> since these are now deprecated (in preparation for removal in a future swift </cmt> <cmt> release), the doc comments reflect that and provide suggestions for what to do </cmt> <cmt> instead (i.e. use customplaygrounddisplayconvertible) and how to </cmt> <cmt> conditionalize usage of playgroundquicklook/customplaygroundquicklookable so </cmt> <cmt> that source code remains compilable both by old versions which only have the old </cmt> <cmt> protocol and newer versions which have removed the old protocol. </cmt>",introduced customplaygrounddisplayconvertible and deprecated playgroundquicklook/customplaygroundquicklookable
1345,<desc> cherry-pick number_helpers fix from 3-0-stable make sure that we don't perform in-place mutation on safebuffer string update missing changelog </desc> <cmt> ensure number helpers can handle html safe strings - closes #1597. </cmt> <cmt> update changelog to mention the json_escape change </cmt> <cmt> make sure that we don't perform in-place mutation on safebuffer string </cmt> <cmt> this will make sure render :inline is working. </cmt> <cmt> closes #1633 </cmt>,render inline fix for 3-0-9
1346,"<desc> now variable_scope always create a new name scope (side-effect?) when invoked. the behavior will result in name scope collision mentioned in #13429 . hence we proposed to add a parameter auxiliary_name_scope to control whether to create new name scope or not. if accepted, we can reenter variable_scope and its original name scope without side-effect: with tf.variable_scope(s, auxiliary_name_scope=false) as ss: with tf.name_scope(ss.original_name_scope) as n: # do something how to test add unit tests pass all tests. </desc> <cmt> tst: add test case </cmt> <cmt> enh: variable_scope supports auxiliary_name_scope </cmt> <cmt> doc: add document </cmt>",variable_scope use auxiliary_name_scope to control whether to create new name scope
1347,"<desc> i noticed some stray ""experimental"" and ""solaris"" files; given that experimental is no longer a build-time option, and solaris support was removed in #35285 and #35373, this is now dead code. there's two solaris files i left intact, because they're inside pkg/, but we can remove if we think it's not gonna be used; pkg/system/stat_solaris.go pkg/parsers/kernel/uname_solaris.go also removing redundant ""linux"", ""windows"" build-tags in files that were already suffixed with _linux.go or _windows.go </desc> <cmt> remove unused experimental code </cmt> <cmt> remove solaris files </cmt> <cmt> solaris is no longer being worked on, so these files </cmt> <cmt> are now just dead code. </cmt>",remove dead code and redundant build tags
1348,"<desc> these changes were required for me to run the sample_bazel.sh and train_bazel.sh scripts in the coconet project, using python 3, and i tried to improve the readme to make it clearer to someone new to the project. i haven't contributed to this project before, but i thought it would be helpful to submit a pr! happy to incorporate any comments/feedback. testing notes: follow the usage instructions in the readme in this pr. if you have a pip-installed version of magenta, set your $pythonpath to the location of the magenta directory from this branch, so that the local version of magenta (containing these changes) takes precedence when magenta is imported. the pre-trained model downloaded from here requires a fix in order to work. the download contains a checkpoint file named checkpoint, which needs to point to the checkpoint binaries in that directory. change the checkpoint file to contain only the line model_checkpoint_path: ""best_model.ckpt"". to do: this doesn't block this pr because it only uses the .npz file, but the pickled files in the repo containing the full jsb chorale datasets, can't be unpickled using python 3 without some trickery, because apparently python 3 doesn't like to unpickle files that python 2 pickled. would be helpful to submit a separate pr containing a python 3-compatible version of those files. </desc> <cmt> fixes to get train_bazel.sh to run </cmt> <cmt> code cleanup, readme improvements </cmt>",fixes + documentation to run coconet code with python 3
1349,"<desc> counterpart to #10389 add soft_endstops_menu_item configuration option. lcd menu option to enable/disable software endstop before moving each axis. sometimes with my delta, corexy(zoffset) printer, i found that irritating(?) enabling software endstop (m211) by command or serial each time i calibrate printer, so i made this menu programmatically. this could, and should be able to apply other printers like corexy, and so on. usage show this menu by enabling soft_endstops_menu_item in configuration.h. </desc> <cmt> add soft_endstops_menu_item to example configs </cmt> <cmt> optional menu item to toggle soft endstops </cmt>",add optional menu item to toggle software endstops
1350,<desc> extend the mem::uninitialized documentation to account for partially initialized arrays and how to correctly handle these. these are used in some datastructures (trees for example) or in ffi. r? @manishearth </desc> <cmt> extend documentation for mem uninit to discuss partial allocation of the values </cmt> <cmt> updates based on comment </cmt>,mem uninit doc ptr drop
1351,"<desc> see also #15953 this allows the  multioutputregressor.fit  to accept a **fit_params to custom estimator fit process. class gradientboostingregressorwithfitparam(gradientboostingregressor): def fit(self, x, y, sample_weight=none, monitor=none, **fit_params): self.fit_params = fit_params super().fit(x, y, sample_weight=sample_weight) x, y = datasets.make_regression(n_targets=3) x_train, y_train = x[:50], y[:50] x_test, y_test = x[50:], y[50:] rgr = multioutputregressor(gradientboostingregressorwithfitparam()) rgr.fit(x_train, y_train, customed_param=true) y_pred = rgr.predict(x_test) to custom some of the estimators' fit processes, we have to redifine the estimators.fit functions with customed paramters besides sample_weight. beacause the fit methods of most defined estimators in the sklearn package just have a sample_weight parameter. </desc> <cmt> add a optional fit_param for multioutput estimator fit call </cmt> <cmt> fix pep8 violations </cmt>",add a optional fit_param to enable custom multioutput fit process
1352,"<desc> this pr reimplements a number of the tests from  there is also one docker image fix here, which is that two of the provided config files had different file permissions to the rest. i've fixed this with another run chmod while building the image, and adjusted the corresponding packaging test. </desc> <cmt> add docker core dump and gid tests </cmt> <cmt> add tests for enabled plugins </cmt> <cmt> add more keystore tests </cmt> <cmt> add tests for docker image labels </cmt> <cmt> add tests for logging and process characteristics </cmt> <cmt> add test to check for presence of /_xpack api </cmt> <cmt> test that os stats include cgroup data </cmt> <cmt> check java version in our docker images </cmt> <cmt> also update a stale comment in the docker entrypoint script. </cmt> <cmt> fix config perms in docker </cmt> <cmt> two config files in the docker image had different permissions from the </cmt> <cmt> rest. fix this, and also fix the java version test. </cmt>",migrate some of the docker tests from old repository
1353,"<desc> the uia provider classes are now shared properly. they're hooked up to conhost and windows terminal. you should actually have a uia tree when you try to use them. the actual text buffer uia element is not hooked up for windows terminal, however. that'll be a later pr. extension of #1691 please read the description in that pr for background information. changes to the windowuiaprovider as mentioned earlier, the windowuiaprovider is the top-level uia provider for our projects. to reuse as much code as possible, i created microsoft::console::types::windowuiaproviderbase. any existing functions that reference a screeninfouiaprovider were virtual-ized. in each project, a windowuiaprovider : windowuiaproviderbase was created to define those virtual functions. note that that will be the main difference between conhost and windows terminal moving forward: how many textbuffers are on the screen. so, conhost should be the same as before, with only one screeninfouiaprovider, whereas windows terminal needs to (1) update which one is on the screen and (2) may have multiple on the screen. windows terminal doesn't have the screeninfouiaprovider hooked up yet. we'll have all the xaml elements in the uia tree. but, since termcontrol is a custom xaml control, i need to hook up the screeninfouiaprovider to it. this work will be done in a new pr and resolve github issue #1352. moved to microsoft::console::types these files got moved to a shared area so that they can be used by both conhost and windows terminal. this means that any references to the servicelocator had to be removed. iconsolewindow windows terminal: islandwindow : iconsolewindow screeninfouiaprovider all references to servicelocator and screen_information were removed. irenderdata was used to accomplish this. refer to next section for more details. uiatextrange all references to servicelocator and screen_information were removed. irenderdata was used to accomplish this. refer to next section for more details. since most of the functions were static, that means that an irenderdata had to be added into most of them. changes to irenderdata since irenderdata is now being used to abstract out servicelocator and screen_information, i had to add a few functions here: bool isareaselected() void clearselection() void selectnewregion(...) hresult searchfortext(...) searchfortext() is a problem here. the overall new design is great! but windows terminal doesn't have a way to search for text in the buffer yet, whereas conhost does. so i'm punting on this issue for now. it looks nasty, but just look at all the other pretty things here. :) miscellaneous known issues issue #1914 - tracing needs to be reattached issue #1352 - windows terminal: the screeninfouiaprovider needs to be attached to the termcontrol. things i'll fix in this pr (just need to add commits on top of it): conhost: the uia rects for the caption buttons are missing. still investigating this issue. i would be very surprised if the tests for conhost pass. deployed conhost from master and conhost from this branch. did some quick validation using inspect.exe. used inspect.exe to see uia tree in windows terminal. </desc> <cmt> moved iscreeninfouiaprovider into shared space. </cmt> <cmt> both projects must now implement the virtual functions. </cmt> <cmt> conhost should be mostly set up. </cmt> <cmt> wt needs a way to implement these (need access to terminal info) </cmt> <cmt> next: fix iscreeninfouiaprovider's references to selection and uiatextrange </cmt> <cmt> fixed conhost (mostly) </cmt> <cmt> todos: </cmt> <cmt> - bugfix: get rects for min/max/close buttons </cmt> <cmt> - clean public/protected/private functions from uia providers (some are in wrong place) </cmt> <cmt> - re-attach tracing </cmt> <cmt> - hook up windows terminal </cmt> <cmt> renamed renderdata's findtext to searchfortext </cmt> <cmt> got windowsterminal uia tree up and running again </cmt> <cmt> todo conhost: </cmt> <cmt> - bugfix: get rects for caption buttons </cmt> <cmt> - re-attach tracing </cmt> <cmt> todo wt: </cmt> <cmt> - attach screeninfouiaprovider to termcontrol </cmt>",finalized shared uia tree model
1354,"<desc> as i have been using libgdx for over 2 years by now, [i] decided to make some contributions to common code base. please find first minor changes to horizontalgroup and verticalgroup (to partially support zero-width widgets), and an addition to actor class as this is something i repeatedly ran into and had to implement locally while developing gdx-based games. </desc> <cmt> support for zero-width widgets. described edge use cases in javadoc. </cmt> <cmt> simple helper method to check if actor handles input events. </cmt>",minor changes in ui widgets
1355,"<desc> in #2496 i didn't make sure the calling cache dir path ends with slash, which will cause the cache report false for subdir in it. beside, there's substitutepath code in the cdirectory::exists, it should be called before check the cache. this pr fixed these 2 problems. </desc> <cmt> check dir cache after substitutepath. </cmt> <cmt> make sure dir ends with slash when check cache. </cmt>",fix problems introduced by pr2496 (check dir exists use dircache)
1356,"<desc> the pr is mainly for bug fixing and also including some enhancement as below: the kernel/program binary cache mechanism is working with latest viennacl now. for details, please refer clcaffe's wiki page. with this feature enabled, the initialization time of opencl caffe application will reduce dramatically. relax the image restrication for spatial convolution kernels, thus we need much less convolution kernels if the application need to process different image sizes for the same net model. fixed one race condition bug and now all test cases could always pass. the random fail sympton get fixed. add dilation support for the spatial convolution kernel. </desc> <cmt> remove unecessary finish in synced memory. </cmt> <cmt> for the to_gpu function with uninitialized memory case, we </cmt> <cmt> do not need to finish queue, and if the head is at cpu and </cmt> <cmt> we support zero copy, then we also don't need to finish </cmt> <cmt> the queue. </cmt> <cmt> refine timing mechanism for auto-tuning phase. </cmt> <cmt> the caffe's timer has some overhead, and when our tunning kernel is </cmt> <cmt> very tiny, the overhead may cause very unstable timing result, so </cmt> <cmt> i increase the iteration count to reduce this type of overhead. </cmt> <cmt> refine softmax layer's forward code path. </cmt> <cmt> if the spatial dimension is relatively large, we should use the default code </cmt> <cmt> path to achieve better parallelism. </cmt> <cmt> refine error handling for spatial convolution. </cmt> <cmt> sometimes, the sub buffer creation may fail, we need to take care of it. </cmt> <cmt> fix incorrectly add __beignet__ macro into option. </cmt> <cmt> some features e.g. opencl_unroll_hint are not allowed for beignet </cmt> <cmt> compiler, use __beignet__ macro to choose whether to build with these </cmt> <cmt> features. </cmt> <cmt> also add an helper func to faciliate judging beignet driver. </cmt> <cmt> fix a bug in spatial convolution engine. </cmt> <cmt> if the input image size changed during runtime, and the kernel type </cmt> <cmt> change to 2 or 5, we need to swizzle the weights again. </cmt> <cmt> spatial conv: remove image padding </cmt> <cmt> added a new basic convolution kernel that supports input image with </cmt> <cmt> no padding, so that no image padding in host code need anymore. </cmt> <cmt> remove unecessary clfinish in spatial convolution engine. </cmt> <cmt> enable conv_spatial dilation parameters </cmt> <cmt> change-id: i392c4e73319fcfc18e628f9476b9bfdcba3cc206 </cmt> <cmt> fix one kernel compilation test failure. </cmt> <cmt> enable ocl version of hdf5_data_layer to fix a race condition </cmt> <cmt> if we simply use the cpu code path to copy the data, we will introduce </cmt> <cmt> one race condition between the gpu queue and the cpu. the scenario is: </cmt> <cmt> when we call it in an iteration loop. the data blob is in a zero-copy </cmt> <cmt> blob, and the first pass may be still blocking on the gpu side. the </cmt> <cmt> second pass will modify the data blob on cpu side before the data is </cmt> <cmt> accessed at the first pass on gpu side. </cmt> <cmt> we can simply add a synchronization point between the two iterations, but that </cmt> <cmt> is not a good fix as we force the gpu queue to flush and wait it to finish. </cmt> <cmt> the best way is to do the copy on the gpu side and in the same queue. thus we </cmt> <cmt> don't need to worry about this race condition any more and without any interfere </cmt> <cmt> the gpu queue. </cmt> <cmt> fix a constant value bug </cmt> <cmt> this will cause relu gradient fail. </cmt> <cmt> don't use fixed image size for gemm like kernels. </cmt> <cmt> prepare to support varying sizes. </cmt> <cmt> use tuning size rather than actual size. </cmt> <cmt> no need to tune different kernel for each different input size. </cmt> <cmt> refine spatial kernel's cache mechanism. </cmt> <cmt> add the platform and driver information to change to use </cmt> <cmt> system cache directory if possible. after this change, we </cmt> <cmt> can reuse a offline tuned configurations. </cmt> <cmt> redirect the intel opencl backend information to wiki page. </cmt> <cmt> eliminate some ocl kernel warnings. </cmt> <cmt> cmake_ext should be empty for now. </cmt> <cmt> lint fix. </cmt>",opencl some bug fixes and feature enhancement
1357,"<desc> se proposal make numeric refine a new additivearithmetic protocol is currently being considered for a formal review by the core team. this patch adopts the new protocol and switches to unified operator lookup for the automatic differentiation transform. concretely, this patch includes the following: apply #19989: introduce additivenumeric and refactor numeric. make vectornumeric refine additivenumeric, sharing additive arithmetic operators. remove *(self, self) to make vectornumeric correctly define an abstract vector space (also discussed on the se thread), keeping only *(scalar, self) and *=(inout self, scalar). further constrain differentiable's tangentvector and cotangentvector to be also differentiable. this limits customization points that won't make sense mathematically. since we are no longer dealing with + defined separately in vectornumeric and numeric, the ad core transform has been refactored to use the unified + operator under additivearithmetic. note: some abi stability tests and operator resolution tests have been temporarily disabled to prevent duplicate work: #19989 is going to handle all of this anyway and the tf branch will be patched when #19989 lands in master. todo next: remove init(_:) from vectornumeric. this is a degenerate case because seeding a vjp using a vector of 1s to get a ""gradient"" is simply incorrect. ad type checking, the core transform, and primitive definitions in the tf module need to be refactored to make this change possible. </desc> <cmt> adopt additivearithmetic protocol </cmt> <cmt> temporarily disable stability tests as these will be addressed upstream </cmt>",adopt additivearithmetic protocol for ad
1358,"<desc> use sklearn's solution for the objective function with zero heassian: only use first-order gradients to construct, then fix the tree's output according to objective function. some benchmarks on l1 objective function: dataset:  result: </desc> <cmt> refine objective functions with zero hessian. </cmt> <cmt> fix parallel logic for renewtreeoutput </cmt>",fix objective functions with zero hessian
1359,<desc> description: based on the comment in the code the unlock directive may not have been (fully) supported when the original unlock handler was written. that is no longer the case and it is now supported with user opt-in and a voice pin. updated the alexa.lockcontroller unlock directive to include the lockstate property in the context of the response as expected by the alexa api.  also added tests for unlock directive. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> update the alexa.lockcontroller unlock directive to include the lockstate property in the context of the response. </cmt> <cmt> added test for alexa.lockcontroller unlock directive to include the lockstate property in the context of the response. </cmt>,update unlock directive for alexa lockcontroller
1360,<desc> fixes the failing chk_pylint job in ci. pylint 2.10 emitts the unspecified-encoding warning if open() does not specify encoding and we had quite a few of these. </desc> <cmt> fix_homebrew_paths_in_standalone_zip.py: remove a superfluous call to open() </cmt> <cmt> fix pylint warnings about encoding not being specified in open() calls </cmt>,fix pylint warnings about encoding in open()
1361,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> added type definitions for react-medium-image-zoom </cmt> <cmt> fixes for react-medium-image-zoom </cmt> <cmt> fixes for react-medium-image-zoom </cmt>",adding type definitions for react-medium-image-zoom
1362,"<desc> issue: #13888 this gracefully replaces control.options with top-level options on argtypes. top-level options are validated by the story store rather than the controls addon. contrary to control.options, options only accepts an array of primitives. labels can be customized using control.labels. argtypes: { foo: { options: [true, false, 42], control: { type: 'select', labels: { true: 'yes', false: 'no' } } } } is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? yes </desc> <cmt> deprecation warning for 'control.options' </cmt> <cmt> validate options on argtypes </cmt> <cmt> render control based on 'control.labels' and fall back to 'control.options' or 'options' (in that order) </cmt>","hoist 'control.options', validate them in core and introduce 'control.labels'"
1363,<desc> i'm adding an option to only add env variables to the main supersetnode pod through the helm chart. see #16625. i added some test values in values.yaml and confirmed that they were being read properly locally. has associated issue: #16625 includes db migration (follow approval process in sip-59) </desc> <cmt> add env variables for supersetnode in helm template </cmt> <cmt> typo in template </cmt>,provide option to add environment variables to only supersetnode
1364,"<desc> this is the edit modal for databases created using the new dynamic form. currently, the steps required would be to create a new database using the dynamic form, and then try to edit it. to create a new database, go to +database and add in: host: localhost port: 5432 username: postgres skip password displayname: test create, then edit the database. includes db migration (follow approval process in sip-59) </desc> <cmt> split db modal file </cmt> <cmt> split db modal file </cmt> <cmt> hook up available databases </cmt> <cmt> add comment </cmt> <cmt> split db modal file </cmt> <cmt> hook up available databases </cmt> <cmt> use new validation component </cmt> <cmt> first draft </cmt> <cmt> use new validation component </cmt> <cmt> first draft </cmt>",dynamic form for edit db modal
1365,"<desc> update arc back-end in lite micro to use the latest pre-release (mli 1.1 rc3) of embarc_mli fix issues caused by upstream changes (some code refactoring was not applied to the arc files) small fixes for arc emsdp target </desc> <cmt> fix of problem with copying of just downloaded tcf </cmt> <cmt> - default heap size was increased to cover all tests </cmt> <cmt> - minor fix in examples readmes </cmt> <cmt> arc emsdp: return uboot.env (was strangely deleted during merge) </cmt> <cmt> fix height slicing in fit branch for odd input </cmt> <cmt> replace mli switchers with specializations in person_detection_generation </cmt> <cmt> arc emsdp </cmt> <cmt> - microspeech int8 integration </cmt> <cmt> - patch sources to use specialization during project generation </cmt> <cmt> arc emsdp: update common lcf to be not limit codesize. update mli link to more recent one </cmt> <cmt> arc mli: scales to be present in 32 bits now </cmt> <cmt> update arc_mli_iss_fix branch with the latest state from upstream master </cmt> <cmt> use embarc mli rc3 for arc targets </cmt> <cmt> update branch with the latest state from upstream master </cmt> <cmt> update according to tflm changes </cmt> <cmt> updates for xy functions to align with tflm changes </cmt> <cmt> added uint32 to int cast, mli_is_applicable check </cmt> <cmt> updated copyrights </cmt> <cmt> avoiding using mli_is_aplicable global var </cmt>",update arc back-end to use latest embarc_mli release.
1366,"<desc> this will allow easier documentation of code, as requested in #151. the build script is kind of scary because uncommitted work in the code branch will be lost in the process of deployment. not sure how to get around that -- right now we prompt people to understand what they're doing. </desc> <cmt> moving gh-pages docs to docs/ folder, with script to build them </cmt> <cmt> improved docs-building script </cmt>","moving gh-pages stuff to docs/ directory, with script to build and deploy to gh-pages."
1367,"<desc> i added boolean userealsizeknobs to scrollpane, to set if the scrollpane should scale knobs or use real image sizes </desc> <cmt> update </cmt> <cmt> added userealsizeknobs to scrollpane, which indicates if knobs are </cmt> <cmt> scaled or real sized by physical width and height of the image </cmt>",scrollpane using real sized knobs
1368,<desc> i need this for testing bwc of a plugin otherwise i will have to copy much code. i first thought we might extract a base class but don't think this is a good idea because at least in my case i want to derive from a different base class already. </desc> <cmt> [test] move methods from bwc test to test package for use in other plugins </cmt> <cmt> move more methods and rename </cmt>,move methods from bwc test to test package for use in plugins
1369,"<desc> these tests create several edge cases that are otherwise uncovered (at least not consistently) by the test suite, so although they're no longer testing what they were meant to test, it's still a good idea to keep them in hope that they'll expose some issue in the future. </desc> <cmt> revive meaningful offset tests </cmt> <cmt> adjust revived meaningful offset tests </cmt> <cmt> these tests create several edge cases that are otherwise uncovered (at </cmt> <cmt> least not consistently) by the test suite, so although they're no longer </cmt> <cmt> testing what they were meant to test, it's still a good idea to keep </cmt> <cmt> them in hope that they'll expose some issue in the future. </cmt>",revive and adjust meaningful offset tests
1370,<desc> add a sql file when the first time  to use seata . it is init to sql database  and add database driver class name  of config </desc> <cmt> add undo_log sql file </cmt> <cmt> add drop table sql </cmt>,add undo_log.sql   and add database driver class config
1371,<desc> pr checklist tests for the changes have been added. purpose of this pr what kind of change does this pull request introduce? feat:     a new feature remove proptypes from production build by adding babel-plugin-transform-react-remove-prop-types. this change removes proptypes and their imports from the production build. this change does not remove proptypes from dependencies from external packages (in node_modules) is there anything you would like reviewers to focus on? does this pr introduce a breaking change? yes closes #14814. reviewers gatsby team? additional reviewers please review: @sidharthachatterjee @neo @wardpeet </desc> <cmt> feat(babel-preset-gatsby): add babel-plugin-transform-react-remove-prop-types to babel-preset-gatsby </cmt> <cmt> remove proptypes from production build </cmt> <cmt> re #14814 </cmt> <cmt> docs(babel-preset-gatsby): add babel-plugin-transform-react-remove-prop-types link to readme in #pac </cmt> <cmt> re #14814 </cmt> <iss> add babel-plugin-transform-react-remove-prop-types </iss>,add babel-plugin-transform-react-remove-prop-types for production builds
1372,"<desc> added steem api to blockchain section my submission is formatted according to the guidelines in the contributing guide all changes have been squashed into a single commit as per issue #2189 added steem api to a new category named blockchain, kindly check for the same. </desc> <cmt> added steem api to blockchain section </cmt> <cmt> added steem </cmt>",added steem to blockchain apis
1373,"<desc> check_consts::resolver contained a layer of abstraction (qualifresolver) to allow the existing, eager style of qualif propagation to work with either a dataflow results cursor or by applying the transfer function directly (if dataflow was not needed e.g. for promotion). however, #63812 uses a different, lazy paradigm for checking promotability, which makes this unnecessary. this pr cleans up check_consts::validation to use flowsensitiveresolver directly, instead of through the now obselete qualifresolver api. also, this contains a few commits (the first four) that address some fixmes in #63812 regarding code duplication. they could be split out, but i think they will be relatively noncontroversial? notably, validation::mode is renamed to constkind and used in promote_consts to denote what kind of item we are in. this is best reviewed commit-by-commit and is low priority. r? @eddyb </desc> <cmt> make check_consts::item work on non-const fns </cmt> <cmt> this was originally only needed for validation, which is never run on </cmt> <cmt> non-const fns. the new promotion pass wants to use it, however. </cmt> <cmt> make item fields pub </cmt> <cmt> deduplicate promote_consts::validator and check_consts::item </cmt> <cmt> use is_lang_panic_fn from check_consts in promote_consts </cmt>",clean up check_consts now that new promotion pass is implemented
1374,"<desc> adds a hook for returning initial metadata to clients when they connect allows badstatus to propagate trailing metadata, so that error metadata gets sent as trailers by raising badstatus with keyword args, exposes output_metadata, a hash available to during call processing on servers whose contents get sent back as trailers also does some refactoring to shorten methods and improve readability fixes #297 </desc> <cmt> refactor: move the pool out from rpcserver </cmt> <cmt> refactor: shorter methods in rpcserver </cmt> <cmt> adds a hook for returning the client connect metadata </cmt> <cmt> allow badstatus to contain metadata </cmt> <cmt> propagate metadata in badstatus </cmt> <cmt> - allow badstatus to contain metadata that's populated by keyword args </cmt> <cmt> - on servers, convert raised badstatus metadata to trailers </cmt> <cmt> - on clients, convert trailers to badstatus metadata when raising badstatus </cmt> <cmt> adds support for updating the output metadata to calls </cmt> <iss> add an api for servers to send metadata to clients </iss>",grpc ruby add support for returning metadata to the rpc server
1375,"<desc> fixes #89334 the changes introduced in #87280 allowed for ""duplicate"" caller bounds candidates to be assembled that only differed in their default substs having been ""exposed"" or not and resulted in an ambiguity error during trait selection. to fix this we expose the defaults substs during the creation of the paramenv. r? @lcnr </desc> <cmt> expose default substs in param_env </cmt> <cmt> add tests </cmt> <iss> possible degradation in const generics </iss>",prevent duplicate caller bounds candidates by exposing default substs in unevaluated
1376,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> updated xrmstatic properties page, utility, and panel  to match the pattern that mobil was doing, and be defined as interfaces.  this also makes allows for variables to easily be tyepd i.e. var p: xrm.page. </cmt> <cmt> also retyped getinitalvalue for booleans and optionsetvalues to be their correct respective types. </cmt> <cmt> fixed linitng issues and fixed header so it could be parsed by the dt bot </cmt> <cmt> fixed other lint-ing issues.  not sure what to do about the header being unparsable.  added commas, maybe that will help? </cmt>",defined interfaces for properties and fixed linting issues
1377,"<desc> this pr is part of the process separation project. this change is move-only and can be easily reviewed with --color-moved=dimmed_zebra. the moves are needed to avoid duplicating common init code between different binaries (bitcoin-node, bitcoin-wallet, etc) in #10102. in #10102, each binary has it's own init file (src/init/bitcoin-node.cpp, src/init/bitcoin-wallet.cpp) so this pr moves the common code to src/init/common.cpp. </desc> <cmt> move common global init code to init/common </cmt> <cmt> move common sanity check code to init/common </cmt> <cmt> move common logging addarg code to init/common </cmt> <cmt> move common logging getargs code to init/common </cmt> <cmt> move common logging start code to init/common </cmt> <cmt> move common package version code to init/common </cmt>",move common init code to init/common
1378,"<desc> this pr is another attempt to fix the failing test loadtlsservercredentials that was introduced in pr #21766 and rolled back in pr #21778. another attempted fix was pr #21804. the only difference between this pr and pr #21804 is adding grpc_init and grpc_shutdown to the main function. why should this fix the problem? the secureservercredentials c++ api does not call these methods, while the securechannelcredentials api does. i'm not sure why there is this discrepancy, but searching for this pattern across the codebase yields examples of having to artificially add in these calls in tests when loading server credentials (e.g. see end2end_test.cc). why was this problem not caught in the presubmit kokoro tests for the previous pr's? the failing kokoro test is the bazel c++ ios test, which is not part of the presubmit kokoro tests. once this pr is submitted, i will monitor the appropriate dashboard to ensure nothing went awry. </desc> <cmt> experiment test </cmt> <cmt> fix config file </cmt> <cmt> remove grpc_init. </cmt> <cmt> adding back in grpc_init. </cmt> <cmt> remove testenvironment. </cmt> <cmt> update from master. </cmt>","updates to tls credentials, version 3"
1379,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). its a non npm package and do not conflict with the name of an npm package. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add types for microsoft graph models </cmt> <cmt> set noimplicitany to true </cmt> <cmt> adding tests for types </cmt> <cmt> added more test for types </cmt> <cmt> removed unnecessary import </cmt> <cmt> remove unnecessary headers from types file </cmt> <cmt> fixing linting error in test file </cmt>",creating types for microsoft graph models
1380,"<desc> so far, the wildcard expansion worked fine for fields that were correctly spelled or fields that do exist in the mapping. in case they didn't exist or they were misspelled, a npe was thrown. this fixes #35092 </desc> <cmt> handle wildcard expansion in case of incorrect column names </cmt> <iss> sql: selecting `*` fields from a sub-query throws an npe </iss>",handle wildcard expansion on incorrect fields
1381,"<desc> this pr adds annotations for three new constants: true_ false_ ufunc_pyvals_name secondly, it fixes the type of little_endian, which should be a boolean instead of an integer. </desc> <cmt> enh: added annotations for 3 new constants </cmt> <cmt> false_, true_ and ufunc_pyvals_name </cmt> <cmt> maint: fix the type of little_endian </cmt> <cmt> it should be a boolean, not an integeer </cmt> <cmt> tst: updated the typing tests </cmt>",add annotations for three new constants
1382,"<desc> bpo-32962: python-gdb catchs valueerror on read_var() (gh-7692) bpo-32962: python-gdb catchs unicodedecodeerror (gh-7693) bpo-32962: fix test_gdb failure in debug build with -mcet -fcf-protection -o0 (gh-6754) </desc> <cmt> bpo-32962: python-gdb catchs valueerror on read_var() (gh-7692) </cmt> <cmt> python-gdb now catchs valueerror on read_var(): when python has no </cmt> <cmt> debug symbols for example. </cmt> <cmt> (cherry picked from commit 019d33b7a447e78057842332fb5d3bad01922122) </cmt> <cmt> bpo-32962: python-gdb catchs unicodedecodeerror (gh-7693) </cmt> <cmt> python-gdb now catchs unicodedecodeerror exceptions when calling </cmt> <cmt> string(). </cmt> <cmt> (cherry picked from commit d22fc0bc7de7882da204abe50884bbde2da4f9e7) </cmt> <cmt> bpo-32962: fix test_gdb failure in debug build with -mcet -fcf-protection -o0 (#6754) </cmt> <cmt> when python is built with the intel control-flow protection flags, </cmt> <cmt> -mcet -fcf-protection, gdb is not able to read the stack without </cmt> <cmt> actually jumping inside the function. this means an extra </cmt> <cmt> 'next' command is required to make the $pc (program counter) </cmt> <cmt> enter the function and make the stack of the function exposed to gdb. </cmt> <cmt> (cherry picked from commit 9b7c74ca32d1bec7128d550a9ab1b2ddc7046287) </cmt>",backport python-gdb.py and test_gdb.py from master
1383,<desc> -- replaced build_and_run_tests.bat with an nmake makefile with tons of useful targets -- added make.bat helper -- the nmake file is far from perfect (no incremental build support) but it allows easy building and testing of targets of windows. </desc> <cmt> add more tests into build_and_run_tests.bat </cmt> <cmt> added nmake file to ease building and running tests. </cmt> <cmt> fixed grpctests.mak and removed build_and_run_tests.bat </cmt> <cmt> added make.bat helper </cmt> <cmt> improving makefile for windows </cmt> <cmt> added some more non-test targets to grpc.mak </cmt> <cmt> polishing of grpc.mak </cmt> <cmt> added libraries to link against </cmt>,adding an nmake makefile for windows
1384,<desc> the actual sx60 work was done by @amnobis who made the sx60. i just cleaned it up and added support for the configurator (at least i'm pretty sure). </desc> <cmt> add sx60 </cmt> <cmt> add config maps and layouts as well as readmes. </cmt> <cmt> cleanup and fixes </cmt> <cmt> correct readme </cmt>,adding sx60 work by amnobis and configurator settings
1385,<desc> fixes fetch (#8768) and node behavior when disableautofetch and disablestream disables fetch when readablestream is not available. </desc> <cmt> adds fetch stream logic for networking part of pdf.js </cmt> <cmt> fixes fetch and node behavior when disableautofetch adn disablestream is used. </cmt> <cmt> disables fetch when readablestream is not available. </cmt>,fixes autofetch and firefox nightly fetch streams
1386,"<desc> xref #18838; follow up on #18842. this pr improves the current any-based placeholder annotations within a number of modules, replacing them with explicit functions, classes or objects when appropiate. while parameters of the respective methods and functions remain unannotated (for now), these changes nevertheless provides a notable improvement over a plain any. part 2 out of 3 in a series of prs; updates the placeholder annotations of np.linalg and np.lib. </desc> <cmt> enh: add improved placeholder annotations for np.linalg </cmt> <cmt> enh: add improved placeholder annotations for np.lib </cmt>",improve the placeholder annotations within sub-modules (part 2)
1387,<desc> adds documentation for lightgbm-ray (as well as all of the necessary changes to requirements and code). updates xgboost-ray docs to match the current release and adds scikit-learn api docs. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> update xgboost-ray docs </cmt> <cmt> update requirements </cmt> <cmt> add lightgbm docs </cmt>,"add lightgbm-ray docs, update xgboost-ray docs"
1388,"<desc> based on: info from @sciresm that devicesavedata is the same as normal save data in terms of path. info from @ognik5377 that devicesavedata must have user id 0 and can be likened to a global, user-less save. also adds the temporarystorage savedataspaceid, which is required to avoid an assert. keeps the same path though. </desc> <cmt> savedata_factory: add support for devicesavedata </cmt> <cmt> uses the same path as savedata except with uid 0. adds a warning if uid is not 0. </cmt> <cmt> savedata_factory: add temporarystorage savedataspaceid </cmt> <cmt> required for temporarystorage saves (in addition to savedatatype) </cmt>",add devicesavedata and fix temporarystorage
1389,"<desc> this does a few things (apologies for the big pr!) improves error messages for st.cache by including the cache stack and the hashing reason. in the process, i moved the place where we product the message strings inside the exception classes, since they're not used anywhere else. makes hashing errors tell the user whether the hashing error occurred when hashing the arguments, the body, or the output. see the hashreason enum. makes userhasherror show up to the user not as userhasherror but as fooerror, for whatever fooerror was actually thrown under the hood. this way the error is easier to google. makes st.cache warnings use exceptions in order to produce a nice stack trace, and then makes them use st.exception() protos so their output looks more similar to the exception output. but since we want warnings to show up in yellow, this also adds an is_warning field to exception protos that lets us tweak colors on the frontend. and some smaller things: makes st.exception() always read tracebacks from their input exception, rather than allow people to pass their own exceptions (since that last code path was not used anywhere in the code). does some light refactoring: makes codehasher a tiny bit less complex by making it not hold a hasher object internally, moves hashing-related exception classes from one file to another, renames a couple of variables, removes some python 2 code, etc. make _hashstacks use weak references to threads rather than thread ids, so avoid a memory leak when threads end. improves the css for code blocks and inline code inside exceptions. </desc> <cmt> cleanups </cmt> <cmt> debug </cmt> <cmt> improve ""mutated object"" warning. </cmt> <cmt> improve css for code block inside alert markdown </cmt> <cmt> docstrings and lint in errors.py </cmt> <cmt> make warnings use exceptions so stack trace looks the same. </cmt> <cmt> improve css of errors/warnings/etc </cmt> <cmt> implement better unhashabletype error message. </cmt> <cmt> got most error messages done! just need to clean up. </cmt> <cmt> finish all error messages. </cmt> <cmt> finish all error messages. </cmt> <cmt> fix existing tests. </cmt> <cmt> no-op </cmt>",better error messages for st.cache
1390,"<desc> (this patch belongs to an epic in which we are deleting the classic autoloader). users cannot enable the classic autoloader since config.autoloader= was deleted in 0d523d8. however, the classic autoloader was still being setup by rails and allowed autoloading from initializers to ease the transition in rails 6.x. autoloading reloadable constants from initializers has been deprecated since 6.0, and finally the support is dropped together with classic. from now on, trying to autoload a reloadable class or module in initializers raises a nameerror. as explained in the documentation included in this patch, you can autoload in initializers constants managed by the once autoloader. that covers the valid uses cases. this leaves orphan code in activesupport::dependencies that later patches will delete. also, later patches will edit changelogs with these and other changes in the epic. </desc> <cmt> delete as::dependencies.hook! </cmt> <cmt> delete as::dependencies.unhook! </cmt> <cmt> deletes the initializer warn_if_autoloaded </cmt> <cmt> deletes the initializer ensure_autoload_once_paths_as_subset </cmt> <cmt> there is no need for this nowadays. you could have a directory somehwere </cmt> <cmt> that is not in autoload_paths, but you want the once loader to manage. </cmt> <cmt> at the same time, when we setup the main loader, we remove any directory </cmt> <cmt> in the autoload_once_paths, since zeitwerk does not allow loaders to </cmt> <cmt> have overlapping root directories. </cmt> <cmt> setup the once autoloader on bootstrap </cmt> <cmt> documents config.autoload_once_paths </cmt>",do not hook the classic autoloader anymore
1391,<desc> pr for review per #115 these are all the easy ones dt didn't have at all (26 of 56) </desc> <cmt> imported 25 definitions from typescript-node-definitions </cmt> <cmt> first batch: the easy pickings </cmt> <cmt> - as per </cmt> <cmt> - added dt headers (scraped creators from git history) </cmt> <cmt> - added tests </cmt> <cmt> - some modifications </cmt> <cmt> - added contributors.md for the substantial defs (>50 loc) </cmt> <cmt> imported request definitions from typescript-node-definitions </cmt> <cmt> - as per </cmt> <cmt> - added dt header (scraped creators from git history) </cmt> <cmt> - added tests </cmt> <cmt> - updated some fields </cmt> <cmt> - restructured to be more accurate </cmt>,batch of imports from typescript-node-definition
1392,"<desc> the server is architected the way that it should be with multiple threads waiting on a single completion queue. the client currently uses a separate completion queue per-thread, but that may change in a later version. </desc> <cmt> new multithreaded async c++ tests. the server is architected the way </cmt> <cmt> that it should be with multiple threads waiting on a single </cmt> <cmt> completion queue. </cmt> <cmt> the client currently uses a separate completion </cmt> <cmt> queue per-thread, as trying to do a single unified queue was leading </cmt> <cmt> to crashes for me. i need to figure that out. </cmt> <cmt> add async multithreaded tests to build scripts </cmt> <cmt> rename async methods from generator to avoid naming conflicts to </cmt> <cmt> bind and other functions </cmt>","multithreaded async c++ perf tests, plus gens rename of async client methods"
1393,"<desc> fixes #2469. this pr makes the checking of destructuring patterns with an object literal or array literal initializers more flexible. when an object literal is contextually typed by the implied type of an object binding pattern: properties with default values in the object binding pattern become optional in the object literal. properties in the object binding pattern that have no match in the object literal are required to have a default value in the object binding pattern and are automatically added to the object literal type. properties in the object literal that have no match in the object binding pattern are an error. when an array literal is contextually typed by the implied type of an array binding pattern: elements in the array binding pattern that have no match in the array literal are required to have a default value in the array binding pattern and are automatically added to the array literal type. some examples: // type of f1 is (arg?: { x?: number, y?: number }) => void function f1({ x = 0, y = 0 } = {}) { } f1(); f1({}); f1({ x: 1 }); f1({ y: 1 }); f1({ x: 1, y: 1 }); // type of f2 is (arg?: (x: number, y?: number) => void function f2({ x, y = 0 } = { x: 0 }) { } f2(); f2({});        // error, x not optional f2({ x: 1 }); f2({ y: 1 });  // error, x not optional f2({ x: 1, y: 1 }); // type of f3 is (arg?: [number, number]) => void function f3([x = 0, y = 0] = []) { } f3(); f3([]);   // error, [] not assignable to [number, number] f3([,]);  // error, [undefined] not assignable to [number, number] f3([,,]); f3([1, 2]); f3([1, 2, 3]); in the f3 example, note that the initializer for the parameter binding pattern is allowed to omit elements (and, in particular, is allowed to be an empty array literal). this is a common pattern that we want to support. however, we still require tuples to specify all elements in other cases, as is demonstrated by the calls to f3. update 1: a question remains about how far we go in allowing tuple literals to omit elements. possible rules are: allow omitted elements when contextually typed by a binding pattern that specifies default values for the elements, e.g. function foo([x = 0, y = 0] = []). since that pattern is common, this is the minimum bar. allow omitted elements when contextually typed by a binding pattern, regardless of whether the binding elements specify default values, e.g. function foo([x, y] = []). we allow this currently, but we could say this is an error. that, however, would perhaps be inconsistent with function foo([x, y, ...z] = []), which we allow because spread and rest elements cause us to infer arrays instead of tuples. allow omitted elements everywhere, e.g. even for var x: [number, number] allow the assignment x = []. this would effectively amount to saying that tuple elements are always optional, i.e. we don't guarantee they're present, but we do guarantee they have the right type when they are present. go all out and support both optional and required elements in tuples. this would be a lot more work and imo not worth the effort. update 2: the pr implements option 1 above. </desc> <cmt> more flexible rules when destructuring have literal initializers </cmt> <cmt> adding a few comments </cmt> <cmt> adding tests </cmt> <cmt> accepting new baselines </cmt>",improved checking of destructuring with literal initializers
1394,"<desc> undoes part of #22154, which originally fixed #20732, given #24906 indicates chrome has some serious perf issues with this property. / fixes #24906. </desc> <cmt> remove clip-path from .sr-only utility as it causes perf regressions in chrome </cmt> <cmt> change snippet to example </cmt>",update .sr-only mixin and utility
1395,"<desc> see #6713 and #6717 for the background: the preprocessor didn't actually check for truthiness of js values properly, and as a result, in particular the environment setting option (where the user can say the code should run just on the web, or just in node, etc.) wasn't properly handled. to fix this, this pr fixes the truthiness handling: the processor will process a number, string, etc. as expected in js as to whether it is true or not. fixes bugs in the code where we depended on the bad behavior, in particular, in the environment code and one spot with wasm_mem_max. reworking the environment options, it was somewhat complicated because we have an older method to set the environment at runtime, by setting module.environment, and a recent compile-time setting, environment. the compile-time setting is more powerful and allows removing more unnecessary code, so this pr removes the old option. i made it throw an error at runtime if the option is used, pointing to the new environment option and how to use it, which tries to minimize any confusion. </desc> <cmt> fix js preprocessor on string values: check for truthiness directly. fixes #6713 </cmt> <cmt> deprecate module.environment, since we now have compile-time setting of the environment, and it makes this much simpler to not have 2 mechanisms. also fix issues with the static mechanism </cmt> <cmt> deprecate module.environment, since we now have compile-time setting of the environment, and it makes this much simpler to not have 2 mechanisms. also fix issues with the static mechanism </cmt> <cmt> fix </cmt> <cmt> changelog [ci skip] </cmt> <cmt> fix </cmt>",fix preprocessor bug handling of truthy values; rework environment setting options
1396,"<desc> this implements distributed reference counting for object ids that are serialized and passed to another process. it also implements reference counting for object ids that get nested in another object. there should be no change in memory management behavior from the user's perspective. by default, all workers will maintain these new ref counts, but they will not be considered when deciding whether an object is still in scope or not. therefore, the current behavior is that if the creator of an object id still has a local reference to the object, then at least one copy of the object will be available in the cluster. the creator of an object id is the process that called ray.put() or that submitted the task that returns the object id. the creator's local reference count includes: local python references to the objectid. number of pending tasks submitted by the creator that depend on the object. the new reference counts added by this pr include: number of objects that contain the objectid that are still in scope. list of processes that have a local reference to the objectid. eventually, object pinning will also consider the new reference counts when deciding when an object stored in plasma can be evicted. the guarantee will be that if any process in a cluster has a reference to the object id or an object that transitively contains the object id, then at least one copy of the object will be available in the cluster. to turn on this behavior, set the distributed_ref_counting_enabled flag to 1 in the internal config passed to ray.init(), like so: ray.init(_internal_config=json.dumps({ ""distributed_ref_counting_enabled"": 1, })) i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> skeleton plus a unit test for simple borrower case </cmt> <cmt> first unit test passes - forward an id and task returns with 1 submitted task pending on the inner id </cmt> <cmt> invariant for contained_in </cmt> <cmt> unit test passes for testing task return without creating a borrower </cmt>",distributed ref counting for serialized objectids
1397,"<desc> this is the first batch of incidental integration tests, based on the fastest running set of network integration tests currently passing using instances provisioned by ansible-test. shippable.yml the integration tests are unchanged from their original copies, aside from minimal updates to use the embedded test support collections. </desc> <cmt> initial copy of incidental network tests. </cmt> <cmt> update incidental test aliases. </cmt> <cmt> add incidental tests to ci. </cmt> <cmt> rewrite module references in tests. </cmt> <cmt> this should not be necessary once module redirection is supported. </cmt> <cmt> rewrite target references for renamed targets. </cmt> <cmt> add support collections for incidental tests. </cmt> <cmt> add ignores for test support code. </cmt>",first batch of incidental integration tests.
1398,<desc> checklist closing issues: #issue i wrote some lines in the radare2book minor fixes in #bin wad plugin </desc> <cmt> remove debug message </cmt> <cmt> fix wad_header_load to parse header info </cmt> <cmt> fix lumplumps type in wad_header_fields parsing </cmt>,fix/minor fixes to wad plugin
1399,"<desc> fixes: part of #10548 updated documentation for random_state in files: sklearn/manifold/_spectral_embedding.py sklearn/manifold/_locally_linear.py sklearn/manifold/_t_sne.py sklearn/manifold/_mds.py with @anaisabeldhero, during #wimdls </desc> <cmt> add 'random_state' descriptions and 'refer to glossary' in sklearn/manifold/* </cmt> <cmt> fixed formatting of random_state documentation </cmt>",add 'random_state' descriptions & 'refer to glossary' in sklearn/manifold/*
1400,<desc> added: exclude weekdays [and a list of specific dates] on gantt. as mentioned on issue #314 it is open to discussion how to render this: keep this way. extending the weekends or excluded days; hide the ignored dates; indicate the ignored dates on the task rectangle in some way. but i think it can be handled on another issue if anyone needs it. </desc> <cmt> added excludes weekdays to gantt </cmt> <cmt> docs </cmt> <cmt> doc html </cmt> <cmt> standard </cmt> <cmt> comments </cmt>,added exclude weekdays to definition
1401,"<desc> fix the mingw build once, build for a day. add mingw compilation to the ci suite, fix the build for life. </desc> <cmt> use lowercase names for windows headers </cmt> <cmt> otherwise we can't cross-compile on linux. </cmt> <cmt> refactor cmakelists.txt for mingw cross-compile </cmt> <cmt> two things: </cmt> <cmt> 1) by default, linux cmake puts -fpic on the link line. so we remove that </cmt> <cmt> for mingw to avoid warnings that it will be ignored. </cmt> <cmt> 2) similarly, move -fvisibility=hidden flag to be for non-mingw </cmt> <cmt> compilation only to avoid warnings that it will be ignored. </cmt> <cmt> enable mingw cross-compile stage in travis-ci </cmt>",enable mingw cross-compilation in travis-ci
1402,"<desc> the csi mock driver has been obsoleted and should not have been used anymore. that #101672 hadn't been merged was an oversight. besides that it is good practice to stay up-to-date, so all images get updated where possible. / </desc> <cmt> test/e2e/storage: replace mock driver with hostpath driver </cmt> <cmt> this is a first step towards removing the mock csi driver completely from </cmt> <cmt> e2e testing in favor of hostpath plugin. with the recent hostpath plugin </cmt> <cmt> changes(pr #260, #269), it supports all the features supported by the mock </cmt> <cmt> csi driver. </cmt> <cmt> using hostpath-plugin for testing also covers csi persistent feature </cmt> <cmt> usecases. </cmt> <cmt> storage e2e: hostpath driver v1.7.3 </cmt> <cmt> this is an automatic update of the testing manifests that mirrors the v1.7.3 </cmt> <cmt> release. all of these changes were created with </cmt> <cmt> test/e2e/testing-manifests/storage-csi$ ./update-hostpath.sh v1.7.3 </cmt> <cmt> storage e2e: update snapshotter sidecard rbac </cmt> <cmt> the same change was already done for csi-driver-host-path master, but not </cmt> <cmt> released yet because csi-snapshotter v5.0.0 itself was not ready yet. </cmt> <cmt> we need this update in k/k because some canary jobs already use the new </cmt> <cmt> snapshotter sidecar which causes permission issues. </cmt>","replace mock driver, update images"
1403,<desc> closes: #9250 </desc> <cmt> adding support for docker build args </cmt> <cmt> updated docs </cmt> <cmt> add extra explanation in docs </cmt> <cmt> declare type allowed in object; throw error when used with ecr uri configurations </cmt> <cmt> removed use of push() </cmt> <cmt> changed how array was built to match spread pattern; added unit test </cmt> <cmt> updated docs so that build-arg description fits in context of other image property write up. </cmt> <cmt> adding docker build --cache-from support; can be specified many times </cmt> <iss> add support for docker build --cache-from </iss>,add support for cachefrom to images
1404,"<desc> related to #15671 here, i improved the benchmark readme.rst as @mattip requested: add asv environment setup. add more practical commands and descriptions. reference: </desc> <cmt> improve benchmark doc </cmt> <cmt> doc improvement </cmt> <cmt> improve benchmark doc formate </cmt> <cmt> improve benchmark doc format2 </cmt> <cmt> improve benchmark doc formating </cmt>",improve benchmark readme with environment setup and more practical command
1405,"<desc> per discussion in #27353, isinstance checks with the abcfoo are about 4x as expensive as the foo checks.  individually they are still very small, but they add up. </desc> <cmt> perf: use faster isinstance checks </cmt>","use isinstance(obj, foo) instead of abcfoo"
1406,"<desc> -- we are collecting the data in a multi machine setup, and not using core limit gives us more comparable results to languages that don't support core limit. </desc> <cmt> dont use corelimit for throughput tests </cmt> <cmt> regenerate tests.json </cmt>",stop using core limit for unconstrained tests
1407,"<desc> i propose this pr to allow transformers to call azureml logging using  the intended behaviour is to enable transformers users to track metrics in the azureml ui in this fashion contributors to  i am glad to improve the following if reviewers like the idea, and update docs and tests if needed. @reviewers feel free to add any suggestions as my contributions to transformers have been very limited so far :) did you read the contributor guideline, was this discussed/approved via a github issue or the forum? yes, check for detais  documentation guidelines, and here are tips on formatting docstrings. @julien-c is aware of this and @sgugger participated in the thread on forums above and implemented callbacks with #7596 </desc> <cmt> first attempt to add azureml callbacks </cmt> <cmt> func arg fix </cmt> <cmt> var name fix, but still won't fix error... </cmt> <cmt> fixing as in </cmt>",add azureml in integrations via dedicated callback
1408,<desc> checklist add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. dashes ->  maketext -> </desc> <cmt> add maketext and dashes to two.js </cmt> <cmt> fix test issues </cmt>,add maketext function and dashes property to two.js
1409,"<desc> references #14216, changed the assert_raises, assert_raise_message, assert_warns to raises in the sklearn/utils/tests/test_estimator_checks.py </desc> <cmt> add permutation imp and change dataset to digits </cmt> <cmt> fix flake8 errors </cmt> <cmt> remove tight layout from plots </cmt> <cmt> reintroduce faces dataset and add the mdi usage warning </cmt> <cmt> fix bullet points and the reference </cmt> <cmt> finalize merge </cmt> <cmt> assert_raises to raises </cmt>",tst changes assert_raises to raises in sklearn/utils/test_estimator_checks.py
1410,<desc> based on #9676 by @smoki3 feature request #9662 on some rare setups you can't home x without the y axis (or vice versa) in the homed position. this pr adds options to perform homing of the other axis first when needed. </desc> <cmt> option to force x or y to home first when homing the other axis </cmt> <cmt> add codependent_xy_homing to example configs </cmt> <cmt> strip excess g28 debug logging </cmt>,option to force homing of a dependent axis
1411,"<desc> added an additional sentence for tips to add platforms when --platforms are not specified when running the command. updated the link to a more accurate place. this update is per offline discussion with @csells @amirh related issues n/a i added the following tests: created plugin supports no platforms should print no platforms message was updated to reflect the change. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> update message </cmt> <cmt> more test update </cmt>",update message for flutter create -t plugin when no --platforms specified
1412,<desc> fixes #13736 increase compatibility with the null balancer </desc> <cmt> fix the exception when the read-write separation type is empty </cmt> <cmt> fix the exception when the read-write separation type is empty </cmt> <iss> execute alter readwrite_splitting rule command error </iss>,fix the exception when the read-write splitting load balancer is null
1413,"<desc> fixing build breaks for missing dependencies mostly due to discrepancy between google internal build system and the oss build system. see commit logs for details. </desc> <cmt> [xla] fix build break in oss by adding missing dependencies. </cmt> <cmt> 1. ""compiler/xla/types.h"" is needed for uint16 in ""compiler/xla/bit_cast.h"". </cmt> <cmt> 2. ""gmock/gmock-more-matchers.h"" is needed for isempty(). </cmt> <cmt> 3. add some more dependencies. </cmt> <cmt> [xla] fix build break due to sqrtf. </cmt> <cmt> use std::sqrt(float) instead of std::sqrtf() as std::sqrtf is missing in many </cmt> <cmt> g++ versions due to non-conformity. </cmt> <cmt> for further info, see: </cmt> <cmt>  </cmt>",fixing build break of compiler/xla/tests
1414,"<desc> fix issue #16082 repair error prompt:  users are prompted to check whether the model or parameter files are damaged when loading parameters are wrong. error info: there is a problem with loading model parameters. please check whether the model file is complete or damaged. </desc> <cmt> merge to local </cmt> <cmt> merge to local </cmt> <cmt> merge to local </cmt> <cmt> merg to local </cmt> <cmt> update load_error_info, test=develop </cmt>",fix exception info for load_var
1415,"<desc> this is the backport of the gradle changes made as part of #22371. backporting these gradle changes will make backporting the high level rest client submodule easier in the future when ready (it is currently under development in master), by simply copying its directory from master to 5.x ideally. </desc> <cmt> require either buildplugin or standalonetestbaseplugin to use resttestplugin </cmt> <cmt> it used to be that resttestplugin ""came with"" standalonetestbaseplugin </cmt> <cmt> but we'd like to use it with buildplugin for the high level rest client. </cmt> <cmt> switch from standalone-test to standalone-rest-test </cmt> <cmt> standalone-rest-test doesn't configure unit tests and for these </cmt> <cmt> integ test only tests, that is what we want. </cmt>",backport gradle changes made in #22371
1416,"<desc> another attempt at #10455 and #11381. tracks which files are used by build plugins to know when it should do a full rebuild, a faster client-only rebuild, or can completely skip rebuilding after a file is modified. this should work with any type of file in any directory, and for both files in the app and files in packages. the most noticeable improvement is when modifying a file only used on the client meteor will only rebuild the client, even if the file is not inside imports or a client folder. these changes don't reduce how many files are watched, only what meteor does when one of them is modified. most build plugins should work correctly with no modifications, or work correctly but make meteor think every file is always used. build plugins that read the content of input files without using the file's api will need to be updated to tell meteor that the content of the file is used. changes for build plugins to track which files are used by build plugins, meteor records if a build plugin accesses an input file's hash or content. some of the methods that access either are: file.getcontentsasbuffer file.getcontentsasstring file.getsourcehash so the file is not unnecessarily marked as used, the build plugin should try to move calls to those functions to be inside of the lazy finalizer passed when adding a resource (or when using cachingcompiler, within compileonefile and getcachekey), which meteor calls once it knows the file will be used. for example, instead of this: const hash = inputfile.getsourcehash(); inputfile.addjavascript({ path: inputfile.getpathinpackage(), hash }, () => { return { data: compiled_content } }); you can move the call to inputfile.getsourcehash() to within the lazy finalyzer: inputfile.addjavascript({ path: inputfile.getpathinpackage() }, () => { const hash = inputfile.getsourcehash(); return { hash, data: compiled_content } }); as before, additional files can be watched/marked as used by calling either of these functions with a file's path: file.readandwatchfile file.readandwatchfilewithhash </desc> <cmt> track which files build plugins use the content of </cmt> <cmt> ignore changes to unused files in client watchset </cmt> <cmt> only use _dataused for source resources </cmt> <cmt> use sourceresource for package source resources </cmt> <cmt> add potentially unused file tests </cmt> <cmt> fix writing prelinked files </cmt> <cmt> update list of unused files after linking </cmt> <cmt> add tests for watching files in packages </cmt> <cmt> remove duplicate code </cmt> <iss> server always rebuilds even when only client side javascript changed. </iss>",track which input files are used by build plugins
1417,<desc> fixes #11389 adds an example to show correct middleware ordering when configuring an asp.net core app to use signalr with asp.net core authentication. also added an explicit note specifying that useauthentication() must be called before usesignalr(). used comments from @davidfowl (aspnet/signalr#2316 (comment)) in the text when explaining why ordering matters. </desc> <cmt> adds example of configuring signalr with authentication </cmt> <cmt> adds note explicitly mentioning ordering of middleware </cmt> <iss> authentication middleware ordering note </iss>,middleware ordering for signalr and authentication
1418,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). all file-based functions also accept streams:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. notes changes were found/tested during the usage of dockerode with typescript the return type for createimage is actually http.incomingmessage, but followed the style of using any in the same way as similar methods imo, any return types should be replaced with correct types in a future pr </desc> <cmt> loadimage and importimage can also accept streams </cmt> <cmt> added contributor </cmt> <cmt> createimage doesn't return dockerode.image </cmt>",update types used for image creation in dockerode
1419,"<desc> okay i didn't mean for there to be two pull requests back to back, but i've been working at this and now i've got it right. the locking mechanism is to press both shift keys at the same time, a very natural and easy motion. i straightened out the lshift/rshift issue at the same time. also fixed an imperfection in the lights. this version should be stable for a while! thanks erez and eric! cheers. </desc> <cmt> the ordinary layout is the most natural and powerful layout for the ergodox ez. come check it out. </cmt> <cmt> the ordinary layout is extraordinarily familiar and powerful </cmt> <cmt> the ordinary layout is the layout you are looking for. come and see. </cmt>",lock layers by pressing both shift keys
1420,"<desc> description: bump the pilight library version to 0.1.1, which incorporates a workaround for a packaging bug reported in the forum bugfix: whitelist filter works now also on data types that are not strings unittest added with 100% coverage related issue (if applicable): fixes # bug was reported in forum not on github. example entry for configuration.yaml (if applicable): pilight: checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> bug message data cannot be changed thus use voluptuous to ensure format </cmt> <cmt> pilight daemon expects json serializable data </cmt> <cmt> thus dict is needed and not a mapping proxy. </cmt> <cmt> add explanation why dict as message data is needed </cmt> <cmt> use more obvious voluptuous validation scheme </cmt> <cmt> pylint:  trailing whitespace </cmt> <cmt> pilight sensor component </cmt> <cmt> python 3.4 compatibility </cmt> <cmt> d202 </cmt> <cmt> use pytest-caplog and no unittest.testcase </cmt> <cmt> fix setup/teardown of unittests </cmt> <cmt> activate coverage testing </cmt> <cmt> bugfix whitelist filter and use bugfixed pilight library </cmt> <cmt> use newest pilight library that has a bugfix </cmt> <cmt> add unittest for pilight hub component </cmt>",bugfixes for pilight hub component and unit tests
1421,"<desc> hello, here is the chain that produces the error in issue #1904. _onviewreset() -> l.map.latlngtolayerpoint() -> l.map.getpixelorigin() -> l.map._checkifloaded() -> boom now the call of _onviewreset() is event-based and waits for the map to get ready ('load' event). that fixes issue #1904 and should work as well for issue #1831 jsfiddle with (manuelly) patched src.  lg fastrde </desc> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> call _onviewreset() not until map is loaded (center and zoom are set) </cmt>",fix worldcopyjump set center and zoom first
1422,<desc> resolves #9476 (devrel-731) resolves #9586 (devrel-939) resolves #9588 (devrel-942) select one </desc> <cmt> remove inaccurate statement on cleos set account command :doc </cmt> <cmt> add info callout about json input on cleos set account command :doc </cmt> <cmt> add link to accounts protocol in cleos set account command :doc </cmt> <cmt> add link to accounts protocol in cleos get account command :doc </cmt> <cmt> add link to accounts protocol in cleos set action permission command :doc </cmt> <cmt> fix goal description in how-to buy ram :doc </cmt> <cmt> add index for cleos main commands :doc </cmt> <cmt> correct description in cleos validate signatures command :doc </cmt> <cmt> add info callout about json input on cleos validate signatures command :doc </cmt>,various additions/fixes to cleos reference
1423,<desc> turns out #6069 wasn't quite as cut-and-dried as i thought it was. whoops! </desc> <cmt> documentation: fix typo (ex2 -> ext2) from #6069 </cmt> <cmt> documentation: fix typo (duplicate osxfuse) from #6069 </cmt> <cmt> this fixes part of #6656. </cmt>,fix some typos from #6069
1424,"<desc> relying on integration test to catch an algorithm bug introduces more flakiness, reduce the test into a unit test to reduce the flakiness until we upgrade java/scala libs. checked the test shall fail with older version of streamspartitionassignor. </desc> <cmt> kick off test migration </cmt> <cmt> reproduce </cmt>",migrate branchedmultilevelrepartitionconnectedtopologytest into a unit test
1425,"<desc> see details in #6644 . note the test harness is not well suited to navbar tests currently where the navbar items are actually hierarchical (which they are with this code), so i'll need to do some additional work here. i've manually tested this quite heavily, and it is javascript specific, so won't impact typescript navbar operation. getting this out for code review now, as vscode wants this asap to start locking down their next release. </desc> <cmt> basic flat list of items </cmt> <cmt> support for amd modules </cmt> <cmt> fixed whitespace </cmt> <cmt> remove temporary test </cmt> <cmt> added accessors, imports, and default export </cmt> <cmt> hardened code and added export specifiers </cmt>",improve navbar experience for javascript files
1426,<desc> this prevents winsock2 redefinition warnings (e.g. see issue gabime/spdlog#1589) and minimizes the stuff that windows.h includes. i also reversed  the #ifdefcondition to avoid redefinition warnings if either  nominmax or win32_lean_and_mean is already defined. </desc> <cmt> added win32_lean_and_mean define before including windows.h </cmt> <cmt> indent </cmt>,added  #define win32_lean_and_mean before including windows.h
1427,"<desc> the current implementation uses the loglog-beta approach to estimate the cardinality from the hyperloglog registers. unfortunately, the method relies on magic constants that have been empirically determined. the formula presented in ""new cardinality estimation algorithms for hyperloglog sketches"", </desc> <cmt> replaced tab by spaces </cmt> <cmt> improved hyperloglog cardinality estimation </cmt> <cmt> based on method described in </cmt> <cmt> that does not rely on any magic constants </cmt> <cmt> improved definition of hll_q </cmt> <cmt> made constant static </cmt>",better hyperloglog cardinality estimation algorithm
1428,"<desc> cf: compile and show output cfc: compile & copy cfp: compile from pasteboard & print </desc> <cmt> add coffeescript aliases: cf, cfc, cfp </cmt> <cmt> cf: compile and show output </cmt> <cmt> cfc: compile & copy </cmt> <cmt> cfp: compile from pasteboard & print </cmt> <cmt> typofix </cmt>",coffeescript aliases for easy compiling
1429,"<desc> with the current code changing opacity multiple times would only work for the first change on oldie. this fixes it and adds a manual test page for reproducing it. causes some visual issues with the clusterer (spiderfy, unspiderfy, spiderfy the same cluster and it wouldn't become partially transparent on the second spiderfy) </desc> <cmt> add a page for testing opacity works. </cmt> <cmt> fix setting opacity multiple times in oldie. was disabling the filter if it should be enabled and vice-versa </cmt>",fix opacity toggling in oldie
1430,"<desc> rearranged the way we set classes, to avoid duplicating regexes between setclasses.js and addtest.js fixes #844 and #808 </desc> <cmt> remove 'no-<feature>' classes if feature is detected </cmt> <cmt> update setclasses code style </cmt> <cmt> tidied up config-all.json: now all in alphabetical order and added any missing detects </cmt> <cmt> corrected stripdefine grunt task to account for variable r.js output (some versions include an empty dependency array in a final define(), others don't) </cmt> <cmt> update code style </cmt> <cmt> conflicts: </cmt> <cmt> grunt.js </cmt> <cmt> code style updates </cmt> <cmt> rearranged setclasses a bit: can now be reused by async tests (to avoid duplicating regexes) </cmt>",tidied up class handling following #844
1431,"<desc> this pr checks if a member is disabled from the member limit during auth and loading front-end views. a member would be disabled when an organization downgrades plans (or lets a trial expire) when they've added additional members but their plan only allows 1 user. a disabled member would get redirected to the /organizations/:orgslug/disabled-member/ view which will explain to the user what needs to be done to become re-enabled (asking their billing admin to upgrade their plan). that view only has a placeholder for now. the code to actually change members to disabled is here: getsentry/getsentry#5604. on the auth side, we disable all org-specific apis for that user-org combo. but non-org specific apis should continue to work (for example, listing all of the organizations for that member). some of those apis will be needed to render the upcoming view for disabled members (such as an organization drop-down). i decided not to make the feature controlled via feature flag in sentry since that adds extra overhead as long as we are using flagr. orgs that don't have the feature flag (organizations:limit-features-on-downgrade) won't have disabled members so checking the feature flag is unnecessary. i am using the new cached version of getting the organization member so we won't add latency with this new requirement </desc> <cmt> adds front end changes </cmt> <cmt> initial work for preventing disabled members from using sentry </cmt> <cmt> update component and route </cmt> <cmt> check feature flag </cmt>",disabled member redirect and auth
1432,"<desc> by default, new field types in sql are treated as unsupported, but because ""flattened"" adds a _keyed sub-field to the flattened field, the fields discovery algorithm in sql (looking at the output of field_caps api) is broken by the _keyed suffix. this pr fixes this situation for the ""flattened"" data type, but also for other future unsupported data types, by marking an entire hierarchy of fields and sub-fields under an unsupported data type field, as unsupported. </desc> <cmt> properly ignore (for the moment) the ""flattened"" data type, treating it </cmt> <cmt> as of unsupported type </cmt>",change the way unsupported data types fields are handled
1433,"<desc> replacement for #7848. fixes #7535. this creates 2 core functions, proxytomainthread and receiveonmainthread. they are variadic js functions, using js's flexibility to avoid a switch with an entry per signature etc. details of the binary approach are in the code, hopefully easy to see with the comments and the 2 functions side by side, but the key issue is the use js numbers (doubles) for all arguments, and the return value, since that's good enough (well, til js has bignums...). on the c side, a queued call has a ""js"" field which if nonzero is a buffer to the serialized code sent between proxytomainthread / receiveonmainthread. the c queues just see it as an opaque value, and pass it back to js. aside from that, this works the same as the old proxy code, with a negative value for an em_asm as opposed to a js library function, the list of proxiedfunctions, etc. a bunch of old complexity could be removed here, including the old postmessage sending and receiving code. </desc> <cmt> newsync experiment </cmt> <cmt> wip [ci skip] </cmt> <cmt> fix comment </cmt> <cmt> fix </cmt> <cmt> builds </cmt> <cmt> whitespace </cmt> <cmt> more whitespace </cmt> <cmt> newsync => sync, remove old mode </cmt> <cmt> em_asms too </cmt> <cmt> yolo [ci skip] </cmt> <cmt> fixes [ci skip] </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> remove all proxy call code </cmt>","proxy js library funcs and em_asms using the c mechanism, avoiding deadlocks"
1434,<desc> the assertion are tested by catching exception in gtest. </desc> <cmt> suppress  vc2013 warning in capitalize </cmt> <cmt> fixes #66 by adding writer::reset() and multiple root check </cmt> <cmt> note it redefines rapidjson_assert() to throw exception in unittest and </cmt> <cmt> check for assertion with gtest. </cmt> <cmt> add writer::iscomplete() </cmt> <cmt> add api doc for writer::reset() and writer::iscomplete() </cmt>,fix #66 by adding writer::reset() and writer::iscomplete()
1435,<desc> this change upgrades to the latest lucene 8.8.0 snapshot. it also restores the compression on binary doc values that was lost in the last snapshot upgrade. the compression is now configurable on binary doc values but we don't expose this functionality yet so this commit ensures that we pick the same compression mode as previous releases (best_compression). </desc> <cmt> update sha1 </cmt> <cmt> always enable compression on binary doc values </cmt>,upgrade to a new lucene 8.8.0 snapshot
1436,"<desc> please review and merge this pr. thank you, pavel </desc> <cmt> [jenkins-28041] extended delete-view cli command to accept multiple names to delete </cmt> <cmt> [jenkins-28041] extended delete-node cli command to accept multiple names to delete </cmt> <cmt> [jenkins-28041] extended delete-job cli command to accept multiple names to delete </cmt>",allow delete-* cli commands to operate on multiple arguments
1437,"<desc> part of #69665 (fixes for webgl, not canvas) fixes #85970 </desc> <cmt> remove unwanted log </cmt> <cmt> xterm@4.9.0-beta.25, xterm-addon-webgl@0.9.0-beta.1 </cmt> <cmt> part of #69665 </cmt> <cmt> clear webgl renderer texture on os resume </cmt> <cmt> support hot swap on webgl renderer </cmt> <cmt> fixes #85970 </cmt> <iss> webgl renderer isn't hot swappable </iss>",hot swap support and force redraw on resume with webgl renderer
1438,"<desc> the pr is based on #10153. it doesn't execute any podspecs until network configuration is done no matter it is master nodes or minion nodes, the detail can be found at  #10153 (comment). fixed #10122 and fixed  #9822. since i couldn't reproduce either  #10122 or #9822 on gce, i run cluster/kube-down.sh && hack/dev-build-and-up.sh && gcutil ssh kubernetes-master sudo docker ps -a for 10 times, and make sure there are no docker containers (kube-apiserver, etcd, pause...) killed at the booting time. </desc> <cmt> disable creation of cbr0, the kubelet does it now. </cmt> <cmt> conditionalize the docker bridge. </cmt> <cmt> fix the container bridge so that it can create cbr0 </cmt> <cmt> fix the kubelet so that it tries to sync status, even if docker is down </cmt> <iss> kube-apiserver fails to start </iss> <iss> kube-apiserver unable to write to etcd </iss>",fix the race between configuring cbr0 and restarting static pods
1439,<desc> currently it's hard to find the true failure in windows build because the log is too long. this pr turns off the logging for conda install and aws s3 cp to make the build more quiet. partially addressing #4990. </desc> <cmt> make conda install more quiet </cmt> <cmt> make s3 cp more quiet </cmt>,make conda install and s3 cp in windows build more quiet
1440,"<desc> the template for aws-java-maven got an example of how to implement the handler when the lambda is the backend to an api gateway proxy. it is a bit tricky, so having the example makes like lots better. what did you implement: closes #xxxxx how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: no is it a breaking change?: no </desc> <cmt> update to scala 2.12 to pick up converters </cmt> <cmt> update to scala 2.12 artifact </cmt> <cmt> give aws-scala-sbt some api gateway love like aws-java got </cmt>","add apigateway templates for aws-scala-sbt, upgrade to scala 2.12"
1441,"<desc> new pr for webaudio implementation by @barkholt (original pr was #4220). i picked the important commits of this pr and merged it against the latest libgdx versions. after testing, i can safely say that this is better than soundmanager2. some advantages i found so far: supports unlocking the sound system on user input and thus works on mobile and is future proof for desktop prefetches sounds when they are loaded, so they are played without a lag no extra js files needed anymore direct access to the web audio api lets us use its rich featureset pitch is working caveats i found so far: while autoplay (playing sounds before the user made an input) works on desktop browsers with soundmanager2, it does not work with this implementation if the browser or user does not allow it. a user input is needed for sounds and music to play. we can expect that it will also not work anymore with soundmanager in the future, so i think this is not a reason not to use this api. (game controller interaction is not counted as user interaction by chrome and firefox, so user needs to click or tap or press a key - this is more a wrong behaviour of the browsers) live example to try tested so far on chrome ubuntu firefox ubuntu chrome android safari ios safari mac for those wanting to try or to use this in existing 1.9.8/1.9.9/1.9.10 games: you can find jitpack dependencies to use with libgdx 1.9.8 (working with 1.9.9, too), 1.9.10 and 1.9.11 here. about the changes on the eclipse files: i don't know if they are needed because i don't use eclipse. if needed, i can revert the changes to .project/.classpath files. changes.md: i did not update changes.md so far because i am not sure if this will get merged (soon) and are afraid of merge conflicts. the following should be added there when this gets merged. * html: changed audio backend to webaudio api. now working on mobiles, pitch implemented. configuration change: preferflash removed. when updating existing projects, you can remove the soundmanager js files from your webapp folder and the references to it from the index.html </desc> <cmt> added web audio api support to gwt backend </cmt> <cmt> update new gwt audio branch to latest version of libgdx </cmt> <cmt> fixes to volume control in music </cmt> <cmt> remove unused code </cmt> <cmt> fix problems with callback, and removed debug </cmt> <cmt> removed soundmanager2 </cmt> <cmt> # conflicts: </cmt> <cmt> #	backends/gdx-backends-gwt/src/com/badlogic/gdx/backends/gwt/gwtapplication.java </cmt> <cmt> #	extensions/gdx-controllers/gdx-controllers-gwt/.classpath </cmt> <cmt> # conflicts: </cmt> <cmt> #	backends/gdx-backends-gwt/src/com/badlogic/gdx/backends/gwt/gwtapplicationconfiguration.java </cmt> <cmt> webaudio better behaviour for unlocking sounds </cmt>",gwt use webaudio instead of soundmanager2 lib
1442,"<desc> fixes #20523 - occurs when the number of references found didn't match the function arity fixes #20520 - ""impossible"" case as described by asserts actually does occur, but can be handled safely fixes #20527, #20474, #20472 - containing function may be undefined in the presence of syntax errors fixes #20542 - symbol writer may sometimes encounter index signature with no types fixes #20475 - symbol writer may sometimes encounter types with no symbol recommend reviewing commit-by-commit. some of these crashes are from telemetry and we've been unable to reconstruct a repro for them. </desc> <cmt> fix #20523 </cmt> <cmt> fix #20520 </cmt> <cmt> fixes #20527 </cmt> <cmt> fixes #20542 </cmt> <cmt> fixes #20475 (no repro found yet) </cmt>",omnibus fixes for telemetry-sourced crashes
1443,"<desc> this handles the remaining part of #91497 (reverted in #92820), in the factory constructor. there's a little bit of trickiness around defaults for certain properties (colorscheme and buttontheme, namely), but i documented it for buttontheme. </desc> <cmt> step 1 </cmt> <cmt> step 2 </cmt> <cmt> step 3 </cmt>","reland ""refactor themedata (#91497)"" (part 2)"
1444,"<desc> fixes #23435 </desc> <cmt> refactor the emit_vtable_methods code to be a bit cleaner in its use of </cmt> <cmt> iterators. </cmt> <cmt> check that predicates hold before emitting an entry for the vtable. </cmt> <cmt> fixes #23435. </cmt> <cmt> only test predicates if this is a default method, as a simple optimization. </cmt> <iss> ice when default method relies on where clauses that object type does not satisfy </iss>",skip default methods whose predicates are not satisfied when constructing vtables
1445,<desc> description: updated pylgtv to 0.1.6 to fix thread leak in asyncio loop related issue (if applicable): fixes #6749 checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> updated pylgtv module to fix problems with timeouts </cmt> <cmt> * dev: </cmt> <cmt> mvglive bug fixes and improvements (#6953) </cmt> <cmt> do not request artwork if not available (#7189) </cmt> <cmt> fix auto discovery for apple tv (#7188) </cmt> <cmt> fix for errors on missing preview on lg webos tv (#6755) </cmt> <cmt> added light.pwm component. (#7009) </cmt> <cmt> add ping binary sensor (#7052) </cmt> <cmt> opensky sensor (#7061) </cmt> <cmt> json mqtt device tracker (#7055) </cmt> <cmt> spotify media player (#6980) </cmt> <cmt> update frontend </cmt> <cmt> add bose soundtouch discovery support and upgrade libsoundtouch library (#7005) </cmt> <cmt> fix wemo discovery (#7183) </cmt> <cmt> updated pylgtv module to fix problems with timeouts (#7184) </cmt> <cmt> mqtt camera test (#7175) </cmt> <cmt> update frontend </cmt> <cmt> - update pylgtv to 0.1.6 </cmt> <cmt> - handle new timeouterror exception from pylgtv </cmt> <iss> webostv keeps files open until file limit is reached </iss>,issue 6749 updated pylgtv to 0.1.6 to fix thread leak in asyncio loop
1446,"<desc> also adds an integration test that runs on gpu if available. other pipelines could do the same if that would be helpful. </desc> <cmt> change summarization-pipeline default to distilbart </cmt> <cmt> change torch default summarizer to distilbart, add integration test that runs on gpu </cmt>",change summarization default to distilbart-cnn-12-6
1447,"<desc> closes #7676 fixed a bug where querying shadow dom could cause the error cannot read property 'length' of undefined in run mode the root cause of this issue is that the framework salesforce uses (aura) wraps the native document.queryselectorall. jquery (via sizzle) determines that document.queryselectorall is not available in that case, because it doesn't think it's native (even though aura calls the native method within its wrapper). this causes jquery to fall back to other methods of querying, which don't work well with shadow dom and result in the error at issue. why does it only happen in run mode? because there is no snapshotting. in interactive mode, an early xhr causes a snapshot, which queries the dom, which makes jquery determine queryselectorall support before the aura code runs. this can also be reproduced in open mode with cypress.config('numtestskeptinmemory', 0). this leads to the solution seen in this pr. when a page is loaded, before user scripts are run, we do a noop query (cy.$$('body')) to make jquery check for queryselectorall early and determine that it's there and it's native. from then on, it appropriately uses it for querying the dom. has the original issue been tagged with a release in zenhub? n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? </desc> <cmt> fix shadow-dom related edge-case </cmt> <cmt> shadow dom related refactor </cmt> <iss> typeerror: cannot read property 'length' of undefined when run test by cypress run </iss>",fix issue with finding elements in shadow dom under specific conditions
1448,<desc> #8150 broke use of the angular 1.5 component router by removing $canactivate and $routeconfig from icomponentoptions. this re-adds them to fix the breakage so we can update to the latest version of these types. i also moved some component router specific code to the appropriate file. </desc> <cmt> fix component router breakage </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>,fix angular component router broken by #8150
1449,"<desc> fixes #26994. we've run into a problem whereby the retry code was not properly holding refs to the send_initial_metadata payload, so if the code above c-core destroyed the metadata after the send_initial_metadata op was completed, the retry code would crash when it tried to replay that op on a subsequent call attempt. there are two parts to this problem.  first, metadata is passed in via the c-core api as an array of grpc_metadata structs.  when this is converted to a grpc_metadata_batch via grpc_mdelem_from_grpc_metadata(), the resulting mdelem is of storage type grpc_mdelem_storage_external, which is not ref-counted.  thus, when the retry code called grpc_metadata_batch_copy() to make a copy of the batch, the copy was not actually holding a new ref.   to fix this, i have changed grpc_metadata_batch_copy() to explicitly create a new mdelem instead of reffing the original one, if the original one is not a ref-counted storage type. second, the optimization added in #19427 made it so that slices created via grpc_slice_from_copied_string() were not actually ref-counted as they should have been.  thus, even if the mdelem was holding a ref to those slices, that ref would have been a no-op.  to fix this, i have changed grpc_slice_from_copied_string() to allocate a new ref-counted slice, the way it did prior to #19427.  this change may have a performance impact, but it's expected that future improvements can compensate for this. @lidizheng and @stanley-cheung, please try out this fix and verify that it solves the php retry crashing problem. </desc> <cmt> add test proving that we fail to take refs to send_initial_metadart payload </cmt> <cmt> fix grpc_slice_from_copied_string() to take refs and grpc_metadata_batch_copy() to copy the mdelems when necessary </cmt> <iss> retry routine causes use-after-free segfault in php extension </iss>",fix retry code to hold refs to send_initial_metadata slices
1450,"<desc> showcase support of different hoc declarations with union props. @pelotom now that we have an official recommendation to use conditionals for a distributive omit (microsoft/typescript#28339 (comment)) i think it's ok to use union props. since styled-components already accepted the fix (used in ad3ea9f) i'd hope other popular hocs would accept the fix as well: export type omit<t, k extends keyof t> = t extends unknown ? pick<t, exclude<keyof t, k>> : never; </desc> <cmt> [typescript] add test for union props and hoc interop </cmt> <cmt> [typescript] latest styled-components typings work with union props </cmt>",add regression test for popular hoc interop
1451,"<desc> #19917 this pr tries to fix ^ this issue. joe helped update g4 instance to use the new nvidia-460 driver, which should be higher than the minimum requirement of the cu112 docker </desc> <cmt> change cd mxnetlib task to use g4 node </cmt> <cmt> add g4 mapping </cmt>",fix cd by adding to $path
1452,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation re-enable pylint on a number of files with pylint globally disabled. no ui changes. test plan run lint run tests requires db migration. confirm db migration upgrade and downgrade tested. reviewers @john-bodley </desc> <cmt> re-enable pylint for superset/jinja_context.py </cmt> <cmt> re-enable pylint for superset/sql_lab.py </cmt> <cmt> re-enable pylint for superset/sql_parse.py </cmt> <cmt> re-enable pylint for superset/exceptions.py </cmt> <cmt> re-enable lint for superset/translations/utils.py </cmt> <cmt> re-enable pylint for superset/views/schedules.py </cmt> <cmt> re-enable pylint for superset/views/base.py </cmt> <cmt> re-enable pylint for superset/views/log/views.py </cmt> <cmt> re-enable pylint for superset/views/annotations.py </cmt> <cmt> black </cmt>",fix a bunch of files with pylint disabled
1453,"<desc> #4642 pipenv lock --pre doesn't actually include prerelease dependencies used the already existing self.pre variable to append --pre to a built command that ultimately results in prerelease dependencies being included in the locking process. this seems to be consistent with conventions at least within that file, and doesn't require additional fields to be defined. a news fragment in the news/ directory to describe this fix with the extension .bugfix, .feature, .behavior, .doc. .vendor. or .trivial (this will appear in the release changelog). use semantic line breaks and name the file after the issue number or the pr #. </desc> <cmt> add --pre as an argument </cmt> <cmt> add the news update </cmt>",4642 fix pipenv lock --pre doesn't include prerelease dependencies
1454,"<desc> this pull request updates our typescript verification process to not wipe out potentially vital user comments. introducing a prompt process was mostly a side effect of users wanting to keep comments. there's no reason we really need this prompt, as answering no would refuse to boot the next.js server anyway. fixes #8128 closes #11440 </desc> <cmt> add comment-json dep </cmt> <cmt> add types for package </cmt> <cmt> clean up existing code </cmt> <cmt> keep user inserted comments </cmt> <iss> `next dev` rewrites tsconfig.json </iss>",do not throw away tsconfig.json comments
1455,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. </desc> <cmt> added tslint.json </cmt> <cmt> added typings for latest version 4.2.0 </cmt> <cmt> readded jsx.element for breakclassname and set default tsconfig values </cmt>,typings for react-paginate (latest version 4.2.0)
1456,<desc> failed tests/test_modeling_speech_encoder_decoder.py::wav2vec2bertmodeltest::test_real_model_save_load_from_pretrained failed tests/test_modeling_speech_encoder_decoder.py::speech2textbertmodeltest::test_real_model_save_load_from_pretrained failed tests/test_modeling_speech_encoder_decoder.py::wav2vec2speech2text2::test_real_model_save_load_from_pretrained problem test_real_model_save_load_from_pretrained was using a missing self.get_inputs() and failing for all three flavors of encoder-decoder models. ci logs:  solution pass pretrained models together with suitably-shaped inputs. </desc> <cmt> add inputs to pretrained tests </cmt> <cmt> make style </cmt>,fix scheduled tests for speechencoderdecodermodel
1457,"<desc> this pr fixes two build errors that i encountered when trying to build serenityos with gcc 12. note that it's still not possible to build serenityos with it without resorting to dirty hacks, as the compiler ices in two places. one of these has already been reported; and i'm going to submit the other one too after the holidays. ak: add missing array.h include to checkedformatstring.h gcc 12 complains that iota_array is used before it's declared. gcc 11 works fine without it though. libcrypto: remove redundant __builtin_memset() call this call caused gcc 12's static analyzer to think that we perform an out-of-bounds write to the v_key vector. this is obviously incorrect, and comes from the fact that gcc doesn't properly track whether we use the inline storage, or the vector is allocated on the heap. while searching for a workaround, sam pointed out that this call is redundant as vector::resize() already zeroes out the elements, so we can completely remove it. </desc> <cmt> ak: add missing array.h include to checkedformatstring.h </cmt> <cmt> gcc 12 complains that iota_array is used before it's declared. gcc 11 </cmt> <cmt> works fine without it though. </cmt> <cmt> libcrypto: remove redundant __builtin_memset() call </cmt> <cmt> this call caused gcc 12's static analyzer to think that we perform an </cmt> <cmt> out-of-bounds write to the v_key vector. this is obviously incorrect, </cmt> <cmt> and comes from the fact that gcc doesn't properly track whether we use </cmt> <cmt> the inline storage, or the vector is allocated on the heap. </cmt> <cmt> while searching for a workaround, sam pointed out that this call is </cmt> <cmt> redundant as vector::resize() already zeroes out the elements, so we </cmt> <cmt> can completely remove it. </cmt>",fix two small build errors when compiling with gcc 12
1458,<desc> as per title fixes #8428 fixes #8189 component name area/packaging #8428: install netdata on a fresh centos 7 system from kickstart re-install netdata over the top and observe the error stop_all_netdata uv_pipe_connect(): no such file or directory #8189: install netdata on a fresh debian 10 (buster) system with --enable-epbf run the uninstaller and observe that all ebpf related files are removed. </desc> <cmt> fix bug in stop_all_netdata() to not try to kill netdata twice </cmt> <cmt> add uninstall support for ebpf collector </cmt> <iss> add uninstaller support for ebpf kernel package and shared libraries </iss> <iss> installer stop_all_netdata uv_pipe_connect() err </iss>,fixes support for uninstalling the ebpf collector in the uninstaller and fixes a minor bug
1459,"<desc> update packages to fix security issues. most important is sgvdata that was outdated and seems incompatible with node 9 and node 10. see also: bewest/sgvdata#3 only allow node 8.9.x in package.json, but execute travis with node 8 and node 10 add mongo port to 27017 mongo_connection in makefile because it will be required in future versions improve readme.md fix regression in booterror. small regression in 0.10.3-dev, but works in 0.10.2 release make mongodb connection string is missing more clear by referencing mongo_connection environment variable current state: upgrading sgvdata gives problems in nightscout. i need to investigate why it fails in nightscout although all sgvdata tests are running fine. this pr is not ready to merge. </desc> <cmt> fix booterrors after move it to server dir </cmt> <cmt> this used to work in 0.10.2, but moving booterror to server dir created a bug. caused by commit </cmt> <cmt> @sulkaharo committed on 27 dec 2017 </cmt> <cmt> make error message more clear for users </cmt> <cmt> improve readme instructions for installation </cmt> <cmt> add more clear message to mongo-storage-test.js as well </cmt> <cmt> stick to latest mongodb client 3.0.x (currently 3.0.11), to avoid warnings about usenewurlparser deprecationwarnings </cmt> <cmt> using mongodb 3.1 will generate (node:29452) deprecationwarning: current url string parser is deprecated, </cmt> <cmt> and will be removed in a future version. to use the new parser, pass option { usenewurlparser: true } to mongoclient.connect. </cmt> <cmt> starting from next nightscout release mongodb://localhost/test_db should not be used, and only use mongodb://localhost:27017/test_db so changing it in the makefile already </cmt> <cmt> more info: </cmt> <cmt> - </cmt> <cmt> - </cmt> <cmt> upgrade supertest </cmt> <cmt> enable node 10 for travis </cmt> <cmt> upgrade mocha and other packages </cmt> <cmt> increase timeout for hasauth.test.js </cmt> <cmt> because it times out with 40000ms on travis with node 10. see </cmt> <cmt> not ok 192 pluginbase does stuff </cmt> <cmt> assertionerror: expected -1 to be above -1 </cmt> <cmt> at assertion.fail (node_modules/should/cjs/should.js:275:17) </cmt> <cmt> at assertion.value (node_modules/should/cjs/should.js:356:19) </cmt> <cmt> at containsline (tests/hashauth.test.js:163:41) </cmt> <cmt> at window.mockconfirm [as alert] (tests/hashauth.test.js:165:7) </cmt> <cmt> at object.u.addbasals (tmp/js/bundle.js:9:2577816) </cmt> <cmt> at object.o.scroll (tmp/js/bundle.js:9:2485436) </cmt> <cmt> at v (tmp/js/bundle.js:9:3092518) </cmt> <cmt> at timeout.e [as _ontimeout] (tmp/js/bundle.js:9:3106675) </cmt> <cmt> # tests 192 </cmt> <cmt> # pass 191 </cmt> <cmt> # fail 1 </cmt> <cmt> upgrade sgvdata because it has security issues and is not compatible with node 9 and node 10 </cmt> <cmt> only allow node 8.9.x in package.json </cmt>",upgrade sgvdata and other packages and other fixes
1460,"<desc> related: #6932 based on the code path followed by numpy.matmul ( 35790f@numpy/core/src/multiarray/multiarraymodule.c#l2408 ), it appears this should also benefit from the syrk optimization. added some benchmarks to demonstrate that optimization. also, updated the release documentation to note where the syrk optimization is used. finally, resorted some benchmarks to match the order they appear at runtime. </desc> <cmt> bench: reorganize existing benchmarks by the order they show up when run in the benchmarking suite. </cmt> <cmt> bench: add some benchmarks for matmul. </cmt>",benchmark matmul and update documentation
1461,<desc> used the sentinel debug command to reduce the overall time it takes for sentinel test cases to run. test time reduced from 3 minutes to 1 minute 40 seconds in local environment. </desc> <cmt> update test cases </cmt> <cmt> minor changes </cmt> <cmt> update 05-manual.tcl </cmt> <cmt> update 10-replica-priority.tcl </cmt>,update test cases for sentinel
1462,<desc> after: </desc> <cmt> fix how the annotation layer interpretes the timestamp string without timezone info; use it as utc </cmt> <cmt> [bug fix] fixed/refactored annotation layer code so that non-timeseries annotations are applied based on the updated chart object after adding all data </cmt> <cmt> [bug fix] fixed/refactored annotation layer code so that non-timeseries annotations are applied based on the updated chart object after adding all data </cmt> <cmt> fixed indentation </cmt> <cmt> fix the key string value in case series.key is a string </cmt> <cmt> fix the key string value in case series.key is a string </cmt>,resolving key conflicts in timeseries annotation layer when key is a string
1463,"<desc> exit(0) in jsb_closewindow case scriptengine static memory freed, so when the scriptenginemanager::destroyinstance called later in appdelegate destructor, double free occurs </desc> <cmt> fix double free issues when js-tests exit on ios platform </cmt> <cmt> remove exit(0) after director::end, since we have do it in director destructor </cmt>",fix double free issues when js/lua-tests exit on ios
1464,"<desc> in the fit function for xgbmodel, if eval_set is specified with missing data there is an error related to 'missing' not being given. this is because the call to dmatrix is missing 'missing=self.missing'. i have fixed that. </desc> <cmt> xgbmodel.fit had a call to dmatrix without missing=self.missing. fixed that </cmt> <cmt> cosmetic change </cmt> <cmt> cosmetic change of putting space after comma compared to previous edit. </cmt>",call to dmatrix was missing 'missing=self.missing'
1465,"<desc> i kept my fixes for go 1.3 and os x in a separate commit from the revert commit so that you can see what changed. i can squash the two commits if desired. i will run hack/e2e-from-release.sh using both the go:1.3 and go:1.4 docker images to verify that it works properly in both places. i don't have an os x machine handy, but the change i originally introduced which broke os x has been reverted. </desc> <cmt> revert ""revert ""once again, use native ginkgo test runner instead of cmd/e2e."""" </cmt> <cmt> this reverts commit 67da1ac0c80eea4f9cc097eee745967b230eae4e. </cmt> <cmt> make e2e compatible with go 1.3 and os x. </cmt> <cmt> go 1.4 added the -o flag to the ""go test"" command as well as support for </cmt> <cmt> the testmain() function, so we must work around these not existing in </cmt> <cmt> go 1.3. </cmt> <cmt> the version of readlink on os x does not have the -f flag - so we'll </cmt> <cmt> just skip canonicalizing the path. </cmt>",use native ginkgo test runner instead of cmd/e2e (attempt n)
1466,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> v0.98.0 changes added </cmt> <cmt> chip javascript plugin usage added </cmt>",update materialize-css definitions to latest version 0.98.0
1467,"<desc> improve handling of integration test aliases: integration tests can now be marked: unstable, disabled, unsupported integration test aliases are verified with a sanity test. unstable integration tests only run on prs changing the test or code under test. ansible-test ansible version ansible 2.6.0 (at-alias-updates ecbd6aaba8) last updated 2018/04/12 14:53:46 (gmt -700) config file = none configured module search path = [u'/users/mclay/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/mclay/code/mattclay/ansible/lib/ansible executable location = /users/mclay/code/mattclay/ansible/bin/ansible python version = 2.7.14 (default, mar 22 2018, 11:39:16) [gcc 4.2.1 compatible apple llvm 9.0.0 (clang-900.0.39.2)] </desc> <cmt> include change classification data in metadata. </cmt> <cmt> add support for disabled tests. </cmt> <cmt> add support for unstable tests. </cmt> <cmt> add support for unsupported tests. </cmt> <cmt> overhaul integration aliases sanity test. </cmt> <cmt> update shippable scripts to handle unstable tests. </cmt> <cmt> mark unstable azure tests. </cmt> <cmt> mark unstable windows tests. </cmt> <cmt> mark disabled tests. </cmt>",improve handling of integration test aliases.
1468,"<desc> looks like there is still bug in epsg3395 (after #1578, #1796 and wrong #358). the problem is in transformation from linear projection coordinates to pixels. current transformation sets different scales for x and y coordinates, but it should be the same (major earth radius). as a result, epsg3395 raster tiles with epsg3395 map projection are shifted (for example, relative to vector data). i've added some tests for crs classes, that check projections of edge pixels of zero zoom tile. </desc> <cmt> fixing wrong epgs3395 transformation </cmt> <cmt> add test specifications for crs classes. </cmt>",wrong transformation in crs epsg3395
1469,"<desc> not very common but some might require to set the maximum number of clients, from code, to less than 4. in my case i must allow only one client at a time. </desc> <cmt> update esp8266wifiap.cpp </cmt> <cmt> it is not very common but some might require to set the maximum number of clients, from code, to smaller than 4. </cmt> <cmt> in my case i must allow only one client at a time (tested working) </cmt> <cmt> update esp8266wifiap.h </cmt> <cmt> as discussed in the .cpp (set max connections) </cmt>",set max_connection from code (when less than 4 is needed)
1470,"<desc> -added new command setwatchtype, not sure if it is necessary but i think it's more clean this way -added possibility to change watch type from context menu (lack of possibility to change the watch type from gui was reported in #2309) </desc> <cmt> dbg: added new command setwatchtype </cmt> <cmt> gui: added slots for changing watch type </cmt> <cmt> gui: added possibility to change watch type from gui, kinda fixed #2309 </cmt>",possibility to change watch type using gui (context menu)
1471,"<desc> this cherry-picks a change from main that ensures that async returns use ret void rather than unreachable on targets which do not support the llvm musttail instruction.  unfortunately, windows does not support the musttail instruction as the pei does not handle the lowering of the frame properly yet. </desc> <cmt> [irgen] put 'ret void' instead of unreachable for non swiftasync cc </cmt> <cmt> if target doesn't support musttail (e.g. webassembly), the function </cmt> <cmt> passed to coro.end.async can return control back to the caller. </cmt> <cmt> so the frontend should emit 'ret void' instead of unreachable after the </cmt> <cmt> coro.end.async intrinsic call to allow such situation. </cmt> <cmt> (cherry picked from commit 671ce74e97ed4f69aad0aa71afcc46408f337d12) </cmt> <cmt> test: repair the irgen tests after #39680 </cmt> <cmt> the change in 39680 impacts more than webassembly, but it did not update </cmt> <cmt> the tests for impacted targets. </cmt> <cmt> (cherry picked from commit 3df2531cd50ba5d4c373a2e6a35805fd9b351b59) </cmt>",cherry-pick a change from main to handle missing mandatory tail call optimizations
1472,"<desc> the apint::tostring api changed and no longer has an overload to return a std::string. instead, you have to pass the memory buffer in directly. also ran git clang-format on the commit, which had some fun with the include ordering. :) rdar://79746541 </desc> <cmt> fixed call to apint::tostring in serializesil </cmt> <cmt> the tostring has been updated so that it doesn't return a std::string </cmt> <cmt> anymore. instead, you have to pass the memory buffer in. this patch </cmt> <cmt> cleans that up. </cmt> <cmt> update all the apint tostrings </cmt> <cmt> just went through and updated the rest of the apint tostring calls. </cmt> <cmt> this should take care of them, i hope. </cmt>",fixes for apint::tostring api changes
1473,"<desc> this pull request temporarily removes eslint, as it was not landed in accordance with our standard experimental policies. we are fully committed to landing this change again. this is being reverted because: next.js has very strict goals for its install size. this feature resulted in adding over 17mb, or a 43.6% increase. the feature was not first landed under the experimental key in next.config.js, rather, it was added under the stable namespace (top-level) using the feature doesn't do a ""guided setup"" like typescript, it should ask you to ""bring your own"" dependencies for eslint it uses a undesirable eslint plugin name: plugin:@next/next/recommended. this should read out as strictly next, or as short as we can get it. does not provide actionable warnings (missing link to resolve issue) does not follow appropriate console output styling. we need to revisit how these are presented. to re-land this, we need to ensure the following minimums are met: very minor change in install size fully experimental (i.e. flagged) with warnings finalized package name and configuration shape, preferably so we can do { extends: 'next' }. </desc> <cmt> revert ""fix yaml parsing issue in eslint docs. (#23511)"" </cmt> <cmt> this reverts commit d4d611119e2a3340a7883410d9f7fb3f88e4dfb8. </cmt> <cmt> revert ""make eslint opt-in until it lands on stable (#23509)"" </cmt> <cmt> this reverts commit 2ec2ea8786dce87bbc428aff577bd13e1728db49. </cmt> <cmt> revert ""fix typo in eslint doc (#23338)"" </cmt> <cmt> this reverts commit 5c7475a6e89990cee45abfec8f396524bc122fa1. </cmt> <cmt> revert ""add eslint to next.js (#22437)"" </cmt> <cmt> this reverts commit e5ef60fecb142c149e0307376a1996f941b2840d. </cmt>",temporarily remove experimental eslint integration
1474,"<desc> this pr adds alignticks option to allow ticks alignment between multiple value or log axis. similar pr: #13210 how it works when a value/log axis is set to alignticks: true. it will find the first value/log axis on the same dimension that is not use alignticks and align the ticks to it. the align algorithm is bacially from radar series, which already has ticks alignment between multiple indicator axes, with some enhancement on the corner cases. the simple idea is find a good interval that having minimal extent that can contain the data. here is a detail explaination get the ticks number of axis align to. the splitnumber is ticksnumber - 1 calculate extent and interval with this splitnumber using calcniceextent. the calculated ticks number is not excatly same to the target number. so we need an extra refine step, the refine step will consider four cases: if min and max are both fixed. it will simply calculate the interval by (max - min) / splitnumber if max is fixed. try to calculate min by max - interval * splitnumber. interval is from the second step. if the calculated min is larger than the minimal value. increase interval util min is less than the minimal value. if min is fixed. similar to max fixed case. if both min and max are not fixed. set max to extent[1] calculated from the second step. then it's similar to the max fixed case. note if the calculated min and max cross the zero value. we need to check if the data extent cross and make sure they are both positive or negative. if the axis align to has set min or max. we need to adjust the calculated min and max proportionally. limitations time axis is not supported yet because the ticks calculation has becoming really complex since 5.0 using alignticks with complex min, max value, e.g. 'datamin', 'datamax', will lead to unreadable ticks. #11390 #10928 more conformance tests </desc> <cmt> feat(axis): add alignticks </cmt> <cmt> feat(alignticks): optimize ticks not crossing zero </cmt> <cmt> feat(alignticks): fix log axis align. add more test cases </cmt> <cmt> feat(alignticks): fix unit test </cmt> <cmt> test(alignticks): add vrt recording </cmt>",add alignticks for mutliple axis alignment.
1475,"<desc> currently, ci and pr validation are run on appveyor and travis using pretty different configurations.  this pr shows how azure pipelines could be used to unify the pipeline configuration and run ci and pr checks more quickly. azure pipelines offers unlimited minutes with 10 parallel jobs. the first commit attempts to match the appveyor and travis builds apples to apples. you can see in the build results that azure pipelines typically runs the linux jobs in <2 minutes and the windows jobs in ~5 minutes. the linux jobs are slightly faster than on travis; the windows jobs, though individually slower than on appveyor, are faster because of the additional parallelism. the second commit unifies the build using a single configuration. ci is run only on linux and coverage only on windows. here's an example of the build results. i also hooked up test reporting for the linux builds which you can see here: i was a little concerned that the windows builds appear to fail intermittently, but i noticed that appveyor seems to have the same flakiness? would you consider trying out azure pipelines and adding it as additional validation for pr/ci? disclaimer: i'm a program manager on azure pipelines. </desc> <cmt> set up azure pipelines for linux and windows </cmt> <cmt> unify linux and windows </cmt>",set up ci with azure pipelines
1476,"<desc> currently, you can only add other directories to the defaults using env['source_annotation_directories'] with rake notes or rake notes:custom. this allows a custom rake task to explicitly set the directories using: sourceannotationextractor.enumerate 'todo|fixme', dirs: %w(app lib), tag: true </desc> <cmt> use case statement </cmt> <cmt> allow :dirs option for .enumerate </cmt> <cmt> allows custom rake tasks to be defined using: </cmt> <cmt> sourceannotationextractor.enumerate 'todo|fixme', dirs: %w(app lib), tag: true </cmt>",allow a :dirs option to sourceannotationextractor.enumerate
1477,"<desc> pr details added a few mathematics books on differential equations and linear algebra added 2 sections on hdl languages (verilog, vhdl) added books on verilog and vhdl added a few linux books </desc> <cmt> update fork </cmt> <cmt> added a few mathematics books and a few hdl (verilog, vhdl) books </cmt>","added a few mathematics books and hdl (verilog, vhdl) books"
1478,<desc> minor fix in schema retrieval of foreign keys rework dialect keyword retrieval </desc> <cmt> typo in sql to retrieve schema fks </cmt> <cmt> add language keywords to dialect </cmt> <cmt> add scalar as keyword </cmt> <cmt> dynamically add non reserved words keywords </cmt>,rework dialect and minor fix
1479,"<desc> don't crash on certain lambda contents that partially match what we are looking for, but are not identical. specifically, we assumed the first line in lambda was a var or an assign. </desc> <cmt> fix an acorn optimizer regression: don't crash on certain lambda contents that partially match what we are looking for, but are not identical </cmt> <cmt> comment </cmt>",fix an acorn optimizer regression from #10724
1480,"<desc> handle the case where we recreate an auth context. add (opt-in) debugging for refcounts on auth contexts. these occur when we reconnect after a server goaway. this change builds upon other fixes in #2254, and it should be merged first. @jboeuf - can you take a look over this. assigning the review elsewhere since we have a merge blocked and it's late in paris. </desc> <cmt> fix leak in chttp2_transport incoming metadata </cmt> <cmt> wait for expectations to be fulfilled </cmt> <cmt> ssl refcounting fixes </cmt> <cmt> handle the case where we recreate an auth context. </cmt> <cmt> add (opt-in) debugging for refcounts on auth contexts. </cmt>",fix a leaks in ssl connection/authentication code
1481,"<desc> these changes are needed to give ray users insight into how their ray program is utilizing their machine's resources. a user should be able to tell at a glance, for example, if a worker they are expecting to be using a gpu is not using one, or if their overall gpu utilization is low. for more information, please see this document:  screenshot i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) there is currently no test framework in place for the front end, so for now i have tested this manually on my desktop with a gpu. one of my next upcoming prs will add some unit tests for the front-end. </desc> <cmt> add gpu monitoring to reporter and add the type annotations to typescript dashboard api file </cmt> <cmt> begin adding elements for gpu util </cmt> <cmt> wip </cmt> <cmt> wip compiles </cmt> <cmt> wip using new library </cmt> <cmt> switch from gputil to gpustat library to get process metrics and leverage them in the displays for worker gram </cmt> <cmt> jslint </cmt>",display gpu utilization in the dashboard
1482,"<desc> currently, these events are based on the number of items in the queue, rather than the number of items currently being processed.  this means the description of these event was totally wrong.  i consider this a breaking change, because if people were using them, then they meant something different. closes #724 </desc> <cmt> convert queue tests to mocha </cmt> <cmt> convert priorityqueue tests to mocha </cmt> <cmt> changed saturated and unsaturated to better reflect reality </cmt>","fix ""saturated"" and ""unsaturated"" events in queues"
1483,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> - [redux-form] add missing parameter to onchange function </cmt> <cmt> - test added </cmt> <cmt> - fix tests </cmt>",bugfix (redux-form) add missing parameter to onchange method
1484,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! add resources i added a link to polish wikibooks site with c++ and to a book published by a polish university. this book covers the basics of c ++ programming. there is an information in book that it is ""free publication available online"". yes not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> added free polish programing books </cmt> <cmt> added (pdf) to a programming book </cmt> <cmt> added alphabetical order </cmt>",added c++ polish programming book
1485,"<desc> move service extensions to new vm service. update resident runner to expose a vm_service.vmservice getter, and update tests to use fake vm service host #52179 </desc> <cmt> squashed commit of the following: </cmt> <cmt> commit ef440f1e44df1e0564d07a65f58aa05e4f211520 </cmt> <cmt> author: jonah williams <campfish91@gmail.com> </cmt> <cmt> date:   wed apr 15 19:29:00 2020 -0700 </cmt> <cmt> dont forget to implement it </cmt> <cmt> commit c0e868262660e71e7b819c223bb8f60523f4c4d5 </cmt> <cmt> author: jonah williams <campfish91@gmail.com> </cmt> <cmt> date:   wed apr 15 19:13:52 2020 -0700 </cmt> <cmt> [flutter_tools] remove isolate implementations </cmt> <cmt> move most tests to testybed </cmt>",even more vm service refactor
1486,"<desc> in this pr, it fixed issue of test_gru_bidirectional #11219 and add robust code. @pengzhao-intel, @taolv feature changes new features fixed issue of test_gru_bidirectional #11219. the reason is when creating temporary tensor for reshape, the code utilize the unallocated memory because of the incorrect start and end point. because the data in unallocated memory didn't be used in linalg_gemm, sometimes the code can pass and sometimes it will crash. we added 1000 times checking for test_gru_bidirectional in tests/python/unittests/test_operator.py. and will keep 1 time checking after testing is passed add robust code like param initialization. it can also make gru/lstm convergence curve (example/rnn/bucketing/cudnn_rnn_bucketing.py) be stable. replace memcpy/memset by using omp for better performance. test input size is from ds2 default parameters(seq_length = 300, batch_size = 20, input_size = 800, hidden_size = 800). layer=1 bidirectional = false inference time(fwd, samples/sec) training time(fwd + bwd, samples/sec) sym.rnn(mem) 357.7 168.06 sym.rnn(omp) 383.14 176.2 speedup 107% 104.8% layer=5 bidirectional = false inference time(fwd, samples/sec) training time(fwd + bwd, samples/sec) sym.rnn(mem) 86.66 37.24 sym.rnn(omp) 88.1 40 speedup 101.6% 107.4% unit-test changes add testcase test_loop_gru_bidirectional to test 1000 times test_gru_bidirectional in tests/python/unittests/test_operator.py. and will remove 1000 times checking after ci is passed. passed code style checking (make lint). all changes have test coverage. code is well-documented. </desc> <cmt> fix param init bug and remove memcpy/memset </cmt> <cmt> fix bug for bidirection size </cmt> <cmt> add 100 times loop for test_gru_bidirectional robust checking </cmt>",fix issue of test_gru_bidirectional #11219 and add robust code
1487,"<desc> synthesize pre-type-checked asts for a few places where we are deriving conformances: the getter for hashvalue == for uninhabited enums == for enums whose cases have no associated values should fix rdar://problem/54712316, a case where the non-type-checked ast was getting processed by silgen. </desc> <cmt> [sema] produce a type-checked ast when deriving the hashvalue getter. </cmt> <cmt> should fix rdar://problem/54712316, a case where the non-type-checked </cmt> <cmt> ast was getting processed by silgen. </cmt> <cmt> [sema] synthesize pre-type-checked == for uninhabited enums. </cmt> <cmt> [sema] synthesize pre-type-checked ast for == on no-associated-value enums </cmt>",synthesize pre-type-checked asts for more derived conformances
1488,"<desc> fixes #3185. modify pom.xml </desc> <cmt> add distributed lock center module </cmt> <cmt> in distributed lock center module, modify code style. </cmt> <cmt> orchestration 5.x </cmt> <cmt> add sharding-orchestration-center. </cmt> <cmt> modify meta-inf.services files in sharding-orchestration-center. </cmt> <cmt> add sharding-orchestration-center module in orchestration 5.x (#3468) </cmt> <cmt> feature 3185 step1 registry (#3486) </cmt> <cmt> recovery pom.xml and leafsegmentkeygenerator </cmt> <cmt> modify pom.xml to avoid dependency on sharding-orchestration-core. </cmt>",modify pom.xml in sharding-orchestration-core module
1489,<desc> this pr adds toggle for thumbnails within cards on homescreen and on chart/dashboard listviews and renders the toggle depending if feature flags is enabled. with feature flag off: with feature flag on: 111588127-5fef1600-8780-11eb-9a88-e5dbf8fbe680.mov test plan to test toggle btn you must set the thumbnails feature flag to true unit test will be updated to reflect new toggle btn. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> add toggle nav and localstorage </cmt> <cmt> add back welcome </cmt> <cmt> add feature flag check </cmt>,toggle thumbnails off or on and feature flag
1490,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add requestidlecallback </cmt> <cmt> satisfy linter, use tabs </cmt> <cmt> all tabs! </cmt>",add types for requestidlecallback api
1491,"<desc> some printers have no power switch, so disable those options when power_supply is 0. includes cleanup of number-to-string functions </desc> <cmt> allow power_supply 0 for no power switch </cmt> <cmt> conditionals and comments for ps = 0 </cmt>",allow power_supply to be 0
1492,<desc> fixes #1160. updates the equation button automation name and tooltip to use different resource items add tooltips to the colors in the style picker fixed the issue where the white color has the wrong automation name manually with narrator and validated the tooltips </desc> <cmt> update equationbutton automation name and tooltips </cmt> <cmt> added tooltips to the stylepicker and fixed the issue where the color name did not update for dark mode colors </cmt> <iss> update tooltips for the equationbutton and add them to the color picker colors </iss>,update tooltips for the equation button and style picker
1493,<desc> backport of #10125. the license.txt file needs to be in the numpy wheels in order to meet the terms of the linked libraries. add it to the configuration datafiles so that it shows up in the numpy package. also a small update to manifest.in adding tox.ini and excluding more development artifacts. </desc> <cmt> bld: include the license file in numpy wheels. </cmt> <cmt> the license.txt file needs to be in the numpy wheels in order to meet </cmt> <cmt> the terms of the linked libraries. add it to the configuration data </cmt> <cmt> files so that it shows up in the numpy package. </cmt> <cmt> bld: update manifest.in </cmt> <cmt> exclude more development artifacts and include the tox.ini file. </cmt>,add license file to numpy wheels.
1494,<desc> this pr fixes two bugs that can arise when _source is disabled and we fetch nested documents: fix indexoutofboundsexception in nested inner_hits with disabled _source. fix nullpointerexception in nested top_hits with disabled _source. add more tests for highlighting inner_hits. these regressions were introduced in #60494. fixes #66524. </desc> <cmt> fix an error when highlighting inner_hits with disabled _source. </cmt> <cmt> fix an error in nested top_hits with disabled _source. </cmt> <cmt> add more tests for highlighting inner_hits. </cmt> <cmt> adjust skip versions in rest tests. </cmt> <iss> innerhits highlight issue with _source disabled </iss>,fix regressions around nested hits and disabled _source.
1495,"<desc> use revision to avoid pom version conflicts between different branches. xxxxx xxxxx follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> use maven ci friendly versions: revision </cmt> <cmt> add back mis-deleted files </cmt>",use maven ci friendly versions: revision.
1496,"<desc> commit message: resolves an issue where people were adding assert(thread::mainthread::ismainthread()) into their systems, when in at least some cases that test was not detecting anything (failed open). this change enforces that we always create the singleton. it also protects (somewhat) against inter-test leakage (i hate singletons) by using raii to declare threads, and tracking nested instantiations of testthread and mainthread, forcing them to be consistent. i don't actually anticipate testthread ever changing, or needing this nested behavior, since we can declare that in main(). however, the main thread can be re-spawned between tests, and i suspect that some tests (fuzzing?) don't block till the previous test is completely quiesced. previous to this pr that would lead to undefined behavior, and in this pr due to the nested tracking, it should assert so that if such a leakage does occur, we'll learn about it. risk level: medium -- we may want to declare testthread in any main()s that link envoy outside this repo. testing: //test/... docs changes: n/a release notes: n/a platform specific features: n/a </desc> <cmt> init main thread at start of each test </cmt> <cmt> remove call to init test thread, now that it's in the test infrastructure. </cmt>",set up mainthread and testthread contexts as raii for more robust ismainthread checking
1497,<desc> for doing so some classes were renamed and the class hierarchy was changed: the codepanel has been split up into one panel for java classes (with smali tab) and one for text based reources (without smali tab). codepanel has been renamed to codecontentpanel (as the new codepanel now is only a codearea + scrollable searchbar) the codearea for java code and smali code now use the same abstract base class abstractcodearea. </desc> <cmt> feat(gui): make search bar usable for smali code </cmt> <cmt> chore: split code panel for class files and text based resources </cmt> <cmt> chore: refactored several classes in codearea package to get a reusable panel with searchbar+codearea and use it to implements java code + smali code view. </cmt> <cmt> chore: formatting applied </cmt>,separate searchbar for java code area and smali code area
1498,"<desc> module to create and manage infoblox nameserver groups through the wapi nsgroups objects. closing the stale pr #35915 in which originally the new module was added, addressed the review comments and added unit tests/integration tests for the respective modules. new module pull request nios_nsgroup </desc> <cmt> adding new nios_nsgroup module </cmt> <cmt> adding new nios_nsgroup module </cmt> <cmt> adding new nios_nsgroup module </cmt>","new module for creating, managing infoblox nios nameserver groups"
1499,"<desc> this pull request upgrades fs-plus to version 3.0.0 across all atom dependencies, so that we can snapshot it and go on with #13916. </desc> <cmt> :arrow_up: fs-plus </cmt> <cmt> upgrade fs-plus on atom packages and node modules </cmt>",upgrade fs-plus to version 3.0.0
1500,"<desc> modify the compression surface api so that message compression and stream compression now have a unified api that performs mutual exclusion of message/stream compression by nature. includes a bug fix: per http specification, allows spaces before/after a comma in the header 'accept-encoding'. </desc> <cmt> change c core surface api </cmt> <cmt> generate_project </cmt> <cmt> allow spaces in content-encoding </cmt> <cmt> clang-format </cmt>",modify stream compression surface interface
1501,"<desc> this is a modification to pull request #898 by @shykes. it fixes the issue where the testuser unit test fails when running a command as a non-root user. the _dockerinit directory was being created with 0700 permissions, which can only be read as root. sysinit could not read the container's rootfs when it dropped to a non-root uid, since _dockerinit is being used as an aufs branch of the rootfs. this caused all commands to fail when not run as root. the fix is to set permissions of the _dockerinit directory to 0755, which matches the permissions of the layer directories of all other images. n.b. if unit tests continue to fail, delete /var/lib/docker/unit-tests and run again. it may contain an old _dockerinit directory, which causes the test runtimes to skip creating it with the right permissions. </desc> <cmt> + runtime: inject dockerinit at /.dockerinit instead of overwriting /sbin/init. this makes it possible to run /sbin/init inside a container. </cmt> <cmt> change permissions of initlayer to be readable by non-root users </cmt>","fix to ""inject dockerinit at /.dockerinit"""
1502,"<desc> second split of pr ##11699, builds on #11746 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [tune] logger refactor part 1: move classes and utilities to own files </cmt> <cmt> [tune] logger refactor part 2: add syncer callback </cmt> <cmt> fix circular dependency </cmt>",logger refactor part 2: add syncercallback
1503,<desc> closes #7294 n/a. this is only an issue in develop has the original issue been tagged with a release in zenhub? n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? </desc> <cmt> fix e2e no-exit timeout </cmt> <cmt> handle webpack protocol for the sake of opening files in ide </cmt> <iss> error file paths can't be opened in ide when using webpack protocol </iss>,handle webpack protocol file opening
1504,"<desc> api(dynamic_gru) error message enhancement for c++ and python and provide unit test. api(chunk_eval) error message enhancement for c++ and python and provide unit test. api(beamsearchdecoder) error message enhancement python. fix crf_decoding output type from fp32 to int64. </desc> <cmt> dynamic_gru err_msg enhancement, test=develop </cmt> <cmt> chunk_eval err_msg enhancement and fix crf_decoding output type, test=develop </cmt> <cmt> beamsearchdecoder err msg enhancement, test=develop </cmt> <cmt> update some missing err msg, test=develop </cmt> <cmt> fix doc for chunk_eval, test=develop </cmt>","api(dynamic_gru, chunk_eval, beamsearchdecoder) error message enhancement"
1505,"<desc> uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design several tweaks to this flake test: don't pull the images always increase the termination grace period increase the timeout holding the tcp connection in the close_wait status poll every 1 second instead of 5 seconds don't close the connection if there is no data, we are not sending data and make the test racy it should fix #71565 :-) does this pr introduce a user-facing change?: </desc> <cmt> e2e kube_proxy pull only if not available </cmt> <cmt> e2e kube-proxy don't delete inmediatly </cmt> <cmt> e2e tcp close-wait don't set conn deadline </cmt> <cmt> don't set a connection deadline for reading, because the read operation will </cmt> <cmt> fail if no data is reaceived after the deadline, and will not keep the </cmt> <cmt> connection in the close_wait status. </cmt> <iss> flake: [sig-network] network should set tcp close_wait timeout </iss>",deflake tcp closewait e2e test
1506,<desc> test configuration: i have signed the contributor license agreement. i have read guidelines for pull request. my code follows the coding guidelines. i have performed a self code review of my own code. </desc> <cmt> add files for exporter </cmt> <cmt> clean and update exporter </cmt> <cmt> remove print </cmt> <cmt> remove comment </cmt> <cmt> exporter changes </cmt> <cmt> exporter </cmt> <cmt> fix exporters </cmt> <cmt> progress on pr </cmt> <cmt> fix pr </cmt>,losses and ops with giou -- new pr
1507,"<desc> @isidorn re-aligned design, color, and svg code manner for all icons. changed remove-all.svg back to multi-box clear icon. removed some ""***-dark"" icons and let the dark theme css point to the same light theme icon files. this is because some inverted colors are either too bright for dark theme, or almost the same as light theme colors so we don't need extra files. tweaked some css to define icon sizes. the svg files are responsive to container size. deleted breakpoint-hint.svg. let's use the regular breakpoint.svg file but set opacity in css. tuned up the green color for stackframe-and-breakpoint.svg to match the highlight color updated the gear icon in both debug and activity bar.  this is the latest version that i have in our master icon repo. #45253 #45128 #44550 #44849 </desc> <cmt> debug icons consistency pass and housekeeping. </cmt> <cmt> will use light theme icon file and css style </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> the red dot path was accidentally turned off by my icon script. turning it on. </cmt>",debug icons consistency and housekeeping work
1508,<desc> also fixes an issue where the loading ui would not show when reloading an instance. microsoft reviewers: open in codeflow </desc> <cmt> do not remove loadingui and focussafeharbor from ui when reloading an instance (#8937) (#8967) </cmt> <cmt> * do not remove loadingui and focussafeharbor from ui when reloading an instance </cmt> <cmt> * change files </cmt> <cmt> * remove bad assumption about number of children in reactrootview </cmt> <cmt> * format </cmt> <cmt> fix change file </cmt>,fix crash when using textinput.blur()
1509,"<desc> if the file name has symbol ':', will make this error like : 'git clone' failed with status 128 </desc> <cmt> fix the file name can not include symbol ':' </cmt> <cmt> fix the file name can not include symbol ':' </cmt> <cmt> fix the windowos download errror </cmt> <cmt> when use http mode, download error </cmt>",fix the  vue init error from private repository  in window os
1510,"<desc> the ""c++ talking directly with javascript objects"" half of embind works in fastcomp/asm.js now. instead of reinterpret_casting function pointers into javascript functions that could take more arguments, it uses variadic templates to pack up the argument wire types into a vararg-like structure on the stack which the javascript side can then parse out. </desc> <cmt> add some unit tests that verify we can pass all kinds of primitive types through val::as </cmt> <cmt> tests for val::as on strings and val too </cmt> <cmt> make val::as<> compatible with asm.js </cmt> <cmt> make val::new_ compatible with asm.js </cmt> <cmt> it appears we can use doubles as generic wire types. </cmt> <cmt> some minor emval simplifications </cmt> <cmt> allow passing memory_views in varargs </cmt> <cmt> fix passing memory_views in varargs </cmt> <cmt> make val::call<> compatible with asm.js </cmt> <cmt> rename readvaluefrompointer to readvaluefromvararg to make its sometimes odd behavior a little clearer </cmt> <cmt> make val::operator() compatible with asm.js </cmt> <cmt> make val::val(t&&) compatible with asm.js </cmt> <cmt> instead of varargs, which depend on the compiler, manually build the varargs packs on the stack. </cmt>",make emscripten::val compatible with fastcomp/asm.js
1511,<desc> this pull requests adds a basic debug symbol type for proguard and removes old remnants from when we had system symbols in the database. changes: get rid of legacy models we no longer need add proguard debug symbol type remove internal dsym type update libsourcemap to a version supporting proguard update docs on debug symbols to mention symbolserver normalize uuids on debug symbol submission </desc> <cmt> update libsourcemap </cmt> <cmt> added proguard image </cmt> <cmt> remove old system symbol data schemas </cmt> <cmt> updated debug_meta tests </cmt>,second pass on debug symbol refactor
1512,"<desc> unchanged backport of #14736. </desc> <cmt> [flink-21104][network] improve debug information for unaligned checkpoints </cmt> <cmt> [flink-21104][network] ensure that converted input channels start in the correct persisting state. </cmt> <cmt> when a checkpoint is aborted, the channelstatepersister of an input channel is stopped for that checkpoint. </cmt> <cmt> a barrier that arrives after that is simply ignored. </cmt> <cmt> however, if a channel is still being recovered during the abortion, the information that the checkpoint is stopped is lost for that particular channel. </cmt> <cmt> this commit initializes converted channels with that state correctly. </cmt> <cmt> additionally, this commit includes test that helped to verify that the channelstatepersister is actually working correctly now. </cmt>",ensure that converted input channels start in the correct persisting state. [1.12]
1513,"<desc> adds very basic support for linking an executing enrich policy to a standalone task other than the one associated with the request that submitted it. the main limitation here is that to execute something as a task in the background, the operation must be submitted to the internal client on the node that it will be running on. this is usually done (see reindex functionality) on the rest layer of the incoming request, but enrich policies can only be run on the master node, thus we need to wait for the transport operation to reach the master node before returning task information for something running in the background. this pr specifically changes the execution logic to create a new task using the execute request, and attaches the new task to the policy runner to be updated. also, a new response is now returned from the execute api, which contains either the task id of the execution, or the completed status of the run. the fields are mutually exclusive to make it easier to discern what type of response it is. additionally, tasks are cleaned up at the end of a run, so including task info on a response that was waited for is not useful. additionally, the status returned if running async will only just say that it's scheduled, which is obvious due to the present task id. this pr is just the ground work for adding in full task support - going forward we will be transitioning to cancellable and potentially persistent tasks, adding the wait_for_completion option (right now it defaults to waiting for ease of testing), and adding more information to the task status. </desc> <cmt> add task registration and unregister paths to the code. </cmt> <cmt> task status reports on what phase the policy execution is in. </cmt> <cmt> add task creation to the execute request. </cmt> <cmt> add a response that holds either a task id or a final task status. </cmt> <cmt> pass the request down to the executor so that a new task can be created. </cmt> <cmt> inject taskmanager into executor to create a new task for running async. </cmt> <cmt> update the completion listener to accept a task listener as well. </cmt> <cmt> pass task to underlying runner to be updated. </cmt> <cmt> update the listener return type to be the new task status </cmt> <cmt> move the executor to the transport action. </cmt> <cmt> we need a task manager for the executor and to get it we need to inject </cmt> <cmt> the transportservice, which is not available in the plugin setup. </cmt> <cmt> there should only be one action that is created, and its the only place </cmt> <cmt> that the executor is used, so we just set up the instance there. </cmt> <cmt> return new response from execute action. </cmt>",add basic task support for executing enrich policies
1514,"<desc> makes for less reading in the case of designated initializers. in the case of std::nullopt, this allows compilers to eliminate unnecessary zeroing out of the optional's buffer. </desc> <cmt> buffer_queue: make use of designated initializers </cmt> <cmt> buffer_queue: make use of std::nullopt </cmt> <cmt> allows compilers to eliminate unnecessary zeroing out of the optional's </cmt> <cmt> buffer. </cmt>",make use of designated initializers/std::nullopt where applicable
1515,<desc> fixes #126251 </desc> <cmt> start of editor override registration </cmt> <cmt> register terminal editor override properly </cmt> <cmt> get dragging uris working </cmt> <cmt> correctly dispose of input after drag </cmt> <cmt> clean up </cmt> <cmt> move input creation into term editor service </cmt> <iss> terminal editors: support drag and drop </iss>,terminal <-> editor drag and drop
1516,<desc> adding personal keymap for planck ez glow my code follows the code style of this project. i have read the contributing document. </desc> <cmt> create readme.md </cmt> <cmt> add personal keymap </cmt> <cmt> edit readme </cmt> <cmt> reorganize layouts </cmt> <cmt> update config.h </cmt> <cmt> edit beep settings </cmt>,add personal keymap for planck
1517,"<desc> description of the change this pull request pulls in the latest changes from electron-link which allow to exclude every module required from a particular file. with this new capability, we can now workaround the issue introduced with the upgrade of the spell-check package, which started requiring the xregexp module. specifically, we will now exclude all the modules required from node_modules/xregexp/xregexp-all.js; this file is already ""browserified"", meaning that it should be fine to embed it verbatim inside the snapshot. the errors observed in e.g.  alternate designs unclear. benefits the build will start passing again and we can use the latest version of spell-check as well. possible drawbacks unclear. verification process ci is green again. verify that spell-check works correctly by typing non-english words in an untitled buffer. /cc: @lee-dohm @daviwil </desc> <cmt> :arrow_up: electron-link </cmt> <cmt> exclude modules required from xregexp-all.js </cmt> <cmt> this file is already ""browserified"", meaning that it should be fine to </cmt> <cmt> embed it verbatim inside the snapshot. the errors observed in e.g. </cmt> <cmt>  </cmt> <cmt> process xregexp's already ""browserified"" modules again using </cmt> <cmt> electron-link. </cmt>",fix snapshot creation after spell-check upgrade
1518,"<desc> adds a help flag, as well as help messages to the gen_l10n.dart tool. this also refreshes the stocks app to reflect the new changes to the tool, while fixing a typo in the regenerate.md tutorial. ~/dev/flutter$ dart ${flutter}/dev/tools/localization/gen_l10n.dart --help --help                        print this help message. --arb-dir                     the directory where all localization files should reside. for example, the template and translated arb files should be located here. also, the generated output messages dart files for each locale and the generated localizations classes will be created here. (defaults to ""lib/l10n"") --template-arb-file           the template arb file that will be used as the basis for generating the dart localization and messages files. (defaults to ""app_en.arb"") --output-localization-file    the filename for the output localization and localizations delegate classes. (defaults to ""app_localizations.dart"") --output-class                the dart class name to use for the output localization and localizations delegate classes. (defaults to ""applocalizations"") related to #41437 </desc> <cmt> add pubspec.yaml comment, as well as help messages for gen_l10n.dart tool </cmt> <cmt> add help message print flag </cmt>","l10n tool improvements, stocks app refresh"
1519,"<desc> note: before submitting this pull request, please review our contributing guidelines. changes celery beat run command in supervisor's celerybeat.conf file </desc> <cmt> update extra/supervisord/celeryd.conf line 18 </cmt> <cmt> adding compatibility with celery 5.0.6 which have different worker 'run' command </cmt> <cmt> merge </cmt> <cmt> changes celery beat run command in supervisor's celerybeat.conf file </cmt> <cmt> due to new celery 5.0.5 syntax </cmt>",new celery beat run command for supervisor
1520,<desc> replaced assert_raises and assert_raises_regex with pytest.raises context manager. related to #14216 </desc> <cmt> fix assert_raises in test_regression.py </cmt> <cmt> related to #14216 </cmt> <cmt> fix assert_raises in test_classification.py </cmt> <cmt> fix assert_raises in test_common.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_pairwise.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_ranking.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_score_objects.py </cmt>,fix assert raises in sklearn/metrics/tests/
1521,"<desc> as reported in #3830, the v2.1 models include the label ""subtok"", which is an internal control symbol used to tell the parser to merge tokens. the learn_tokens setting was not being passed through correctly, and even if disabled, the parser was still adding the subtok label. the other part of the bug in 3830 was that, even if we did want to learn the tokens, the merge_subtokens pipeline component wasn't necessarily being added to the pipeline. this process is better handled in the postprocesses list that the parser and entity recognizer can define. i have submitted the spacy contributor agreement. </desc> <cmt> prevent subtok label if not learning tokens </cmt> <cmt> the parser introduces the subtok label to mark tokens that should be </cmt> <cmt> merged during post-processing. previously this happened even if we did </cmt> <cmt> not have the --learn-tokens flag set. this patch passes the config </cmt> <cmt> through to the parser, to prevent the problem. </cmt> <cmt> make merge_subtokens a parser post-process if learn_subtokens </cmt> <cmt> fix train script </cmt> <cmt> add test for 3830: subtok problem </cmt> <cmt> fix handlign of non-subtok in parser training </cmt>",'subtok' label being added even if learn_tokens=false
1522,<desc> fixes #2214. </desc> <cmt> modify number_ </cmt> <cmt> modify literals_ </cmt> <cmt> add hexadecimalliterals </cmt> <cmt> use numberliterals </cmt> <cmt> rename to string_literals </cmt> <cmt> use number_literals </cmt> <cmt> rename to stringliterals </cmt> <cmt> check style </cmt> <cmt> add charactersetname_ </cmt> <cmt> simply rule </cmt> <cmt> modify stringliterals </cmt> <cmt> rename to literals </cmt> <cmt> delete spaces </cmt> <iss> review the dcl parsing rules for different databases </iss>,review literals parsing g4 file
1523,<desc> use client::_timeout in wificlientsecure::connect instead of a hardcoded value. this can be modified via client::settimeout before connecting. set default _timeout for wificlientsecure to 15 seconds. ref. #3944 </desc> <cmt> wificlientsecure: use _timeout setting when connecting </cmt> <cmt> this timeout value can be customized via a call to settimeout function. </cmt> <cmt> closes </cmt> <cmt> wificlientsecure: increase default connection timeout to 15 sec </cmt>,"configurable wificlientsecure connect timeout, better default value"
1524,"<desc> this pr does three things: removes support for building playgroundlogger on linux (this never actually worked, so it doesn't make sense to keep maintaining something which doesn't work). this pr incorporates my earlier changes from #14003. merges the ""playgroundsupport"" and ""playgroundlogger"" products in build-script and updates presets where necessary updates how playgroundlogger and playgroundsupport are built, taking advantage of a new workspace and new schemes to do per-platform xcodebuild invocations (requires apple/swift-xcode-playground-support#18). resolves <rdar://problem/36512531>. </desc> <cmt> [build-script] removed the always-broken support for building playgroundlogger on linux. </cmt> <cmt> as far as i can tell, this never worked, so removing it cannot break anything. </cmt> <cmt> now playgroundlogger is treated similarly to playgroundsupport, directly referencing xcodebuild instead of indirecting through variables. </cmt> <cmt> this commit also introduces explicit error messages when attempting to build playgroundlogger or playgroundsupport for non-darwin platforms. </cmt> <cmt> this addresses <rdar://problem/36594779>. </cmt> <cmt> [build-script] merged the playgroundlogger and playgroundsupport products. </cmt> <cmt> these don't make sense to build separately, and indeed it's likely that playgroundlogger will soon depend on playgroundsupport. </cmt> <cmt> as a result, build them as one product (playgroundsupport) in build-script. </cmt> <cmt> aside from removing the playgroundlogger product, this otherwise continues to build playgroundlogger and playgroundsupport the same way. </cmt> <cmt> this is for <rdar://problem/36512531>. </cmt> <cmt> [build-script] adjust how playgroundlogger and playgroundsupport are built. </cmt> <cmt> instead of building separately, they are now built together using a new workspace with new schemes. </cmt> <cmt> as a result, xcodebuild is now invoked once per-platform, allowing for platform-specific build setting and architecture overrides. </cmt> <cmt> this addresses <rdar://problem/36512531>. </cmt>",fix how the playground frameworks build in build-script.
1525,"<desc> in #3053, upon suspending, all the children under the suspense's portal were rerendered. this pr changes that behavior such that the children under suspense's portal no longer rerender when they are suspended. instead, the portal's previous vnode id is reused just causing this children to be re-positioned under the portal's parentdom. this change requires moving the root node startdom handling outside of rendercomponent so that it still happens even when a portal's vnode id is the same. this change also improves handling suspense in and around fragments. the biggest fix is just making sure that a portal's (or root node's) _dom pointer doesn't bubble up to its parent internals when it has a different parentdom pointer. those little special if conditionals will hopefully go away when we stop bubbling _dom pointer up the tree through component internals. also, re-enabled the suspense hydration around scu components since backing tree enables this to just work. </desc> <cmt> improve suspending around fragments support </cmt> <cmt> add test for mounting a suspense component after a render </cmt> <cmt> re: the removed todo: this situation doesn't happen because in the render where lazy throws, it's siblings and parent finish rendering as if nothing happened. so all the parent pointers above and around lazy are set up correctly. so when the fallback goes to render and getdomsibling is called for the suspense portal, parent pointers have the correct children (they are the same children as what was just rendered and suspended) so getdomsibling works correctly. </cmt> <cmt> update follow ups </cmt> <cmt> don't rerender the suspense portal when rerendering </cmt> <cmt> fix suspense hydration through scu </cmt> <cmt> add note about bubbling up dom pointers through portals </cmt>",only reposition suspense children when suspending & improve suspending around fragments
1526,"<desc> previously, to work around a zoom button but on macos, the zoom button was disabled if previously disabled in certain places. #6664 showed a case where it wasn't properly enabled when it should have been. this pull request adjusts the workaround to always set the state of the zoom button to the state it was in before setstylemask or setcollectionbehavior. closes #6664 </desc> <cmt> add failing spec </cmt> <cmt> always reset maximizable state </cmt>",always restore maximizable state after changing window behavior/style
1527,"<desc> fixed null break bug and added option to include fixes #69012 fixes #69013 (adds clog, tests and options to orig fix) flatten </desc> <cmt> fix flatten loop control issue (break -> continue) </cmt> <cmt> fix issue #69012 </cmt> <cmt> (cherry picked from commit 2127be5ec5e6f892e1e303a3032f8aab394b97b2) </cmt> <cmt> fixed null break bug and added option to include </cmt> <cmt> fixes #69012 </cmt> <cmt> fixes #69013 </cmt> <iss> flatten field yields unexpected results when it hits none </iss>",fix flatten handling of nulls/nones
1528,"<desc> disclaimer: i've been looking for a project to start contributing to oss, and this one seemed interesting and not too complicated. since i'm a newbie in all this, any advice and suggestions are welcome! thanks! i intend to work on the issue ""short descriptions #184"" (#184), and the first step was to include some explanation about the factory method pattern. if possible, i would like some feedback on the description i added so i can have a better idea on what to do with the others. </desc> <cmt> added explanation about the factory method pattern. </cmt> <cmt> corrected description of factory method pattern. </cmt>",explanation of the factory method pattern
1529,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> preparations for publication of persian docs. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix for language direction in data_types </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added the warning about the vulnerability of the odbc driver. </cmt>,warning about vulnerability of odbc driver
1530,"<desc> fixes #17408, using @oliviertassinari's proposed solution. also, this fixes #16942, using the approach suggested here, taken from react-swipeable-views and simplified/adapted for the swipeable drawer. i changed the temporary swipeable drawer demo to show the reproduction content on all sides, here's a video (github doesn't let me upload webm files and the gif was way too big): demo.webm.zip i have followed (at least) the pr section of the contributing guide. </desc> <cmt> [swipeabledrawer] implement olivier's proposed fix for #17408 </cmt> <cmt> [swipeabledrawer] add support for native scrolls inside the drawer </cmt> <iss> [swipeabledrawer] not scrolling content when anchor=""bottom"" on mobile </iss> <iss> swipeabledrawer get triggered when scrolling on a dialog that appears on top of it </iss>",only trigger a swipe when appropriate
1531,<desc> we were hitting an illegalstateexception: there is already a changelog registered for ... in trunk-eos due to failing to call taskmanager#cleanup on unrevoekd tasks that we end up closing in handleassignment after failing to batch commit </desc> <cmt> cleanup tasks </cmt> <cmt> log level is too info </cmt> <cmt> revert excetion type change for now </cmt> <cmt> need to call cleanuptask before calling closeclean or closedirty </cmt> <cmt> add test </cmt> <cmt> add new test </cmt>,need to cleanup any tasks closed in taskmanager
1532,<desc> remove localflutterroot from globals (turns out tests weren't depending on it) and update startcontext just to take in a string conductorversion to write to the state file. </desc> <cmt> lift git-rev-parse in conductor start </cmt> <cmt> remove localflutterroot from globals.dart </cmt>,lift rev parse in conductor
1533,"<desc> the build was ignoring suffixes like ""beta1"" and ""rc1"" on the version numbers which was causing the backwards compatibility packaging tests to fail because they expected to be upgrading from 6.0.0 even though they were actually upgrading from 6.0.0-beta1. this adds the suffixes to the information that the build scrapes from version.java. it then uses those suffixes when it resolves artifacts build from the bwc branch and for testing. closes #26017 </desc> <cmt> teach build about version suffixes like beta and rc </cmt> <cmt> this should fix the upgrade tests when the upgrade from version is </cmt> <cmt> 6.0.0-beta1. version.java and version.groovy don't line up 100% but </cmt> <cmt> they are closer now, which is useful. </cmt> <cmt> update version test </cmt> <iss> [ci] vagrant centos packaging tests fail reliably </iss>",teach the build about betas and rcs
1534,"<desc> closes #23324 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry similar strategy as #22647, added a nonexistent keyword argument to round, ceil, and floor to control rounding when encountering a nonexistenttimeerror this is also fixes a bug in the nonexistent='shift' implementation in #22644 where dates with timezones with negative utc offsets got shifted by an additional hour. this bug is naturally tested by these rounding tests </desc> <cmt> nonexistent rounding </cmt> <cmt> fix shifting bug and add tests and whatsnew </cmt> <iss> rounding valid timestamps near daylight savings jumps should not throw nonexistenttimeerror </iss>",handle nonexistenttimeerror in date rounding
1535,"<desc> components have a model class method, that's used to instantiate their statistical model. this model classmethod hard-codes the architecture. this makes it pretty awkward to plug in a different model architecture --- you have to subclass. technically you can work around this, but it's messy. this pr brings in a technique we experimented with in spacy-pytorch-transformers, that seems to be working pretty well. the idea is to register creation functions, so that the component config can fetch the creation function by name. this avoids the problem of passing in a function --- if you pass a function in you can't serialise it, leading to all sorts of trouble. i've introduced a new term, architecture, for the types of functions we're registering. the problem is that model is too ambiguous: we tend to use it for a binary with the weights and config, but it can also be the object that does the prediction. that ambiguity is bad enough --- if we start calling the functions that create the models ""models"" as well, we'll really be in trouble. i think architecture is a nice term because it can't be confused for the thing itself, and people do use it in this sort of sense. it's a bit long, which is disappointing, and some might find it difficult to spell. but i don't have any better suggestions. i've tried to set up the entry points as well, but i might have gotten this wrong. once we fix the config system so that you can pass a config json to spacy train, the effect should be pretty good. the idea is that you should be able to write your own architecture and install it as a package, and then pass the config to spacy train and everything should work. another neat thing is that architectures can naturally be nested. architectures often have choices for the various layers inside them. this should make it easy to write models where you can swap out just the embedding strategy, or change the cnn for a bilstm, etc. i have submitted the spacy contributor agreement. </desc> <cmt> add architecture registry </cmt> <cmt> add test for arch registry </cmt>",add registry for model creation functions ('architectures')
1536,"<desc> non-automated tests renamed to ""checks"" and put in a 'manual' directory automated tests put into specific 'auto' directory first step. running py.test will now find and run the auto tests without also finding the manual checks by mistake. the automated test is still a bit slow (about 8s on my machine) and in future some effort should be made to move towards automated tests. i will also have a go at setting up travis-ci for automated builds if there is interest. </desc> <cmt> renamed non-automatable tests as ""checks"" </cmt> <cmt> moved tests into either manual or auto subdirectories. </cmt> <cmt> rename a manual test to a check </cmt>",simple refactor of directories to support auto testing
1537,<desc> implementation for hill climbing algorithm </desc> <cmt> dependency injection examples </cmt> <cmt> dependency injection examples for evaluation article </cmt> <cmt> junit test cases added for dependency injection </cmt> <cmt> junit test cases added for dependency injection </cmt> <cmt> classnotfoundexception vs noclassdeffounderror </cmt> <cmt> example to reproduce classnotfoundexception & noclassdeffounderror </cmt> <cmt> junit test cases for classnotfoundexception & noclassdeffounderror </cmt> <cmt> test cases to reproduce classnotfoundexception & noclassdeffounderror </cmt> <cmt> deleting exampls for evaluation article </cmt> <cmt> bael-831 examples for classnotfoundexception & noclassdeffounderror </cmt> <cmt> bael-831 removed wrapper class </cmt> <cmt> removing evaluation article example </cmt> <cmt> bael-831 removed wrapper class </cmt> <cmt> bael-875 - hill climbing algorithm </cmt> <cmt> bael-875 - implementation for hill climbing algorithm </cmt>,bael-875 example of hill climbing algorithm
1538,"<desc> thank you for taking the time to work on a pull request for this project! to ensure your pr is dealt with swiftly please check the following: your submissions are formatted according to the guidelines in the contributing guide. your changes are made in the readme file, not the auto-generated json. your additions are ordered alphabetically. your submission has a useful description. each table column should be padded with one space on either side. you have searched the repository for any relevant issues or prs. any category you are creating has the minimum requirement of 3 items. </desc> <cmt> added a health api and a geolocation api </cmt> <cmt> added a health api and a geolocation api </cmt> <cmt> fixed alphabetical order in health list. </cmt> <cmt> fixed alphabetical order in health list. </cmt>",added daum maps and lexigram apis
1539,<desc> have tested in machine translation demo which has two hidden layer inside rnn block. the benchmark result for the first batch is following(by bytes): model before after saving machine translation 525144064 490860544 6.53% </desc> <cmt> limit variable type to lod tensor in memory optimization transpiler </cmt> <cmt> init </cmt> <cmt> set rnn </cmt> <cmt> refine policy </cmt> <cmt> support while operator </cmt> <cmt> clean code </cmt> <cmt> fix code </cmt>,memory optimization on dynamic rnn
1540,"<desc> envoy's lua function httpcall is synchronous - envoy waits until the upstream request completes before continuing. this pr adds an optional flag to httpcall enabling the request to be asynchronous - envoy does not wait until the upstream service responds, and in fact ignores the response. httpcall continues to be synchronous by default. risk level: medium? testing: added a unit test and an integration test docs changes: added doc change to lua_filter.rst release notes: added release note to version_history.rst </desc> <cmt> extract http call functions into a new class, luafilterlibrary </cmt> <cmt> create fire and forget listener; lua function httpcallasync </cmt> <cmt> group class functions together </cmt> <cmt> add documentation for httpcallasync </cmt> <cmt> add release note to version history </cmt>",add fire-and-forget functionality to http call
1541,"<desc> this lets organizations with the necessary feature enabled override the active grouping config in the project settings. the grouping config is stored in the event payload (as grouping_config) so that wen can re-run the grouping later perfectly without having to store the actual component tree. in the project config the grouping algorithm can be set as follows: this ui is not intended to ever become user visible except for people enrolled in a grouping trial. later we probably want to just provide an ""upgrade grouping"" button and show this ui to customer support only. it also adds a small dropdown to the grouping page so one can try other variations of the grouping algorithm: </desc> <cmt> feat(grouping): add project option to force grouping and persit it </cmt> <cmt> feat(grouping): expose the grouping config forcing through the api </cmt> <cmt> ref: improved grouping config selectiong </cmt> <cmt> feat(grouping): add grouping config to the ui (feature flagged) </cmt>",add project option to force grouping and persist it
1542,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  (and its docs:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [mithril] add missing route parameter in routeresolver's onmatch </cmt> <cmt> [mithril] run prettier on everything </cmt>",add missing route parameter to routeresolver's onmatch
1543,"<desc> in case of a new cheat sheet, you have used the cheat sheet template. all the markdown files do not raise any validation policy violation, see the policy. all the markdown files follow these format rules. all your assets are stored in the assets folder. all the images used are in the png format. any references to websites have been formatted as text the ci build of your pr pass, see the build status here. this pr covers issue #747 </desc> <cmt> php 8 protects against xxe by default </cmt> <cmt> php 8 protects against xxe by default </cmt>",add message to say that php8+ prevents xxe by default.
1544,<desc> use __dict__ as default getstate and setstate. validation is added to make sure __dict__ is able to be converted to json. closes #18426 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> up </cmt> <cmt> up </cmt> <cmt> up </cmt> <cmt> format </cmt> <iss> restrict getstate/setstate to return json and use __dict__ by default for virtual actor </iss>,define default __getstate__ and __setstate__
1545,"<desc> closes #36727 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry the segfault was caused by self.obj.index.asi8=none when index is a string index. self._on.asi8 solves that issue. additionally i noticed, that obj.index was already sorted, so the insert of extra_col mixed up the order. we should use self.obj.index. i will add a whats new after #36689 is merged. </desc> <cmt> fix bugs in rolling sefault </cmt> <cmt> change test to test for all issues </cmt> <cmt> run black pandas </cmt> <iss> bug: segmentation fault when doing pandas.core.window.rolling.rollinggroupby.apply </iss>",segfault with string index when using rolling after groupby
1546,<desc> this pr adds dashboard info for proc_net_sockstat and proc_net_sockstat6 collector's charts. component name web/ install this pr; check the proc_net_sockstat and proc_net_sockstat6 charts; ensure the info is on the dashboard. fixes part of netdata/product#2104 </desc> <cmt> fix grammar </cmt> <cmt> add proc_net_sockstat charts info </cmt>,add proc_net_sockstat and sockstat6 charts info
1547,"<desc> adjustments have been made to scripts/eosio_build.sh and scripts/helpers/eosio.sh to support prompting to use the default installation path or to input a custom installation path. the -i flag can be used to set the installation path to avoid the prompt. the -y flag will avoid prompting for the installation path and instead use the default value. additionally, a bats test is added to ensure this functionality works as expected. environment variables have been split into two files as some are exported again when a custom path is set. </desc> <cmt> adjusted build script functionality to prompt for custom installation path if one is not provided. </cmt> <cmt> added suggested improvements. </cmt> <cmt> added removal of double quotes in version numbers. </cmt>",custom path support for eosio installation.
1548,"<desc> the distortion adjustment fixes this case, where t - .5 = 0.3947904614820772. expected: </desc> <cmt> add test for pointradius function type coercion. </cmt> <cmt> resample between first and last ring points. </cmt> <cmt> adjust threshold for distortion resampling. </cmt> <cmt> includes test case. </cmt>","resample between first and last ring points, and another distortion fix."
1549,"<desc> currently, the flutter create command did not respect disabled ios and android in config but created the android and ios folders nonetheless. this pr adds a simple check to not make the mentioned project subfolders if these platforms are disabled. command flutter create now behaves the same for ios and android as it does for other platforms/features. fixes #77925 repo flutter/tests left intact. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. </desc> <cmt> slflf-2: respect disabled ios and android on flutter create </cmt> <cmt> slflf-2: add tests </cmt> <iss> flutter create should respect disabled platforms </iss>",command flutter create respects disabled ios and android
1550,"<desc> closes rust-lang/rls#1390 this (probably?) fixes the case where we run the save-analysis code on the following snippet: trait test<'a> { type thing: test2; } trait test2 { fn print(); } #[allow(unused)] fn example<t>(t: t) where t: for<'a> test<'a> { t::thing::print(); //~ error cannot extract an associated type from a higher-ranked trait bound in this context // ^ only errors in save-analysis mode } the chain is as follows: culprit is hir_ty_to_ty which calls ast_ty_to_ty in the itemctxt which calls associated_path_to_ty which finally fails on projected_ty_from_poly_trait_ref rust/src/librustc_typeck/collect.rs lines 212 to 224 in 3de0106 if let some(trait_ref) = poly_trait_ref.no_bound_vars() { self.tcx().mk_projection(item_def_id, trait_ref.substs) } else { // no late-bound regions, we can just ignore the binder span_err!( self.tcx().sess, span, e0212, ""cannot extract an associated type from a higher-ranked trait bound \ in this context"" ); self.tcx().types.err } i'm not exactly sure why hir_ty_to_ty fails - is it because it needs more setup from typeck to work correctly? i'm guessing the fix is okay since we just pull the already typeck'd data (we run save-analysis after all the analysis passes are complete) from the tables. with this change we can 'go to def' on all segments in the t::thing::print() path. </desc> <cmt> save-analysis: use qpath_def for associated types </cmt> <cmt> save-analysis: simplify match arm for type node def </cmt> <iss> gstreamer fails to build with rls </iss>",pull associated type definition using qpath_def
1551,"<desc> the asp.net 4.x docs have moved to aspnet/aspnetdocs. this pr deletes the aspnet folder, removes the asp.net 4.x docset from .openpublishing.publish.config.json, and updates the readme & contribution files. </desc> <cmt> remove asp.net 4.x docset </cmt> <cmt> readme and contribution updates </cmt>",remove the asp.net 4.x conceptual docset
1552,<desc> update vue documentation with examples for whats a story / vue button story with args setup / vue - your component setup / vue - preview global decorator is this testable with jest or chromatic screenshots? no. does this need a new example in the kitchen sink apps? no. does this need an update to the documentation? yes. </desc> <cmt> fix: preset webpack test regexp for mdx stories </cmt> <cmt> docs: whats a story / vue button story with args </cmt> <cmt> docs: setup / vue - your component </cmt> <cmt> docs: setup / vue - preview global decorator </cmt>,docs / vue - getting started - examples
1553,"<desc> avoid introducing new critical edges. passes will end up resplitting them, forcing simplifycfg to continually rerun. also, we want to allow sil utilities to assume no critical edges, and avoid the need for several passes to internally split edges and modify the cfg for no reason. also, handle arbitrary block arguments which may be trivial and unrelated to the real optimizations that trampoline removal exposes, such as ""unwrapping"" enumeration-type arguments. the previous code was an example of how to write an unstable optimization. it could be defeated by other code in the function that isn't directly related to the ssa graph being optimized. in general, when an optimization can be defeated by unrelated code in the function, that leads to instability which can be very hard to track down (i spent multiple full days on this one). in this case, we have enum-type branch args which need to be simplified by unwrapping them. but, the existence of a trivial and entirely unrelated block argument would defeat the optimization. </desc> <cmt> rewrite simplifycfg's trampoline removal. </cmt> <cmt> avoid introducing new critical edges. passes will end up resplitting </cmt> <cmt> them, forcing simplifycfg to continually rerun. also, we want to allow </cmt> <cmt> sil utilities to assume no critical edges, and avoid the need for </cmt> <cmt> several passes to internally split edges and modify the cfg for no </cmt> <cmt> reason. </cmt> <cmt> also, handle arbitrary block arguments which may be trivial and </cmt> <cmt> unrelated to the real optimizations that trampoline removal exposes, </cmt> <cmt> such as ""unwrapping"" enumeration-type arguments. </cmt> <cmt> the previous code was an example of how to write an unstable </cmt> <cmt> optimization. it could be defeated by other code in the function that </cmt> <cmt> isn't directly related to the ssa graph being optimized. in general, </cmt> <cmt> when an optimization can be defeated by unrelated code in the </cmt> <cmt> function, that leads to instability which can be very hard to track </cmt> <cmt> down (i spent multiple full days on this one). in this case, we have </cmt> <cmt> enum-type branch args which need to be simplified by unwrapping </cmt> <cmt> them. but, the existence of a trivial and entirely unrelated block </cmt> <cmt> argument would defeat the optimization. </cmt> <cmt> simplifycfg; trampoline cleanup </cmt> <cmt> remove a pile of crufty ""trampoline"" elimination code that didn't make </cmt> <cmt> sense. </cmt> <cmt> add information to silverifier stack nesting diagnostic. </cmt> <cmt> simplifycfg; add jump-threading successors to the worklist. </cmt> <cmt> this is required for simplifycfg to iterate over simplified blocks </cmt> <cmt> when it does critical edge splitting. </cmt>",rewrite simplifycfg trampoline removal to generalize it (avoid critical edges as a side-effect)
1554,"<desc> we get compilation errors when using hw serial with ep enabled on stm32. this fix that and add one more lib maple compatibility. as we are beginning to add more boards on stm32, we will need setup options to take care... this fix two.. </desc> <cmt> fix compilation error with ep enabled on a board without usb serial / cdc </cmt> <cmt> add one more lib maple compatibility </cmt>",fix ep compilation error when using hw serial for stm32
1555,"<desc> fixes #14503. this pr enables early stopping by default in hgbm: n_iter_no_change=10 instead of n_iter_no_change=none (not sure about this value, i looked at #14303) the docstrings have been changed accordingly the following sentence has been added in the docstrings (changes are welcomed, lack of inspiration): early stopping is the default behavior, as it usually makes the fitting process much faster without a substantial difference in terms of predictive performance. the random_state has to be fixed in the examples (for the cross-validation), because the performance (clf.score(x, y)) depends on the splitting. n_iter_no_change=none has been added to some existing tests, so that they can check the expected behavior. a small test has been added that checks that early stopping is enabled by default </desc> <cmt> update docstrings and change default value </cmt> <cmt> disable early stopping for some tests </cmt> <cmt> check that early stopping is enabled by default </cmt> <cmt> fix the random state in the examples </cmt> <iss> turn on early stopping by default in histgradientboosting estimators </iss>",fea turn on early stopping in histogram gbdt by default
1556,"<desc> parameterize main_common_test over ipv4 and v6. risk level: low testing: ran affected test locally docs changes: n/a release notes: n/a fixes #2649 </desc> <cmt> parameterize google_com_proxy_port_0.v2.yaml </cmt> <cmt> adds an '{{ ip_any_address }}' replacement pattern and uses that to </cmt> <cmt> interpolate the correct (ipv4 vs ipv6) ip address into the config. </cmt> <cmt> paramterize main_common_test over both ip versions </cmt> <cmt> now that the config has been templatized, run the test for both </cmt> <cmt> versions, injecting the right address format for each. </cmt>",run main_common_test with ipv4 and v6
1557,"<desc> the commit messages contain more information about the individual changes. this commit makes sure that our code is consistent and avoids the issue now reported upstream in puppeteer/puppeteer#7836 so that it's no longer a blocker for us. fixes #14363. </desc> <cmt> consistently use string arguments for page.waitforfunction calls </cmt> <cmt> we use string arguments in all other places, so these two places are a </cmt> <cmt> bit inconsistent in that sense. moreover, it's just one argument now, </cmt> <cmt> which makes it a bit easier to read and see what it does because we </cmt> <cmt> don't have to pass the always-empty options argument anymore. finally, </cmt> <cmt> doing it like this ensures it works in all puppeteer versions given </cmt> <cmt>  </cmt> <cmt> upgrade to puppeteer 13.0.0 </cmt> <iss> fix broken puppeteer upgrade to version 13.0.0 </iss>",consistently use string arguments for page.waitforfunction calls and upgrade to puppeteer 13.0.0
1558,"<desc> small cleanups and follow-up for #3131. </desc> <cmt> machinectl: simplify option string assignment </cmt> <cmt> it's better to avoid having the option string duplicated, lest we forget </cmt> <cmt> to modify them in sync in the future. </cmt> <cmt> networkd: drop unnecessary stmt </cmt> <cmt> basic/dirent-util: do not call hidden_file_allow_backup from dirent_is_file_with_suffix </cmt> <cmt> if the file name is supposed to end in a suffix, there's not need to check the </cmt> <cmt> name against a list of ""special"" file names, which is slow. instead, just check </cmt> <cmt> that the name doens't start with a period. </cmt>",various small cleanups in shared code
1559,"<desc> this pr replaces array with readonlyarray in the arguments. i've confirmed the all arrays are not modified by prosemirror-menu. this pr also updates rendergrouped function's argument type. the content argument receives only array<array<element>>, but the type definitions accepted array<element> also unexpectedly. the upstream's documentation has been fixed. prosemirror/prosemirror-menu#34 add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: prosemirror/prosemirror-menu#34 add it to notneededpackages.json. </desc> <cmt> [prosemirror-menu] replace array with readonlyarray </cmt> <cmt> [prosemirror-menu] fix rendergrouped's argument type </cmt>",replace array with readonlyarray in the arguments
1560,"<desc> i hereby agree to the terms of the cla available at:  detailed description / documentation draft: background: #27252 add an explicit dependency from libroaring to clickhouse_common_io. since this would create a circular dependency, remove the dependency on roaring from clickhouse_common_io and add it to dbms. another option would have been to detect the split build environment and avoid running the test, but that wouldn't fix the underlying issue (tracking libroaring memory use). i've tested with split build and release mode (single binary by default) and it works under both setups. feel free to suggest better approaches (if any). i'm also adding a list of drawbacks to the split build documentation based on comments from @alexey-milovidov </desc> <cmt> add explicit dependency between roaring and clickhouse_common_io </cmt> <cmt> fixes roaring memory tracker for split builds </cmt> <cmt> add a note about split build drawbacks </cmt>",fix 01961_roaring_memory_tracking for split builds
1561,"<desc> previously, when encountering a borrow of a guaranteed value, the end_borrows of that reborrow were marked alive.  only doing that enables end_borrows of the outer borrow scope can be marked as dead.  the result is that uses of the reborrowed value (including its end_borrow) can outstrip the outer borrow scope, which is illegal. here, the outer borrow scope's end_borrows are marked alive.  to do that, the originally borrowed values have to be identified via findguaranteedreferenceroots. </desc> <cmt> [silopt] add utility to find guaranteed roots. </cmt> <cmt> the new utility looks through ownership forwarding instructions to find </cmt> <cmt> the original values with guaranteed ownership. </cmt> <cmt> [test] removed spurious attribute. </cmt> <cmt> [test] improved pattern name. </cmt> <cmt> [nfc] used already cast value. </cmt>",keep outer borrows alive when reborrowing.
1562,"<desc> what do these changes do? adjust the sigma of parameter space gaussian noise according to the sigma of ou noise multiplied by noise_scale. thus, we are able to keep consistent with the actually intended action space noise. #5173 linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> make parameter space noise consistent with action space noise </cmt> <cmt> modified according to lint check </cmt> <cmt> indent </cmt>",keep parameter space noise consistent with action space noise (fix 5173)
1563,"<desc> mainly redefining how test utils should explore fiber's internals. </desc> <cmt> test fiber internals differently in reactelement </cmt> <cmt> instead of being able to access the owner's instance via getpublicinstance(), we use the fiber's statenode. (fiber does not have methods, it's just a structure!) </cmt> <cmt> fix iscompositecomponentwithtype for fiber </cmt> <cmt> in reacttestutils.iscompositecomponentwithtype, we provide a way to walk through fiber's internals in place of using _currentelement.type. we keep support for non-fiber though. </cmt>",fix tests for fiber in reactelement-test
1564,"<desc> 5.5 cherry-pick of #37189 if we're lifting them outside of the control flow structure they're dealing with, turn them into placeholders, as they will no longer perform the control flow the user is expecting. this handles: return statements at the top-level of the callback. break statements in switches that we re-write. in addition, fix a bug where we'd inadvertently transform an unrelated switch statement in the callback. resolves rdar://74014897. </desc> <cmt> [refactoring] have addcustom take a sourcerange </cmt> <cmt> and have it automatically track to the end of the </cmt> <cmt> token, as that's the behavior we seem to always </cmt> <cmt> want. </cmt> <cmt> [refactoring] don't transform unrelated switches </cmt> <cmt> we were missing a return here to ignore any </cmt> <cmt> switch statements that don't have anything to do </cmt> <cmt> with the error handling. </cmt> <cmt> [refactoring] replace lifted breaks/returns with placeholders </cmt> <cmt> if we're lifting them outside of the control flow </cmt> <cmt> structure they're dealing with, turn them into </cmt> <cmt> placeholders, as they will no longer perform the </cmt> <cmt> control flow the user is expecting. </cmt> <cmt> this handles: </cmt> <cmt> - return statements at the top-level of the callback. </cmt> <cmt> - break statements in switches that we re-write. </cmt> <cmt> resolves rdar://74014897. </cmt> <cmt> [refactoring] [test] use more strict matching on returns and breaks </cmt> <cmt> make sure we match against an exact return or </cmt> <cmt> break in these cases, rather than a placeholder. </cmt>",replace lifted breaks/returns with placeholder for async transform
1565,"<desc> i moved bfs and dfs (graph implementation) to the graph section and added a good explanation video on bfs and dfs implementation for trees. maybe @jwasham, you will consider to merge this pull request, because bfs and dfs for trees are easier to implement and people who will study trees won't need to go into graph implementation, before they face graphs, so maybe this link will fit there :) </desc> <cmt> update readme.md </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update readme.md </cmt>",moved bfs and dfs (grapht implementation) videos to the graph section
1566,"<desc> follow-up of #20567 this pr improves helper function log1pexp a bit, which speeds up halfbinomialloss.loss(..) ideally, this pr is merged before #21808 and #20811. it will improve their benchmarks. </desc> <cmt> enh log1pexp </cmt> <cmt> mnt set loss class default to n_classes=none </cmt>",enh log1pexp for binomial loss in loss module
1567,"<desc> testing that the package builds work prior to actually building the packages is a waste of time and is causing issues for certain package builds. just skip our packaging ci checks on those builds instead. component name area/ci verified using travis on my fork with dummy packaging commits. sample test build that demonstrates this working: </desc> <cmt> revert ""fix travis ci builds and skip fedora 31 i386 build/test cycles (#9781)"" </cmt> <cmt> this reverts commit 07e67c4b62b100ab048070f1a0291fe904ff7513. </cmt> <cmt> this will be fixed differently. </cmt> <cmt> skip package build checks on builds that build packages. </cmt> <cmt> we don't need to check that package builds work if we're actually </cmt> <cmt> building packages. </cmt>",don't run packaging checks on travis builds that build packages.
1568,"<desc> this is to fix an issue i encountered with commit 78b9bb4 and markdown processing. the following snippet will be rendered in reveal with the greater than transformed to a '&gt;' <section data-markdown> ## a markdown slide square = (x) -> x*x end code block </section> markdown.pl will output the following html for this snippet: <h2>a markdown slide</h2> <pre><code>square = (x) -&gt; x*x </code></pre> <p>end code block</p> the showdown preview does not output an entity: <h2>a markdown slide</h2> <pre><code>square = (x) -> x*x </code></pre> <p>end code block</p></div> </desc> <cmt> support for external markdown files, including configurable (vertical) slide separator </cmt> <cmt> more/better examples in markdown demo </cmt> <cmt> slightly refactored ""slidify"" flow </cmt> <cmt> update plugin/markdown/markdown.js </cmt> <cmt> use textcontent instead of innerhtml to prevent encoding of certain characters in markdown code blocks. </cmt>",use textcontent instead of innerhtml to prevent encoding of certain entities in markdown code blocks.
1569,"<desc> porting #7744 (which fixes #6328) to master. </desc> <cmt> add test </cmt> <cmt> move type predicates back onto signatures, remove narrowing for property/get type guards. </cmt> <cmt> error on nodes which should not have type predicates. </cmt> <cmt> minor rename. </cmt> <cmt> added tests. </cmt> <cmt> actually, it makes more sense to error on the predicate annotation than anything else. </cmt> <cmt> removed trailing whitespace for linter. </cmt> <cmt> fixed up fourslash tests to only test functions. </cmt> <cmt> addressed cr feedback. </cmt> <cmt> added tests for declaration emit. </cmt> <cmt> accepted baselines. </cmt>","remove notion of predicates as types, move predicates back to signatures"
1570,"<desc> based on a suggestion by neildarlow, comment out filament_sensor define. those who want to use the feature can assure it is properly configured and un-comment the define. </desc> <cmt> sync up to marlin </cmt> <cmt> commented out filament_sensor #define </cmt> <cmt> commented out the filament_sensor define so that it is not enabled by </cmt> <cmt> default.  code does not work on all hardware variants. </cmt>",comment out the filament_sensor define by default in config.
1571,<desc> properly release memory used for the charts when accessing archived data (charts are archived) properly shutdown the sqlite database connection database close was not issued during agent shutdown store and finalize sql statements to release memory during shutdown (quick fix) keep a list of statements to finalize and do sqlite3_finalize on shutdown address coverity cid 369624:  resource leaks  (resource_leak) cid 369623:  api usage errors  (lock) component name database sqlite reported memory leaks during shutdown should vanish (or greatly reduced) e.g. run with valgrind --leak-check=full --show-leak-kinds=all </desc> <cmt> shutdown sqlite database </cmt> <cmt> quick fix: maintain and finalize statements on shutdown (allocated in thread local storage) </cmt> <cmt> release context storage for archived charts </cmt> <cmt> properly mark this as a context request </cmt>,fix memory leak when archived data is requested
1572,"<desc> this fixes two issues: looks like the repeat implementation in core started to rely on unfold being a view, which means we'll need a lowering for it. this pr partially fixes it by lowering repeat instead, since it's generally useful and used in a few places by higher level operators. the select followed by copy_ pattern broke when selecting on inner dimensions. this pattern is used by select_backward, so i'm providing a placeholder for it which converts to eager tensor in its implementation. </desc> <cmt> add support for repeat </cmt> <cmt> we could also implement unfold correctly instead (as a view), given that </cmt> <cmt> the repeat in core started to rely on it. however, repeat is a fairly </cmt> <cmt> popular operation for which it can be beneficial to have direct </cmt> <cmt> representation in the ir instead. </cmt> <cmt> test plan: </cmt> <cmt> test/cpp/build/test_ptltc --gtest_filter=atenltctstensortest.* </cmt> <cmt> add placeholder support for select_backward </cmt> <cmt> after the last merge, select followed by copy_ stopped working </cmt> <cmt> correctly. add a placeholder select_backward to re-enable the test for </cmt> <cmt> now. </cmt> <cmt> test/cpp/build/test_ptltc --gtest_filter=atenltctstensortest.* </cmt>",fix some issues after latest merge
1573,<desc> this has changes for determining when to qualify symbol name and also moved the logic of isdeclarationvisible still todos are: error reporting to use the enclosingdeclaration and meaning correctly to report the error message isdeclarationvisible is setup in checker so it could be used to verify and report errors on visibility of types </desc> <cmt> start emitting qualified path if the current symbol is not visible in enclosing declaration </cmt> <cmt> note that this doesnt handle aliases yet. </cmt> <cmt> check if there is alias symbol in the scope corresponding to the symbol whose name we are trying to get in the symbol table </cmt> <cmt> check if accessible symbol needs futher qualification </cmt> <cmt> use the isdeclarationvisible in checker to determine if the declaration needs to be emitted </cmt> <cmt> this would help in unifying logic of when to check if the type is visible </cmt>,changes to determine when to qualify the symbol in given enclosing declaration
1574,<desc> ... as pointed out by fneufneu the fallback was not working because of poissoned variable use. this fixes the fallback by tracking use_airtunes and only at the end of testing changing the use_airtunes variable. @fneufneu - can you test please? (i tried all constellations on ubuntu 10.4.2 - worked for me with this pr). </desc> <cmt> [configure/airtunes] - fixed typo </cmt> <cmt> [configure/airtunes] - fix fallback to libshairport if libshairplay can't be found. bail out if --enable-airtunes was given and none of both libs was found. </cmt>,fix the fallback to libshairport if libshairplay can't be found...
1575,"<desc> reland of #67669 the flutter tool has a number of crashes on stable where an argumenterror is thrown due to the process manager not being able to resolve an executable. so that we can adjust/modify this logic, fold it into flutter and add some additional logging. caches the resolved executable per target directory, to avoid repeated look ups. instead of throwing an argument error, attempts to run the executable as given if an exact path can't be found accept files or symlinks for the executable path. user where/which to resolve path instead of package:process logic. </desc> <cmt> [flutter_tools] fold excetuable resolution into flutter </cmt> <cmt> use correct import </cmt> <cmt> address review comments </cmt> <cmt> replace on argumenterror with on processexception(2) </cmt> <cmt> fix imports </cmt> <cmt> adjust test and follow links </cmt> <cmt> remove prints </cmt> <cmt> just use which/where </cmt> <cmt> fix canrun logic </cmt>",fold process resolution logic into the flutter tool
1576,<desc> fixes #54738 i adjusted the font-size and padding so they're a bit smaller. before after it also matches closer to the native arrows: </desc> <cmt> make arrow smaller and increase padding </cmt> <cmt> adjust padding on submenu arrow </cmt> <iss> submenu arrows too large </iss>,adjust submenu arrows on windows custom menu
1577,"<desc> make component tooltip inherit cascade correct: itemoption.tooltip -> componentoption.tooltip -> globaloption.tooltip (previous incorrect cascade: itemoption.tooltip -> globaloption.tooltip enable trigger component tooltip by chart.dispatchaction({ type: 'showtip', toolboxindex: 0, name: 'sometootboxitemname' }); // or chart.dispatchaction({ type: 'showtip', legendid: 'legend_id', name: 'somelegenditemname' }); to make (2) happen, this commit migrate ecelement['tooltip'] to ecdata['tooltipconfig']['option'], and add other info in ecdata['tooltipconfig']: interface ecdata { // ... tooltipconfig?: { // used to find component tooltip option, which is used as // the parent of tooltipconfig.option for cascading. // if not provided, do not use component as its parent. // (set manatary to make developers not to forget them). componentmaintype: componentmaintype; componentindex: number; // target item name to locate tooltip. name: string; option: componentitemtooltipoption<unknown>; }; } to locate a tooltipable component element by a payload. test/tooltip-component.html </desc> <cmt> feature: [tooltip] </cmt> <cmt> (1) make component tooltip inherit cascade correct: itemoption.tooltip -> componentoption.tooltip -> globaloption.tooltip </cmt> <cmt> (previous incorrect cascade: itemoption.tooltip -> globaloption.tooltip </cmt> <cmt> (2) enable trigger component tooltip by chart.dispatchaction({ type: 'showtip', legendindex: 0, name: 'some' }); </cmt> <cmt> to make (2) happen, this commit migrate ecelement['tooltip'] to ecdata['tooltipconfig']['option'], </cmt> <cmt> and add other info in ecdata['tooltipconfig']: </cmt> <cmt> { </cmt> <cmt> componentmaintype </cmt> <cmt> componentindex </cmt> <cmt> name </cmt> <cmt> } </cmt> <cmt> to locate a tooltipable component element by a payload. </cmt> <cmt> fix: [tooltip] add test case for the last commit. </cmt>",correct component tooltip cascade and support manually trigger component tooltip.
1578,<desc> fixes #283. also bumped gem version so that we can release a fixed version to rubygems. </desc> <cmt> fixed issue #283: crash in json handler cleanup. </cmt> <cmt> includes repro test case from @wfarr. </cmt> <cmt> bump gem version to release bugfix. </cmt> <iss> ruby: encoding messages w/ message fields as json segfaults </iss>,json handler cleanup typo causing segfault.
1579,<desc> patch moto s3 implementation add integration test issue fixed: #2481 s3 storage class header does not work for larger files </desc> <cmt> implement iam simulateprincipalpolicy </cmt> <cmt> * patch moto iam implementation </cmt> <cmt> * add integration test </cmt> <cmt> issue fixed: </cmt> <cmt> #1674 iam simulateprincipalpolicy returns xml error </cmt> <cmt>  conflicts: </cmt> <cmt> 	tests/integration/test_iam.py </cmt> <cmt> handle storage class on multipart upload </cmt> <cmt> * patch s3 moto implementation </cmt> <cmt> * add integration test </cmt> <cmt> issue fixed: </cmt> <cmt> #2481 s3 storage class header does not work for larger files </cmt>,fix s3 handle storage class multipart upload
1580,"<desc> logrotator and runlist allocated a lot of arrays during the creation of the sub-list. fix contains small optimizations. entry 1: set initial capacity in runlist.sublist entry 2: don't copy already a new instance of list in logrotator.perform changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue must exist, be a bug or improvement, and be labeled as lts-candidate to be considered (see query). </desc> <cmt> runlist.sublist: reduce allocations in internal arraylist </cmt> <cmt> logrotator.perform: remove copy of already new instance from sublist </cmt> <cmt> logrotator.perform: change list to runlist for strict new list instance in builds.sublist </cmt> <cmt> logrotator: remove unused imports </cmt>",optimize allocations in logrotator and runlist
1581,"<desc> add test and fix the monotonicity check to support unsigned bin values, see #9222. </desc> <cmt> tst: add test for unsigned bins monotonicity check, see #9222 </cmt> <cmt> bug: fixes unsigned bins monotonicity check, see #9222 </cmt>",fixes histogram monotonicity check for unsigned bin values
1582,"<desc> @joshkerr preferences - advanced settings - security added the rpc secret setting, aria2's default rpc-secret is empty, you can use the dice button to the right of the input box to generate a random password, and the generated password will be automatically copied to the clipboard. you can display the password by clicking the eye icon in the input box. </desc> <cmt> feat: add icon dice </cmt> <cmt> feat: preferences add rpc-secret setting </cmt> <cmt> feat: i18n preferences rpc-secret </cmt> <cmt> fix: npm add randomatic deps </cmt>",preferences add rpc-secret setting #138
1583,"<desc> modification of the model-m 101 membrane adapter (converter/modelm101) to work with amiga 1200 (and possibly amiga 500/600). a small pcb adapter needs to be used to make the necessary connections between the membrane and the teensy 2.0 board. this is meant for using the original amiga keyboard as a usb input device, either with a desktop pc or a r-pi/fpga board hosted inside the amiga case. info.json, and keymap files have been modified to fit amiga keyboard layout </desc> <cmt> add files via upload </cmt> <cmt> delete keyboards/converter/a1200/files directory </cmt> <cmt> update readme.md </cmt>",commodore amiga 1200 membrane converter
1584,"<desc> explanation: explicitly stating these requirements in child protocols allows the code in their extensions take advantage of optimized overloads. scope of issue: fixes unexpected behavior of standard library collections. risk: minimal. the types of functions don't change, so the code should still compile and produce the same results, only faster. reviewed by: ben cohen @airspeedswift testing: automated test suite directions for qa: n/a radar: rdar://problem/42408692 picked from #18165 test is stolen from #18066 </desc> <cmt> [stdlib] explicitly declare collection requirements on child protocols </cmt> <cmt> fixes: <rdar://problem/42408692> and sr-8022 </cmt> <cmt> (cherry picked from commit 7cbfed3f3adc42ee673b4e8bcd3115f5bc2b75d3) </cmt> <cmt> add test for sr-8022 </cmt>",add explicit requirements to bidirectional and randomaccesscollection
1585,"<desc> this pr adds context menu for first folder plugin result. pr checklist applies to #6026 cla signed. if not, go over here and sign the cla tests added/passed info on pull request the following changes have been made in this pr : context menu icons have been added for first folder result. selectionchanged event is not being called sometimes on result view if the topmost entry is same. this results in missing context menu on topmost result. this issue has been fixed by explicity setting selecteditem before result view is updated. all user facing strings in folder plugin have been localized. validation steps performed manually validated that context menu icons are shown for first folder plugin result. </desc> <cmt> added context menu to first folder result </cmt> <cmt> added context menu to first folder result </cmt> <cmt> add localization for string in folder plugin </cmt>",show context menu for first folder plugin result
1586,"<desc> fixes #17953 note that somebody (probably me) mistakenly already checked in baselines for a test named 'checkjsdoctypetag3', but the test itself was gone. so the deleted baselines have nothing to do with the new test. </desc> <cmt> parsing:allow questiontoken as start of type </cmt> <cmt> test:jsdoc nullable syntax legal in type arguments </cmt> <cmt> and update baselines </cmt>",allow question token as start of type
1587,"<desc> the following tokenizers were moved: classic, edge_ngram, letter, lowercase, ngram, path_hierarchy, pattern, thai, uax_url_email and whitespace. the only tokenizer that i didn't move in this pr is keyword. this is because normalizer infrastructure directly dependents on this tokenizer and should be tackled in a separate pr. also quite some tests use this tokenizer. i plan to do this after this pr. this pr is mainly mechanical and tests were either moved to analysis-common module or changed to use the standard tokenizer or mock whitespace tokenizer. relates to #23658 </desc> <cmt> moved tokenizers to analysis-common module </cmt> <cmt> the following tokenizers were moved: classic, edge_ngram, keyword, </cmt> <cmt> letter, lowercase, ngram, path_hierarchy, pattern, thai, uax_url_email and </cmt> <cmt> whitespace. </cmt> <cmt> relates to #23658 </cmt> <cmt> moved keyword tokenizer factory back to server, because </cmt> <cmt> normalizers directly depend on it.this should be addressed on a </cmt> <cmt> follow up change. </cmt> <cmt> fixed tests </cmt>",move tokenizers to analysis common module
1588,<desc> allow aws account id to be defined in the variables files by using it as the preferred source of the account id. move the check for a valid account id until after contingent loading of the id has been executed and clarify the error message. this pull request resolves #790 </desc> <cmt> allow aws account id to be defined in the variables files by using it as the preferred source of the account id. </cmt> <cmt> move the check for a valid account id until after contingent loading of the id has been executed. </cmt> <cmt> clarify the error message reporting that an account id could not be loaded to indicate the valid sources of an account id. </cmt>,allow variable declaration of aws account id
1589,"<desc> these are mostly grammar edits. the last example was removed because ""this example is confusing because it extrapolates outside the meaningful domain of the model."" </desc> <cmt> update to 15 march </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> apply edits from allen downey's review of the linear_regression docs. </cmt>",edits from allen downey's review of the linear_regression() docs.
1590,"<desc> commit message: marks the matching api more clearly as experimental and updates the composite filter security posture to reflect this. risk level: low, docs only testing: n/a docs changes: n/a release notes: n/a platform specific features: n/a </desc> <cmt> docs: mark matching api and associated protos as experimental </cmt> <cmt> proto_format </cmt> <cmt> update posture of composite to reflect experimental nature </cmt>",mark matching api and related features as alpha
1591,"<desc> followup to #20245.   the nightly release failed because circleci was interpreting booleans we were sending as strings.  this pr fixes that issues.  supercedes #20273 pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> ci: fix circleci handling of booleans </cmt> <cmt> explicitly specify 2.1 </cmt>",fix triggering circleci release builds
1592,<desc> this pr should fix loading files from gcsfs or any other fsspec compatible filesystem. closes #17501 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> . </cmt> <cmt> . </cmt> <iss> `ray.data.read_parquet()` does not support gcs path </iss>,fix reading parquet from gcs
1593,"<desc> i'm really unsure on the correctness of the pointer set (stb_ps*) in this state, but it does compile at least.  and stb_sdict works fine, compiled on vs2013 for 64-bit. </desc> <cmt> don't use __asm int 3; on 64-bit platforms </cmt> <cmt> don't truncate pointers to 4 bytes on 64-bit </cmt> <cmt> fix 64-bit compile for pointer set </cmt>",fix 64-bit compilation issues in stb.h
1594,"<desc> let's split this out to make src/core/ a bit smaller, and have it only cover the service manager itself. </desc> <cmt> update todo </cmt> <cmt> shutdown: fix up return type of sync_making_progress() </cmt> <cmt> we shouldn't return negative errnos as ""bool"", hence fix the type of the </cmt> <cmt> function to ""int"". </cmt> <cmt> shutdown: (void)ify more stuff </cmt> <cmt> shutdown: rearrange shutdown sources in source tree </cmt> <cmt> let's move the shutdown binary into its own subdirectory in </cmt> <cmt> src/shutdown, after all it is relatively isolated from the normal pid 1 </cmt> <cmt> sources, being a different binary and all. </cmt> <cmt> unfortunately it's not possible to move some of the code, since it is </cmt> <cmt> shared with pid 1, that i wished we could move, but i still think it's </cmt> <cmt> worth it. </cmt>",move src/core/shutdown.c and helpers to src/shutdown/
1595,"<desc> change due to the public name change and the need to add an api here, i'm doing both at the same time.  the change is to add a download function, which just directly invoked the downloader and returns the hash.  additionally, we now publish the symbols for the util binary. also fixes a bug with the deployment-on-exit list, which affects the util dll. testing manually validated functionality from a c# test exe. </desc> <cmt> rename util dll and add download api </cmt> <cmt> update pipeline for name change and publish symbols </cmt>",rename utility binary and add download function
1596,"<desc> revisions with @seberg of some additional sections. </desc> <cmt> doc: revise nep 42 ""common dtype"" section </cmt> <cmt> doc: eliminate duplicate doc in nep42 </cmt> <cmt> doc: fix missing 'not' in nep42 edit </cmt> <cmt> doc: minor typos in nep42 edit </cmt> <cmt> doc: reword opening sentence of nep 42 revision </cmt> <cmt> also clarify a wording. </cmt> <cmt> doc: correct :class: reference in nep42 edit </cmt> <cmt> doc: fix windows line-enders on nep42 edit </cmt> <cmt> doc: new round of common dtype edits of nep 42 </cmt> <cmt> doc: uniquify anchors in nep 42 </cmt> <cmt> doc: typo in nep42 edit </cmt> <cmt> doc: last push for nep 42 edit </cmt>",new round of nep 42 edits
1597,<desc> backport of the following prs: #71610 #71569 #71446 #71413 #69991 #69508 #69526 #69522 ansible-test </desc> <cmt> add encoding.py from devel to support backports. </cmt> <cmt> add io.py from devel to support backports. </cmt> <cmt> update ansible-test support for ci providers. (#69522) </cmt> <cmt> refactored ci provider code to simplify multiple provider support and addition of new providers. </cmt> <cmt> (cherry picked from commit d8e0aadc0d630c776349b745243c20b62f22ebec) </cmt> <cmt> add shippable request signing to ansible-test. (#69526) </cmt> <cmt> (cherry picked from commit e7c2eb519be2612832de15aa85c5d7618e979f85) </cmt> <cmt> ansible-test local change detection: use --base-branch if specified (#69508) </cmt> <cmt> (cherry picked from commit 43acd61901e26fdb2faf89baa3e9b2c7647fc89e) </cmt> <cmt> add azure pipelines support to ansible-test. </cmt> <cmt> (cherry picked from commit 8ffaed00f87f1ae41f86cb4a7fe399d8aa339286) </cmt> <cmt> update ansible-test remote endpoint handling. (#71413) </cmt> <cmt> * request ansible-core-ci resources by provider. </cmt> <cmt> * remove obsolete us-east-2 ci endpoint. </cmt> <cmt> * add new --remote-endpoint option. </cmt> <cmt> * add warning for --remote-aws-region option. </cmt> <cmt> * update service endpoints. </cmt> <cmt> * allow non-standard remote stages. </cmt> <cmt> * add changelog fragment. </cmt> <cmt> (cherry picked from commit d099591964d6fedc174eb1d3fc1bbee8d2ba0f16) </cmt> <cmt> fix ansible-test coverage traceback. (#71446) </cmt> <cmt> * add integration test for ansible-test coverage. </cmt> <cmt> * fix ansible-test coverage traceback. </cmt> <cmt> * fix coverage reporting on python 2.6. </cmt> <cmt> (cherry picked from commit f5b6df14ab2e691f5f059fff0fcf59449132549f) </cmt> <cmt> use new endpoint for parallels based instances. </cmt> <cmt> (cherry picked from commit 98febab9751ed73b70c3004fe9dafb4dc09abf26) </cmt> <cmt> add pause to avoid same mtime in test. </cmt> <cmt> (cherry picked from commit 3d769f3a76a867ea61df16eee328bd40fc91a950) </cmt>,backport ansible-test ci provider support.
1598,"<desc> fixes #13232 it silences the runtime warning in partial_fit when a target class was not observed, which results in log of 0s. this should not affect the predictions as demonstrated in the implemented unit test. it does have an unpleasant effect of producing -inf in class_log_prior_ attribute when the class was not yet observed. this value is then updated after adding a training case with such a class. ping: @gaelvaroquaux </desc> <cmt> add test outline </cmt> <cmt> added test for issue #13232 </cmt> <cmt> silence log of 0 warning </cmt> <cmt> add tests for unobserved classes </cmt> <cmt> fixed linting issues </cmt> <cmt> add comment </cmt> <iss> partial_fit does not account for unobserved target values when fitting priors to data </iss>",fix warning in multinomialnb.partial_fit when target class was not yet observed
1599,<desc> this is a carry of #9184 closes #9184 fixes #8270 </desc> <cmt> add warnning log when other graphdrvier(storage driver) used before </cmt> <cmt> added warnning log when other graphdrvier(storage driver) used before for feature request #8270 </cmt> <cmt> remove error return from check graph driver func </cmt> <iss> feature request: show warning when the storage driver changes after a restart </iss>,add warning log when high priority graphdriver used before
1600,"<desc> we want to make sure libobjc doesn't crash when clang references a weak-exported class stub from a swift dylib. </desc> <cmt> un-xfail validation-test/runtime/class_stubs.m and adjust for clang changes </cmt> <cmt> the objc_loadclassref() symbol is weak linked from clang now, so we can </cmt> <cmt> un-xfail this test. note that we have to pass a special flag to clang </cmt> <cmt> since objc_loadclassref() is not in the sdk's tbd files yet. </cmt> <cmt> also, change the test to use its own asserts instead of filecheck since </cmt> <cmt> there's no output unless a new libobjc is available. </cmt> <cmt> printasobjc: add support for @_weaklinked attribute </cmt> <cmt> clang already takes availability into account when checking if a </cmt> <cmt> declaration is weak imported, so this is only needed for testing. </cmt>",add tests for weak-linked class stubs
1601,"<desc> adds an optional argument to the zero shot pipeline constructor to specify the label id of the nli model that corresponds to ""entailment"", which it needs to calculate each candidate label's score. most models in the hub use the last last label id, but some differ (e.g. the recent ynie/roberta-large-snli_mnli_fever_anli_r1_r2_r3-nli). if the argument is not passed, the pipeline will attempt to look up the entailment dimension in the model config's id2label mapping. if the config does not specify the entailment dimension, the value will be set to -1, indicating the last dimension of the model output. with this logic in place, the arg only needs to be passed when both (1) the model's entailment label id is not the last id and (2) when the model config's label2id doesn't specify the entailment id. </desc> <cmt> add entailment dim argument </cmt> <cmt> rename dim -> id </cmt>",infer entailment label id on zero shot pipeline
1602,"<desc> we should not call out into js to do a check, as that is silly and slow. the users were the async code - rewrote those to do the checks in asm/wasm. </desc> <cmt> don't import js assert() into asm.js/wasm; for the emterpreter, use an internal emterpassert, to avoid calls into js and back </cmt> <cmt> asyncify fix </cmt> <cmt> test updates </cmt> <cmt> test fix </cmt> <cmt> updates </cmt>",remove assert from being imported into asm.js/wasm
1603,"<desc> fixes linting ci job on azure. currently it always returns a green status because the env fails to activate and the error is silenly ignored. the error on master is, commandnotfounderror: your shell has not been properly configured to use 'conda activate'. to initialize your shell, run $ conda init <shell_name> currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell see 'conda init --help' for more information and options. important: you may need to close and restart your shell after running 'conda init'. originally fix added in #17053 see discussion there for more details. </desc> <cmt> fix linting on azure </cmt> <cmt> fix mypy errors </cmt>",mnt properly activate the env in the linting ci
1604,"<desc> translate ""select & where clause"" page into chinese the page url is  the markdown file is located in docs/content.zh/docs/dev/table/sql/select.md translate 'flink/docs/content.zh/docs/dev/table/sql/select.md'. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving):  no the serializers:  no the runtime per-record code paths (performance sensitive):  no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn, zookeeper:  no the s3 file system connector:  no does this pull request introduce a new feature?  no if yes, how is the feature documented? not documented </desc> <cmt> local </cmt> <cmt> update </cmt> <cmt> [flink-23243]translate ""select & where clause"" page into chinese </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt>","[flink-23243][docs-zh]translate ""select & where clause"" page into chinese"
1605,"<desc> fixes #19080 added separate command (dags show-dependencies) to print/save the dependencies in cli. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> [19080] add serializeddag to cli_parser </cmt> <cmt> [16185] added localkubernetesexecutor to breeze supported executors </cmt> <cmt> revert ""[16185] added localkubernetesexecutor to breeze supported executors"" </cmt> <cmt> this reverts commit a1c532eacfeddcbefaa3e565a0522e25315286c4. </cmt> <cmt> added cli dag command to show dag dependencies </cmt> <cmt> added test for dag dependencies cli command </cmt> <cmt> removed unused dependency </cmt> <cmt> added tests to cover show_dag_dependencies and dot_renderer </cmt> <iss> display dags dependencies  in cli </iss>",add show dag dependencies feature to cli
1606,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. note: the version number is set to 1.1. this is not strictly correct, the latest version of merge-stream is 1.0.1. however these types have already erroneously been released as 1.1.0, so to avoid confusion i have left the version number as it is. </desc> <cmt> apply standard lint rules to merge-stream. </cmt> <cmt> * format version number as major.minor, patch is not allowed. </cmt> <cmt> * delete consecutive blank lines. </cmt> <cmt> * cut down author list into multiple lines. </cmt> <cmt> * replace author's website with their github page. </cmt> <cmt> * remove i prefix from mergedstream interface. </cmt> <cmt> * use array<...> for complex array type. </cmt> <cmt> * delete blank line at start of file. </cmt> <cmt> * replace all uses of 'var' with 'let' or 'const'. </cmt> <cmt> * combine overloads into one signature. </cmt> <cmt> apply strict null checks to merge-stream. </cmt> <cmt> use readonlyarray in preference to array where appropriate. </cmt> <cmt> merge() and add() do not modify the arrays passed to them, </cmt> <cmt> so they can be typed as readonlyarray. </cmt> <cmt> add self to authors list. </cmt>","apply standard lint rules, fix common mistakes"
1607,"<desc> fixes #6769 when vswhere is missing (or we fail to find msbuild tools), we fail to print an error message before exiting microsoft reviewers: open in codeflow </desc> <cmt> print error message when missing vswhere/msbuild </cmt> <cmt> change files </cmt> <iss> application doesn't run or open anything when npx react-native run-windows </iss>",print error message when vswhere/msbuild tools are missing
1608,"<desc> closes #25165 closes #24263 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry a slice return caused issues everywhere, when this function was used. so i unpacked it right in there. </desc> <cmt> bug in loc raised error when non integer interval was given for multiindex </cmt> <cmt> adjust tests </cmt> <iss> bug: multiindex.get_loc errors if get_loc on level returns a slice </iss> <iss> partial date string indexing doesn't work on multiindex </iss>",bug in loc raised error when non-integer slice was given for multiindex
1609,<desc> added support for building on centos 7. added instructions for building centos 7 to readme.md added instructions for manual install of dependencies for centos in readme.md removed instructions to build binaryen in manual install of dependencies section of  readme.md. minor changes to all build scripts to dynamically display minimum storage requirements in case of validation error on build. </desc> <cmt> added support for building on centos 7. added file scripts/eosio_build_centos.sh. </cmt> <cmt> added build script for centos linux </cmt> <cmt> merging master including externals/binaryen </cmt> <cmt> merging master into centos branch to avoid conflicts </cmt> <cmt> minor formatting changes in eosio_build.sh for readability </cmt> <cmt> merging master branch into centos branch </cmt> <cmt> added centos install instructions to readme.md </cmt> <cmt> minor formatting changes to build scripts for readability </cmt> <cmt> removed references to install binaryen in manual install of dependencies in readme.md </cmt> <cmt> merging master before push and pr </cmt>,addition of centos & updated readme
1610,"<desc> fixes #34933. this introduces a new global option, $enable-container-classes, to separately toggle the inclusion of .container-* classes in our compiled css. our containers are still useful when opting into the new css grid layout, so we don't want to exclude those when flipping over. </desc> <cmt> separate container classes from enable-grid-classes optoin </cmt> <cmt> document the new option </cmt> <cmt> mention in migration guide </cmt> <iss> switching to css grid should keep container classes </iss>",separate container classes from $enable-grid-classes option
1611,"<desc> towards  #15601 this pr adds a possibility of defining sample_weight for the standardscaler (only for the dense x). right now  #3020 and #17743 are on hold because if we would like to substitute the use of normalize in linear models we need to assure that the suggested way of substitution will work in all cases (ie suggested way is using a pipeline with a standardscaler). however, as pointed out in #18159 this would not work in the case if the linear model is using sample_weight. by adding possibility to add sample_weight to standardscaler we are making the above substitution valid again. </desc> <cmt> initial test sample_weights </cmt> <cmt> added self.mean_ with sample weights </cmt> <cmt> added the incremental variance for sample_weight </cmt> <cmt> init test </cmt> <cmt> test on standardscaler with sparse input and sample_wegiths </cmt> <cmt> flake8 </cmt> <cmt> clean up; </cmt>",mrg sample weight for standardscaler
1612,"<desc> towards #15601 it adds a possibility to calculate the mean and variance for the sparse x with sample_weight </desc> <cmt> init </cmt> <cmt> sklearn/utils/tests/test_sparsefuncs.py </cmt> <cmt> checkopoint </cmt> <cmt> first working pass, no nans </cmt> <cmt> test corrected </cmt> <cmt> updated test to check for incremental </cmt> <cmt> make incremental work </cmt> <cmt> dirty works of sparse </cmt> <cmt> cleaning up </cmt> <cmt> clean up </cmt> <cmt> remove faulty test </cmt>",incremental mean and var for weighted sparse x
1613,"<desc> this is the fix for #140. change eyeem/creativemarket/eve online detection method to use the newly refurbished ""response_url"" detection method. </desc> <cmt> problems with false positives on eyeem/creativemarket/eve online.  add these sites to the tests to capture failure. </cmt> <cmt> change eyeem/creativemarket/eve online detection method to use the newly refurbished ""response_url"" detection method. </cmt>",fix eyeem/creativemarket/eve online false positives
1614,"<desc> jira:  notes & observations: spring-boot: springbootplainapp does nothing on its main function: public static void main(string[] args) { } based on its name, i'm thinking this might be intentional, but i wanted to point it out just in case. there are 2 resource files missing (international.html and utils.html), which were moved in this pr to another module. they affect this article, and the utilsapplication app (i didn't check which article is related to it). spring-boot-autoconfiguration springcontextintegrationtest and autoconfigurationintegrationtest are named as integration tests, but they require a mysql server running locally to pass. we might want to rename them spring-boot-bootstrap springbootbootstrapintegrationtest is a live test actually, it requires the app to be running to tests the its endpoints spring-boot-disable-console-logging disabling-console-log4j2 and disabling-console-jul submodules can't inherit our root parent-modules pom, it has direct logback dependencies that can't be in those apps' classpath. i updated their spring-boot version, but we might want to analyze a workaround (maybe exclude the logging dependencies from the parent-module) spring-boot-mvc we might want to consider removing vehiclefactoryapplication, its commented out: // @springbootapplication public class vehiclefactoryapplication { //    public static void main(string[] args) { //        springapplication.run(vehiclefactoryapplication.class, args); //    } } spring-boot-vue springbootmvcapplicationunittest is actually an integration test, marked with @springboottest annotation, it impacts obviously on the regular build time. spring-data-rest applications are bootstrapping correctly, but there is an issue on integration tests related to the context load (not related to this change, the module was already using spring-boot version 2.1.0) tests run: 9, failures: 0, errors: 9, skipped: 0, time elapsed: 5.394 s <<< failure! - in com.baeldung.validator.springdatarestvalidatorintegrationtest whenstartingapplication_thencorrectstatuscode  time elapsed: 0.001 s  <<< error! java.lang.illegalstateexception: failed to load applicationcontext caused by: org.springframework.beans.factory.beandefinitionstoreexception: failed to parse configuration class [com.baeldung.springdatarestapplication]; nested exception is java.io.filenotfoundexception: could not open servletcontext resource [/persistence-h2.properties] caused by: java.io.filenotfoundexception: could not open servletcontext resource [/persistence-h2.properties] </desc> <cmt> migrated modules to use parent-boot with version spring-boot 2.1 </cmt> <cmt> * migrated the following modules: </cmt> <cmt> spring-boot </cmt> <cmt> spring-boot-autoconfiguration </cmt> <cmt> spring-boot-bootstrap </cmt> <cmt> spring-boot-client </cmt> <cmt> spring-boot-ctx-fluent </cmt> <cmt> spring-boot-disable-console-logging </cmt> <cmt> spring-boot-jasypt </cmt> <cmt> spring-boot-mvc </cmt> <cmt> spring-boot-ops </cmt> <cmt> spring-boot-vue </cmt> <cmt> spring-cloud/spring-cloud-vault </cmt> <cmt> spring-data-rest </cmt> <cmt> migrated the following modules to parent-boot with spring-boot 2.1: </cmt> <cmt> spring-cloud-data-flow/etl/customer-mongodb-sink </cmt> <cmt> spring-cloud-data-flow/etl/customer-transform </cmt>",| upgrade set of modules to use boot 2.1 - part 2
1615,"<desc> bael-812: list of rules engines for java removed evaluation article files (on spring-core/src/main/java/com/baeldung/autowired) move examples folders (easy-rules, rulebook and openl-tablets) from /tutorials to /tutorials/rule-engines </desc> <cmt> spring beans di examples </cmt> <cmt> fix-1: shortening examples </cmt> <cmt> list of rules engines in java </cmt> <cmt> bael-812: openl-tablets example added </cmt> <cmt> bael-812: artifacts names changed </cmt> <cmt> bael-812: moving rule-engines examples to rule-engines folder </cmt> <cmt> bael-812: removing evaluation article files </cmt>",moving examples to rule-engines folder
1616,<desc> #53172 r? @nikomatsakis </desc> <cmt> librustc_metadata: enable feature(nll) for bootstrap </cmt> <cmt> librustc_lint: enable feature(nll) for bootstrap </cmt> <cmt> librustc_borrowck: enable feature(nll) for bootstrap </cmt> <cmt> libgraphviz: enable feature(nll) for bootstrap </cmt> <cmt> liballoc_system: enable feature(nll) for bootstrap </cmt> <cmt> liballoc_jemalloc: enable feature(nll) for bootstrap </cmt> <cmt> liballoc: enable feature(nll) for bootstrap </cmt>,enable feature(nll) on various crates for bootstrap
1617,"<desc> if no keys were provided, the random.choice that is used to choose the host to do the final cardinality check would error. if there are no keys provided, we know that the cardinality is 0, so it's safe to just return that. @getsentry/infrastructure @mattrobenolt </desc> <cmt> add failing test for empty key sequence. </cmt> <cmt> add guard for empty key sequence. </cmt>",guard against empty key sequence provided to redistsdb.get_distinct_counts_union.
1618,<desc> wikimedia - capitalization languages which do not capitalize day names portuguese / portuguese_brazil capitalization of month names portuguese / portuguese_brazil also microsoft released a patch for their software </desc> <cmt> updated portuguese language to be all lowercase for months and days </cmt> <cmt> updated brazilian portuguese and portuguese tests </cmt>,updated  portuguese and portuguese_brazil to use lower-case month and day names
1619,<desc> thought these packages deserved some attention aswell :d </desc> <cmt> golf hooks </cmt> <cmt> return native event during setting -2b </cmt> <cmt> one step to childarray -2b </cmt> <cmt> cleaner representation </cmt> <cmt> hooks foreach --> some -7b </cmt> <cmt> convert nullish checks to ! in compat -8b </cmt> <cmt> convert nullish checks to ! in /hooks -2b </cmt> <cmt> inline schedule flush after paint -4b </cmt> <cmt> undo inline </cmt>,- golf hooks (-11b) and compat (-18b)
1620,<desc> support running renderers in multiple ext host and loading renderers when reloading from backup. </desc> <cmt> support renderer and content provider registered in different extension host. </cmt> <cmt> switch mimetype now should be done async. </cmt> <cmt> transform outputs for backup </cmt> <cmt> combine events from edits from ext host. </cmt>,load custom renderers when reloading from backup.
1621,"<desc> three changes: vertical and horizontal scroll bars in scene2d ui can be set to left/right, or top/bottom respectively. implemented a test for scroll bars (scrollpanescrollbarstest in above pic) formatted and alphabetized the list of tests in utils.gdxtests (better readability, easier to add new tests) if anyone has a project/game with scrollpane it would be nice if you could test changing the scroll bar locations with these two methods: setvscrollbaratright(false); sethscrollbaratbottom(false); </desc> <cmt> scene2dui scroll bars can now flip left/right and top/bottom, added scrollpanescrollbarstest to tests </cmt> <cmt> format and alphabetize lists of test classes in test.utils.gdxtests </cmt> <cmt> alphabetize for real now </cmt> <cmt> remove scaffolding, fix fade </cmt>","scene2dui scroll bars can change sides, implement scrollbar test, format tests list"
1622,<desc> new keyboard ext65 and fix up aegis config.h. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> aegis config update and ext65 added </cmt> <cmt> update readme's </cmt> <cmt> pid ext65 change </cmt>,aeboards ext65 - new keyboard & aegis update
1623,"<desc> i've closed my other pr (#9675) in favor of this one, because i really messed up with almost everything. this time i forked the latest develop branch and requested to merge the pr back into develop. i'm sorry for any inconvenience, but i'm pretty new to git group projects :) summary old pr for users it's pretty unhandy to fill out the ""idle time limit"" in milliseconds. as discussed with @geekgonecrazy and @jszaszvari it would be more practical to set this value in seconds. @sampaiodiego targets version 0.63.0 for this fix. </desc> <cmt> changed idle time limit from milliseconds to seconds to make it more handy to use. </cmt> <cmt> database migration to convert idle time limit from milliseconds to seconds. </cmt>","""idle time limit"" using milliseconds instead of seconds"
1624,"<desc> this is a possible fix to #19582 (comment), mostly solved by @as-cii. @as-cii i tweaked the implementation to use the syntax tree instead of the buffer range to detect whether an iterator is at the start of end of its injection. my concern about using the range is that the layers' ranges can change over time as the document is edited, so if we store a range property, it can become stale. i think that we can achieve a similar result by checking if we're parked at the start or end of the root node of the syntax tree. i think there are still there are theoretically cases where we might erroneously cover scope boundaries with this logic, and we should probably be even more restrictive about when we cover scope boundaries, but i can't think of a concrete case where they would occur, so i think this idea is a good way to fix the problem we're currently seeing. </desc> <cmt> report scopes from shallower layers at the start or end of an injection </cmt> <cmt> detect the end of an injected tree based on the iterator's state </cmt>",avoid covering up scopes at boundaries of injection layers
1625,"<desc> easel's docs list the ""next"" parameter as a string but the text of their docs states it can also be a boolean. relevant documentation: ""specifies the name of the animation to continue to after this animation ends. you can also pass false to have the animation stop when it ends. by default it will loop to the start of the same animation."" </desc> <cmt> updated the type of the ""next"" parameter in spritesheetbuilder's addanimation method. from the easeljs docs: ""specifies the name of the animation to continue to after this animation ends. you can also pass false to have the animation stop when it ends. by default it will loop to the start of the same animation."" </cmt> <cmt> removed whitespace changes </cmt>","fix parameter typing for the spritesheetbuilder's ""addanimation"" method in createjs"
1626,"<desc> solution for #1012 seems like with just a bit of refactoring to the polar chart's controller, this same thing could be applied to that chart as well. i did not add any new tests for this, i think i will need some guidance on how best to test this. </desc> <cmt> issue #2252, added usepointstyle option to allow label boxes to match the shape(pointstyle) of the corresponding data. </cmt> <cmt> merge remote-tracking branch 'chartjs-origin/master' </cmt> <cmt> conflicts: </cmt> <cmt> src/core/core.legend.js </cmt> <cmt> removed unused varaible from legend's draw() </cmt> <cmt> merge remote-tracking branch 'chartjs-origin/master' </cmt> <cmt> add an option for radar chart to have offsetangle. issue #1012 </cmt> <cmt> merge remote-tracking branch 'chartjs-origin/master' </cmt>",issue #1012. added offsetangle option for radar charts.
1627,"<desc> the previous change was not passing a bitcode flag, woops! reland of #52091 </desc> <cmt> [flutter_tools] refactor gensnapshot and aotbuilder </cmt> <cmt> update build.dart </cmt> <cmt> fix default values of extragensnapshot and extrafrontend </cmt> <cmt> add fuchsia specific exit message </cmt> <cmt> fix nullability of extragensnapshotoptions </cmt> <cmt> fix bitcode </cmt>","refactor aotbuilder, removing globals and duplicated kernel compilation"
1628,"<desc> similar to #4903, this pr proposes changes to ensure that parameter aliases in lgb.train() and lgb.cv() are handled correctly in the r package. currently, internal helper functions access params$objective and params$metric directly, without considering aliases. lightgbm/r-package/r/utils.r line 168 in ce486e5 if (is.character(params$objective)) { lightgbm/r-package/r/utils.r line 194 in ce486e5 if (is.null(params$metric)) { as a result, it's not possible today to use any of the aliases for objective with lgb.train() and lgb.cv(). library(lightgbm) data(""agaricus.train"", package = ""lightgbm"") train <- agaricus.train dtrain <- lgb.dataset( data = train$data , label = train$label ) bst <- lgb.train( data = dtrain , params = list( num_leaves = 5l , application = ""binary"" , num_iterations = 5l ) ) error in lgb.check.obj(params = params, obj = obj) : lgb.check.obj: objective should be a character or a function this pr proposes the following changes to address that: populate params$objective and params$metric using internal helper function lgb.check.wrapper_param(), which handles reconciling parameters passed by main parameter name and aliases move code for handling the possibility of custom objective and metrics (which are r function objects, not strings) down so it happens after aliases have been handled in params </desc> <cmt> [r-package] respect aliases for objective and metric </cmt> <cmt> move eval code closer to eval processing </cmt> <cmt> remove unnecessary diff </cmt>",respect aliases for objective and metric and lgb.train() and lgb.cv()
1629,<desc> it looks like i'm not the only one who didn't look very closely when i added new vfs protocols. all of the following vfs protocols are currently only available if there's at least one active network interface even though they have nothing to do with networking (unless i misunderstood something): pipe:// bluray:// resource:// events:// these commits adjust the directory and file factories to also handle these vfs protocols if no network interface is available. this will require a partial backport to isengard (without the events:// related commit). </desc> <cmt> filesystem: make pipe:// available even if there's no network interface available </cmt> <cmt> filesystem: make bluray:// available even if there's no network interface available </cmt> <cmt> filesystem: make resource:// available even if there's no network interface available </cmt> <cmt> filesystem: make events:// available even if there's no network interface available </cmt>,"make pipe://, bluray://, resource:// and events:// available even if there's no network interface available"
1630,<desc> addresses #20308 this pr ensures gradientboostingclassifier is compatible with numpydoc. remove gradientboostingclassifier from docstring_ignore_list. verify that all tests are passing. #dataumbrella sprint </desc> <cmt> remove gradientboostingclassifier from docstring_ignore_list. </cmt> <cmt> fix numpydocs from gradientboostingclassifier. </cmt>,doc ensures that gradientboostingclassifier passes numpydoc validation
1631,"<desc> introduce a new --suppress switch enable suppressing index checks with noimplictany using --suppress implictanyindex (#1232, and #835) </desc> <cmt> add new compiler flag to suppress noimplicitany errors for object access </cmt> <cmt> commandline definitions use a property ""paramtype"" to specify the name of thier type e.g. file, version, etc.., that was changed in the defintion to paramname, without changing the use site, changing it back to paramtype. </cmt>",suppress no implicit any errors
1632,"<desc> this is in relation to and fixes issue #24374.  tf.einsum is not.  einsum is not properly calculating trace.  this fix functions by properly identifying a trace call and utilizing math_ops.trace.  previously it would receive an error subscript not supported: an axis appears more than once: i or something similar.  before that error, people with older versions were receiving the wrongly calculated value. </desc> <cmt> fixed trace for tf.einsum in python in base case </cmt> <cmt> added in unit tests for trace in einsum </cmt> <cmt> removed logging from einsum </cmt>",24374 fix tf.einsum so it computes the trace correctly
1633,"<desc> adds the ability to resize panes with the keyboard. closes #991 i work here tests added/passed - this box makes me cry i actually kinda just went for this one. this is accomplished by making the column/rowdefinitions for a pane use gridlengthhelper::frompixels to set their size. we store a pair of floats that represents the relative amount that each pane takes out of the parent pane. when the window is resized, we use that percentage to figure out the new size of each child in pixels, and manually size each column. then, when the user presses the keybindings for resizepane{left/right/up/down}, we'll adjust those percentages, and resize the rows/cols as appropriate. currently, each pane adjusts the width/height by 5% of the total size at a time. i am not in love with this, but it works for now. i think when we get support for keybindings with arbitrary arg blobs, then we could do either a percent movement, or a number of characters at a time. the number of characters one would be trickier, because we'd have to get the focused control, and get the number of pixels per character, as adjacent panes might not have the same font sizes. opened a bunch of panes and tried moving them with the keybindings </desc> <cmt> add the keybinding for panes back </cmt> <cmt> start working on resizable panes. this sorta works as you increase the size, but doesn't resize down. i also had to remove the seperator. i think i need to have the resize event start from the top, then recurse down </cmt> <cmt> panes can now be a variable percent of their parent </cmt> <cmt> * works for both vertical and horizontal splits </cmt> <cmt> * seperator is visible too </cmt> <cmt> * resizing the window works right </cmt> <cmt> add keybindings and code for handling resizing panes </cmt> <cmt> if you add keybindings for resizing, like so: </cmt> <cmt> json </cmt> <cmt> { </cmt> <cmt> ""command"" : ""resizepanedown"", </cmt> <cmt> ""keys"" : </cmt> <cmt> [ </cmt> <cmt> ""alt+shift+down"" </cmt> <cmt> ] </cmt> <cmt> }, </cmt> <cmt> { </cmt> <cmt> ""command"" : ""resizepaneleft"", </cmt> <cmt> ""keys"" : </cmt> <cmt> [ </cmt> <cmt> ""alt+shift+left"" </cmt> <cmt> ] </cmt> <cmt> }, </cmt> <cmt> { </cmt> <cmt> ""command"" : ""resizepaneright"", </cmt> <cmt> ""keys"" : </cmt> <cmt> [ </cmt> <cmt> ""alt+shift+right"" </cmt> <cmt> ] </cmt> <cmt> }, </cmt> <cmt> { </cmt> <cmt> ""command"" : ""resizepaneup"", </cmt> <cmt> ""keys"" : </cmt> <cmt> [ </cmt> <cmt> ""alt+shift+up"" </cmt> <cmt> ] </cmt> <cmt> }, </cmt> <cmt>  </cmt> <cmt> then you can now resize the panes, 5% at a time. </cmt> <cmt> we correctly traverse the tree to find the separator that's closest to the </cmt> <cmt> focused pane (depth-wise), but also the correct direction. </cmt> <cmt> excessive doc commenting </cmt> <iss> panes should be resizable with the keyboard. </iss>",enable resizing the panes with the keyboard.
1634,"<desc> done with reference to #1623. controls the length of url displayed using the -d or flow_detail option. the full length url is displayed if flow_detail > 0, else it is shortened. also uses the terminal width obtained from click.get_terminal_size() to determine the cutoff length. </desc> <cmt> update dumper.py to respect the -d option </cmt> <cmt> if the detail level is less than 1, the url length is shortened to a limit of 200 </cmt> <cmt> update dumper.py </cmt> <cmt> update dumper.py </cmt>",controls the length of url displayed using the -d option
1635,"<desc> this pr swaps the class and type attributes in stock alarm configurations, to bring them in sync with the up-to-date xls in  it also updates the relevant entries in reference.md. any help/comments on the docs are welcome! component name health check that the agent correctly reads the stock configuration files. observe in various endopoints (api/v1/alarms, api/v1/alarm_log, etc) that they are populated. promised to @ilyam8 to note to change also:  there are couple of discrepancies between the xls and the conf files, e.g. mysql_galera_cluster_state in xls has an empty class entry, but we have a value in the file. not sure if we should remove from files, or add in xls. </desc> <cmt> swap type and class </cmt> <cmt> edit reference.md </cmt>",swap class and type attributes in stock alarm configurations
1636,"<desc> adds an option to profile the run and exec commands. it produces a performance profile which can be analyzed using devtools in a chromium-based browser. profiles the run and exec commands and produces a performance profile which can be analyzed using devtools in a chromium-based browser (direct url: devtools://devtools/bundled/devtools_app.html). the profile shows a timeline of the operations where each operation is assigned to an open slot. the number of slots is determined by the --concurrency option and the number of open slots is determined by --concurrency minus the number of ongoing operations. the end result is a visualization of the parallel execution of your scripts. the default location of the performance profiles is at the root of your project. we have over 200 packages in our repository and we see build time regressions from time to time. visualizing lerna run build helps us uncover obvious mistakes or opportunities for improvement. for instance, in the example above, the final green box in thread 0 depends on the green box immediately preceding it on thread 1 (expanding the threads in the devtool reveals the name of each package). by splitting the green package on thread 1, we can allow the final package on thread 0 to start much sooner, giving us a performance improvement of ~5 mins on all builds. i have tested this locally with all the argument permutations. if we should have some more formal testing of this feature, i would greatly appreciate some guidance on what that could look like. i have read the contributing document. </desc> <cmt> update p-queue </cmt> <cmt> add profiler class to run-topologically </cmt> <cmt> add --profile option to run </cmt> <cmt> add --profile option to exec </cmt> <cmt> use upath to deal with platform specific sep </cmt> <cmt> lint </cmt>",add --profile option to lerna exec and lerna run
1637,"<desc> once a session had verified certs for a host once, it continued to do so even when verify was set to false. (a timeout error was actually thrown the second time, due to the way the errors were handled) this fixes the issue. </desc> <cmt> make sure verify=false is respected for session even when there has already been a verified request to the same host. </cmt> <cmt> update tests to expose the (fixed) problem. </cmt> <cmt> add myself to authors </cmt>",stop always verifying certs for same host that has verified once.
1638,"<desc> this allows a library to ""fix"" an initializer or method that should have been failable or non-failable by gating the change on the user's version of swift. initializer failability and whether or not a method or initializer throws are two things that doesn't change the ""overload signature"", so normally the compiler would call this an invalid redeclaration. but since only one version can be active at a time based on the client context, there won't be a problem in practice. sr-4171 / rdar://problem/30470854 </desc> <cmt> fix accidental use of a pointer as a boolean. </cmt> <cmt> this argument treated the pointer value as an ""allow invalid"" flag, </cmt> <cmt> meaning the search could turn up a 'dynamic' attribute that was </cmt> <cmt> already marked invalid. in practice this will probably affect absolutely </cmt> <cmt> no one, but the old code was still wrong. </cmt> <cmt> default declattributes::getattributes to skipping invalid attributes. </cmt> <cmt> this matches the singular 'getattribute', and all three current users </cmt> <cmt> of this api were passing 'false' here anyway. no functionality change. </cmt>","allow ""redeclaring"" an initializer or method with non-overlapping availability."
1639,"<desc> change the previous implementation (using a semaphore) was not resilient to unexpected process termination, as windows does not track semaphore ownership.  this could lead to a deadlock in a waiting process, and at least one user even experienced an ongoing deadlock despite having killed all of the active processes (which should have destroyed and thus reset the named semaphore). this version uses a set of named mutexes instead, which windows will release for us in the event of abandonment.  as part of the change i have also added the ability to pass in an iprogresscallback to allow for cancellation of the wait. on top of that change, i realized the the source management functions were not properly indicating that they were cancelled.  while a ctrl+c in the middle of a source add would in fact cancel the action internally, it would still add the source information into the settings stream.  i have updated the stack to handle cancellation now, including the output from top level now saying cancelled rather than done to indicate that ctrl+c actually did stop the action. validation all existing tests pass with these changes; a new test is added for iprogresscallback cancellation. microsoft reviewers: open in codeflow </desc> <cmt> checkpoint before splitting the work </cmt> <cmt> fix crossprocessreaderwritelock to use a set of mutexes rather than a semaphore </cmt> <cmt> remove todo </cmt>",make crossprocessreaderwritelock resilient to process termination
1640,"<desc> this pr allows for the use of a readonly attribute which disables the input for text editor elements: <atom-text-editor readonly /> the read-only state is stored on the texteditor model. as of now this state merely prevents text from being input into the editor. future considerations include using the state to determine modified status, preventing saving, etc. / </desc> <cmt> add 'readonly' attribute to <atom-text-editor> element </cmt> <cmt> store readonly state on the texteditor model </cmt>",add readonly attribute to text editor element
1641,"<desc> copying a csp instance fails if the instance contains boolean directives; specifically, this affects the block_all_mixed_content, upgrade_insecure_requests and sandbox directives. </desc> <cmt> failing test for csp copy, with boolean directives </cmt> <cmt> pass failing test for csp copy, with boolean directives </cmt>",fix csp copy boolean directives
1642,"<desc> refactor current tests should pass if relevant, link to documentation update: n/a summary upgrade harmonyimportdependency and harmonyacceptimportdependency to es6 no other information amend usage of harmonyacceptimportdependency in harmonyacceptdependency </desc> <cmt> refactor harmonyacceptimportdependency to es6 </cmt> <cmt> raw transform of harmonyimportdependency to es6 </cmt> <cmt> move makestatement to template </cmt> <cmt> move makestatement to template and call it getcontent </cmt> <cmt> change all of its users </cmt>",refactor harmony import and harmony accept import dependency to es6
1643,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add types to @riderize/passport-strava-oauth2 </cmt> <cmt> fix lint issue on index.d.ts </cmt> <cmt> remove @ from the package name </cmt>",add types support for the @riderize/passport-strava-oauth2
1644,<desc> brings the window options between the settings applications inline with another. </desc> <cmt> displaysettings: prevent minimising the window </cmt> <cmt> this matches how the new mousesettings application works. </cmt> <cmt> keyboardsettings: prevent resizing the window </cmt> <cmt> this matches the other settings applications. </cmt> <cmt> keyboardsettings: prevent minimising the window </cmt> <cmt> this matches how the new mousesettings application works. </cmt>,match window options between applications
1645,"<desc> there are now only 2 tests left in test/libyul/parser.cpp that are not really syntax tests, but one an analysis test and the other one is testing default type assignment. i wonder if it is possible to extract them. p.s.: there's one dead macro in this file now (check_error(text, typ, substr)). i wonder if that one can be removed? i also split the extractions into topic commits, for easier review. </desc> <cmt> extract yul syntax tests: if statement </cmt> <cmt> extract yul syntax tests: for statement </cmt> <cmt> extract yul syntax tests: switch statement </cmt> <cmt> extract yul syntax tests: recursion depth </cmt> <cmt> extract yul syntax tests: multiple assignment expression </cmt> <cmt> extract yul syntax tests: function </cmt> <cmt> extract yul syntax tests: invalid use of builtin identifiers </cmt>",continued yul syntax test extractions.
1646,"<desc> graphs now scale correctly on high resolution screens. comparison (open the images in new tabs to really see the difference) after (on a macbook pro) changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue must exist, be a bug or improvement, and be labeled as lts-candidate to be considered (see query). </desc> <cmt> initial </cmt> <cmt> update graph.java </cmt>",graphs now scale correctly for high-dpi screens
1647,<desc> explain briefly about why the bug exists and how to fix it. use static class name for analysis instead of dynamic jobname record job execute exception reference quartz-scheduler plugin commit update the changes log. </desc> <cmt> update operationname of quartz-scheduler plugin </cmt> <cmt> fix </cmt>,change the operation name of quartz-scheduler plugin
1648,<desc> issue: #6639 removed redundant code that broke examples/ember-cli. still todo looks like maybe #10381 is broken for that example? repro: cd examples/ember-cli yarn storybook </desc> <cmt> argstable: clean up component extraction for primary comonent only </cmt> <cmt> ember-cli: remove redundant preset.js </cmt>,fix args table generation for story with no component
1649,"<desc> astscopes still off-by-default. bug fix for eager scope tree construction. also when an assertion failes in the astscope system, suggest trying -disable-astscope-lookup. </desc> <cmt> ensure that decls aren't added needlessly before creating tree eagerly. </cmt> <cmt> when astscope assertions fails, direct user to try disabling astscopes. </cmt> <cmt> add astscope_unreachable </cmt> <cmt> add explanations to all asserts. </cmt>",bug fix for eager scope tree construction & better failure messages
1650,"<desc> this is based on @tlrx's branch in #32703, so a review should probably hold off until that pr is merged so that this diff is a little cleaner. the getrollupindexcaps api uses basically the same serialization of objects with a slightly different endpoint, but this pr was getting big enough already so i'll do that one in a followup. related #29827 </desc> <cmt> add create rollup job api to the high level rest client </cmt> <cmt> fix license </cmt> <cmt> add cron validation </cmt> <cmt> add getrollupcaps api to the high level rest client </cmt> <cmt> related #29827 </cmt>",add getrollupcaps api to high level rest client
1651,"<desc> refs #15791. this pr makes the file:// protocol support asar files when using networkservice. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> add proxyingurlloaderfactory </cmt> <cmt> intercept file:// protocol to support asar archives </cmt>",migrate protocol module to networkservice (part 8)
1652,"<desc> this avoids constructing a std::string and calling into memory::readblock() if a game decides to be silly with how it's calling the service function. it's unlikely, but it's a trivial case to avoid. </desc> <cmt> svc: correct parameter type for outputdebugstring() </cmt> <cmt> this should be a u64 to represent size. </cmt> <cmt> svc: do nothing if svcoutputdebugstring() is given a length of zero </cmt> <cmt> while unlikely, it does avoid constructing a std::string and </cmt> <cmt> unnecessarily calling into the memory code if a game or executable </cmt> <cmt> decides to be really silly about their logging. </cmt>",do nothing in svcoutputdebugstring() if given a length of zero
1653,"<desc> remove repeat line what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where ""xxx"" is the issue number) if adding a new feature, the pr's description includes: </desc> <cmt> [release] weex-vue-framework@2.4.2-weex.1 (#6196) </cmt> <cmt> * build(release weex): ignore the file path of entries </cmt> <cmt> * [release] weex-vue-framework@2.4.2-weex.1 </cmt> <cmt> style($compile): remove repeat line </cmt> <cmt> remove repeat line </cmt>",remove repeat line in patch.js
1654,"<desc> commit 1: there before was as __stdcall by windows builds, but as this not works by 32 bit becomes now a new #ifdef added to separate between 32 and 64 bit. the 64 bit uses ""__stdcall"" and the 32 bit ""__cdecl"". related error before was: cannot convert from 'bool (__cdecl *)(kodi_addon_audiodecoder_hdl,const char *)' to 'pfn_kodi_addon_audiodecoder_supports_file_v1' commit 2: this reduce the length about attribute_forceinline to attr_forceinline. the others before attr_apientry and attr_dll_... was already reduced in length. for here now to have equal. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [addons] fix win32 builds by use of attr_apientry </cmt> <cmt> there before was as __stdcall by windows builds, but as this not works by 32 bit becomes now a new #ifdef added to separate between 32 and 64 bit. </cmt> <cmt> the 64 bit uses ""__stdcall"" and the 32 bit ""__cdecl"". </cmt> <cmt> related error before was: </cmt> <cmt>  </cmt> <cmt> cannot convert from 'bool (__cdecl *)(kodi_addon_audiodecoder_hdl,const char *)' to 'pfn_kodi_addon_audiodecoder_supports_file_v1' </cmt> <cmt>  </cmt> <cmt> [addons] reduce line length about attribute_forceinline </cmt> <cmt> this reduce the length about attribute_forceinline to attr_forceinline. the others before attr_apientry and attr_dll_... was already reduced in length. for here now to have equal. </cmt>",fix win32 builds by use of attr_apientry and reduce line length about attribute_forceinline
1655,"<desc> based on #1946 by @kapouer. this changes the max bounds behavior so that minzoom is not enforced, and instead the view stays anchored to the bounds when zooming in/out. should fix a hell lot of max bounds issues, including #1908, #2081, #2168. </desc> <cmt> paninsidebounds: fit or center, pass options, remove boundsminzoom </cmt> <cmt> deltas are calculated on x, y pixel coordinates separately. </cmt> <cmt> options are propagated from setmaxbounds to panby. </cmt> <cmt> no panby loops. fixes #1908. </cmt> <cmt> test map#setmaxbounds and map#paninsidebounds </cmt> <cmt> * 'patch-1' of </cmt> <cmt> test map#setmaxbounds and map#paninsidebounds </cmt> <cmt> paninsidebounds: fit or center, pass options, remove boundsminzoom </cmt> <cmt> add max bounds outline to debug file for easier testing </cmt> <cmt> reimplement max bounds with proper zooming </cmt> <cmt> proper rounding of max bounds offsets </cmt>",reimplement max bounds enforcement with proper zooming and lookahead
1656,"<desc> this is a port of pr #71441 but ported to the master branch, as discussed in yesterday's t-compiler meeting </desc> <cmt> revert ""move early needs_subst bailout to _after_ linting."" </cmt> <cmt> this reverts commit 99492e41b60f21f2f461e8131605e054020d328e. </cmt> <cmt> adjust tests </cmt>",revert pr 70566 for const validation fix
1657,"<desc> added a queue implementation for c#, as well as fixed some capitalization and comments for stack.cs. </desc> <cmt> - add queue.cs </cmt> <cmt> - update stack.cs to be more inline with c# conventions </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> - moved queue.cs to the correct folder </cmt>",add queue.cs; fixed comments and method names in stack.cs
1658,"<desc> makes the layout macro data more conformant to qmk's standards, enables community layout support, and cleans up some metadata.  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> genesis hotswap: rename layout to layout_tkl_ansi </cmt> <cmt> genesis hotswap: delete blank layers from default keymap </cmt> <cmt> results in a smaller compiled firmware size. </cmt> <cmt> genesis hotswap: tidy-up via keymap </cmt> <cmt> fixes the visual alignment of keycodes. </cmt> <cmt> genesis hotswap: specify hotswap in info.json </cmt> <cmt> genesis hotswap: enable community layout support </cmt> <cmt> genesis hotswap: remove kbfirmware parser references </cmt> <cmt> genesis hotswap: specify hotswap in config.h </cmt> <cmt> genesis solder: correct keyboard layout </cmt> <cmt> genesis solder: rename layout to layout_all </cmt> <cmt> i don't actually know with certainty that this *is* layout_all, but in the absence of more concrete information, i'm going with this. </cmt> <cmt> genesis solder: delete blank layers from default keymap </cmt> <cmt> results in a smaller compiled firmware size. </cmt> <cmt> genesis solder: tidy-up via keymap </cmt> <cmt> fixes the visual alignment of keycodes. </cmt> <cmt> genesis solder: specify hotswap in info.json </cmt> <cmt> genesis solder: add layout_tkl_ansi </cmt> <cmt> genesis solder: enable community layout support </cmt> <cmt> genesis solder: remove kbfirmware parser references </cmt> <cmt> genesis solder: specify solder in config.h </cmt>",layout macro update and clean-up
1659,<desc> currently the reindex request is propogated to the coordinating node in a cluster state update. this commit moves the reindex request into a specialized reindex index. </desc> <cmt> work on </cmt> <cmt> wip </cmt> <cmt> changes </cmt>,store reindex request in index
1660,"<desc> in the caching layer's flush listener call, we should always write to the underlying store, before flushing (see #4331 's point 4) for detailed explanation). when fixing 4331, it only touches on kv stores, but it turns out that we should fix for window and session store as well. also apply the optimization that was in session-store already: when the new value bytes and old value bytes are all null (this is possible e.g. if there is a put(k, v) followed by a remove(k) or put(k, null) and these two operations only hit the cache), upon flushing this mean the underlying store does not have this value at all and also no intermediate value has been sent to downstream as well. we can skip both putting a null to the underlying store as well as calling the flush listener sending null -> null in this case. modifies corresponding unit tests. </desc> <cmt> first try </cmt> <cmt> add single point query </cmt> <cmt> unit tests </cmt> <cmt> checkstyle fixes </cmt> <cmt> move to sessionstore </cmt> <cmt> one minor fix </cmt> <cmt> rebase from trunk </cmt> <cmt> fix unit tests </cmt> <cmt> github comments </cmt> <cmt> unit tests </cmt> <cmt> fix a final bug </cmt>",part iii; put to underlying before flush
1661,"<desc> ref: #13222 base-64-url values in jwk are encoded without padding, and have a non-canonical representation since the last character may include 2 or 4 unused ""overflow"" bits. encoding should be canonical but decoders may be tolerant, as per btoa - forgiving-base64-decode. chrome and node implementations of webcrypto importkey are tolerant and ignore the overflow bits. previous deno implementation in js used btoa so was tolerant, see here pr implements ""forgiving"" in jwk decode passing suitable config to base64::decode_config. includes test-case. rationale: specifications are somewhat unclear on this, rfc4648 - 3.5.  canonical encoding states that ""decoders may choose to reject an encoding if the pad bits have not been set to zero"", but jws/jwk does not mandate or clarify this .. json web signature (jws) where example code (c#) just adds missing padding = before conversion. </desc> <cmt> base64url for jwk - impl as per whatwg forgiving-base64-decode </cmt> <cmt> test case </cmt>",fix(ext/crypto) base-64 for jwk
1662,<desc> adds an undocumented hidden api call to declaratively deploy backends. todos: incrementally roll out new versions. right now this tears down all of the old version then brings up all of the new version. update the goal completion check to wait for the versions to be updated. doesn't affect existing code. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> basic version working </cmt> <cmt> working w/ basic test </cmt>,add basic support for a declarative deploy() api call
1663,"<desc> r? @nikic or @cuviper </desc> <cmt> remove synchronizationscope::other </cmt> <cmt> added in b7615389978eae2ae9f3cba9a776fd8da3f743ca, it started out already </cmt> <cmt> unused. </cmt> <cmt> remove filetype::other </cmt> <cmt> added in #35174, this was already unused (and new uses have not been introduced </cmt> <cmt> since then). </cmt> <cmt> remove asmdialect::other </cmt> <cmt> added in #35174, this was already unused (and new uses have not been introduced </cmt> <cmt> since then). </cmt> <cmt> remove codegenoptlevel::other </cmt> <cmt> also introduced in #35174, and immediately unused. </cmt> <cmt> remove archivekind::other </cmt> <cmt> also unused since introduction in #35174 </cmt>",remove some dead variants in llvm ffi
1664,"<desc> hi @heifner , i have added support for 160-bit keys aka ripemd160 on the command line --key-type ripemd160 i have also added --encode-type [hex/dec] for some cases like --key-type i256 --encode-type hex i have tested on my smart contract it works in our project now utils.hpp static key160 checksum160_to_key160(const checksum160& value) { key160 k; const uint32_t  *p32 = reinterpret_cast<const uint32_t *>(&value); k.data()[0] = p32[0]; k.data()[1] = p32[1]; k.data()[2] = p32[2]; k.data()[3] = p32[3]; k.data()[4] = p32[4]; return k; } contract.cpp ///@abi table tokenholders i64 struct token_holder { account_name account{}; checksum160 address{}; uint64_t balance{}; account_name primary_key() const { return account; } key160 by_address() const { return checksum160_to_key160(address); } eoslib_serialize(token_holder, (account)(address)(balance)) }; please let me know if anything you want to change / add thank you! </desc> <cmt> add ripemd160 and --encode-type </cmt> <cmt> add support for 160-bit keys </cmt>",add support for 160-bit keys and key encoder type
1665,<desc> #4812 added integration test to verify that hitting low ram threshold will shutdown nodeos and nodeos can be restarted with a higher max ram and it will start without restart/resynch flags. </desc> <cmt> adding contract for miscelaneous actions for integration tests. gh #4812 </cmt> <cmt> added relaunching node with new or changed command line parameters. gh #4812 </cmt> <cmt> added passing in extra command args for cluster launch and passing extra flags for account creation. gh #4812 </cmt> <cmt> added method to check if the node's pid is still active. gh #4812 </cmt> <cmt> added integration test to verify that nodeos will shutdown if minimum ram setting hit and can restart with higher ram. gh #4812 </cmt>,low ram shutdown integration test
1666,"<desc> with the existence of the .devcontainer directory, when a user opens the repository using vs code, they will be automatically prompted to re-open the directory from inside the developer container. t the vs code window is connected to that container, being able to both use extensions to facilitate programming, tools. to check that the code is according to our standards (e.g flake8) and use vs code sidebar as a gui for file navigation inside the container. finally, vs code syncs the directory that we just opened inside the container, meaning that any file we place from our host machine into that directory (e.g netdata), it will be synced inside the container. the developer container contains all the required dependencies to build from source: netdata python.d.plugin go.d.plugin netdata dashboard the new contribution workflow will be the following: fork the netdata/netdata repository git clone the forked repository locally open the directory using vs code reopen from inside the devenv, ready to develop! this new optional workflow greatly simplifies the contribution process, since the user only needs to have vs code installed. component name download the repository and open the directory using vs code </desc> <cmt> add devcontainer.json for devenv </cmt> <cmt> add devenv file </cmt>",support vs code container devenv
1667,"<desc> tab now moves focus across and down for help source and custom run. </desc> <cmt> rearrange initialization. </cmt> <cmt> edit docstrings and comments, call dummy create_extra. </cmt> <cmt> convert subclasses to create_extra. </cmt> <cmt> fix custom run htest. </cmt> <cmt> news entries. </cmt>",fix focus traversal for 2 idle dialogs
1668,"<desc> moving the upgrade topic out of ""setup"" was a suggestion that came up in our doc-support sync. this makes it more discoverable and is consistent with the placement in our other docs. </desc> <cmt> [docs] added link to the upgrade guide & tweaked the intro. </cmt> <cmt> [docs] bumped upgrade topic up to the top level of the toc </cmt>",added link to upgrade guide and bumped the upgrade topic up to the top level
1669,"<desc> analogue to #70798 for devel (and stable-2.10). bumps the antsibull-changelog version to 0.7.0, which includes a new option to be more strict about suffixes (ansible-community/antsibull-changelog#33), enables this option in changelogs/config.yaml, and adjusts the sanity test to flag all files that are not processed, with the exception of .keep and .gitkeep. (.keep and .gitkeep seem to be the most common ways of people making sure empty subdirectories are kept by git and other version control systems:   changelog changelog sanity test </desc> <cmt> bump antsibull-changelog version. </cmt> <cmt> flag all dotfiles, except .keep and .gitkeep. </cmt> <cmt> enable ignoring other fragment extensions. </cmt>",make changelog tool be more strict about suffixes
1670,"<desc> fixes #3962 added linux specific code along with the windows specific code, so as to make it work in both build systems. </desc> <cmt> add autoformat checking for js code </cmt> <cmt> autoformat code using prettier </cmt> <cmt> added binary heap </cmt> <cmt> minor fixes </cmt> <cmt> merge conflict </cmt> <cmt> fix #3962 by adding linux specific code along with windows code </cmt> <cmt> fix #3962 remove unnecessary includes </cmt> <iss> travis build for c programs failing due to windows specific code </iss>",fixes #3962 travis windows build
1671,"<desc> description: i started off thinking i would try to knock off a bunch of the places where we compute stats by name in one go, but dynamo deserves its own pr mostly; there's one unrelated file in it. if this goes in first we should remove the whitelist entry in #7573 and if that goes in first then we should merge that in and remove the entry before checking this one in. this is another step toward resolving #4196 and enabling submission of #4980. risk level: medium -- could introduce lock contention for stats associated with status-codes and table-names. this pr may need more work because of that. note that #7008 offers a solution to this problem; it's just not clear yet whether it's worth the cost until we see perf traces. testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> partial compilation </cmt> <cmt> dynamo tests passing. </cmt> <cmt> remove temporary pools. </cmt>",convert dynamo stats to use statname interface
1672,"<desc> minor fixes to snapcraft builds </desc> <cmt> snapcraft: fix bcc-wrapper, handle ' ' quoting correctly </cmt> <cmt> this allows '' quoted parameters to be passed in the wrapper. </cmt> <cmt> snapcraft: fix the fetching of the most recent tag version </cmt>",a couple of snapcraft fixes
1673,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update @types/d3kit to 3.2 </cmt> <cmt> update @types/d3kit to 3.2 </cmt>",updating existing @types/d3kit definition to new version: 3.1.2 ==> 3.2
1674,"<desc> fixes #395 </desc> <cmt> adhere to pointdot option in config </cmt> <cmt> - added display property on point classes, to determine whether the </cmt> <cmt> draw sequence should run or not. </cmt> <cmt> default display of chart point to true </cmt> <iss> pointdot option does not work! </iss>",fix option for pointdot not being obeyed
1675,"<desc> fixes #47146 (introduced by #42425 which enabled this syntax) previously this code ran without error: type oh_no = { get [k in wat](): string }; because we incorrectly swallowed the errors in checkcomputedpropertyname under the assumption that we were looking at a { [k in t]: u } declaration. the code path where the error would have been detected -- in the mapped checking logic -- obviously does not run because this is not actually a mapped type. thankfully the computed type was completely useless (see comments in linked issue), so it isn't feasible that anyone took a dependency on this. </desc> <cmt> add test that should fail </cmt> <cmt> make it fail </cmt> <cmt> fixes #47146 </cmt> <iss> infer on setter argument gives unknown </iss>",correctly check computed property names in type-space get/set accessors
1676,"<desc> follows from #10969 and issue #10883 expand brier score explanation wrt calibration and refinement loss in the user guide fix brier_score_loss docstring: #10969 removed some blank lines, which removed the paragraph structure of the docstring. added lines back here. link to brier score part of user guide and not calibration part correct pos_label description some minor rewording to make it easier to understand and more similar to the user guide. </desc> <cmt> fix brier </cmt> <cmt> fix brier </cmt>","doc expand brier score, fix docstring"
1677,<desc> resolves devrel-1575: fix broken references to eos repo docs (backport of pr #10570 #10571 #10572 to 2.0) select one: select any that apply: </desc> <cmt> remove broken cleos wrap cmd ref link :doc </cmt> <cmt> fix self link in keosd wallet plugin index :doc </cmt> <cmt> fix broken links in upgrade 1.8 guide :doc </cmt>,fix some broken anchors and links - 2.0
1678,"<desc> looks like sometwo was also asking for comment fixes, here you go. </desc> <cmt> fixed comments in other files as per request of jvrv </cmt> <cmt> more changes made to comments, as requested by jvrv </cmt>",more comments in core fixed
1679,"<desc> specifically, the problem there is that while rewinding will work properly, if you later unwind again, that unwinding will also unwind through that extra compiled code that was on the stack - causing a later rewind to behave badly. this should avoid problems like the one mentioned in #10515 . </desc> <cmt> asyncify: add an assertion for rewinding with compiled code on the stack. avoids #10515 </cmt> <cmt> fix </cmt>",add an assertion + docs for rewinding with compiled code on the stack
1680,"<desc> #10661 fixed toggle command. shutterbutton toggle now up,stop,down,stop,up and so on #xxxx  fixed stepper motor overrun because pwmfrequency is hardcoded minimum 100hz #xxxx  added compiler option for unit test. testing different functions on the correct calculation #xxxx fixed shuttertoggledir if the shutter is running #10860 removed triggering additional relays to ensure up to 4 stepper motors. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> several fixes </cmt> <cmt> update xdrv_27_shutter.ino </cmt>",several bugfixes for stepper motors and buttons
1681,"<desc> this no longer reports useless (none, none) invalid locations from the sourcemap expansion. this fixes #5814 </desc> <cmt> do not report an error for completely missing js locations </cmt> <cmt> correctly skip over js frames without lineno attributes </cmt> <cmt> add a test for not reporting useless no-location frames </cmt> <iss> invalid location in source map: (none, none) </iss>",resolve invalid location in source map
1682,<desc> @glenn-jocher i noticed the final val results from best.pt was not being logged in the loggers class for both wandb and tb. this pr addressed multiple issues and prs. fixes issue -> #6116 solves pr -> #6085 </desc> <cmt> log best.pt metrics at train end </cmt> <cmt> update </cmt> <iss> the training statistical results are inconsistent with wandb </iss>,log best results after training ends
1683,"<desc> fix missing rules and sort orders. the compilation flag had been omitted as a rule for albums playlists, adding it means that users can now create playlists and filter type custom nodes for compilations (or exclude them). similarly with last played date, including it means that users can create their own variations of the recently played albums node without core code changes. while doing that found that some of the sort orders were missing too, causing the display to ignore the order defined in the playlist. a good test would be to create a playlist of recently played compliations. </desc> <cmt> add compilation as an ""albums"" smart playlist rule. </cmt> <cmt> add lastplayed as album smart playlist rule. </cmt> <cmt> fix missing sort orders </cmt>",album is compilation and last played rules and fix missing sort orders in smart playlists
1684,"<desc> jira:  note that the temporary parent-boot-2.0-temp module was deleted for good now :) notes & observations: 1- spring-rest-template it seems that this module was already migrated to the spring-rest module. but only one class still remains here (it's also in spring-rest, it seems they just forgot to delete this). maybe we have to remove this module   2- spring-resttemplate the app starts, but for some reason it finishes right away, as if it wasn't a web-app. livetests of course don't work we should revisit the project structure (i believe the main class is not scanning all packages) and the pom file (its really complex, there are lots of dependencies and configurations that could probably be removed) 3-  spring-security-mvc-boot springdatawithsecurityunittest seems to be an integration test actually. 4- spring-vault all integration tests (vaultintegrationtest and springcontextintegrationtest) throw exception. it is not related to this change, it seems to be trying to run a 'vault' command to start a vault server in the host machine. of course it needs the environment to be configured for this, i would rename them it as a 'manualtest', or change the approach of the test. even with the command available, 2 out of 3 tests fail (not related to the spring-boot version upgrade, i checked using the former version, and tests still failed). 5- spring-webflux-amqp springcontextintegrationtest requires a rabbitmq running insttance to pass. maybe we want to rename it as livetest or manualtest? also, i changed the spring.rabbitmq.host property. it had a hard ip value, now its using 'localhost' so that tests pass successfuly. the reason why i mention this is because in the related article it also has the fixed ip. i didn't read the whole article, but that ip is not mentioned when setting up the rabbitmq server, so we might want to analize the possibility of changing it to 'localhost' as well 6- vaadin i'm having an error on this module when bootstraping this app, not related to this change (i tried with the 2.0.x version too): also, it seems spring 2.1 is supported from version 8 onwards (we're using v7): vaadin/spring#331 (comment) the apis change quite a lot in that version, the process (and probably the related article) will need quite a lot of refactoring if we want to upgrade to the latest versions (it seems v10 was a big milestone). 7- vavr this has a vavr-validation folder in the root directory, which also has a maven project structure, but of course, it is not an actual sub-module, it has no pom file, and it doesn't seem very useful as it is. maybe we should make this a module with 2 submodules? </desc> <cmt> migrated modules to parent-boot-2 usign spring-boot 2.1: </cmt> <cmt> spring-mvc-forms-thymeleaf </cmt> <cmt> spring-rest </cmt> <cmt> spring-rest-angular </cmt> <cmt> spring-rest-query-language </cmt> <cmt> spring-rest-shell </cmt> <cmt> spring-rest-simple </cmt> <cmt> spring-rest-template </cmt> <cmt> spring-resttemplate </cmt> <cmt> spring-security-mvc-boot </cmt> <cmt> spring-security-openid </cmt> <cmt> spring-security-sso </cmt> <cmt> spring-security-thymeleaf </cmt> <cmt> migrated modules to parent-boot-2 with spring-boot 2.1: </cmt> <cmt> spring-session/spring-session-jdbc </cmt> <cmt> spring-vault </cmt> <cmt> spring-webflux-amqp </cmt> <cmt> vaadin </cmt> <cmt> vavr </cmt> <cmt> deleted temporary parent-boot module using spring-boot 2.0.x </cmt>",| upgrade set of modules to use boot 2.1 - part 3
1685,"<desc> tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> enh: add numba engine to rolling.var </cmt> <cmt> fix typing </cmt> <cmt> add std, support multiple versions in numba args docstring </cmt> <cmt> fix tests for std </cmt>",add numba engine to rolling/expanding.std/var
1686,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [mapbox-gl] allow for just lnglatlike </cmt> <cmt> [mapbox-sdk] update path overlay to reflect docs </cmt> <cmt> [mapbox-sdk] add test </cmt>",update pathoverlay to reflect jsdocs
1687,"<desc> merge from 4.3-pre back to 4.1 to fix #1077. </desc> <cmt> spi: bcm2835: set up spi-mode before asserting cs-gpio </cmt> <cmt> when using reverse polarity for clock (spi-cpol) on a device </cmt> <cmt> the clock line gets altered after chip-select has been asserted </cmt> <cmt> resulting in an additional clock beat, which confuses hardware. </cmt> <cmt> this did not show when using native-cs, as the same register </cmt> <cmt> is used to control cs as well as polarity, so the changes came </cmt> <cmt> into effect at the same time. unfortunately this is not true </cmt> <cmt> with gpio-cs. </cmt> <cmt> to avoid this situation this patch moves the setup of polarity </cmt> <cmt> (spi-cpol and spi-cpha) outside of the chip-select into </cmt> <cmt> prepare_message, which is run prior to asserting chip-select. </cmt> <cmt> also fixes resetting 3-wire mode after use of rx-mode, so that </cmt> <cmt> a 3-wire sequence tx, rx, tx works as well (right now it runs </cmt> <cmt> tx, rx, rx instead) </cmt> <cmt> reported-by: noralf tronnes <noralf@tronnes.org> </cmt> <cmt> cc: stable@vger.kernel.org </cmt> <cmt> (cherry picked from commit acace73df2c1913a526c1b41e4741a4a6704c863) </cmt> <cmt> spi: bcm2835: fix overflow in calculation of transfer time </cmt> <cmt> this resulted in the use of polling mode when other approaches </cmt> <cmt> (dma or interrupts) would have been more appropriate. </cmt> <cmt> happened for transfers longer than 477 bytes. </cmt> <cmt> reported-by: noralf tronnes <noralf@tronnes.org> </cmt> <cmt> (cherry picked from commit 0122a5183088e3117bb9c8fbe248914efb502f3f) </cmt>",rpi 4.1.y spi bcm2835 patches clock-polarity issues
1688,"<desc> this is quite an experiment, so let me know what you think! when working on #1530 i noticed that i had to manually update the pipfile.lock, which gave some issues with platforms and versions at first. so when i got it working, i decided to try to automate it for consistency and efficiency. in this pr i added a workflow with github actions that opens a pr to update the pipfile.lock on one of two conditions: weekly (currently monday 08:00 utc) when the pipfile is modified the weekly pr will be opened directly against the master branch, while when the pipfile is modified the pr would open against the branch in which the pipfile is modified. this way dependencies won't change in an unexpected manner, but will be updated regularly. the pr will be opened in the update-pipfile branch. if it doesn't exist it will be created, if last weeks pr is still open it will be updated and when it's merged is will be deleted. currently only the major versions of dependencies that were previously fully locked are now locked. this pr also move the tensorflow-gpu to tensorflow package (which are at this point identical) and thus can replace #1530. an example run of the workflow can be seen here and an example of the pr here: ewouth#3 if you like the general idea, please also comment on specifics (used versions, the schedule, naming, etc.) </desc> <cmt> create workflow to update the pipfile.lock weekly </cmt> <cmt> update-pipfile: also install wheel </cmt> <cmt> install wheel in different step </cmt> <cmt> pipfile: only lock major versions </cmt> <cmt> assumes semantic versioning, and only sets the major versions of all packages </cmt> <cmt> run update-pipfile on changes in pipfile and use tensorflow </cmt> <cmt> move from tensorflow-gpu to tensorflow, an excelent test for this pr </cmt> <cmt> [create-pull-request] automated change </cmt> <cmt> update pipfile.lock (dependencies) </cmt>",add workflow to update pipfile.lock weekly
1689,"<desc> this could improve the rllib performance on cpu only environments a lot.  it could improve 6x training performance in the following test with impala atari. the test node has 48 physical cores. the totally omp_num_threads should less and equal than totally physical cores. we could only set omp_num_threads=1 from system level because we have a total of 33 processes. and with this patch, we could set the trainer and workers separately. so we could fully use the cpu. master branch: # config: atari-impala: env: grid_search: - breakoutnoframeskip-v4 - beamridernoframeskip-v4 - qbertnoframeskip-v4 - spaceinvadersnoframeskip-v4 run: impala stop: timesteps_total: 1000000 config: num_gpus: 0 rollout_fragment_length: 50 train_batch_size: 500 num_workers: 32 num_envs_per_worker: 5 lr_schedule: [ ] tf_session_args: intra_op_parallelism_threads: 2 inter_op_parallelism_threads: 2 local_tf_session_args: inter_op_parallelism_threads: 2 intra_op_parallelism_threads: 16 num_cpus_per_worker: 2 num_cpus_for_driver: 16 # results memory usage on this node: 21.6/503.4 gib using fifo scheduling algorithm. resources requested: 0/96 cpus, 0/0 gpus, 0.0/339.65 gib heap, 0.0/103.17 gib objects result logdir: /home/xianyang/ray_results/atari-impala number of trials: 4 (4 terminated) +------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------+ | trial name                               | status     | loc   | env                         |   iter |   total time (s) |      ts |   reward | |------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------| | impala_breakoutnoframeskip-v4_00000      | terminated |       | breakoutnoframeskip-v4      |     63 |          1287.12 | 1011500 |    20.21 | | impala_beamridernoframeskip-v4_00001     | terminated |       | beamridernoframeskip-v4     |     63 |          1298.43 | 1015500 |   460.04 | | impala_qbertnoframeskip-v4_00002         | terminated |       | qbertnoframeskip-v4         |     63 |          1285.1  | 1014000 |   466    | | impala_spaceinvadersnoframeskip-v4_00003 | terminated |       | spaceinvadersnoframeskip-v4 |     63 |          1310.37 | 1007500 |   202.5  | +------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------+ set extra python env with this patch: # config atari-impala: env: grid_search: - breakoutnoframeskip-v4 - beamridernoframeskip-v4 - qbertnoframeskip-v4 - spaceinvadersnoframeskip-v4 run: impala stop: timesteps_total: 1000000 config: num_gpus: 0 rollout_fragment_length: 50 train_batch_size: 500 num_workers: 32 num_envs_per_worker: 5 lr_schedule: [ ] tf_session_args: intra_op_parallelism_threads: 2 inter_op_parallelism_threads: 2 local_tf_session_args: inter_op_parallelism_threads: 2 intra_op_parallelism_threads: 16 num_cpus_per_worker: 2 num_cpus_for_driver: 16 extra_python_environs_for_driver: omp_num_threads: 16 extra_python_environs_for_worker: omp_num_threads: 2 # results memory usage on this node: 22.2/503.4 gib using fifo scheduling algorithm. resources requested: 0/96 cpus, 0/0 gpus, 0.0/339.65 gib heap, 0.0/103.17 gib objects result logdir: /home/xianyang/ray_results/atari-impala number of trials: 4 (4 terminated) +------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------+ | trial name                               | status     | loc   | env                         |   iter |   total time (s) |      ts |   reward | |------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------| | impala_breakoutnoframeskip-v4_00000      | terminated |       | breakoutnoframeskip-v4      |     21 |          281.231 | 1044500 |   14.06  | | impala_beamridernoframeskip-v4_00001     | terminated |       | beamridernoframeskip-v4     |     21 |          278.364 | 1047000 |  447.76  | | impala_qbertnoframeskip-v4_00002         | terminated |       | qbertnoframeskip-v4         |     21 |          268.376 | 1005000 |  360.119 | | impala_spaceinvadersnoframeskip-v4_00003 | terminated |       | spaceinvadersnoframeskip-v4 |     21 |          274.457 | 1020500 |  254.25  | +------------------------------------------+------------+-------+-----------------------------+--------+------------------+---------+----------+ cpu utilization from ~6% to ~80%. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> support set extra python environments </cmt> <cmt> wrap value with str </cmt>",[rllib]add config for rllib to support set python environments
1690,"<desc> i made a slight modification in the conversion file, now it is also able to convert hexadecimal to binary i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. all new algorithms have a url in their comments that points to wikipedia or other similar explanations. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added a file that converts hexa to binary </cmt> <cmt> added file to convert hexadecimal to binary </cmt> <cmt> update hex-bin.py </cmt> <cmt> added type hint in the code </cmt> <cmt> added doctest </cmt>",added a hex-bin.py file in conversion.py
1691,"<desc> ... and rename to commitcallbacks. this change is a step to further separate the core diff from a specific component implementation. though i suspect that _commitcallbacks won't forever stay on internal (depends on how we implement an extensible component api), i figured i'd move it to internals for now so we can start to peel away other parts of the codebase. </desc> <cmt> rename _rendercallbacks to _commitcallbacks </cmt> <cmt> add commitqueue internal type </cmt> <cmt> remove _hydrating from mangle config </cmt> <cmt> move commitcallbacks from component to internal </cmt>",move render callbacks to internals
1692,"<desc> for #2992. recheck all checkstyle and open checkstyle during building format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> re-check code style for nacos-config module. </cmt> <cmt> re-check code style for other module. </cmt> <cmt> open checkstyle plugin check during build </cmt> <iss> unified code style file to do format verification and formatting </iss>",[issue #2992]recheck all checkstyle and open checkstyle during building
1693,"<desc> to correctly configure a security group, the logic of bootstrap_aws currently requires subnets to be specified head_nodes and worker_nodes fields. this pr adds a test that validates that adding head_nodes and worker_nodes fields with subnet data to a multi-node-type config leads to a correct configuration of a security group. i've run scripts/format.sh to lint the changes in this pr. test passes. </desc> <cmt> validate logic </cmt> <cmt> add assertion </cmt>",validate current state of subnet-specification
1694,<desc> should close #1197 - screenshots in this comment </desc> <cmt> added user sync data setting and reverting indentation. </cmt> <cmt> syncing common user data during login based on admin setting. </cmt> <cmt> added translation messages </cmt> <cmt> supporting single and multi e-mails addresses </cmt>,ldap - sync user data based on settings
1695,"<desc> this is some cleanups that i committed that were reverted since we do not have a precondition when building standalone. </desc> <cmt> [benchmark][cmake] provide our own precondition impl. </cmt> <cmt> this ensures that we have a precondition implementation both when building in </cmt> <cmt> tree and out of tree. </cmt> <cmt> revert ""reverting benchmark cmake changes. they break out-of-tree benchmark builds, which is used by some bots"" </cmt> <cmt> this reverts commit db21063afae47d3dac2f6e00dd55157182534bcd. </cmt>",recommit benchmark changes with precondition
1696,"<desc> right now this only works for single-signature decorators that accept no arguments. we could improve this to cases where there are too many arguments from the decorated entity for every signature and the min arg count is 0 for every signature we now give a more helpful error message when a decorator receives too many arguments and 0 arguments could be given this comes up for me all the time in angular where i end up forgetting to invoke the decorator: @component({ /*... */ }) class foocomponent { @input foo: string; // oops, i meant @input(), not @input } </desc> <cmt> give a more helpful error message when users try decorating using expressions that take no arguments. </cmt> <cmt> accepted baselines. </cmt>",give a more helpful error message for certain decorators with too many arguments
1697,"<desc> the implments quick fixes were not providing the host required to generate good paths for import types into the type node helpers they used, so they were always generating absolute paths (or amd module names). fixes #29406 </desc> <cmt> pass module specifier resolution host thru types constructed by implements quickfixes </cmt> <cmt> add regression test </cmt> <iss> absolute `import(...)` path used in type for the implement interface quick fix </iss>",fix implement interface quickfix import types
1698,"<desc> fix a bug brought in with pr: #8638 see, #8936 #8638 closes #8936 tests passed with the help from @nc-x, the issue is reproduced and fixed by this patch. clsctx_in_process is not good enough for all cases to create ishellwindows interface. put a clsctx_all fixes the issue. another debugging warning dialogs  for reusing not null com_ptr in the loop is fixed too. (this was shown in debug builds only) </desc> <cmt> make open terminal here context menu for directory background </cmt> <cmt> use win32 explorer window to find current directory folder path </cmt> <cmt> link user32.lib </cmt> <cmt> disable vcpkg use nuget packages </cmt> <cmt> fix missing new line </cmt> <cmt> code formating </cmt> <cmt> spell checker </cmt> <cmt> update src/cascadia/shellextension/openterminalhere.cpp </cmt> <cmt> update src/cascadia/shellextension/openterminalhere.h </cmt> <cmt> bug fix private function rename </cmt> <cmt> trivial </cmt> <cmt> revert vcpkg settings </cmt> <cmt> move user.lib linking to the project setting </cmt> <cmt> bug fixing </cmt> <cmt> update two other appxmanifest to enable folder background context menu </cmt> <cmt> merge </cmt> <cmt> fix crashing on create_instance, use try_create_instance instead, and use clsctx_all </cmt> <cmt> fix not nullptr warning </cmt> <cmt> a few comments </cmt> <cmt> trivial </cmt> <iss> context menu -> open in windows terminal -> ""the server threw an exception"" </iss>",fix crash in explorer background context menu logic
1699,<desc> this adds the ability to access tokens directly and makes flipping microprofile after a fence instead of before. </desc> <cmt> microprofile: allow accessing token. </cmt> <cmt> nvflinger: do the microprofile flip after processing a valid frame. </cmt>,small corrections and features to microprofile
1700,<desc> fixes the problem when std of a covariate is zero. @duchesnay could you please check if you agree </desc> <cmt> ensure that std is not zero </cmt> <cmt> add test case for scale div through zero </cmt>,pls scale by zero bug
1701,"<desc> also changed it to ask for permissions only when executing a query and not on every click, which was annoying. fixes #953. </desc> <cmt> ask for notification permissions only on query execution </cmt> <cmt> fix: show notifications only when page in background </cmt>",show browser notification only when page is hidden
1702,"<desc> updated according to changes mentioned in r84 release: </desc> <cmt> three update r84 #10393: </cmt> <cmt> binarytextureloader deprecated in favour of datatextureloader #10393 </cmt> <cmt> three update to r84 #10474: </cmt> <cmt> box3 added expandbyobject(). #10474 </cmt> <cmt> three update to r84 c8265b9: </cmt> <cmt> curve deprecated create(). c8265b9 </cmt> <cmt> three update to r84 fe98988: </cmt> <cmt> curveutils removed. fe98988 </cmt> <cmt> three update to r84 #9597: </cmt> <cmt> eventdispatcher removed apply(). #9597 </cmt> <cmt> three update to r84 #10367, #10375: </cmt> <cmt> matrix3 removed applytovector3array(). #10367 </cmt> <cmt> matrix4 removed applytovector3array(). #10367 </cmt> <cmt> matrix4 changed makefrustum() to makeperspective(). #10375 </cmt> <cmt> three update to r84 #10415, #10397 : </cmt> <cmt> spline deprecated in favour of catmullromcurve3. #10415 </cmt> <cmt> splinecurve3 deprecated in favour of catmullromcurve3. #10397 </cmt> <cmt> three update to r84 #10405, #10412: </cmt> <cmt> vector2 renamed fromattribute() to frombufferattribute(). #10412 </cmt> <cmt> vector3 renamed fromattribute() to frombufferattribute(). #10412 </cmt> <cmt> vector3 combined applyprojection() into applymatrix4(). #10405 </cmt> <cmt> vector4 renamed fromattribute() to frombufferattribute(). #10412 </cmt> <cmt> three update to r84: </cmt> <cmt> updated d.ts version to 0.84.0 </cmt>",three updated from r83 to r84
1703,<desc> fixed a race condition in the resize listener & used the correct merged config object for the responsive setting. this fixes #1520 </desc> <cmt> fix a race condition in the resize listener & use the correct merged config object for the responsive setting </cmt> <cmt> put comment back in correct spot </cmt>,use the correct merged responsive setting in the resize listener
1704,"<desc> i plan to improve integrity check code so that it could also verify node_modules structure. this pr moves most of the integrity checking and saving code into a separate class, no actual changes to the logic. all tests should pass (integrity checks are covered with integration tests) pending things to do: a bit of cleanup </desc> <cmt> proper integrity check: first commit </cmt> <cmt> moved the rest code to integrity-check and integrated with install and check commands </cmt> <cmt> more fixes </cmt>",refactored integrity generation and check
1705,"<desc> original pull-request #17615 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix logging </cmt> <cmt> fix logging in mergetree </cmt>",cherry pick #17615 to 20.11: fix logging in mergetree
1706,"<desc> use some template metaprogramming trickery to provide an operation to extract the source location from certain basic ast types (declarations, declaration contexts, attributes, etc.) as well as compound types built from those (pointer unions and tuples). use that so that simplerequest can provide default implementations for the diagnosecycle and notecyclestep functions that are needed in every request type used with the request-evaluator, eliminating a lot of boilerplate from requests. </desc> <cmt> [request-evaluator] remove unused ""simplified"" cycle diagnostics. </cmt> <cmt> simplerequest tried to make it easy to provide cycle diagnostics, but it </cmt> <cmt> wasn't being used and wasn't right. remove this code. </cmt> <cmt> [request-evaluator] provide defaults for diagnosecycle/notecyclestep. </cmt> <cmt> introduce some template metaprogramming infrastructure to retrieve the </cmt> <cmt> ""nearest"" source location to the inputs of a request, and use that to </cmt> <cmt> provide default diagnosecycle and notecyclestep implementations. this </cmt> <cmt> will help remove a bunch of boilerplate from new requests. </cmt> <cmt> [request-evaluator] remove extraneous diagnosecycle/notecyclestep impls. </cmt> <cmt> all of these can use the default implementations now. </cmt> <cmt> [docs] remove some irrelevant ""open projects"" for the request-evaluator </cmt>",eliminate cycle-diagnostic boilerplate from simplerequest subclasses
1707,"<desc> added the last completion box colors  font and scroll bar). exposed show line numbers, highlight all occurrences to the user, through gdscript and properties. updated the textedit theme to contain the newly added colors. i didn't add custom_bg_color and symbol_color because i would have to break api compatibility to keep the styling consistent and didn't want to throw in a work around. lastly, updated the docs to reflect these changes. </desc> <cmt> added completion scroll color </cmt> <cmt> added completion font colors </cmt> <cmt> expose colors to theme </cmt> <cmt> expose show line numbers </cmt> <cmt> expose highlight all occurrences </cmt> <cmt> update textedit docs with colors, show line number and highlight all occurences </cmt> <cmt> removed duplicate color </cmt>","added completion box colors. exposed show line numbers, highlight all occurrences, and updated theme."
1708,"<desc> context: the new rustdoc ""auto trait"" feature walks across impls and tries to run trait solving on them with a lot of unconstrained variables. this is prone to overflows. these overflows used to cause an ice because of a caching bug (fixed in this pr). but even once that is fixed, it means that rustdoc causes an overflow rather than generating docs. this pr therefore adds a new helper that propagates the overflow error out. this requires rustdoc to then decide what to do when it encounters such an overflow: technically, an overflow represents neither ""yes"" nor ""no"", but rather a failure to make a decision. i've decided to opt on the side of treating this as ""yes, implemented"", since rustdoc already takes an optimistic view. this may prove to include too many items, but i suspect not. we could probably reduce the rate of overflows by unifying more of the parameters from the impl -- right now we only seem to consider the self type. moreover, in the future, as we transition to chalk, overflow errors are expected to just ""go away"" (in some cases, though, queries might return an ambiguous result). fixes #52873 </desc> <cmt> replace bug! call with overflow </cmt> <cmt> give a more informative failure in this case </cmt> <cmt> don't cache overflow results globally </cmt> <cmt> expose evaluate_obligation that captures overflow, use in rustdoc </cmt> <iss> ice when running `cargo doc` on `typenum` at `librustc/traits/structural_impls.rs:178` </iss>",overlook overflows in rustdoc trait solving
1709,<desc> currently it's not possible to use prometheusmetricstrackerfactory if you have multiple pools. even if you create one instance of factory it's not thread-safe and collector created multiple times. related to #1331 fixes #1465 </desc> <cmt> add support for multiple prometheus histogram metric trackers </cmt> <cmt> add tests </cmt> <iss> prometheushistogrammetricstracker should not register metrics twice </iss>,fix prometheus histogram metric tracker for multiple pools
1710,"<desc> this pr adds an experimental ray_plasma_unlimited=1 flag that lifts the size limit on the plasma object store. the tricky part here is preserving the object store performance, since naively placing all pages in the filesystem can lead to excessive disk thrashing as the os tries to flush large amounts of object store pages to disk. this mechanism works as follows: first, we try to allocate from the normal pool of plasma memory. we disable overcommit, so allocations return nullptr once the initial pool of pages allocated in /dev/shm is exhausted. we fallback to allocating filesystem pages from /tmp. we set dlmalloc's mmap_threshold to zero for these types of allocations, which means each object is given its own unique file. when the object is deallocated, the file is also removed. this means that once spaces frees up, future allocations will go to /dev/shm (fast) instead of reusing pages in /tmp (slow). what this effectively means is users should never see oom as long as they have any disk space left. the existing spilling and memory admission control mechanisms in ray are still important, but they now primarily impact the performance of ray instead of correctness (avoiding oom). note that spilling alone cannot guarantee no oom since plasma pages can be pinned in memory by the application (e.g., ray.get() or temporary buffers for ray.put()), hence you can still oom due to lack of /dev/shm space. you can try it out with this code: unlimited.py: import ray import time import numpy as np ray.init(object_store_memory=1e9) x1 = ray.put(np.zeros(1024 * 1024 * 800, dtype=np.uint8)) x1p = ray.get(x1) print(""putting x2"") x2 = ray.put(np.zeros(1024 * 1024 * 500, dtype=np.uint8)) time.sleep(.1) print(""putting x3"") x3 = ray.put(np.zeros(1024 * 1024 * 400, dtype=np.uint8)) time.sleep(.1) print(""putting x4"") x4 = ray.put(np.zeros(1024 * 1024 * 200, dtype=np.uint8)) time.sleep(.1) print(""putting x5"") x4 = ray.put(np.zeros(1024 * 1024 * 100, dtype=np.uint8)) print(""getting x2"") z = ray.get(x2) eric@eric-thinkpad-t490s:~$ ray_plasma_unlimited=1 python unlimited.py 2021-05-26 14:54:53,592	info services.py:1274 -- view the ray dashboard at  putting x2 (raylet) [2021-05-26 14:54:56,895 e 26756 26773] store.cc:246: shared memory store full, falling back to allocating from filesystem: 524288258 putting x3 (raylet) [2021-05-26 14:54:57,105 e 26756 26773] store.cc:246: shared memory store full, falling back to allocating from filesystem: 419430658 putting x4 (raylet) [2021-05-26 14:54:57,347 e 26756 26773] store.cc:246: shared memory store full, falling back to allocating from filesystem: 209715455 putting x5 getting x2 eric@eric-thinkpad-t490s:~$ ray_plasma_unlimited=0 python unlimited.py 2021-05-26 14:55:27,386	info services.py:1274 -- view the ray dashboard at  putting x2 2021-05-26 14:55:39,810	info worker.py:1530 -- put failed since the value was either too large or the store was full of pinned objects. traceback (most recent call last): file ""unlimited.py"", line 11, in <module> x2 = ray.put(np.zeros(1024 * 1024 * 500, dtype=np.uint8)) file ""/home/eric/desktop/ray/python/ray/_private/client_mode_hook.py"", line 62, in wrapper return func(*args, **kwargs) file ""/home/eric/desktop/ray/python/ray/worker.py"", line 1527, in put object_ref = worker.put_object(value) file ""/home/eric/desktop/ray/python/ray/worker.py"", line 289, in put_object serialized_value, object_ref=object_ref)) file ""python/ray/_raylet.pyx"", line 1107, in ray._raylet.coreworker.put_serialized_object file ""python/ray/_raylet.pyx"", line 1024, in ray._raylet.coreworker._create_put_buffer file ""python/ray/_raylet.pyx"", line 153, in ray._raylet.check_status ray.exceptions.objectstorefullerror: failed to put object ffffffffffffffffffffffffffffffffffffffff0100000002000000 in object store because it is full. object size is 524288252 bytes. the local object store is full of objects that are still in scope and cannot be evicted. tip: use the ray memory command to list active objects in the cluster. </desc> <cmt> wip </cmt> <cmt> lint </cmt> <cmt> rename </cmt> <cmt> lint </cmt> <cmt> update </cmt> <cmt> lint </cmt> <cmt> fix up </cmt>",unlimited plasma allocations by falling back to a filesystem allocator (off by default)
1711,"<desc> as per sentry/src/sentry/api/event_search.py lines 1232 to 1243 in b0657e4 ""avg"": { ""name"": ""avg"", ""args"": [durationcolumnnolookup(""column"")], ""aggregate"": [""avg"", u""{column}"", none], ""result_type"": ""duration"", }, ""sum"": { ""name"": ""sum"", ""args"": [durationcolumnnolookup(""column"")], ""aggregate"": [""sum"", u""{column}"", none], ""result_type"": ""duration"", }, </desc> <cmt> sum() only works for duration fields </cmt> <cmt> avg() only works for duration fields </cmt>",sum() and avg() aggregation functions only work on fields of type duration
1712,"<desc> >>> import mxnet as mx >>> x=mx.nd.array([[1,2], [3,4], [5,6]]) >>> x <ndarray 3x2 @cpu(0)> >>> idx=mx.nd.array([[0,1],[1,2]]) >>> idx <ndarray 2x2 @cpu(0)> >>> mx.nd.take(x,idx) <ndarray 2x2x2 @cpu(0)> >>> >>> >>> idx=mx.nd.array([[0,3],[-1,-2]]) >>> >>> mx.nd.take(x,idx, axis=1, mode='wrap') <ndarray 3x2x2 @cpu(0)> please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> fix doc of take operator </cmt>",fix document for take operator
1713,"<desc> this pull request extends the definition of the box class to allow possibly unbounded boxes. current implementation currently, a box object is specified by the cartesian product of closed, bounded intervals, but it is possible to instantiate a box object with unbounded intervals. for example, nonnegative_orthant = box(low=0., high=np.inf, shape=(5,)) is legal code. in addition to the constructor accepting this description, the contains, to_jsonable, from_jsonable, __repr__, and __eq__ methods are compatible with such instances. the above code is incompatible with the sample method, however. it raises an overflowerror on nonnegative_orthant because the current approach involves sampling a uniform distribution over the region specified by the box. this is a reasonable choice for compact regions, but impossible for unbounded ones. proposed changes this pull request modifies box to allow cartesian products of intervals of the form [a,b], (-oo,b], [a,oo), and (oo,oo). as i mentioned above, no changes were needed to the majority of methods. the sample method is modified to sample according to the form of each interval: (-oo, b]: (reflected and shifted) exponential distribution, [a, oo): (shifted) exponential distribution, (-oo,oo): normal distribution. these distributions are available from the seed associated with each instance of the class. the choices are, in a sense, natural. on the other hand, they are also arbitrary. if folks here strongly prefer correctly supported distributions as alternatives to these choices, i'm happy to adopt them. the second change is to include an is_bounded method. this function takes a keyword parameter manner (default is ""both"") and returns whether the box is bounded according to manner. that is, is_bounded(manner=""below"") returns whether the box is bounded from below, is_bounded(manner=""above"") returns whether the object is bounded from above, and is_bounded(manner=""both"") returns whether the object is bounded from both above and below. if one interval in the cartesian product is unbounded (below or above, respectively), the entire box is said to be unbounded (below or above, respectively). any other value for manner raises a valueerror. the third change is to provide descriptions for when the assert statements fail in the constructor method. presently, not all of the assert statements come with descriptions of the failure. test cases have been added for unbounded box instances in the relevant test file. there are also no visible changes to the behavior of box instances whose endpoints are all bounded, although the internals of the sample method have been modified, so this should not break existing use cases. rationale for the change some of my research involves mdps with noncompact state/action spaces. classical problems, including inventory control, naturally have unbounded states and actions. while in practice it is usually possible to simply choose large endpoints and simulate the problems in this fashion, i have found ""large"" to be a relative quantity, and i like adhering to realistic models for simulating problems. this change will allow myself and others to experiment with unbounded state/action spaces without concern about triggering undefined corner cases. for example, it will allow random agents to be defined on these problems in the same way they are for others. </desc> <cmt> added support for unbounded box endpoints. </cmt> <cmt> documentation and code cleanup. </cmt> <cmt> fixed some of the logic of upper bounded versus lower bounded spaces. </cmt> <cmt> included unbounded box instances for the original tests. </cmt> <cmt> unbounded box </cmt> <cmt> removed unnecessary attribute in the box class. </cmt>",extending the box class to allow possibly unbounded boxes
1714,"<desc> designed a replacement pcb for my northgate omnikey keyboard.  add support for omnikeyish pcb based keyboards. custom local dynamic macro implementation used for that keyboard. didn't like the design limitations inherent to the core dynamic macro implementation, so made a keyboard local fork that supports more than two! macro keys. it has optional eeprom macro storage support. no omnikeyish keyboard support? my code follows the code style of this project. (your opening brace location is heresy, but ran clang format on the code) i have read the contributing document. </desc> <cmt> add omnikeyish keyboard support. </cmt> <cmt> remove out of date comment </cmt> <cmt> pcb rev 1.1 moved row5's pin to e6, because the teensy++ hangs an onboard led off d6. </cmt> <cmt> move string.h include to .c file </cmt> <cmt> add pcb kicad link. </cmt> <cmt> add info.json </cmt> <cmt> move macro programming to numlock's keyposition, the most useless key on the post model m layout. force numlock enabled on host at init time, so you're not stuck without a numpad (hopefully) </cmt> <cmt> make the macro blink function toggle leds from their previous state. </cmt> <cmt> use incorrect but code style compliant opening curly bracing style. </cmt>",omnikeyish - a replacement pcb for the northgate omnikey family
1715,"<desc> fixes pdf in #1049 required lots of intermediate fixes/improvements (such as better error/message handling), but the critical ones are: translatefont() in evaluator.js setfont() in canvas.js handling of spaces when reading font matrix stream in fonts.js interestingly these are all unrelated, but equally critical for #1049... </desc> <cmt> fix worker message, better error handling </cmt> <cmt> improved error handling/message </cmt> <cmt> more robust fontmatrix parsing, error checking </cmt> <cmt> clarifying variable role </cmt> <cmt> nit </cmt> <cmt> setfont() supports negative size, closes #1049 </cmt> <cmt> lint </cmt>","fontmatrix parsing fix, setfont() supports negative sizes"
1716,"<desc> update jenkins buildsteps for m1 platform m1 target osx builds jenkins job created (thanks @kambala-decapitator) and built. requires other patches n/a currently. eventually we'll have apple silicon build targets bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [jenkins] update macos-arm64 jenkins buildsteps devaultenv </cmt> <cmt> currently our jenkins agents only support xcode 12.4 (os catalina) </cmt> <cmt> [tools/depends][buildsteps] macos-arm64 build kodi/addons build steps </cmt> <cmt> [tools/depends][packaging] remove hardcoded intel string </cmt> <cmt> [tools/depends][target] enable pythonmodules for apple silicon </cmt>",macos m1 buildsteps and minors
1717,<desc> i hereby agree to the terms of the cla available at:  now clickhouse-keeper supports zookeeper-like digest acls. </desc> <cmt> initial implementation </cmt> <cmt> working test </cmt> <cmt> more correct implementation </cmt> <cmt> fixup acl </cmt> <cmt> superdigest support </cmt> <cmt> add tests </cmt>,add acl system to keeper
1718,"<desc> what did you implement: this pr adds usage plan to amazon api gateway. closes #2450 closes #2741 how did you implement it: by adding aws::apigateway::usageplan and aws::apigateway::usageplankey to amazon api gateway build flow. how can we verify it: create a service with api key(s) and verify that deployment creates usage plan and usage plan key(s) to cf stack and aws. todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add usage plan to api gateway </cmt> <cmt> add ref to api stage api id </cmt> <cmt> fix usage plan and usage plan key naming, create api gateway stage with cloudformation, disassociateusageplan on remove </cmt> <cmt> add tests for disassociating stage from usage plan </cmt> <cmt> add quota and throttle to usage plan </cmt> <cmt> add tests for usageplan naming, run describe stack resources and get usage plan parallel on remove </cmt> <cmt> add usage plan and resource names to documentation </cmt> <cmt> add usageplan config to serverless.yml.md file </cmt> <cmt> refactor disassociateusageplan to be moved to api gateway plugin </cmt> <cmt> re-enable api keys integration tests </cmt> <cmt> adding stage in deployment resource </cmt> <cmt> removed naming refs for stage resoruce </cmt>",follow up - add usage plan to amazon api gateway
1719,"<desc> i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> add in-memory store client </cmt> <cmt> add part code </cmt> <cmt> add part code </cmt> <cmt> add part code </cmt> <cmt> add part code </cmt>",[gcs]add in-memory gcs table storage
1720,"<desc> adds a new endindent parameter to adjust the the dividers from the end as well. i decided to not update indent to startindent, as that would be a breaking change. edit: i would appreciate some feedback on this, since startindent is much clearer, but changing the api would also result a breaking change. i also took this opportunity to update the divider docs, since i tried to create vertical lines with it and do not think it can actually be used that way. edit: this also fixes verticaldivider to now properly add indents at the top, not at the start related issues #21244 i added the following tests: test for divider's indent and endindent test for verticaldivider's indent and endindent before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> implement endindent </cmt> <cmt> add endindent to verticalpadding </cmt> <cmt> fix typo from rightindent to endindent </cmt> <cmt> added horizontal divider indent test </cmt> <cmt> add vertical divider tests, update docs </cmt> <cmt> revert doc explanations from physical pixel to device pixel </cmt> <cmt> improve divider indent test fidelity </cmt>",add endindent property to divider and verticaldivider
1721,<desc> resolves todo to add a panic guard to dap handlers; recovery will log and error and send back an internal error response to the client. this pulls in (and vendors) a newer version of google/go-dap </desc> <cmt> panic guard for dap request handling </cmt> <cmt> use getseq </cmt> <cmt> re-vendor new version of go-dap </cmt> <cmt> remove comment </cmt> <cmt> update error message </cmt>,add panic guard to dap handlers
1722,<desc> all these changes has been made according to switchbrew website. add ipc commandtype : invalid as cmd number 0 legacyrequest as cmd number 1 legacycontrol as cmd number 3 add some hid functioninfo : add functions useful for 4.0.0+ and 5.0.0+ </desc> <cmt> add some commandtype </cmt> <cmt> add some hid functioninfo </cmt> <cmt> add some other hid functioninfo </cmt>,add ipc commandtype & some hid functioninfo
1723,"<desc> a few places where string formatting is modernized removed remaining # cython: profile=false comments the main (and possible controversial) thing done here is changing some functions to use type-hint syntax.  the affected functions are all currently cpdef, but are never used in cython, so should only be def.  but cython's syntax does not allow for specifying a return type in def functions, so this is the cleanest way to remove unnecessary cpdef without losing typing.  (some discussion of this occurred in #22180) </desc> <cmt> remove cython:profile annotations </cmt> <cmt> uncdef functions not used from within cython </cmt> <cmt> un-cpdef functions that dont need to be </cmt> <cmt> change fickle syntax </cmt> <cmt> modernize string formatting </cmt>","more cython cleanups, with bonus type annotations"
1724,"<desc> this pr adds the following feature:  changes: added helper function get_release_sessions_time_bounds to src/sentry/snuba/sessions.py to fetch the first session timestamp and the last session timestamp for a specific (org_id, project_id, release and environments) combination added keys sessions_lower_bound and sessions_upper_bound to the response of organisationsreleasemetaendpoint corresponding to the sessions bound added tests </desc> <cmt> added node14js support for lambda integration </cmt> <cmt> added snuba get_release_sessions_time_bounds function + tests </cmt> <cmt> added logic that handles when no sessions exist in release health </cmt> <cmt> added documentation to get_release_session_time_bounds </cmt> <cmt> added the sessions release bounds to the organization meta endpoint </cmt>",add release sessions time bounds
1725,<desc> it's difficult to write a css selector for sidebar items in pendo because we don't have ids and class names are auto-generated. this pr adds an id to the sidebar items which should be unique as i am prepending with sidebar-item. </desc> <cmt> adds default data-test-id for sidebar item </cmt> <cmt> use id instead </cmt>,adds id for sidebar item
1726,"<desc> fixes #3502, it looks there's a malformed call to the function that returns api throttling errors. </desc> <cmt> rebase from master (#1) </cmt> <cmt> rebase 2 (#2) </cmt> <cmt> rebase correctly </cmt> <cmt> fixing call to function in dynamodb listener </cmt> <iss> no attribute 'error_response_throughput' when using dynamodb-error-probability </iss>",fix dynamodb listener to properly look up throttling configuration
1727,"<desc> combines #5253 and #5103. this allows one to specify the maximum number of row processed in in a call. the new functionality allows for reading more complex data formats. for instance, multiple calls can be used to read in multiple arrays stored in a single file. closes #5084. closes #5093. </desc> <cmt> enh:add keyword nrows to genfromtxt. </cmt> <cmt> this allows one to specify the maximum number of row processed in </cmt> <cmt> in a call. the new functionality allows for reading more complex </cmt> <cmt> data formats. for instance, multiple calls can be used to read in </cmt> <cmt> multiple arrays stored in a single file. </cmt> <cmt> closes #5084. </cmt> <cmt> closes #5093. </cmt> <cmt> enh: genfromtxt: change 'nrows' to 'max_rows'. </cmt> <iss> hope genfromtxt function add nrows keyword </iss>",enh:add keyword max_rows to genfromtxt.
1728,"<desc> fixes #26779 fixes #26780 this pr aligns the diagnostic reporting for empty files with the behavior described in the handbook: note that starting with 3.0, it is no longer an error to have an empty files array if you have at least one reference in a tsconfig.json file. specifically, the following 3 issues are addressed by this pr: the command-line parser logs errors whenever files is empty, regardless of the value of references the configfileparsingdiagnostics are not being passed to createprogram from buildsingleproject, meaning any parsing errors will go unreported for the queue of projects being processed in buildallprojects, errors will go unreported if the for-loop iteration is continued because the errors are reported in buildsingleproject, which is at the end of the loop iteration unit tests are included to account for the new behavior. </desc> <cmt> fix diagnostic reporting for empty files in tsconfig </cmt> <cmt> add newline to bottom of tsconfig files </cmt>",fix empty files diagnostics reporting
1729,"<desc> after merging the binaries together, the logic for handling shutdowns got a little muddled between the worker and the watcher. this adds an explicit clear on the pointer to the shutdown routine, as well as provides assurances that the watcher will be the only process to execute the shutdown logic. this partially addresses #3619 in that the service now correctly exits and does not emit any error level logging, however the service still technically crashes as a dump is generated at the destruction of the dispatcher @theopolis hope you don't mind that i cherry-picked your commit <3 </desc> <cmt> bug: updating windows service debug printing to use std::string </cmt> <cmt> worker: clear shutdown method after calling once </cmt> <cmt> worker: small nits on worker mutex </cmt> <cmt> worker: preventing call of shutdown handler if isworker </cmt>",shutdown safely on windows only if not worker
1730,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: yaireo/tagify@c74bcf4 yaireo/tagify@c8d1220 v4.0.0 </desc> <cmt> missing param identifier in jsdoc </cmt> <cmt> data passed with suggestionclick hook </cmt> <cmt> getcleanvalue() </cmt> <cmt> bump major version 4.0 </cmt>,"update docs, bump major version 4.0"
1731,"<desc> closes #24011 tests added / passed  (see  passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> bug: gh24011 </cmt> <cmt> tst: gh24011 </cmt> <cmt> cln: remove trailing spaces & compound operations </cmt> <iss> rich comparisons of timestamps raise typeerror instead of returning notimplemented </iss>",gh24011 - rich comparisons of timestamps now return notimplemented
1732,<desc> #13127 memory leaks no no nothing </desc> <cmt> clear compilation queues to reduce memory usage </cmt> <cmt> move defineremovedmoduletemplates into separate function as it leaks memory in the feedback vectors </cmt> <cmt> unreference some of the intermediate data when unserializing </cmt>,reduce memory usage and fix memory leaks
1733,<desc> somehow github did not update the previous pr #38994 so here's a new one. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  the package does commons default export and i got misled by the tslint error. following numerous other packages i disabled that lint rule. also switched to the default typing of fetch as the package does not really import node-fetch </desc> <cmt> fix: sparql-http-client should use built-in fetch </cmt> <cmt> fix: disable tslint rule to accommodate for commonjs default export </cmt> <cmt> revert default export </cmt> <cmt> change export syntax </cmt>,sparql-http-client updated to use correct exports
1734,<desc> description: final piece in the context puzzle: propagate context through automations and scripts. checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> add context to script helper </cmt> <cmt> update script component </cmt> <cmt> add context to automations </cmt>,add context to scripts and automations
1735,"<desc> added global versions of the references graph and of the data graph. the other kind of graphs (except the callgraph, which was already made) do not need a global version imho, so now i'll focus on finishing correct argument handling. also updated the ag? help for the new commands. </desc> <cmt> added aga global graph and agr global graph </cmt> <cmt> added r_str_trunc_ellipsis() to truncate node titles too long </cmt> <cmt> removed comments and fixed r_agraph_get_node() </cmt> <cmt> updated ag? help </cmt> <cmt> fixed segfault in r_str_trunc_ellipsis() </cmt> <cmt> fix agc* command </cmt> <cmt> fix callgraph bug not resetting is_callgraph </cmt>",added 'agr' and 'aga' global references and data references graphs
1736,"<desc> i hereby agree to the terms of the cla available at:  allow to create html report from purest junit xml report. detailed description / documentation draft: to be used in ci. by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. </desc> <cmt> add junit_to_html_util </cmt> <cmt> better colors </cmt> <cmt> fix integration/test_distributed_ddl/test_replicated_alter </cmt> <cmt> output call duration in junit report </cmt> <cmt> fix check-include </cmt> <cmt> update readme in intergration </cmt> <cmt> fix check-ungrouped-includes.sh </cmt> <cmt> better </cmt>",add junit to html util
1737,"<desc> i have confirmed that the project have met all the requirements. this is my 4th project on this page. thanks for your work to keep everything so organized! please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks!  note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added godoc link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> merge remote-tracking branch 'avelino/master' </cmt> <cmt> add gleam </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> sync </cmt> <cmt> adding vasto </cmt>","adding vasto, a distributed key value store."
1738,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff removed some unused variables, added some fixtures for dataframes used in test_pairwise.py, and utilize more pytest.mark.parameterize </desc> <cmt> clean test_timeseries_window </cmt> <cmt> cln: more pytest idioms to pandas/tests/window </cmt>",more pytest idioms in pandas/tests/window
1739,"<desc> added proper solution to the guide for the problem apply a style until a condition is met with @while , this is hopefully no longer a stub i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. closes #35088 </desc> <cmt> guide: added solution @while sass </cmt> <cmt> added proper solution to the guide for the problem apply a style until a condition is met with @while, this is no longer a stub </cmt> <cmt> guide: added solution while sass </cmt> <iss> sass: apply a style until a condition is met with @while: add proper guide </iss>",added solution in guide to while sass problem
1740,<desc> fixes #758 . support insert without columns. support insert without columns and generating generated-key. add some tests and expected files for this usage. modify some tests. </desc> <cmt> support insert without columns. </cmt> <cmt> modify javadoc and remove the default value. </cmt> <cmt> add expected xml for insert testing. </cmt> <cmt> modify primary key type due to generated key test. </cmt> <cmt> add expected xml for db testing and modify sharding rule for db testing. </cmt> <cmt> add expected xml for ms testing and modify sharding rule for ms testing. </cmt> <cmt> add expected xml for m-only testing and modify sharding rule for m-only testing. </cmt> <cmt> add expected xml for dbtbl testing and modify sharding rule for dbtbl testing. </cmt> <cmt> delete some testing xml and testing functions. </cmt> <cmt> rewrite testing functions. </cmt> <cmt> add some tests. </cmt> <cmt> add some tests. </cmt> <cmt> add some tests. </cmt> <cmt> delete some expected testing xml. </cmt> <cmt> delete some expected testing xml. </cmt>,the second usage of metadata
1741,<cmt> improve docs about converting datetime.timedelta to scalars </cmt> <cmt> bpo-36097: use only public c-api in the_xxsubinterpreters module (adding as necessary). (#12003) </cmt> <cmt> improve docs about converting datetime.timedelta to scalars </cmt> <cmt> improve docs about converting datetime.timedelta to scalars </cmt> <cmt> improve docs about converting datetime.timedelta to scalars </cmt>,improve docs about converting datetime.timedelta to scalars.
1742,"<desc> when the user encounters an error, if running with --verbose we can print out the sessionid so that if they decide to file a bug, they can provide the session id so that we can look up the telemetry to help us investigate and hopefully unblock them more easily. microsoft reviewers: open in codeflow </desc> <cmt> print out sessionid when erroring out in run-windows so people can choose to let us know when filing bugs </cmt> <cmt> change files </cmt>",print out sessionid if verbose
1743,"<desc> original pull-request #31528 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> remove partial_merge_join_optimizations </cmt> <cmt> this option is redundant because optimization is controlled by partial_merge_join_left_table_buffer_bytes </cmt> <cmt> disable partial_merge_join_left_table_buffer_bytes due to bug </cmt>",disable partial merge join left table buffer bytes
1744,"<desc> the new h2olog raw is designed to trace all the usdt probes defined in h2o-probes.d as well as quicly-probes.d. introducing a breaking interface and behavior changes: h2olog traces raw usdt events in a json-lines format h2olog -h traces http-level events in a varnishlog-style log format it also removes quicly-id to h2o-id conversions in http/3 handling (ba5177f), which is theoretically redundant,  making it hard to handle http/1 and http/2 in the same way as http/3,  and introducing extra complexity as well. tools using h2olog outputs can handle this kind of conversion, anyway. </desc> <cmt> h2olog: remove h2o conn id to quicly conn id conversion </cmt> <cmt> it's just redundant and hard to maintain </cmt> <cmt> handle all the usdt probes in the ""h2o"" provider </cmt> <cmt> h2olog: rename ""quic"" mode to ""raw"" mode </cmt>",trace all the usdt probes in h2o-probes.d as well as quicly-probes.d
1745,"<desc> closes #6535 this is a redo of a previous pull request #6814 under a github account that has the ""allow edits by maintainers"" option. i have reviewed my changes in staging (look for the deploy-to-heroku link in your pull request, then click view deployment). for content changes, i have completed the self-review checklist. </desc> <cmt> update creating-a-strong-password.md </cmt> <cmt> added reference to keeper password manager, a soc2 and iso27001 certified product that competes with lastpass and 1password, over 15 million users, zero-knowledge security. </cmt> <cmt> update configuring-two-factor-authentication.md </cmt> <cmt> added reference to keeper password manager, a soc2 and iso27001 certified product that offers totp storage similar to lastpass and 1password, over 15 million users, zero-knowledge security. </cmt> <iss> improvement: add keeper as a suggested service to a couple more articles </iss>",added keeper to list of mentioned password managers and totp storage
1746,"<desc> bug fixes others the framework will throw an error when user load custom c++ op from different modules, the pr fix this bug, so now user can load multiple modules of custom c++ op </desc> <cmt> fix a bug : can't load more than one custom op module </cmt> <cmt> fix a bug : can't load more than one custom op module </cmt>",can't load multiple modules of custom c++ op
1747,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. </desc> <cmt> update local my own fork </cmt> <cmt> added missing method sync() </cmt> <cmt> fix tabs </cmt>,add missing sync method to reveal
1748,"<desc> hi raspberry pi team, i've backported some fixes and improvements to the smsc95xx ethernet driver for the r-pi 3.6.y kernel, please pull. these patches make the ethernet device consume less power during system suspend, or alternatively allow the user to enable wake on lan via magic packet. these patches have all been accepted upstream already for the 3.7.0-rc family. </desc> <cmt> smsc95xx: sleep before read for lengthy operations </cmt> <cmt> during init, the device reset is unexpected to complete immediately, </cmt> <cmt> so sleep before testing the condition rather than after it. </cmt> <cmt> smsc95xx: remove unnecessary variables </cmt> <cmt> removes unnecessary variables as smsc95xx_write_reg takes its </cmt> <cmt> value by parameter.  early versions passed this parameter by </cmt> <cmt> reference. </cmt> <cmt> also replace hardcoded interrupt status value with a #define </cmt> <cmt> smsc95xx: check return code from control messages </cmt> <cmt> this patch adds additional checks of the values returned by </cmt> <cmt> smsc95xx_(read|write)_reg, and wraps their common patterns </cmt> <cmt> in macros. </cmt> <cmt> smsc95xx: fix resume when usb device is reset </cmt> <cmt> this patch fixes an issue on some systems, where after suspend the </cmt> <cmt> link is re-established but the ethernet interface does not resume. </cmt> <cmt> smsc95xx: enable power saving mode during system suspend </cmt> <cmt> this patch enables the device to enter its lowest power suspend2 </cmt> <cmt> state during system suspend, instead of staying up using full power. </cmt> <cmt> patch updated to not add two pointers to .suspend & .resume. </cmt> <cmt> patch updated to replace bug_on with warn_on_once and return. </cmt> <cmt> smsc95xx: add wol magic packet support </cmt> <cmt> this patch enables wake from system suspend on magic packet. </cmt> <cmt> patch updated to replace bug_on with warn_on_once and return. </cmt> <cmt> smsc95xx: fix tx checksum offload for big endian </cmt> <cmt> f7b2927 introduced tx checksum offload support for smsc95xx, </cmt> <cmt> and enabled it by default. this feature doesn't take </cmt> <cmt> endianness into account, so causes most tx to fail on </cmt> <cmt> those platforms. </cmt> <cmt> this patch fixes the problem fully by adding the missing </cmt> <cmt> conversion. </cmt> <cmt> an alternate workaround is to disable tx checksum offload </cmt> <cmt> on those platforms. the cpu impact of this feature is very low. </cmt>",smsc95xx updates for raspberry pi 3.6.y
1749,"<desc> just some initial work, i think we should modify device api to have the ability to specify blending ops instead of hard code it </desc> <cmt> ggui transparency prototype </cmt> <cmt> particles </cmt> <cmt> blend func </cmt>",ggui initial alpha transparency support
1750,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).   increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. </desc> <cmt> dolog accepts a label </cmt> <cmt> use promiselike instead of promise in frompromise functions </cmt> <cmt> bacon accepts promises/a+ -compatible promises that have just the .then </cmt> <cmt> function, so the full promise type is not actually required. </cmt> <cmt> this also removes the need for the jqueryxhr special case, because </cmt> <cmt> jqueryxhr is compatible with promiselike. </cmt>","dolog accepts a label, use promiselike in frompromise"
1751,<desc> issue: n/a add react-specific readme update triconfig docs add pointer to ember docs n/a </desc> <cmt> update triconfig instructions for sb docs frameworks </cmt> <cmt> add react-specific sb docs docs </cmt> <cmt> sb docs point to ember framework docs </cmt>,sb docs readme for react and triconfig
1752,<desc> this pr adds details from  it also removes machine learning prs from the list that were already shipped in 7.6.x releases. </desc> <cmt> [docs] adds ml-cpp prs to release notes </cmt> <cmt> [docs] removes released ml prs from release notes </cmt>,add ml-cpp prs to 7.7 release notes
1753,"<desc> in trielookuptable the default destructor will use call-stack to recursively find all unique_ptr and reset them. if the string added to trie is very long, for example, with 40000 characters, the trie will have a depth of 40000 and call-stack will encounter stack-overflow. added a constraint length<=1000 for route.prefix().size(). risk level: low passed a crashed test case reported by network_readfilter_fuzz_test. / / / </desc> <cmt> added a test case with long string for trie, and added destructor of the </cmt> <cmt> trie. </cmt> <cmt> set string to be const. </cmt> <cmt> added a comment for destructor </cmt> <cmt> added a helper function to makecode clearer. </cmt> <cmt> refined the comments </cmt> <cmt> refined the comments </cmt> <cmt> added regression test for fuzzer </cmt> <cmt> fixed issue 24558 by constrain the length of route.prefix.length() </cmt> <cmt> restore a empty line </cmt> <cmt> removed an empty line </cmt> <cmt> added a new line </cmt>",added a constraint for route.prefix().size()
1754,"<desc> here we split parser.rs (~7.9 kloc) into more reasonably sized files (all < 1.8 kloc): ./src/libsyntax/parse/ parser.rs parser/ pat.rs expr.rs stmt.rs ty.rs path.rs generics.rs item.rs module.rs closes #60015. r? @petrochenkov </desc> <cmt> parser: split into expr.rs </cmt> <cmt> parser: split into pat.rs </cmt> <cmt> parser: split into {item,module}.rs </cmt> <cmt> parser: split into {ty, path}.rs </cmt> <cmt> parser: move parse_ident_or_underscore into item.rs </cmt> <cmt> parser: move parse_fn_block_decl into expr.rs </cmt> <cmt> parser: move into stmt.rs </cmt> <cmt> parser: move into generics.rs </cmt> <cmt> parser: {check,expect}_lifetime into ty.rs </cmt> <iss> `libsyntax/parse/parser.rs` became too big for github </iss>",refactor parser.rs into reasonably sized logical units
1755,"<desc> this adds disposition, referrer and postbody to the details object passed to the window open handler. builds on #28513, which fixes a number of postbody-related issues. closes #28380. npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: added disposition, referrer and postbody to the details object passed to the window open handler registered with setwindowopenhandler. </desc> <cmt> fix: invoke the window open handler for _blank links </cmt> <cmt> feat: add disposition to setwindowopenhandler details </cmt> <cmt> fix: pass postdata to new-window event </cmt> <cmt> postdata can be heterogeneous </cmt> <cmt> fix type of postbody </cmt> <cmt> fix type of uploadfile and uploadrawdata to be discriminated unions </cmt> <cmt> exclude the empty string from additionalfeatures </cmt> <cmt> add a test </cmt> <cmt> add postbody and referrer to setwindowopenhandler args </cmt> <iss> [feature request]: add {options, disposition, additionalfeatures, referrer, postdata} to setwindowopenhandler </iss>",add more info in setwindowopenhandler details
1756,"<desc> what do these changes do? when we are testing fo, we will kill raylet using ""kill -9"". we found there are many core dump files from java. we'd better remove the code that causes jni crash. instead, we could throw java exceptions. for one thing, it is not easy to debug core dump files. for another, jni crash will crash the whole jvm program. n/a </desc> <cmt> remove ray_check in jni </cmt> <cmt> try to add mvn test to test the exception. </cmt> <cmt> refine </cmt>",remove ray_check from jni code
1757,"<desc> these are almost all cut/paste moving tests to the appropriate places.  two exceptions: some ""todo: de-duplicate this with that"" notes (mostly to myself) testtimedeltaindexarithmetic.test_numeric_compat badly needed to be split into more specific tests, so that is done here. </desc> <cmt> put timedelta index/series/scalar tests in the right places </cmt> <cmt> centralize arithmetic and comparison tests </cmt> <cmt> some de-duplication </cmt> <cmt> update test based on fixed index*series behavior </cmt> <cmt> comment and whitespace cleanup </cmt>",centralize and de-duplicate comparison and arith tests
1758,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. </desc> <cmt> fix export to reflect updates to node http package </cmt> <cmt> bugfix: handle null error case in ps-tree </cmt>,account for null errors in ps-tree
1759,"<desc> fixes sr-6502 | rdar://problem/35773760. </desc> <cmt> keypaths: put an override shim on swift_getkeypath. </cmt> <cmt> this will let future compilers that support new key path features backward-deploy logic for interpreting new kinds of key path patterns. </cmt> <cmt> keypaths: take a bit for encoding ""let""-ness of stored properties. </cmt> <cmt> if we know a key path component can be accessed as a stored property, then we should also know whether it's a let or not, so it should be safe to encode this in the key path pattern. stage this change in by changing the number of bits used to store in-line offsets, fixing up the parts of the key path implementation that assumed that it took up the entire payload bitfield. </cmt>",preserve 'let'-ness of stored properties in key paths.
1760,"<desc> closes #12703 this implementation stores de filter values in the localstorage and will load the last used values as the default filter values. in addition, a new action was added to allow quick cleaning of the input / filter values. </desc> <cmt> store default filters on the current chats template. </cmt> <cmt> fix lint erros. </cmt> <cmt> fix agents default filter value. </cmt> <iss> default filter on opened chats only instead of all chats in window ""current chats"" </iss>",save default filters in the omnichannel current chats list
1761,<desc> the multiproducersequencer currently has contention problems when many threads try to get the next sequence. it is not necessary to loop trying to compareandset the new sequence number. the producer can allocate sequence numbers upfront as long as it does not return when the consumer has not consumed the slot yet. the up-front allocation is valid because the call to gethighestpublisedsequence is the one that will tell the consumer that a slot has been published by the publisher. note: this pull request was first issued as #355 (on the older version). this new pull request is based off the master branch. i've also added the multiproducersingleconsumer jmh benchmark test. </desc> <cmt> increase multiproducersequencer performance on getting next sequence </cmt> <cmt> number </cmt> <cmt> remove unsafe operation and add jmh test for multiproducersequencer </cmt>,increase multiproducersequencer performance on getting next sequence (master branch)
1762,<desc> fixes #4781. </desc> <cmt> open comment </cmt> <cmt> merge </cmt> <cmt> add start index and stop index for literal-expression </cmt> <cmt> format code </cmt> <cmt> add start index and stop index </cmt> <cmt> merge </cmt> <cmt> add start index </cmt> <cmt> merge </cmt> <cmt> alter index </cmt> <cmt> add index </cmt> <cmt> finish start index and stop index </cmt> <cmt> merge </cmt> <iss> add start-index and stop-index assertion for literalexpressionsegment </iss>,add start-index and stop-index for literalexpressionsegment
1763,"<desc> this pr adds the option to use split_common for helix keyboard compilation. compiling as follows will compile with the current helix custom code. make helix:default make helix/pico:default compiling as follows will compile with split_common code. make helix/rev2/sc:default make helix/pico/sc:default you can also specify the use of split_common by adding the following in rules.mk for each keymap: split_keyboard = yes all keymaps have been tested and verified to work. what is split_common different from current helix custom code due to the current limitation of split_common, the current layer information cannot be obtained on the slave side, so the layer information cannot be displayed correctly on oled etc. split_common scans the matrix a bit slower. scan cycle/second helix custom code 1590 split_common 1190 keymaps source file compatibility all keymaps 'keymap.c' and 'config.h' are unchanged. there is no need to change. the 'rules.mk' of all keymaps except 'xulkal' have not changed. in the 'xulkal' keymap rules.mk, split_keyboard = yes was added to always use the split_common code, and the following code in 'users/xulkal/custom_oled.c' was removed. #if keyboard_helix_rev2 extern uint8_t is_master; bool is_keyboard_master(void) { return is_master; } #endif all compile option patterns build helix/pico (helixpico) with helix current codes $ make helix/pico:key_map $ make helix/pico/back:key_map $ make helix/pico/under:key_map build helix/rev2 (helix or helix beta) with helix current codes $ make helix:key_map $ make helix/rev2/back:key_map $ make helix/rev2/under:key_map $ make helix/rev2/oled:key_map $ make helix/rev2/oled/back:key_map $ make helix/rev2/oled/under:key_map build helix/pico (helixpico) with split_common codes $ make helix/pico/sc:key_map $ make helix/pico/sc/back:key_map $ make helix/pico/sc/under:key_map build helix/rev2 (helix) with split_common codes $ make helix/rev2/sc:key_map $ make helix/rev2/sc/back:key_map $ make helix/rev2/sc/under:key_map $ make helix/rev2/sc/oled:key_map $ make helix/rev2/sc/oledback:key_map $ make helix/rev2/sc/oledunder:key_map my code follows the code style of this project. i have read the contributing document. </desc> <cmt> is_master, has_usb() move to rev2.[hc] </cmt> <cmt> do recent helix/rev2 changes to helix/pico as well. </cmt> <cmt> helix/pico/matrix.c: remove 'is_master' </cmt> <cmt> helix/pico/pico.c: add 'is_master' </cmt> <cmt> helix/pico/pico.h: add 'has_usb()' macro </cmt> <cmt> helix/pico/split_util.c: remove 'setup_handedness()' 'has_usb()', add 'is_helix_master()' etc </cmt> <cmt> add helix=scan option into {rev2/pico}/local_features.mk </cmt> <cmt> made debug_matrix_scan_rate easy to use. </cmt> <cmt> changed rules.mk to link ""helix/local_drivers/ssd1306.c"" only when oled_enable = yes. </cmt> <cmt> added option to use split_common for helix/rev2, helix/pico keyboard. </cmt> <cmt> how to build: </cmt> <cmt> ### build helix/pico (helixpico) with helix current codes </cmt> <cmt> $ make helix/pico:key_map </cmt> <cmt> $ make helix/pico/back:key_map </cmt> <cmt> ### build helix/rev2 (helix or helix beta) with helix current codes </cmt> <cmt> $ make helix:key_map </cmt> <cmt> $ make helix/rev2/back:key_map </cmt> <cmt> $ make helix/rev2/under:key_map </cmt> <cmt> $ make helix/rev2/oled:key_map </cmt> <cmt> $ make helix/rev2/oled/back:key_map </cmt> <cmt> $ make helix/rev2/oled/under:key_map </cmt> <cmt> ### build helix/pico (helixpico) with split_common codes </cmt> <cmt> $ make helix/pico/sc:key_map </cmt> <cmt> $ make helix/pico/sc/back:key_map </cmt> <cmt> $ make helix/pico/sc/under:key_map </cmt> <cmt> ### build helix/rev2 (helix) with split_common codes </cmt> <cmt> $ make helix/rev2/sc:key_map </cmt> <cmt> $ make helix/rev2/sc/back:key_map </cmt> <cmt> $ make helix/rev2/sc/under:key_map </cmt> <cmt> $ make helix/rev2/sc/oled:key_map </cmt> <cmt> $ make helix/rev2/sc/oledback:key_map </cmt> <cmt> $ make helix/rev2/sc/oledunder:key_map </cmt> <cmt> add matrix_slave_scan_user() to helix/rev2/rev2.c, helix/pico/pico.h </cmt> <cmt> changed 'helix:xulkal' to always use split_common and removed ad hoc code. </cmt> <cmt> added the following line to 'helix/rev2/keymaps/xulkal/rules.mk': </cmt> <cmt> split_keyboard = yes </cmt> <cmt> removed the following ad hoc code from 'users/xulkal/custom_oled.c': </cmt> <cmt> #if keyboard_helix_rev2 </cmt> <cmt> extern uint8_t is_master; </cmt> <cmt> bool is_keyboard_master(void) { return is_master; } </cmt> <cmt> #endif </cmt> <cmt> helix: add split_common option </cmt>",helix add split common option
1764,<desc> update our bits for rnw 0.63 from 0.63.0 to 0.63.2. we get to remove some patching we added as it was cherry-picked into 0.63 upstream. (we keep the patching for anyone using rnw 0.63 with rn 0.63.0 or 0.63.1) microsoft reviewers: open in codeflow </desc> <cmt> integrate 0.63.2 </cmt> <cmt> change files </cmt>,integrate rn 0.63.2 into rnw 0.63
1765,"<desc> previously all webcontents related apis and ipc message handling were done by the nativewindow, this pr creates a new webcontents api that separate out those things out, making the web page related api and ipc api much more cleaner. </desc> <cmt> initial empty api_web_contents. </cmt> <cmt> move some apis from window to webcontents. </cmt> <cmt> add executejavascript method for webcontents. </cmt> <cmt> add getter for devtoolswebcontents. </cmt> <cmt> get webcontents on request. </cmt> <cmt> be safe on lifetime of webcontents. </cmt> <cmt> move webcontents events away from window. </cmt> <cmt> add destroyed event for webcontents. </cmt> <cmt> move loading events to webcontents. </cmt> <cmt> fix releasing the wrong renderer view. </cmt> <cmt> move navigator related apis to webcontents. </cmt> <cmt> add send for webcontents. </cmt> <cmt> make send and loadurl also supported methods of browserwindow. </cmt> <cmt> handle ipc messages in webcontents instead of browserwindow. </cmt> <cmt> separate the webcontents code in a new file. </cmt> <cmt> avoid using processid and routingid directly. </cmt> <cmt> :memo: add docs on webcontents. </cmt> <cmt> :memo: update docs of ipc module. </cmt>",separate out webcontents api to a new class
1766,"<desc> install and build the main repo once, and share that build output with other jobs (in the same workflow) that need it. i've combined the previous ""build"" and ""test"" jobs so that we only install our dev dependencies once. if the build and tests pass then the build output is uploaded as an artifact which other jobs can download. this change means that no other job (i.e. benchmarks) will run unless tests pass. depending on what you want that could be a feature or a bug  let me know what you think! i determine what the build output is by running npm pack to generate our npm tarball. then the build untars that file and uploads it's contents. i wanted to use npm pack to reuse the declaration of our build output from our package.json's files property. i don't upload the tarball directly cuz then each job that needed the output would have to download the artifact, untar it, and then shuffle the files around into their correct position in the repo. the approach done here means that other jobs that want to re-use the build output just download the artifact into the working directory (which is a clone of the preact repo) and the build files are already correctly placed for them. we could also upload the tarball if that's useful but i figured we just do that once we had a use for it. i removed the node_modules cache from the benchmarks jobs cuz it was consistently failing and just added a lot of duplication between the benchmarks. the npm ci command usually takes between 20s - 40s so i'm not going to sweat it now. we can look at the cache issue later if that becomes important/if there is interest. </desc> <cmt> combine build an test jobs </cmt> <cmt> upload build artifacts </cmt> <cmt> download build-output in benches instead of rebuilding </cmt> <cmt> list directory contents before and after benchmark </cmt> <cmt> remove failing node_modules cache in bench jobs </cmt> <cmt> don't upload tarball until we plan to do something with it </cmt> <cmt> update ci-master to match ci-pr </cmt>",share build output between action jobs
1767,"<desc> ensure all linting tests pass, see here for how to run them also adds a pre-commit check that errors in doc/source/reference/general_utility_functions.rst are synced with pandas/errors/__init__.py </desc> <cmt> doc: ensure all pandas.errors are documents in general_utility_functions.rst </cmt> <cmt> use ast to check for the errors </cmt>",ensure pandas warnings & exceptions are always documented in api docs
1768,"<desc> i've run the latest black with default args on new code. but there was a file (tests/_card_render.py) about which black complained, but this one isn't included in the changes. another small contribution to #37 . i am not so sure about the last two tests, because i couldn't exactly pinpoint what the traceback is supposed to do in those cases. also: i added a no cover statement. i noticed that when i add a print statement before the break, both the break and the print are reached according to coverage (which makes sense). when i remove the print, the break isn't reached anymore. not sure what happens there, might be a bug in pytest coveragepy? happy to make some changes / additions to this pr. let me know if you need or want it. thanks! edit: formatting and small change in wording </desc> <cmt> syntaxerror for traceback testing </cmt> <cmt> test for nested exceptions </cmt> <cmt> excluded line from coverage because of possible coverage bug </cmt> <cmt> exceptions in weird files </cmt> <cmt> blackify </cmt>",tests on traceback to 100% coverage
1769,"<desc> thank you for contributing to kubernetes/charts. before you submit this pr we'd like to    sunils-macbook-pro:charts sunilganatra$ helm lint stable/redis ==> linting stable/redis lint ok 1 chart(s) linted, no failures sunils-macbook-pro:charts sunilganatra$ helm package stable/redis successfully packaged chart and saved it to: /users/sunilganatra/charts/redis-1.1.7.tgz sunils-macbook-pro:charts sunilganatra$ helm install --name redis-build-infra1 --namespace build-infra1 --set servicetype=nodeport --set image=bitnami/redis:3.2.9-r2 --set persistence.path=/bitnami/redis --set securitycontext.isenabled=false stable/redis name:   redis-build-infra1 last deployed: wed jan 17 12:48:11 2018 namespace: build-infra1 status: deployed resources: ==> v1/persistentvolumeclaim name                      status   volume            capacity  access modes  storageclass  age redis-build-infra1-redis  pending  *******  2s ==> v1/service name                      type      cluster-ip     external-ip  port(s)         age redis-build-infra1-redis  nodeport  172.21.53.229  <none>       6379:32634/tcp  2s ==> v1beta1/deployment name                      desired  current  up-to-date  available  age redis-build-infra1-redis  1        1        1           0          2s ==> v1/pod(related) name                                       ready  status   restarts  age redis-build-infra1-redis-659fd95df5-zcj7v  0/1    pending  0         2s ==> v1/secret name                      type    data  age redis-build-infra1-redis  opaque  1     2s notes: redis can be accessed via port 6379 on the following dns name from within your cluster: redis-build-infra1-redis.build-infra1.svc.cluster.local to get your password run: redis_password=$(kubectl get secret --namespace build-infra1 redis-build-infra1-redis -o jsonpath=""{.data.redis-password}"" | base64 --decode) to connect to your redis server: 1. run a redis pod that you can use as a client: kubectl run --namespace build-infra1 redis-build-infra1-redis-client --rm --tty -i \ --env redis_password=$redis_password \ --image bitnami/redis:3.2.9-r2 -- bash 2. connect using the redis cli: redis-cli -h redis-build-infra1-redis -a $redis_password </desc> <cmt> updated to enable / disable securitycontext </cmt> <cmt> for dev environment securitycontext not required. so, added flag to enable or disable securitycontext. </cmt> <cmt> added isenabled for securitycontext </cmt> <cmt> updated key value name </cmt>",add enable flag for security context
1770,"<desc> backporting #47096 into v2.7. junos ansible version ansible 2.7.0.post0 (backport/2.7/47096 82830ac742) last updated 2018/10/17 10:04:58 (gmt -500) config file = none configured module search path = [u'/users/fxfitz/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/fxfitz/dev/ansible/lib/ansible executable location = /users/fxfitz/.pyenv/versions/ansible/bin/ansible python version = 2.7.15 (default, may 29 2018, 20:16:38) [gcc 4.2.1 compatible apple llvm 9.1.0 (clang-902.0.39.1)] n/a </desc> <cmt> fix junos terminal regex (#47096) </cmt> <cmt> fix junos stdout regex </cmt> <cmt> change at hing </cmt> <cmt> (cherry picked from commit fc341e01face3544c649b54015605f94597e069c) </cmt> <cmt> changelog: adds fragment for junos fix terminal </cmt> <cmt> prompt regex </cmt> <cmt> proper yaml formatting </cmt>",junos terminal regex prompt fix to v2.7
1771,<desc> improve zh-tw translation media/doc/for_chinese_translation.txt update more translation improve </desc> <cmt> [translation] improve zh-tw translation </cmt> <cmt> *modification of media/doc/for_chinese_translation.txt </cmt> <cmt> *[calc] [systeminfo] add chinese traditional translation </cmt> <cmt> *[write] [winfile] translation sync to wine </cmt> <cmt> *more translation improvement </cmt> <cmt> update for_chinese_translation.txt </cmt> <cmt> update for_chinese_translation.txt 2 </cmt> <cmt> chinese grammar lol. </cmt>,chinese traditional (zh-tw) translation improvement
1772,"<desc> speed improvements for zstd_btopt fixed bugs in bench.c </desc> <cmt> clock() is default timer for all platforms except windows </cmt> <cmt> cache literal prices for zstd_btopt </cmt> <cmt> bench.c: ignore directories from a file list for benchmark </cmt> <cmt> removed zstd_compressbegin_targetsrcsize </cmt> <cmt> introduced zstd_deafult_clevel for (compressionlevel<=0) </cmt> <cmt> bench.c: fixed rare compression and decompression speed bug </cmt> <cmt> concerns only big files with compression or decompression time longer </cmt> <cmt> than 100 seconds </cmt> <cmt> bench.c: force at least one compression and decompression loop </cmt> <cmt> fix for -i0 with small files </cmt> <cmt> zst_opt.h: minor compression speed improvement </cmt> <cmt> minor speed improvements 2 </cmt> <cmt> bench.c: block size has to be bigger than 32 bytes </cmt> <cmt> zstdcli.c: support for e.g. -b16k -b16m </cmt> <cmt> separation of lib/ into common/, compress/, decompress/, dictbuilder/, legacy/ </cmt> <cmt> introduced zstd_nocompress to generate decompressor only </cmt> <cmt> updated cmakelists.txt </cmt> <cmt> error functions moved to common/zstd_common.c </cmt> <cmt> introduced zstd_nodecompress to link only compressor </cmt> <cmt> fix for g++ compilation </cmt>",separation into compressor and decompressor
1773,"<desc> this adds to the docs a basic guide describing how to use ansible and vagrant together. i tried not to duplicate a lot of vagrant documentation, but instead just get users started and then link to the vagrant docs for the details. </desc> <cmt> add a topical guide for vagrant integration </cmt> <cmt> fix up word wrapping </cmt>",add a basic guide describing vagrant and ansible
1774,<desc> ->  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> fix: value and onchange are supposed to be string instead of color </cmt> <cmt> -> </cmt> <cmt> fix: updated tests </cmt>,wordpress__components - value and onchange are supposed to be string instead of color
1775,<desc> i hereby agree to the terms of the cla available at:  added function zookeepersessionuptime() which returns uptime of current zookeeper session in seconds. detailed description / documentation draft: </desc> <cmt> add function zookeepersessionuptime() </cmt> <cmt> better check for session expiration in clickhouse-test </cmt>,"add function zookeepersessionuptime(), fix some flaky tests"
1776,"<desc> from #52495, while looking into the potential scalability issue service controller may have, i found it really hard to debug as the log sometimes doesn't reference which lb it is for, or sometimes it just doesn't log at all. it get even harder that in correctness cis we reduce verbose level to v1:  which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes #none /assign @nicksardo @bowei  release note: </desc> <cmt> service_controller: include service key in error messages </cmt> <cmt> gce_loadbalancer_external: critical path logging cleanup </cmt>",service controller / gce loadbalancer logging cleanup
1777,"<desc> original branch merges cleanly (no rebase needed) see also #17946 </desc> <cmt> bugfix: include ""csv"",""!segwit"" in ""rules"" </cmt> <cmt> they have been missing since buried deployments were merged </cmt> <cmt> qa: feature_segwit: check that template ""rules"" includes ""!segwit"" as appropriate </cmt>","restore ""!segwit"" and ""csv"" to ""rules"" key"
1778,"<desc> make cscript::clear() release memory (indirectly causing transaction outputs being spent to release associated heap memory). make ccoinsview::batchwrite consume the passed ccoinsmap, rather than copy from it. as a result, ccoinsviewdb now progressively converts the map to leveldb entries, rather than copying. merging a ccoinsviewcache into a parent cache uses ccoins::swap + release rather than copy + bulk release at the end. should reduce peak memory usage and some cpu time. </desc> <cmt> allow batchwrite to destroy its input, reducing copying </cmt> <cmt> make cscript::clear() release its memory </cmt>",some coin database memory usage tweaks.
1779,"<desc> see </desc> <cmt> apply align-items: center; to .input-group instead of input group sub components, causes .input-group .form-control and .input-group-addon to be large when next to a tall element </cmt> <cmt> remove vertical-align: middle from .input-group-addon and .input-group-btn left over from v3 </cmt>",input-group inside d-flex with a tall item causes input and input-group-addon to be too tall
1780,"<desc> make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, ""[airflow-xxx] my airflow pr""  in case you are fixing a typo in the documentation you can prepend your commit with [airflow-xxx], code changes always need a jira issue. in case you are proposing a fundamental code change, you need to create an airflow improvement proposal (aip). in case you are adding a dependency, check if the license complies with the asf 3rd party license policy. here are some details about my pr, including screenshots of any ui changes: my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 </desc> <cmt> bringing my fork current </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changing docutap to experity as it underwent merger </cmt> <cmt>  </cmt>",readme - experity merger from docutap
1781,"<desc> in researching the cause of #13377, we've decided to make some changes to the element pool. based on a hypothesis that a package could be inserting foreign nodes into the text editor's dom structure, we now only free elements that the element pool itself created. if the above hypothesis is incorrect, we now report assertion failures rather than throwing exceptions, and include the html of the freed element just in case that might be helpful. in addition, we've converted the class and tests to js and removed some closure allocations on  code paths. we think we should probably merge this only to 1.15 (beta) because it's a somewhat risky change, but we'd like to get feedback pretty soon from it. / </desc> <cmt> convert domelementpool and specs to js </cmt> <cmt> remove closure allocations from domelementpool build methods </cmt> <cmt> use a map instead of an object to store freeelementsbytagname </cmt> <cmt> allow metadata to be passed to atom.assert </cmt> <cmt> fail assertion with content metadata if the same element is freed twice </cmt> <cmt> this changes the element pool to only remove elements' children right </cmt> <cmt> before we use an element again in order to preserve the structure of </cmt> <cmt> double-freed elements. this will aid in debugging double-free </cmt> <cmt> occurrences. it's also less work in cases where nodes aren't reused. </cmt> <cmt> only free elements that the domelementpool created </cmt>",overhaul element pool and debug double-free errors
1782,"<desc> @rocketchat/core closes #7610 this change allows admin user to choose extra fields to be shown in the user's info tab. a new field was introduced (accounts): below is a screenshot of the userinfo tab: besides that, as the template var handling logic was extracted to a method, i changed the getdatatosyncuserdata method to use it. </desc> <cmt> display custom fields in user info tab </cmt> <cmt> this change allows admin user to choose extra fields to be shown in the user's info tab. </cmt> <cmt> replacing code by method call </cmt> <cmt> the templatevarhandler method was created by extracting from the getdatatosyncuserdata method the code that handles the template var substitution. this commit makes use of the extracted method aiming to not duplicate code. </cmt>",template to show custom fields in user info view
1783,"<desc> there is a bug in jdk 8 for windows where, with flags such as -xx:+printflagsfinal, memory sizes are printed as unsigned 32-bit integers. the maximum value of such an integer is 2^32 - 1, which is one byte less than the value of 4g in a jvm argument. if you pass -xx:+printflagsfinal -xmx=4g, you will see a heap size of zero. this bug only seems to affect display; the jvm still starts with the correct heap size. on windows and linux, the size value is cast to an unsigned 64-bit integer, which has plenty of room for holding realistic memory sizes. in jdk 9 and beyond, this bug was fixed, so any memory size will be displayed correctly. this issue affects our jvmergonomics code. in order to set maxdirectmemorysize, we parse the output from java -xx:+printflagsfinal -version (adding whichever flags we'd like to see), retrieve the value for maxheapsize, and set maxdirectmemorysize to half of heap. however, if the user has provided a value for maxdirectmemorysize, we use the provided value. consider a system with 40g of physical ram. by default, the jvm would set the maxheapsize at one quarter of that, which is to say, 10g. our intention would be to set maxdirectmemorysize to 5g. but on windows, jdk 8 will print maxheapsize as 2g, and maxdirectmemorysize will be set to 1g. the workaround is simple: set -xx:maxdirectmemorysize directly. if we wanted to fix this problem under the hood, we'd have to do two things when running on windows with jdk8: check whether the user has passed in one of the maximum heap size flags (not just -xmx but also -xx:maxheapsize). if so, parse the value for that flag and see if it's over 4g. if so, use the parsed value to set maxdirectmemorysize. if maxheapsize is unspecified, use an operatingsystemmxbean to find the system's physical memory. use that to set a correct heap size and a correct maxdirectmemorysize. not only does the above seem like brittle logic, it also puts us in the business of duplicating java's logic for parsing memory values. the virtue of our current implementation is that we don't have to do that at all. note that starting with 8.0.0, we will require a java 11 runtime, so this problem won't happen on the 8.x line. in light of that level of complexity, i think it's sufficient to emit a warning when running on windows with java 8 when there's no explicit setting for maxdirectmemorysize. i am not sure how bad it is to have an incorrect setting (a setting of 0 in the worst case), but i could easily be persuaded that we should fail to start without an explicit maxdirectmemorysize setting in a case where our jvm ergonomics would set it incorrectly, but that would be a breaking change to startup configuration for some users and we'd probably have to flag it in release notes or something. fixes #47384 </desc> <cmt> mute test that fails with java 8 on windows </cmt> <cmt> our jvm ergonomics extract max heap size from jdk printflagsfinal </cmt> <cmt> output. on jdk 8, there is a system-dependent bug where memory sizes are </cmt> <cmt> cast to 32-bit integers. on affected systems (namely, windows), when 1/4 </cmt> <cmt> of physical memory is more than the maximum integer value, the output of </cmt> <cmt> printflagsfinal will be inaccurate. in the pathological case, where the </cmt> <cmt> max heap size would be a multiple of 4g, the test will fail. </cmt> <cmt> this commit mutes the test for that specific circumstance, but i will </cmt> <cmt> need to do some further investigation of the consequences of this </cmt> <cmt> behavior. </cmt> <cmt> simplify to match other muted tests </cmt> <cmt> add broad warning for windows/jdk8 </cmt>",warn when maxdirectmemorysize may be incorrect (windows/jdk8 only issue)
1784,<desc> this should fix #5226 i also addd an nbcsportsie. yahooie and nbcsportsie are both based on nbcsportsvplayerie. i put nbcsportsie and nbcsportsvplayerie before nbcnewsie because they're more relevant to nbcie. </desc> <cmt> [yahoo/nbcsports] fix #5226 </cmt> <cmt> [yahoo/nbcsports] generalize nbc sports info extractor </cmt> <cmt> [nbcsports] move imports alphabetically </cmt> <iss> error: yahoo returned error: missing video tag </iss>,fix 5226 and add support for nbc sports
1785,<desc> update doc makefile for some changes on hosting server. update f2py front page and some doc build metadata. remove outdated doc/f2py content. </desc> <cmt> doc: bld: update doc makefile for some changes on hosting server. </cmt> <cmt> doc: update f2py front page and some doc build metadata. </cmt>,some doc build maintenance and f2py doc updates
1786,"<desc> this complicates a little bit the logic in browsableapirenderer.get_rendered_html_form, but it allows to use view.serializer_class when get_serializer is not there. i tested it locally and it seems to be working. </desc> <cmt> set serializer_class on obtainauthtoken view </cmt> <cmt> make browsableapirenderer use serializer_class when present </cmt>","use serializer_class for browsable api display, even on plain apiview."
1787,"<desc> and added some logging and unreachable() macro calls. this fixes the cutscene in sonic mania. </desc> <cmt> shaders: log and crash when using an unimplemented texture type in a texture sampling instruction. </cmt> <cmt> shaders: fixed the coords in tex with texture2d. </cmt> <cmt> the x and y coordinates should be in gpr8 and gpr8+1, respectively. </cmt> <cmt> this fixes the cutscene rendering in sonic mania. </cmt>",fixed texture coordinates in tex with texture2d
1788,"<desc> protocols have the implicit self generic parameter, which was preventing this type alias from getting created, so some renamed imported protocols for swift 3 weren't emitting the expected diagnostics and fix-its. rdar://problem/26304496 </desc> <cmt> [qoi] don't skip over protocols when importing swift 2 type aliases </cmt> <cmt> protocols have the implicit self generic parameter, which was </cmt> <cmt> preventing this type alias from getting created, so some renamed </cmt> <cmt> imported protocols for swift 3 weren't emitting the expected </cmt> <cmt> diagnostics and fix-its. </cmt> <cmt> rdar://problem/26304496 </cmt> <cmt> [test] use semantics-free nswobbling example rather than nscopying. </cmt>",swift 3 imported protocol alias 26304496
1789,"<desc> @mathiasbynens as discussed. recommend going by commit as the last commit is just the re-format, the first two do the setup. happy to change any of the config. i also took the opportunity to tidy the eslint file and remove rules that prettier will effectively enforce. </desc> <cmt> prettier </cmt> <cmt> configure eslint and prettier </cmt> <cmt> run prettier on all files </cmt>",add prettier to the codebase.
1790,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  constants for indicating what kind of presence a term must have in matching documents.  the term is used as is, i.e. no tokenization will be performed by this method. instead conversion to a token or token-like string should be done before calling this method. increase the version number in the header if appropriate. version bump should not be nesscary if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. tslint.json already exists extending dt.json </desc> <cmt> add lunr.query.presence constants </cmt> <cmt> update lunr.query.prototype.term to accept arrays and token objects </cmt> <cmt> update tests to verify term and query changes </cmt>","lunr - add query.presence constants, update term method arguments"
1791,"<desc> lib2to3 is effectively eol, but it was never taught to parse positional only args ala pep-570 that shipped in 3.8. this fixes that oversight. even though destined to wind up on pypi instead of in the stdlib, this should help give it a proper sendoff and unblock things still using it under 3.8.x and 3.9.x from falling over on modern syntax. notably the blib2to3 within black already backported these </desc> <cmt> add positional only args support to lib2to3 pgen2. </cmt> <cmt> this adds 3.8's pep-570 support to lib2to3's pgen2.  lib2to3, while </cmt> <cmt> being deprecated is still used by things to parse all versions of python </cmt> <cmt> code today.  we need it to support parsing modern 3.8 and 3.9 constructs. </cmt> <cmt> add tests for complex *expr and **expr's. </cmt>",add lib2to3 grammar pep-570 pos-only arg parsing
1792,"<desc> i needed create a keyboard for a person that can only use one finger at the time. so i changed the all mod keys to the one keypress variation, so all key bindings can be done with one finger. the console = no it's to reduce the size of the binary to support unicode my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fix led index </cmt> <cmt> update </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> cami accessibility keymap </cmt>",fix my personal keymap // custom keymap for kbdfans/kbd67/rev2 with improvements on accessibility
1793,"<desc> finds and replaces $family and ${family} in health info strings. continues from #10801. component name health insert a $family or ${family} variable in an alarm's configuration info string. observe it to be replaced with the family value in dashboard, aclk, v1/api and notification emails. we should merge this in the feature branch so it can be tested generally. when it goes into master we should have decided if we're going to support both variable formats, or just one of them, and whether we need more (i.e. $this, $units, etc). </desc> <cmt> replace $family variable in info strings </cmt> <cmt> also support ${family} </cmt>",find and replace $family variable in health info strings.
1794,"<desc> working on getting the tf trainer running on tpus for multiple choice. i'm quite the newb so input is needed. add 1 gpu strategy args for tpu name add mpc example for tftrainer fix docstrings gpu on swag  tpu on swag (fails, havent looked into it might be my misstake):  glue on tpu (fails, havent looked into it, might be my mistake) </desc> <cmt> catch gpu len 1 set to gpu0 </cmt> <cmt> add mpc to trainer </cmt> <cmt> add mpc for tf </cmt> <cmt> fix tf automodel for mpc and add albert </cmt> <cmt> apply style </cmt> <cmt> fix import </cmt> <cmt> note to self: double check </cmt> <cmt> make shape none, none for datasetgenerator output shapes </cmt> <cmt> add from_pt bool which doesnt seem to work </cmt>",add multiplechoice to tftrainer [wip]
1795,"<desc> fixes #2998 i think basically there are two ways to move pages, using history.push and using an <a/> tag. however, when using history.push, the page cannot be displayed in a new tab as pointed out #2998 . so this pr use <a/> tag (strictly speaking <link/> component of react-router-dom) instead of history.push. </desc> <cmt> use link of react-router-dom </cmt> <cmt> add styles for link element </cmt> <cmt> use theme.palette </cmt> <cmt> update unit tests for tracestablerow </cmt> <iss> cannot open traces in a new tab </iss>",allows lens to open traces in a new tab
1796,"<desc> fix #1708 when two keys that use the same keycode, but different modifiers were pressed at the same time, the second keypress wasn't registered. this is fixed by forcing a key release when we detect a new press for the same keycode. note that this might have some unforseen consequences. if that's the case we can enable/disable this behaviour with a define. but so far i haven't thought of anything, so i rather enable it completely, than having too many confusing configuration options. </desc> <cmt> fix extra keyboard report during test_fixture teardown </cmt> <cmt> add tests for pressing two keys with only different modifers </cmt> <cmt> fix #1708 </cmt> <cmt> when two keys that use the same keycode, but different modifiers were </cmt> <cmt> pressed at the same time, the second keypress wasn't registered. this is </cmt> <cmt> fixed by forcing a key release when we detect a new press for the same </cmt> <cmt> keycode. </cmt> <iss> rollover 'delayed' when pressing both unshifted and shifted keycodes at the same time </iss>",fix pressing two keys with the same keycode but different modifiers
1797,"<desc> this fixes #14202 by (1) showing the affordance when you mouse out of the window and (2) making sure that the collapsed docks still have a pixel-wide hover area so the affordance can still be shown when the window's fullscreened. </desc> <cmt> :bug: make sure docks affordance can always be revealed </cmt> <cmt> ensure dock mask has size of zero </cmt> <cmt> this no longer seems to be an issue. </cmt> <iss> after collapsing a dock, unable to expand dock again </iss>",ensure that dock toggle affordances can always be revealed
1798,"<desc> this pr is not to be merged in wholesale. i am just documenting the changes i've made in this branch to compare the type baselines with the old compiler's type baselines. the changes were in the service of making the new baselines and old baselines look as similar as possible. the idea is to pick and choose the changes we actually want to port to master. various smaller / more nuanced differences were captured in the form of bugs with the prefix [typebaselines]. the majority of the changes ported should be source changes, but a few test changes may be ported as well. </desc> <cmt> baseline and harness changes </cmt> <cmt> more type baseline changes </cmt> <cmt> adjust baselines after rebase </cmt> <cmt> update baselines </cmt>",changes to typewriter and type baselines
1799,"<desc> i wanna add my firmware to qmk repository my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> info.json </cmt> <cmt> add files via upload </cmt>",adding my custom keypad to qmk repository
1800,"<desc> setting border: 0 on a handful of elements breaks our universal border style reset, since the unviersal selector has no specificity and is defeated by element selectors. turns out those old resets don't matter anyways since our universal reset does the same job. this also resets the border radius of buttons and button-like things to 0 because chrome 62 recently shipped some new default styles for buttons on macos. this has been reverted upstream in chrome, but i think it makes sense to keep this in our own reset until chrome 62 is no longer in active use. </desc> <cmt> don't reset borders in suit fork; reset all radiuses to 0 </cmt> <cmt> latest chrome adds default border radius to buttons, wow. </cmt> <cmt> only reset border radius on elements chrome borked it on </cmt>","don't reset borders for specific elements, fix chrome 62 border radius debacle"
1801,<desc> flip the switch on python 3 in infra tooling. </desc> <cmt> run 2to3 on tools directory </cmt> <cmt> delete github_stats_tracking </cmt> <cmt> re-run 2to3 </cmt> <cmt> remove unused script </cmt> <cmt> remove unused script </cmt> <cmt> remove unused line count utility </cmt> <cmt> yapf. isort </cmt> <cmt> remove accidentally included file </cmt> <cmt> migrate tools/distrib directory to python 3 </cmt> <cmt> remove unnecessary shebang </cmt> <cmt> restore line_count directory </cmt> <cmt> immediately convert subprocess.check_output output to string </cmt> <cmt> take care of python 2 shebangs </cmt> <cmt> invoke scripts using a python 3 interpreter </cmt>,migrate infrastructure scripts to python 3
1802,"<desc> fixes: #3400 this pr adds some clarification about where the mass bounds in multirotorparams.hpp come from. where the max limit is actually the mass equivalent to the maximum lift force the rotors+propellers would be able to generate. (1.6kg if using the parameters in rotorparams.hpp on a quadrotor) and the min limit is the minimum weight equivalent to 50%of the maximum lift power, aka: the lift power at 50% throttle which is the idling throttle (on simpleflight). anything lower than this will lift off as soon as the drone is armed (ie: with the throttle stick untouched) (0.8kg  if using the parameters in rotorparams.hpp on a quadrotor) this pr also fixed a broken link in the docs </desc> <cmt> added mass limit clarification </cmt> <cmt> fixed broken link </cmt> <iss> colour pallet link is broken in docs </iss>",multirotor mass limit clarification & broken link fix
1803,"<desc> modifies the gen_l10n tool to use synthetic packages by default. this allows developers to generate the localization output files in a package that will not need to be checked into the user's flutter project. while this is a breaking change to the existing users of the tool, i believe it is justified since the tool is still in its early stages and not publicized. i would prefer that the default behavior of the tool be the preferred method of using synthetic packages rather than not. however, i'd like to get some feedback on what people think about this breaking change. to not use synthetic packages if calling gen_l10n via the command line, simply add --no-synthetic-package to your call: ${flutter}/bin/dart ${flutter}/dev/tools/ --no-synthetic-package {other options} if using l10n.yaml, add the following option: # other options synthetic-package: false to use synthetic packages in your flutter project, add the following to your pubspec.yaml file: flutter: ## note, this is not dependencies: flutter: generate, but is instead ## flutter: generate, which is usually further down in your pubspec.yaml ## file. generate: true after generating the localizations files for your flutter application (you can do this through calling flutter run), simply update the location where you are importing your localization file. for example, in the stocks app: // previous import: // import 'i18n/stock_strings.dart'; // now, import the synthetic package instead import 'package:flutter_gen/gen_l10n/stock_strings.dart'; remove the generated localizations output files from where they previously were. i added the following tests: modified existing tests to understand expect generated files to be in the synthetic package directory by default modified existing tests to generate output files in custom directories if the synthetic package flag is turned off. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> synthetic packages by default in gen_l10n tool </cmt> <cmt> refactor default path for synthetic package </cmt> <cmt> remove unused import </cmt> <cmt> code cleanup </cmt> <cmt> further improvements to help text </cmt> <cmt> refactor synthetic package path </cmt> <cmt> remove newlines </cmt> <cmt> test cleanup </cmt> <cmt> clean up logic in inputs and outputs list function </cmt> <cmt> update l10n.yaml usage </cmt> <cmt> only add option if value is non-null </cmt> <cmt> update stocks app as proof of concept for synthetic package usage </cmt>",synthetic package generation by default
1804,"<desc> part of api standardization add element-wise functions add asin, asinh, acos, acosh, atan, atan2, atanh, bitwise_invert, pow & _ipow_ add manipulation functions add concat change statistical functions std: change keyword ""ddof"" to ""correction"" var: change keyword ""ddof"" to ""correction"" change linalg functions add vecdot eigvalsh: change keyword ""uplo"" to ""upper"" eigh: change keyword ""uplo"" to ""upper"" </desc> <cmt> [website] fix website publish (#20573) </cmt> <cmt> * fix website publish </cmt> <cmt> * update </cmt> <cmt> * remove .asf.yaml from version/master </cmt> <cmt> * force include .asf.yaml </cmt> <cmt> * include .htaccess </cmt> <cmt> * add .asf.yaml check in ci </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> change linalg & statical funcs </cmt> <cmt> add vecdot </cmt>",[api standardization]standardize mxnet numpy statistical & linalg functions
1805,<desc> fix a serious issue where the unicode routines would sometimes read past a string's null termination. allow the spinner dialog box to work with command strings with the m0 command. </desc> <cmt> fix for incorrect handling of string terminator. </cmt> <cmt> fix spinner dialog box to allow m0 commands. </cmt>,fix to ftdi eve unicode routine and spinner dialog box
1806,"<desc> backport of #54281 this will add the valuessourceregistry to the 7.x branch </desc> <cmt> add valuessource registry and associated logic (#54281) </cmt> <cmt> * remove valuessourcetype argument to valuessourceaggregationbuilder (#48638) </cmt> <cmt> * valuessourceregistry prototype (#48758) </cmt> <cmt> * remove generics from valuessource related classes (#49606) </cmt> <cmt> * fix percentile aggregation tests (#50712) </cmt> <cmt> * basic thread safety for valuessourceregistry (#50340) </cmt> <cmt> * remove target value type from valuessourceaggregationbuilder (#49943) </cmt> <cmt> * cleanup default values source type (#50992) </cmt> <cmt> * corevaluessourcetype no longer implements writable (#51276) </cmt> <cmt> * remove genereics & hard coded valuessource references from matrix stats (#51131) </cmt> <cmt> * put values source types on fields (#51503) </cmt> <cmt> * remove vst any (#51539) </cmt> <cmt> * rewire terms agg to use new vs registry (#51182) </cmt> <cmt> also adds some basic aggtestcases for untested code </cmt> <cmt> paths (and boilerplate for future tests once the it are </cmt> <cmt> converted over) </cmt> <cmt> * wire cardinality aggregation to work with the valuessourceregistry (#51337) </cmt> <cmt> * wire percentiles aggregator into new vs framework (#51639) </cmt> <cmt> this required a bit of a refactor to percentiles itself.  before, </cmt> <cmt> the builder would switch on the chosen algo to generate an </cmt> <cmt> algo-specific factory.  this doesn't work (or at least, would be </cmt> <cmt> difficult) in the new vs framework. </cmt> <cmt> this refactor consolidates both factories together and introduces </cmt> <cmt> a percentilesconfig object to act as a standardized way to pass </cmt> <cmt> algo-specific parameters through the factory.  this object </cmt> <cmt> is then used when deciding which kind of aggregator to create </cmt> <cmt> note: corevaluessourcetype.histogram still lives in core, and will </cmt> <cmt> be moved in a subsequent pr. </cmt> <cmt> * remove generics and target value type from multivsab (#51647) </cmt> <cmt> * fix checkstyle after merge (#52008) </cmt> <cmt> * plumb valuessourceregistry through to querysearchcontext (#51710) </cmt> <cmt> * convert rareterms to new vs registry (#52166) </cmt> <cmt> * wire up value count (#52225) </cmt> <cmt> * wire up max & min aggregations (#52219) </cmt> <cmt> * valuessource refactoring: wire up sum aggregation (#52571) </cmt> <cmt> * valuessource refactoring: wire up sigterms aggregation (#52590) </cmt> <cmt> * soft immutability for vsconfig (#52729) </cmt> <cmt> * unmute testsupportedfieldtypes, fix percentiles/ranks/terms tests (#52734) </cmt> <cmt> also fixes percentiles which was incorrectly specified to only accept </cmt> <cmt> numeric, but in fact also accepts boolean and date (because those are </cmt> <cmt> numeric on master - thanks testsupportedfieldtypes for catching it!) </cmt> <cmt> * vs refactoring: wire up stats aggregation (#52891) </cmt> <cmt> * valuessource refactoring: wire up string_stats aggregation (#52875) </cmt> <cmt> * vs refactoring: wire up median (mad) aggregation (#52945) </cmt> <cmt> * fix valuesourcetype issue with constant_keyword field (#53041)x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/job/rollupindexer.java </cmt> <cmt> this commit implements getvaluessourcetype for </cmt> <cmt> the constantkeyword field type. </cmt> <cmt> master was merged into feature/extensible-values-source </cmt> <cmt> introducing a new field type that was not implementing </cmt> <cmt> getvaluessourcetype. </cmt> <cmt> * valuessource refactoring: wire up avg aggregation (#52752) </cmt> <cmt> * wire percentileranks aggregator into new vs framework  (#51693) </cmt> <cmt> * add a vsconfig resolver for aggregations not using the registry (#53038) </cmt> <cmt> * vs refactor wire up ranges and date ranges (#52918) </cmt> <cmt> * wire up geo_bounds aggregation to valuessourceregistry (#53034) </cmt> <cmt> this commit updates the geo_bounds aggregation to depend </cmt> <cmt> on registering itself in the valuessourceregistry </cmt> <cmt> relates #42949. </cmt> <cmt> * vs refactoring: convert boxplot to new registry (#53132) </cmt> <cmt> * wire-up geotile_grid and geohash_grid to valuessourceregistry (#53037) </cmt> <cmt> this commit updates the geo*_grid aggregations to depend </cmt> <cmt> on registering itself in the valuessourceregistry </cmt> <cmt> relates to the values-source refactoring meta issue #42949. </cmt> <cmt> * wire-up geo_centroid agg to valuessourceregistry (#53040) </cmt> <cmt> this commit updates the geo_centroid aggregation to depend </cmt> <cmt> on registering itself in the valuessourceregistry. </cmt> <cmt> relates to the values-source refactoring meta issue #42949. </cmt> <cmt> * fix type tests for missing aggregation (#53501) </cmt> <cmt> * valuessource refactor: move histo vstype into xpack module (#53298) </cmt> <cmt> - introduces a new api (getbareaggregatorregistrar()) which allows plugins to register aggregations against existing agg definitions defined in core. </cmt> <cmt> - this moves the histogram vstype over to xpack where it belongs. gethistogramvalues() still remains as a core concept </cmt> <cmt> - moves the histo-specific bits over to xpack (e.g. the actual aggregator logic). this requires extra boilerplate since we need to create a new ""analytics"" percentile/rank aggregators to deal with the histo field. doubly-so since percentiles/ranks are extra boiler-plate'y... should be much lighter for other aggs </cmt> <cmt> * wire up datehistogram to the valuessourceregistry (#53484) </cmt> <cmt> * vs refactor parser cleanup (#53198) </cmt> <cmt> first batch of easy fixes </cmt> <cmt> remove list.of from valuessourceregistry </cmt> <cmt> note that we intend to have a follow up pr dealing with the mutability </cmt> <cmt> of the registry, so i didn't even try to address that here. </cmt> <cmt> more compiler fixes </cmt> <cmt> more compiler fixes </cmt> <cmt> more compiler fixes </cmt> <cmt> precommit is happy and so am i </cmt> <cmt> add new core vsts to tests </cmt> <cmt> disabled supported type test on sigterms until we can backport it's fix </cmt>",backport valuessourceregistry and related work
1807,"<desc> uplift #43782 to beta. fixes #43153. r? @alexcrichton (approved by @rust-lang/dev-tools ) </desc> <cmt> some tidying up around include! </cmt> <cmt> doc tests: use the filename from the source file for doc test programs, rather than a dummy name </cmt>",uplift fix for include! in doc tests to beta
1808,"<desc> cherry-picks #25619 (reviewed by @xedin) #25620 (reviewed by @jckarter) #25510 (by @owenv, reviewed by @slavapestov and others) #25624 (reviewed by @jckarter) to the 5.1 branch. rdar://problem/50346954 </desc> <cmt> don't offer a fix-it to convert to a 'some' type (#25619) </cmt> <cmt> there's no way to spell an opaque type in a cast, and that means </cmt> <cmt> there's no way to force the conversion today (even if you know the </cmt> <cmt> types are dynamically the same). </cmt> <cmt> part of rdar://problem/50346954 </cmt> <cmt> (cherry picked from commit 9e471e4124ddbadd5dd8cc99a20449b6726dc902) </cmt> <cmt> treat 'some' types as having non-simple representations by default (#25620) </cmt> <cmt> that is, if they appear inside a larger type, they may need to be </cmt> <cmt> parenthesized. astprinter is careful about this already, so this </cmt> <cmt> doesn't actually change any existing behavior, but it makes the </cmt> <cmt> default more conservative when no printoptions are in play. </cmt> <cmt> (cherry picked from commit 4c26f95c01cc4b155061675869259433540b5845) </cmt> <cmt> [diagnostics]: qualify type arguments to diagnostics if there are name collisions </cmt> <cmt> (cherry picked from commit d939e786c4e63d99565391a3eaa3b401ceef6320) </cmt> <cmt> show 'some' type origins in diagnostics, like 'aka' for sugared types (#25624) </cmt> <cmt> currently only works for types that are /just/ a 'some' type, not in a </cmt> <cmt> nested position. also won't show them for opaque types with different </cmt> <cmt> requirements, to avoid noise when it's not strictly necessary. this </cmt> <cmt> does mean that 'some p' vs. 'some p & q' won't get the origin part. </cmt> <cmt> part of rdar://problem/50346954 </cmt> <cmt> (cherry picked from commit cb6d47ef24070dbd9fe3fb96945dde0d157f003d) </cmt>",various improvements for 'some' type diagnostics
1809,"<desc> unifies the codebase to a single formatting. runs prettier over: examples (was already the case) packages (next.js core, specifically all .js and .ts files) **/*.ts **/*.md packages/**/*.json removes tslint in favor of standard which we already had running. potentially might want to remove standard in the future, but not a priority right now. </desc> <cmt> run prettier over packages/**/*.js </cmt> <cmt> run prettier over packages/**/*.ts </cmt> <cmt> run prettier over examples </cmt> <cmt> remove tslint </cmt> <cmt> run prettier over examples </cmt>",move syntax formatting to prettier
1810,"<desc> i guess there's a race condition in the xcuitests that caused some flakiness in the tests. this pr is to try another workaround, the first try with tap on app didn't work. #89175 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> try tap app before apping the element </cmt> <cmt> try tap button again if not working the first time </cmt>",trying tap the buttons again if the first time didn't work
1811,"<desc> this pr pulls in a documentation / helper change that raises a warning if necessary dlls could not be found on the windows system. see the messages from the included commits for more details. </desc> <cmt> add msvcp140_1.dll to list of import-time-check windows dlls </cmt> <cmt> resolves </cmt> <cmt> for tensorflow 2.1.0rc1, the tensorflow team built windows packages with microsoft visual studio 2019 16.4, upgraded from visual studio 2017. as discovered in the issue linked above, this caused an import error for windows tf python whls, because the build upgrade pulled in an additional visual c++ dll dependency, msvcp140_1.dll, which can be found in the latest visual c++ package for all visual studio releases since 2015 ( </cmt> <cmt> i discovered the missing dll by unpacking the two wheels for rc0 and rc1 and separately running dumpbin /dependents tensorflow_core/python/_pywrap_tensorflow_internal.pyd (thanks to @yifeif for help with this!). </cmt> <cmt> in this change, i've updated the import-time checker to look for both msvcp140_1.dll and msvcp140.dll in a way that supports simple future additions to the list. </cmt> <cmt> piperorigin-revid: 285476568 </cmt> <cmt> change-id: ia9727e50801a4ddad1ea30653a74478fb7aee4e8 </cmt> <cmt> document new windows dll requirements </cmt>",cherrypick windows dll warning changes and related notes
1812,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): add the ability to build clickhouse with coverage via packager script. also add image for coverage info. mostly for usage in ci. </desc> <cmt> add coverage images for ci </cmt> <cmt> don't fail if no coverage info </cmt> <cmt> add ignore variable </cmt>,add coverage image for ci
1813,"<desc> backspace still acts as control when you hold it down, but if you tap it twice and hold it's a held backspace. tapping it more than twice it continues to act as backspace, but it deletes more characters with each tap with the quantity deleted based on the fibonacci sequence. if you tap it 4 times it switches to deleting by word for subsequent taps (and restarts the fibonacci sequence). holding after 4 taps deletes words while it's held. the following table is a non-exhaustive list key presses result held ctrl 1 tap backspace 1 tap then held backspace held down 2 taps backspace twice 3 taps backspace four times 4 taps backspace four times, then alt+backspace 4 taps and held backspace four times, then alt+backspace are both held down 5 taps backspace four times, then alt+backspace twice 6 taps backspace four times, then alt+backspace four times 7 taps backspace four times, then alt+backspace 11 times and you should probably have hit ctrl+u by now </desc> <cmt> add haegin's keymap </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> potential improvements to the keyboard </cmt> <cmt> add haegin minidox layout </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add haegin's keyboard to ergodox layouts </cmt> <cmt> update haegin's minidox keymap </cmt> <cmt> add home, end, and page up and down </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> magic backspace </cmt> <cmt> backspace still acts as control when you hold it down, but if you tap it </cmt> <cmt> twice and hold it's a held backspace. tapping it more than twice it </cmt> <cmt> continues to act as backspace, but it deletes more characters with each </cmt> <cmt> tap with the quantity deleted based on the fibonacci sequence. </cmt> <cmt> switch to deleting words after 4 taps </cmt> <cmt> when hitting backspace, after 4 taps this switches to deleting by word </cmt> <cmt> because if you're hitting backspace that frantically you must need to </cmt> <cmt> delete a lot of stuff. holding backspace after 4 taps will delete words </cmt> <cmt> in the same way that holding alt+backspace deletes words on a normal </cmt> <cmt> keyboard. </cmt>",add magic backspace to my layout
1814,"<desc> we now use glcopyimagesubdata to copy texture data instead of binding the textures to the color attachment of some framebuffers and blitting them. this pr also fixes the size used for the copy rectangle when dealing with compressed textures. our texture cache should be rewritten to make it simpler, the current one is a beast that evolved from the needs of the 3ds's pica200 and is overly complicated for the needs of the switch. see #540 </desc> <cmt> glcache: simplify the logic to copy from one texture to another in blittextures. </cmt> <cmt> we now use glcopyimagesubdata, this should avoid errors with trying to attach a compressed texture as a framebuffer's color attachment and then blitting to it. </cmt> <cmt> maybe in the future we can change this to glcopytexturesubimage which only requires gl_arb_direct_state_access. </cmt> <cmt> glcache: use the full uncompressed size when blitting from one texture to another. </cmt> <cmt> this avoids the problem of only copying a tiny piece of the textures when they are compressed. </cmt>",fixed copying compressed textures in the rasterizer cache.
1815,<desc> trying to clear up the confusing: common.py defines base test_base.py imports base from common test_common does not and try to get away from the create_index usage to just use the index fixture small steps. </desc> <cmt> tst/ref: disambiguate base tests </cmt> <cmt> ref/tst: move non-base tests from base subclasses </cmt>,take things out of base tests
1816,<desc> this pull request adds support magic wand and micro speech examples on himax we1 evb </desc> <cmt> remove unuse comment </cmt> <cmt> sync to upstream </cmt> <cmt> sync to upstream </cmt> <cmt> tflm: add himax we1 evb to support tflm example(magic wand and micro speech) </cmt>,to add himax we1 evb examples
1817,"<desc> issue: #4185 upon attempting to close a socket, asynpool only removes the queue writer from the hub, not the reader.  this leads to a deadlock on the file descriptor, and eventually the worker stop accepting new tasks.  i moved the call to hub_remove from on_inqueue_close to destroy_queues, since the latter is called directly after the former and allows removing both fds in a single loop. </desc> <cmt> remove read socket from thread hub on queue close </cmt> <cmt> removed socket for queue reader </cmt>",deadlock on inqueue close (#4185)
1818,"<desc> duplicate of accidentally squashed pr #7591 </desc> <cmt> decaffeinate: rename index.coffee and 138 other files from .coffee to .js </cmt> <cmt> decaffeinate: convert index.coffee and 138 other files to js </cmt> <cmt> decaffeinate: run post-processing cleanups on index.coffee and 138 other files </cmt> <cmt> cleanup decaf </cmt> <cmt> fix tests after decaffeination </cmt> <cmt> fix decaf header, server/test/e2e </cmt>","fix develop history, undo effect of squashed decaf pr"
1819,"<desc> backport of  #11406. in einsum, if out is given, it should be assigned to ret. </desc> <cmt> bug: ensure ret is out in einsum </cmt> <cmt> check for unlikely error in assign_zero </cmt> <cmt> maint: cleanup ret assignment </cmt>",ensure out is returned in einsum.
1820,"<desc> and also removes default_preferences.js file. somewhat fixes #7797, and also properly addresses #7448. now we can remove hack from viewer.js and improve domcontentloaded handling. </desc> <cmt> removes web/default_preferences.js file. </cmt> <cmt> better domcontentloaded handling. </cmt> <iss> non-determinism during viewer initialization. </iss>",removes promise usage from preferences.js
1821,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> refine argument types of assert.thorw methods. </cmt> <cmt> add author. </cmt>",tighten argument types of assert.throw methods.
1822,"<desc> closes #19954. todo: update references to .values in the docs to use .array or .to_numpy() cross ref between .values and the rest </desc> <cmt> api: public data attributes for ea-backed containers </cmt> <cmt> this adds two new methods for working with ea-backed series / index. </cmt> <cmt> - .array -> union[extensionarray, ndarray]: the actual backing array </cmt> <cmt> - .to_numpy() -> ndarray: a numpy representation of the data </cmt> <cmt> .array is always a reference to the actual data stored in the container. </cmt> <cmt> updating it inplace (not recommended) will be reflected in the series (or </cmt> <cmt> index for that matter, so really not recommended). </cmt> <cmt> to_numpy() may (or may not) require data copying / coercion. </cmt> <cmt> closes </cmt> <cmt> update </cmt> <cmt> more notes </cmt> <cmt> update </cmt>",public data for series and index: .array and .to_numpy()
1823,<desc> only relevant files were touched (also remember to update changelog.ino file) the code change is tested and works. the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> add vl53l0x </cmt> <cmt> update my_user_config.h </cmt>,add support for vl53l0x time of flight sensor
1824,"<desc> x ] add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. add it to notneededpackages.json. </desc> <cmt> added closeonscroll prop definition </cmt> <cmt> bumped type definition version specifier </cmt>",added closeonscroll prop definition for react-datepicker
1825,"<desc> currently, the global configuration can be used to turn preview links on or off. for previewlinks: false it is possible to locally turn on preview links by <a href=""..."" data-preview-link>link</a>. this pull request allows to turn off preview links for previewlinks: true by <a href=""..."" data-preview-link=false>link</a>. this is particularly useful if you want to have preview links in general, but some pages do not allow to be opened in an iframe. </desc> <cmt> syncing to current version </cmt> <cmt> allow switching off preview links </cmt> <cmt> the data-preview-link=false tag can be used to switch off preview links </cmt>",turn off preview links locally
1826,"<desc> this introduces the main types behind the matching api and partially implements the matching logic. this is based on the poc in #13365, and so includes many of the concepts necessary to support matching on a stream of data (e.g. http bodies). risk level: low, not used testing: new uts docs changes: n/a release notes: n/a </desc> <cmt> matching: initial implementation of matcher </cmt> <cmt> spelling </cmt> <cmt> better logging </cmt>",initial implementation of matching api
1827,"<desc> this pr bumps dist-various-2 to 18.04 lts and both x86_64-gnu and x86_64-gnu-debug to 19.04. another change is the switch to rust-lang/mirror-google-fuchsia-zircon as the zircon repository, used during fuchsia tests: the original repository (fuchsia.googlesource.com/zircon) is now behind a login wall and it doesn't contain anything at all. r? @alexcrichton </desc> <cmt> ci: update dist-various-2 to ubuntu 18.04 </cmt> <cmt> ci: use our own mirror for fuchsia's zircon repository </cmt> <cmt> the canonical repository on fuchsia.googlesource.com is not accessible </cmt> <cmt> anymore, neither for anonymous access nor logged in access. this commit </cmt> <cmt> switches our ci to fetch the repository from our own mirror. </cmt> <cmt> ci: bump ubuntu 18.10 images to 19.04 </cmt>",upgrade non-lts ubuntu images in ci
1828,"<desc> hi! i've found a kernel crash while using the mv command: i've fixed the mv command itself to stop passing bad paths to the kernel and to print proper error messages (if mv failed, it did not print any information). i've also fixed the vfs::rename from using null pointers so that it doesn't crash even if given improper inputs. final result: thanks! </desc> <cmt> utilities: fix mv command requesting incorrect path </cmt> <cmt> when moving multiple files by using *, e.g.,: mv * /new_path/ </cmt> <cmt> if there was an error while trying to move a file to the new path </cmt> <cmt> the next file in the file list to be moved would have its path </cmt> <cmt> incorrectly set. </cmt> <cmt> - fixed mv loop to always append the correct path to the destination </cmt> <cmt> path. </cmt> <cmt> - added proper error message when mv fails. </cmt> <cmt> kernel-vfs: fixed kernel crash if parent custody is null </cmt> <cmt> in vfs::rename, if new_path is equal to '/', then, parent custody is </cmt> <cmt> set to null. </cmt> <cmt> vfs::rename would then use parent custody without checking it first. </cmt> <cmt> fixed vfs::rename to check both old and new path parent custody </cmt> <cmt> before actually using them. </cmt>",vfs::rename - fixed kernel crash while using mv command
1829,"<desc> the streamsbrokerbouncetest.test_broker_type_bounce experienced what looked like a transient failure.  after looking over this test and failure, it seems like it is vulnerable to timing error that streams will start before the kafka service creates all topics. org.apache.kafka.streams.errors.topologyexception: invalid topology: stream-thread [smoketest-44232843-7798-4a19-b0a8-56deedd866e6-streamthread-1-consumer] topic not found: sum at org.apache.kafka.streams.processor.internals.streamspartitionassignor$copartitionedtopicsvalidator.validate(streamspartitionassignor.java:923) at org.apache.kafka.streams.processor.internals.streamspartitionassignor.ensurecopartitioning(streamspartitionassignor.java:902) at org.apache.kafka.streams.processor.internals.streamspartitionassignor.assign(streamspartitionassignor.java:468) at org.apache.kafka.clients.consumer.internals.consumercoordinator.performassignment(consumercoordinator.java:419) at org.apache.kafka.clients.consumer.internals.abstractcoordinator.onjoinleader(abstractcoordinator.java:592) at org.apache.kafka.clients.consumer.internals.abstractcoordinator.access$1100(abstractcoordinator.java:94) at org.apache.kafka.clients.consumer.internals.abstractcoordinator$joingroupresponsehandler.handle(abstractcoordinator.java:544) at org.apache.kafka.clients.consumer.internals.abstractcoordinator$joingroupresponsehandler.handle(abstractcoordinator.java:527) at org.apache.kafka.clients.consumer.internals.abstractcoordinator$coordinatorresponsehandler.onsuccess(abstractcoordinator.java:894) at org.apache.kafka.clients.consumer.internals.abstractcoordinator$coordinatorresponsehandler.onsuccess(abstractcoordinator.java:874) after making the changes, i kicked off a branch builder with five repeats note that the reason i chose five repeats is the test uses a matrix and generate eight versions of the test and each test lasts about 5 minutes. there will be mirrored prs for 2.1 and trunk. </desc> <cmt> revert ""minor: increase throughput too slow for consumer to read within timeout"" </cmt> <cmt> this reverts commit 47595608 </cmt> <cmt> sync with upstream/2.0 </cmt> <cmt> minor: add check all topics created before starting streams </cmt> <cmt> minor: add self.num_kafka_nodes variable </cmt>",add check all topics created check streams broker bounce test (2.0)
1830,"<desc> unless the debugging tools (i.e. pdfbug) are enabled, or the browsertest is running, the pdfpageproxy.stats aren't actually used for anything. rather than initializing unnecessary stattimer instances, we can simply re-use one dummy class (with static methods) for every page. note that by using a dummy stattimer in this way, rather than letting pdfpageproxy.stats be undefined, we don't need to guard every single stats collection callsite. since it wouldn't make much sense to attempt to use pdfpageproxy.stats when stat collection is disabled, it was instead changed to a ""private"" property (i.e. pdfpageproxy._stats) and a getter was added for accessing pdfpageproxy.stats. this getter will now return null when stat collection is disabled, making that case easy to handle. for benchmarking purposes, the test-suite used to re-create the stattimer after loading/rendering each page. however, modifying properties on various api code from the outside in this way seems very error-prone, and is an anti-pattern that we really should avoid at all cost. hence the pdfpageproxy.cleanup method was modified to accept an optional parameter, which will take care of resetting this.stats when necessary, and test/driver.js was updated accordingly. finally, a tiny bit more validation was added on the viewer side, to ensure that all the code we're attempting to access is defined when handling pdfpageproxy stats. fixes #5215. edit: it would probably be good a idea to add a few unit-tests to check that pdfpageproxy.stats behaves reasonable with/without stats collection enabled. however, given that all options are currently global, the tests will be so much easier to write once pr #9185 has landed, which is why i didn't add any tests here. </desc> <cmt> move stattimer from src/shared/util.js to src/display/dom_utils.js </cmt> <cmt> since the stattimer is not used in the worker, duplicating this code on both the main and worker sides seem completely unnecessary. </cmt> <cmt> convert stattimer to an es6 class </cmt>",only create a stattimer for pages when enablestats == true (issue 5215)
1831,"<desc> for this pulling request, i have updated and improved existing simplified chinese translation of readme file. details as follows: added new contents from english readme file that hasn't been updated in simplified chinese translation of readme file. translated contents that were left untouched by last translation. replaced a number of half-width punctuation characters with full-width punctuation characters as following language usage habits. however, characters in commands and codes have been left unchanged per convenience of copying and pasting codes. replaced phrases for more precise translation based on contents. </desc> <cmt> update simplified chinese version of readme </cmt> <cmt> fix a few characters for a more precise translation. </cmt> <cmt> fix a character for a more precise translation. </cmt>",update & improvements on existing simplified chinese translation of readme
1832,<desc> based on #10271 by @d-side assign 243 (like efb) as ender-4/cr-8 board id add to makefile add to pins.h </desc> <cmt> fix ender 4 / cr-8 compilation </cmt> <cmt> - assign 243 (like efb) as ender-4/cr-8 board id </cmt> <cmt> - add to makefile </cmt> <cmt> - add to pins.h </cmt> <cmt> add more avr boards to makefile </cmt>,"fix ender 4 compilation, add more avrs to makefile"
1833,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add ses object type to sestransport.mailoptions </cmt> <cmt> fix linting issues </cmt>",add ses object type to sestransport.mailoptions nodemailer package
1834,"<desc> using the historic low in merge-able pull requests to do some restructuring. pycharm was so nice to remove some unused imports as well. algorithms = implementations of said entities. that's why blake2/ is there and not in crypto/, which otherwise only has abstractions and management things, no implementations. checked sdist, looks complete. </desc> <cmt> create package borg.algorithms with borg.algorithms.crc32 module </cmt> <cmt> move blake2 to borg/algorithms </cmt> <cmt> move chunker to borg.algorithms </cmt>",create borg.algorithms and borg.crypto packages
1835,<desc> used karma as the test launcher with jasmine as the test framework. added a new gulp command to run the tests gulp unittest added unittest to the watch command. added initial unit tests for the linear scale & fixed a bug that was found with the padding when the scale was vertical. @tannerlinsley @derekperkins check this out </desc> <cmt> initial test setup </cmt> <cmt> watch mode runs tests. </cmt> <cmt> remove wrong addition of padding </cmt> <cmt> initial scale tests </cmt>,initial unit test framework + linear scale test starting point
1836,<desc> the rpm ci builds were failing after a recent upgrade to a new fedora 20 container. fedora 21 came out last december so lets starts building on that. </desc> <cmt> build on fedora 21 </cmt> <cmt> try using canonical nodejs npm packages </cmt> <cmt> log detected version </cmt> <cmt> disable npm version check on ci </cmt> <cmt> upgrade to npm 1.4 on fedora </cmt> <cmt> remove janky bypass of npm version check </cmt> <cmt> only log install errors </cmt>,build rpm package on fedora 21
1837,"<desc> we are currently not logging failures of shfileoperation in a systematic and consistent way some err() are unduly triggered for normal operations we use getlasterror() while msdn states : ""do not use getlasterror with the return values of this function."" result sometime wrongly used as hresult systematic design pattern for shfileoperation logging explicit use of shfileoperationw replace err() by trace() for normal operations err() shows return code instead of getlasterror as per msdn result never used as hresult </desc> <cmt> [shell32] adding err log on shfileoperation failure </cmt> <cmt> more </cmt>",fix use of shfileoperation results and improve log on failure / fix log spam
1838,<desc> risk level: low. testing: unit release notes: cluster: add :ref:option envoy_api_field_cluster.close_connections_on_host_health_failure to close tcp_proxy upstream connections when health checks fail. </desc> <cmt> cluster: add option to close tcp_proxy connections when health checks fail. </cmt> <cmt> add release note </cmt>,add option to close tcp_proxy upstream connections when health checks fail.
1839,"<desc> hi all, pr related to the bael-554 article about spring remote with burlap and hessian. as grzegorz asked, i added a couple of junit tests that take care of running both the server and the clients. </desc> <cmt> burlap & hessian server added </cmt> <cmt> burlap & hessian client work </cmt> <cmt> fixed main </cmt> <cmt> fixed formatting </cmt> <cmt> spring remote example based on burlap & hessian runs in a junit test </cmt> <cmt> fixed main </cmt> <cmt> fixed formatting </cmt> <cmt> spring remote example based on burlap & hessian runs in a junit test </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt>",bael-554 - junit test that run server and clients
1840,"<desc> original pull-request #29531 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix </cmt> <cmt> fix pathstartswith </cmt>",cherry pick #29531 to 21.9: fix pathstartswith
1841,"<desc> this pr removes a couple of more defaults from the argument spec: uid, gid and mode have been removed from configs and secrets. they are already defaulted to the same values in docker-py. i've added two generic compare functions to handle cases where default values are returned by the docker api but is missing from the argument spec. in these cases they are ignored in the same manner as we do with self.some_option is not none and self.some_option != some_old_option. just some thoughts that might not be related to this pr: this leaves us with two defaults left. publish.protocol which defaults to tcp and mounts.type which defaults to bind. mounts.type can't be changed since it is different from the docker-py default which is volume. publish.protocol is a bit tricky to remove since it's passed to docker-py as a dictionary and thus we have no control of what order each element is sent to the docker api. by some testing it looks like the docker engine does use protocol to sort the elements along with target_port and published_port. just had a quick glance over the generic compare functions in docker/common.py, maybe compare_generic(a, b, method=""allow_more_present"", type=""set(dict)"")could work? in my opinion the best way forward would have been to implement the comparisons with the same logic and style as in docker_container and some other docker-modules but i don't think i have time to make such a big refactor before the deadline hits. docker_swarm_service </desc> <cmt> remove defaults </cmt> <cmt> skip redundant casting </cmt> <cmt> indentation fix </cmt> <cmt> use generic compare functions </cmt> <cmt> add tests for compare functions </cmt>",remove configs and secrets defaults
1842,"<desc> fixes issue #9497 this deprecates random_state in oneclasssvm as oneclasssvm is not random and does not provide probability estimation. this also clarifies the docstrings of random_state in svc, nusvc and linearsvc and adds information about the randomness of the underlying implementations of these estimators in the user guide. </desc> <cmt> deprecate random_state parameter in oneclasssvm as the libsvm implementation of smo is not random and oneclasssvm does not provide probability estimates </cmt> <cmt> clarify random_state docstring in svc and nusvc </cmt> <cmt> clarify random_state docstring in linearsvc </cmt> <cmt> add information about randomness of the underlying implementations of svc, linearsvc and oneclasssvm in the doc </cmt>",deprecate random_state in oneclasssvm and add clarifications in docstrings and doc
1843,"<desc> fixed doc formatting (type, examples, etc) added return value pg_utils added missing ci tests added aliases: name, login_db, login_port </desc> <cmt> postgresql_lang: fixed doc </cmt> <cmt> postgresql_lang: add pg_utils </cmt> <cmt> postgresql_lang: added return value - queries </cmt> <cmt> postgresql_lang: added ci tests </cmt>","fixed doc formatting, added aliases, pg_utils, added missing ci tests"
1844,"<desc> this change is resolves an issue i see frequently in my contentful project where entries linking to drafted or deleted content would trigger a graphql error. drafted content link deleted content link typical graphql error since resolvable.has(entryitemfieldvalue.sys.id) is false, the original field linking to the invalid does not get deleted from entryitemfields on master. this leads to an invalid schema. ideally editors would never link to deleted/drafted content, but it's a really easy mistake to make in contentful; when you're deleting an entry, you have no way to see what other entries might be linking to it. let me know your thoughts! </desc> <cmt> wip </cmt> <cmt> [gatsby-source-contentful] delete original link regardless of presence of resolvable id </cmt>",delete original link regardless of id validity
1845,"<desc> supersedes #16089 (some changes were already merged as part of #15969). </desc> <cmt> ios (and probably other aot platforms) needs to have delegates registered </cmt> <cmt> - if a managed delegate is going to be passed to native code, then it requires an attribute </cmt> <cmt> - instead of depending on xamarin.ios for this, we can just create our own, the ios runtime just checks for the type name </cmt> <cmt> - reference: </cmt> <cmt> add explanation for monopinvokecallback attribute </cmt>",mark native callbacks with monopinvokecallback
1846,"<desc> related to the issue #2639 it enables parse following code by rax2 -f char *shellcode = ""\x31\xc0\x50\x68\x2f\x2f\x73\x68\x68\x2f\x62\x69"" ""\x6e\x89\xe3\x50\x53\x89\xe1\xb0\x0b\xcd\x80""; before this patch, the result is 31c050682f2f7368682f6269 after this patch, 31c050682f2f7368682f62696e89e3505389e1b00bcd80 </desc> <cmt> add early return </cmt> <cmt> fix space </cmt> <cmt> enable parse str like ""a"" ""b"" </cmt>",rax2 fix hex from c
1847,"<desc> added a couple new plugins, added some helpers to others, and made a few minor tweaks (missing eof newlines and such). </desc> <cmt> ruby switching helpers </cmt> <cmt> add helper functions to switch gemsets on ruby-1.8.7-p334 and ruby-1.9.2-p180. </cmt> <cmt> add completion definitions for helper functions. </cmt> <cmt> helpful listing aliases </cmt> <cmt> add alias to list installed rubies. add alias to list gemsets in active ruby. </cmt> <cmt> rvm update helpers </cmt> <cmt> add helper function to get rvm head. add helper function to link zsh </cmt> <cmt> completion that comes with rvm into om-my-zsh plugin directory, but don't </cmt> <cmt> overwrite the completion that comes with oh-my-zsh (oh-my-zsh's completion is </cmt> <cmt> better, but i want to be able to compare). </cmt> <cmt> gem list helper </cmt> <cmt> add helper function to list gems in a pretty way (only with rvm, for now). add </cmt> <cmt> missng eof newline and a todo to the ruby plugin. </cmt> <cmt> brew plugin </cmt> <cmt> merge completion with official brew completion. add a helper to link official </cmt> <cmt> completion into oh-my-zsh plugin (without overwriting). add an alias to list </cmt> <cmt> installed brews. add brews to the path (in a somewhat strange way). </cmt> <cmt> pow! restart helper </cmt> <cmt> add helper function to restart an app running on pow! </cmt> <cmt> node.js helpers </cmt> <cmt> add helper function to open node api in browser. add binaries installed via </cmt> <cmt> npm to path. tell node where to find things (what things?). </cmt> <cmt> os x helpers </cmt> <cmt> add helper aliases for show/hide files. add helper alias to recursively delete </cmt> <cmt> .ds_store files. </cmt> <cmt> cleanup </cmt> <cmt> add missing newlines at eof. remove redundant comment. fix grammar in comment. </cmt> <cmt> thor </cmt> <cmt> add plugin with completion for thor. </cmt>","brew, rvm, node, npm, pow, and thor."
1848,"<desc> in reaction to #6345, this makes the instantiation of files implementation overridable on android. gwt is done, too, because overriding it is useful in projects often to change the handling of local files. discussing with @obigu, we never had the need to change files on desktop or ios, so this is not changed here. testing discovered that filestest was broken on non-gwt platforms by #6188 and is fixed hereby. entry suggestion for changes file: * api change: androidfiles and gwtfiles instantiation can be overriden by own classes. noexternalandroidfiles implementation can be used to avoid unnecessary write to external files dir if not needed (see #6345) </desc> <cmt> make instantiation of androidfiles overridable </cmt> <cmt> fixed filetest, broken on desktop by change in #6188 </cmt> <cmt> make instantiation of gwtfiles overridable </cmt> <cmt> make accessing getexternelfiledir overridable, with class doing so for use in projects, fixes #6345 </cmt> <iss> androidfiles initialization does disk i/o on ui thread (android) </iss>",make instantiation of files overridable
1849,"<desc> there is more to do here, but this is already a lot more robust. don't clean workspace in teardown, it might be useful for debugging if stuff fails. kill es/clean workspace in setup, so things always work even in the case of ^c use pidfile to kill fail if kill errors refactor a bit more logic here part of #12063 </desc> <cmt> harden logic around integ test workspace and process mgmt </cmt> <cmt> there is more to do here, but this is already a lot more robust. </cmt> <cmt> * don't clean workspace in teardown, it might be useful for debugging if stuff fails. </cmt> <cmt> * kill es/clean workspace in setup, so things always work even in the case of ^c </cmt> <cmt> * use pidfile to kill </cmt> <cmt> * fail if kill errors </cmt> <cmt> * refactor a bit more logic here </cmt>",harden integration tests setup/teardown more
1850,"<desc> design doc:  this is the last p0 item to implement basic placement group functionalities. it implements raylet side logic for atomic placement group creation. note that in order to separate the current cancel methods, i always commit resources before canceling if necessary. in this way, we can reuse the current method. unlike specified in the design doc, i don't guarantee the idempotency yet. it has some benefits since we don't have retry yet, having idempotency has no meaning. instead i added more check to guarantees invariants. this will help us detecting bugs easily if there are. i added todo to make these methods idempotent (and it will be implemented when we implement retry). #9807 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> in progress. </cmt> <cmt> in progress </cmt> <cmt> basic done. </cmt>",atomic creation using 2 phase protocol part 2.
1851,"<desc> ...and also fixes ""valueerror the queryset value for an exact lookup must be limited to one result using slicing"" under django 2.0, converting these to use in qs[:1] as well. to find these, i just grepped for [:1] (surprisingly, not many hits) and fixed what i saw. i was happy that these fixes were all reflected in test failures on django 2.0, which gives me more confidence in our test coverage. nothing in getsentry by the way. this change in django 2.0 says if rhs on exact is a query that has_limit_one (like [:1]) then forcefully select the pk. it's still in django main to this day, so we should adapt our code rather than maintain a monkeypatch for previous behavior. relevant django ticket:  here's a comparison illustrating those changes in django 2.0: in 1.11 the release_id=qs[:1] would be = v0.release_id. in 2.0 they force pk there so it's = v0.id. using __in  in both versions retains the desired release_id in this example; the special pk forcing logic only exists in exact in >=2.0. </desc> <cmt> convert exact lookups to subqueries of size 1 to in </cmt> <cmt> fix ""valueerror the queryset value for an exact lookup must be limited to one result using slicing"" under django 2.0 </cmt>",convert exact lookups to in where the rhs is a qs limit 1
1852,"<desc> using distributed processing frameworks, django or ray, users encountered errors when trying to run mxnet in separate threads. #11331 and dmlc/gluon-cv#156 calling the _current.value.get within the context of the respective object solved the issue. does anybody have a suggestion as to how to test this without introducing a dependency on ray? please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> add scope to namemanager </cmt> <cmt> add attrscope scope </cmt>",'_thread._local' object has no attribute 'value'' on distributed processing applications
1853,"<desc> this pr adds data-forwarding as an organization feature so we can check that value in the integration directory. this way, we can know if an org should be able to install a data-forwarding plugin like amazon sqs or splunk without loading the available features for a project. this pr must be merged with: getsentry/getsentry#3758 </desc> <cmt> add integrations-data-forwarding feature </cmt> <cmt> comment out test </cmt> <cmt> use value </cmt> <cmt> undo change </cmt> <cmt> fix test </cmt> <cmt> cleanup </cmt> <cmt> cleanup </cmt>",adds data-forwarding feature as organization feature
1854,<desc> fixes 2 bugs: 'undefined undefined' when sql query is empty and we switch to another clause save button inactive until clause is switched test plan has associated issue: #12266 requires db migration. confirm db migration upgrade and downgrade tested. cc: @villebro @junlin </desc> <cmt> fix save button disabled until clause is switched </cmt> <cmt> fix 'undefined undefined' when sql query is empty </cmt>,bugs in custom sql editor in filter popover
1855,"<desc> 1.19 backport of #94112 fixed a bug where improper storage and comparison of endpoints led to excessive api traffic from the endpoints controller </desc> <cmt> remove headlessservice label in endpoints controller before comparing </cmt> <cmt> do not mutate endpoints in the apiserver </cmt> <cmt> the endpoints api handler was using the canonicalize() method to </cmt> <cmt> reorder the endpoints, however, due to differences with the </cmt> <cmt> endpoint controller repacksubsets(), the controller was considering </cmt> <cmt> the endpoints different despite they were not, generating unnecessary </cmt> <cmt> updates evert resync period. </cmt>",remove canonicalization of endpoints by endpoints controller for better comparison
1856,"<desc> h2o uses h2o_token_t to represent some of the often-used headers.  most of them have a corresponding entry in the static table of hpack, but some don't (see token.pl line 153). however, the hpack encoder has made an incorrect assumption that a header name represented using h2o_token_t always has an entry in the hpack static table, and the fact has lead to incorrect output or server crash when upstream (i.e. proxy, fastcgi, mruby) emits one of thoese headers. this pr fixes the issue. </desc> <cmt> add failing test </cmt> <cmt> use the supplied name (which is part of the token) </cmt>",fix hpack encoder error (and crash) when trying to encode a token wo. hpack index
1857,"<desc> not all of them, but whittling them down. the tests are copied almost verbatim.  the only change is updating the datetime64/timedelta64 expected results to be datetime64/timedelta64 instead of inat. </desc> <cmt> tst: port tests from #23982 </cmt> <cmt> tst: port more tests from 23892 </cmt>",port maybe_promote tests from #23982
1858,"<desc> no-issue as discussed this should improve the ux of opening a magic link. no longer will it require a page refresh after loading, but the redirected page should be rendered as if the member was signed in </desc> <cmt> installed @tryghost/members-ssr@0.5.0 </cmt> <cmt> no-issue </cmt> <cmt> this includes changes that can be used to signin via a get request </cmt> <cmt> simplified urlutils require path </cmt> <cmt> no-issue </cmt> <cmt> this was previously going to a parent directory which was shared by both modules </cmt> <cmt> protected members middleware with a labs check </cmt> <cmt> no-issue </cmt> <cmt> this would have been creating a lot of noisy logs for sites without </cmt> <cmt> members enabled. </cmt> <cmt> updated members service usage of members-ssr@0.5.0 </cmt> <cmt> no-issue </cmt> <cmt> members-ssr@0.5.0 changed the membersapi param with getmembersapi </cmt> <cmt> added a middleware to handle signin via a get </cmt> <cmt> no-issue </cmt> <cmt> this also adds a basic check before handing of to the members-ssr </cmt> <cmt> module, this should make logs a little less noisy and only log warnings </cmt> <cmt> if a token was passed and that token was invalid/incorrect. </cmt> <cmt> removed post signin functionality </cmt> <cmt> no-issue </cmt> <cmt> this is no longer needed as we can signin with a get now </cmt>",updated /members/ssr to handle signin with get request
1859,"<desc> the results with lesser tasks contains un-stable wait times, so increased the number of tasks in a hope for less noisy wait times. minor in changes in assert comparisons have also been made for lesser error. i've run scripts/format.sh to lint the changes in this pr. cc: @wuisawesome </desc> <cmt> increasing num_tasks to reduce noise in wait times </cmt> <cmt> removed upper bound for last_wait </cmt>",increase in num_tasks for stable wait times in test_worker_capping:test_exponential_wait
1860,"<desc> i hereby agree to the terms of the cla available at:  added a new layout direct which loads all the data directly from the source for each query, without storing or caching data. detailed description / documentation draft: documentation added. performance: </desc> <cmt> created direct dictionary (has bugs, doesn't work properly) </cmt> <cmt> fixed bug & created functional test for new layout </cmt>",add direct layout for dictionaries
1861,"<desc> a fix for #1193 . mostly @kazuki43zoo 's work. :d by setting system property org.mybatis.usexsd to true, users can use xsd instead of dtd when writing mapper/config xml. <mapper namespace=""org.apache.ibatis.builder.xsd.authormapper"" xmlns="" xmlns:xsi="" xsi:schemalocation="" <configuration xmlns="" xmlns:xsi="" xsi:schemalocation="" migration steps would be....(just an idea) in version 3.5.0, keep dtd as the default. in version x (when some xsd-only enhancement is added?), change the default to xsd and output a log message (info or warn) like dtd is deprecated, to use xsd, see ... to encourage users to migrate to xsd.. in version y, remove dtd support. @jeffgbutler , this may affect generator in some way. please let me know if there is any concern. </desc> <cmt> support xml parsing using xsd </cmt> <cmt> add tests for support xml parsing using xsd </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/main/java/org/apache/ibatis/builder/xml/xmlmapperbuilder.java </cmt> <cmt> #	src/main/java/org/apache/ibatis/parsing/xpathparser.java </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/main/java/org/apache/ibatis/builder/xml/xmlmapperentityresolver.java </cmt> <cmt> use a system property as the switch. </cmt> <cmt> clear the system property at the end of each test. </cmt>",xsd support in mapper/config xml
1862,"<desc> now reduced to 64. also, restored max limit to 256 when in 64-bit mode, since it had been reduced to 200 to give more room for 32-bit environments, which ultimately proved not enough. </desc> <cmt> reduce max nb workers to 64 in 32-bit mode </cmt> <cmt> and restored limit to 256 when in 64-bit mode </cmt> <cmt> (it was reduced to 200 to give more room for 32-bit). </cmt> <cmt> this should fix test instability issues </cmt> <cmt> using lot of threads in 32-bit environments. </cmt>",reduce zstdmt_nbworkers_max in 32-bit mode
1863,"<desc> updated tests with flag introduced in #6959 printing git info to deterministically identify commit the tests are run on. </desc> <cmt> [flink-10678] disabled log checking in tests that fail jobs on purpose </cmt> <cmt> [hotfix] printing remote, branch, commit hash that is being tested </cmt>",disabled log checking in tests that fail jobs on purpose master-e2e
1864,"<desc> rework diagnostics related to nil literal to give a solver a chance to detect and diagnose situations when it's invalid to use it without more context e.g. _ = nil, nil as? int, or _ = nil!. </desc> <cmt> [csfix] add a fix to detect when type of  couldn't be inferred </cmt> <cmt> [diagnostics] diagnose cases when it's impossible to infer type for nil </cmt> <cmt> detect and diagnose situations when it's invalid to use nil </cmt> <cmt> literal without more context e.g. _ = nil, nil as? int, or </cmt> <cmt> _ = nil!. </cmt> <cmt> [cssimplify] allow optional object constraint to look through holes </cmt> <cmt> if right-hand side (optional type) has been determined to be a hole, </cmt> <cmt> let's establish that optional object of a hole is a hole and continue </cmt> <cmt> searching for a solution. </cmt> <cmt> [csbindings] start recording specifycontextualtypefornil fix when nil is bound to a hole </cmt> <cmt> [csbindings] adjust impact of an event when nil is bound to a hole </cmt> <cmt> [csgen] rework constraint generation for nil to avoid failing </cmt>",diagnose cases when it's impossible to infer type for nil literal
1865,"<desc> reverted ""the delayms option for staticresponses used with cy.intercept has been renamed to delay."" this pr is preparation for #14543 goal of this pr is to simplify the addition of new request events and the implementation of arbitrary subscriptions (req.on....) switched from bespoke http:request:received, http:response:received, http:response:complete event implementations to a generic implementation that calls handlers for all 3 updated existing driver code to use this new backend implementation. later, this system can be reused for req.on events. bonus benefit: much more declarative and easy to understand what is going on #14822 had to be reverted - see commit for details: 2704886 - ends up creating an inconsistency in the api that would be extremely confusing to paper over fixes (maybe) #15038 and #9359 has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? cypress-io/cypress-documentation#3629 have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> some notes </cmt> <cmt> notes </cmt> <cmt> add middleware prop, event types </cmt> <cmt> wip: middleware, subscriptions </cmt> <cmt> send:static:response event </cmt> <cmt> convert existing code to use send:static:response </cmt> <cmt> continue genericizing events </cmt> <cmt> wip </cmt> <cmt> remove new middleware changes </cmt> <cmt> all tests pass </cmt> <cmt> revert ""feat: rename delayms to delay, deprecate delay (#14822)"" </cmt> <cmt> this reverts commit d662c5d077331c4e2e269f59652c9be39a461776. </cmt> <cmt> had to revert this because it ends up creating an inconsistency in the apis. </cmt> <cmt> res.delay() is a function, which is why res.delayms needs to be the scalar. </cmt> <cmt> fix tests </cmt>",refactor cy.intercept internals to generic event-based system
1866,"<desc> a misfire kind of push added a few change sets that shouldn't have been included. this pullreq is fine and dandy. </desc> <cmt> fixes #555 </cmt> <cmt> case-insensitive match for websocket upgrade, in all websocket transports </cmt>",minor potential issues corrected in websocket transports
1867,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> subtitle: added function stringifyvtt </cmt> <cmt> fixed toms typo error </cmt>,fixed toms instead of toms
1868,"<desc> added fast-access-layout-keys to the zones-settings.json. currently the schema is: { ""devices"": [], ""custom-zone-sets"": [], ""templates"": [], ""fast-access-layout-keys"": [ { ""key"": 1, ""uuid"": ""{xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx}"" } } what is include in the pr: for testings purposes, i added the temporary button at the bottom of the editor that calls adding and freeing fast access keys. after clicking you can verify in the json file that some values were added (and weren't duplicated) and they're not erased after reading and rewriting settings by the fancyzoneslib. the temporary button will be removed in the next pr or in this pr after reviewing. by default, the fast-access-layout-keys array is empty. linked issue: #10025 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> add fast-access-layout-keys to the json schema </cmt> <cmt> keep json data </cmt> <cmt> temp test button </cmt> <cmt> removed freekeys container </cmt>",add the schema element to zones-settings.json
1869,"<desc> mobx latest version is v6 , big difference with v5. new observer pattern with makeobservable/makeautoobservable builtin function, migration guide is here . changelist: drop inject/observer pattern , and using react context (hooks version) using makeobservable rather than decorate delete eslint relative deps (just a example, don't need so many eslint config for fast try) gatsby(@next) not working with eslint@v6.x.x example sceenshot n/a i am mobxjs team member, so this is just a simple support for @mobxjs user commuity </desc> <cmt> chore: update gatsby example for mobx </cmt> <cmt> chore: add new line </cmt>",use mobx v6 in using-mobx example
1870,"<desc> removing redundant boilerplate code now that config for status leds exist. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> refactor to use led config </cmt> <cmt> refactor to use led config </cmt> <cmt> refactor to use led config </cmt>",refactor to use led config - part 1
1871,"<desc> went into trouble when tried to start powershell tab after updating ps to version 5.1. bin\vendor\profile.ps1 : cannot dot-source this command because it was defined in a different language mode. to invoke this command without importing its contents, omit the '.'  operator. at line:1 char:1 . 'bin\vendor\conemu-maximus5..\profi ... + categoryinfo          : invalidoperation: (:) [profile.ps1], notsupportedexception + fullyqualifiederrorid : dotsourcenotsupported,profile.ps1 google helped me to find out that ""."" invocation (dot-sourcing) is kinda deprecated or announced as insecure feature, but can be replaced with import-module commandlet </desc> <cmt> update profile.ps1 </cmt> <cmt> fixes powershell 5.1 error when windows software restriction policy is enabled: </cmt> <cmt> bin\vendor\profile.ps1 : cannot dot-source this command because it was defined in a different language mode. to invoke this command without importing its contents, omit the '.'  operator. </cmt> <cmt> at line:1 char:1 </cmt> <cmt> + . 'bin\vendor\conemu-maximus5\..\profi ... </cmt> <cmt> + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </cmt> <cmt> + categoryinfo          : invalidoperation: (:) [profile.ps1], notsupportedexception </cmt> <cmt> + fullyqualifiederrorid : dotsourcenotsupported,profile.ps1 </cmt> <cmt> powershell 5.1 compatibility </cmt> <cmt> fixes powershell 5.1 error when windows software restriction policy is enabled: </cmt> <cmt> bin\vendor\profile.ps1 : cannot dot-source this command because it was defined in a different language mode. to invoke this command without importing its contents, omit the '.'  operator. </cmt> <cmt> at line:1 char:1 </cmt> <cmt> + . 'bin\vendor\conemu-maximus5\..\profi ... </cmt> <cmt> + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </cmt> <cmt> + categoryinfo          : invalidoperation: (:) [profile.ps1], notsupportedexception </cmt> <cmt> + fullyqualifiederrorid : dotsourcenotsupported,profile.ps1 </cmt>",powershell 5.1 and windows software restriction policy compatibility
1872,"<desc> minor updates to explore docs to better reflect the current version. update/add new screenshots reflecting current ui. includes db migration (follow approval process in sip-59) </desc> <cmt> update db modal screenshots, rm stale info </cmt> <cmt> pivot table v2 tutorial </cmt> <cmt> more updates </cmt>",various updates to match latest superset version
1873,"<desc> reland: #56167 requires cl/312100656 </desc> <cmt> [flutter_tools] integration l10n tool </cmt> <cmt> add runtime skip to build system </cmt> <cmt> update build_system.dart </cmt> <cmt> add links to issues, comments </cmt> <cmt> update packages/flutter_tools/test/general.shard/build_system/build_system_test.dart </cmt> <cmt> update packages/flutter_tools/lib/src/build_system/targets/localizations.dart </cmt> <cmt> update localizations.dart </cmt> <cmt> switch to gen_l10n localizations </cmt> <cmt> fix tests </cmt>",integrate l10n tool into hot reload/restart/build
1874,<desc> implements #6874. thanks for reviewing! </desc> <cmt> added reactprodinvariant and the corresponding babel pass </cmt> <cmt> added stack info to the query params </cmt> <cmt> fixed actual module names </cmt> <cmt> wip added a prod test (failing) </cmt> <cmt> error.stack null check </cmt>,add reactprodinvariant and corresponding babel rewrite pass
1875,<desc> this pr add feature to save filters sets in metadata and remove them from there. also here fixed relevant bug that sometimes dashboard is updated when non-instant filter changed. screen.recording.2021-02-18.at.12.51.11.mov test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> feat: poc adding filters set feature </cmt> <cmt> lint: fix ts </cmt> <cmt> fix: fix ff name </cmt> <cmt>  conflicts: </cmt> <cmt> 	superset-frontend/src/featureflags.ts </cmt> <cmt> 	superset/config.py </cmt> <cmt> refactor: fix cr notes </cmt> <cmt> fix: fix update values in filter bar </cmt> <cmt> refactor: save filter sets in meta </cmt> <cmt>  conflicts: </cmt> <cmt> 	superset-frontend/src/dashboard/actions/nativefilters.ts </cmt> <cmt> 	superset-frontend/src/dashboard/components/nativefilters/filterbar/filterbar.tsx </cmt> <cmt> 	superset-frontend/src/dashboard/reducers/nativefilters.ts </cmt> <cmt> feat(filter-sets): save filters sets in metadata </cmt>,saving filter sets in metadata
1876,"<desc> backport of #10460 . </desc> <cmt> [hotfix][e2e] cleaning logs before executing single tests. </cmt> <cmt> logs of successful tests are cleaned up automatically. however, logs of </cmt> <cmt> failing tests remain to ease debugging. however, if the developer does </cmt> <cmt> not clean them before executing a new test with exception checks, the </cmt> <cmt> new test will fail independent of the actual result as the old logs will </cmt> <cmt> cause the checks to fail. </cmt> <cmt> with this fix, failing tests will not cause subsequent tests to fail </cmt> <cmt> because of parsing old logs. </cmt> <cmt> [hotfix][e2e] removing unused s3 methods </cmt> <cmt> [flink-14574][e2e] replacing s3util with dockerized aws cli enabling </cmt> <cmt> customized endpoints and other features that would needed to be manually </cmt> <cmt> implemented. </cmt> <cmt> [flink-14574][e2e] providing minio based s3 setup allowing users without </cmt> <cmt> aws secrets to test plugins. </cmt> <cmt> [flink-14574][core/e2e] wrap filesystem to use plugin context classloader. </cmt> <cmt> filesystems loaded through pluginmanager are wrapped in </cmt> <cmt> pluginfilesystem, which swaps the context classloader for all direct </cmt> <cmt> methods. thus, lazily loaded classes (security, optimizations) are </cmt> <cmt> loaded with the expected classloader. in particular, </cmt> <cmt> java.util.serviceloader will use that context classloader to load new </cmt> <cmt> services. </cmt> <cmt> this change will fix the s3-hadoop plugin while writing. </cmt> <cmt> also added minio-based s3 batch tests that write to s3. </cmt> <cmt> modified existing s3 batch tests to also write to s3. </cmt> <cmt> modified existing s3 streaming test to checkpoint onto s3. </cmt>",fixing writing with plugin s3 filesystem.
1877,"<desc> implements _makepane in terminalpage, which creates a pane that then can be used to pass into another pane to split or to create a new tab with. places where we split pane or create a new tab now use _makepane. closes #11021 cla signed. if not, go over here and sign the cla i work here stands up to manual testing with multiple new pane/new tab commands as well as startup actions </desc> <cmt> make pane </cmt> <cmt> kinda works </cmt> <cmt> replace more instances </cmt> <cmt> open new tab </cmt> <iss> unify pane splitting and new tab creation </iss>",unify splitting panes and creating new tabs
1878,"<desc> add blackberry 8520 trackpad support for crkbd via two new keymaps. i've created an adapter that allows adding the blackberry 8520 trackpad mod to the crkbd via additional 'adapter' pcb. the adapter pcb uses elite-c board as there are not enough pins on promicro. the trackpad add-on requires different firmware for the left and right keyboards as 'adapter pcb' is used only on the right board and it rewires some pins that were originally set for promicro (like hardware spi pins). please see more details here:   my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add vlukash crkbd keymap to support trackpad adapter. </cmt> <cmt> the trackpad adapter uses elite-c board that has five extra pins. </cmt> <cmt> also spi pins are taken for trackpad, keymap config updates column data </cmt> <cmt> pins for matrix scan. </cmt> <cmt> update vlukash keymap </cmt> <cmt> enable pointing devide, configure mouse btn1 </cmt> <cmt> set tapping_term to 300 </cmt> <cmt> add support for the blackberry 8520 trackpad </cmt> <cmt> add vlukash keymap for master-right no-trackpad version </cmt> <cmt> remap backspace </cmt> <cmt> set extrakey_enable = yes </cmt> <cmt> update thumb keys mappings </cmt> <cmt> set bootloader to atmel-dfu </cmt> <cmt> sync keymap </cmt> <cmt> add scrolling support </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> make debug leds conditional </cmt> <cmt> add support for both flex and no-flex pcbs </cmt> <cmt> add readme and rename root folders </cmt> <cmt> update readme file with blog link </cmt> <cmt> fix readme file formatting </cmt>",add bb8520 trackpad support for crkbd
1879,"<desc> stop wrapping/prepending error messages so that we do not loose the stack trace. for this, update a few manually thrown errors with better messages (usually including a file path). speed up locations by doing manual sourcemapsupport.wrapcallsite() for a single call site. performance gain in the runner process with 100 files x 100 tests each: 25% on the fresh run without babel cache; 80% on the cached run where babel is almost instant. also some obvious cleanups around stack traces (removing unused code). </desc> <cmt> fix(test runner): speed up location calculation </cmt> <cmt> remove prependerrormessage </cmt>",expose real stack traces and speed up locations
1880,"<desc> some users want to use rapidjson with std::string objects.  this pull-request adds an (opt-in) feature to include some basic support.  the implementation uses std::basic_string<ch> as generic string type. genericvalue's string support currently covers: construction / setstring comparison no special apis for addmember or pushback have been added, as std::string most probably requires copying (or an explicit stringref() call).  using the genericvalue constructor should be sufficient: std::string str; d.addmember(""string"", value(str, d.getallocator()).move(), d.getallocator()); the functionality needs to be enabled by defining rapidjson_has_stdstring. the travis ci config has been updated to add this define by default to include the tests. last, but not least, the comparison operators have been refactored to simplify the addition of new overloads (see 702b45b).  with the new forwarding structure, only a single function needs to be added to extend the comparison support. </desc> <cmt> genericvalue: refactoring of operator==/!= </cmt> <cmt> by restructuring the call forwarding of the various operator== and </cmt> <cmt> operator!= overloads, new overloads can be added by simply adding an </cmt> <cmt> additional member operator==. </cmt> <cmt> additionally, the ""ch*"" overloads are dropped in favour of an sfinae </cmt> <cmt> version that removes the pointer variants from matching the templated </cmt> <cmt> operator== (see also operator=). </cmt> <cmt> genericvalue: add (optional) support for std::string </cmt> <cmt> some users may want to use rapidjson with std::string objects.  this commits </cmt> <cmt> adds an (opt-in) feature to include some basic support.  the implementation </cmt> <cmt> uses std::basic_string<ch> as generic string type. </cmt> <cmt> support currently covers: </cmt> <cmt> * construction </cmt> <cmt> * comparison </cmt> <cmt> no special apis for addmember or pushback have been added, as std::string </cmt> <cmt> most probably requires copying (or an explicit stringref() call). </cmt> <cmt> add tests for rapidjson_has_stdstring </cmt> <cmt> .travis.yml: include rapidjson_has_stdstring tests </cmt>",add optional support for std::string
1881,<desc> avoid unnecessary extern storage class specifiers </desc> <cmt> make some global variables static </cmt> <cmt> they do not need to be extern. </cmt> <cmt> fix a linkage error with mac clang </cmt> <cmt> prevent symbol cache variables from being instantiated multipe times. </cmt> <cmt> make some functions static </cmt> <cmt> they don't need to be extern </cmt>,correct storage classes of variables an functions
1882,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see </desc> <cmt> broadens input type </cmt> <cmt> version bump </cmt>,widen input type of schema
1883,"<desc> what did you implement: closes #2882 sdk generation is incomplete with regard to parameters (path, querystring, and headers) for lambda-proxy integration.  allowing only the request.parameters object in configuration allows for the successful generation of an sdk that supports their use. how did you implement it: check for keys other than ""parameters"" on the request object and remove them (showing a warning to the user) if they exist.  maintained existing behavior for response configurations, they are still removed and a warning is shown. how can we verify it: examples: service: test frameworkversion: "">=1.13.2 <2.0.0"" provider: name: aws runtime: nodejs6.10 region: us-east-2 memorysize: 128 functions: helloworld: handler: dist/hello.hello events: - http: path: /{name} method: get request: parameters: querystrings: foo: true paths: bar: true todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> fix for </cmt> <cmt> allow the 'parameters' field of the request object to be configured when using lambda_proxy integration </cmt> <cmt> update to correctly validate the remainder of the request object after stripping non-parameter object off of it and formatting correctly for the cloudformation stack </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> cleanup and tests </cmt>",allow request parameter configuration with lambda-proxy integration
1884,"<desc> it is now considered a historical accident that e.g. for loops and the iter() built-in function do not require the iterators they work with to define __iter__, only __next__. </desc> <cmt> update the glossary </cmt> <cmt> add a news entry </cmt> <cmt> update the built-in functions </cmt> <cmt> add some glossary links to the data model </cmt> <cmt> update stdtypes.rst </cmt> <cmt> clarify collections.abc docs </cmt> <cmt> add glossary links to the c api for iterators </cmt>",fix docs regarding __iter__ and iterators being inconsistently required by cpython
1885,<desc> use newly exposed bwc:minor / checkout artifact as opposed to coding directly against the output of a bwc:minor checkout task. the copy test/api tasks have been updated to lazily compute the subset of the files from the configuration. this is to facilitate compatible testing which needs to filter singular bwc:minor checkout in core/x-pack/project set of files. by default (unless explicitly requested) the copy test/api tasks will continue to use the full filetree of the configuration. related: #63173 </desc> <cmt> initial support </cmt> <cmt> minor change to support jar file </cmt>,gradle - compatible rest test plugin - adopt bwc artifact
1886,"<desc> path/to/binary is the required argument replaces #847 cmd: include replay command in docs even if rr is not installed. @custa the problem with the replay command was my fault, sorry. </desc> <cmt> cmd: include replay command in docs even if rr is not installed. </cmt> <cmt> path/to/binary is the required argument </cmt> <cmt> replaces #847 </cmt>",path/to/binary is the required argument (#847 fixed)
1887,"<desc> this adds an implementation of cat-file to the examples directory that i wrote up when trying to chase down some potential issues in handling repository data. it turned out that everything was fine, but i thought the cat-file example might be interesting to people. it is not a lot of code. while i was working on it, however, i found that there were a few public apis that were not taking const pointers to objects that i really felt should be taking const pointers. it turns out that, in the tree api at least, the reason for this is that we want to do a git_vector_bsearch on the tree entries and that call thinks that it may need to call git_vector_sort so const pointers are disallowed. however, with a little care, we can make sure that the tree object is always sorted and push const-ness back into the api. i did that (asserting that the vector is already sorted and then making the public api take a const pointer to the tree). also, there were a couple of non-const commit apis, but i think that was just an oversight which i also corrected. lastly, i've been building with threadsafe on my local machine and i found that the diff example wouldn't run against a threadsafe build of the library, so i fixed that too. </desc> <cmt> add cat-file example and increase const use in api </cmt> <cmt> this adds an example implementation that emulates git cat-file. </cmt> <cmt> it is a convenient and relatively simple example of getting data </cmt> <cmt> out of a repository. </cmt> <cmt> implementing this also revealed that there are a number of apis </cmt> <cmt> that are still not using const pointers to objects that really </cmt> <cmt> ought to be.  the main cause of this is that git_vector_bsearch </cmt> <cmt> may need to call git_vector_sort before doing the search, so a </cmt> <cmt> const pointer to the vector is not allowed.  however, for tree </cmt> <cmt> objects, with a little care, we can ensure that the vector of </cmt> <cmt> tree entries is always sorted and allow lookups to take a const </cmt> <cmt> pointer.  also, the missing const in commit objects just looks </cmt> <cmt> like an oversight. </cmt> <cmt> make examples/diff.c compile vs threadsafe library </cmt>",add cat-file to examples (with some public api improvements)
1888,"<desc> in support of getsentry/snuba#1683, this change will limit the current org stats page and other places where snuba outcomes tsdb is used to only receive errors. places where this is used do not currently support showing outcomes of different categories, so they need to be restricted to errors. it is my understanding that going forward we will use the new outcomes snuba module in places where we need to query the outcomes dataset. note that the test cases added don't actually test the required snuba changes since this change is going out first. however, i have tested locally and confirmed intended behavior with that branch. #sync-getsentry </desc> <cmt> test filters </cmt> <cmt> use variable </cmt>",filter new outcome category types in snuba tsdb module
1889,"<desc> issue: #11264 add check for api/modules/stories, to only navigate to valid storyid + viewmode fix spelling error in story_store add default values for viewmode & storyid to framesrenderer start a storybook, have it auto-open in the browser expected: the first story is selected in the manager & preview shows it correctly </desc> <cmt> fix #11264 </cmt> <cmt> add check for api/modules/stories, to only navigate to valid storyid + viewmode </cmt> <cmt> fix spelling error in story_store </cmt> <cmt> add default values for viewmode & storyid to framesrenderer </cmt> <cmt> fix versions </cmt>",fix undefined/undefined in url on init
1890,"<desc> the pack/unpack's parameter 'd' and 'f' are machine order in php. the number 236.0 packed to 'd' is: 0000000000806d40. i was reversing a game save file, which uses 406d800000000000. here is how i decode that in php. public function readdouble() { $data = substr($this->stream, $this->ptr, 8); $this->ptr += 8; $data = implode('', array_reverse(str_split($data, 1))); $int = unpack('d', $data); return (double) ($int[1]); } since integers are allowed to pack/unpack in both little endian and big endian, i think double/float also need. in this pr, i choose: e: little endian double e: big endian double g: little endian float g: big endian float. btw, these formats, 'e', 'e', 'g', and 'g' are not taken in perl. </desc> <cmt> pack()/unpack() for big endian float/double and little endian float/double </cmt> <cmt> comments for e,e,g,g </cmt>",pack/unpack double/float in little endian and big endian
1891,"<desc> references #20536 one last indent.  (maybe a bit much, but was syncing repo, forgot branch had already been merged and found it while solving merge conflicts). </desc> <cmt> additivechi2sampler: fix numpy validation errors </cmt> <cmt> ? forgot what i did ? </cmt> <cmt> fixed typo: array or sparse matrix </cmt> <cmt> fixed typos, added missing periods. </cmt> <cmt> found where the missing period is supposed to be </cmt> <cmt> apply suggestions from code review </cmt> <cmt> indent default assignment when it wraps to second line </cmt>",additive chi2 sampler (one last indent)
1892,"<desc> currently there is no smooth way to access checkpoints on cloud storage after a run. this is especially true when e.g. the best checkpoint was trained on a worker node (and not the head node) - the checkpoint lives on cloud storage but may have to be downloaded to the driver node for postprocessing. this pr adds a trialcheckpoint abstraction that is returned by experimentanalysis.get_best_checkpoint() and experimentanalysis.best_checkpoint (instead of the local trial path previously, which did not ensure consistency or even local existence of the checkpoint). the trialcheckpoint keeps a record of a local and cloud location and offers utilities to sync between these: the trialcheckpoint.download() method allows downloading from cloud storage to local storage the trialcheckpoint.upload() method allows uploading from local storage to cloud storage the trialcheckpoint.save() method allows saving to both local and cloud storage and fetches the checkpoint from cloud before if needed this pr adds a new module, ray.tune.cloud, which includes the checkpoint syncing logic. this is somewhat of a duplicate to the ray.tune.sync_client abstractions. this is currently sensible in order to avoid refactoring sync clients in this pr. in a future pr, this should be consolidated. the pr also adds api and local/ci end to end tests. in a follow-up pr, the features should be tested in the tune cloud checkpointing release tests. example usage: best_checkpoint = analysis.best_checkpoint print(""remote checkpoint path"", best_checkpoint.cloud_path) best_checkpoint.save(""./out_checkpoint_dir"") backwards compatibility is achieved by making this a os.pathlike class. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> trialcheckpoint on cloud first iteration </cmt> <cmt> upload api test </cmt> <cmt> finish unit tests </cmt> <cmt> wip: add end to end test </cmt>","introduce trialcheckpoint class, making checkpoint down/upload easie"
1893,"<desc> plus cleaning up some semi-related documentation. </desc> <cmt> macro for a momentary layer switch with mods </cmt> <cmt> passes through to the existing action_layer_mods macro, albeit with more </cmt> <cmt> limited options due to lack of space in the quantum_keycodes enum. </cmt> <cmt> add documentation for lm layer-mod macro </cmt> <cmt> clean up tap toggle documentation </cmt>",add macro for momentarily switching to a layer while some mods are active
1894,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""@definitelytyped/dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: extenddeep]( add it to notneededpackages.json. method signature for util.extenddeep was not correct and did not support adding multiple mergefrom objects. unfortunately, you cannot have ...rest processing of arguments in the middle of a method signature; the ...rest must be the last element. while the type and the function are compatible with this fix, the intellisense documentation won't prompt for the depth parameter. the user will have to look at the node-config documentation to understand all the options. perhaps future versions of node-config will fix this ambiguity in some way. </desc> <cmt> fixing extenddeep signature </cmt> <cmt> adding additional test </cmt>",fixing config js extenddeep signature
1895,<desc> include doc.cats in doc serialization include doc.cats in docbin serialization add tests for doc.cats in doc and docbin serialization fixes #4770. bugfix. i have submitted the spacy contributor agreement. </desc> <cmt> include doc.cats in to_bytes() </cmt> <cmt> include doc.cats in docbin serialization </cmt> <cmt> add tests for serialization of cats </cmt> <cmt> test serialization of cats for doc and docbin. </cmt> <iss> text classification results (document.cat) missing when multiprocessing enabled </iss>,include doc.cats in serialization of doc and docbin
1896,"<desc> the .appveyor.yml file currently uses ""make install"" to perform the tests. the problem is that we recently disallowed (within the host code) to run ""make install"" on non-windows systems. therefore appveyor failed to run the tests for the last months :( since we decided that ""make install"" should only run on linux/maxos/*bsd etc systems, i suggest that we add those system as exceptions (whitelist) and block the ""install"" target on all other supported os. thanks </desc> <cmt> appveyor: use just 'make' instead of 'make install' (which is not supported on windows) </cmt> <cmt> makefile: fixed whitespace by using spaces instead of tabs where possible </cmt> <cmt> makefile: disallow running 'make install' on windows systems (including cygwin/msys etc) </cmt>",the test should not run make install (only test a normal make)
1897,"<desc> closes #30933 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry a new decorator to handle docstring formatting. there is also an update for an existing case to show how it works. </desc> <cmt> add docstring decorator </cmt> <cmt> use doc decorator for _shared_docs['factorize'] </cmt> <iss> doc: replace old string formatting syntax in calling of appender decorators </iss>",replace appender and substitution with simpler doc decorator
1898,"<desc> support for bazel 0.7.0, but continues to work with bazel 0.6.0. the link option is unfortunate, but i think this must be some change to flags within bazel 0.7.0. as noted in the build file, gperftools has already removed the feature that causes this and the linker flag can be removed after their next release. (see discussion in gperftools/gperftools#901) also modifies mac ci build to be more explicit about options (instead of trying to use .bazelrc). </desc> <cmt> macos build: changes to support bazel 0.7.0 </cmt> <cmt> macos ci: attempt to avoid no output timeout </cmt>",bazel 0.7.0 support and more regular ci output
1899,"<desc> issue: currently main is waiting to register its services, until the shared process is ready and initialised. this is an issue if services in shared process need to request main during initialisation. eg: storage service initialisation on shared process. given this scenario where main as server and shared process as client, server can wait until the client connection is established to register its channels. this pr introduces a new barrier whenipcready that is released when shared process ipc (client) is ready and thereafter server (main) can register its channels. those who are clients to shared process should keep continue to wait whenready that is when shared process is ready and initialised. </desc> <cmt> shared process - add separate whenipcready </cmt> <cmt> shared process - register channels when ipc ready </cmt>",separate shared process ipc (client) ready and server ready
1900,"<desc> the full enum definitions let intellisense work in visual studio, but the original variables are also still there so existing code doesn't break. there were a couple of cases where variables were defined as enums but weren't, although, except for debugging, i'm not sure these are very significant. most of the arguments to the datatexture constructor should be optional so i made them so. </desc> <cmt> added enum definition values to make intellisense work in visual studio. </cmt> <cmt> changed the type of mapping to functions from enum </cmt> <cmt> changed the type of pathactions members to a user type string from enum </cmt> <cmt> fixed the implicit any and made several of the datatexture constructor's arguments optional. </cmt>",threejs - added enum definitions and fixed a few mis-definitions
1901,"<desc> tested with 3.0. updated the sdk version for the prerequisite added a brief explanation for dotnet new command params. fixes #10479 </desc> <cmt> just updated sxs link per issue 10559 </cmt> <cmt> updates for side by side and web root references </cmt> <cmt> updated per tdykstra recommendations, link changes </cmt> <cmt> changes xref to relative link for web root </cmt> <cmt> link fix, switching contentroot to webroot </cmt> <cmt> updated for 3.0 </cmt>",update asp.net core get started for 3.0
1902,"<desc> in #53637 and #53410, we refactored nodesinforequest and nodesstatsrequest to have a general interface for adding metrics to the request. here, we refactor the corresponding builders to match this interface. the change has been straightforward, so i'm handling nodesinforequestbuilder and nodesstatsrequestbuilder in a single pr. </desc> <cmt> remove hard-coded setters from nodesinforequestbuilder </cmt> <cmt> remove hard-coded setters from nodesstatsrequest </cmt>",refactor nodes stats request builders to match requests
1903,<desc> reland of previous pr #33800 with removed dependency on package test </desc> <cmt> add capability to flutter test --platform=chrome </cmt> <cmt> cleanup dependencies </cmt> <cmt> fix license headers </cmt> <cmt> fix imports </cmt> <cmt> make sure we dont compile tool to web </cmt> <cmt> add ignores </cmt> <cmt> address comments </cmt> <cmt> insource a stripped down b manager </cmt> <cmt> use in sourced browser manager </cmt> <cmt> remove flutter tool import </cmt> <cmt> remove imports </cmt> <cmt> fix pubspec </cmt>,reland support flutter test on platform chrome
1904,<desc> #2408 </desc> <cmt> move rule-definition to another package </cmt> <cmt> adjust function position </cmt> <cmt> add parseruleregistrytest.java </cmt> <cmt> add rule definition for oracle </cmt> <cmt> add rule definition for for pg </cmt> <cmt> add rule definition for sql server </cmt> <cmt> add assertmasterslaveparseruleregistry </cmt> <cmt> add rule definition for encrypt </cmt> <cmt> add rule definition for ms </cmt> <cmt> add parseruleregistrytest </cmt>,add test cases for loading parsing rule
1905,"<desc> wip, please do not merge! initial commit of the laptreus bluetooth keyboard. this adds the default, and a personal layout, as well as beginning on a doc for a debug layout. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> add userspace files for vosechu </cmt> <cmt> code review corrections </cmt> <cmt> few more code review corrections </cmt>",initial commit of laptreus keyboard
1906,<desc> since the correct/optimal value is defined in boards.json for every board/variant the code change is tested and works with tasmota core esp32 v.1.0.7 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> rm upload speed </cmt> <cmt> rm upload speed </cmt> <cmt> add 4m board variants </cmt> <cmt> rm upload speed </cmt> <cmt> rm upload speed </cmt>,remove platformio global upload speed setting
1907,"<desc> issue: this pr is based on the changes in #4027. in order to support a single standard of configuration, i've changed core and frameworks to work with presets. </desc> <cmt> initial implementation of the core and framework presets </cmt> <cmt> fix presets.test.js </cmt> <cmt> combine all presets to one and add core-preset-babel-cache and core-preset-webpack-custom </cmt> <cmt> build ""entries"" with presets and inject them to the presets.extendwebpack </cmt> <cmt> logging presets with ""=>"" </cmt>",refactor core and frameworks to work with presets
1908,<desc> r? @catamorphism first contribution; contains struct definitions and some useful traits.  can possibly be improved by removing the dependence on the clone trait.  this is intended to be the beginning of a long-term project. </desc> <cmt> added skeleton implementation of a b-tree with a few bells and </cmt> <cmt> whistles.  no major functionality added yet (such as insertion and </cmt> <cmt> removal). </cmt> <cmt> re-arranging some things in btree.rs to accommodate testing. </cmt>,skeleton implementation of a b-tree: issue 4992
1909,"<desc> use an externs file for fullscreen-related functionality on the player object. otherwise, closure compiler replaces them with minified method names and makes it impossible to supply a simpler ""player"" object with customized fullscreen logic for the fullscreentoggle to interact with. </desc> <cmt> fix typo in test description </cmt> <cmt> availble -> available </cmt> <cmt> don't use minifiable player methods in fullscreentoggle </cmt> <cmt> use string literals to lookup fullscreen-related methods on the player object in the fullscreentoggle component. otherwise, closure compiler replaces them with minified method names and makes it impossible to supply a simpler ""player"" object with customized fullscreen logic for the fullscreentoggle to interact with. </cmt> <cmt> use externs to prevent obfuscation </cmt> <cmt> instead of using string literals, create an externs file for the player and use that to ensure fullscreen functionality is never minified. </cmt>",add a vjs.player externs file for fullscreen functionality
1910,"<desc> this patchset adds support for capturing from a different x server by implementing advanced settings for the xshm plugin which allow the user to select a specific x server if he chooses so. due to issues with the properties system, the old integer control to select the captured screen was replaced with a select list. </desc> <cmt> linux-xshm: improve source struct. </cmt> <cmt> this adds documentation to the source struct and moves one bool to the </cmt> <cmt> end to avoid a hole due to alignment. </cmt> <cmt> linux-xshm: use macro for logging. </cmt> <cmt> this adds a macro to automatically prepend the plugin name to debug </cmt> <cmt> statements like it is done in other plugins. </cmt> <cmt> linux-xshm: improve geometry update function. </cmt> <cmt> this adds the screen id from the source properties to the source </cmt> <cmt> struct and changes the geometry function to use that value instead </cmt> <cmt> of requiring the settings object of the source. </cmt> <cmt> linux-xshm: small change for texture update function. </cmt> <cmt> this removes the entering/leaving of the graphics context from this </cmt> <cmt> function and requires the calling code to make sure the context is </cmt> <cmt> present. </cmt> <cmt> linux-xshm: refactoring of setup code. </cmt> <cmt> this moves the code to start/stop the capture to respectively named </cmt> <cmt> function in order to clean up the update function. </cmt> <cmt> this means that the capture is stopped/started whenever the settings are </cmt> <cmt> changed. while this increases overhead for some settings, this will also </cmt> <cmt> enable future settings that require a full restart of capture process. </cmt>",allow capturing from a different x server
1911,"<desc> a 50ms delay will often causes failures on slower machines. this pr is an alternative to pr gh-14926. in this pr, both of the tests with a delay have been merged into one, to avoid multiple time.sleep() calls, reducing the overall run time. for reference, the total run time for test_idle on my machine is about 7.5 seconds. 0.15 seconds, which is the delay time added by these tests, is 2% of that. </desc> <cmt> refactor common check into a method </cmt> <cmt> refactor hover tests with a delay into a single test </cmt> <cmt> this is done to avoid waiting for a delay to expire multiple times. </cmt> <cmt> increase hover delay and sleep duration for robustness </cmt> <cmt> minor: whitespace and import ordering </cmt> <cmt> add a news entry </cmt>",idle: fix and optimize flaky tool-tip hover delay tests
1912,"<desc> this is a fix for regression in not-needed script introduced in #49620 by removing of the forth parameter and not shifting the fifth </desc> <cmt> fix not-needed script regression, introduced by removing of the sourcerepourl parameter in #49620 (3868b76e679793d5918c5e5262ab4bccdcaf829d) </cmt> <cmt> doc fix example of npm run not-needed </cmt>",bugfix not-needed script argument parsing
1913,"<desc> this pr adds support for custom sizes when creating fluid images. the current implementation returns sizes in the following way: num / 4   // if num is 800 --> 200 num / 2   // if num is 800 --> 400 num       // if num is 800 --> 800 num * 1.5 // if num is 800 --> 1200 num * 2   // if num is 800 --> 1600 num * 3   // if num is 800 --> 2400 with this pr you have direct control of the sizes you get back by using a new parameter called customsizes. see the example for how it works. example query (for this example image.jpg has a width of 1000) { fluid: file(relativepath: {eq: ""image.jpg""}) { childimagesharp { fluid (customsizes: [ 50, 180, 400, 710, 900 ]) { src sizes srcset } } } } output { ""data"": { ""fluid"": { ""childimagesharp"": { ""fluid"": { ""src"": ""/static/image-f00db918cb54b413b814ed8e193478ad-97776.jpg"", ""sizes"": ""(max-width: 800px) 100vw, 800px"", ""srcset"": ""/static/image-f00db918cb54b413b814ed8e193478ad-12166.jpg 50w,\n/static/image-f00db918cb54b413b814ed8e193478ad-3e6f0.jpg 180w,\n/static/image-f00db918cb54b413b814ed8e193478ad-7d9ea.jpg 400w,\n/static/image-f00db918cb54b413b814ed8e193478ad-97776.jpg 710w,\n/static/image-f00db918cb54b413b814ed8e193478ad-a0877.jpg 900w,\n/static/image-f00db918cb54b413b814ed8e193478ad-fd737.jpg 1000w"" } } } } } here's srcset in a more readable format: /static/image-f00db918cb54b413b814ed8e193478ad-12166.jpg 50w, /static/image-f00db918cb54b413b814ed8e193478ad-3e6f0.jpg 180w, /static/image-f00db918cb54b413b814ed8e193478ad-7d9ea.jpg 400w, /static/image-f00db918cb54b413b814ed8e193478ad-97776.jpg 710w, /static/image-f00db918cb54b413b814ed8e193478ad-a0877.jpg 900w, /static/image-f00db918cb54b413b814ed8e193478ad-fd737.jpg 1000w some questions should maxwidth automatically be inserted into the customsizes array so that we have a perfect fit? right now the nearest width to maxwidth is selected for src. (in the example above the 710w version is chosen for src.) is customsizes a good name for it? </desc> <cmt> update lockfile after imagemin-mozjpeg was added to gatsby-plugin-sharp/package.json in #8621 </cmt> <cmt> sizes for srcset can be configured </cmt> <cmt> use ternary </cmt> <cmt> add check to see if array exists </cmt> <cmt> change name to customsizes </cmt> <cmt> add documentation and description </cmt> <cmt> add test for custom sizes </cmt>",add custom sizes for fluid images
1914,"<desc> explanation: improve the fix-it for the @nskeyedarchivelegacy attribute to provide the class name one should use for archive compatibility, and ban the implementation-detail @_staticinitializeobjcmetadata attribute. scope: ui improvement to a newly-added attribute. radar: rdar://problem/32118614 risk: extremely low; this tunes the diagnostic text of a new warning and bans the use of a new, hidden attribute. testing:  compiler regression testing. </desc> <cmt> [type checker] provide actual objc runtime name in @nskeyedarchivelegacy fix-its. </cmt> <cmt> (cherry picked from commit 6ceb47bd6cf4285a40d9708552a21c181845b4ab) </cmt> <cmt> ban the use of @_staticinitializeobjcmetadata; it's an implementation detail. </cmt> <cmt> (cherry picked from commit 23bc3223ce8b5f6ab9d1d16b074034f2c9f3ee1e) </cmt> <cmt> add a note about deliberate use of the swift 3 mangling. </cmt> <cmt> (cherry picked from commit 2986e816c72bf4c2b7df93450cccf0b6dc56841c) </cmt> <cmt> only enable nscoding-related runtime name warnings with objective-c interop </cmt> <cmt> (cherry picked from commit 5a67ecceb4c2fdbfec7854d6229ddcd677924892) </cmt>",clean up diagnostics for @nskeyedarchivelegacy attributes
1915,"<desc> this includes: #14880 #14929 with those changes,  rdar://problem/37710244 </desc> <cmt> restore build and install of the swiftimageinspectionshared library </cmt> <cmt> commit 0c42b57962 (""elf: restructure image metadata registration"") </cmt> <cmt> removed the swift_install_in_component lines for both </cmt> <cmt> swiftimageinspectionstatic and swiftimageinspectionshared libraries, </cmt> <cmt> even though only the former library was removed in that change. as a </cmt> <cmt> result, the swiftimageinspectionshared was not being built or </cmt> <cmt> installed. this should fix sr-7038. </cmt> <cmt> rdar://problem/37710244 </cmt> <cmt> utils: add -lswiftimageinspectionshared to static-executable-args.lnk </cmt> <cmt> this fixes the -static-executable part of the problem reported in </cmt> <cmt> sr-7038 (rdar://problem/37710244). </cmt>",cherry-pick the remaining fixes for swift 5.0
1916,<desc> update check for at least one evaluation document for goldcorpus / example updates and ignore misaligned none label in ner checks. bugfix. i have submitted the spacy contributor agreement. </desc> <cmt> add error in debug-data if no dev docs are available (see #4575) </cmt> <cmt> update debug-data for goldcorpus / example </cmt> <cmt> ignore none label in misaligned ner data </cmt>,fix minor issues in debug-data
1917,"<desc> with this pr we properly check rest parameters of any subtype of any[], including user-defined array types and unions of tuple types. in cases where a rest parameter type is not exactly a t[] or a tuple type, we now collect the corresponding remainder of the argument list as a tuple type and then check that this tuple type is assignable to the rest parameter type. declare const foo: (x: string, ...args: [string] | [number, boolean]) => void; declare const t: [string] | [number, boolean]; foo(""abc"", ""def"");  // ok foo(""abc"", 10, true);  // ok foo(""abc"", ...t);  // ok foo(""abc"", 10);  // error, [number] not assignable to [string] | [number, boolean] foo(""abc"");  // error, [] not assignable to [string] | [number, boolean] effectively, rest parameters typed as unions of tuple types provide a form of overloading expressed in a single function type signature. unlike regular overloading, generic rest parameters can be used to form composed overloads: type func<t extends any[]> = (x: string, ...args: t) => void; declare const f: func<[] | [string] | [number, ...boolean[]]>; f(""abc""); f(""abc"", ""def""); f(""abc"", 10); f(""abc"", 10, true); f(""abc"", 10, true, false); f();  // error f(""abc"", true);  // error function type relations have been improved to handle rest parameters of union types: declare let f1: (x: string, ...args: [string] | [number, boolean]) => void; declare let f2: (x: string, y: string) => void; declare let f3: (x: string, y: number, z: boolean) => void; declare let f4: (...args: [string, string] | [string, number, boolean]) => void; f2 = f1;  // ok f3 = f1;  // ok f4 = f1;  // error, misaligned complex rest types f1 = f2;  // error f1 = f3;  // error f1 = f4;  // error, misaligned complex rest types note that we currently don't ""normalize"" misaligned rest parameters. it would certainly be possible to do so, but it is not clear that the additional complexity is merited. fixes #26110. fixes #26491. </desc> <cmt> use getspreadargumenttype when relating to complex rest parameter types </cmt> <cmt> accept new baselines </cmt> <cmt> revise complex rest parameter handling in relations and inference </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",improve checking of complex rest parameter types
1918,"<desc> if a jsx element has both a children prop and children (ie. <div children={childone}>{childtwo}</div>), ie throws an multiple definitions of a property not allowed in strict mode. this modifies the previous fix (which used an object.assign) by making the duplicate children a sequence expression on the next prop/child instead so that ordering is preserved. for example: <component children={usea()} foo={useb()} children={usec()}>{used()}</component> should compile to react.jsx(component, {foo: (usea(), useb()), children: (usec(), used)}) </desc> <cmt> add code </cmt> <cmt> modified comment </cmt>",modify babel react jsx duplicate children fix
1919,<desc> fixes #21556 this pr proposes to enhance the documentation of sklearn.metrics.mean_absolute_percentage_error by removing a false statement in the documentation and by providing a new example to understand one of the caveats of mape. </desc> <cmt> enhanced the core documentation of mean_absolute_percentage_error </cmt> <cmt> added a pathological example to show caveats </cmt> <iss> mean_absolute_percentage_error error in the documentation </iss>,"enhance mape documentation, fixes #21556"
1920,<desc> fixes for: unused variables reduce scope of variables remove unnecessary checks static_cast vs. c-style casts pass const function parameter by reference </desc> <cmt> db/db_iter.cc: remove unused variable </cmt> <cmt> db/db_test.cc: reduce scope of some variables </cmt> <cmt> db/deletefile_test.cc: remove unused variable </cmt> <cmt> table/cuckoo_table_reader.cc: pass func parameter by reference </cmt> <cmt> fix for: </cmt> <cmt> [table/cuckoo_table_reader.cc:196]: (performance) function </cmt> <cmt> parameter 'target' should be passed by reference. </cmt> <cmt> table/format.cc: reduce scope of some variables </cmt> <cmt> db/db_test.cc: remove unused variable </cmt> <cmt> table/block_based_table_builder.cc: remove unused variable </cmt> <cmt> document_db.cc: remove unused variable </cmt> <cmt> util/cache_test.cc: use static_cast over c-style cast </cmt> <cmt> db/version_set.cc: remove unnecessary checks </cmt> <cmt> fix for: </cmt> <cmt> [db/version_set.cc:1219]: (style) unsigned variable 'last_file' </cmt> <cmt> can't be negative so it is unnecessary to test it. </cmt> <cmt> [db/version_set.cc:1234]: (style) unsigned variable 'first_file' </cmt> <cmt> can't be negative so it is unnecessary to test it. </cmt> <cmt> ttl/ttl_test.cc: pass const string param by reference </cmt> <cmt> document_db_test.cc: pass const string param by reference </cmt> <cmt> backupable_db_test.cc: pass const string param by reference </cmt>,fix some issues from sca
1921,<desc> fix issues parsing direct dependency urls fix vistir rmtree error handling automated attempts at chmod invocation which may not always be permitted fix nested direct dependency parsing parse requires-python values specifying constraint versions of python starting from 1.x fixes #4226 fixes #3964 fixes #3976 requires updated vendored dependencies including vistir and requirementslib: requirementslib 1.5.8 => 1.5.9 vistir 0.5.0 => 0.5.1 jinja2 2.11.1 => 2.11.2 click 7.1.1 => 7.1.2 dateutil (none) => 2.8.1 backports.functools_lru_cache 1.5.0 => 1.6.1 enum34 1.1.6 => 1.1.10 toml 0.10.0 => 0.10.1 importlib_resources 1.4.0 => 1.5.0 </desc> <cmt> re-vendor vistir and requirementslib </cmt> <cmt> - fix issues parsing direct dependency urls </cmt> <cmt> - fix vistir rmtree error handling automated attempts at chmod </cmt> <cmt> invocation which may not always be permitted </cmt> <cmt> - fix nested direct dependency parsing </cmt> <cmt> - fixes #4226 </cmt> <cmt> - fixes #3964 </cmt> <cmt> parse requires-python values of old pythons </cmt> <cmt> - parse requires-python values specifying constraint versions of </cmt> <cmt> python starting from 1.x </cmt> <cmt> - requires updated vendored dependencies including vistir and </cmt> <cmt> requirementslib: </cmt> <cmt> - **requirementslib** 1.5.8 => 1.5.9 </cmt> <cmt> - **vistir** 0.5.0 => 0.5.1 </cmt> <cmt> - **jinja2** 2.11.1 => 2.11.2 </cmt> <cmt> - **click** 7.1.1 => 7.1.2 </cmt> <cmt> - **dateutil** (none) => 2.8.1 </cmt> <cmt> - **backports.functools_lru_cache** 1.5.0 => 1.6.1 </cmt> <cmt> - **enum34** 1.1.6 => 1.1.10 </cmt> <cmt> - **toml** 0.10.0 => 0.10.1 </cmt> <cmt> - **importlib_resources** 1.4.0 => 1.5.0 </cmt> <iss> pipenv does not follow url-based subdependencies of a url-based dependency </iss> <iss> pipenv fails to resolve subdependency </iss> <iss> pipenv 2020.4.1b1: keyerror: 1 on install </iss>,fix direct dependency url parsing
1922,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> add common struct for skip indices </cmt> <cmt> implement methods for index struct </cmt> <cmt> intermediate stage (doesn't compile) </cmt> <cmt> i'm able to build it </cmt> <cmt> indices description as vector </cmt> <cmt> split files </cmt> <cmt> better naming </cmt> <cmt> more readable code </cmt> <cmt> fix bug with empty column </cmt> <cmt> merge with consistent_metadata2 </cmt>,more consistent metadata for secondary indices
1923,"<desc> in a second version of #26050 i want to introduce alternate forms of unmerge that 1) partition events by slightly different criteria 2) emit slightly different snuba replacements instead of writing completely separate tasks that do the same thing, let's refactor unmerge such that the user can inject logic from the outside. for that the unmergereplacement abc is used, to inject all logic from the outside that is specific to how current unmerge works. this also creates a separation between ""fingerprints"" that need to be unmerged and postgres grouphashes that need to be locked, something which will drift apart further with future implementations of that baseclass. in addition the unmerge task arguments have been refactored to be strongly typed. while introducing the replacement argument i found that i didn't really understand what all these arguments were for and made an effort to make them slightly more strongly typed. there's still room for improvement to make typing more rigorous: one could create pg group and eventstream_state in the first iteration regardless of whether destination_events have been found. then those fields can become non-nullable on successiveunmergeargs. this is a behavioral change one could refactor the single test to not pass in a destination_id.. i didn't dare to do this because essentially i'd have to rewrite the test amendment: allow unmerging into multiple groups from unmerge task we realized that future implementors of unmergereplacement will need to unmerge a set of events into multiple groups. since the unmerge task can only take one destination_id at the moment, this would mean that we'd have to spawn n tasks which would iterate through all events each and potentially interfere wrt pagination. </desc> <cmt> ref: really allow passing destination_id into unmerge task </cmt> <cmt> ref: class-based unmerge arguments </cmt>",class-based and typed unmerge arguments
1924,"<desc> hello, this is just a tiny pull request that add the missing entries of the #13326 and #13363 pull requests. also fix few typos in the documentation. i think that this is really three different commits but to avoid noise on the tracker but if you want me to squash them, let me know! have a nice day. </desc> <cmt> add a changelog entry for #13363 [ci skip] </cmt> <cmt> add a changelog entry for #13326 [ci skip] </cmt>",add missing changelog entries and fix few typos
1925,"<desc> when updating netdata using netdata-updater.sh, certain variables are expanded on every iteration. for example the path variable is getting bigger and bigger. this pr attempts to fix this. path keeps only unique entries netdata_configure_options keeps each option only once. so, netdata can be updated repeatedly using netdata-updater.sh without magnifying these variables. </desc> <cmt> avoid magnifying path </cmt> <cmt> prevent magnifying configure options </cmt> <cmt> added missing quote </cmt>",prevent magnifying bash variables while updating netdata
1926,"<desc> added a haskell implementation for converting a decimal number to a k-bit binary number. also, updated the package specific readme.md </desc> <cmt> added haskell implementation for decimal to binary conversion. updated package specific readme doc. </cmt> <cmt> updated readme, improved design. </cmt>",added haskell implementation for converting from decimal number to binary number
1927,"<desc> original pull-request #21438 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> multimessage avro format for kafka test </cmt> <cmt> kafka/avro works against table </cmt> <cmt> avro bug with format_setting reference and a typo in kafka test </cmt> <cmt> avrorowinputformat::readprefix inroduced </cmt> <cmt> old avro test data removed </cmt>",loading more than one avro formatted message from kafka does not work
1928,"<desc> quantum algorithms #4116 added python implementation of shor's algorithm used in quantum computing in quantum_algorithms folder. </desc> <cmt> grover's algorithm in python issue [quantum algorithms #4116] (#1) </cmt> <cmt> * create readme.md for grover's algorithm </cmt> <cmt> added python implementation of grover's algorithm used in quantum computing. </cmt> <cmt> * add: grover's algorithm implementation </cmt> <cmt> code to implement the problem stated in readme.md </cmt> <cmt> * add: solution to p-1 in readme.md </cmt> <cmt> * update and format p1_grover_plot.py using black </cmt> <cmt> shor's algorithm in python issue [quantum algorithms #4116] (#1) (#2) </cmt> <cmt> * create readme.md for shor's algorithm </cmt> <cmt> * update readme.md </cmt> <cmt> * add: solution p1_shor_primefactorization.py </cmt> <cmt> revert ""shor's algorithm in python issue [quantum algorithms #4116] (#1) (#2)"" </cmt> <cmt> this reverts commit f49c128b2ebb98bec7e0c429215341478eab2bff. </cmt>",shor's algorithm in python [quantum algorithms #4116] (#1)
1929,<desc> recently i setup a project for win32 daily builds.  could you include a link to this in the document? i also added how to install ag on msys2. </desc> <cmt> doc: add a link to win32 unofficial daily builds </cmt> <cmt> doc: describe how to install on msys2 </cmt>,"update windows doc, add a link to daily builds"
1930,"<desc> device lab failures should be fixed by updating package:dds from 1.2.1->1.2.2. </desc> <cmt> reland ""add support for dart development service (dds) in flutter tools (#59114)"" (#61276)"" </cmt> <cmt> this reverts commit 5b9c6e2b0ec69b0a7ac88d48a64d659c26709e8f. </cmt> <cmt> roll dds dependency </cmt>","reland ""add support for dart development service (dds) in flutter tools (#61276)"""
1931,"<desc> cherry-pick for swift-3.1-branch of #5977 includes option setting the bridging pch system to off by default. see rdar://29016063 </desc> <cmt> [bridging pch] add clangimporter::emitbridgingpch. </cmt> <cmt> [bridging pch] add -emit-pch to frontend; call emitbridgingpch. </cmt> <cmt> [bridging pch] store clangimporter::bridgingheaderlookuptable indirectly. </cmt> <cmt> [bridging pch] populate bridging lookup table when reading mk_pch module. </cmt> <cmt> [bridging pch] pass .pch bridging headers to clang -import-pch </cmt> <cmt> [bridging pch] add testcase for emitting, importing a bridging pch file. </cmt> <cmt> [bridging pch] auto-generate and use temporary bridging pchs from driver. </cmt> <cmt> [bridging pch] warn on non-redundant implicit bridging-header imports. </cmt> <cmt> we're trying to get rid of implicit bridging-header imports, as a feature. </cmt> <cmt> these are imported_header blocks left in modules built with bridging </cmt> <cmt> headers, that trigger re-importing the bridging header into any client </cmt> <cmt> that imports the module. </cmt> <cmt> as a half-way measure to deprecating them, we add a warning here that </cmt> <cmt> triggers when an implicit bridging-header import occurs that is _not_ </cmt> <cmt> suppressed as redundant by clang. </cmt> <cmt> [bridging pch] handle mixed pch + implicit bridging header imports. </cmt> <cmt> this happens fairly regularly in unit testing scenarios. </cmt> <cmt> [bridging pch] add -enable-bridging-pch option, set default to disabled. </cmt>",rdar 29016063 swift 3.1 branch precompile bridging header
1932,<desc> these changes update the jruby/jdbc database support to be a little friendlier. you will be able to use rails new app with no arguments and get a proper jruby/sqlite3-based rails app. rails new app -d sqlite3 and rails new app -d jdbcsqlite3 will do the same thing. add a rails new app -d jdbc template for all other databases. </desc> <cmt> remove superfluous pg driver install instructions </cmt> <cmt> add generic 'jdbc' database option </cmt> <cmt> convert database names to ones appropriate for jruby </cmt> <cmt> use non-'jdbc*' names so that db:create and db:drop work </cmt>,more jruby gem for database fixes
1933,"<desc> these are a few trivial things i noticed while browsing serializers.py. please see the commits. </desc> <cmt> serializers: removes no longer needed compat checks </cmt> <cmt> uuidfield and durationfield are both supported in all supported django </cmt> <cmt> versions. </cmt> <cmt> ipaddressfield was removed in django 1.9, which is no longer supported. </cmt> <cmt> serializers: move related code closer together </cmt> <cmt> this way it's easier to see all of the mappings in one place. </cmt> <cmt> serializers,docs: remove some drf 2.x references </cmt> <cmt> the last release of drf 2.x was 5 years ago, it seems fine to remove </cmt> <cmt> these references now. </cmt>",remove a few no longer needed compat checks and references
1934,"<desc> unit tests for plugins are totally unrealistic (no plugin structure, in same classpath/loader, etc). we tried to support the extra permissions for insecure plugins by using file:/- as a url, to match anything. this would also work on windows. but it would not work on windows if the tests were running from a different drive letter than e.g. .m2/repository. here is a different solution (tested on windows). it adds complexity but only to test code. we can't let our real code get complicated because of the crazy way these things are tested... closes #13623 </desc> <cmt> support tests for insecure plugins on systems with multiple fs roots. </cmt> <cmt> revert ""disable unit tests until they work"" </cmt> <cmt> this reverts commit 606cc456d25aebdbab842de12aca7b2a0f9b4fe1. </cmt> <cmt> revert ""quiet flakey gce tests"" </cmt> <cmt> this reverts commit 7eef7e42d4d2e1ee744c3ed5dab97347df2dd988. </cmt>",insecure plugin tests with multiple roots
1935,"<desc> this is re-applies a squashed version of #64823 as well as including #65337 to fix bugs noted after merging the first pr. the second pr is confirmed as fixing windows-gnu, and presumably also fixes other platforms, such as musl (i.e. #65335 should be fixed); rustup_dist_server= </desc> <cmt> minimize the rust-std component </cmt> <cmt> this splits out a rustc-dev component with the compiler crates, and </cmt> <cmt> keeps the status quo of default installed files on nightly. the default </cmt> <cmt> changing to not install compiler libraries by default is left for a </cmt> <cmt> future pull request. </cmt> <cmt> however, on stable and beta, this does remove the compiler libraries </cmt> <cmt> from the set of libraries installed by default, as they are never needed </cmt> <cmt> there (per our stability story, they ""cannot"" be used). </cmt> <cmt> add rustc-dev to nightly default and complete profiles </cmt> <cmt> package non-rust objects </cmt>",split the rustc target libraries into separate rustc-dev component
1936,<desc> need update in schema-utils @evilebottnawi existing tests no nothing </desc> <cmt> improve performance of limitchunkcountplugin a lot </cmt> <cmt> disallow shorthand cache groups syntax with cache group named test </cmt> <cmt> this is a potential config error </cmt> <cmt> fixes #9722 </cmt> <cmt> improve performance of limitchunkcountplugin a lot </cmt> <cmt> disallow shorthand cache groups syntax with cache group named test </cmt> <cmt> 4.41.0 </cmt>,merge 4.41.0 and upgrade schema-utils
1937,"<desc> added support for google hangouts chat as an alert destination. hangouts chat is google's version of slack and integrated into gsuite. this allows organizations who use gsuite to have a webhook post an alert into a chat room. this is very useful in operational scenarios, where you may be monitoring key metrics and need to be alerted once some threshold criteria is met. like slack, hangouts chat has a web client and mobile client. this integration automatically works with both. the alerts get posted into chat.google.com rooms like this when the alert state returns to normal configuration steps inside hangouts chat click on the room name drowdown, select configure webhooks give it a name, and optionally a link to an icon click save. you will see the url for the webhook. copy this to the clipboard in redash, setup a new alert destination. give it a name (can be anything) paste the webhook url optionally provide a link to an image that will appear in the post setup an alert for a query in redash </desc> <cmt> add support for google hangouts chat as alert destination </cmt> <cmt> remove redundant imports </cmt>",add hangouts chat as alert destination
1938,"<desc> since xcom values can contain pickled data, we would no longer allow editing xcom values from the ui. we don't allow changing dag files from the ui, so this brings xcoms in line with that make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> restrict editing xcom values from the ui </cmt> <cmt> since xcom values can contain pickled data, we would no longer allow editing xcom values from the ui. </cmt> <cmt> we don't allow changing dag files from the ui, so this brings xcoms in line with that </cmt> <cmt> fixup! restrict editing xcom values from the ui </cmt>",restrict changing xcom values from the webserver
1939,"<desc> original pull-request #28036 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update dockerfile </cmt> <cmt> follow-up to #28016 </cmt>",cherry pick #28036 to 21.8: follow-up to #28016
1940,<desc> create ranking data via the general function _create_data() use multiple with statements at one line to not make the code over-indented (#3994 (comment)) </desc> <cmt> simplify dask tests code </cmt> <cmt> enable ci </cmt> <cmt> disable ci </cmt>,simplify code in dask tests
1941,"<desc> this relands #65226, which was reverted in #66918 because it caused regressions in google3 for tests involving page views that used ensurevisible. a test was added in #67021 which covers it. the changes between this and the original change are in b840a8a, which does the following: minor optimization to avoid calculating a rect when targetrenderobject == renderobject override ensurevisible in _pageposition to discard the targetrendreobject. as explained in the comment, this prevents further attempts to ""center"" the target render object, which could result in changing which page is used. @xu-baolin fixes #65100 </desc> <cmt> revert ""revert ""improve the behavior of scrollable.ensurevisible when scrollable nested (#65226)"" (#66918)"" </cmt> <cmt> this reverts commit e8812c409b646d44ade244c6d425c47940214c6b. </cmt> <cmt> fix for page views </cmt> <iss> scrollable.ensurevisible does not work with nested singlechildscrollviews on both axes </iss>",reland ensure visible fix for nested viewports
1942,<desc> figured the adding a default keymap will help those who prefer command line qmk looks like i also forgot an #endif </desc> <cmt> add a default keymap to e6v2 le </cmt> <cmt> forgot to put an endif </cmt> <cmt> add a default keymap for now </cmt>,e6v2 le missing a default keymap
1943,"<desc> please do not merge it now. feedbacks and comments are appreciated. performance tests and improvements is needed. </desc> <cmt> issue #4437: add new tmx. </cmt> <cmt> issue #4437: add test and fix transform. </cmt> <cmt> issue #4437: add dirty tag. </cmt> <cmt> issue #4437: fix some bugs. </cmt> <cmt> issue #4437: fix crash when doesn't support vao, and make calculation more precisely. </cmt> <cmt> issue #4437: config for android and linux. </cmt> <cmt> issue #4437: add vertex z support, fix some bugs. </cmt> <cmt> issue #4437: change name tmxlayer2 and tmxtiledmap2 to fasttmxlayer and fasttmxtiledmap, change point to vec2 </cmt> <cmt> refactor fast tmx rendering </cmt> <cmt> conflicts: </cmt> <cmt> cocos/2d/ccfasttmxlayer.cpp </cmt> <cmt> use quad command for tile map rendering </cmt> <cmt> new version of rendering for tile map </cmt> <cmt> clean up fast tmx code </cmt> <cmt> clean up fast tmx code2 </cmt> <cmt> conflicts: </cmt> <cmt> build/cocos2d_libs.xcodeproj/project.pbxproj </cmt> <cmt> add fast tmx files to xcode project file </cmt> <cmt> using stable sort for quads </cmt>",fast tmx (added culling for tile map)
1944,"<desc> new features ops added onednn reduce_op fwd fp32 and bf16 kernels (reduce_max, reduce_min, reduce_mean, reduce_mul). backward operator will be implemented in the nearest future. </desc> <cmt> added external reorder to profiler </cmt> <cmt> resolved conflicts </cmt> <cmt> added mkldnn reduce op kernel </cmt> <cmt> refactored reduce op </cmt> <cmt> reverted old file </cmt> <cmt> added clang formatting </cmt> <cmt> removed unnecessary imports and comments </cmt> <cmt> minor change </cmt>",added onednn reduce_op fwd kernel
1945,"<desc> this pr bundles all the files under atom.app/contents/resources/atom/* into an asar archive, so the final distribution doesn't contain lots of .js files. it doesn't have other benefits though. fixes #716. </desc> <cmt> asar@0.2.2 </cmt> <cmt> use __dirname when setting globalpaths </cmt> <cmt> put compiled coffee sources into asar archive </cmt> <cmt> set process.resourcespath in c++ </cmt> <iss> ship bundled .js files in .asar package ? </iss>",bundle all the .js files in asar archive
1946,"<desc> incremental updates to dlg's tada68 keymap. disable space cadet map lalt-4 to lalt-f4 so you can close windows in windows remove backlight breathing mapping, does not appear to work. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> alt-4 as alt-f4 </cmt> <cmt> update readme </cmt> <cmt> remove breathing, does not appear to work </cmt>",update dlg's tada68 keymap
1947,"<desc> hello, i'm doing the unattended box on htb and thanks to the video of @ippsec, i have identified that i have missed 2 folders and made some typos in the inital dictionary proposed. this pr address the identified issues. thank you very much in advance. </desc> <cmt> ass html folder </cmt> <cmt> add missing ending / </cmt> <cmt> add www folder </cmt>",add www and html folders
1948,"<desc> also some bug fixes in the c++ autocomplete engine. screenshot of a languageserver crashing: </desc> <cmt> hackstudio: set icon for 'make is not available' notification </cmt> <cmt> languageservers/cpp: handle autocomplete request on an empty line </cmt> <cmt> libcpp: fix lexing & parsing of non-terminated strings </cmt> <cmt> hackstudio: handle crash of the languageserver gracefully </cmt> <cmt> previously, hackstudio exited whenever a languageserver crashed. </cmt> <cmt> now, we disconnect all clients from that language server instance and </cmt> <cmt> show a nice notification. </cmt> <cmt> languageservers/cpp: use parser-based autocomplete engine by default </cmt>",handle languageserver crashing & use parser-based c++ autocomplete by default
1949,"<desc> issue: #10757 this completely overhauls the sidebar. it replaces the tree to be more performant and to add keyboard navigation, as well as expand/collapse all functionality. the search has been replaced to show results in a list instead of filtering the tree, improving usability and performance. furthermore i've added a ""recently opened"" list so allow quickly switching between recently viewed components. additionally, this fixes a bug in composition where stories with the same path/id between refs would both get highlighted when one was selected. subtleties: scroll into view for highlighted and selected nodes allow collapsing a node even if a story is selected inside double expand/collapse via keyboard does expand all / collapse all video:  i've added stories for every major component and state in the sidebar. besides that, it reuses existing logic that's already covered by unit tests. this is going to require significant qa. things to consider: navigating the tree with the mouse navigating with keyboard, both with tab and arrow keys expanding, collapsing nodes + collapse/expand all (try expanding an already expanded node etc) making changes to the storybook (i.e. hmr functionality), does the tree update accordingly and scroll into view? what happens if the selected story becomes broken? enable ""highlight updates"" in react devtools. does it rerender an excessive amount of things? to do link up search results / recently viewed to actually open the selected result properly sync up search input state with downshift state show the first story when clicking to expand a component for the first time search by and highlight the component path as well design approval by @domyen cleanup old stuff qa </desc> <cmt> tweak search input style for recognizability. </cmt> <cmt> tweaks for dark mode compatibility. </cmt> <cmt> tweak visual style of tree items for legibility and contrast. </cmt> <cmt> replace search and tree in sidebar and implement proper keyboard navigation. </cmt>","better search, keyboard shortcuts, and ""recently viewed"""
1950,"<desc> this first attempt will not change functionality. this will add support for toggling a breakpoint for [count] hits. the commands to do this will be dbi  [count]. count is assigned to bp->togglehits, which will be used to determine whether to stop or not. each time a breakpoint is hit, decrement togglehits. once togglehits reaches 0, toggle the bp. if togglehits is initially 0, the bp isn't affected. the next step will be to implement the toggle behavior. i'm still new to the code, but i see a few potential areas i could implement this: in r_debug_bp_hit, r_debug_recoil, and/or r_debug_continue_kill -- might not be a good way, since from what i understand, execution is already expected to stop let the breakpoint plugins handle it let me know any feedback or how it should be implemented differently, thanks. </desc> <cmt> add initial feature support </cmt> <cmt> add temp breakpoint support </cmt> <cmt> remove help message until feature implemented </cmt> <cmt> ... </cmt>",add initial temp breakpoint support
1951,<desc> fix issue sns return message id doesn't match with message id in notification sent fix sns implementation: build message body logic update integration test issue fixed: #2924 sns message id doesn't match in the response and the notification </desc> <cmt> change kinesis consumer timestamp format to unix timestamp (#2835) </cmt> <cmt> release v0.11.4 </cmt> <cmt> support int/str types for dynamodb globalsecondaryindex in cf templates (#2828) </cmt> <cmt>  conflicts: </cmt> <cmt> 	tests/integration/test_cloudformation.py </cmt> <cmt> fix issue sns return message id doesn't match with message id in notification sent </cmt> <cmt> * fix sns implementation: build message body logic </cmt> <cmt> * update integration test </cmt> <cmt> issue fixed: </cmt> <cmt> #2924 sns message id doesn't match in the response and the notification </cmt>,fix sns message id doesn't match with notification sent
1952,"<desc> adjust colors used in cupertinoalertdialog and cupertinoactionsheet change the modalbarrier color that used for cupertino popup routes cupertinoalertdialog dark mode. related issues part of #35541 fixes #39941 fixes #20469 screenshots (iphone xr device, ios 13.1 17a5831c) the native alert view has some additional visual effects that we have yet to add to cupertinoalertdialog, so it looks more opaque than cupertinoalertdialog in the screenshots below. native cupertino i added the following tests: dialog dark mode route dark mode before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> alertview update </cmt> <cmt> add tests </cmt> <cmt> add tests </cmt> <cmt> use const </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> update barrier color </cmt> <cmt> get rid of background decoration </cmt> <cmt> update color </cmt> <cmt> get rid of dialog blur overlay </cmt> <cmt> update tests </cmt> <iss> correct cupertinoalertdialog divider colors </iss> <iss> cupertinoactionsheet (and potentially cupertinoalertdialog) fidelity issue </iss>",cupertinoalertdialog dark mode & cupertinoactionsheet fidelity
1953,"<desc> fix #244 no path2d handles visible update hotkey to be consistent with collisionpolygon editor add view-base point snap support (independent from node transform) original curve use normal snapping, point is snapped to next step position activate view-base snapping, point is snapped to next grid point on view </desc> <cmt> fix #244 no path2d handles visible </cmt> <cmt> fixed delete path2d node will crash editor </cmt> <cmt> use shift for control point in paht2d editor (to be consistent with path editor) </cmt> <cmt> move point in path2d edtitor now respect snap configure; press alt when </cmt> <cmt> moving point to activate view base snapping; path2d editor inherits from </cmt> <cmt> hboxcontainer now"" </cmt> <iss> no path2d handles visible </iss>",path2d editor bug fix and improvement
1954,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> update ink-select-input to support latest version and ink2 </cmt> <cmt> major version up </cmt>",ink select input update for latest version and ink2 support
1955,<desc> begins the process of adding graphql to the unified-desktop-gui branch: adds: yarn dev:watch from the root for a server that restarts when graphql code is updated graphql code generator yarn codegen --watch from the launchpad app ipc link for executing graphql todo: add testing integration / tooling codegen vue prop types for fragments hook graphql codegen so it runs alongside vite with yarn watch has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> refactor: use getpathtodesktopindex for launchpad path </cmt> <cmt> chore: add dependencies for graphql </cmt> <cmt> get graphql & vue working together </cmt> <cmt> update vue and remove need for patch-package </cmt> <cmt> add apollo example </cmt> <cmt> update wizard.vue </cmt>,add graphql to unified-desktop branch
1956,"<desc> this change cuts ingest plugins over the new pull based plugins model. </desc> <cmt> added ingestplugin api, cutover common and geoip, changed ingest factory </cmt> <cmt> api to take processorsregistry </cmt> <cmt> tests pass, started removing generics from processor factory </cmt> <cmt> remove unnecessary optional injection of scriptservice into nodeservice </cmt> <cmt> fix line lengths for ingest config utils </cmt> <cmt> fix test oops </cmt> <cmt> remove unused clusterservice member of nodeservice </cmt> <cmt> update ingest useragent plugin to use new ingest plugin </cmt> <cmt> simplify ingest useragent construction </cmt>",add ingestplugin api for plugins to add ingest processors
1957,"<desc> this pr renames the parameters previously introduce to the following: url parameters put twitter/_doc/1?if_seq_no=501&if_primary_term=1 { ""user"" : ""kimchy"", ""post_date"" : ""2009-11-15t14:12:12"", ""message"" : ""trying out elasticsearch"" } delete twitter/_doc/1?if_seq_no=501&if_primary_term=1 bulk api post _bulk { ""index"" : { ""_index"" : ""test"", ""_type"" : ""_doc"", ""_id"" : ""1"", ""if_seq_no"": 501, ""if_primary_term"": 1 } } { ""field1"" : ""value1"" } { ""delete"" : { ""_index"" : ""test"", ""_type"" : ""_doc"", ""_id"" : ""2"", ""if_seq_no"": 501, ""if_primary_term"": 1 } } java api indexrequest.ifseqno(long seqno) indexrequest.ifprimaryterm(long primaryterm) deleterequest.ifseqno(long seqno) deleterequest.ifprimaryterm(long primaryterm) relates #36148 relates #10708 </desc> <cmt> rest layers </cmt> <cmt> /have/has </cmt> <cmt> use current requests values </cmt> <cmt> linting </cmt> <cmt> renames </cmt> <cmt> merge from master </cmt>",rename seq# powered optimistic concurrency control parameters to ifseqno/ifprimaryterm
1958,"<desc> i think discussions of tokenizing unicode have often got caught up in trying to design nicer apis for it. i am taking the much lazier approach of promoting the existing but undocumented generate_tokens api to a public api. why should we do this? generate_tokens() has been there for several releases already (at least since 3.3.0), so we can start using it without having to wait until a new python version is widespread. someone (ahem  ) might already be using it - ide tab completion doesn't know that it's not public, and there's no other publicly documented way to tokenize code that's already unicode. although the naming is not very clear, the interface is a close parallel to tokenize(), so it's easy to understand. we can do this without having to design, implement, review and debug any new interface! </desc> <cmt> document tokenize.generate_tokens() </cmt> <cmt> add news file </cmt> <cmt> add test for generate_tokens </cmt> <cmt> document behaviour around encoding token </cmt>",document tokenize.generate_tokens() as public api
1959,"<desc> this pr resolves an issue with the git for windows (msys) version of less. it doesn't use vt processing for emitting text tothe buffer, so when it hits writecharslegacy, wc_delay_eol_wrap is not set. when this happens, less is writing some text that's longer than the width of the buffer to the last line of the buffer. we're hitting the status = adjustcursorposition(screeninfo, cursorposition, wi_isflagset(dwflags, wc_keep_cursor_visible), psscrolly); call in _stream.cpp:560. the cursor is currently at {40, 29}, the start of the run of text that wrapped. we're trying to adjust it to {0, 30}, which would be the start of the next line of the buffer. however, the buffer is only 30 lines tall, so we've got to incrementcircularbuffer first, so we can move the cursor there. when that happens, we're going to paint frame. at the end of that frame, we're going to try and paint the cursor position. the cursor is still at {40, 29} here, so unfortunately, the cursorisindeferredwrap check in xtermengine::paintcursor is false. that means, conpty is going to try to move the cursor to where the console thinks the cursor actually is at the end of this frame, which is {40, 29}. if we're painting the frame because we circled the buffer, then the cursor might still be in the position it was before the text was written to the buffer to cause the buffer to circle. in that case, then we don't want to paint the cursor here either, because it'll cause us to manually break this line. that's okay though, the frame will be painted again, after the circling is complete. closes #5691 i work here i suppose that's the detailed description above ran tests checked that the bug was actually fixed in the terminal </desc> <cmt> this _should_ be a test for #5691 but they must implement scrolling weirdly </cmt> <cmt> huh, writecharslegacy doesn't seemt to repro it... </cmt> <cmt> these are useful test util helpers </cmt> <cmt> i tried to do a scrolling thing here, but i think that wasn't it </cmt> <cmt> i can't explain it, but only metadataset5 fails in this version of the test. that's all we need, but man that's just weird </cmt> <cmt> um what the heck </cmt> <cmt> clean this test up. this test does catch a real regression, but it's definitely not the one that is actually reported in the bug. i'm gonna start fresh. </cmt> <cmt> again, this should be a test for this case. why isn't it? </cmt> <cmt> could this finally be a test for #5691?? </cmt> <cmt> holy crap, this fixed it </cmt> <cmt> code cleanup for review </cmt> <iss> ""git log --pretty=oneline"" at the bottom of the buffer line-wraps wrong </iss>",fix wrapped lines in less in git for windows
1960,"<desc> with this pr we improve type inference for discriminated unions by only inferring between constituent object types with matching discriminants. for example: type item<t> = { kind: 'a', data: t } | { kind: 'b', data: t[] }; declare function foo<t>(item: item<t>): t; let x1 = foo({ kind: 'a', data: 42 });  // number let x2 = foo({ kind: 'b', data: [1, 2] });  // number previously this example would fail on x2 because we'd infer number[] for t. now we only infer to the variant with a matching kind property. fixes #28862. </desc> <cmt> only infer from constituents with matching discriminants in unions </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",improved type inference for discriminated unions
1961,"<desc> the last part of #53228. doesn't affect #53924, so i'm creating a pr for it. no changelog since it only affects a new feature for ansible 2.8. openssl_csr </desc> <cmt> fix ip address support for openssl_csr. </cmt> <cmt> remove dirname support, which doesn't work as this and seems harder to fix. also, i don't know of an example of how it actually works. </cmt>",fix san handling for cryptography backend
1962,<desc> pull request consists of migration of cor example from core-java module to patterns module </desc> <cmt> bael-1422: measure performance of random and threadlocalrandom using jmh </cmt> <cmt> bael-1422: updated benchmarking examples of random and threadlocalrandom to use newworkstealingpool that leverages forkjoinpool </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> bael-1422: refactored benchmarking examples for comparing performance of threadlocalrandom and random </cmt> <cmt> - initialised the collection of callable before running benchmarking </cmt> <cmt> - removed for loop for submitting task and instead used executor.invokeall(collection_of_callable) </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> bael-1282: added tdd type junit tests for geospatial queries elasticsearch </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> # conflicts: </cmt> <cmt> #	spring-data-elasticsearch/src/test/java/com/baeldung/elasticsearch/geoqueriestest.java </cmt> <cmt> bael-1524: added example for chain of responsibility design pattern </cmt> <cmt> bael-1524: added bdd style junit test to test unknown handler in chainofresponsibility design pattern </cmt> <cmt> bael-1524: refactored chainofresponsibility design pattern example </cmt> <cmt> bael-1524: refactored chainofresponsibility design pattern example </cmt> <cmt> bael-1524: updated chainofresponsibility design pattern example </cmt> <cmt> bael-1524: updated chainofresponsibility design pattern example </cmt> <cmt> bael-1524: moved chain of responsibility example from core-java module to patterns module </cmt>,chain of responsibility design pattern in java
1963,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add missing ignorebounds for tooltip </cmt> <cmt> add missing semicolon, add author </cmt>",add missing ignorebounds property for tooltip
1964,"<desc> this finishes the mvp for multi instance, resource demand based autoscaling. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> . </cmt> <cmt> [autoscaler] expand key path for hashing with expanduser </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> test </cmt> <cmt> test </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt> <cmt> . </cmt>",resource demand vector (hearbeat -> autoscaler plumbing)
1965,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> typings for just-clone </cmt> <cmt> updated tests </cmt> <cmt> added more tests </cmt> <cmt> moved test </cmt>",adding new typings for just-clone module
1966,"<desc> this pr is a pivot from #134570 adding an ondidchangemodel event to the editorgroupmodel. i felt a bit strange exposing the model as we only want people listening to this event but feel free to let me know if this should change. we're missing a few model events which i added comments to and wanted to get your thoughts on before adding. </desc> <cmt> add aggregate model event </cmt> <cmt> switch to aggregate model events </cmt> <cmt> use groupchangekind instead </cmt> <cmt> switch to using groupchange event </cmt> <cmt> introduce an ondidmodelchange </cmt> <iss> api access to ""open editors"": events fired multiple times on open and close </iss>",introduce ondidmodelchange to the group
1967,<desc> rpc metrics were parsed incorrectly affecting the nfsd.rpc chart. we fix that. file handler metrics were never used and are always zero. corresponding dimensions are removed from the nfsd.filehandles chart. thread histogram has been disabled since 2009 (kernel 2.6.30). we remove two charts - threads_fullcnt and nfsd.threads_histogram. readahead cache has been disabled since 2019 (kernel 5.4). we add a comment about that. component name proc plugin </desc> <cmt> fix rpc dimensions </cmt> <cmt> remove unused file handler statistics </cmt> <cmt> remove thred histogram </cmt> <cmt> add comment about removal of readahead cache </cmt> <cmt> fix typos </cmt>,fix nfsd rpc metrics and remove unused nfsd charts and metrics
1968,"<desc> when managing kerberos tickets ourselves, run kinit with the -f flag to retrieve a forwardable ticket if ansible_winrm_kerberos_delegation is set to yes. backport of #37815 winrm ansible version 2.5 </desc> <cmt> winrm: added flag handler for kinit to request forwardable ticket when delegation is set (#37815) </cmt> <cmt> (cherry picked from commit 22f2388ef163e401833b666c65049aee019ce0da) </cmt> <cmt> added changelog fragment </cmt>",backport 2.5 added flag handler for kinit to request forwardable ticket when delegation is set
1969,<desc> things fixed in this pr presign authentication failing when key contains special char in the name presign authentication failing while multipart uploading added test cases for multipart upload and special char as a key name fix for issues #3713 #3759 </desc> <cmt> fix: special char as a key in presign url </cmt> <cmt> fix: multipart upload signature </cmt> <cmt> added: test-case for presign multipart upload </cmt>,key name with special char and multipart upload in presign url auth
1970,"<desc> description: after some back and forth this should be final implementation of the knx climate component. it now uses the setpoint-shift group address to set a target temperature. the new setpoint shift is calculated out of current setpoint shift, current target temperature and desired target temperature. related issue (if applicable): xknx/xknx#48 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3903 example entry for configuration.yaml (if applicable): climate: - platform: knx name: hass-kitchen.temperature temperature_address: '5/1/1' setpoint_shift_address: '5/1/2' setpoint_shift_state_address: '5/1/3' target_temperature_address: '5/1/4' operation_mode_address: '5/1/5' </desc> <cmt> added myself to codeowners </cmt> <cmt> improved climate support with setpoint shift for knx. ( </cmt> <cmt> requirements_all.txt </cmt> <cmt> typo </cmt> <cmt> flake </cmt>",improvement of knx climate component
1971,"<desc> added type hints to methods per issue #9708 make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> improve type hinting for microsoft provider </cmt> <cmt> changes the order of imports following pylint instruction </cmt>",improve type hinting to provider microsoft
1972,"<desc> this pr addresses issue #1257, which aims to add non-coupled scaling factors for bilinear 2d upsampling. i've added two new tests, and currently everything passes. this is a relatively simple change which only touches python code. furthermore, this is is a re-do of pr #1279, wherein i messed up a rebase.  there are some in-line comments there that might be worth skimming through, as well, but i tried to address most of the concerns raised there.  in particular, i maintained the base class of all the upsampling methods. tests pass, on gpu and cpu. tagging @apaszke @fmassa @soumith.  thanks in advance everyone. ps:  i'll probably need a pointer on how to best rebase to master, eventually ;) </desc> <cmt> bilinear upsampling module </cmt> <cmt> bilinear upsampling functions </cmt> <cmt> bilinear upsampling tests </cmt>",add flexible bilinear upsampling aspect ratio redux
1973,"<desc> these prs were merged into the master branch, but should have been merged into the release branch instead: #5736 #5720 #5893 #5749 #5722 </desc> <cmt> test robustness of writeablesinglehandler against non-single writers </cmt> <cmt> make writeable with single handler robust against stream writers </cmt> <cmt> use a named constant for error domain and code </cmt> <cmt> make copyright not expire one year too soon. </cmt> <cmt> add monitoring of connectivity </cmt> <cmt> move c-layer call creation into grpcchannel, so that it always acts on a </cmt> <cmt> non-destroyed channel. </cmt> <cmt> listen for connectivity in the grpccall, and destroy the channel. </cmt> <cmt> not call external methods from within a critical section </cmt> <cmt> clean up ownership of the connection loss handler </cmt> <cmt> kscnetworkreachabilityflagsiswwan is only available on ios, not all mac targets. </cmt> <cmt> use a singleton completion queue </cmt> <cmt> for grpcoperation's, ensure finish _handler can only be called once, and release it when called, so weak ptrs needn't be used with it, and the call won't be released until the finish handler is called. </cmt> <cmt> when the connectivitymonitor determines the connection has been lost, pull the host disconnect call. creates an unreliable connection when connectivity is restored. calling finishwitherror: is sufficient. </cmt> <cmt> fixing copyrights. </cmt>",cherrypick connectivity fixes into release branch
1974,"<desc> this adds the ability to index term prefixes into a hidden subfield, enabling prefix queries to be run without multitermquery rewrites. the subfield reuses the analysis chain of its parent text field, appending an edgengramtokenfilter. it can be configured with minimum and maximum ngram lengths. query terms with lengths outside this min-max range fall back to using prefix queries against the parent text field. the mapping looks like this: ""my_text_field"" : { ""type"" : ""text"", ""analyzer"" : ""english"", ""index_prefix"" : { ""min_chars"" : 1, ""max_chars"" : 10 } } this implementation uses a dedicated fieldtype and fieldmapper within textfieldmapper supersedes #28222 </desc> <cmt> add index_prefix option to text fields </cmt> <cmt> move prefixwrappedanalyzer into private class </cmt> <cmt> checkstyle </cmt> <cmt> use double-dot fieldname to prevent mapping clashes </cmt> <cmt> wip </cmt> <cmt> use prefix fieldtype and mapper </cmt>",add ability to index prefixes on text fields
1975,"<desc> this pr changes the template digest code to build a dependency tree data structure before calculating the fingerprint and child finger prints.  i carefully made the tree produce exactly the same digests that the previous code produced (if you read the commits you'll see that i tested them side by side). pros slightly shorter implementation easier to extend (we can just add new tree node types) less memory consumption (i'll talk about this later) easier to debug (i'll talk about that later too) cons possibly slower key calculation (i'll also talk about this later) memory consumption / key calculation speed the previous implementation would cache a digest for all nodes in any particular tree.  this would speed up digest calculation for templates that have common subtrees.  the downside is that any nodes that are not in common waste memory and once the app is warmed up, those keys are also wasting memory (since we only ever look up a digest by it's root node).  iow, our in-memory cache is always wasting memory. the implementation i'm proposing here only caches the digest for the top most node (which is the node callers of digest were asking about). key calculation time should be amortized over the life of the app, so i don't think slowing down some calculations should be a big deal, but i'm happy to change if this turns out to be an issue.  fortunately all we have to do to support that is pass the cache object down as we walk the tree. strange things i found if you have a wildcard dependency, like this: <% # template dependency: users/* %> everything in users/ will be considered a ""dependency"", even files that are not templates.  here is a visualization of the dependency tree for a test app: these files that are not templates will be considered as ""missing"" and the parent template will end up getting an empty string returned for that template and will digest a string like ""--"".  the point being that these so-called ""missing dependencies"" can impact the digest of the parent template even though we don't care about them.  if i delete the file ""users/show"" from the tree in the picture, it would impact the digest for ""users/new"" even though ""users/new"" doesn't care whats inside ""users/show"" at all!  this test demonstrates the issue: +  def test_non_partials_do_not_impact_wildcard_dependencies +    old_caching, actionview::resolver.caching = actionview::resolver.caching, false +    before = digest ""events/index"" +    add_template 'events/show' + +    actionview::digestor.cache.clear +    assert_equal before, digest(""events/index"") +  ensure +    actionview::resolver.caching = old_caching +  end this test fails with the current implementation.  i would like to remove this ""feature"" and fix the above test. if we're ok with this pr i'd also like to add a rake task that outputs the dependency tree as a dot file so we can get a visual representation of the deps. </desc> <cmt> introduce a tree factory method for creating the dep tree </cmt> <cmt> also add an empty sentinel node </cmt> <cmt> pull template check up to match existing behavior </cmt> <cmt> also remove the empty node since we won't need it </cmt> <cmt> fix recursive templates </cmt> <cmt> clean up classes a little </cmt> <cmt> convert structs to a regular class </cmt> <cmt> change internal implementation to use a tree </cmt> <cmt> remove dead code </cmt> <cmt> this commit removes unused code and changes the monitor to a mutex. </cmt> <cmt> since the digest doesn't recurse on itself anymore, we can just use a </cmt> <cmt> mutex </cmt> <cmt> remove more dead code </cmt> <cmt> fix rake tasks </cmt>",use a tree data structure to build template digests
1976,"<desc> stop formatting and saving fixtures. let the users use their own favorite formatting tools. </desc> <cmt> do not reformat json / js fixtures, close #902 </cmt> <cmt> do not reformat coffee fixtures </cmt> <cmt> remove html rewriting </cmt> <cmt> update js rewriting tests </cmt> <cmt> remove .only </cmt>",do not format fixture on run
1977,<desc> closes #10449 files uploaded through the api were missing the userid of the uploader. this caused those files to not be included in some endpoints. </desc> <cmt> added missing userid </cmt> <cmt> fixed roomfiles method to return files without users too </cmt>,missing user data on files uploaded through the api
1978,"<desc> issue #3373 exposed a problem where the environment variable osquery_deps, meant to control where to place osquery's build dependencies, is not always respected. this makes using a non-default directory for the build dependencies (including a path which doesn't require root/sudo/admin access) unfeasible. this pull request replaces the hard-coded path /usr/local/osquery with an attempt at accessing the osquery_deps environment variable, defaulting to /usr/local/osquery. with these changes, it becomes possible to use osquery_deps to place build dependencies in a user controlled directory. the pr includes 6 commits (one per touched file) for easier review. note that this pr does not close #3373 completely since it doesn't fix: python needing to be recompiled when osquery_deps is set; libmagic formula needing a different mirror. see #3388 for that. </desc> <cmt> respect osquery_deps when creating osx packages </cmt> <cmt> this removes hard-coded paths to /user/local/osquery </cmt> <cmt> when attempting to create macos/osx packages. </cmt> <cmt> respect osquery_deps when creating linux packages </cmt> <cmt> this removes hard-coded paths to /user/local/osquery </cmt> <cmt> when attempting to create linux packages. </cmt> <cmt> do _not_ add /usr/local/bin to path when creating macos packages </cmt> <cmt> this directory should never have been touched by </cmt> <cmt> the build process, so we should not depend on this! </cmt> <cmt> the directory contains normally what homebrew installs, </cmt> <cmt> but osquery uses its own version of homebrew and </cmt> <cmt> should _not_ depend on an already installed version. </cmt> <cmt> do _not_ add /usr/local/bin to path when creating linux packages </cmt> <cmt> this directory should never have been touched by </cmt> <cmt> the build process, so we should not depend on this! </cmt> <cmt> the directory contains normally what homebrew installs, </cmt> <cmt> but osquery uses its own version of homebrew and </cmt> <cmt> should _not_ depend on an already installed version. </cmt> <cmt> don't use hard-coded path /usr/local/osquery in python base class </cmt> <cmt> attempt instead to get the osquery_deps environment </cmt> <cmt> variable and use a default value if not set. </cmt>",replace hardcoded paths throughout code base
1979,<desc> as per issue #1287 - fixed a typo that led to an incorrect message being displayed on user leaving a channel. also updated the leave message to bring it inline with the join message. </desc> <cmt> fixed user leave message </cmt> <cmt> changed user left message to bring it inline with the join message </cmt>,fixed message on user leaving channel
1980,"<desc> what i did listtype of player never seems to have existed, looking at how the tests were setup i think this was a typo and was meant to be playlist as the documentation states. so i have renamed it accordingly. listtype of search was deprecated last year, so i added the @deprecated jsdoc. cc_lang_pref was added in 2018, so i added it here as well. checklist add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> feat: add cc_lang_pref + playlist listtype </cmt> <cmt> docs(youtube): update playlist jsdoc </cmt>",add cc_lang_pref and update listtype
1981,"<desc> minor cleanups and fixes for mz binaries and 16-bit real-mode registers. </desc> <cmt> bin_mz: restructure check_bytes for clarity </cmt> <cmt> as checks have been added for file formats that include an mz header but </cmt> <cmt> are handled by a different plugin, bin_mz's check_bytes has gotten hard </cmt> <cmt> to understand.  restructure it as a default true with early exits to </cmt> <cmt> simplify the logic. </cmt> <cmt> bin_mz: implement header command (ih) </cmt> <cmt> dreg: fix printing of 16-bit x86 segment registers </cmt> <cmt> 'ar seg' ends up calling r_debug_reg_list() with size=0.  this should </cmt> <cmt> disable filtering of matches by size per the inner loop iterating over </cmt> <cmt> the registers.  an earlier check to ensure the requested size is valid </cmt> <cmt> for this register set fails to allow for size=0 and will force it to </cmt> <cmt> size=32 instead.  when in 16-bit mode, that will cause no registers to </cmt> <cmt> be printed. </cmt>",mz and 16-bit x86 real-mode cleanups
1982,<desc> this pr does two things: avoid breaking changes when people had a custom datacollator with a collate_batch method (there is still the breaking change with datacollator not being a class anymore) makes default_data_collator more flexible by handling dicts on top of inputexamples classes coming from our examples this fixes #5049 </desc> <cmt> make default_data_collator more flexible </cmt> <cmt> accept tensors for all features </cmt> <iss> datacollator problem </iss>,make default_data_collator more flexible and deprecate old behavior
1983,"<desc> this targets spike/evergreen-bem: #9524. i changed the component-testing example to use the cypress testing api instead of using vue test utils as per @jessicasachs's recommendation as a good way to get my hands dirty. also the type definitions for mount in @cypress/vue appear to be incomplete, this can probably be fixed either here or in vue test utils, but this doesn't seem like very important thing to do right now, so i left it as-is. </desc> <cmt> chore: use cypress/vue instead of test utils for example specs </cmt> <cmt> chore: add eslint file to server-ct project </cmt>",use cypress in vue tests
1984,"<desc> #13439 - examples cleanup @mrdoob these two can be combined (both in the same scene)   this pr combines the two scenes of webgl_lines_colors and webgl_lines_splines into a single example. lines colors had additional effects applied to the scene which were unnecessary so those were not merged. lines spinles used buffergeometry while lines colors used geometry, however i have include both in this example as i think it makes for a better example to show both methods of adding color to three.line. </desc> <cmt> create combination of webgl_lines_splines and webgl_lines_colors </cmt> <cmt> remove old examples </cmt>",combine webgl lines colors and splines
1985,"<desc> put some settings below the acrylic & background image settings. those groups have controls that will become visible when the user enables the setting. if there's other controls below them, then it's less likely that the user has exactly scrolled to the checkbox. that means it's more likely that the newly visible controls will be on-screen. closes one checkbox in #8764 i work here </desc> <cmt> 50 ways to _not do this correctly_ </cmt> <cmt> what if we just took bikini bottom, and _pushed it somewhere else_ </cmt>",move the window settings below the acrylic settings
1986,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. closes #43448 i found out that what was causing this problem is that react for some reason doesn't create a ref for the search bar on the first render(still digging on why it does so), so when the function handleclickoutside is triggered the menu bar doesn't close because it has a condition that says close it only if there is a seearchbarref.current. what i did here is that i removed the searchbarref from the logic, i understand this might not be the best solution, i am just opening a discussion here to find out the importance of the searchbarref in the codebase logic and then try to find a better solution. </desc> <cmt> removed serachbarref </cmt> <cmt> removed serachbarref </cmt> <iss> menu bar items don't disappear when pressing on certain item only in home page </iss>",fix(client):make menu bar disappear after user chooses item from it on landing page
1987,"<desc> this minor mod adds rocm support for the quantized and dequantize ops. background info these ops are fundamental to tensorflow, and this mod has been running for more than 1 year on our rocm port of tf. we have published docker images at:  and also pypi packages:  for a sample rocm test run you can refer to:  //tensorflow/python:quantized_ops_test                                   passed in 2.1s //tensorflow/python:dequantize_op_test                                   passed in 2.2s </desc> <cmt> added rocm support for the quantize and dequantize ops </cmt> <cmt> added comment to endif </cmt>",added rocm support for the quantized and dequantize ops
1988,"<desc> i hereby agree to the terms of the cla available at:  ubuntu 20.04 is now used to run integration tests, docker-compose version used to run integration tests is updated to 1.28.2. environment variables now take effect on docker-compose. rework test_dictionaries_all_layouts_separate_sources to allow parallel run. detailed description / documentation draft: ubuntu 20.04 is now used to run integration tests docker-compose version used to run integration tests is updated to 1.28.2. environment variables now take effect on docker-compose added pytest-xdist to allow parallel runs in pytest rework test_dictionaries_all_layouts_separate_sources to allow parallel run compose: cassandra - do not map port to localhost compose: cassandra - pass ports with env compose: hdfs logs are placed in bound folder compose: kerberized hdfs logs are placed in bound folder compose: kafka - pass ports with env compose: kerberized kafka - pass ports with env compose: minio - pass ports with env compose: mongo - pass ports with env compose: mysql - logs are placed in bound folder compose: mysql - hostnames for 5.7 and 8.0 are changed to mysql57 and mysql80 respectively compose: mysql - expose port instead of mapping ports to localhost compose: mysql cluster - logs are placed in bound folder compose: mysql cluster - expose port instead of mapping ports to localhost compose: postgres - expose port instead of mapping ports to localhost compose: postgres - logs are placed in bound folder compose: postgres cluster - expose port instead of mapping ports to localhost compose: postgres cluster - logs are placed in bound folder compose: rabbitmq - pass ports with env compose: redis - pass ports with env dockerd - use address pool 172.17.0.0/12 as it has more ip subnets than default. dockerd - place dockerd logs to directory with integration tests. ci runner - enable use of tmpfs for dockerd inside runner. ci runner - enable parallel run with 10 parallel workers ci runner - add passing list of parallel tests to run from parallel.json ci runner - pass dockerd.log to ci results helpers client - ignore errors with binary symbols. helpers cluster - cassandra - add roundrobinpolicy to connect to cluster as it it necessary in new versions. helpers cluster - fix minio bucket cleanup as it can't delete nonempty bucket. helpers cluster - fix environment passing to docker-compose. helpers cluster - switch logging from prints to logging. helpers cluster - move rabbitmq cluster wait to helpers code from test. helpers cluster - rework cleanup for docker objects. stop containers for the same project name, remove unused images and volumes. helpers cluster - pass all variables to compose via env. helpers cluster - wait * to start now work via ip resolving to use exposed ports. helpers cluster - use random ports for ports that should be mapped to localhost. helpers cluster - increase timeouts as parallel run can result in longer container start in separate containers. helpers cluster - split directories for configs, logs etc. when there are several test files in one dir. helpers cluster - improve errors logs grep in shutdown procedure helpers cluster - improve clickhouse_stop procedure to check it is successfully killed etc. helpers cluster - fix lost dependencies for docker-compose services ssd cache dict - fix path to store dictionary /etc/clickhouse -> /etc/clickhouse-server hdfs api - simplify code. don't use dns to make queries. hdfs api - disable ssl check for python code, clickhouse code should work with ssl certs verification helpers network - retry iptables calls on fails. pytest - setup logging to file and logging format. parallel runs: add first 315 tests to run in parallel. parallelism is by test files. runner - add argument to run tests in parallel runner - add args to use tmpfs for dockerd inside runner container runner - add args to bind directory for dockerd files remove logging configuration in modules add if not exists/if exists if necessary to allow unclean run test_adaptive_granularity - fix xml configuration to remove config and not merge them. add retries to calls that use zookeeper as we can get connect error. test_allowed_url_from_config - use hdfs api from cluster test_backward_compatibility, test_dictionary_allow_read_expired_keys - add project name prefix for test files that are not tests.py. test_cluster_copier - use started_cluster explicitly and not cluster object. test_cluster_copier, test_match_process_uid_against_data_owner - use docker_client from started_cluster test_dictionaries_all_layouts_separate_sources - pass test_name to have separate directories for different tests in parallel run fix test names that use hyphens, spaces and other strange symbols. test_dictionaries_mysql - add retries for mysql client initial creation test_dictionaries_postgresql, test_postgresql_database_engine, test_storage_postgresql - use ip:port and not localhost test_disabled_mysql_server, test_mysql_database_engine, test_storage_mysql - use ip:port and not localhost test_match_process_uid_against_data_owner - fix issue with sanitizers where last error not expected but about slow work. fix mysql_killed_while_insert test with default retry policy enabled max_wait_time_when_mysql_unavailable test_materialize_mysql_database, test_mysql_database_engine - remove docker-compose code from test and use common cluster helpers test_profile_events_s3, test_storage_s3 - use ip:port and not localhost for minio test_storage_kafka, test_storage_kerberized_kafka - kafka and schemaregistry is already started in helper code and checked there. test_storage_kafka - use kafka port from cluster configuration test_storage_rabbitmq - remove docker-compose code from test and use common cluster helpers test_storage_rabbitmq - use ip:port and not localhost by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> update runner </cmt> <cmt> wip </cmt>",grand integration tests refactoring: allow parallel run
1989,"<desc> resolves #14002 resolves #14005 with pandas >= 0.24, we can support pandas sparse arrays. #14005 (comment) but given the nature of how pandas uses np.nan as the zero value, this pr will continue to raise an error for pandas sparse arrays a = pd.sparsearray([1, np.nan, 2, 1, np.nan]) np.array(a) # array([ 1., nan,  2.,  1., nan]) np.array(pd.sparseseries(a)) # array([ 1., nan,  2.,  1., nan]) np.array(pd.series(a)) # array([ 1., nan,  2.,  1., nan]) </desc> <cmt> bug updates support for pandas sparse arrays </cmt> <cmt> cln uses nans </cmt> <iss> sparseseries deprecated: scipy-dev failing on travis </iss>",errors for pandas sparse arrays as target
1990,"<desc> this is a developer experience contribution for storybook contributors. it's an easy way to build packages within the monorepo. it presents all lerna packages that use the @storybook/name pattern and you can select multiple or single to build, also being able to toggle watch mode. this is how it looks like: in the order of the video above present a prompt for options: yarn build build all @ storybook packages: yarn build --all build a specific @ storybook package: yarn build --@storybook/package-name build on watch mode (works for specific package or all): add --watch to the command, like yarn build --all --watch or yarn build --@storybook/package-name --watch p.s. if you select more than 5 packages to build on watch mode, it asks if you really want to do that, given that it's an expensive process that might eat up ram really quick. it's also there for people who might mistakenly select all or more packages than they wanted. please hit me up with whatever requests and i'll be happy to do them to improve this contribution! </desc> <cmt> chore: add build packages script </cmt> <cmt> refactor(bootstrap): use common code from cli-utils </cmt>",build script for package development
1991,"<desc> now that mappedfieldtype no longer extends lucene's fieldtype, we need to have a way of getting the index information about a field necessary for building text queries, building term vectors, highlighting, etc.  this commit introduces a new textsearchinfo abstraction that holds this information, and a gettextsearchinfo() method to mappedfieldtype to make it available.  field types that do not support text search can just return null here. this allows us to remove the mapperservice.getlucenefieldtype() shim method. </desc> <cmt> add textsearchinfo class to wrap up text search details </cmt> <cmt> javadocs </cmt>",add text search information to mappedfieldtype
1992,"<desc> the @color parameter for the #gradient > .striped() mixin is not being used. currently, the striped color is hard coded  to be a transparent white and not the #555 color value set as the default @color parameter. </desc> <cmt> apply @color argument to striped gradient </cmt> <cmt> the @color argument is currently not being used for the striped gradient. </cmt> <cmt> remove progress bar striped @color parameters; use default transparent white. </cmt> <cmt> * if the @color parameter is not removed, the stripes are the same color as the element background color. in this case, the stripes do not appear. </cmt>",apply gradient stripe @color parameter
1993,<desc> wrote documentation for all undocumented methods on the color.html and vector2.html </desc> <cmt> added color.set documentation </cmt> <cmt> added documentation for the color.lerp method </cmt> <cmt> add return for color.set documentation </cmt> <cmt> wrote documentation for all todos in vector2d </cmt>,completed todo list for color.html and vector2.html
1994,"<desc> send alt/f10 through the control we were not listening for wm_syskey{up,down} extract the actual scancode during wm_char, not the bitfield we were accidentally sending some of the additional keypress data in with the character event in win32 input mode set default fg/bg to campbell the wpf control starts up in powershell blue even though it's not typically used in powershell blue. don't rely on the font to determine wideness this is a cross-port of #2928 to the wpf control deterministic shutdown in testing, i saw a handful of crashes on teardown because we were not shutting down the render thread properly. don't pass 10 for the font weight ... when cascadia code is set, it just looks silly. trigger render when selection is cleared, do it under lock fixes #6966. </desc> <cmt> wpf: trigger render when selection is cleared, do it under lock </cmt> <cmt> fixes #6966. </cmt> <cmt> wpf: don't pass 10 for the font weight ... </cmt> <cmt> wpf: deterministic shutdown </cmt> <cmt> wpf: don't rely on the font to determine wideness </cmt> <cmt> wpf: set default fg/bg to campbell </cmt> <iss> wpf: selection invalidation on keypress doesn't properly invalidate selection w/ renderer </iss>",fix a handful of issues with the wpf control
1995,"<desc> fixes #16646 this pr is an improvement to the docstrings of some transformer classes in sklearn.preprocessing._data. as described in issue #16646, polynomialfeatures does not mention the possibility to pass sparse matrices. the same holds for other classes in the same module, such as standardscaler, maxabsscaler, robustscaler, binarizer. with this pr all the descriptions of x are changed to array-like, shape (n_samples, n_features) {array-like, sparse matrix, dataframe} of shape (n_samples, n_features) depending on whether the corresponding methods accept sparse matrices and dataframes respectively. i took the liberty of formatting other occurrences of [n_samples, n_features] to (n_samples, n_features), for consistency within the module. further fixes: docstrings with no returns are completed; every .fit method documents the ignored argument y, and the default values are described in a consistent format throughout the module. </desc> <cmt> doc make consistent description of x in preprocessing._data, take into account sparse matrices (#16646) </cmt> <cmt> doc last fixes to x docs for quantiletransformer (#16646) </cmt> <cmt> doc further fixes to restore ndarray instead of array-like (#16646) </cmt> <iss> polynomialfeatures' docstring does not mention that sparse data is allowed for fit </iss>",fix missing 'sparse matrix' in docstrings when allowed #16646
1996,"<desc> fixes #42741 first contribution. update param name and docstring for parseint to be more readable/consistent. </desc> <cmt> feat(lib): improve parseint type definition and docstring </cmt> <iss> description of radix argument in parseint calls string ""numstring"", but parseint header calls it ""s"" </iss>",update parseint parameter name and jsdoc
1997,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  increase the version number in the header if appropriate. </desc> <cmt> missing comment </cmt> <cmt> merged upstream </cmt> <cmt> missing comment </cmt> <cmt> merge master </cmt> <cmt> merged </cmt> <cmt> add missing scale & gridbackground </cmt> <cmt> remove scale which is from a plugin </cmt>,add missing chartist element in classnames object
1998,"<desc> fixes accidentally incorrect condition in hostvmservice early return, which for some reason didn't run on ci </desc> <cmt> allow specifying device-vmservice port </cmt> <cmt> handle null values </cmt> <cmt> add observatory discovery test </cmt> <cmt> more updates </cmt> <cmt> fix test cases </cmt> <cmt> update attach_test.dart </cmt> <cmt> rename vmservice to correct casing, format, rename local </cmt> <cmt> fix failing tests </cmt>",allow specifying device-vmservice-port and host-vmservice-port
1999,<desc> added 2 generic methods and changed some parts to make use them. but also added backward compatibility for the existing modules for now. </desc> <cmt> cloudstack: fix other projects not found </cmt> <cmt> cloudstack: add _get_by_key() to utils </cmt> <cmt> generic method to get the whole dict or just a singe value by key if found. </cmt> <cmt> cloudstack: use _get_by_key in get_...() methods in utils </cmt> <cmt> but also add backward compatibility for existing modules in extras. </cmt> <cmt> cloudstack: add _has_changed() to utils </cmt> <cmt> generic method to compare values in dict. </cmt>,extend and fix cloudstack utils
2000,"<desc> the next major piece of work here, as described in #15511, is to improve the resilient access pattern to support two-phase metadata initialization.  i don't expect to pick that up right away, though. </desc> <cmt> optimize the layout of metadatacacheentrybase to pack fields more effectively. </cmt> <cmt> minor changes to how we track and lock around metadata dependencies </cmt> <cmt> to enable the general cycle-dependency runtime error. </cmt> <cmt> detect unbreakable metadata dependency cycles and abort with a diagnostic. </cmt> <cmt> add cyclic-metadata support to tuples. </cmt> <cmt> i was going to put this off for awhile, but it turns out that a lot of </cmt> <cmt> my testcases are enums with multi-payload cases, which we currently </cmt> <cmt> compile as tuples, so they were all still hanging until this patch. </cmt> <cmt> test that we handle metadata cycles in a bunch of different situations. </cmt> <cmt> rdar://18157434 </cmt>",finish the first stage of incomplete type metadata support
2001,"<desc> remove useless async package from hackathon-starter and replace it by built-in es6 promises, then() and all(), which are equivalent to async::waterfall() and async::parallel() use. side improvements: createrandomtoken() and user.findone(...) are dispatched in parallel instead of sequentially (as happened before with waterfall()) because there is no dependency between each other; suppresses the async idiomatic if (err) { return done(err); }, because ""if an error is thrown in the executor function, the promise is rejected."" (from developer.mozilla.org promise) replaces the idiomatic (err, results) => { if (err) { return next(err); } ... /* else block */ with .catch(next); </desc> <cmt> replace async::waterfall() by promise::then() </cmt> <cmt> replace async::parallel() by promise::all() </cmt> <cmt> remove async module from package.json </cmt>",remove async package and use built-in es6 promises
2002,"<desc> making merge pr for dhe release, testing </desc> <cmt> make space for dhe menu item again </cmt> <cmt> (cherry picked from commit 493437616d1aabef50768d71ce786595f7295554) </cmt> <cmt> copy over the dhe documentation for release to docs.docker.com </cmt> <cmt> (cherry picked from commit b0ad95daa84354c4b41679d0182fafbd259e5a69) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/docker-hub-enterprise/install-config.md </cmt>",dhe merge to docs branch
2003,"<desc> this pr adds support for error count cumulation during serialisation check in ocserializelib, which closes acidanthera/bugtracker#1467 as well. </desc> <cmt> ocserializelib: support for error count cumulation during parsing </cmt> <cmt> in the wake of this commit, ocvalidate can count errors received from occonfigurationinit in occonfigurationlib. </cmt> <cmt> occonfigurationlib: cleanup </cmt> <cmt> ocvalidate: cleanup </cmt> <cmt> ocserializelib: fix indentation </cmt> <cmt> ocmainlib: fix compilation </cmt> <iss> change ocvalidate to return exit code other than 0 when any of the checks fail </iss>",support for error count cumulation during occonfigurationinit call
2004,"<desc> implement two tweaks for the import of async functions: don't import as async old apis that were already deprecated by ~2018. we don't need to improve them.  (rdar://73620586) make sure we drop ""withblock"" as a completion-handler suffix.  (rdar://73641827) </desc> <cmt> [concurrency] disable async imports for apple apis deprecated by ~2018. </cmt> <cmt> implements rdar://73620586. </cmt> <cmt> [importer] make sure we drop ""withblock"" as a completion-handler suffix. </cmt> <cmt> fixes rdar://73641827. </cmt>",minor tweaks for async imports
2005,"<desc> this pr improves compatibility with libt 2.0 but does not aim to fix all compile errors (there are many and non-trivial). imo it would be better to slice the ""supporting libt 2.0"" work into smaller steps and this pr is one of them. add helper function to convert to string from lt::socket_type_t type migrate away from deprecated address::from_string() migrate away from deprecated address::to_string(error_code) the other overload require users to handle exceptions themselves. </desc> <cmt> add helper function to convert to string from lt::socket_type_t type </cmt> <cmt> migrate away from deprecated address::from_string() </cmt>",improve compatibility with libt 2.0
2006,"<desc> custom inline styles would not work for certain elements that were contained inside a toolbar, this is fixed. also, i've added custom color overrides for the raisedbutton, for both the label and background and seperate options for when the button is disabled. </desc> <cmt> [raisedbutton] allow custom labelcolor & backgroundcolor </cmt> <cmt> [toolbargroup] correctly transfer inline styles of direct children </cmt> <cmt> [raisedbutton] custom colors always take precedence unless disabled </cmt> <cmt> [raisedbutton] custom disabled colors </cmt> <cmt> [raisedbutton] document changes </cmt>",inline style fix & custom colors enhancement for raisedbutton
2007,<desc> resolves #34826 i changed the wording in servral sentences and paragraphs. fixing those small errors should make the readme.he.md file be easier to understand for hebrew speakers. </desc> <cmt> updated first paragraph </cmt> <cmt> update readme.hb.md </cmt> <cmt> update readme.hb.md </cmt> <cmt> update readme.hb.md </cmt> <iss> refine readme.hb (hebrew) </iss>,translationg and wording changes to readme.he.md file
2008,"<desc> currently, react treats all aria-* props as custom props. there are 46 aria attributes; we can easily enumerate all of them and verify that an aria-* prop on an element exists in the spec.  i've included the list of props from the upcoming aria 1.1 working draft. i work with one of the editors of this specification. it's currently taken about 3 years to update from 1.0 to 1.1. we should not expect any churn in this list of props in the short- or mid-term future. </desc> <cmt> add a hook that throws a runtime warning for invalid wai aria attributes and values. </cmt> <cmt> resolved linting errors. </cmt> <cmt> added a test case for many props. </cmt>",react dom invalid aria hook
2009,"<desc> some permissions corrections here. also needs re-vendor of go-winio. create the layer folder directory as standard, not with sddl. it will inherit permissions from the data-root correctly. apply the vm group sid access to layer.vhd permissions after this changes data root: ps c:\> icacls test test builtin\administrators:(oi)(ci)(f) nt authority\system:(oi)(ci)(f) lcow subdirectory under dataroot ps c:\> icacls test\lcow test\lcow builtin\administrators:(i)(oi)(ci)(f) nt authority\system:(i)(oi)(ci)(f) layer.vhd in a layer folder for lcow .\test\lcow\c33923d21c9621fea2f990a8778f469ecdbdc57fd9ca682565d1fa86fadd5d95\layer.vhd nt virtual machine\virtual machines:(r) builtin\administrators:(i)(f) nt authority\system:(i)(f) and showing working ps c:\> docker-ci-zap -folder=c:\test info: zapped successfully ps c:\> docker run --rm alpine echo hello unable to find image 'alpine:latest' locally latest: pulling from library/alpine 8e402f1a9c57: pull complete digest: sha256:644fcb1a676b5165371437feaa922943aaf7afcfa8bfee4472f6860aad1ef2a0 status: downloaded newer image for alpine:latest hello @jterry75 ptal </desc> <cmt> vendor microsoft/go-winio@c599b533 </cmt> <cmt> lcow: add sids to layer.vhd at creation </cmt> <cmt> some permissions corrections here. also needs re-vendor of go-winio. </cmt> <cmt> - create the layer folder directory as standard, not with sddl. it will inherit permissions from the data-root correctly. </cmt> <cmt> - apply the vm group sid access to layer.vhd </cmt> <cmt> permissions after this changes </cmt> <cmt> data root: </cmt> <cmt>  </cmt> <cmt> ps c:\> icacls test </cmt> <cmt> test builtin\administrators:(oi)(ci)(f) </cmt> <cmt> nt authority\system:(oi)(ci)(f) </cmt> <cmt>  </cmt> <cmt> lcow subdirectory under dataroot </cmt> <cmt>  </cmt> <cmt> ps c:\> icacls test\lcow </cmt> <cmt> test\lcow builtin\administrators:(i)(oi)(ci)(f) </cmt> <cmt> nt authority\system:(i)(oi)(ci)(f) </cmt> <cmt>  </cmt> <cmt> layer.vhd in a layer folder for lcow </cmt> <cmt>  </cmt> <cmt> .\test\lcow\c33923d21c9621fea2f990a8778f469ecdbdc57fd9ca682565d1fa86fadd5d95\layer.vhd nt virtual machine\virtual machines:(r) </cmt> <cmt> builtin\administrators:(i)(f) </cmt> <cmt> nt authority\system:(i)(f) </cmt> <cmt>  </cmt> <cmt> and showing working </cmt> <cmt>  </cmt> <cmt> ps c:\> docker-ci-zap -folder=c:\test </cmt> <cmt> info: zapped successfully </cmt> <cmt> ps c:\> docker run --rm alpine echo hello </cmt> <cmt> unable to find image 'alpine:latest' locally </cmt> <cmt> latest: pulling from library/alpine </cmt> <cmt> 8e402f1a9c57: pull complete </cmt> <cmt> digest: sha256:644fcb1a676b5165371437feaa922943aaf7afcfa8bfee4472f6860aad1ef2a0 </cmt> <cmt> status: downloaded newer image for alpine:latest </cmt> <cmt> hello </cmt> <cmt>  </cmt>",add vmgroup sid to layer.vhd; fix layer folder perm
2010,"<desc> adds tools/run_tests/run_tests_matrix.py script. the idea is to be able to run all tests for given platform in a single run. on linux, configurations are run in separate docker containers. on windows and mac, local repo is cloned in a ""workspace"" from where it is built. currently the scripts contains definitions for all configurations being run by grpc_master and grpc_portability_master. selection of configurations to run is done through ""filters"". examples # runs basictests for all langs tools/run_tests/run_tests_matrix.py -f linux basictests # runs sanitizers for c++ tools/run_tests/run_tests_matrix.py -f linux sanitizer c++ # run windows portability tests tools/run_tests/run_tests_matrix.py -f windows portability this is going to be useful for: -- being able to run tests on a dedicated worker with a single executor (and thus being able start rebooting workers after every build). -- easier management what configurations should/shouldn't be run. -- for integration with the internal k****o ci system (no matrix jobs supported). </desc> <cmt> add matrix run script </cmt> <cmt> improve report collection </cmt> <cmt> run matrix improvements </cmt>",script for running a matrix of run_tests.py instances at once.
2011,"<desc> this speeds up date_histogram aggregations without a parent or children. this is quite common - it's the aggregation that kibana's discover uses all over the place. also, we hope to be able to use the same mechanism to speed aggs with children one day, but that day isn't today. the kind of speedup we're seeing is fairly substantial in many cases: |                              |                                            |  before |   after |    | | 90th percentile service time |           date_histogram_calendar_interval | 9266.07 | 1376.13 | ms | | 90th percentile service time |   date_histogram_calendar_interval_with_tz | 9217.21 | 1372.67 | ms | | 90th percentile service time |              date_histogram_fixed_interval | 8817.36 | 1312.67 | ms | | 90th percentile service time |      date_histogram_fixed_interval_with_tz | 8801.71 | 1311.69 | ms | <-- discover's agg | 90th percentile service time | date_histogram_fixed_interval_with_metrics | 44660.2 | 43789.5 | ms | this uses the work we did in #61467 to precompute the rounding points for a date_histogram. now, when we know the rounding points we execute the date_histogram as a range aggregation. this is nice for two reasons: we can further rewrite the range aggregation (see below) we don't need to allocate a hash to convert rounding points to ordinals. we can send precise cardinality estimates to sub-aggs. points 2 and 3 above are nice, but most of the speed difference comes from point 1. specifically, we now look into executing range aggregations as a filters aggregation. normally the filters aggregation is quite slow but when it doesn't have a parent or any children then we can execute it ""filter by filter"" which is significantly faster. so fast, in fact, that it is faster than the original date_histogram. the range aggregation is fairly careful in how it rewrites, giving up on the filters aggregation if it won't collect ""filter by filter"" and falling back to its original execution mechanism. so an aggregation like this: post _search { ""size"": 0, ""query"": { ""range"": { ""dropoff_datetime"": { ""gte"": ""2015-01-01 00:00:00"", ""lt"": ""2016-01-01 00:00:00"" } } }, ""aggs"": { ""dropoffs_over_time"": { ""date_histogram"": { ""field"": ""dropoff_datetime"", ""fixed_interval"": ""60d"", ""time_zone"": ""america/new_york"" } } } } is executed like: post _search { ""size"": 0, ""query"": { ""range"": { ""dropoff_datetime"": { ""gte"": ""2015-01-01 00:00:00"", ""lt"": ""2016-01-01 00:00:00"" } } }, ""aggs"": { ""dropoffs_over_time"": { ""range"": { ""field"": ""dropoff_datetime"", ""ranges"": [ {""from"": 1415250000000, ""to"": 1420434000000}, {""from"": 1420434000000, ""to"": 1425618000000}, {""from"": 1425618000000, ""to"": 1430798400000}, {""from"": 1430798400000, ""to"": 1435982400000}, {""from"": 1435982400000, ""to"": 1441166400000}, {""from"": 1441166400000, ""to"": 1446350400000}, {""from"": 1446350400000, ""to"": 1451538000000}, {""from"": 1451538000000} } } } } which in turn is executed like this: post _search { ""size"": 0, ""query"": { ""range"": { ""dropoff_datetime"": { ""gte"": ""2015-01-01 00:00:00"", ""lt"": ""2016-01-01 00:00:00"" } } }, ""aggs"": { ""dropoffs_over_time"": { ""filters"": { ""filters"": { ""1"": {""range"": {""dropoff_datetime"": {""gte"": ""2014-12-30 00:00:00"", ""lt"": ""2015-01-05 05:00:00""}}}, ""2"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-01-05 05:00:00"", ""lt"": ""2015-03-06 05:00:00""}}}, ""3"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-03-06 00:00:00"", ""lt"": ""2015-05-05 00:00:00""}}}, ""4"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-05-05 00:00:00"", ""lt"": ""2015-07-04 00:00:00""}}}, ""5"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-07-04 00:00:00"", ""lt"": ""2015-09-02 00:00:00""}}}, ""6"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-09-02 00:00:00"", ""lt"": ""2015-11-01 00:00:00""}}}, ""7"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-11-01 00:00:00"", ""lt"": ""2015-12-31 00:00:00""}}}, ""8"": {""range"": {""dropoff_datetime"": {""gte"": ""2015-12-31 00:00:00""}}} } } } } } and that is faster because we can execute it ""filter by filter"". finally, notice the range query filtering the data. that is required for the data set that i'm using for testing. the ""filter by filter"" collection mechanism for the filters agg needs special case handling when the query is a range query and the filter is a range query and they are both on the same field. that special case handling ""merges"" the range query. without it ""filter by filter"" collection is substantially slower. its still quite a bit quicker than the standard filter collection, but not nearly as fast as it could be. </desc> <cmt> execute date_histo agg as date_range agg </cmt> <cmt> wip </cmt> <cmt> factor out collector </cmt> <cmt> ordered </cmt> <cmt> refactor </cmt> <cmt> fixup </cmt> <cmt> better name </cmt> <cmt> experiment </cmt> <cmt> rework </cmt> <cmt> use query </cmt> <cmt> super hack </cmt> <cmt> shuffle </cmt> <cmt> tests </cmt> <cmt> look </cmt> <cmt> no looking </cmt>",speed up date_histogram without children
2012,<desc> this superseded #311 and fully implements efficient varlen encoding for both signed and unsigned integers in bytecode. </desc> <cmt> bytecode uint varlen encoding: support arbitrary values. </cmt> <cmt> bytecode int varlen encoding: support arbitrary values for signed ints too. </cmt>,support varlen encoding for arbitrary int and uint numbers
2013,"<desc> in practice, these are the changes: improvements: implement window resize, maximize, fullscreen implement get_screen_size implement set_window_title implement shell_open implement proper alert fixes: selecting text with cursor drag and drop scrolling no longer causes gui lock up invalid locale error print debug messages without terminal color codes entering fullscreen is subject to browser security limitations and will only work in response to a user input, such as a key or mouse button press. scrolling on chromium is inverted due to emscripten's glut implementation. this is not a regression from these changes. we can use another api or fix it upstream (or hack it). </desc> <cmt> os additions and fixes for webassembly/asm.js </cmt> <cmt> - implement alert, shell_open, set_window_title </cmt> <cmt> - add locale lookup, fixes #2477 </cmt> <cmt> - print without color control sequences </cmt> <cmt> - move get_executable_path implementation to os_javascript </cmt> <cmt> fix some mouse bugs in webassembly/asm.js </cmt> <cmt> - emit mouse wheel release events </cmt> <cmt> - set button masks, fixes #5092 </cmt> <cmt> add window features in web export </cmt> <cmt> - add 'window' (canvas) resize, maximize and fullscreen </cmt> <cmt> - implement get_screen_size </cmt> <cmt> - fix fullscreen resolution </cmt>",work on asm.js and webassembly platforms
2014,<desc> updated code based on review for bael-924  ali.raza </desc> <cmt> bael-924: how to get all localdates between two dates? </cmt> <cmt> bael-924: updated code based on review from editor </cmt> <cmt> bael-924: updated code based on review from editor </cmt>,bael 924 updated code based on review from editor
2015,"<desc> originally updating any active media listing after a video library update was done in cguidialogvideoscan which was replaced by cguidialogextendedprogressbar in #1560 but the code to invalidate the videodatabase cache and to update any currently active listing was lost with the removal of cguidialogvideoscan. this adds the old logic to the end of cvideoinfoscanner::process() where we also send the videolibrary.onscanfinished announcement, similar to how it's done in cmusicinfoscanner. </desc> <cmt> cmusicinfoscanner: always send gui_msg_scan_finished </cmt> <cmt> cvideoinfoscanner: make sure to update any active listing after a finished scan </cmt> <cmt> originally this was done in cguidialogvideoscan which was replaced by </cmt> <cmt> cguidialogextendedprogressbar in 79ed7ae but the code to invalidate the </cmt> <cmt> videodatabase cache and to update any currently active listing was lost. </cmt>",fix refreshing of active media listings after a library update
2016,"<desc> i do not expect that there is a bug, but it makes sense to test empty files as it is one corner case. </desc> <cmt> we should be able to open empty files. </cmt> <cmt> testing also the ondemand api. </cmt>",we should be able to open empty files (paranoid test)
2017,"<desc> motivation i was using carbon this week (great tool btw), and thought to myself that the user experience might be a bit better if the file names were timestamped, like how the native screen capture tool on macos saves files as screen shot 2018-07-13 at 1.47.37 am or how monosnap saves files as screencast 2018-07-12 14-24-21.mp4 it's a minor improvement, but i personally find it easier to sort through multiple carbon-generated files if they all have unique file names like this, since: date/time is a lot easier to read through and gives more information than carbon, carbon(1), carbon(2), etc.. the order in which your files are displayed is consistent with time. if you instead save all files with the same name, you can get mixed up while deleting (e.g. if you have up to carbon(7), but you delete carbon(3), your next file will be saved as carbon(3), which is mildly confusing). my changes i added a few lines of code in the save() function within editor.js that parse a timezone-adjusted iso8601 time stamp (slightly formatted for readability). of course, i also made it a toggle in the settings so that it wasn't forced upon everyone. result files are now saved in this format: carbon yyyy-mm-dd hh-mm-ss.ext (e.g. carbon 2018-07-13 01-31-11.png). p.s. i also added .ds_store to the .gitignore since it was bugging me, but it's totally unrelated to the rest of this pr. </desc> <cmt> add timestamp to file name save </cmt> <cmt> add .ds_store to .gitignore </cmt> <cmt> add setting to toggle timestamp on file save </cmt>",add optional timestamp to saved file names
2018,<desc> plus some other small refactors </desc> <cmt> refactor: move create_http_client to deno_fetch </cmt> <cmt> refactor: deno crate doesn't need to depend on deno_tls </cmt> <cmt> refactor: no need to handle clientbuilder errors </cmt> <cmt> add 30 second timeout to fetch clients </cmt>,cli doesn't need to depend on deno_tls
2019,<desc> also includes for its substructure: function-call-argument function-call-argument-list symbolic-reference-expression (for the call target) </desc> <cmt> [syntax] implement function-call-expression in lib/syntax </cmt> <cmt> also includes for its substructure: </cmt> <cmt> - function-call-argument </cmt> <cmt> - function-call-argument-list </cmt> <cmt> - symbolic-reference-expression (for the call target) </cmt> <cmt>  </cmt> <cmt> [syntax] roughly categorize unimpemented productions in status.md </cmt>,implement stuff for function call expressions
2020,<desc> question: how does darling handle it when files such as /etc/darling/dylib.conf are changed in the source of the project which also exist in the prefix? i couldn't get it to install and had to copy it over to my prefix. </desc> <cmt> move ruby out from an unnecessary subdirectory </cmt> <cmt> add the python framework to /etc/darling/dylib.conf </cmt> <cmt> fixes an issue where the dynamic linker could not load them </cmt> <cmt> update the ruby submodule to reflect moving it up a directory </cmt>,"add python to /etc/darling/dylib.conf, move the ruby folder up, and add debugsymbols.framework"
2021,<desc> three parts modification: 1 add some supplement i18n and l10n; 2 remove src setting from org.jkiss.dbeaver.ext.sample.database.nls; 3 add babel fragments to org.jkiss.dbeaver.rcp.nls.feature. </desc> <cmt> update coreresources_zh.properties </cmt> <cmt> fix </cmt> <cmt> update coreresources_zh.properties </cmt> <cmt> update to 4.2.5 </cmt> <cmt> add some supplement. </cmt> <cmt> i18n supplement for sqleditor.java </cmt> <cmt> supplement l10n for bundle_zh in org.jkiss.dbeaver.core.nls </cmt> <cmt> update </cmt> <cmt> remove src setting from org.jkiss.dbeaver.ext.sample.database.nls to fix </cmt> <cmt> error. </cmt> <cmt> add babel fragments to org.jkiss.dbeaver.rcp.nls.feature. </cmt>,add babel fragments to ..rcp.nls.feature and remove src setting from ..ext.sample.database.nls
2022,"<desc> this implementation will add the warning header if the license is going to expire in less than {license_expiration_warning_period} days. the messages added: warning: 299 elasticsearch-8.0.0-###""your license will expire in [n] days. contact your administrator or update your license for continued use of features"" warning: 299 elasticsearch-8.0.0-### ""your license expires today. contact your administrator or update your license for continued use of features"" if license has expired less than {grace_period_duration} days ago following warning is added: warning: 299 elasticsearch-8.0.0-### ""your license expired on [""eeee, mmmm dd, yyyy"" ]. contact your administrator or update your license for continued use of features"" both {license_expiration_warning_period} and {grace_period_duration} are currently 7 days. the message will be added to each request unless authentication fails. note: with this change all warning headers will be removed from a response if authentication fails. #backport #64948 </desc> <cmt> adding a warning header when a license is about to expire (#64948) </cmt> <cmt> * this change adds a warning header when a license is about to expire </cmt> <cmt> resolves #60562 </cmt> <cmt> * this change adds realm name of the realm used to perform authentication to the responses of _security/oidc/authenticate and _security/oidc/authenticate apis </cmt> <cmt> resolves #53161 </cmt> <cmt> * adding doc for the new api introduced by #64517 - /_security/saml/metadata/{realm} </cmt> <cmt> related to #49018 </cmt> <cmt> * adding a warning header when a license is about to expire </cmt> <cmt> resolves #60562 </cmt> <cmt> * addressing the pr feedback </cmt> <cmt> * switching back to adding the header during featurecheck to allow </cmt> <cmt> warnings when authentication is disabled as well. adding filterheader </cmt> <cmt> implementation to securityrestfilter exception handling to remove all </cmt> <cmt> the warnings if authentication fails. </cmt> <cmt> * changing the wording for ""expired"" message to be consistent with the log </cmt> <cmt> messages; changing ""today"" calculation; adding a test case for failing </cmt> <cmt> authn to make sure we remove the warning header </cmt> <cmt> * small changes in the way we verify header in tests </cmt> <cmt> * nit changes </cmt> <cmt> resolving backporting issue: adding copymapwithremovedentry() util function </cmt> <cmt> fixing unused imports </cmt>",adding a warning header when a license is about to expire #64948
2023,"<desc> fix broken link to ""interact with new charts"" component name documentation n/a n/a </desc> <cmt> add note for the new release of charts on the cloud </cmt> <cmt> update docs/visualize/interact-dashboards-charts.md </cmt> <cmt> update docs/visualize/interact-dashboards-charts.md </cmt> <cmt> add note for the new release of charts on the cloud </cmt> <cmt> fix broken link </cmt> <cmt> fix broken link </cmt>",charts 2.0 - fix broken link
2024,"<desc> rewrite sort on long field (number or date) to lucene distancefeaturequery. this allows to skip non-competitive hits leading to speedups on sort. </desc> <cmt> optimize sort on numeric long and date fields (#39770) </cmt> <cmt> optimize sort on numeric long and date fields, when </cmt> <cmt> the system property es.search.long_sort_optimized is true. </cmt> <cmt> skip optimization if the index has duplicate data (#43121) </cmt> <cmt> skip sort optimization if the index has 50% or more data </cmt> <cmt> with the same value. </cmt> <cmt> when index has a lot of docs with the same value, sort </cmt> <cmt> optimization doesn't make sense, as distancefeaturequery </cmt> <cmt> will produce same scores for these docs, and lucene </cmt> <cmt> will use the second sort to tie-break. this could be slower </cmt> <cmt> than usual sorting. </cmt> <cmt> sort leaves on search according to the primary numeric sort field (#44021) </cmt> <cmt> this change pre-sort the index reader leaves (segment) prior to search </cmt> <cmt> when the primary sort is a numeric field eligible to the distance feature </cmt> <cmt> optimization. it also adds a tie breaker on _doc to the rewritten sort </cmt> <cmt> in order to bypass the fact that leaves will be collected in a random order. </cmt> <cmt> i ran this patch on the http_logs benchmark and the results are very promising: </cmt> <cmt>  </cmt> <cmt> |                                       50th percentile latency | desc_sort_timestamp |    220.706 |      136544 |   136324 |     ms | </cmt> <cmt> |                                       90th percentile latency | desc_sort_timestamp |    244.847 |      162084 |   161839 |     ms | </cmt> <cmt> |                                       99th percentile latency | desc_sort_timestamp |    316.627 |      172005 |   171688 |     ms | </cmt> <cmt> |                                      100th percentile latency | desc_sort_timestamp |    335.306 |      173325 |   172989 |     ms | </cmt> <cmt> |                                  50th percentile service time | desc_sort_timestamp |    218.369 |     1968.11 |  1749.74 |     ms | </cmt> <cmt> |                                  90th percentile service time | desc_sort_timestamp |    244.182 |      2447.2 |  2203.02 |     ms | </cmt> <cmt> |                                  99th percentile service time | desc_sort_timestamp |    313.176 |     2950.85 |  2637.67 |     ms | </cmt> <cmt> |                                 100th percentile service time | desc_sort_timestamp |    332.924 |     2959.38 |  2626.45 |     ms | </cmt> <cmt> |                                                    error rate | desc_sort_timestamp |          0 |           0 |        0 |      % | </cmt> <cmt> |                                                min throughput |  asc_sort_timestamp |   0.801824 |    0.800855 | -0.00097 |  ops/s | </cmt> <cmt> |                                             median throughput |  asc_sort_timestamp |   0.802595 |    0.801104 | -0.00149 |  ops/s | </cmt> <cmt> |                                                max throughput |  asc_sort_timestamp |   0.803282 |    0.801351 | -0.00193 |  ops/s | </cmt> <cmt> |                                       50th percentile latency |  asc_sort_timestamp |    220.761 |     824.098 |  603.336 |     ms | </cmt> <cmt> |                                       90th percentile latency |  asc_sort_timestamp |    251.741 |     853.984 |  602.243 |     ms | </cmt> <cmt> |                                       99th percentile latency |  asc_sort_timestamp |    368.761 |     893.943 |  525.182 |     ms | </cmt> <cmt> |                                      100th percentile latency |  asc_sort_timestamp |    431.042 |      908.85 |  477.808 |     ms | </cmt> <cmt> |                                  50th percentile service time |  asc_sort_timestamp |    218.547 |     820.757 |  602.211 |     ms | </cmt> <cmt> |                                  90th percentile service time |  asc_sort_timestamp |    249.578 |     849.886 |  600.308 |     ms | </cmt> <cmt> |                                  99th percentile service time |  asc_sort_timestamp |    366.317 |     888.894 |  522.577 |     ms | </cmt> <cmt> |                                 100th percentile service time |  asc_sort_timestamp |    430.952 |     908.401 |   477.45 |     ms | </cmt> <cmt> |                                                    error rate |  asc_sort_timestamp |          0 |           0 |        0 |      % | </cmt> <cmt>  </cmt> <cmt> so roughly 10x faster for the descending sort and 2-3x faster in the ascending case. note </cmt> <cmt> that i indexed the http_logs with a single client in order to simulate real time-based indices </cmt> <cmt> where document are indexed in their timestamp order. </cmt> <cmt> relates #37043 </cmt> <cmt> remove nested collector in docs response </cmt> <cmt> as we don't use cancellablecollector anymore, it should be removed from </cmt> <cmt> the expected docs response. </cmt> <cmt> use collector manager for search when necessary (#45829) </cmt> <cmt> when we optimize sort, we sort segments by their min/max value. </cmt> <cmt> as a collector expects to have segments in order, </cmt> <cmt> we can not use a single collector for sorted segments. </cmt> <cmt> thus for such a case, we use collectormanager, </cmt> <cmt> where for every segment a dedicated collector will be created. </cmt>",optimize sort on long field
2025,<desc> this is part of the initiative to return disposables in any place we add something we may later want to remove. i'll be opening prs for each specific subsystem to keep things small. </desc> <cmt> return disposables from menumanager which can be used to remove menus </cmt> <cmt> :pencil: update docs </cmt>,return disposables from menumanager::add and add specs
2026,"<desc> demo for using feathers with vue 2.0. it includes authentication, vue-router, vue-infinite-loading and roles </desc> <cmt> feathers and vue 2.0 blog admin demo </cmt> <cmt> demo for using feathers with vue 2.0. it includes authentication, </cmt> <cmt> vue-router, vue-infinite-loading and roles </cmt> <cmt> feathers and vue 2.0 blog admin demo </cmt>",vue 2.0 and feathers blog admin demo
2027,"<desc> this is a new d.ts for datatables v. 1.10.0 - 1.10.5. starting from version 1.10 datatables has a new api and new options. this file has also some of the old interfaces located under the settingslegacy namespace. anyway this is a new file with new namings, so this may not be compatible with the old d.ts file. also this is my first public d.ts file and i'm not sure if the structure matches your expectation. updated request to fix bugs in travis-ci. </desc> <cmt> new jquery.datatables.d.ts for new api 1.10.x </cmt> <cmt> # complete file adding new settings and api for datatable </cmt> <cmt> # all methods and settings for 1.10.5 </cmt> <cmt> # basic testing </cmt> <cmt> add (legacy) settings for internal api use </cmt> <cmt> # add (legacy) settings for internal api use </cmt> <cmt> # remove i from naming </cmt> <cmt> # update tests </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add reference paths </cmt>",new d.ts for datatables version 1.10.5
2028,<desc> changes are mostly for updating version strings. also change tf_patch_version in master to head. </desc> <cmt> update version string to 0.11.0. </cmt> <cmt> update version string to 0.11.0. </cmt> <cmt> disable flacky test contrib/slim/learning_test. </cmt> <cmt> disable flacky test contrib/slim/learning_test. </cmt> <cmt> reformat markdown. </cmt> <cmt> change: 138541907 </cmt> <cmt> (cherry picked) </cmt> <cmt> reformat markdown. </cmt> <cmt> fix syntax error in unchangedshape example code (#5566) </cmt> <cmt> update master patch version. </cmt>,merge release version back to master.
2029,"<desc> fix #2353 ignore the attribute of interfacename in serviceannotationbeanpostprocessor#buildservicebeandefinition method follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskiptests & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> sync apache dubbo code </cmt> <cmt> add getter and setter for serviceconfig's interfacename property#2353 </cmt> <cmt> add getter and setter method for serviceconfig's interfcename </cmt> <cmt> property#2352 </cmt> <iss> @serviceinterfacenameserviceconfiginterface </iss>",[dubbo-2353]fix invalid property 'interfacename' of bean class [org.apache.dubbo.config.spring.servicebean]#2353
2030,<desc> fix subtle flaws in scripts in tools/gce and make them pass shellcheck. expand shellcheck enforcement on tools/gce directory. progress on #11601. </desc> <cmt> fix create_interop_worker.sh to pass shellcheck </cmt> <cmt> fix create_linux_worker.sh to pass shellcheck </cmt> <cmt> fix linux_worker_init.sh to pass shellcheck </cmt> <cmt> fix create_linux_kokoro_performace_worker.sh to pass shellcheck </cmt> <cmt> fix create_windows_debug_worker.sh to pass shellcheck </cmt> <cmt> fix linux_kokoro_performance_worker_init.sh to pass shellcheck </cmt> <cmt> fix linux_performance_worker_init.sh to pass shellcheck </cmt> <cmt> fix create_linux_performance_worker.sh to pass shellcheck </cmt> <cmt> enforce shellcheck on tools/gce </cmt>,enforce shellcheck on tools/gce directory
2031,"<desc> this is to fix a bug in #10580 the bug happens when an ndarray already has a mkldnn memory with a special mkldnn format. in some cases (group convolution), the mkldnn memory uses 5 dimensions, while the ndarray still uses 4 dimensions. in this case, when getmkldnndata is called, setmklmem will discard the original mkldnn memory due to incompatible dimensions between mkldnn memory and ndarray. this messes up the data in the ndarray. the test code in the pr can actually reproduce the bug in #10580 this pr also tries to add c++ unit tests to cover all possible combinations with getting mkldnn memory from an ndarray. thank @taolv @pengzhao-intel for finding the root cause of this bug. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> test inference multiple times. </cmt> <cmt> fix a bug in getmkldnndata(). </cmt> <cmt> update comments. </cmt>",fix a bug in the mkldnn integration.
2032,"<desc> change the overload manager api to extend the overload action state with non-binary values. this will allow future overload actions to take effect in response to increasing load, instead of to the existing inactive/active binary values. this pr also adds a range field to the overload trigger config, though no actions currently trigger on the 'scaling' state. the existing behavior is preserved by replacing all places where overloadactionstate::active was being used with overloadactionstate::saturated(). this is a minimal re-hashing of #11697 for ##11427. risk level: medium testing: ran unit and integration tests docs changes: none release notes: add ""scaling"" trigger for overloadmanager actions </desc> <cmt> add 'scaling' to overloadmanager action states </cmt> <cmt> extend the existing overload action states with a 'scaling' state with a </cmt> <cmt> value in the range [0, 1]. the scaling state is not used yet, but will </cmt> <cmt> be used to support actions that can take partial effect even if resource </cmt> <cmt> pressure is below saturation. </cmt> <cmt> add range trigger to overload manager </cmt> <cmt> add a range trigger that will produce overload action states that are in </cmt> <cmt> between the inactive and saturated states. this will enable the creation </cmt> <cmt> of actions that take more effect as load increases. </cmt>",add support for range trigger overload actions
2033,"<desc> i think we'll need to update the hook as well, will check that once with @dzhwinter . </desc> <cmt> adding more details to cluster_train </cmt> <cmt> update copyright for notest_dist_image_classification </cmt> <cmt> fixed copyright </cmt> <cmt> updating the copyright year and content </cmt>",updating the copyright year for the recent files.
2034,"<desc> commit message: refactor watermark accounting logic during encodeheaders|data|trailers() by wrapping the code counting buffer size before and after into a scoped object. additional description: the above change fix 2problems: when the stream gets reset or connection gets closed during the scope of updating watermark buffer, the watermark accounting clean-up was nested in the another buffer updating; in gquic, quicconnection::oncanwrite() counts buffered bytes change twice against connection buffer watermark if oncanwrite() triggers encodeheaders(). risk level: low testing: added stream unit tests to test connection close during writeheaders() and writebodyslices() and session unit tests to test oncanwrite() triggers encodeheaders(); part of #2557 </desc> <cmt> add 100 continue </cmt> <cmt> add tests </cmt> <cmt> watermark buffer </cmt>",prevent nested buffer watermark accounting
2035,"<desc> changelog entry (up to few sentences, required except for non-significant/documentation categories): removed ""pie"" code generation that gcc from debian packages occasionally brings by default. detailed description (optional): after upgrading from gcc-8 to gcc-9 in our ci about half a year ago, occasionally our code starts to be generated with ""position independent executable"" option. this leads to less efficient addressing of global const tables. we saw slight performance degradation in our ci but decided to not pay attention. </desc> <cmt> removed pie </cmt> <cmt> corrections to prev. revision </cmt>","removed ""pie"" code generation that gcc occasionally brings by default"
2036,"<desc> updates the buildresult to track input and output files. due to some issues with other parts of the tool re-writing these files constantly, some have been factored out of the list. adds an ""optional"" source and a pod rule to use it. until i add a configuration/planning phase i need to add the pod step to every build, but only run it when a podfile exists. implementation of flutter assemble for the macos build. this updates the entrypoint script to move all artifact copying/generation into build rules. this also generates an input/output xcfilelist that can be used by xcode to skip the entire script phase. this requires the project changes in google/flutter-desktop-embedding#459 #32921 </desc> <cmt> re implementation of macos assemble </cmt> <cmt> make it go vroom vroom </cmt>",flutter assemble for macos take 2!
2037,"<desc> purpose this pr delivers the resolved config section to the project settings page. closes #unify-262 how to test open up the cypress component test runner within this branch. yarn workspace @packages/launchpad cypress:open # from the project root settings page, so far... this is the final component to be built within the settings page. here's how it looks! components the resolved config is ready to be plumbed into gql to fetch the real project config. right now, it's only rendering a json object to the screen -- it still needs the syntax highlighting logic. config-file.mov configcode the component responsible for displaying the resolved json from the config object. it supports copying, but there is still an outstanding task to hook it up so that it opens the user's editor. this is waiting on the proper endpoint. configlegend the component that renders the correct text for each label and described where each setting comes from. configbadge the small badge and description below that's used to build the configlegend. i'm exploring the idea of text matching for content, based off of the default localized english strings. this both makes sure that we're choosing high-confidence tests as well as means that we won't inadvertently break tests when making changes to the app's copy. it's only complicated by the localized strings which require html to be set inside of them. it's not that big of a deal and right now i'm just string slicing. in the future, if we actually care more about this, or like this approach, i have an idea for how to build it this support into a cy command so that it behaves like a normal cy.contains might. </desc> <cmt> feat: adding strings for the resolved config </cmt> <cmt> feat: adding the resolved settings section and a ton of tests </cmt> <cmt> feat: adding strings for the resolved config </cmt> <cmt> feat: adding the resolved settings section and a ton of tests </cmt>",adding the resolved config to the settings page
2038,"<desc> following up on #7448 and #6398, bump to pydot >= 1.2.4, and import pydot, as required in setup.py. pydot is maintained at:  also, these changes improve the error messages, distinguishing between whether pydot isn't installed (if so indicating how to install it), or graphviz executables (dot) cannot be found. see also: pydot/pydot#152 #5313 </desc> <cmt> rel: bump to pydot >= 1.2.4 in extras_require </cmt> <cmt> mai: import pydot (as required in extras_require) </cmt> <cmt> mai: refine error messages for pydot and graphviz </cmt> <cmt> distinguish between absence of pydot and failure to find </cmt> <cmt> the executables of graphviz in the $path. </cmt> <cmt> dev: ignore .pytest_cache </cmt>","import pydot, improve error messages about pydot and graphviz, bump to pydot >= 1.2.4"
2039,"<desc> create strings directory fix docs add test i have read contributing.md. this pr only changes one algorithm file.  to ease review, please open separate prs for separate algorithms. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> * rename file </cmt> <cmt> * create strings directory </cmt> <cmt> * fix docs </cmt> <cmt> * add test </cmt> <cmt> updating directory.md </cmt>",created strings directory and rename files
2040,<desc> fixes #21877. the documentation example under section 1.12.2.2. multioutputclassifier corresponds to a multi-class multi-output classification and fits better under section 1.12.3. multiclass-multioutput classification. i have moved the example and made sure example is better conform with the contribution guide guidelines. i also link to the example in section 1.12.2.2. multioutputclassifier. </desc> <cmt> doc: moved example multiclass-multioutput to next section </cmt> <iss> multioutputclassifier example </iss>,doc multioutput classifier example loc change
2041,"<desc> add readmes for userspace features that didn't have them. separate out userspace code into more logical units add folders for userspace, to keep folder cleaner pull out pointing device user code into userspace force disable optimization for autocorrect add watchdog reset for split syncing add keyboard reboot code (eg, reset but not into bootloader) add file for all per user tap-hold functions cleanup oled font file a bit replace userspace copyright headers with spdx version fix up userspace rules fix up various keyboards not compiling properly my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> update font file </cmt> <cmt> fix issues with worklouder workboard keymap </cmt> <cmt> disable optimization for autocorrection </cmt> <cmt> work louder keymap tweaks </cmt> <cmt> move rgb matrix indicators into userspace </cmt> <cmt> clean up keymaps and enabled features </cmt> <cmt> clean up keymaps </cmt> <cmt> disable caps words by default </cmt> <cmt> fix debug scan rate function </cmt> <cmt> add autocorrection keycode to crkbd </cmt> <cmt> enhance autocorrect generation </cmt> <cmt> improve caps word </cmt> <cmt> re-add mod checks to autocorrect </cmt> <cmt> add unicode fixes </cmt> <cmt> update tapping config </cmt> <cmt> further reorganized userspace to make more modular </cmt> <cmt> reorganize userspace rules </cmt> <cmt> make lt lower backspace key easier to trigger properly </cmt> <cmt> update copyright headers </cmt>","reorganization, cleanup and readmes for drashna code"
2042,"<desc> fixes multi_worker data loader when record file is used. the mxrecordio instance needs to require a new file handler after fork to be safely manipulated simultaneously. this fix also safely voids the previous temporary fixes #12093 #11370. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> temp solution to record file dataset with multi worker </cmt> <cmt> fix cascaded dataset for gluon dataloader, when multi_worker > 0 is used </cmt>",fix lazy record io when used with dataloader and multi_worker > 0
2043,"<desc> i hereby agree to the terms of the cla available at:  changelog entry (up to few sentences, required except for non-significant/documentation categories): add install scripts for .tgz packages. </desc> <cmt> some updates in trash scripts </cmt> <cmt> uncomment line </cmt>",install script for tgz package
2044,"<desc> refactored the default keymap to use #include qmk_keyboard_h, and gave it a readability update. also filled out the info.json for configurator support. </desc> <cmt> default keymap refactor: qmk_keyboard_h include; readability </cmt> <cmt> configurator support </cmt>",kmini refactor and configurator support
2045,"<desc> this is based on the discussion in #1430. it adds order preservation to the async.concat functions. i feel like i might have changed our internal structure a little bit too much though by removing internal/concat and internal/doseries. if i did, let me know, i'll change the pr to only modify the tests and internal/concat. thanks! this isn't actually changing our public api, so i feel like it should be okay? otherwise, i still want to add a couple more tests before merging (for sparse results, original untouched, etc...). added tests. </desc> <cmt> preserve order in concat </cmt> <cmt> remove comment </cmt> <cmt> fix concatlimit linting </cmt>","preserve order, make variadic and handle falsy values in concat"
2046,"<desc> a better workaround for #7224 than #14164, this implements @hixie's suggestion of skipping over the extraneous error message in the test expectation.  however, since we don't want to lose track of the check for unusual error messages entirely, add a new test that specifically checks for that. </desc> <cmt> ignore extraneous error messages outside of one skipped test </cmt>",make automated_tests mostly ignore extraneous error messages
2047,"<desc> manual backport of #29255 and #29295 . updates documentation from our current master branch npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> docs: update 14.0.0 stable dates (#29255) </cmt> <cmt> * docs: update 14.0.0 stable dates </cmt> <cmt> * update docs/tutorial/electron-timelines.md </cmt> <cmt> docs: update currently supported versions for 13.0.0 release (#29295) </cmt>",change 14.0.0 stable dates and currently supported versions
2048,"<desc> re: issue #4694 add flatbuffers_ prefix to the following defines, to avoid clashes with other libraries which may define similar names: struct_end -> flatbuffers_struct_end manually_aligned_struct -> flatbuffers_manually_aligned_struct define_bitmask_operators -> flatbuffers_define_bitmask_operators regenerated code in test/, added the changes if any were significant. </desc> <cmt> rename struct_end to add flatbuffers_ prefix, now flatbuffers_struct_end. via running ag -l struct_end | xargs rpl struct_end flatbuffers_struct_end </cmt> <cmt> rename manually_aligned_struct to add flatbuffers_ prefix, now flatbuffers_manually_aligned_struct. via running ag -l manually_aligned_struct | xargs rpl manually_aligned_struct flatbuffers_manually_aligned_struct && cd tests && sh generate_code.sh </cmt> <cmt> rename define_bitmask_operators to add flatbuffers_ prefix, now flatbuffers_define_bitmask_operators. via running ag -l define_bitmask_operators | xargs rpl define_bitmask_operators flatbuffers_define_bitmask_operators </cmt>",add flatbuffers_ prefix to defines [c++]
2049,"<desc> with #10995 merged, i'm moving ahead with breaking all our dashboard/web server content into a new series docs, starting with the following: how the dashboard works, which explains the fundamentals of the dashboard and charts. interact with charts, which outlines all the different ways to interact with charts. this information already exists elsewhere, but not completely obvious formats/locations. once this pr is merged, i'll move on to the next batch. the next batch is chart dimensions, contexts, and families and select timeframes to visualize, followed by import, export, and print snapshots and customize the standard dashboard, and lastly an improved web server reference. once those are all merged, i'll remove obsolete docs and change links to the new files. component name area/docs area/web </desc> <cmt> finish initial draft </cmt> <cmt> finish with draft of installation flow </cmt> <cmt> change analytics path </cmt> <cmt> rename file and improve flow </cmt> <cmt> init new files </cmt> <cmt> init new dashboard files </cmt> <cmt> finish initial draft </cmt> <cmt> finish with draft of installation flow </cmt> <cmt> change analytics path </cmt> <cmt> rename file and improve flow </cmt> <cmt> init new files </cmt> <cmt> init new dashboard files </cmt> <cmt> merge in changes </cmt>",improve dashboard documentation (part 1)
2050,"<desc> this pr adds a command to paste without performing any reformatting, regardless of the source of the copied text or the settings for the current file. the following transformations are suppressed: line ending normalization. all instances of \r\n and \n in the pasted text will be preserved regardless of the line endings in the file. auto-indent there is a global ""auto-indent on paste"" setting that can also be assigned per-language, but this command is a way to momentarily bypass that setting. relative indent level adjustment by default, we attempt to keep the relative indent level of all lines consistent with the copied text. sometimes people don't want that. relevant to recent discussion in #1407 </desc> <cmt> add preservetrailinglineindentation option to selection.inserttext </cmt> <cmt> we can use this to support a new command that preserves all formatting </cmt> <cmt> when pasting. </cmt> <cmt> respect format-preserving options in texteditor.pastetext </cmt> <cmt> add paste without reformatting command </cmt> <cmt> it is bound to cmd-shift-v on macos and ctrl-shift-v on windows and </cmt> <cmt> linux. it is also available in the edit menu. </cmt>",add command to paste without reformatting
2051,"<desc> backport of gh-14290. all but the merge commit are identical. </desc> <cmt> bug: make np.record work on structured fields with no fields </cmt> <cmt> this replaces some more uses of bool(dt.fields) and bool(dt.names) with dt.names is not none. </cmt> <cmt> dt.fields is not none would have worked too, but checking .names is more prevalent elsewhere </cmt> <cmt> bug: fix crash in recarray if nested structured dtypes contain padding </cmt> <cmt> previously attempting to access a field of such an array (such as when printing it!) would result in valueerror: changing the dtype of a 0d array is only supported if the itemsize is unchanged. </cmt> <cmt> bug: fix crash on genfromtxt with nested empty structured array </cmt> <cmt> previously this would fail with valueerror: could not assign tuple of length 2 to structure with 3 fields., now it raises notimplementederror. </cmt> <cmt> bug: recfunctions: don't return none in place of empty sequences </cmt> <cmt> replacing empty tuples with none is a bad idea, and just results in an api that is hard to consume - especially since the behavior was never documented. </cmt> <cmt> this affects get_names, get_names_flat, and get_fieldstructure. </cmt> <cmt> maint: test names against none for consistency </cmt> <cmt> in these instances the behavior isn't changed, since the for loop below acts like an if. </cmt> <cmt> however, in general this is an antipattern that crashes on 0-field structured types, and is warned against in the docs. </cmt> <cmt> if we remove instances of the antipattern, it will hopefully not reappear via copy-paste code. </cmt> <cmt> maint: improve ndpointer.__name__ for structured types with 0 fields </cmt> <cmt> without this change, np.dtype('v0') and np.dtype([]) produced types with the same name, which was misleading as they are different types. </cmt> <cmt> this is mostly cosmetic. </cmt> <cmt> maint: remove incorrect comment about flattening </cmt> <cmt> also adjust the code to more clearly indicate what actually happens. </cmt> <cmt> the behavior is identical before and after this patch. </cmt> <cmt> maint: use the .names is none idiom to detect structured array in arrayprint </cmt> <cmt> no behavior change here </cmt> <cmt> bug: don't allow extra fields to be added in genfromtxt </cmt> <cmt> previously passing dtype=[], names=['a'] would append an extra field, even though dtype=['a'], names=['b', 'c'] does not. </cmt> <cmt> bug: don't construct masked arrays with the wrong mask type in genfromtxt </cmt> <cmt> this only affects arrays with dtype([]), but also follows the recommended way to check for structured arrays in our docs </cmt> <cmt> bug: fix detection of structured arrays in mrecords </cmt> <cmt> this check would fail on the structured type np.dtype([]). </cmt> <cmt> no test, since i don't really understand mrecords </cmt> <cmt> maint: fix remaining misuses of bool(dt.names) </cmt> <cmt> it's not clear that these have any visible effect, but we should be consistent with how we detect structured types. </cmt>",fix misuse of .names and .fields in various places (backport 14290 to 1.17)
2052,"<desc> fix temp_key being stale on key re-insert. this pull request re-uses the existing key, which matches the previous behavior. before the fix, there was a chance that temp_key would be the last inserted key, or effectively garbage data. this manifested for me in double frees and entries with incorrect keys. see issue #992 and pull request #993. </desc> <cmt> fix temp_key being stale on key re-insert </cmt> <cmt> see issue #992 and pull request #993. </cmt> <cmt> added macoy madson to contributors </cmt>",shputs duplicate insert: fix stale temp_key
2053,"<desc> when we form a collection upcast of a collection literal, upcast the individual elements directly so we avoid a call through the runtime. this both improves code generation and sidesteps a regression involving the inability to dynamically cast function types. fixes sr-7362 / rdar://problem/39218656. </desc> <cmt> [ast] optimize collection upcasts of array literals. </cmt> <cmt> when we form a collection upcast of an array literal, upcast the </cmt> <cmt> individual elements directly so we avoid a call through the </cmt> <cmt> runtime. this both improves code generation and sidesteps a regression </cmt> <cmt> involving the inability to dynamically cast function types. </cmt> <cmt> fixes sr-7362 / rdar://problem/39218656. </cmt> <cmt> [type checker] extend the upcast-of-literal peephole to dictionary literals. </cmt> <cmt> when the operand of a collection upcast is a dictionary literal, </cmt> <cmt> upcast the elements of the collection instead. this avoids going </cmt> <cmt> through the dynamic-casting machinery. </cmt> <cmt> [type checker] factor out the collection upcast peephole code. </cmt> <cmt> while here, cope with extra parentheses as well. they shouldn't </cmt> <cmt> inhibit this optimization. </cmt>",optimize collection upcasts of collection literals.
2054,<desc> microsoft/vscode-docs#1530 updates settings.md which pulls descriptions from default settings also fixing typos in vscode.previewhtml displayed in vscode-api-commands.md. </desc> <cmt> edit pass on built-in extension descriptions </cmt> <cmt> merge vscode master </cmt> <cmt> update settings description typos </cmt>,update settings descriptions to match vscode-docs pr#1530
2055,<desc> description: fixed issue with tilt range potentially being non-zero based pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#2548 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> repairing functionality for non-zero based ranges </cmt> <cmt> fixing documentation </cmt>,fixed status reporting for range with non-zero base
2056,"<desc> now the crash report sent through the programming port respects the baudrate fixed a huge startup delay if wdt reset the board and usb native port was being used. added a traceback to the crash report.  for it to work, you need to compile the project with -funwind-tables and -mpoke-function-name compiler flags.  a due_debug section has been added to platformio.ini to include those flags when debugging.  adding the flags increases the flash usage by 5% - 8% so they shouldn't be enabled by default. the traceback reports as many stack levels as is available.  it also reports the function name associated with each level.  you'll need the .elf file to unmangle most of the names or feed the program counter to the arm-none-eabi-addr2line utility to get a really nice report including file name & line number. </desc> <cmt> as bob-the-khun suggested, resetting the usb peripheral solves the huge startup delays that happen when a wdt reset happens and we are connected through the native port </cmt> <cmt> now the crash reporter uses the configured baudrate to send the report through the programming port. and also shows the traceback of functions as discussed. for that latest feature to work, you need to compile the project with -funwind-tables and -mpoke-function-name compiler flags </cmt>","solve wdt startup delay, add traceback & crash report uses programming port baud rate"
2057,"<desc> these commits fix  the first commit fixes the behaviour in grouputils::group() to return true when grouping an empty list. imo this is correct as the empty list has been grouped (nothing to group). the second commit fixes cguidialogvideoinfo::getsetformovie() to not fail if there are no sets available. the last commit fixes the focus problem in cguidialogselect which happens when the dialog is opened with an empty list. by default an item in the list is auto-focused but that doesn't work properly if the list is empty. as a result nothing is focused and using arrow keys to focus something else (the extra button) does not work either. the fix sets focus to the extra button (if visible) if the list is empty. </desc> <cmt> grouputils: grouping an empty list is not an error </cmt> <cmt> video library: show the ""select movie set"" dialog even if there are no sets to choose from </cmt> <cmt> cguidialogselect: focus the extra button (if available) when the selection list is empty </cmt>","fix ""manage movie sets..."" doing nothing when there are no sets available"
2058,"<desc> added k.o,y layout for several boards, as well as a german keyboard layout for xd75re. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added accent. </cmt> <cmt> added keymap for 5x6 dactyl manuform on koy layout </cmt> <cmt> added xd75 folder that is not in the main repo anymore? </cmt> <cmt> added keymap for naked48 on koy layout </cmt> <cmt> added keymap for splitreus62 on koy layout </cmt> <cmt> added keymap for dactyl manuform 4x6 with rgb leds and k.o,y layout </cmt> <cmt> fixed error where handedness was not correctly determined because of combining vbus pins of both controllers. </cmt>",k.o.y and german layout for several boards
2059,"<desc> this allows users to run commands in the initialization_commands section of their yaml that may require logging out and logging in. specifically, it makes docker installation possible from the initialization_commands section. the docs have been fixed to mention that docker will not be installed. closes #7519 addresses stackoverflow question helps #8975 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> check installed </cmt> <cmt> lint fix </cmt> <iss> [autoscaler] how to install docker within the setup yaml file? </iss>",run initialization_commands without a persistent connection
2060,"<desc> the module won't support empty list for label. need to set it to none. </desc> <cmt> for bucketing, set the learning rate to per sample. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> change default clipping to 0. </cmt> <cmt> adding peephole; fix softmax error. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix decoding for speech demo. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix some lint error. </cmt>",fix decoder for speech demo
2061,"<desc> i experimented with simplifying the eslint config to just use eslint-config-standard and eslint-config-prettier. there were too many errors to make it a quick change, but i did find a few useful rules we could adopt instead. </desc> <cmt> lint: remove useless return statements </cmt> <cmt>  </cmt> <cmt> lint: split declarations into multiple statements </cmt> <cmt>  </cmt> <cmt> lint: remove unneeded ternary operators </cmt> <cmt>  </cmt> <cmt> lint: require symbol descriptions </cmt> <cmt>  </cmt> <cmt> lint: disallow declarations in nested blocks </cmt> <cmt>  </cmt> <cmt> lint: disallow yoda conditions </cmt> <cmt>  </cmt>",add some standardjs-esque eslint rules
2062,"<desc> moved ""structuring reducers"" to be under /docs/structuring-reducers/, for url consistency. fixed up a bunch of page ids to tweak page urls. fixed a bunch of hardcoded redux.js.org urls. fixed a bunch of broken links. </desc> <cmt> move ""structuring reducers"" docs to /structuring-reducers/ </cmt> <cmt> also fixed a bunch of hardcoded http links in the immutable </cmt> <cmt> data faq page, and a bad merge in recipes/readme.md </cmt> <cmt> replace ""github"" link with an icon </cmt> <cmt> fix weird toc formatting in immutable data faq </cmt> <cmt> replace remaining redux.js.org references </cmt> <cmt> fix up docs page ids and urls </cmt> <cmt> made api urls camelcase (""bindactioncreators"") </cmt> <cmt> combined ""other"" docs pages </cmt> <cmt> fixed some casing typos </cmt> <cmt> format docs </cmt> <cmt> fix footer links </cmt> <cmt> fix glimmer-redux link </cmt>",clean up docs page structure
2063,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. overview of changes in v4:  overview of changes in v5:  webpackassetsmanifest.options type derived from:  webpackassetsmanifest.options.replacer type derived from:    webpackassetsmanifest type derived from: </desc> <cmt> [webpack-assets-manifest] fix accessing integrity in tests </cmt> <cmt> [webpack-assets-manifest] fix passing required params in tests </cmt> <cmt> [webpack-assets-manifest] add missing type info in v4.0.0 </cmt> <cmt> overview of changes in v4: </cmt> <cmt> - </cmt> <cmt> webpackassetsmanifest.options type derived from: </cmt> <cmt> - </cmt> <cmt> webpackassetsmanifest.options.replacer type derived from: </cmt> <cmt> - </cmt> <cmt> - </cmt> <cmt> - </cmt> <cmt> webpackassetsmanifest type derived from: </cmt> <cmt> - </cmt> <cmt> [webpack-assets-manifest] add type changes from v4.0.0 -> v4.0.6 </cmt> <cmt> derived from diff between v4.0.0 & v4.0.6: </cmt> <cmt> - </cmt> <cmt> webpackassetsmanifest.options type derived from: </cmt> <cmt> - </cmt> <cmt> webpackassetsmanifest type derived from: </cmt> <cmt> - </cmt>,"add missing types, fix existing types & update to latest minor versions"
2064,"<desc> this pr contains changes to enable fxcop analyzer for wox.plugin note: this pr will be merged after prs #7457 and #7464 have been merged since the fixes for fxcop errors are contained in those prs pr checklist applies to #5129 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? validation steps performed built solution and ran unit tests </desc> <cmt> pulling in changes from microsoft/powertoys </cmt> <cmt> merging in changes from microsoft/master </cmt> <cmt> enabled fxcopanalyzer for wox.plugin </cmt>",fixes for wox.plugin (3of3) - enable fxcop analyzer
2065,"<desc> fixes #15565 depends on atom/text-buffer#272 previously, whenever we changed the range of a selection, we destroyed all intersecting folds. this caused us to destroy even folds that the selection completely contained, which was a counter-intuitive behavior. this pr upgrades to a new version of text-buffer containing a new destroyfoldscontainingbufferpositions method that takes an array of positions and destroys any folds containing one of these positions (exclusive of its endpoints). i also use the new method on some other code paths that only need to destroy folds intersecting individual points rather than ranges. </desc> <cmt> don't destroy folds that are completely contained within a selection </cmt> <cmt> use destroyfoldscontainingbufferposition in more cases </cmt>",preserve folds that are fully contained by the selection when changing selection ranges
2066,"<desc> during fixing circular dependency between e2ekubelet and core framework, i need to do cleanup dumpallnamespaceinfo() in advance. this pr does the following 2 things: reduce redundant nodes().list() call reduce indents of dumpallnamespaceinfo() does this pr introduce a user-facing change?: </desc> <cmt> reduce indents of dumpallnamespaceinfo() </cmt> <cmt> during cleanup of dumpallnamespaceinfo(), the code was a little </cmt> <cmt> unreadable. this reduces the indents for the code readability. </cmt> <cmt> reduce redundant nodes().list() call </cmt> <cmt> dumpallnodeinfo() called nodes().list() internally, but the function </cmt> <cmt> is called from dumpallnamespaceinfo() only and dumpallnamespaceinfo() </cmt> <cmt> calls nodes().list() before calling dumpallnodeinfo(). </cmt> <cmt> so this makes the result of nodes().list() being passed to </cmt> <cmt> dumpallnodeinfo() then reduce a call of nodes().list(). </cmt>",cleanup dumpallnamespaceinfo() in e2e test
2067,<desc> godbolt link to the preprocessed output of using the macro:  (scroll down to the bottom of the preprocessed output to see it parrotting the noexcept specifier verbatim) fixes #2472 let me know if y'all can think of any other test cases to throw at it. </desc> <cmt> use the verbatim noexcept spec in mocked_method </cmt> <cmt> fix spacing </cmt> <iss> gmock doesn't support noexcept functions </iss>,fix mock_method to handle noexcept correctly
2068,"<desc> i have read and agreed to the rethinkdb contributor license agreement  adding circleci config to make sure the code style, integration and unit tests are running. please note that rql tests are not in scope right now since the drivers should be extracted and polyglot/rql tests should be handled somehow differently. also, at this moment unit and integration tests are failing. fixes #6840 related #6841 </desc> <cmt> fix styling issues and add ci config </cmt> <cmt> fix unintentional file changes </cmt>",add circleci config and fix styling issues
2069,"<desc> i was getting several compiler errors when trying to format a std::chrono::duration to a wide string, and found that various parts of chrono.h had a hard dependency on narrow chars. i tried to make it agnostic as possible, and it seems to work fine for me now, although i haven't tested it with anything besides std::chrono::duration<double, std::milli>. if anything needs to be changed or fixed to get this merged just let me know. i agree that my contributions are licensed under the {fmt} license, and agree to future changes to the licensing. </desc> <cmt> fix formatting chrono durations to wide strings </cmt> <cmt> make format buffers const correct </cmt>",fix formatting std::chrono::duration types to wide strings
2070,"<desc> fixes #10113 predict_proba checks self.estimators_[0], not self.estimator test for predict_proba </desc> <cmt> fix hasattr param </cmt> <cmt> correct spelling + add test </cmt> <cmt> minor format fix </cmt> <cmt> more test </cmt> <iss> sgdclassifier never has the attribute ""predict_proba"" (even with log or modified_huber loss) </iss>","fix sgdclassifier never has the attribute ""predict_proba"" (even with log or modified_huber loss)"
2071,<desc> i'm doing this so that i can publish an update to the node library that is compatible with the released c core. </desc> <cmt> replaced underscore and underscore.string modules with lodash </cmt> <cmt> updates install on node.js readme.md </cmt> <cmt> added tests for serializing and deserializing 64 bit values in proto messages </cmt> <cmt> fixed handling of long values </cmt> <cmt> bump version of node library </cmt> <cmt> update node package version to 0.9.2 </cmt>,backport node library js changes to the release branch
2072,"<desc> what is this about? i found that the error reporting window for non-dispatcher exceptions will not work and found that it was fixed on the wox repo ( pr checklist applies to #xxx cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? validation steps performed how does someone test & validate? currently the only operations that happen on a non-dispatcher thread are on a task.run call without task.wait. task.run does not rethrow the error on the main thread unless wait is used. to repro a non-dispatcher exception i added the following statements in this block of the query method: powertoys/src/modules/launcher/powerlauncher/viewmodel/mainviewmodel.cs lines 454 to 467 6a531ca private void queryresults() { if (!string.isnullorempty(querytext)) { var querytimer = new system.diagnostics.stopwatch(); querytimer.start(); _updatesource?.cancel(); var currentupdatesource = new cancellationtokensource(); _updatesource = currentupdatesource; var currentcancellationtoken = _updatesource.token; _updatetoken = currentcancellationtoken; var querytext = querytext.trim(); var pluginquerypairs = querybuilder.build(ref querytext, pluginmanager.nonglobalplugins); thread t = new thread(() => { throw new exception(); }); t.start(); </desc> <cmt> possible fix for dispatcher error </cmt> <cmt> revert changes on other files </cmt>",fix error reporting window for exceptions that are not on the dispatcher thread
2073,"<desc> if encoder layer is about to return inf, clamp to a float near the boundary of fp16 range this improves rouge for distil-pegasus-xsum-12-12 in fp16 by 0.1 rouge 2 i cannot think of how this change could make things worse. other models' metrics are unaffected! </desc> <cmt> clean clamp </cmt> <cmt> boom boom </cmt> <cmt> take some other changes </cmt> <cmt> boom boom </cmt> <cmt> boom boom </cmt> <cmt> boom boom </cmt> <cmt> one chg </cmt> <cmt> boom boom </cmt> <cmt> fix test </cmt>",enable pegasus fp16 by clamping large activations
2074,"<desc> radar rdar://problem/28680453 this is an updated version of #8909 it addresses the code review comments and splits the pr into multiple commits reduce the size of the text area (code size of the compiled output) by changing the way we generate llvm ir for loadable types: we do a sil level transformation, during irgen, that, from a bird's eye view, does the following: for every every function that takes as an input a big type, re-write it to take a pointer to a big type instead. : $@convention(method) (bigstruct) turns into $@convention(method) (@in_constant bigstruct) there are a few new sil pieces to support this: a @in_constant calling convention new retain_value_addr and release_value_addr sil instructions that take as an input an address, load the value inside it and call retain_value and release_value respectively new outlined functions that do retains and releases of large values please note: for outlined retain/release, i currently create a function per large type in irgen, re-using the retain/releases from the value-witness table is less efficient than a direct call to a smaller function we currently add new alloc_stack instructions and, in some cases, load of the function arguments to make this work. the current implementation, while it has some peephole optimizations for the most painful cases, is still very conservative: we can update this in the future, further reducing the code size in case we had call to a function that takes a $bigtype, and now takes $*bigtype, there are cases wherein we create new alloc_stack and store instructions in order to call said function. just like the point made above - the current implementation is very conservative / can be further optimized. this will be done in phases the radar mentioned in this pr contains a test program called bigtypeprog: this program contains a big struct with some loadable types + a class / need for retain and release. passes it around to different functions that access the struct. under -onone we have 3x binary size reduction, under -o a 2x binary size reduction. the text area is reduced by around 84% and 65% respectively. </desc> <cmt> @in_constant calling convention - part of passing large loadable types by address </cmt> <cmt> retain_value_addr and release_value_addr sil instructions: take as an input an address, load the value inside it and call retain_value and release_value respectively </cmt>",pass large loadable types by address instead of by value - updated version
2075,<desc> temporary disable x_tunnel fix start.vbs fix test appid change python path in some files </desc> <cmt> temporary disable x_tunnel </cmt> <cmt> fix start.vbs doesn't work </cmt> <cmt> change handshake impossible log level </cmt> <cmt> the warnning error show too much...change it to debug. </cmt> <cmt> fix test appid </cmt> <cmt> change python path </cmt>,"fix start.vbs , test-appid , disable x-tunnel and change python path in some files"
2076,"<desc> there were several llvm changes recently that broke swift's master-next branch. this pr includes fixes for most of them. there is one change that i think should go to master. with those changes, i am able build for macos and run the tests, but there are still a bunch of unexpected failures. </desc> <cmt> adjust use of preprocessor::getcurrentsubmodule to match clang r302098. </cmt> <cmt> adjust addattributes calls for llvm r301981 </cmt> <cmt> these now take an attrbuilder argument instead of an attributelist. </cmt> <cmt> adjust for llvm r302060: avoid argno+1 attribute indexing </cmt> <cmt> tidy loop iterator to match the mergefunctions.cpp change from llvm r273808 </cmt> <cmt> adapt to llvm r301812 rename of weakvh to weaktrackingvh </cmt>",various fixes to get master-next building again
2077,"<desc> serve webfonts locally style changes around blockquote and code minor adjustments from previous changes bringing back updated examples: modified tutorial and modified manual. and for rustdoc, modified enum.filetype, modified std and modified std::io. </desc> <cmt> rustdoc: fixes </cmt> <cmt> doc: slight design refresh </cmt> <cmt> doc,rustdoc: store webfonts locally </cmt> <cmt> - avoids cross-domain requests restrictions </cmt> <cmt> - better availability of content </cmt> <cmt> - no html queries needed for an offline build </cmt> <cmt> rustdoc: bring it inline </cmt>",slight fixes and style changes
2078,"<desc> it was previously quite non-deterministic; now it's only slightly non-deterministic. it referred to float80 incorrectly. rdar://problem/40150393 #16516 #16523 </desc> <cmt> [test] float80 only exists on some platforms. </cmt> <cmt> [test] non-determinism down to 0.999999 (1-in-a-million) rather than 0.999. </cmt> <cmt> with the number of tests swift does, this had a relatively high chance to fail </cmt> <cmt> regularly somewhere. </cmt> <cmt> also, rejecting the lower tail means rejecting things that are perfectly </cmt> <cmt> uniform, which i don't think should be the purpose of this test. </cmt>",two small tweaks to random test.
2079,"<desc> this adds a globally propagated configuration context to dataset, where configs can be set on the driver and workers can retrieve them via singleton pattern. this avoids redundant plumbing of configuration / resources like the block owner through developer / public apis, which may make api stability difficult to maintain. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> update </cmt>",add configuration context to dataset
2080,"<desc> enables the user to provide arbitrary argument values to shortcut actions through a new args member of keybindings. for some keybindings, like newtabwithprofile<n>, we previously needed 9 different shortcutactions, one for each value of index. if a user wanted to have a newtabwithprofile11 keybinding, that was simply impossible. now that the args are in their own separate json object, each binding can accept any number of arbitrary argument values. so instead of: { ""command"": ""newtab"", ""keys"": [""ctrl+shift+t""] }, { ""command"": ""newtabprofile0"", ""keys"": [""ctrl+shift+1""] }, { ""command"": ""newtabprofile1"", ""keys"": [""ctrl+shift+2""] }, { ""command"": ""newtabprofile2"", ""keys"": [""ctrl+shift+3""] }, { ""command"": ""newtabprofile3"", ""keys"": [""ctrl+shift+4""] }, we can now use: { ""command"": ""newtab"", ""keys"": [""ctrl+shift+t""] }, { ""command"": { ""action"": ""newtab"", ""index"": 0 }, ""keys"": [""ctrl+shift+1""] }, { ""command"": { ""action"": ""newtab"", ""index"": 1 }, ""keys"": [""ctrl+shift+2""] }, { ""command"": { ""action"": ""newtab"", ""index"": 2 }, ""keys"": [""ctrl+shift+3""] }, initially, this does seem more verbose. however, for cases where there are multiple args, or there's a large range of values for the args, this will quickly become a more powerful system of expressing keybindings. the ""legacy"" keybindings are left in in this pr. they have helper methods to generate appropriate iactionargs values. prior to releasing 1.0, i think we should remove them, if only to remove some code bloat. see the spec for more details. this is part two of the implementation, part one was #2446 closes #1142 i work here ran tests removed the legacy keybindings from the defaults.json, everything still works tried leaving the legacy keybingings in my profiles.json, everything still works. </desc> <cmt> this is a start, but there's a weird linker bug if i take the setkeybinding(shortcutaction, keychord) implementation out, which i don't totally understand </cmt> <cmt> a good old-fashioned clean will fix that right up </cmt> <cmt> all these things work </cmt> <cmt> hey this actually _functionally_ works </cmt> <cmt> mostly cleanup and completion of implementation </cmt> <cmt> hey i bet we could just make newtab the handler for newtabwithprofile </cmt> <cmt> start writing tests for keybinding args </cmt> <cmt> add tests </cmt> <cmt> revert a bad sln change, and clean out dead code </cmt> <iss> feature request: support arbitrary arguments for keybindings </iss>",add support for arbitrary args in keybindings
2081,<desc> the minified source code is merged in #728. no breaking change. the internal structure is adjusted to make the code more maintainable. notable change: support the first version of <recycle-list>. </desc> <cmt> * [jsfm] remove framework banner in weex-js-runtime </cmt> <cmt> * [jsfm] support to pass event params to native </cmt> <cmt> * [jsfm] upgrade weex-rax-framework to 0.4.13 </cmt> <cmt> * [jsfm] release 0.22.0 </cmt> <cmt> * [jsfm] stop freeze element and element.prototype </cmt> <cmt> * [jsfm] pass component type to weexelement </cmt> <cmt> * [jsfm] upgrade weex-vue-framework to 2.4.2-weex.5 </cmt> <cmt> * [jsfm] upgrade weex-rax-framework to 0.4.14 </cmt> <cmt> * [jsfm] release 0.22.3 </cmt> <cmt> * [test] modify the test case to suit the new event handler </cmt>,sync the source code of weex-js-framework@0.22.3
2082,"<desc> it reads input table and produces output table, that retain some properties of input, but contains different data. it allows to publish almost real production data for usage in benchmarks. it is designed to retain the following properties of data: - cardinalities of values (number of distinct values) for every column and for every tuple of columns; - conditional cardinalities: number of distinct values of one column under condition on value of another column; - probability distributions of absolute value of integers; sign of signed integers; exponent and sign for floats; - probability distributions of length of strings; - probability of zero values of numbers; empty strings and arrays, nulls; - data compression ratio when compressed with lz77 family or lz77 + entropy family of codecs; - continuouty of time values across table; continuouty of floating point values. - date component of datetime values; - utf-8 validity of string values; - string values continue to look somewhat natural. most of the properties above are viable for performance testing: - reading data, filtering, aggregation and sorting will work at almost the same speed as on original data due to saved cardinalities, magnitudes, compression ratios, etc. it works in deterministic fashion: you define a seed value and transform it performs totally determined by input data and by seed. some transforms are one to one and could be reversed, so you need to have large enough seed and keep it in secret. it use some cryptographical primitives to transform data, but from the cryptographical point of view, it doesn't do anything properly and you should never consider the result as secure, unless you have other reasons for it. it may retain some data you don't want to publish. it always leave numbers 0, 1, -1 as is. also it leaves dates, lengths of arrays and null flags exactly as in source data. for example, you have a column ismobile in your table with values 0 and 1. in transformed data, it will have the same value. so, the user will be able to count exact ratio of mobile traffic. another example, suppose you have some private data in your table, like user email and you don't want to publish any single email address. if your table is large enough and contain multiple different emails and there is no email that have very high frequency than all others, it will perfectly anonymize all data. but if you have small amount of different values in a column, it can possibly reproduce some of them. and you should take care and look at exact algorithm, how this tool works, and probably fine tune some of it command line parameters. usage: ./clickhouse-obfuscator [options] < in > out input must be seekable file (it will be read twice). options: --help                                produce help message -s [ --structure ] arg                structure of the initial table (list of column and type names) --input-format arg                    input format of the initial table data --output-format arg                   default output format --seed arg                            seed (arbitary string), must be random string with at least 10 bytes length --limit arg                           if specified - stop after generating that number of rows --silent arg (=0)                     don't print information messages to stderr --order arg (=5)                      order of markov model to generate strings --frequency-cutoff arg (=5)           frequency cutoff for markov model: remove all buckets with count less than specified --num-buckets-cutoff arg (=2)         cutoff for number of different possible continuations for a context: remove all histograms with less than specified number of buckets --frequency-add arg (=0)              add a constant to every count to lower probability distribution skew --frequency-desaturate arg (=0)       0..1 - move every frequency towards average to lower probability distribution skew --determinator-sliding-window-size arg (=8) size of a sliding window in a source string - its hash is used as a seed for rng in markov model example: ./clickhouse-obfuscator --seed ""$(head -c16 /dev/urandom | base64)"" --input-format tsv --output-format tsv --structure 'counterid uint32, urldomain string, url string, searchphrase string, title string' < stats.tsv </desc> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: development [#clickhouse-2] </cmt> <cmt> data obfuscator: added documentation [#clickhouse-2] </cmt> <cmt> data obfuscator: added documentation [#clickhouse-2] </cmt>",simple tool for table data obfuscation.
2083,"<desc> improved regex for multiline texts to find <br /> as well as <br/> and <br>. design descisions improved regex for multiline texts in sequence diagram renderer. resolves #702 </desc> <cmt> sync my fork </cmt> <cmt> fork sync </cmt> <cmt> sync fork </cmt> <cmt> #702 improve handling of different ""br"" tag notations for multiline texts in sequence diagrams </cmt> <iss> sequencediagram text with <br /> br tag with space fails </iss>",bug/702 br tags in sequence diagrams
2084,"<desc> the declaration emitter now uses the checker for emitting the type of optional, uninitialised parameter properties when strictnullchecks is on. this means that a parameter property like constructor(public s?: string) is emitted as public s: string | undefined, and the emitted constructor parameter is constructor(s?: string | undefined) fixes #15872 </desc> <cmt> use checker for decl emit:optional parameter props </cmt> <cmt> optional parameter properties create a property with a type that unions </cmt> <cmt> with undefined when strictnullchecks is on. this needs to be reflected </cmt> <cmt> in the generated declaration. </cmt> <cmt> add isoptionaluninitializedparameterproperty </cmt> <cmt> improves declaration emit and code readability </cmt> <cmt> test:declaration emit of optional parameter props </cmt>","use checker for declaration emit of optional, uninitialised parameter properties"
2085,"<desc> several disabled pylint rules utils files can be removed: bad-whitespace - autoformatting, unused-import and import-error not prompting error, e0202 no-member in some cases are resolved. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> updated pylint in cache.py in utils: unecessary bad-whitespace. autoformatting </cmt> <cmt> updated pylint in core.py in utils: e0202. </cmt> <cmt> updated pylint in logging_configurator.py in utils: disable=no-member. formatting </cmt> <cmt> updated pylint in machine_auth.py in utils: unused-import </cmt> <cmt> updated pylint in screenshots.py in utils: unused-import and import-error </cmt> <cmt> updated pylint in webdriver.py in utils: unused-import </cmt>",updated utils with pylint rules
2086,"<desc> move responsibility of json-encoding into the nodestore baseclass while making it overridable. this change allows bigtable/django backends to care less about caches too. as a side-effect django nodestore no longer uses pickle, but can still read pickle data. see first commit. we want to store multiple json payloads (the unprocessed payload for reprocessing, and the saved event) in the same key to benefit from compression gains. this allows us to add this feature just in the baseclass instead of every backend. the second commit does just that and wires it up to reprocessing. note: in theory all the logic in the baseclass could (should) live in eventstore (leaving nodestore to really just be a simple bytes kv store), were it not for the odd case of the django backend having to tweak its decoding behavior. </desc> <cmt> ref: refactor nodestores to perform json-decode in baseclass </cmt> <cmt> move responsibility of json-encoding into the nodestore baseclass while </cmt> <cmt> making it overridable. this change allows bigtable/django backends to </cmt> <cmt> care less about caches too. as a side-effect django nodestore no longer </cmt> <cmt> uses pickle, but can still read pickle data. </cmt> <cmt> we want to store multiple json payloads (the unprocessed payload for </cmt> <cmt> reprocessing, and the saved event) in the same key to benefit from </cmt> <cmt> compression gains. this allows us to add this feature just in the </cmt> <cmt> baseclass instead of every backend. </cmt> <cmt> note: in theory all the logic in the baseclass could (should) live in </cmt> <cmt> eventstore (leaving nodestore to really just be a simple bytes kv </cmt> <cmt> store), were it not for the odd case of the django backend having to </cmt> <cmt> tweak its decoding behavior. </cmt> <cmt> ref: store reprocessing payload within nodestore </cmt> <cmt> write some tests </cmt>","refactor nodestores to perform json-decode in baseclass, add subkeys feature"
2087,"<desc> small adjustments - fixed typos, added link, reorder some info </desc> <cmt> fix typo </cmt> <cmt> add file names to snippets </cmt> <cmt> improvements to code snippets </cmt> <cmt> line highlights, file format etc </cmt> <cmt> changed the storybook setup commands to be more in line with official storybook docs </cmt> <cmt> code snippet as side note/comment </cmt> <cmt> added storybook website link </cmt>",doc improvements to visual testing with storybook guide
2088,<desc> adding remaining typescript list demos from #14897 i have followed (at least) the pr section of the contributing guide. </desc> <cmt> [list] add nested list typescript demo </cmt> <cmt> [list] add switch list secondary typescript demo </cmt>,add nested list and switch list secondary typescript demos
2089,"<desc> physically arrange layout_all macro fix key sequence in qmk configurator  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> serneity65: correct layout_all configurator key sequence </cmt> <cmt> physically arrange layout_all macro </cmt> <cmt> moves the matrix identifiers / keycodes mapped to the rotary encoder to the top row, on either side of the encoder's click keycode. </cmt> <cmt> ( rotate left, click, rotate right ) </cmt>",layout macro rework and configurator fix
2090,"<desc> with the implementation of the more elaborate json benchmarking suite at, the third-party performance tests are superseded.  this pull-request drops the packaged copies of jsoncpp ultrajson yail and removes the performance tests from perftest.h and premake4.lua. additionally, an unused .gitignore is dropped and the generated doxygen database file is ignored in the top-level .gitignore. </desc> <cmt> .gitignore: ignore doxygen database </cmt> <cmt> drop unneeded doc/diagram/.gitignore </cmt> <cmt> drop thirdparty json implementations/performance tests </cmt> <cmt> with the implementation of the more elaborate benchmarking </cmt> <cmt> suite at </cmt> <cmt> the thirdparty performance tests are superseded. </cmt> <cmt> performance.md: reference new benchmark suite </cmt>",drop thirdparty libraries and minor cleanups
2091,"<desc> use loadbalance policy when providers less 2 fix abstractclusterinvokertest outofmemoryerror remove the following code fragment in abstractclusterinvoker.java : -        // if we only have two invokers, use round-robin instead. -        if (invokers.size() == 2 && selected != null && !selected.isempty()) { -            return selected.get(0) == invokers.get(0) ? invokers.get(1) : invokers.get(0); -        } add clear invocation operation after invoking in abstractclusterinvokertest.java : mockito.clearinvocations(invoker1, invoker2, invoker3, invoker4, invoker5); all test cases are pass. follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskiptests & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> fix #934 use loadbalance policy to choose invoke when providers less than 2 </cmt> <cmt> fix #1756, clear mock invocation after invoking </cmt>",fix #934 #1756 use loadbalance policy to choose invoke when providers less 2
2092,"<desc> updated response from nodeos to clarify meaning of ""delegated_bandwidth"" as ""self_delegated_bandwidth"" vs ""bandwidth delegated to me by others"". avoid need to construct asset() using default symbol and eliminate asset math which was the source of the exception that caused the error. </desc> <cmt> fix #3917 - exception from cleos get account pretty printing </cmt> <cmt> clarify variable name in json, #3917 </cmt>",issue3917 - fix exception thrown while cleos pretty print get account
2093,"<desc> fix: when saving a query it was ""hiding"" all existing visualizations. fix: creating new query fails if user has old schema with visualizations.description non nullable. change chart type bar to column (there is no such thing bar). add scatter plot type. improve highcharts performance (see: 8fbcd0c). bring back logging level setting. ... and some more. </desc> <cmt> set default visualization description to ''. </cmt> <cmt> return query with visualizations when saving. </cmt> <cmt> set visualization.description to nullable. </cmt> <cmt> set description of default table visualization to """". </cmt> <cmt> after duplicating a query, put user back on table tab. </cmt> <cmt> there is no bar chart type -- it's column. </cmt> <cmt> add scatter plot type. </cmt> <cmt> cc: @christophervalles </cmt> <cmt> make tooltip work for all chart types. </cmt> <cmt> fix for high charts bug with stacked areas. </cmt> <cmt> bring back logging level setting </cmt> <cmt> remove series_types from visualization. </cmt> <cmt> performance improvements for chart rendering: </cmt> <cmt> 1. don't redraw when adding or removing a single series, but redraw at the end. </cmt> <cmt> 2. use $timeout to postpone high charts rendering until dom is ready. </cmt>",fixes and improvements (most related to visualizations)
2094,"<desc> related issue = #2658 currently, opt_level has two options 0 and 1. 0 will disable cfg optimization passes. 1 will do nothing. to run tests with opt_level, simply changed opt_level=1; into opt_level = 0; what i have done to fix broken tests after disabling cfg optimization. assertstmt in opengl backend missing (avoid crash and mark todo) constant_fold from llvm doesn't behave as expected (adjust test to avoid calling llvm's constant_fold) internal function called from cc backend (disable such tests) localstore following atomic op has illed type for customint/customfloat (skip localstore is val->is() with customint/customfloat) bls needs (enforce opt_level = 1 in when .blocked_local() get called) autodiff needs cfg to determine ad variables stack size (enforce opt_level = 1 when .grad() get called) we might want discuss whether there is a better way to resolve 4. to 6. </desc> <cmt> add opt_level flag </cmt> <cmt> do whole_kernel_cse while opt_level > 0 </cmt> <cmt> do cfg_optimization while opt_level > 0 </cmt> <cmt> placeholder for assert in opengl backend </cmt> <cmt> ti_warn for opengl assert </cmt> <cmt> separate constant_fold flush to zero test from cfg_optimization </cmt> <cmt> internal function call is not for cc backend </cmt> <cmt> skip local store for atomic operations </cmt> <cmt> enforce opt_level = 1 for bls analysis and autodiff </cmt> <cmt> only skip localstore with atomicop(customint/customfloat) </cmt> <cmt> add ti_warn for skip localstore </cmt>",implement opt_level for accelerating compiling
2095,"<desc> another option here might be to add full preprocessor support to the file packager, but that would be a large change given the different use cases and current code structure. specific options is consistent with the current codebase. fixes #14486 </desc> <cmt> fix #14486 </cmt> <cmt> flake </cmt> <iss> closure: `variable require is undeclared` (regression since `2.0.23`) </iss>",add an option to avoid node.js support in the file packager
2096,<desc> this pr adds the missing amazon-kclpy package to requirements (local tests currently fail without the package). the pr also adds an exclusion marker to the package because we don't want it to be included in the localstack pip package. supersedes #180 </desc> <cmt> add missing amazon-kclpy package to requirements </cmt> <cmt> exclude amazon-kclpy when building the pip package </cmt>,add missing amazon-kclpy package to requirements (updated pr)
2097,"<desc> this is a major refactor of image-classification. changes include: moved common codes such as argument, data iterator and training into common/ moved symbol definitions into symbol/ added scripts to prepare data and download pretrained models added score.py and fine-tune.py updated readme added resnet from  all *.py in the root fold are tested manually. some todos refactor the r part instructions to enable mirror double check benchmark.py on multiple machines a test/ fold with scripts to test this example </desc> <cmt> refactor of example/image-classification </cmt> <cmt> move example/cpp/image-classification </cmt> <cmt> update readme </cmt>",a major refactor of example/image-classification
2098,"<desc> change both dns cache and dfp cluster to use global maps guarded by mutexes. previously, each of these maps would be copied on each add/remove, which led to performance issues as the maps grew. change worker dns cache callback container to use a map from hostnames to lists of callbacks. this ensures that callbacks are only invoked for the hosts that are completely ready (e.g. the dynamic forward proxy's host info has been populated). risk level: medium -- change involves cross-thread synchronization unit tests manual testing under heavy load docs changes: n/a release notes: n/a (not sure if this is a candidate for release notes) platform specific features: n/a fixes #14018 </desc> <cmt> dns cache: replace copy-on-update with lock-guarded global map </cmt> <cmt> * change both dns cache and dfp cluster to use global maps guarded by </cmt> <cmt> mutexes. previously, each of these maps would be copied on each </cmt> <cmt> add/remove, which led to performance issues as the maps grew. </cmt> <cmt> * change worker dns cache callback container to use a map from </cmt> <cmt> hostnames to lists of callbacks. this ensures that callbacks are only </cmt> <cmt> invoked for the hosts that are completely ready (e.g. the dynamic </cmt> <cmt> forward proxy's host info has been populated). </cmt> <cmt> * hold the primaryhostinfo objects by shared_ptr to reduce the time </cmt> <cmt> required for the main thread to hold the map lock. </cmt> <iss> poor dns cache performance with large number of unique domains </iss>",replace copy-on-add/remove with lock-guarded global map
2099,"<desc> adds a setting that, when enabled, directs any currently running exporters in monitoring will treat any cluster alert definition as excluded from the list of allowed cluster alert watches. this is the first step to adding a migration path away from using cluster alerts configured by the monitoring plugin and toward those managed by the stack monitoring solutions on the new alerting feature. </desc> <cmt> wip </cmt> <cmt> actually test creation and updating of watches in local monitoring. </cmt> <cmt> this will allow us to test if the exporters actually pull the watches back down when they aren't in use. </cmt> <cmt> add test cases that ensure cluster alerts are torn down when decommissioning setting is present. </cmt> <cmt> appease the precommit beast </cmt>",add setting to decommission legacy monitoring cluster alerts
2100,"<desc> this is a followup to #2266 -- that pr laid down the flushing policy framework + made task table flushable.  this pr in addition makes xray's task table flushable. testing program: submitting n noops in a loop, monitor memory usage of the redis data shard.  built and ran with both ray_use_new_gcs and ray_use_xray. import subprocess import time import redis import ray # pass this flag to avoid annoying output on program exit. info = ray.init(redirect_worker_output=true) # turn on flushing with the next two lines. pol = ray.experimental.simplegcsflushpolicy( flush_when_at_least_bytes=0, flush_period_secs=1e-4, flush_num_entries_each_time=10000) ray.experimental.set_flushing_policy(pol) primary_port = info['redis_address'].split(':')[-1] primary = redis.strictredis('127.0.0.1', primary_port) splits = primary.lrange('redisshards', 0, -1)[0].split(b':') shard_port = splits[-1].decode() print('ports: primary {} shard {}'.format(primary_port, shard_port)) measure_shard = true port = primary_port if measure_shard: port = shard_port pid = subprocess.run( stdout=subprocess.pipe).stdout[:-1].decode() logfile = 'psrecord-{}.log'.format(port) @ray.remote def noop(): return time.sleep(1) args = [ 'psrecord', pid, '--interval', '1', '--duration', '60', '--log', logfile # 'psrecord', pid, '--interval', '1', '--duration', '100000', '--log', logfile ] print(' '.join(args)) subprocess.popen(args) # assuming each noop generates ~3 writes to the gcs, we need a flush throughput # of ~2.1k/s to break even.  <- use this a sanity check. num_noops = 200000 i = 0 start = time.time() while i < num_noops: noop.remote() i += 1 print('time to execute {} no-ops: {:.2f} seconds'.format( num_noops, time.time() - start)) </desc> <cmt> monitor.py: issue flushes to data shard </cmt> <cmt> resulttableadd & objecttableadd: add credis-managed versions </cmt>",make xray object table credis-managed and hence flushable.
2101,"<desc> follow up to #1138, now including a nice test case (showing to some extent what i'd like to implement next.) i ended up deciding to do a parse_cpu_set that would take the arguments about the unit/file/line, etc. and modeled it somewhat after extract_first_word_and_warn which gets those parameters for logs... let me know if you still prefer something simpler, even if that means the logs are not as ""rich""... next step is to refactor config_parse_exec_cpu_affinity() but i didn't have time to test it a lot... so i thought i would send this batch first and then work on that one when i have more time. cheers! filipe </desc> <cmt> util: refactor cpu_set parsing into its own function </cmt> <cmt> use the new code in config_parse_cpu_affinity2. </cmt> <cmt> tested by modifying cpuaffinity=... setting in /etc/systemd/system.conf </cmt> <cmt> and reloading the daemon, then checking ^cpus_allowed in /proc/1/status </cmt> <cmt> to confirm the correct cpu mask is in place. </cmt> <cmt> util: add test for parse_cpu_set </cmt>",factor out code to parse cpu affinity
2102,<desc> refer to #1421 (comment). i think that we can just give a reference to the parameters and highlight where to find the most important ones instead of copy-pasting the part of the params' description in quick-start.rst. @guolinke is this list on cli-only params correct now? please correct me. </desc> <cmt> refined parameters section in quick start guide doc </cmt>,clarify cli-only parameters and rework parameters section in quick-start guide
2103,"<desc> this change adjusts the changes of #45276 to account for the backport to the 7.x branch in #45324. </desc> <cmt> revert ""[ml-dataframe] muting tests for backport (#45277)"" </cmt> <cmt> this reverts commit 8d28029d87ac32a4b76dfee42fada6eb0aba6428. </cmt> <cmt> uncomment assertions that should work following backport </cmt>",adjust bwc tests following backport
2104,"<desc> specializing calls is going to need a lot of specialized bytecode if we want to specialize all four of call_function, call_function_kw, call_method and call_method_kw independently. since the only real difference between between the call_function and call_method forms is shifting the start of the arguments by one or two, it makes sense to move that into a pre-call instruction. the above four opcodes are replaced by: precall_method: pairs with load_method. set the pre-call argument delta, and post-call stack shrink for a method call. call_no_kw: combines call_function and call_method call_kw: combines call_function_kw and call_method_kw this means that we can specialize calls to methods with much extra effort. specialization of calls to python methods happens almost for free (we need an additional check that the number of args is as expected). specialization of method descriptors needs a few more instructions, but no extra adaptive form is needed. 1% speedup i think that the slowdowns are calls to bound-methods. so they are next on the list. </desc> <cmt> add 3 new opcodes for calls: precall_method, call_no_kw, call_kw. </cmt> <cmt> update specialization to handle new call opcodes. </cmt> <cmt> specialize call to method descriptors. </cmt> <cmt> remove old call opcodes: call_function, call_method, call_method_kw, call_function_kw. </cmt> <cmt> make sure that we have the correct number of arguments in call_no_kw_py_simple. </cmt>",split calls into precall and call
2105,<desc> converted the guidelines/design-tokens page to theme-ui fixed the desktop alignments & layout fixed the responsive layout(except tables) fixed the responsive layout by making table horizontally scrollable local url:  production url:  screenshot(s) before(actual) after(fixed) </desc> <cmt> converted guidelines containers from styled-system to theme-ui </cmt> <cmt> copycolumn sticky styling fixed for responsive </cmt> <cmt> fixed the linting issue by converting double quotes to backtick </cmt> <cmt> guidelines design token page responsive layout fixed </cmt> <cmt> contentcolumn width changed for mobile </cmt> <cmt> used flex from theme-ui instead of styled </cmt> <cmt> used the box component from theme-ui inside layout </cmt> <cmt> updated the breakpoints </cmt> <cmt> tweaking </cmt> <cmt> updated sections with no right padding </cmt> <cmt> styling updates </cmt> <cmt> created separate component for <td> with verticalalignment of top </cmt>,layout for /guidelines/design-tokens + convert to theme-ui
2106,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> adding plotly.js-dist-min package </cmt> <cmt> adding plotly.js-dist-min package </cmt> <cmt> fixing tests in plotly.js-dist-min </cmt>",creating types for plotly.js-dist-min package
2107,<desc> description: added new display categories. updated fancapabilities to default to the fan category. updates tests to reflect new display category. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> added fan to display categories. </cmt> <cmt> added doorbell to display categories. </cmt> <cmt> added microwave to display categories. </cmt> <cmt> added security panel to display categories. </cmt> <cmt> updated fancapabilities to use fan display category. </cmt> <cmt> updated tests for fancapabilities to use fan display category. </cmt>,added alexa display categories and updated fancapabilities display category
2108,"<desc> move and rename formatter config file, so that it is easier for eclipse users to import. also switch to an opt-out list for formatting. instead of explcitly listing projects that should be formatted, instead list projects that should not be formatted. this means that any new projects will automatically be formatted and checked. </desc> <cmt> move and rename formatter config file </cmt> <cmt> switch to an opt-out list for formatting </cmt> <cmt> instead of explcitly listing projects that should be formatted, instead </cmt> <cmt> list projects that should not be formatted. this means that any new </cmt> <cmt> projects will automatically be formatted and checked. </cmt>",rename formatter config and switch to an opt-out list
2109,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> add randomuuid to v14 </cmt> <cmt> add randomuuid to latest </cmt> <cmt> add jsdoc comments </cmt>,add randomuuid function to crypto module
2110,"<desc> this stdallocator is a std::allocator, thus usable with the stl containers and/or std::basic_string. it's built on top (composition) of any allocator implementing the rapidjson allocator concept : template <typename t, typename baseallocator = crtallocator> class stdallocator : public std::allocator<t> { ... /* implicit */ stdallocator(const baseallocator& allocator) rapidjson_noexcept : allocator_type(), baseallocator_(allocator) { } ... }; so wherever a rapidjson allocator is available (i.e. almost anywhere), one can define a stl containter or string like: memorypoolallocator<> a; typedef stdallocator<ch, memorypoolallocator<> > challocator; typedef std::basic_string<ch, std::char_traits<ch>, challocator> string; string s{challocator(a)}; s = ...; this requires that the baseallocator be copyable, so this pr make it so for memorypoolallocator by sharing/refcounting the allocated chunks between copies. i don't expect non-copyable => copyable to be a compatibility issue.. crtallocator is already copyable (an empty class actually), nothing to change there. #1485 can be rebased on top of this pr (will do), and possibly #1848's genericuri could use it too to forward the user allocator to the string members. </desc> <cmt> provide rapidjson_has_cxx11 and use it for rapidjson_has_cxx11_rvalue_refs and rapidjson_has_cxx11_noexcept. </cmt> <cmt> rapidjson_noexcept_assert should assert regardless of rapidjson_has_cxx11_noexcept. </cmt>","provide stdallocator, stl compatible, for use with standard types"
2111,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! added a couple of link for spanish free course list. one for latex and on for markdown there's no links about latex and markdown before in the spanish list. are available in internet free for everyone. no accounts, or something like that needed yep, free courses to follow not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> add course about latex (es) </cmt> <cmt> added markdown tutorial (es) </cmt>",added a couple of resources for spanish lcourses list
2112,"<desc> builds on #9416 . merge that one before this in additional to performing the queries, run-sift.js also currently converts the results into connections (if connection query). but as part of #9338, we will be using loki to perform queries too. so we would need to duplicate the connection logic in both query engines. this pr pulls the connection logic out of run-sift and into build-node-connections which makes sense to me as the query engine doesn't need to know about connections. only about whether it should return one result or many (thus the firstonly flag). another benefit is that the query engine no longer needs to understand page dependencies. </desc> <cmt> add nodes namespace to support loki feature flag </cmt> <cmt> naughty console log </cmt> <cmt> switch for db nodes backend </cmt> <cmt> move connection out of run-sift </cmt> <cmt> revert snapshot for gatsby-remark-embed </cmt>",move connection out of sift
2113,"<desc> as previously discussed please ignore any changes from me on the    update prebuildstep.bat i have just added a simple commit to add some functionality . it's a minor change but for anyone that wants to just copy an address ,  i have added the keyboard command alt+ins to copy an address change this if you feel it it should be done differently. also this remains customize able through the shortcuts menu. </desc> <cmt> update prebuildstep.bat </cmt> <cmt> the files when built have an underscore . i think that this is because despite having the file target name set to x32bridge.lib in msc++2013 , it will place an underscore in the name. so i altered the  prebuild script when i realized the files weren't being copped over. </cmt> <cmt> added a shortcut for copying the address </cmt> <cmt> linking the shortcut actioncopyaddress to mcopyaddress </cmt> <cmt> added line. </cmt> <cmt> mcopyaddress->setshortcut(configshortcut(""actioncopyaddress"")); </cmt> <cmt> created additional shortcut to the copyaddress() function </cmt> <cmt> created additional shortcut to the copyaddress() function. i currently have this set as alt+ins but if people want to change they can easily do so from  the shortcut config menu. </cmt> <cmt> mcopyaddress = new qaction(""&address"", this); </cmt> <cmt> mcopyaddress->setshortcutcontext(qt::widgetshortcut); </cmt> <cmt> this->addaction(mcopyaddress); </cmt> <cmt> connect(mcopyaddress, signal(triggered()), this, slot(copyaddress())); </cmt> <cmt> changed back to match master branch </cmt> <cmt> changed back to match master branch </cmt>",added shortcut to just copy address
2114,"<desc> this commit adds rest apis for logstash and its system index, .logstash, which is used to store pipelines for central management. the module adds new endpoints that enable crud operations on the pipelines stored in the index. </desc> <cmt> add logstash module with wrapped apis </cmt> <cmt> remove wrapped apis and add dedicated logstash apis </cmt>",add logstash system index apis
2115,"<desc> this adds the newer nag fortran compiler, nagfor, to distutils. nag.py modified to include nagfor added tests for the version pattern only for linux atm, as unable to test other os </desc> <cmt> enh: added compatability for the nag fortran compiler, nagfor </cmt> <cmt> updating branch </cmt> <cmt> tst: improved tests for nag fortran compiler </cmt>","added compatibility for the nag fortran compiler, nagfor"
2116,"<desc> using the same logic as libnetdata' thead_set_name(), we should set the name of the other threads. implementing uv_thread_set_name within libnetdata for libuv threads came from issue #7531 / comment #566285792 component name libnetdata/threads/ exporting database/engine daemon/command collector/proc.plugin/proc_stat generated output: 1886  1886 17848 netdata         ./netdata -d 1886  1896 17848 dbengine        ./netdata -d 1886  1897 17848 plugin[proc]    ./netdata -d 1886  1898 17848 plugin[diskspac ./netdata -d 1886  1899 17848 plugin[cgroups] ./netdata -d 1886  1900 17848 plugin[tc]      ./netdata -d 1886  1901 17848 plugin[idlejitt ./netdata -d 1886  1902 17848 statsd          ./netdata -d 1886  1905 17848 web_server[stat ./netdata -d 1886  1906 17848 pluginsd        ./netdata -d 1886  1907 17848 health          ./netdata -d 1886  1908 17848 daemon_command  ./netdata -d 1886  1911 17848 pluginsd[slabin ./netdata -d 1886  1912 17848 pluginsd[python ./netdata -d 1886  1913 17848 pluginsd[pcm]   ./netdata -d 1886  1914 17848 web_server[stat ./netdata -d 1886  1916 17848 web_server[stat ./netdata -d 1886  1917 17848 pluginsd[apps]  ./netdata -d 1886  1919 17848 web_server[stat ./netdata -d 1886  1920 17848 web_server[stat ./netdata -d 1886  1921 17848 pluginsd[go.d]  ./netdata -d 1886  1930 17848 web_server[stat ./netdata -d 1886  1933 17848 statsd_collecto ./netdata -d 1886  2405 17848 dbengine        ./netdata -d 1886  2406 17848 dbengine        ./netdata -d 1886  2407 17848 dbengine        ./netdata -d 1886  2409 17848 dbengine        ./netdata -d </desc> <cmt> [libnetdata/threads] add uv_thread_set_name </cmt> <cmt> this is inspired from thread_set_name() but for libuv threads. </cmt> <cmt> both are based on pthread, but for uv we need to call it with the </cmt> <cmt> uv_thread_t pointer, instead of being the thread that calls the </cmt> <cmt> function for itself. </cmt> <cmt> this limit our use on apple as only the calling thread can set its name. </cmt> <cmt> some hack exists to get the os-threadid (like done internally by </cmt> <cmt> pthread_setname_np) by casting pthread_t to a struct_pthread then </cmt> <cmt> accessing tid, but getting this info for a log message is not worth </cmt> <cmt> the breakage risk. </cmt> <cmt> [exporting] set libuv threadname to ""exporting-index"" </cmt> <cmt> the same way we set netdata_thread to a meaningful name, we should set </cmt> <cmt> libuv thread too to avoid having ""netdata"" generic names. </cmt> <cmt> would have helped issues #7531 / #7541 </cmt> <cmt> [database/engine] set libuv thread name to ""dbengine"" </cmt> <cmt> the same way we set netdata_thread to a meaningful name, we should set </cmt> <cmt> libuv thread too to avoid having ""netdata"" generic names. </cmt> <cmt> i didn't find a more unique id within the function rrdeng_init. </cmt> <cmt> instance doesn't seem to give a use for the thread, and dbfiles_path </cmt> <cmt> is common to all 5 threads. </cmt> <cmt> would have helped issues #7531 </cmt> <cmt> sample output of ps -leo pid,tid,ppid,comm,args </cmt> <cmt>  </cmt> <cmt> 21241 21241 17848 netdata         ./netdata -d </cmt> <cmt> 21241 21251 17848 dbengine        ./netdata -d </cmt> <cmt> 21241 21252 17848 plugin[proc]    ./netdata -d </cmt> <cmt> 21241 21253 17848 plugin[diskspac ./netdata -d </cmt> <cmt> 21241 21254 17848 plugin[cgroups] ./netdata -d </cmt> <cmt> 21241 21255 17848 plugin[tc]      ./netdata -d </cmt> <cmt> 21241 21256 17848 plugin[idlejitt ./netdata -d </cmt> <cmt> 21241 21257 17848 statsd          ./netdata -d </cmt> <cmt> 21241 21260 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21261 17848 pluginsd        ./netdata -d </cmt> <cmt> 21241 21262 17848 health          ./netdata -d </cmt> <cmt> 21241 21263 17848 netdata         ./netdata -d </cmt> <cmt> 21241 21265 17848 pluginsd[slabin ./netdata -d </cmt> <cmt> 21241 21266 17848 pluginsd[python ./netdata -d </cmt> <cmt> 21241 21267 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21268 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21269 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21271 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21273 17848 pluginsd[pcm]   ./netdata -d </cmt> <cmt> 21241 21274 17848 pluginsd[apps]  ./netdata -d </cmt> <cmt> 21241 21278 17848 pluginsd[go.d]  ./netdata -d </cmt> <cmt> 21241 21279 17848 statsd_collecto ./netdata -d </cmt> <cmt> 21241 21280 17848 web_server[stat ./netdata -d </cmt> <cmt> 21241 21694 17848 dbengine        ./netdata -d </cmt> <cmt> 21241 21695 17848 dbengine        ./netdata -d </cmt> <cmt> 21241 21696 17848 dbengine        ./netdata -d </cmt> <cmt> 21241 21697 17848 dbengine        ./netdata -d </cmt> <cmt>  </cmt> <cmt> [daemon/command] set libuv thread name to ""daemon-command"" </cmt> <cmt> the same way we set netdata_thread to a meaningful name, we should set </cmt> <cmt> libuv thread too to avoid having ""netdata"" generic names. </cmt> <cmt> [collectors/proc] set pthread name to ""plugin[cpuidle]"" </cmt> <cmt> the same way we set netdata_thread to a meaningful name, we should set </cmt> <cmt> non-libnetdata threads too to avoid having ""netdata"" generic names. </cmt>","set standard name to non-libnetdata threads (libuv, pthread)"
2117,"<desc> as-is when i click another language option in quiz component, the quiz sentence is not changed to another language. translation json files have 'title' and 'id' fields each quiz, but not using this fields. to-be update questions data -> computed on quiz component. refactor home component using v-for references #130 </desc> <cmt> update questions data using computed </cmt> <cmt> when i click another language option in quiz component, </cmt> <cmt> the quiz sentence is not changed to another language. </cmt> <cmt> so i refactor questions 'data' to 'computed' </cmt> <cmt> refactor home component using v-for </cmt> <cmt> translation json file has 'title' and 'id' fields each quiz. </cmt> <cmt> so refactor using this fields. </cmt>",fix questions data re-rendering & refactor home component (on quiz-app)
2118,"<desc> this pr exports stylefunctionsx function from the system, that can be used by developers for adding the sx functionality on their custom components. it is used by the experimentalstyled utility as well for adding support for this prop. in addition to this, the signature was changed to simply accept props and extracts the sx and theme values from there, to be consistent with the other style functions. edit: added logic for correct breakpoints merge in the stylefunctionsx as well, as it is used standalone in the experimentalstyled() </desc> <cmt> wip </cmt> <cmt> fixes and tests </cmt>",export stylefunctionsx and improve signature
2119,<desc> fix #285 sometimes the users can accidentally pass wrong values to getters/actions/mutations options. it causes an unexpected and unpredictable error like reported on #285. this patch add assertions for them and let the users know which value is problematic in early timing. </desc> <cmt> add assertions of module assets </cmt> <cmt> disallow to register the root module by registermodule </cmt>,add assertion of module assets
2120,<desc> kill writeformattedstring and replace it with fmt::format_to to avoid expensive string operations in vtrenderer. this saves ~8% of the cpu time. inspired by #10362 (comment) </desc> <cmt> draft implementation for fast string formatting </cmt> <cmt> why not work </cmt> <cmt> ok now it works </cmt> <cmt> stack allocation only </cmt>,prefer fmt_compile for string formatting in vtrenderer
2121,"<desc> this pr contains a sequence of commits that: move valueownershipkind into silargument and provides a unified interface therein to ownership kind. updates function signature optimization to propagate functionargument's proper valueownershipkind. adds code so that all function arguments have correct ownership and verifies that the valueownershipkind is correct in the verifier. removes all places in the compiler that created phi arguments with any ownership with an initial approximation of the correct ownership. this means that creating a phi arguments with any ownership will cause an assert. now the only thing that can have any ownership is silundef (or potentially values derived from silundef). the initial approximation of correct ownership is not checked though. i am going to be going through the compiler with the verifier to make sure that they are correct, but i need some ""initial"" value to start. rdar://29791263 </desc> <cmt> [semantic-sil] move valueownershipkind -> silargument and have subclasses pass in said value. </cmt> <cmt> this in the case of insertfunctionargument requires a valueownershipkind to be </cmt> <cmt> specified since we use that for transformations of function argument lists that </cmt> <cmt> are only correct after the transformation is complete. this only occurs in </cmt> <cmt> functionsignatureoptimizations. </cmt> <cmt> on the other hand, createfunctionargument is only used to construct completely </cmt> <cmt> new argument lists, so we can instead just rely on the function we are in rather </cmt> <cmt> than require the user to pass it in. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [semantic-sil] update functionsignatureopts to propagate forward the correct valueownershipkind into functionsignatureopts. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [semantic-sil] ensure that all function arguments have the correct ownership kind and create a verifier check that this is preserved. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [semantic-sil] eliminate valueownershipkind::any from silphiarguments in semantic sil. </cmt> <cmt> most of this involved sprinkling valueownershipkind::owned in many places. in </cmt> <cmt> some of these places, i am sure i was too cavalier and i expect some of them to </cmt> <cmt> be trivial. the verifier will help me to track those down. </cmt> <cmt> on the other hand, i do expect there to be some places where we are willing to </cmt> <cmt> accept guaranteed+trivial or owned+trivial. in those cases, i am going to </cmt> <cmt> provide an aggregate valueownershipkind that will then tell silargument that it </cmt> <cmt> should disambiguate using the type. this will eliminate the ackwardness from </cmt> <cmt> such code. </cmt> <cmt> i am going to use a verifier to fix such cases. </cmt> <cmt> this commit also begins the serialization of valueownershipkind of arguments, </cmt> <cmt> but does not implement parsing of value ownership kinds. that and undef are the </cmt> <cmt> last places that we still use valueownershipkind::any. </cmt> <cmt> rdar://29791263 </cmt>",silarguments now must always have valueownershipkind
2122,"<desc> this converts rankfeaturefieldmapper, rankfeaturesfieldmapper, searchasyoutypefieldmapper and tokencountfieldmapper to parametrized forms.  it also adds a textparams utility class to core containing functions that help declare text parameters - mainly shared between searchasyoutypefieldmapper and keywordfieldmapper at the moment, but it will come in handy when we convert textfieldmapper and friends. </desc> <cmt> wip: token count tests still need converting </cmt> <cmt> complete conversion of mapper-extras </cmt>",convert all fieldmappers in mapper-extras to parametrized form
2123,"<desc> some fancy-schmancy osx audio devices support planar audio by specifying that they have a bunch of streams that are single-channels.  the higher level api handles this fine, but we don't as we're using the low-level api.  fortunately these cases are pretty simple to detect. as ae currently doesn't support planar audio to the sink, we de-interleave in the output.  once ae supports it, much of the changes in the render callback can be removed. gotham material. </desc> <cmt> [osx] support planar audio devices in the core audio sink. </cmt> <cmt> [cosmetics] indenting </cmt>",support planar audio devices in core audio osx sink
2124,"<desc> dirs_exist_ok doesn't exist in python 3.7, which is our minimum required version currently. copy_tree from distutils has the desired behaviour, and is available in 3.7 however distutils will be deprecated in py3.10 and removed in py3.12 the changes in this pr: walk the directories and apply templates file by file. changed the templates to use printf-style formatting, to be consistent with the rest of qmk changed license header to the smaller spdx header. (as suggested in #14705) added -n, --realname if people want their real name in copyright headers #16408 my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> use copy_tree from distutils for python 3.7 support </cmt> <cmt> bump python version in docs </cmt>",refactor new-keyboard to be python3.7 compatible
2125,<desc> description: don't sync entities that don't map to a known google type checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> skip entity if no device type found </cmt> <cmt> add test for potentially skipped binary sensors </cmt>,google assistant skip missing type
2126,"<desc> see #5079 . note that i was unable to repro the issue locally, so this is using the recommendation in the issue. microsoft reviewers: open in codeflow </desc> <cmt> attempt to fix publish pipeline </cmt> <cmt> change files </cmt>",attempt to fix publish pipeline in 0.62
2127,<desc> device change events could wake up engine from suspend which resulted in loss of audio @memphiz maybe related to the issue on osx too </desc> <cmt> activeae: add a misssing state transition </cmt> <cmt> activeae: ignore devicechange events in suspend state </cmt>,ignore device change events in suspend state
2128,"<desc> #4931 this shows that if the there is a dict with a key items or iteritems, less likely but it proves the point, the main content is not rendered. </desc> <cmt> iter over items in python, not template </cmt> <cmt> add failing tests </cmt>",add failing tests and fix for dict that have a key items #4931
2129,"<desc> backport of #41767 for ansible 2.6 lineinfile.py ansible version 2.6 </desc> <cmt> skip if insertbefore bof until later (#41767) </cmt> <cmt> if a line match is found in the file and no regexp is specified, insertbefore would improperly try to add a line if set to bof. </cmt> <cmt> add tests for this scenario. </cmt> <cmt> (cherry picked from commit eaae1318f83b6ef4d02ab9262ff7ab2641b51944) </cmt> <cmt> add changelog fragment </cmt>",backport #41767 for 2.6 - skip if insertbefore is using bof until later in the module
2130,"<desc> unchanged backport of #17019. </desc> <cmt> [flink-23854][datastream] expose the restored checkpoint id in managedinitializationcontext. </cmt> <cmt> [flink-23854][datastream] pass checkpoint id to sinkwriter#snapshotstate and restoredcheckpointid to sink#initcontext. </cmt> <cmt> [flink-23896][streaming] implement retrying for failed committables for sinks. </cmt> <cmt> in batch mode and add stop-with-savepoint with drain, the commitretryer will wait indefinitively in a close loop to avoid data loss. </cmt> <cmt> otherwise, it will retry every second until all commits succeed. </cmt> <cmt> [hotfix][connectors/kafka] add testlogger to kafka tests. </cmt> <cmt> [flink-23678][tests] re-enable kafkasinkitcase and optimize it. </cmt> <cmt> [flink-23854][connectors/kafka] abort transactions on close in kafkawriter. </cmt> <cmt> all transactions that have been opened since last (pre)commit are transient by definition, so cancel them asap. </cmt> <cmt> [flink-23854][connectors/kafka] transfer kafkaproducer from writer to committer. </cmt> <cmt> [flink-23896][connectors/kafka] retry committing kafkacommittables on transient failures. </cmt> <cmt> [flink-23854][connectors/kafka] add flinkkafkainternalproducer#settransactionalid. </cmt> <cmt> this will allow reuse of the producer in the next commit which will also include flinkkafkainternalproduceritcase. </cmt> <cmt> [flink-23854][connectors/kafka] reliably abort lingering transactions in kafka. </cmt> <cmt> the new approach depends on successively aborting transactions until an unused transaction is ensured. this approach covers all edge cases including failures before first checkpoint and downscaling without checkpoints. </cmt> <cmt> [flink-23854][kafka/connectors] adding pooling </cmt>",ensure lingering kafka transactions are aborted reliably. [1.14]
2131,"<desc> see:  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> this is already supposedly on 14.14, but this changed was introduced in 14.6 </desc> <cmt> add microtaskmode to createcontextoptions </cmt> <cmt> see: </cmt> <cmt> add test </cmt>",add microtaskmode to createcontextoptions (node:vm)
2132,"<desc> this pr adds several enhancements: adds a generic startswith function to ql modifies the existent eql startswith function to be case sensitive aware improves the existent eql startswith function to use a prefix query when the function is used in a case sensitive context. same improvement is used in sql's newly added starts_with function. adds case sensitivity to eql configuration through a case_sensitive parameter in the eql request, as established in #54411. the case_sensitive parameter can be specified when running queries (default is case insensitive) what this pr is not covering: case sensitivity in other string related eql functions case sensitivity aware integration testing in eql fixes #55340. relates to #54411. </desc> <cmt> * startswith is case sensitive aware </cmt> <cmt> * added case sensitivity to eql configuration </cmt> <cmt> * case_sensitive parameter can be specified when running queries (default </cmt> <cmt> is case insensitive) </cmt> <cmt> * added starts_with function to sql as well </cmt> <cmt> add case sensitive aware queryfolder tests </cmt> <iss> ql: optimize startwith to prefix queries where possible </iss>",case sensitive support in eql
2133,"<desc> revert pr #14284 because it cause massive breaking </desc> <cmt> revert ""fix #11566 allows sfc to return null"" </cmt> <cmt> this reverts commit 81730dfd225b778bfd0f0a7e1524899a372ad37c. </cmt> <cmt> revert ""add tests and fix broken test"" </cmt> <cmt> this reverts commit d79f340d574873ca4deabd545ee4b9fdab1164ec. </cmt>",revert incorrect fix to react
2134,<desc> deleting from the in-process store is never desirable: you can instead unref the object ids which will trigger immediate deletion. only deleting from plasma is safe since we have a timeout for fetching in that case. closes #7105 </desc> <cmt> good changes </cmt> <cmt> wip </cmt> <cmt> format </cmt> <cmt> fix </cmt> <cmt> fix test </cmt> <cmt> time </cmt> <iss> [ray] attempting to fetch an object that has been freed blocks forever </iss>,delete() should never remove objects from in-process memory store
2135,"<desc> this also fixes a potential issue with thread-safety (as all threads used to use that same location, previously). </desc> <cmt> avoid a static allocation in js exceptions code, which also makes it threadsafe </cmt> <cmt> fix </cmt> <cmt> wip [ci skip] </cmt> <cmt> fix </cmt>",remove a static allocation in c++ exceptions support code in js
2136,"<desc> this implements a refactoring action in the ide to collapse nested if statements. it handles collapsing only a single outer if statement with single inner if statement. each if statement may contain one or more conditionals. for example if a > 2 { if a < 10 {} } would be refactored to if a > 2, a < 10 {} to do: filter out statements where the outer if statement contains anything besides the inner if handle collapsing if let statements add tests addresses sr-5739. </desc> <cmt> add test file for nested if refactoring action </cmt> <cmt> [ide] add refactoring action to collapse nested if </cmt> <cmt> this is a work-in-progress that adds a refactoring action to </cmt> <cmt> collapse nested if statements. see sr-5739. </cmt>",sr-5739 add refactoring action to collapse nested if
2137,<desc> a layer for all functions and mouse keys a layer for arrows and media arrows on ijkl caps and control on caps lock - wonderful things to reduce my finger travel just about everywhere my code follows the code style of this project. i have read the contributing document. </desc> <cmt> change arrows keys around </cmt> <cmt> move arrows and layer tap </cmt> <cmt> mouse keys and other mods </cmt> <cmt> add readme and add media keys too </cmt>,updates to madhatter keymap - project keyboard alice pcb
2138,"<desc> bug fixes others when users use gumbel_softmax, they can use paddle.seed() in python for fixed seed. </desc> <cmt> add new op: gumbel_softmax </cmt> <cmt> add new op: gumbel_softmax </cmt> <cmt> add new op: gumbel_softmax (amend) </cmt> <cmt> add __main__ function in unit test </cmt> <cmt> fix bugs when test in windows ci </cmt> <cmt> update en docs </cmt> <cmt> delete reletive error in unit test </cmt> <cmt> delete relative error in unit test </cmt> <cmt> set hard=true in unit test </cmt> <cmt> support fix seed in python for test </cmt>",support fixed seed in python for test
2139,<desc> create a piecewise learning rate schedule with warmup class and use it for in-graph learning rate computation. this change overlaps the learning rate calculation and assignment with other function execution and reduce the gaps between steps due to slow callbacks. </desc> <cmt> add learning rate tensor. this makes training slower </cmt> <cmt> improve learningrateschedule with better efficiency </cmt>,use tensorflow ops for keras learningrateschedule
2140,"<desc> this pr is part of the range aggregation work from #34644.  decoding functions will be necessary for aggregations to operate on the numeric values of the ranges. the decode logic for ip, float, and double values is straightforward as the classes we use for encoding already provide a decoder.  longs are a custom encoding, and i hand-rolled the bit manipulation to do the decoding.  reviewer, please pay the most attention to this.  i believe my logic to be sound and my test cases are passing, but it is the part of this work i am least confidant in.  thanks. in addition to the decode logic, i did some small refactoring: the encoding logic for ip ranges was in the rangetype enum; i moved it to binaryrangeutil, where all the other encoding logic is. defined equals (and hashcode) function for range, to make life easier for writing tests. made the lengthtype#readlength method public, and made lengthtype a field of rangetype since those two concepts are fundamentally linked. also note, i expect a small conflict with #41160.  i'll fix once that merges. </desc> <cmt> double range decoder </cmt> <cmt> refactoring the decode function </cmt> <cmt> decode float ranges </cmt> <cmt> decode long ranges </cmt> <cmt> make lengthtype a property of rangetype </cmt> <cmt> wire decode logic into the rangetype enum </cmt> <cmt> ip range decoder & tests </cmt> <cmt> some test randomization </cmt> <cmt> fixed checkstyle issue </cmt>",decode functions for range field binary encoded doc values
2141,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. i'm not sure if usereducedmotion and usefocusvisible return a boolean. this is a wild guess. </desc> <cmt> added flex and minor imporovements </cmt> <cmt> typo and missed flex prop </cmt>",updated with new componet flex props. datepicker is still not added.
2142,"<desc> #760 this change is </desc> <cmt> use last codepage conveniently </cmt> <cmt> merge </cmt> <cmt> 1. fix bug: ""inc"" and ""dec"" commands have no effect. </cmt> <cmt> 2. fix bug: ""bswap"" command cannot execute when not debugging. </cmt> <cmt> 3. fix bug: app crash when displaying a variable smaller than 15. </cmt> <cmt> 4. new feature: script timeout </cmt> <cmt> 5. new feature: execute script when the debuggee initializes at the system breakpoint. </cmt> <cmt> add settings for initialzation script and helponsymbolicnameurl </cmt> <cmt> fix </cmt>",execute script automatically on attach or initialize
2143,"<desc> issue: #1020 description: updated date_input so that value can be a single date/datetime or a list of 0-2 date/datetime. dateinput updated to accept an array of dates. if a single value is passed, it is converted into a list. if a list is provided, the range attribute will be set to true. update slider so that value can be an empty list. if an empty list is provided, set the default to max/min values. by submiting this pull request you agree that all contributions to this project are made under the apache 2.0 license. </desc> <cmt> enable range on date_input taking an optional iterable </cmt> <cmt> update e2e date_input tests </cmt> <cmt> update dateinput so that one value does not result in a range, update slider to accept [] </cmt>",update date_input to accept a range for a ranged datepicker
2144,"<desc> pipe runtime_env in through ray client converter methods don't convert runtime_env to a parsedruntimenv inf .options() if runtime_env is none.  the reason is that we need to know later on in .remote() if runtime_env is none or not, to know whether or not to fall back to the runtime_env specified in the @ray.remote() decorator.  we need to maintain the distinction between none and an empty runtime_env (runtime_env = {}.) closes #19002 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> pipe runtime env through client_convert </cmt> <cmt> preserve none in .options(runtime_env=none) </cmt> <cmt> lint </cmt> <cmt> lint </cmt> <iss> [runtime env] [bug] runtime env specified in @ray.remote not respected when using ray client </iss>",allow specifying runtime env in @ray.remote decorator with ray client
2145,"<desc> hope you don't think i'm spamming pr, it's just when i fix transitive dependency error another one turns up maybe this need to be peerdependency?? </desc> <cmt> chore: update dependencies </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> chore: update dependencies </cmt>",add transitive dependency for pnp
2146,"<desc> add ""-dmaven.test.failure.ignore=true"" . this option will not ignore all tests but will ignore the failures when running tests. </desc> <cmt> add mvn options to ignore test failures </cmt> <cmt> add ""-dmaven.test.failure.ignore=true"" . </cmt> <cmt> this option will not ignore all tests but ignore the failures when run tests. </cmt> <cmt> add mvn options to ignore test failures </cmt>",add mvn option to ignore test failures
2147,<desc> fixes #80072 </desc> <cmt> complete language variants filled in for lang var </cmt> <cmt> part of #80072 </cmt> <cmt> improve some comments </cmt> <cmt> part of #80072 </cmt> <cmt> change setlocalevariables to detectlocale </cmt> <cmt> the setting is now an enum instead of boolean and defaults to auto </cmt> <cmt> which should provide better detection and not set in cases where it </cmt> <cmt> shouldn't. </cmt> <cmt> fixes #80072 </cmt> <iss> utf-8 '' cannot be written in the vscode terminal </iss>,improve when $lang is set and expand the number of languages supported
2148,"<desc> preview  jul-22-2564.11-34-54.mp4 jul-22-2564.11-35-01.mp4 this pr includes header (mobile and desktop) link works but not correct url yet hero section responsive the ui demo on the right in not included to make pr easier to review which will be added later because they are static. design tokens added some details is difference from webflow. headline is dynamic to the viewport (i like it than using media query) hero is align center in mobile and tablet viewport (i tried with align-left, it looks weird to me). i have followed (at least) the pr section of the contributing guide. </desc> <cmt> wip </cmt> <cmt> add home and navigation </cmt> <cmt> add hero </cmt> <cmt> fix hero responsive </cmt> <cmt> add headernavdropdown </cmt>",add hero section to homepage
2149,"<desc> hi kelsey - here's the pr to the guide - once this meets your approval and gets integrated in, i'll have another pr for you on kelseyhightower/kubernetes-coreos to point to this source. </desc> <cmt> update cloud_config with instructions on required changes and add network.md, correct links in quick_start </cmt> <cmt> clean up formatting </cmt> <cmt> attempting in document relative link </cmt> <cmt> adding one more hint for fusion users </cmt> <cmt> update coreos_cloud_config.md </cmt> <cmt> correcting relative link </cmt>",should specify required cloud-config changes #1770
2150,<desc> fix for issue #88 </desc> <cmt> set restriction on selected actions </cmt> <cmt> used self.action_space instead of custom set </cmt> <cmt> move action validation to core.py </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merging latest update </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> fix for cartpole observations outside of observation_space </cmt>,cartpole observations can occur outside of observation space limits - issue #88
2151,"<desc> this pull request improves hiveconf creation. see  introduce hiveconfutils to create hiveconf instance, avoid reset hive configuration to default value. this change is already covered by existing tests, such as (hivetablesourceitcase). dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (no) the serializers: (no) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature?  no </desc> <cmt> merge base master </cmt> <cmt> [flink-20913][hive]improve create hiveconf instance </cmt>",[flink-20913][hive]improve hiveconf creation
2152,"<desc> this pr contains two additional groups of new apis for managedvalue that allow for ownership invariants to be enforced via asserts. managedvalue transform(silvalue) &&; the first patch contains a new method called transform. the key thing to notice is that it can only be called on rvalue references, yet it returns a new managedvalue. the reason for this is that transform is meant to ""forward"" a cleanup/transform and then destroy the original managedvalue. this transformation happens in a bunch of places in silgen. in most of these cases, the original cleanup is passed forward. i believe that in a semanticarc world this will no longer be correct since in most cases where one is performing forwarding, one wants the destroy_value to occur on the newly forwarded value. in a future patch i may put the code into transform that enables the old cleanup to be destroyed and the new cleanup to be placed on the ""transformed"" managedvalue. specific static constructor with asserts the next patch adds new static constructors that create managedvalues with specific semantics. there are asserts in each one of these to ensure that the relevant semantics are being followed. an example of this is the class method, managedvalue::getownedobjectrvalue(silvalue v, cleanuphandle handle) this first verifies that the given silvalue exists, that that v.getownershipkind() is owned, before finally creating the managedvalue. rdar://29791263 </desc> <cmt> [semantic-sil] objc metatypes as metatypes are trivial. only once converted to objects do they have @owned ownership. </cmt> <cmt> this commit cleans up a few places in bridging code, where we were treating </cmt> <cmt> metatypes as if they had non-invalid cleanups. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [semantic-sil] add a new api managedvalue::transform() for transforming/forwarding a cleanup for a managedvalue. </cmt> <cmt> in silgen, we often times want to transform a managedvalue, while maintaining </cmt> <cmt> the underlying cleanup. the managedvalue::transform api attempts to formalize </cmt> <cmt> this pattern through the usage of std::move to create a movable rvalue, but </cmt> <cmt> returning a different managedvalue as a full value. this ensure that the </cmt> <cmt> original managedvalue is destroyed at end of statement, will allowing the </cmt> <cmt> underlying cleanup to be forwarded. </cmt> <cmt> from an ownership perspective, i think the majority of these cases should </cmt> <cmt> actually recreate the underlying cleanup since in most cases they involve </cmt> <cmt> forwarding. for today though i am using this to just formalize this pattern at </cmt> <cmt> the relevant call sites. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [semantic-sil] introduce new specific static constructors for managedvalue. </cmt> <cmt> this is the first step towards eliminating: </cmt> <cmt> * managedvalue::forunmanaged(silvalue) </cmt> <cmt> * managedvalue::managedvalue(silvalue, cleanuphandle). </cmt> <cmt> the reason why these two methods must be eliminated is that: </cmt> <cmt> 1. currently non-trivial values are ""borrowed"" using </cmt> <cmt> managedvalue::forunmanaged. with semantic sil, we are now able to represent </cmt> <cmt> borrows via begin_borrow and end_borrow. this will make the semantics that </cmt> <cmt> silgen is trying to describe more accurate. </cmt> <cmt> 2. managedvalue::managedvalue can be used to add arbitrary cleanups. we want </cmt> <cmt> methods that add cleanups, but that at the same time allow the caller to specify </cmt> <cmt> what it expects the ownership of the given silvalue to be. this would then cause </cmt> <cmt> an assertion to trip giving greater clarity. </cmt> <cmt> rdar://29791263 </cmt>",some more additional managedvalue apis
2153,"<desc> related issue: #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> [mypy] added/fixed type annotations for ""rotate_matrix.py"" </cmt> <cmt> [mypy] added/fixed type annotations for ""test_matrix_operation.py"" </cmt>","added/fixed type annotations for ""rotate_matrix.py"" & ""test_matrix_operation.py"""
2154,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes </desc> <cmt> fixedoffsetzone.utcinstance returns fixedoffsetzone </cmt> <cmt> update luxon-tests.ts </cmt>,"fixedoffsetzone.utcinstance returns fixedoffsetzone, not string"
2155,"<desc> split into multiple commits based on base directory, to make review more easier. let me know if you'd prefer to have the commits squashed together. </desc> <cmt> man: fix typos </cmt> <cmt> s/alternativly/alternatively/ </cmt> <cmt> s/explicity/explicitly/ </cmt> <cmt> s/occurences/occurrences/ </cmt> <cmt> s/sokets/sockets/ </cmt> <cmt> s/successfull/successful/ </cmt> <cmt> s/timetamps/timestamps/ </cmt> <cmt> docs: fix typo </cmt> <cmt> s/recommanded/recommended/ </cmt> <cmt> tools: fix typos </cmt> <cmt> s/are'nt/aren't/ </cmt> <cmt> s/availible/available/ </cmt> <cmt> s/behavoir/behavior/ </cmt> <cmt> s/colums/columns/ </cmt> <cmt> s/conections/connections/ </cmt> <cmt> s/dont/don't/ </cmt> <cmt> s/efficency/efficiency/ </cmt> <cmt> s/erorrs/errors/ </cmt> <cmt> s/explicity/explicitly/ </cmt> <cmt> s/indentify/identify/ </cmt> <cmt> s/occurences/occurrences/ </cmt> <cmt> s/ouptut/output/ </cmt> <cmt> s/ouput/output/ </cmt> <cmt> s/overriden/overridden/ </cmt> <cmt> s/reseting/resetting/ </cmt> <cmt> s/reseting/resetting/ </cmt> <cmt> s/smaple/sample/ </cmt> <cmt> s/successfull/successful/ </cmt> <cmt> s/successfuly/successfully/ </cmt> <cmt> s/theres/there's/ </cmt> <cmt> s/wilcard/wildcard/ </cmt> <cmt> tests: fix typos </cmt> <cmt> s/arugment/argument/ </cmt> <cmt> s/availiable/available/ </cmt> <cmt> s/compatbility/compatibility/ </cmt> <cmt> s/overriden/overridden/ </cmt> <cmt> src: fix typos </cmt> <cmt> s/accross/across/ </cmt> <cmt> s/attemp /attempt / </cmt> <cmt> s/availiable/available/ </cmt> <cmt> s/destrcuted/destructed/ </cmt> <cmt> s/emtpy/empty/ </cmt> <cmt> s/initalized/initialized/ </cmt> <cmt> s/interpeter/interpreter/ </cmt> <cmt> s/wheather/whether/ </cmt> <cmt> examples: fix typos </cmt> <cmt> s/availiable/available/ </cmt> <cmt> s/mantains/maintains/ </cmt> <cmt> s/splitted/split/ </cmt> <cmt> s/succesive/successive/ </cmt>",fix a bunch of typos
2156,"<desc> previously thiscontainer (previously called containercontainer) would update on every block, not just those that could bind this. in addition, if the constructor symbol still can't be found, then no binding happens. this is usually ok because people don't add new properties in methods too often. fixes #22774 </desc> <cmt> track thiscontainer for this-property-assignments in js </cmt> <cmt> previously it would update on every block, not just those that could </cmt> <cmt> bind this. </cmt> <cmt> in addition, if the constructor symbol still can't be found, then no </cmt> <cmt> binding happens. this is usually ok because people don't add new </cmt> <cmt> properties in methods too often. </cmt> <cmt> update additional baselines </cmt>",correctly track thiscontainer for this-property-assignments in js nested containers
2157,<desc> this pr adds a link to slack in the issue alert emails and digests if the org does not have any alert integrations (or plugins) installed for that org/project. this is a follow up to #26030 which got reverted because styling got messed up in emails as email doesn't support certain flexbox features and svgs. here are changes i made on top of the original pr: use display: inline-grid instead of display: flex for the div button wrapper use an png logo instead of svg (not supported in many email clients) other minor css tweaks </desc> <cmt> update styles for email </cmt> <cmt> fix margin </cmt>,email alert link to slack v2
2158,"<desc> previously, we skipped setting the buttonvalue if the fieldvalue is not available, due to an early return. obviously the button still has a value even if the field doesn't, so i'm not sure how i missed that before, but this patch fixes it and adds a unit test for it (that fails when this patch is not applied and passes if it is applied). supersedes #8031. </desc> <cmt> interactive forms: values for radio buttons (issue #6995) </cmt> <cmt> interactive forms: unit test for radio buttons without a field value </cmt>",set the buttonvalue for radio buttons that do not have a fieldvalue
2159,"<desc> currently, gptj does not run common tests because its testes class does not subclass modeltestermixin, generationtestermixin.  this pr enables common tests for gptj and fixes a few things along the way. i've run the slow tests manually and verified that they pass. thanks a lot, @sgugger  for spotting this!  fixes #14107 </desc> <cmt> enable common tests, small fixes </cmt> <cmt> don't tie word embeds </cmt> <cmt> don't ignore lm_head </cmt> <iss> gpt-j models cannot load if tokens have been resized using resize_token_embeddings method </iss>",enable common tests and few fixes
2160,<desc> // </desc> <cmt> quickpick - move themable to platform </cmt> <cmt> quickpick - first cut platform quick input service </cmt> <cmt> quickpick - extract legacy pieces into legacyquickinputquickopencontroller </cmt> <cmt> quickpick - use layout service from platform </cmt> <cmt> quick pick - push down picker foreground/background colors </cmt> <cmt> quick pick - introduce quickinputtitle.background color </cmt> <cmt> quickpick - remove dependency to editor group service </cmt> <cmt> quick pick - add quick pick service to platform and register for standalone editor </cmt>,make quick input service available in platform
2161,"<desc> this patch addresses #1660, which was caused by keying all pre-trained vectors with the same id when telling thinc how to refer to them. this meant that if multiple models were loaded that had pre-trained vectors, errors or incorrect behaviour resulted. the vectors class now includes a .name attribute, which defaults to: {nlp.meta['lang']_nlp.meta['name']}.vectors the vectors name is set in the cfg of the pipeline components under the key pretrained_vectors. this replaces the previous cfg key pretrained_dims. in order to make existing models compatible with this change, we check for the pretrained_dims key when loading models in from_disk and from_bytes, and add the cfg key pretrained_vectors if we find it. i have submitted the spacy contributor agreement. </desc> <cmt> fix loading of multiple pre-trained vectors </cmt> <cmt> this patch addresses #1660, which was caused by keying all pre-trained </cmt> <cmt> vectors with the same id when telling thinc how to refer to them. this </cmt> <cmt> meant that if multiple models were loaded that had pre-trained vectors, </cmt> <cmt> errors or incorrect behaviour resulted. </cmt> <cmt> the vectors class now includes a .name attribute, which defaults to: </cmt> <cmt> {nlp.meta['lang']_nlp.meta['name']}.vectors </cmt> <cmt> the vectors name is set in the cfg of the pipeline components under the </cmt> <cmt> key pretrained_vectors. this replaces the previous cfg key </cmt> <cmt> pretrained_dims. </cmt> <cmt> in order to make existing models compatible with this change, we check </cmt> <cmt> for the pretrained_dims key when loading models in from_disk and </cmt> <cmt> from_bytes, and add the cfg key pretrained_vectors if we find it. </cmt> <cmt> set pretrained_vectors in begin_training </cmt> <cmt> add message noting vectors </cmt> <cmt> set pretrained_vectors in parser cfg </cmt> <cmt> remove print statement </cmt>",fix loading of multiple vector models
2162,"<desc> this pr changes the constraints of the predefined parameters<t>, constructorparameters<t>, returntype<t> and instancetype<t> from t extends (...args: any[]) => any to the less restrictive t extends (...args: any) => any with this change, the types can be applied to functions that themselves have generic rest parameters. for example: type foo<t extends any[]> = returntype<(...args: t) => string>;  // string previously, this was an error. fixes #26856. </desc> <cmt> less restrictive constraints in parameters and returntype types </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",less restrictive parameters<t> and returntype<t>
2163,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <<paper.js/base.js>> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [paper] add base class </cmt> <cmt> [paper] type save getters and setters </cmt> <cmt> [paper] import/export test </cmt> <cmt> [paper] fix: ""common mistakes"" </cmt>",include base class definition + type save getters and setters
2164,<desc> add resources i added a couple courses from metarhia organization of javascript. the author is timur shemsedinov and the courses are free but they are really cool courses for getting deeper knowledge of js we can open metarhia organization github </desc> <cmt> add courses from metarhia organization </cmt> <cmt> alphabetic order </cmt>,add some corses from metarhia organization
2165,"<desc> warning, some breaking type changes here. currently, there is virtually no property checking when creating a chart with a given set of data. here an example using master: we can see that: the data array type is inferred to the default unknown, and there is an incoherence with the options type the options type is inferred to the type of what the user has put inside so the user can put any invalid or not existing property, nothing will check that the given properties are accepted by the library with this branch: chart type is inferred to the actual type property the data array type is inferred to the actual type of what we have put inside data strong typing of the properties according to the chart type: if we have type: 'line', then only line chart properties are allowed (doesnotexist is not highlighted in red above because my ide shows only one error at a time for each call, but there also is a compile error for that) as we have discussed for enums, plugins developpers and users can extend the registry interfaces to add custom chart types and options, while preserving the strong typing. </desc> <cmt> sync </cmt> <cmt> sync with upstream </cmt>",strong chart object and properties typing
2166,"<desc> this allows for removing keys without specifying the options in the authorized_keys file. also a fix of the writekeys function, which wrote the options space separated, which isn't allowed according to the sshd man page. instead they are comma separated with this patch. copy of #4512 without the merge </desc> <cmt> don't mind the options of a key when removing it </cmt> <cmt> this allows to remove a key without knowing the options in the </cmt> <cmt> authorized_key file </cmt> <cmt> set the options of an authorized key comma separated </cmt> <cmt> according to the sshd man page, no spaces are permitted between the </cmt> <cmt> options of an authorized ssh key </cmt>",remove keys regardless of the options
2167,"<desc> build cython files with scons instead of python setup scripts </desc> <cmt> complie boardd without python </cmt> <cmt> not good, but don't want to lose the file, because it works </cmt> <iss> replace cython setup files with scons builder </iss>",scons builder for cython extensions
2168,"<desc> should help with some benchmarks where we want to: oversaturate start a huge number of channels from multiple client machines what ends up happening is that we slam the server from the first client, and the second client never gets a chance to get connected. </desc> <cmt> add an initial mark that clients could use to delay startup of requests </cmt> <cmt> dont start requests until all clients have gotten connected </cmt>",wait to start c++ clients until all connections are made
2169,<desc> i was going through some scripts and saw the usage of short options for udev that was not documented in --help text. fix this and complement additional components when i was on. </desc> <cmt> udevd: list all short options in help text </cmt> <cmt> udevadm-info: list all short options in help text </cmt> <cmt> udevadm-control: list all short options in help text </cmt> <cmt> stio-bridge: list all short options in help text </cmt> <cmt> journal-upload: remove duplication of --help and --version in help text </cmt> <cmt> busctl: list all short options in help text </cmt>,fix help textes for components
2170,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). setmindate setmaxdate setdate increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> pickaday: correct naming of boolean method parameter on setdate </cmt> <cmt> pickaday: add explicit null types to match usage for clearing min/max dates </cmt>","add null type to setmindate and setmaxdate parameter, fix setdate parameter name"
2171,"<desc> on a mac with a case sensitive file system (most people won't have this as it's not the default) then the opencl headers fail to be included by: #include <opencl/opencl.h> however, this works: #include <opencl/opencl.h> please note this fixed the issue for me and i am now able to compile opencv on my mac. i don't have any other macs to test on, and obviously someone will need to check that this doesn't break case insensitive filesystems. </desc> <cmt> update util.hpp to fix opencl import on case sensitive mac fs </cmt> <cmt> on a mac with a case sensitive filesystem <opencl/opencl.h> does not exist but <opencl/opencl.h> does. i presume (!), but have no way to test, that on a mac with case insensitive fs this change will make no difference. </cmt> <cmt> update safe_call.hpp to fix opencl import on case sensitive mac fs </cmt> <cmt> on a mac with a case sensitive filesystem <opencl/opencl.h> does not exist but <opencl/opencl.h> does. i presume (!), but have no way to test, that on a mac with case insensitive fs this change will make no difference. </cmt>",fix for opencl headers on case sensitive filesystem.
2172,"<desc> see also #16348 in  #16348 tests for network datasets were enabled in the travis cron job. this pr enables an additional test on california_housing, which requires pandas not to be installed. this is achieved by introducing a mock fixture that hides available pandas. </desc> <cmt> download and test rcv1 in cron job </cmt> <cmt> download and test 20news in cron job [scipy-dev] </cmt> <cmt> fix typo [scipy-dev] </cmt> <cmt> california_housing, covtype, kddcup99, olivetti_faces [scipy-dev] </cmt> <cmt> fix kddcup99 [scipy-dev] </cmt> <cmt> fetch datasets in wrapper func [scipy-dev] </cmt> <cmt> fix rcv1 test [scipy-dev] </cmt> <cmt> do not skip test_pandas_dependency_message [scipy-dev] </cmt> <cmt> introduce fetch fixtures [scipy-dev] </cmt> <cmt> remove pandas hiding fixture [scipy-dev] </cmt> <cmt> fix flake8 issue [scipy-dev] </cmt> <cmt> tst enable test in travis cron job </cmt>",enable california_housing pandas test in cron job
2173,"<desc> i opened #13637 yesterday, and then i noticed some more link references that needed to be updated. i added some contributing documentation for how to fix links when moving things around, too, including redirects and find + replace instructions! hopefully this is the last of them. </desc> <cmt> fix links to new plugin docs </cmt> <cmt> clean up urls so they work locally </cmt> <cmt> add contributing information for docs renaming </cmt>",fix more plugin documentation links
2174,"<desc> passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> fix profiler examples </cmt> <cmt> fix cpp-package example </cmt> <cmt> more readme </cmt>",fix examples of profiler and cpp-package
2175,"<desc> a couple fixes to to how ip is invoked.  first, use full path for ip.  if this isn't used and the user doesn't have ip in his/her path, this will trigger a traceback.  this tries to find ip in either /sbin or /usr/sbin.  the second fix is to be explicit about showing current configured addresses. </desc> <cmt> tweak invocation of ip in linuxnetwork </cmt> <cmt> specify full path to ip and add third argument 'show' to be explicit </cmt> <cmt> about requested action.  this goes from 'ip addr' to </cmt> <cmt> '/sbin/ip addr show'. </cmt> <cmt> try to find ip command in either /sbin or /usr/sbin </cmt> <cmt> if ip is not found in either /sbin or /usr/sbin, this will return </cmt> <cmt> an empty result.  it seems extremely unlikely that a linux system will </cmt> <cmt> not have iproute2 installed </cmt>",a couple fixes for setup module
2176,"<desc> the class seems not to exclude non_trainable_weight (moving_variances and moving_mean in batchnormalization) correctly, see the script and its logs below for more details: # tf 1.8, cpu import tensorflow as tf import numpy as np x = np.ones((32, 10, 10, 3)) y = np.ones((32,)) y = tf.keras.utils.to_categorical(y) model = tf.keras.models.sequential() model.add(tf.keras.layers.batchnormalization(input_shape=(10, 10, 3))) model.add(tf.keras.layers.flatten()) model.add(tf.keras.layers.dense(2, activation='softmax')) model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy']) model.summary() cbks = [tf.keras.callbacks.tensorboard(histogram_freq=1, batch_size=2, write_grads=true)] model.fit( x, y, batch_size=4, validation_data=(x, y), callbacks=cbks, epochs=2, verbose=0) traceback (most recent call last): file ""test.py"", line 24, in <module> verbose=0) file ""/users/facai/library/anaconda3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 1232, in fit validation_steps=validation_steps) file ""/users/facai/library/anaconda3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py"", line 156, in fit_loop callbacks.set_model(callback_model) file ""/users/facai/library/anaconda3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/callbacks.py"", line 70, in set_model callback.set_model(model) file ""/users/facai/library/anaconda3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/callbacks.py"", line 716, in set_model grads = model.optimizer.get_gradients(model.total_loss, weight) file ""/users/facai/library/anaconda3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/optimizers.py"", line 115, in get_gradients raise valueerror('an operation has none for gradient. ' valueerror: an operation has none for gradient. please make sure that all of your ops have a gradient defined (i.e. are differentiable). common ops without gradient: k.argmax, k.round, k.eval. </desc> <cmt> tst: write_grads for non_trainable_weights </cmt> <cmt> bug: bypass non_trainable_weights for write_grad </cmt>",keras.callbacks.tensorboard raises an exception for non_trainale_weights
2177,"<desc> this pr enables it easily extend httphandler to provide a custom connection, for example to use a proxy, without having to reimplement emit. </desc> <cmt> make it easy to extend httphandler with custom connection. solves issue 39826 </cmt> <cmt> make it easy to extend httphandler with custom connection. solves issue 39826 </cmt>",add getconnection() hook to logging httphandler
2178,"<desc> add commands for moving, selecting, and deleting camelcase words. fixes #1982 and an alternative to #3961. also, hopefully can used with atom/vim-mode#377. replaces #4429. </desc> <cmt> add subword navigation </cmt> <cmt> - add commands for moving, selecting, and deleting camelcase words </cmt> <cmt> add keymaps </cmt> <iss> support subword navigation </iss>",add subword cursors - take 4
2179,"<desc> this is an automated, bulk addition of frontmatter to all our documentation (.md) files. i used a script to create the title field via the # blah blah heading, and the custom_edit_url field via the pathname. by adding basic frontmatter to all our documentation, we support two efforts: improve seo by explicitly declaring page titles enable the new docusaurus-powered documentation site with better page titles and edit this page on github links that work properly i had wanted to do this in a more nuanced fashion, but we need to move quickly so that this isn't a blocker for both the above efforts. the marketing team has already discussed how we'll improve this existing frontmatter with good descriptions and keywords. the frontmatter is commented out so that it doesn't appear when viewing the file in github itself. the documentation build process strips these comments out before generating the html. one implication of this effort is that the docs team will need to enforce similar frontmatter on every new document. component name docs * description of testing that the developer performed i have tested this pr by generating the mkdocs site locally, and it works fine. i also tested with our in-progress docusaurus-powered documentation site, and everything appears to work normally. finally, i'll test the netlify deploy preview when it's live. i will also ask ian to check this pr against his ingest/sanitize script so we are aware if it creates any issues before this is merged. </desc> <cmt> bulk add frontmatter </cmt> <cmt> a few extra edge cases </cmt>",bulk add frontmatter to all documentation
2180,"<desc> category bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation charts with the metadata value uselegacyapi set to false will now query the new api endpoint. this is demonstrated with the word cloud plugin, which has been upgraded to the non-legacy version. test plan i've added a test for the api query, and verified both the new word cloud and a few of the legacy chart types in explore. still verifying that charts work correctly in dashboards. you're encouraged to try out the branch. requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> calling new chart api (mostly working) </cmt> <cmt> can't .then when the promise has already been await-ed </cmt> <cmt> add handling for v1 api response </cmt> <cmt> comment </cmt> <cmt> update word cloud plugin & dependencies </cmt> <cmt> testing </cmt>",query the new chart data api for charts that support it
2181,"<desc> when the dependency on a has_many association is not set it defaults to :nullify which runs an sql update query. when the association is loaded vs not loaded the sql being produced is different. not loaded: category.categorizations.delete_all update ""categorizations"" set ""category_id"" = null where ""categorizations"".""category_id"" = 1 should produce the same sql as category.categorizations    # irb automatically calls inspect on category.categorizations category.categorizations.delete_all but instead produces this update with an in statement: update ""categorizations"" set ""category_id"" = null where ""categorizations"".""category_id"" = 1 and ""categorizations"".""id"" in (1, 2) this pull request makes both examples produce the simpler sql from the first example: update ""categorizations"" set ""category_id"" = null where ""categorizations"".""category_id"" = 1 this pull request also updates some of the tests involving this change. the two tests call clear which is the same as delete_all and then returns self. clear does not fire callbacks because it is calling delete_all, therefore we shouldn't be testing that callbacks are fired. callbacks were removed on delete_all with any dependency in #10604. previously :destroy and :nullify fired callbacks, but no longer do. cc/ @tenderlove </desc> <cmt> flip conditional in delete_all to handle nullify better </cmt> <cmt> nullify (or nil dependency) was doing the same thing delete_all </cmt> <cmt> was doing in issue #14546, creating a large in statement if </cmt> <cmt> the association was loaded. loaded and not loaded associations </cmt> <cmt> should behave the same. the in statement is also not great because </cmt> <cmt> it's inefficient. </cmt> <cmt> rewrite test to correctly test clear method </cmt> <cmt> clear should not call callbacks because it clear calls </cmt> <cmt> delete_all and then returns self. it should behave the same </cmt> <cmt> as delete_all. this test clarifies the goal of the test and </cmt> <cmt> tests the correct outcome. </cmt> <cmt> clear shouldnt fire callbacks so remove order test </cmt> <cmt> since clear shouldn't fire callbacks the order doesn't </cmt> <cmt> matter since it was never updated. remove the portion </cmt> <cmt> of this test that tests for order after clear. </cmt> <cmt> add test to check that loaded and non laoded are the same </cmt> <cmt> test checks that sql is the same for a loaded vs not loaded </cmt> <cmt> association (category.categorizations, category.categorization.delete_all </cmt> <cmt> vs category.cartegroization.delete_al). this was fixed for delete_all </cmt> <cmt> dependency but was not fixed for no (:nullify, or nil) dependency). </cmt>",fix delete all with nil (:nullify) dependency to not produce in statement
2182,<desc> updates the openssl static library to be linked into the react windows desktop dll. see introduced  changes: jurocha-ms/openssl@6539cd3...jurocha-ms:bd711e537cc6afab0c295ad81d9728ec7ee6c51d microsoft reviewers: open in codeflow </desc> <cmt> upgrade openssl nuget to 1.1.1-d.3 </cmt> <cmt> change files </cmt>,upgrade openssl nuget to 1.1.1 d.3
2183,<desc> this change converts the module and plugin parameters for testclusters to be lazy. meaning that the values are not resolved until they are actually used. this removes the requirement to use project.afterevaluate to be able to resolve the bundle artifact. note - this does not completely remove the need for afterevaluate since it is still needed for the custom resource extension. </desc> <cmt> initial commit </cmt> <cmt> clean up </cmt>,lazy test cluster module and plugins
2184,"<desc> the inventory produced by the infoblox inventory script is incomplete. indeed, we should have the list of complete extensible attributes for each record, a minor bug overwrites the extensible attributes dictionary, the result is in the extensible attributes dictionary with only one entry. contrib/inventory/infoblox.py ansible version ansible 2.5.0 (devel_infoblox_exattrs 01091cddf6) last updated 2018/01/26 21:41:03 (gmt +200) config file = /home/clement/documents/projects/ansible_env_setup/ansible/ansible.cfg configured module search path = ['/home/clement/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /home/clement/documents/projects/ansible_env_setup/ansible/lib/ansible executable location = /home/clement/documents/projects/ansible_env_setup/ansible/bin/ansible python version = 3.6.3 (default, oct  9 2017, 12:07:10) [gcc 7.2.1 20170915 (red hat 7.2.1-2)] python infoblox.py --list --- # this file provides the configuration information for the infoblox dynamic # inventory script that is used to dynamically pull host information from nios. # this file should be copied to /etc/ansible/infoblox.yaml in order for the # dynamic script to find it. # sets the provider arguments for authenticating to the infoblox server to # retrieve inventory hosts.  provider arguments can also be set using # environment variables.  supported environment variables all start with # infoblox_{{ name }}.  for instance, to set the host provider value, the # environment variable would be infoblox_host. provider: host: <server_ip> username: <username> password: <password> # filters allow the dynamic inventory script to restrict the set of hosts that # are returned from the infoblox server. filters: # restrict returned hosts by extensible attributes extattrs: {'in_devicetype': 'access', 'in_service': 'campus', 'in_country': fr', 'in_owner': 'lan'}, # restrict returned hosts to a specified dns view view: default expected results ""xxxx.xxxxx.com"": { ""extattrs"": { ""in_vendor"": ""xxx"", ""in_country"": ""xxx"", ""in_service"": ""xxx"", ""in_site"": ""xxx"", ""in_devicetype"": ""xxx"", ""in_owner"": ""xxx"" }, ""view"": ""default"" actual results ""xxxx.xxxxx.com"": { ""extattrs"": { ""in_owner"": ""xxx"" }, ""view"": ""default"" }, </desc> <cmt> *fix: re-create the exattrs dict into the hostvars[name] dict </cmt> <cmt> *fix: remove unwanted files </cmt>",contrib infoblox exattrs fixes #35409
2185,<desc> this pr fixes #110397 </desc> <cmt> wip: try to use vscode.open and vscode.diff in git/scm </cmt> <cmt> related to #110397 </cmt> <cmt> :lipstick: </cmt> <cmt> revert change to commands.converter.tointernal </cmt> <cmt> complete usage os vscode.open and vscode.diff in git extension </cmt> <iss> git: investigate using `vscode.open` and `vscode.diff` as commands in scm </iss>,use vscode.open and vscode.diff for a better editor opening experience
2186,<desc> hopefully fixes systemd/systemd-centos-ci#117 (comment). </desc> <cmt> linux: update kernel headers </cmt> <cmt> linux: make ubsan quiet </cmt> <cmt> ethtool-util: fix returned value when ethtool_cmd_speed() is speed_unknown </cmt> <cmt> ethtool: add missing link mode </cmt> <cmt> ethtool: reindent link mode table </cmt>,make ubsan quiet and add missing link modes
2187,"<desc> closes #19671 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> add require_iso8601 parameter and documentation in dataframe method iterrows </cmt> <cmt> remove blank line </cmt> <cmt> expose require_iso8601 parameter </cmt> <cmt> expose require_iso8601 parameter </cmt> <cmt> expose require_8601 parameter </cmt>",iso8601-compliant datetime string conversion in iterrows() and series construction.
2188,"<desc> avoid different comparators to sort only a single time use buffer.allocunsafe for better performance and buffer pooling measure size of objects to decide about inline or lazy storing improve typings of serializermiddlewares change serializer api to be not file serialization specific store pack only one time instead of twice refactoring, performance existing tests yes serializer api changed nothing </desc> <cmt> avoid different comparators to sort only a single time </cmt> <cmt> use buffer.allocunsafe for better performance and buffer pooling </cmt> <cmt> measure size of objects to decide about inline or lazy storing </cmt> <cmt> improve typings of serializermiddlewares </cmt> <cmt> change serializer api to be not file serialization specific </cmt>",performance and persistent caching improvements
2189,"<desc> follows the work done by @markerikson in #2807. this branch will be used to finish the switch to redux toolkit and the ducks pattern. changes added redux toolkit (rtk) removed the explicit dependency on redux, since rtk re-exports everything. converted the store setup logic in configurestore.js to use rtk's configurestore method updated the sample and template apps: created an rtk ""slice"" for all the homepage and localetoggle features moved app container's reducer/saga/actions into the homepage deleted all redundant actions/constants/reducer files determined ownership of repos in saga so that repolistitem can become a component updated all broken tests and write new tests for slices added eslint exception for ""slice"" files so that we can remove eslint exceptions removed obsolete store setup tests that checked for calling the devtools extension global api to do obsolete actions/reducers/constants files need to be deleted along with their tests appslices need to be tested update the template app update container generator restore 100% coverage update documentation with references to the redux toolkit usage guide consider if we can actually remove reselect and/or immer as dependencies. implement the reselect recommendations in this comment. </desc> <cmt> add redux toolkit </cmt> <cmt> remove explicit dependencies on packages used by rtk </cmt> <cmt> replace references to plain redux package </cmt> <cmt> convert store setup to use configurestore from rtk </cmt> <cmt> replace references to plain reselect library </cmt> <cmt> add an initial app slice </cmt> <cmt> update other uses of app slice actions </cmt> <cmt> fix lint errors in appslice </cmt> <cmt> fix mismatched argument in saga test </cmt> <cmt> fix incorrect preloadedstate argument for configurestore </cmt> <cmt> remove obsolete configurestore test </cmt> <cmt> fix broken initial state in template store setup </cmt> <cmt> fix broken test </cmt> <cmt> use appslice reducer in application </cmt>",add redux toolkit and ducks pattern
2190,"<desc> implements a formatter that it being used by the dagrun list view to display the passed conf. as discussed in #10519, it standardized the requested conf is passed as a json and should be displayed as a json (not as a python str). this also facilitates the to reuse of previews manually triggered dags confs (copy from dagrun list -> use to trigger a new dagrun). closes: #10519 ps: sent a commit message out of standard, next time i will get it right :) read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> include json field formatter, included it as a formatter on the dagrun view. fixed test match the changes (single quotes to double quotes on the string) </cmt> <cmt> include json field formatter, included it as a formatter on the dagrun view. fixed test match the changes (single quotes to double quotes on the string) </cmt> <cmt> fix spacing between functions on json_f </cmt> <iss> trigger dag requires a json conf but dag run view display a python dict </iss>",display conf as a json in the dagrun list view
2191,"<desc> upgrade xdiff to version used in core git 2.4.5 (0df0541). corrects an issue where a trailing newline is added at the eof when all the inputs lacked a trailing newline. </desc> <cmt> merge_files: don't add trailing newlines </cmt> <cmt> when invoked with three files that each lack a trailing newline, </cmt> <cmt> the merge result should also lack a trailing newline. </cmt> <cmt> revert: correct test that added trailing newline </cmt> <cmt> xdiff: upgrade to core git 2.4.5 </cmt> <cmt> upgrade xdiff to version used in core git 2.4.5 (0df0541). </cmt> <cmt> corrects an issue where an lf is added at eof while applying </cmt> <cmt> an unrelated change (ba31180), cleans up some unused code (be89977 and </cmt> <cmt> e5b0662), and provides an improved callback to avoid leaking internal </cmt> <cmt> (to xdiff) structures (467d348). </cmt> <cmt> this also adds some additional functionality that we do not yet take </cmt> <cmt> advantage of, namely the ability to ignore changes whose lines are </cmt> <cmt> all blank (36617af). </cmt>",don't add unnecessary trailing newline during file merge
2192,"<desc> this changes the requestclient::start_request() method to take a url instead of string url as argument. all callers of the method already had a url object anyway, and start_request() in turn parses the string back into a url. this removes this unnecessary conversion. it also changes requestclient.{cpp,h} to use east const style. </desc> <cmt> libprotocol: change requestclient.{cpp,h} to use east const style </cmt> <cmt> libprotocol: use url class in requestclient::start_request argument </cmt> <cmt> this changes the requestclient::start_request() method to take a url </cmt> <cmt> object instead of a url string as argument. all callers of the method </cmt> <cmt> already had a url object anyway, and start_request() in turn parses the </cmt> <cmt> url string back into a url object. this removes this unnecessary </cmt> <cmt> conversion. </cmt>",pass url instead of string as argument to requestclient::start_request
2193,<desc> supersedes #15226. adds more information on claiming stalled or unclaimed issues and more closely integrates these guidelines with those for taking over stalled pull requests. </desc> <cmt> doc: instructions for taking issues </cmt> <cmt> update doc/developers/contributing.rst </cmt> <cmt> [doc quick] more closely intergate stalled prs and stalled issues doc </cmt>,doc guidelines for handling stalled issues
2194,<desc> this should fix things so that we actually publish everything correctly. component name area/ci n/a </desc> <cmt> fix hnadling of static build artifacts for release builds. </cmt> <cmt> fix overall artifact handling for release build. </cmt>,fix handling of artifacts for nightlies and release builds.
2195,"<desc> ensure that runkubelet() returns errors consistently, and make info output match kube conventions. allows openshift to more easily reuse the kubelet. also sets fakedocker to emulate docker 1.6, and ensures defaulthealthz can't stomp on itself. </desc> <cmt> bump fake docker version to emulate docker 1.6 </cmt> <cmt> defaultmux should only register the first time </cmt>",make it easier to reuse kubelet server code
2196,"<desc> fixes #2641 this pr delays character-by-character measurement in the lines component when the editor is hidden, just like we delay measurement of the line height and default character width already. this also updates the cursor position as soon as character widths are updated by emitting a character-widths-changed event with a change count integer. using an integer was the easiest way to communicate to the cursors and highlights components that the scoped character widths have changed. </desc> <cmt> break into separate specs for lineheight, fontsize, and fontfamily </cmt> <cmt> wait to measure characters if editor is hidden </cmt> <cmt> also, when characters *are* measured, request a display update </cmt> <iss> cursor gets messed up when changing font with editor hidden </iss>",don't measure character widths when editor is hidden
2197,"<desc> fix onnx export for size_array by reshaping output from scalar to 1d tensor. adds onnx export unit tests for the following operators: rnn_param_concat size_array sample_multinomial </desc> <cmt> convert scalar result into 1d array for array_size, add unit tests for rnn_param_concat and size_array. </cmt> <cmt> add onnx export unit test for sample_multinomial operator. </cmt>",add more onnx operator export unit tests
2198,<desc> for insecure deserialization/java.md - added a new tool (ysoserial-modified) that handles os pipes and redirection where the original ysoserial does not handle. added a zip slip vulnerability template in upload insecure files directory with basic exploitation command. </desc> <cmt> update </cmt> <cmt> create readme </cmt> <cmt> delete readme </cmt> <cmt> create readme.txt </cmt> <cmt> update java.md </cmt> <cmt> update and rename readme.txt to readme.md </cmt>,updated insecure deserialization/java.md and created zip slip in upload insecure files
2199,<desc> make jinja context class attributes private requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix(jinja): make sqlalchemy models private on sql templates </cmt> <cmt> add missing privates </cmt> <cmt> fix test </cmt>,make context attrs private on sql templates
2200,"<desc> i built a node class which connects to other nodes, creating a graph. i then implemented a function, bfs(), that performs a breadth first search for the nodes. </desc> <cmt> adds: breadth first search </cmt> <cmt> adds: comments </cmt> <cmt> removes: unnessecary spaces </cmt>",breadth first search implemented in ruby
2201,"<desc> changes to support printing and parsing sil boxes with compound layouts. </desc> <cmt> change sil box promotion passes to use silboxtype::getfieldtype() instead of getboxedtype(). </cmt> <cmt> allocboxtostack should only have to deal with one-element boxes for local variables, and capture promotion will need reworking for box-based closure representation. </cmt> <cmt> move sillayout from sil to ast. </cmt> <cmt> trying to contain it in sil doesn't really work if we want to be able to print or parse sil box types, since the type parser and printer doesn't otherwise depend on the sil module. </cmt> <cmt> fix typo in sillayout constructor. </cmt> <cmt> walk silboxtype structure by looking at their layout arguments. </cmt> <cmt> in the new sil box scheme, a box's layout is invariant and parameterized by independent generic arguments, so these arguments are what should be structurally walked when transforming or walking types. type::transform's interface does not currently provide a reasonable way to resolve substitutions, unfortunately, but our only immediate need to transform silboxtypes is for mapping them in and out of generic contexts, for which we can maintain abstract generic conformances. </cmt>",printing and parsing sil boxes with layouts
2202,"<desc> this pr does two things: adds a note to clarify that zero-tuples are an intended feature of the specification fixes apparent typos or inconsistencies in the choice of index notation used in the spec for item 2: the abi spec begins by using 1-indexing.  i assume this is because 1-indexing is more common in mathematical expositions and the abi spec seems to follow that style.  for that reason, it seemed appropriate to correct occurrences of 0-indexing to use 1-indexing and not the other way around. of course, if all that notation was chosen intentionally and there's something i'm just not understanding, please ignore me  . </desc> <cmt> add note about zero-tuples </cmt> <cmt> make index notation more consistent </cmt>",a couple of abi spec improvements
2203,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. react-native-navigation has prop overridebackpress which can be passed as argument when for example pushing new screen. the purpose of the argument is to control what happens when user presses back button on android. more info on this here: </desc> <cmt> add missing prop to screen </cmt> <cmt> use new prop in tests </cmt>",add missing argument for screen (react-native-navigation)
2204,<desc> i hereby agree to the terms of the cla available at:  short description (up to few sentences): fix join results for key columns when used with join_use_nulls. attach nulls instead of columns defaults. </desc> <cmt> analyzedjoin refactoring </cmt> <cmt> fix join_use_nulls results for key columns </cmt>,fix join_use_nulls. nulls in join keys issue
2205,"<desc> intercepting mod-tap to workaround caveats is a frequently asked question in discord. documented here are code examples of doing so. faq in qmk discord my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add mod-tap custom code examples </cmt> <cmt> more edits </cmt> <cmt> remove const </cmt>",document examples on intercepting mod-tap
2206,"<desc> when trying to run ""make all"" on my local system, the printf statements in util/cache_bench.cc that use priu64 generated errors. they were fixed by includint inttypes.h in the file. </desc> <cmt> added include for inttypes.h to fix nonworking printf statements </cmt>",util/cache_bench.cc needs to include inttypes.h
2207,"<desc> revise and add default widgets to the default error dashboard. for some widgets, i've added conditions to filter out transaction events. </desc> <cmt> add explicit event type condition to filter out transactions </cmt> <cmt> add big number widgets </cmt> <cmt> add errors by browser </cmt>",update the default error dashboard
2208,"<desc> after discovering a module where the separator was not set to hashconfig->separator consistently, i went through all modules and fixed all of them where this was also the case. </desc> <cmt> update </cmt> <cmt> fixing all inconsistent hash separators </cmt>",patch all inconsistent separators in modules
2209,"<desc> the healthcheck scripts are no longer written to a file during startup. they are instead mounted from a configmap with appropriate permissions. this should make it easier to maintain the chart in the future. the healthcheck scripts are mounted to /usr/local/sbin/ instead of /opt/bitnami/rabbitmq/sbin/. this is to accomodate images that don't have /opt/bitnami/rabbitmq/sbin/ on their path. instead of creating and removing a .start file, when the healthcheck is first run, it is created after the healthcheck has been run. the if statement has been negated. dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/rabbitmq] move healthchecks into configmap </cmt> <cmt> [stable/rabbitmq] bump chart version </cmt> <cmt> [stable/rabbitmq] reversed startup check </cmt> <cmt> [stable/rabbitmq] env is set during healthchecks </cmt> <cmt> [stable/rabbitmq] clean edits in branch </cmt> <cmt> for minimal changeset in squashed merge commit </cmt>",fix healthchecks for non-bitnami images
2210,"<desc> due to the size of the commit, i'm submitting the unit tests in a separate request. </desc> <cmt> add basic k2 storage system implementation. </cmt> <cmt> - all exceptions. </cmt> <cmt> - storage driver interfaces </cmt> <cmt> - internal k2 interface (k2storage/store) </cmt> <cmt> - i18n strings </cmt> <cmt> remove redundant dependency from installeddriver. </cmt> <cmt> replace // with /* for copyright headers. </cmt> <cmt> add comments and fix formatting for installeddriver. </cmt> <cmt> fix missing javadoc @returns on wrap methods. </cmt> <cmt> add more documentation to k2storage methods. </cmt>",add basic k2 storage framework implementation.
2211,"<desc> we keep getting reports from folks who hit build issues that turn out to be due to them not running the dependencies script. when building fails, check whether rnw-dependencies has been run. update the script to leave a sentinel file behind so we can check it. also plan to submit whether the sentinel is there in telemetry. also move node to use lts version (currently 14). microsoft reviewers: open in codeflow </desc> <cmt> check whether dependencies have been installed </cmt> <cmt> change files </cmt>",check deps when builds fail
2212,"<desc> this fixes... discord will tell us how many test262 tests :^) </desc> <cmt> libjs: rename js_enumerate_{error_subclasses => native_errors} </cmt> <cmt> the fact that they *are* subclasses is an implementation detail and </cmt> <cmt> should not be highlighted. the spec calls these nativeerrors, so let's </cmt> <cmt> use that. </cmt> <cmt> also added a comment explaining *why* they inherit from error - i was </cmt> <cmt> about to change that :^) </cmt> <cmt> libjs: only initialize in add_constructor() if not already done </cmt> <cmt> libjs: implement aggregateerror </cmt>",implement aggregateerror (+ a minor rename)
2213,<desc> added panoptic segmentation serving module added script to export saved_model training script python -m official.vision.beta.projects.panoptic_maskrcnn.serving.panoptic_segmentation_test i have signed the contributor license agreement. i have read guidelines for pull request. my code follows the coding guidelines. i have performed a self code review of my own code. </desc> <cmt> added panopticsegmentationmodule </cmt> <cmt> added tests for panopticsegmentationmodule </cmt> <cmt> added script to export saved_model </cmt> <cmt> added registry_imports </cmt> <cmt> added training script </cmt>,added serving module for panoptic maskrcnn
2214,<desc> adds ability to manage arbitrary clusters using the spinnaker chart. currently you can only (easily) manage the one that you deploy to. </desc> <cmt> update component versions </cmt> <cmt> bump spinnaker version in chart.yaml </cmt> <cmt> use either local or kubeconfig accounts </cmt> <cmt> update docs for spinnaker multicluster </cmt> <cmt> fix capitalization of values </cmt> <cmt> fix readme indentation </cmt> <cmt> add more info to values file </cmt>,allow users to register arbitrary kubernetes clusters
2215,"<desc> display the omnichannel room closing data on the visitor info panel send a system message to display who closed the room when the author is the visitor(or external systems). this process wasn't working because the sendmessage method was expecting a valid user and the visitor wasn't being considered. also, now the subscription will be removed after the room is closed. the agent doesn't need the subscription anymore. </desc> <cmt> added some improvements on closing and tracking omnichannel rooms. </cmt> <cmt> display ""agent"" when the user who closed and served the room is the same. </cmt> <cmt> fix indentation. </cmt> <cmt> fix closeat information on omnichannel rooms. </cmt>",show more information related to the omnichannel room closing data
2216,<desc> fixes issue #12750 this pr implements a simple check of the arguments to make sure that the missingindicator raises an exception when both arguments sparse=true and missing_values=0 or array is sparse and missing_values=0. it fixes old tests that allowed for these cases and implements one new test. </desc> <cmt> adding argument check for the case spare=true and missing_values=0 </cmt> <cmt> issue #12750 </cmt> <cmt> missing indicator: handle case array is sparse and missing values==0 </cmt> <cmt> issue #12750 </cmt>,check arguments of missingindicator imputer when handling sparse arrays
2217,<desc> fixes #33910 </desc> <cmt> fix documentation and starter for use of status in getserverdata </cmt> <cmt> use status from getserverdata in develop and serve </cmt> <iss> `gatsby serve` and `develop` should respect http status returned from `getserverdata` </iss>,ensure status returned by getserverdata is respected
2218,"<desc> fixes #5814, continuation of #7477 move alpha setting into fit and partial_fit </desc> <cmt> fix #5814 </cmt> <cmt> fix pep8 in naive_bayes.py:716 </cmt> <cmt> fix sparse matrix incompatibility </cmt> <cmt> fix python 2.7 problem in test_naive_bayes </cmt> <cmt> make sure the values are probabilities before log transform </cmt> <cmt> improve docstring of  _safe_logprob </cmt> <cmt> clip alpha solution </cmt> <cmt> clip alpha solution </cmt> <cmt> clip alpha in fit and partial_fit </cmt> <cmt> add what's new entry </cmt> <iss> multinomial bayes issue </iss>",fix multinomialnb and bernoullinb alpha=0 bug (continuation)
2219,"<desc> explanation: these two patches are recent fixit improvement motivated by our experience in migrating real world projects. they improve the compiler in three situations: (1) a return statement needs coercion to match the return type; (2) an initialization needs coercion on the right hand side of '=' to match the type of the instance being initialized; and (3) a booleantype instance is used inside conditions like if or guard statements. we issue automatic fixits in these situations to help users cope with id-as-any and booleantype's removal changes introduced by swift 3. scope: this is a fairly common migration situations; we saw them in actual codebase. risk: low reviewed by: argyrios and jordan testing: regression test added. resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [fixcode] apply coercion fixits on return statement and initialization as well. rdar://27891589 rdar://27891426 </cmt> <cmt> we saw manual migration is necessary on these cases to add 'as type'. this patch starts </cmt> <cmt> to issue compiler fixits on return statement and initialization just like in other type-mismatch </cmt> <cmt> cases. </cmt> <cmt> [fixcode] add diagnosis/fixit to help users deal with booleantype's removal (#4392) </cmt> <cmt> * [fixcode] add diagnosis/fixit to help users deal with booleantype's removal. </cmt> <cmt> due to migration reasons, types used to conform to booleantype, which </cmt> <cmt> must contain a member var 'boolvalue', now does not convert to bool. this patch </cmt> <cmt> adds a specific diagnosis/fixit to explicitly invoke 'boolvalue' to please the </cmt> <cmt> context types. </cmt> <cmt> * address jordan's code review comments. </cmt>",fixit enhancement for migration needs (3.0)
2220,"<desc> add resource(s) | improve repo recovers ""laravel 8 free course"" pr intent made at #5465 by @gustavors22 locks #5465, resolves #5465 follow initial pr. it's a especializati academy's  course read our contributing guidelines search for duplicates. #5465 followup check the output of travis-ci for linter errors! </desc> <cmt> laravel-8-free-course </cmt> <cmt> (cherry picked from commit 603f7cc2a11bd548d44dfc1a8db57e9680a08152) </cmt> <cmt> @gustavors22 </cmt> <cmt> move laravel-8-free-course into php category </cmt> <cmt> initial commit made by @gustavors22 </cmt> <cmt> reorganize removing laravel/code igniter section </cmt> <cmt> initial commit made by @gustavors22. </cmt> <cmt> completes </cmt>","recover ""laravel 8 free course"" at #5465"
2221,"<desc> switching viz type between a chart type and filter was broken due to a different type of data payload (array for charts and object for filter) and additional rerender caused by dispatching reset_fields after render caused by switching viz type. i moved the logic of resetting control fields to set_field_value reducer, thus removing 1 rerender. before: see #12624 after:  test plan has associated issue: fixes #12624 requires db migration. confirm db migration upgrade and downgrade tested. cc: @junlin </desc> <cmt> fix switching viz_type to and from filter_box </cmt> <cmt> remove reset_fields action </cmt>",fix switching viz type to and from filter box
2222,"<desc> the idea being that when the daily user tests fail on vsts, it can run this script and automatically open a pr wih the changes. @ryancavanaugh should i make a new bot account for this (to keep credential reuse low), or should we reuse one of the other bots? </desc> <cmt> draft of script to automatically create user baseline update prs </cmt> <cmt> some modifications to make testing easier </cmt>",add script for automatically creating prs for user test updates
2223,"<desc> copyedit changes to the engines guide: change to gender neutral language (brothers -> siblings) correct verb tense (if the table wasn't already existing -> if the table didn't already exist) fix comma splice (they do not hook into any particular framework, instead they run... -> they do not hook into any particular framework, but instead they run...) (i opened a previous pr but did not put [ci skip] into each git commit correctly.  i closed that one and created this one.) </desc> <cmt> gendered wording not necessary; changed to neutral [ci skip] </cmt> <cmt> verb tense correction [ci skip] </cmt> <cmt> fix comma splice [ci skip] </cmt>","neutral language,  verb tense, comma splice [ci skip]"
2224,"<desc> this is inspired by the original work of #6699 by @flowermin. it tries to achieve the same cpu savings by reducing unnecessary byte allocation and corresponding gc. unlike #6699 though, which depends on skipbytes of lz4 which used a shared byte array, in this pr we create a skip buffer outside of the compressed input stream. the reason is that not all compressed inputstream's implementation is optimized, more specifically: gzip used bufferedinputstream, which has a shared buffer, sized 16kb snappy used its own snappyinputstream -> inputstream, which dynamically allocate lz4 used its own kafkalz4blockinputstream, which has a shared buffer of 64kb zstd used its own zstdinputstream, but it's own overriden skip also dynamically allocate the detailed implementation can be summarized as follows: add skipkeyvalueiterator() into defaultrecordbatch, used in logvalidator; also added partialdefaultrecord which extends defaultrecord. 1.a. in order make this optimization really effective, we also need to refactor the logvalidator to refactor part of the validation per record into the outer loop so that we do not need to update inplaceassigment inside the loop any more. and then based on this boolean we can decide whether or not to use skipkeyvalueiterator or not before the loop. 1.b. also used streaming iterator instead when skip-iterator cannot be used. with skipkeyvalueiterator, pre-allocate a skip byte array with fixed size (2kb), and use this array to take the decompressed bytes through each record, validating metadata and key / value / header size, while skipping the key / value bytes. also tighten the unit tests of logvalidator to make sure scenarios like mismatched magic bytes / multiple batches per partition / discontinuous offsets / etc are indeed validated. </desc> <cmt> kafka-8106:reducing the allocation and copying of bytebuffer when logvalidator do validation. </cmt> <cmt> kafka-8106:reducing the allocation and copying of bytebuffer when logvalidator do validation. </cmt> <cmt> github comments </cmt>",skipping bytebuffer allocation of key / value / headers in logvalidator
2225,<desc> description: the image_processing.draw_box function is drawing the label text inside the line. this adjusts the text offset to account for the font size. related issue: fixes #27766 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> adjust font text such that it won't be drawn inside the bow line in image_processing.draw_box </cmt> <cmt> adjust font_height after actually counting the pixels </cmt> <iss> bounding box covers text annotation on some images </iss>,avoid drawing image_processing font text inside the bow line
2226,<desc> correcting path direction on several geometric shapes. closes #192 reversed path direction of inner bits of the five problematic geometric shapes. now rendering as expected. updated forms ran a build and checked resulting files are working correctly. </desc> <cmt> update cascadia-code-characters.png </cmt> <cmt> making prettier </cmt> <cmt> update build.py </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> correcting path direction </cmt> <iss> bug report: some geometric shape characters have incorrect contour directions </iss>,fixing path direction on geometric shapes
2227,"<desc> this pr adds a full-container opaque mouseregion to the following widgets in order to prevent widgets behind it reacting to mouse events: modalbarrier the barrier of drawer check out related issues to see reason of this change. how do i make sure they are all cases that need changing? i searched blocksemantics and they are the only usages. related issues fixes #32915 fixes #33679 the behavior is fixed for modalroute (which applies to most common cases), but not its superclasses. i added the following tests: drawer hover test modalbarrier prevents hover interactions with widgets behind it modalbarrier does not prevent hover interactions with widgets in front of it an empty opaque mouseregion is effective before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add opaque to barriers </cmt> <iss> hover effects are incorrectly shown for all widgets under cursor. </iss> <iss> route should be opaque to mouseenter/exit events </iss>",modalbarrier and drawer barrier prevents mouse events
2228,"<desc> this commit adds support both for finding embedded ted video on a page, as well as adding direct support for embed.ted.com links. </desc> <cmt> [generic] add support for embeded ted videos </cmt> <cmt> [tedie] add support for embeded ted video urls </cmt>",add support for embedded ted videos
2229,"<desc> closes #39434 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry added validation of ascending for sort_index methods. proposed a solution to raise valueerror when either of the elements of ascending turned out to be none. </desc> <cmt> tst: add failing tests </cmt> <cmt> bug: add ascending kwarg validation </cmt> <iss> bug: regression in sort_index with ascending=none </iss>",raise when sort_index with ascending=none
2230,"<desc> for elements with dangerouslysetinnerhtml attr, initial rendering will take place correctly. ( only test case for initial render is present in the unit tests ). after that, after some updating, if we are again rendering the same element, it was not working. this pull request fixes that issue. ( unit test also included ) </desc> <cmt> fix: should proceed to setaccessor function if the attr name is dangerouslysetinnerhtml. </cmt> <cmt> - even if element is taken from cache, its child nodes which was previously set using dangerouslysetinnerhtml is some how lost ( garbage collected ) </cmt> <cmt> - so comparing with old values doesnt make sense here. so proceed to setaccessor </cmt> <cmt> drying... </cmt> <cmt> added tests for dangerouslysetinnerhtml mutation fix </cmt>",dom mutation was not happening for elements with dangerouslysetinnerhtml.
2231,<desc> modify managed_connect() helper to support in-memory databases. use it for the regression tests added in gh-27844.  automerge-triggered-by: gh:pablogsal </desc> <cmt> bpo-44958: fix ref. leak in test_table_lock_cursor_non_readonly_select() </cmt> <cmt> bpo-44958: fix ref. leak in test_table_lock_cursor_non_readonly_select() </cmt> <cmt> modify managed_connect() helper to support in-memory databases. use it </cmt> <cmt> for the regression tests added in gh-27844. </cmt>,fix ref. leak introduced in gh-27844
2232,"<desc> saw this while snooping around, the gci command on powershell core seems to store the full path in the variable as oppose to just the leaf. the other modification is to use the powershell module that vs ships to setup the environment. </desc> <cmt> fix for diferent behavior of gci in powershell 7 </cmt> <cmt> use vsdevshell module to do the hard work </cmt> <cmt> cleanup </cmt>",use devshell module; tidy up for powershell 6+
2233,"<desc> this continues down the path of removing custom code required for elasticsearch painless scripts from the user and ir nodes. this change uses ir nodes to inject gets methods, needs methods, and the bootstrap method as required. there is no reason for the sclass/classnode to know about these specific items. though, these appear as separate phases for now, this is purely transitional. eventually, these will be rolled into a single ""build"" phase where the user tree is semantically checked and converted into an ir tree. this intermediate step is necessary to make the changes occur in smaller consumable steps. </desc> <cmt> removed scopes for functions to see used variables </cmt> <cmt> change scoping to track variables in all scopes </cmt> <cmt> partially removed execute method exceptino customization </cmt> <cmt> move autoreturn out of ir nodes </cmt> <cmt> add es specific exceptions in decorate execute phase </cmt> <cmt> remove commented out code </cmt> <cmt> response to pr comments </cmt> <cmt> move static constant generation </cmt> <cmt> create bootstrap methods with external phase </cmt> <cmt> move gets methods and static variables out of class node </cmt> <cmt> inject needs methods </cmt>",continue removal of custom script code in classnode in painless
2234,"<desc> the build will pass (run yarn test and yarn lint) more info can be found by clicking the ""guidelines for contributing"" link above. </desc> <cmt> replaced i18n.t w/ tpl helper in pages.js </cmt> <cmt> refs: #13380 </cmt> <cmt> replaced i18n.t w/ tpl helper in pages-public.js </cmt> <cmt> refs: #13380 </cmt>",replaced i18n.t w/ tpl helper in public.js and pages-public.js #13399
2235,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add type for backaction on shellbar </cmt> <cmt> fix typo backbutton --> backaction </cmt> <cmt> update fundamental-react -> list and add list.selection </cmt>",update fundamental-react list and add list.selection
2236,<desc> this pr extracts the nitty-gritty of the starting of the webpack dev server and cli bootstrapping from the develop-process command into a startwebpackserver service. in the state machine branch this is spawned during bootstrap. it also extracts some of the functions used by that into seperate utils files. </desc> <cmt> add typings for action arrays and thunks </cmt> <cmt> switch back to non-null assertion </cmt> <cmt> add comment </cmt> <cmt> refactor bootstrap into services </cmt> <cmt> use separate gql runner for bootstrap </cmt> <cmt> import reporter typings </cmt> <cmt> switch to new bootstrap </cmt> <cmt> fix imports </cmt> <cmt> add create pages </cmt> <cmt> add extract queries </cmt> <cmt> fix typings </cmt> <cmt> rebuild schema with sitepage </cmt> <cmt> rename context vars </cmt> <cmt> refactor out startserver </cmt> <cmt> add start webpack server service </cmt> <cmt> bootstrap webpack from service </cmt>,change develop command to use startwebpackserver service
2237,<desc> fixes astscope lookup for lazily-parsed function bodies in non-primary files. adds a test. addresses rdar://56384593 also includes better debugging printing in a separate commit. suggest reviewing each commit separately. </desc> <cmt> better debugging code </cmt> <cmt> fix expansion of lazily-parsed function bodies </cmt>,create lazily-parsed function body scopes.
2238,<desc> backports: make grpc podspec template more robust #21445 (required to merge the following) remove grpc sources from grpc++ #21662 fixes #21213 </desc> <cmt> make grpc podspec template more robust </cmt> <cmt> remove grpc sources from grpc++ </cmt>,backport of #21445 and #21662
2239,"<desc> download of some videos on blip.tv failed with this error: $ youtube-dl --verbose  error: unable to extract video_id; please report this issue on  traceback (most recent call last): file ""/usr/lib/python3.4/site-packages/youtube_dl/youtubedl.py"", line 553, in extract_info ie_result = ie.extract(url) file ""/usr/lib/python3.4/site-packages/youtube_dl/extractor/common.py"", line 240, in extract return self._real_extract(url) file ""/usr/lib/python3.4/site-packages/youtube_dl/extractor/bliptv.py"", line 79, in _real_extract video_id = self._search_regex(r'config\.id\s*=\s*""([0-9]+)', info_page, 'video_id') file ""/usr/lib/python3.4/site-packages/youtube_dl/extractor/common.py"", line 478, in _search_regex raise regexnotfounderror('unable to extract %s' % _name) youtube_dl.utils.regexnotfounderror: unable to extract video_id; please report this issue on  this was caused by "" also fixed extractor returning urls which end with \n\n as described by @tycode here. </desc> <cmt> [bliptv] fix resolution of lookup id in some videos </cmt> <cmt> in some videos (for example, </cmt> <cmt> lookup id would fail, because page at </cmt> <cmt>  </cmt> <cmt> it. fixed by requesting different url and inspecting the url which the </cmt> <cmt> client is redirected to. </cmt> <cmt> [bliptv] fix \n\n at the end of real_url </cmt> <cmt> see </cmt>",fix some videos not downloading
2240,"<desc> hi there, i added a login_unix_socket option for two mysql modules. this is very handy if you have more than one mysql installation on a system or if you have completely custom paths. can be used in a playbook like this: - name: create database action: mysql_db login_unix_socket=/path/to/sock login_user=""root"" login_password=""mysecretpw"" db=dbname state=present - name: create db-user action: mysql_user login_unix_socket=/path/to/sock login_user=""root"" login_password=""mysecretpw"" name=username password=""mysecretpw"" priv=*.*:all state=present regards ingo </desc> <cmt> added login_unix_socket option to mysql_db module </cmt> <cmt> added login_unix_socket option to mysql_user module </cmt>",login_unix_socket option for mysql modules
2241,"<desc> i've managed to get xbmc added to the list of open source projects that is scanned for free by the coverity static analysis tool. see  for other developers that are interested in viewing the static analysis output, please contact me for login information. this pull request aggregates all of my commits to fix these static analysis issues.  please note that some of the uninitialized class member ""fixes"" may not resolve actual bugs, but instead follow good practice of initializing class members in the constructor. </desc> <cmt> fix possible buffer overrun in dvddemuxffmpeg.cpp. </cmt> <cmt> we should check that istreamid is strictly less than max_streams to </cmt> <cmt> avoid reading past the end of the array. </cmt> <cmt> fix use after free of file pointer. </cmt> <cmt> fix memory leak on control sequence parse error. </cmt> <cmt> init suffix and prefix buffers. </cmt> <cmt> init suffic and prefix buffers in animatedgif.cpp to avoid possible </cmt> <cmt> uninitialized reads. </cmt> <cmt> fix memory leak in guifontttfgl::cachecharacter </cmt> <cmt> please note that it is safe to call delete on a null pointer. </cmt> <cmt> fix leak in jpegio::createthumbnailfromsurface </cmt> <cmt> fix memory leak in cguitexturemanager::canload </cmt> <cmt> fix memory leak in cperformancestats::addsample. </cmt> <cmt> fix memory leak in scraperparser.cpp </cmt> <cmt> fix possible uninitialized reads in scraperurl.cpp </cmt> <cmt> fix memory leaks in videoinfoscanner.cpp </cmt>",fix coverity static analysis issues in xbmc
2242,<desc> this pr implements support for glob patterns. atm prettier only processes the first file if a list of files is given in arguments. this will allow running prettier with  closes #58 </desc> <cmt> chore: added .js extension to ./bin/prettier </cmt> <cmt> feature: add support for passing multiple files </cmt> <cmt> fixes #58 </cmt> <cmt> style: run prettier on the source code </cmt> <cmt> build: add more scripts to test </cmt>,accept globs and lists of files
2243,"<desc> these 2 commits add accelerometer mount matrix and location info for 2 devices. </desc> <cmt> hwdb: add accel location quirk for the gpd win </cmt> <cmt> the acceleromater in the gpd win is in the base, mark it as such so that </cmt> <cmt> iio-sensor-proxy does not try to use it for display rotation. </cmt> <cmt> note as mentioned in the added comment the dmi strings are unfortunately </cmt> <cmt> somewhat generic, but the combination of using all dmi strings including </cmt> <cmt> the bios build data + the sensor modalias should be unique enough. </cmt> <cmt> hwdb: add accel. mount matrix and location for the trekstor primebook c11b </cmt> <cmt> the trekstor primebook c11b 2-in-1 has 2 accelerometers. add mount-matrix </cmt> <cmt> and location info for both to 60-sensor.hwdb. </cmt>",accel quirks for 2 devices
2244,"<desc> what this pr does / why we need it: proper fix for the issue i found in #67215. some machines (like apparently workstations at google) have a restrictive umask, so the qemu-arch-static binaries were getting installed in images without world read/execute permissions, causing utilities like apt-get to fail. there was also a duplicate download/install of these binaries for debian-iptables, which further confused the issue. i've since removed that duplicate installation. many thanks to @bentheelder for asking the right question to get me to look at the permissions again. i haven't pushed any images yet. after merge, i'll build/promote debian-base:0.3.2, then update everything to use it, then push some more images, write some more prs, ... release note: /assign @tallclair </desc> <cmt> ensure qemu-arch-static binary is world readable and executable </cmt> <cmt> only register qemu-user-static when necessary. </cmt> <cmt> also, don't re-download qemu-arch-static binaries for debian-iptables </cmt> <cmt> bump debian-base to 0.3.2 </cmt>",fix permissions of qemu-arch-static in debian-base and other images
2245,<desc> resulting in code size decrease between 1k and 3k. updating tasmota stage core 2.7.4.7 (same as 2.7.4.5 + more wstring optimization) some optic beautifying the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.5 + stage core the code change is tested and works on core esp32 v.1.12.2 + stage core i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> -mno-target-align </cmt> <cmt> target align for espxx and esp32 </cmt>,use compiler option no target align for stage
2246,<desc> further improvements to #10178 improve terminate pending state tests. serialize pending state for editor. keep pending item upon losing focus. </desc> <cmt> change order of tests </cmt> <cmt> refactor pending item tests </cmt> <cmt> :art: </cmt> <cmt> :white_check_mark: ensure terminate handler is invoked only once </cmt> <cmt> early return from promise if pane is destroyed </cmt> <cmt> serialize pending state for editor </cmt> <cmt> add spec for serialzing/deserialzing pending state for editor </cmt> <cmt> improve terminate pending state tests. </cmt> <cmt> remove argument to remove pending state listeners. </cmt> <cmt> keep pending pane upon losing focus </cmt> <cmt> use __dirname in path.resolve for specs </cmt> <cmt> update specs for pending item behavior </cmt>,further improvements to pending item functionality
2247,"<desc> this commit actually includes the ones from 1-2 as well. i generally tried to give less help on the later bonfires. the comma mistype from the other commit should be fixed here as well. </desc> <cmt> links from database are being passed to the view. todo create links </cmt> <cmt> links iterated through on the page. todo formatting and adding more data. </cmt> <cmt> formatting done. </cmt> <cmt> links added, basic functionality working across pages. </cmt> <cmt> if no links are present, the template does not show the helpful links header. </cmt> <cmt> fixed comma error for merge. </cmt> <cmt> added bonfire links for level 2. </cmt> <cmt> added bonfire links for level 3. </cmt>",bonfire mdn links: 3-4 flame
2248,"<desc> foldsequence() may hoist these expression up by mutating their sub expression. when completing operators, this behavior ruins reusability of operand. since these expression doesn't affect completion, we can strip them out. rdar://problem/42452085 also, this pr contains follow-up fix for f577578. the same treatment for ternary expression (ifexpr). plus, fix a regression where infix operator were disappeared from results when leading sequence contains assignexpr. </desc> <cmt> [codecomplete] strip out try and optional eval expr in operator compilation </cmt> <cmt> foldsequence() may hoist these expression up by mutating their sub </cmt> <cmt> expression. when completing operators, this behavior ruins reusability </cmt> <cmt> of operand. since these expression doesn't affect completion, we can </cmt> <cmt> strip them out. </cmt> <cmt> rdar://problem/42452085 </cmt> <cmt> [codecomplete] handle ternary expression in sequence completion </cmt> <cmt> follow-up to f577578a6adf3059b03a8ca43cf979d72bd50a65. the same </cmt> <cmt> treatment for ternary expression (ifexpr). plus, fix a regression </cmt> <cmt> introduced in f577578a where infix operators were disappeard from </cmt> <cmt> results. </cmt>",strip out try and optional eval expo in operator completion
2249,"<desc> the outputstatemachine needs to collect ""intermediate"" characters to be able to call designate g0 character set (as well as other sequences we don't yet support). however, the inputstatemachine used by conpty to process input should not collect these characters. the input engine uses \x1b as an indicator that a key was pressed with alt. for keys like /, we want to dispatch the key immediately, instead of collecting it and leaving us in the escape state. closes #1209 cla signed. if not, go over here and sign the cla </desc> <cmt> add a test for this case </cmt> <cmt> fix this bug </cmt> <cmt> we need the input state machine to not collect intermediate chars </cmt> <cmt> add more commenting to this test </cmt> <iss> previous keystrokes modify following keystrokes </iss>",the inputstatemachine should dispatch intermediate characters
2250,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: documentation increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added extensions usage for cytoscape </cmt> <cmt> fix for extension type definition </cmt>",added extension usage into cytoscape definitions
2251,"<desc> this pr introduces a new colortype to allow us to distinguish between sgr indexed colors from the 16 color table, the lower half of which can be brightened, and the iso/itu indexed colors from the 256 color table, which have a fixed brightness. retaining the distinction between these two types will enable us to forward the correct sgr sequences to conpty when addressing issue #2661. the other benefit of retaining the color index (which we didn't previously do for iso/itu colors) is that it ensures that the colors are updated correctly when the color scheme is changed. this is another step towards fixing the conpty narrowing bugs in issue #2661. this is technically a fix for issue #5384, but that won't be apparent until #2661 is complete. closes #1223 requires documentation to be updated the first part of this pr was the introduction of a new colortype in the textcolor class. instead of just the one isindex type, there is now an isindex16 and an isindex256. isindex16 covers the eight original ansi colors set with sgr 3x and sgr 4x, as well as the brighter aixterm variants set with sgr 9x and sgr 10x. isindex256 covers the 256 iso/itu indexed colors set with sgr 38;5 and sgr 48;5. there are two reasons for this distinction. the first is that the ansi colors have the potential to be brightened by the sgr 1 bold attribute, while the iso/ito color do not. the second reason is that when forwarding an attributes through conpty, we want to try and preserve the original sgr sequence that generated each color (to the extent that that is possible). by having the two separate types, we can map the isindex16 colors back to ansi/aixterm values, and isindex256 to the iso/itu sequences. in addition to the vt colors, we also have to deal with the legacy colors set by the windows console apis, but we don't really need a separate type for those. it seemed most appropriate to me to store them as isindex256 colors, since it doesn't make sense to have them brightened by the sgr 1 attribute (which is what would happen if they were stored as isindex16). if a console app wanted a bright color it would have selected one, so we shouldn't be messing with that choice. the second part of the pr was the unification of the two color tables. originally we had a 16 color table for the legacy colors, and a separate table for the 256 iso/itu colors. these have now been merged into one, so color table lookups no longer need to decide which of the two tables they should be referencing. i've also updated all the methods that took a color table as a parameter to use a basic_string_view instead of separate pointer and length variables, which i think makes them a lot easier and safer to work with. with this new architecture in place, i could now update the adaptdispatch sgr implementation to store the iso/itu indexed colors as isindex256 values, where before they were mapped to rgb values (which prevented them reflecting any color scheme changes). i could also update the terminaldispatch implementation to differentiate between the two index types, so that the sgr 1 brightening would only be applied to the ansi colors. i've also done a bit of code refactoring to try and minimise any direct access to the color tables, getting rid of a lot of places that were copying tables with memmove operations. i'm hoping this will make it easier for us to update the code in the future if we want to reorder the table entries (which is likely a requirement for unifying the adaptdispatch and terminaldispatch implementations). for testing, i've just updated the existing unit tests to account for the api changes. the textcolortests required an extra parameter specifying the index type when setting an index. and the adaptertest and screenbuffertests required the use of the new setindexedxxx methods in order to be explicit about the index type, instead of relying on the textattribute constructor and the old setforeground and setbackground methods which didn't have a way to differentiate index types. i've manually tested the various console apis (setconsoletextattribute, readconsoleoutputattribute, and readconsoleoutput), to make sure they are still setting and reading the attributes as well as they used to. and i've tested the setconsolescreenbufferinfoex and getconsolescreenbufferinfoex apis to make sure they can read and write the color table correctly. i've also tested the color table in the properties dialog, made sure it was saved and restored from the registry correctly, and similarly saved and restored from a shortcut link. note that there are still a bunch of issues with the color table apis, but no new problems have been introduced by the changes in this pr, as far as i could tell. i've also done a bunch of manual tests of osc 4 to make sure it's updating all the colors correctly (at least in conhost), and confirmed that the test case in issue #1223 now works as expected. </desc> <cmt> distinguish between indexed colors from the 16 color palette (which can be brightened), and the 256 color palette (which can't). </cmt> <cmt> make the terminal dispatcher use the 256 color index format for sgr 38:5 and 48:5 escape sequences. </cmt> <cmt> update unit tests to account for the updated index color formats. </cmt> <cmt> avoid directly copying the color table with memmove. </cmt> <cmt> remove some unnecessary functions that made the code harder to follow. </cmt> <cmt> combine the 16 and 256 color tables, and use string_views when passing the tables around. </cmt> <cmt> make the conhost dispatcher use the 256 color index format for sgr 38:5 and 48:5 escape sequences. </cmt> <cmt> update unit tests to account for the corrected interpretation of indexed colors. </cmt> <iss> [host] changing a color table value above 16 does not update the color of other cells with that index </iss>",fix sgr indexed colors to distinguish indexed256 color (and more)
2252,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description this updates the code behind the za command. previously the input was split into fields by r_str_word_set0. this resulted in type signatures being incorrectly formatted because their double quotes were stripped. for example: za main t func.main.ret=int func.main.args=2 func.main.arg.0=""int,argc"" func.main.arg.1=""char **,argv"" za main t func.main.ret=int func.main.args=2 func.main.arg.0=int argc func.main.arg.1=char ** argv after this commit the type signature will work properly. this make it easy to test if types are correctly applied on signature matches. so two new signature tests are also included in this pr. test plan see provided tests. closing issues </desc> <cmt> fix bug in adding type ##signatures with za </cmt> <cmt> add test for applying signature info </cmt>",fix zig add type ##signatures
2253,"<desc> the documentation and examples indicate that the same options for the inline datepicker are also used in the popup datepicker, but you can't unless idatepickerpopupconfig extends idatepickerconfig </desc> <cmt> bringing up to date </cmt> <cmt> i believe idatepickerpopupconfig has everything in idatepickerconfig, plus additional things, so it should extend idatepickerconfig. </cmt>",angular-ui-bootstrap -- idatepickerpopupconfig should extend idatepickerconfig
2254,"<desc> this pull request introduces (a very, very stripped-down copy of) the wil fallback error reporter. it emits error records, usually immediately before the application implodes, into the event stream. this should improve diagnosability of issues that take terminal down, and allow us to give out a .wprp file to gather traces from users. </desc> <cmt> wire up fallback error reporting </cmt> <cmt> it shouldn't need to be spelled out but here we are </cmt>",hook up the wil fallback error tracer in terminal
2255,<desc> i looked at all public stdlib drop implementations and categorized them into insigificant/maybe/significant drop. reasons are noted here:  one thing missing from this pr is tagging hashmap as insigificant destructor as that needs some discussion. r? @mark-simulacrum </desc> <cmt> 2229: early exit when we see an insigificant drop </cmt> <cmt> 2229: annotate stdlib with insignficant dtors </cmt> <cmt> update tests </cmt> <cmt> handle type params in insig dtors </cmt>,mark insignificant dtor in stdlib
2256,"<desc> jira: </desc> <cmt> fixed spring context test in spring-data-rest-querydsl module </cmt> <cmt> fixed spring-ejb/spring-ejb-client context tests, removed contextintegrationtest and added a note to the contextlivetest. plus, redefined spring-ejb-remote url in pom, it was not working properly' </cmt> <cmt> fixed context test in spring-remoting/remoting-jms/remoting-jms-server, added notes for live test </cmt> <cmt> fixed context test in spring-remoting/remoting-rmi\remoting-rmi-server, added notes for live test </cmt> <cmt> fixed context test in spring-rest-query-language, added note for contexttest and deleter contextintegrationtest </cmt>",fix failing context tests - part 2
2257,<desc> this drastically improves audio clicky on boards with loud switches -- see the feature_audio.md update.  if you configure a click delay then you can have the audio clicky happen after the physical click. </desc> <cmt> adding an audio_clicky_delay_duration configurable value to the audio_clicky feature. </cmt> <cmt> tweaking my community keymap to work better with my rev 4 planck. </cmt>,adds a configurable initial delay to the audio clicky feature.
2258,"<desc> moved definitions from global ( evil :) ) context to 'restify' module/namespace. added inheritance of server, request and response from nodejs 'http' module. removed 'on' method from server definition, now is inherited from http.server added 'body' property to request interface still compilable with --noimpicitany flag. documentation here: </desc> <cmt> moved definitions from global (evil) context to 'restify' module/namespace, added inheritance of server, request and response from nodejs 'http' module </cmt> <cmt> removed 'on' method from server definition, it is inherited now </cmt> <cmt> removed 'on' method from server - it is inherited now. added body property to request definition </cmt>","moved definitions to 'restify' namespace, added inheritance of server, request and response"
2259,"<desc> allow passing fetches to tf.session.run() in k.function() in tensorflow backend. allow passing additional operations, such as stagingarea.put() previously (#6693) only options and run_metadata could have been passed note that providing feed_dict substitutions doesn't make much sense here since: they can be passed in the input argument if they're passes via kwargs in model.compile() the values would be constant the main reason is to allow using tensorflow stagingarea for copying input data to gpu asynchronously. a working implementation of such as pipeline is in stagingareacallback. several examples are provided (mnist, cifar10, resnet50. example usage (pseudocode): features_tensor, labels_tensor = ... next batch ... area = tf.contrib.staging.stagingarea( dtypes=[tf.float32, tf.float32]) area_put = area.put([features_tensor, labels_tensor]) area_get_features, area_get_labels = area.get() input = model(tensor=area_get_features) model = ... create model ... model.compile(optimizer='sgd', loss='categorical_crossentropy', target_tensors=[area_get_labels], fetches=[area_put]) this approach is inspired by </desc> <cmt> allow passing fetches and feed_dict to tf.session.run() in k.function() in tensorflow backend. </cmt> <cmt> - allow passing additional operations, such as stagingarea.put() </cmt> <cmt> - allow passing additional tensor substitutions, such as for feedable iterators (dataset api) </cmt> <cmt> - previously (#6693) only options and run_metadata could have been passed </cmt> <cmt> - note that provided feed_dict substitutions are merged with substitutions from inputs </cmt> <cmt> remove passing feed_dict to tf k.function() since it would be constant. </cmt>",tensorflow k.function() additional ops via fetches
2260,<desc> v-bind & : v-if v-else v-else-if v-for v-on & @ </desc> <cmt> feat($compiler): supports compiling v-bind to the weex native directive in recycle-list </cmt> <cmt> feat(compile): supports compiling v-if to the weex native directive </cmt> <cmt> feat($compiler): supports compiling v-for to the weex native directive </cmt> <cmt> feat($compiler): compile weex native directives in pretransformnode </cmt>,implement weex native directive compiler for <recycle-list>
2261,"<desc> this adds keyboard support for jj4x4 which is almost exact copy of the jj40 except the keys are arranged differently on the microcontroller lines. everything is copied from the jj40 keyboard files except the key mapping which i managed to reverse engineer. the jj4x4 pcb is populated identically as the jj40 so i assume everything else is the same, and indeed it seems to flash and work fine. checklist: my code follows the code style of this project. i have read the contributing document. ( **i've edited the readme.md to reflect the changes. it is essentially the jj40 documentation, but half the stuff in there i have no idea about so i've left it in there. </desc> <cmt> added keyboard jj4x4, a shorter version of the jj40 </cmt> <cmt> removed useless file </cmt> <cmt> edited jj4x4 readme.md </cmt>",support for jj4x4 numpad/macropad by kprepublic
2262,<desc> deprecation the expansionpanel components were renamed to accordion. the old imports will be removed in v5. -import { expansionpanel } from '@material-ui/core'; +import { accordion } from '@material-ui/core'; this pr cherry picks changes from #21494 to be merged in master. also cover #21630 ### question should we revert the changes in the examples and docs api pages? </desc> <cmt> [expansionpanel] rename to accordion (#21494) </cmt> <cmt> * wip </cmt> <cmt> * wip </cmt> <cmt> * reverted some changes </cmt> <cmt> * sorting </cmt> <cmt> * migration </cmt> <cmt> * fix in migration </cmt> <cmt> * fix in migration </cmt> <cmt> * fix in migration </cmt> <cmt> * update docs/src/pages/getting-started/supported-components/supported-components.md </cmt> <cmt> * added redirect </cmt> <cmt> * fixed material design links </cmt> <cmt> * codemod fix </cmt> <cmt> * prettier + formatted </cmt> <cmt> * changed accordions to accordion </cmt> <cmt> * docs:api </cmt> <cmt> * renamed accordions to accordion </cmt> <cmt> * update docs/src/pages/components/accordion/accordion.md </cmt> <cmt> * update docs/src/pages/components/accordion/accordion.md </cmt> <cmt> * update docs/src/pages/components/accordion/accordion.md </cmt> <cmt> * added deprecated exports for expansionpanel components </cmt> <cmt> * added motivation for renaming component </cmt> <cmt> * update docs/src/pages/components/accordion/accordion.md </cmt> <cmt> * update docs/src/pages/guides/migration-v4/migration-v4.md </cmt> <cmt> * update docs/src/pages/guides/migration-v4/migration-v4.md </cmt> <cmt> * cleandup migration </cmt> <cmt> * prettier </cmt> <cmt> * changed comments on deprecated components </cmt> <cmt> * removed </cmt> <cmt> * reverted del files </cmt> <cmt> * renamed </cmt> <cmt> * fixed d.ts fiels </cmt> <cmt> * r </cmt> <cmt> * added </cmt> <cmt> * renamed </cmt> <cmt> * renamed types </cmt> <cmt> * redirects </cmt> <cmt> * revert markdown source changes </cmt> <cmt> * move markdown source from expansion-panel to accordion </cmt> <cmt> * expansion panel -> accordion </cmt> <cmt> * revert attempt at renaming </cmt> <cmt> docs:api </cmt>,"rename to accordion, add warning to current exports"
2263,"<desc> when streaming and following a container log, no response headers are sent from the kubelet containerlogs endpoint until the first byte of content is written to the log. this propagates back to the api server, which also will not send response headers until it gets response headers from the kubelet. that includes upgrade headers, which means a websocket connection upgrade is not performed and can time out. to recreate, create a busybox pod that runs /bin/sh -c 'sleep 30 && echo foo && sleep 10' as soon as the pod starts, query the kubelet api: curl -n -k -v ' or the master api: curl -n -k -v ' in both cases, notice that the response headers are not sent until the first byte of log content is available. this pr: does a 0-byte write prior to handing off to the container runtime stream copy. that commits the response header, even if the subsequent copy blocks waiting for the first byte of content from the log. fixes a bug with the ""ping"" frame sent to websocket streams, which was not respecting the requested protocol (it was sending a binary frame to a websocket that requested a base64 text protocol) fixes a bug in the limitwriter, which was not propagating 0-length writes, even before the writer's limit was reached this change is </desc> <cmt> send ping frame using specified encoding </cmt> <cmt> if base-64 encoding was requested, send the ping frame as a 0-length text frame, rather than as a 0-length binary frame. </cmt> <cmt> make limitwriter respect 0-byte writes until limit is reached </cmt> <cmt> do initial 0-byte write to stdout when streaming container logs </cmt>",fix hang/websocket timeout when streaming container log with no content
2264,<desc> this is a continuation of pr #2320 adds tests to validate date serialization & deserialization in iso format adds support to pick timezone randomly in the date related tests fixes failing test for localdatetime in some timezones </desc> <cmt> feat(test): add support to run tests with different timezones </cmt> <cmt> * randomly pick timezones before running the test </cmt> <cmt> fix(test): correct the failing test in different timezones </cmt> <cmt> * json.defaulttimezone needs to be overriden as this would </cmt> <cmt> have already initialized </cmt>,add support to run date tests in different timezones
2265,"<desc> also adds a health check command to our docker image for being able to see health with docker ps. docker hub automatically runs this file after building an image. example build at  currently, the test just curl's the health endpoint, without jq. this doesn't actually test until line/armeria#2088 - i figured since this is a new test, it's not worth getting too complex finding a reputable image with curl and jq and can wait until that's in to finish it. </desc> <cmt> add docker test and health check. </cmt> <cmt> pre_build instead of build since it sets up builds. </cmt> <cmt> add docker test and health check. </cmt> <cmt> update docker-compose.test.yml </cmt>",adds a docker-compose.test.yml to do a health check of built container.
2266,"<desc> removed schwapi.lib, shcore.lib from project dependencies, added link into the dpi_aware.h pr checklist applies to #5907 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx </desc> <cmt> warning: __null_import_descriptor already defined in shlwapi.lib(shlwapi.dll) </cmt> <cmt> added missing lib </cmt>",additional dependencies in common project
2267,<desc> the following changes (hopefully) make it feasible to run release-1.1 branch conformance tests on master code in mesos environments. this should also fix mesos smoke tests on cherry-pick prs to release-1.1. backport contrib/mesos/ci to release-1.1 #17511 #17842 #17835 skip [skipped] tests when testing for conformance #17180 add cluster/test-conformance.sh script #17997 support passing args to cluster/test-smoke.sh #15404 support annotated tags in conformance test version detection #17839 (this only affects smoke/conformance tests. so e2e tests are not required.) </desc> <cmt> backport contrib/mesos/ci to release-1.1 </cmt> <cmt> backport smoke/conformance test script changes </cmt> <cmt> - skip [skipped] tests when testing for conformance #17180 </cmt> <cmt> - add cluster/test-conformance.sh script #17997 </cmt> <cmt> - support passing args to cluster/test-smoke.sh #15404 </cmt> <cmt> - support annotated tags in conformance test version detection #17839 </cmt>,backport smoke/conformance test harness changes to release-1.1 from master
2268,"<desc> a direct comparison to google's official model seems quite hard - not sure if that's absolutely needed @thomwolf, @craffel but some integration tests for t5 would be very nice, to be sure that changes in the future will not break t5. this pr adds hard-coded integration tests, where the input for summarization is copied from bart's summarization tests and the input for translation is taken from appendix d of the official paper checking the expected output for pt, one can see that the output looks quite good! add pytorch integration tests verify quality (subjectively for the moment) add tf integration tests same output for pt and tf update: found a big bug in tf beam search generation (see comment) -> this pr fixes it </desc> <cmt> add some t5 integration tests </cmt> <cmt> finish summarization and translation integration tests for t5 - results loook good </cmt>",add extensive hard-coded integration tests and make sure pt and tf give equal results
2269,"<desc> test_nt_helpers assumed that two versions of a windows path could be compared case-sensitively. this is not the case, and the difference can be triggered (apparently) by running the test on a path somewhere below a junction. this change adds a simple method to compare without considering case and uses it in test_ntpath.testntpath.test_nt_helpers </desc> <cmt> fix case-sensitive comparison </cmt> <cmt> test_nt_helpers assumed that two versions of a windows path could be compared case-sensitively. this is not the case, and the difference can be triggered (apparently) by running the test on a path somewhere below a junction. </cmt>",fix case-sensitive comparison in test_nt_helpers
2270,"<desc> fix #15211 the problem was due to the missing mkldnn_version.h file under include/mkldnn. the mkldnn_version.h is generated at compile time by mkldnn library. it is linked to 3rdparty/mkldnn/build/include when mxnet is built using make, the default build system currently supported in mxnet. an earlier pr #14899 fixed the issue when mxnet is installed by pip. this pr is to fix the build error when mxnet is built from source. thanks @taolv for rootcausing the problem and his suggestions. </desc> <cmt> fix horovod build when mxnet is built from source </cmt> <iss> mxnet with mkldnn failed to install horovod </iss>",fix horovod build failure when mxnet is built from source
2271,"<cmt> checkpoint </cmt> <cmt> bpo-33141: add field.__set_name__ and call the default value, if it exists. this allows the descriptor protocol's __set_name__ to work. </cmt> <cmt> remove unused code from an early implementation. </cmt> <cmt> added blurb. </cmt>",have dataclasses.field pass through __set_name__ to any default descriptor.
2272,<desc> add myself as creator add project petite&minimal add project petite&minimal concept store demo </desc> <cmt> add annie pic via upload. </cmt> <cmt> profile pic for annie taylor chen. </cmt> <cmt> update creator.yml by adding annie. </cmt> <cmt> information about annie taylor chen. </cmt> <cmt> update creator.yml by adding annie. </cmt> <cmt> add annie pic via upload. </cmt> <cmt> update sites.yml - add two projects by me </cmt> <cmt> add two projects: </cmt> <cmt> - petite & minimal  - eco-friendly lifestyle website </cmt> <cmt> - petite & minimal concept store demo for jamstack e-commerce solution </cmt>,add annie as creator and add two projects.
2273,<desc> moves the keyword tokenizer to the analysis-common module. the keyword tokenizer is special because it is used by customnormalizerprovider so i pulled it out into its own pr. to get the move to work i've reworked the lookup from static to one using the analysisregistry. this seems safe enough. part of #23658. </desc> <cmt> repipe keyword analyzer </cmt> <cmt> drop now unused </cmt> <cmt> move pre-configured keyword tokenizer to analysis common </cmt>,"move pre-configured ""keyword"" tokenizer to the analysis-common module"
2274,"<desc> dont look at the changes, its huge, instead check the individual commits re-enable shadows for the bullet tests, use basebullettest.shadows to enable/disable them. we might want to disable them for ios. update to swig 2.0.12, nothing changed thats relevant to the wrapper. update to bullet project to visual studio 2013 (still use vs2010 emulation) add charactertest to show how to use btkinematiccharactercontroller changed gl10 to gl20 in the swig interface pathtest was removed in 38e6533, added it back and updated it to gles20. </desc> <cmt> re-enable shadows for bullet, made them optional. </cmt> <cmt> update to swig 2.0.12 (afaik no relevant changes) </cmt> <cmt> vs2013 </cmt> <cmt> add charactertest </cmt> <cmt> conflicts: </cmt> <cmt> tests/gdx-tests/src/com/badlogic/gdx/tests/bullettestcollection.java </cmt> <cmt> tests/gdx-tests/src/com/badlogic/gdx/tests/bullet/basebullettest.java </cmt> <cmt> bullet: remove gl10 </cmt> <cmt> resurrect pathtest </cmt>","various changes, mostly bullet related"
2275,"<desc> add a new attribute textsecondary to listitemtext component classes property. it allows customising secondary text styles separately from the primary text. breaking change <listitem classes={{ -   text: 'my-class', +   textprimary: 'my-class', }} /> closes #9223 </desc> <cmt> feat: [listitemtext] add class property to allow customize secondary text style </cmt> <cmt> test: [listitemtext] add test for classes.text and classes.textsecondary </cmt>",add extra class to style secondary text
2276,"<desc> make it clear that 1.10.5 was a minor release, and that there are no breaking changes in the release. </desc> <cmt> fix whitespace </cmt> <cmt> make it clear that 1.10.5 wasn't accidently omitted </cmt>",make it clear that 1.10.5 wasn't accidentally omitted from updating.md
2277,<desc> the empty bytes object (b'') and the 256 one-character bytes objects are allocated at runtime init.  here we statically allocate and initialize them. </desc> <cmt> _py_bytes_state -> _py_global_objects. </cmt> <cmt> statically initialize the empty bytes object. </cmt> <cmt> statically initialize the single character bytes objects. </cmt> <cmt> reset the hash when re-initializing. </cmt>,statically allocate and initialize global bytes objects.
2278,"<desc> this is a documentation backport of #25216. out of the 4 commits, only the first commit was regenerated with the script. the other 3 were cherry-picked. r? @steveklabnik </desc> <cmt> squeeze the last bits of tasks in documentation in favor of thread </cmt> <cmt> an automated script was run against the .rs and .md files, </cmt> <cmt> subsituting every occurrence of task with thread. in the .rs </cmt> <cmt> files, only the texts in the comment blocks were affected. </cmt> <cmt> fix invalid references due to the automated string substitution </cmt> <cmt> please the make tidy </cmt> <cmt> fix the tests broken by replacing task with thread </cmt>",backport task -> thread to beta
2279,"<desc> currently bufferprovider#requestbufferblocking method is only used for unit tests, so we could refactor the related tests to use methods of bufferprovider#requestbufferbuilderblocking or bufferprovider#requestbuffer instead. then we could remove this legacy method completely to clean up the interface. remove legacy class nullableasyncdatainput remove optional class field from localbufferpool remove interface method bufferprovider#requestbufferblocking refactor the relevant unit tests for the removal of bufferprovider#requestbufferblocking the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, yarn/mesos, zookeeper: (yes / no / don't know) </desc> <cmt> [hotfix][task] fix the code formatting in streamtask </cmt> <cmt> [hotfix][runtime] remove legacy nullableasyncdatainput class </cmt>",remove unnecessary interface method bufferprovider#requestbufferblocking
2280,"<desc> add or edit tests to reflect the change. run npm test follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: bookshelf/bookshelf#1779, bookshelf/bookshelf#2005, bookshelf/bookshelf#2006, bookshelf/bookshelf#1699 if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed dear reviewers, i would suggest checking commit by commit bc i had to run prettier. best regards. </desc> <cmt> new require: true documentation </cmt> <cmt> remove removed methods </cmt> <cmt> add myself to definitions by </cmt> <cmt> update version header </cmt> <cmt> run prettier </cmt>","prettier, methods removed and update options"
2281,"<desc> description of the change this pull request stops transpiling (via babel) javascript files located in the following folders: benchmarks exports src please, note that we still transpile core packages. eventually, it might be worth transitioning away from babel for those as well. alternate designs none. why should this be in core? core is where transpilation and packaging takes place. benefits reduced complexity of the build, which now only transpiles babel files found in core packages. smaller footprint for js files, thanks to removing source maps. easier debugging, thanks to removing babel async generators. possible drawbacks unclear, but theoretically none. verification process run tests and see that they pass. run atom and see that no syntax error occurs. snapshots are generated correctly. /cc: @atom/maintainers </desc> <cmt> don't transpile js files found in benchmarks, exports and src folders </cmt> <cmt> replace import and export keywords with require and module.exports </cmt>","stop using babel in atom core (benchmarks, exports, src)"
2282,"<desc> label docstrings with versionadded #15426 closes #15494 continuing work by @harini-sridhar for sf #wimlds sprint (nov 2019) </desc> <cmt> added sphinx versionadded to timeseriessplit docstring (issue #15426) </cmt> <cmt> added sphinx versionadded to docstrings of plscanonical, plsregression, plssvd, patchextractor, pipeline, powertransformer, predefinedsplit (issue #15426) </cmt> <cmt> moving 'versionadded' to before parameters section </cmt> <cmt> fixed flake8 whitespace errors </cmt>",doc add versionadded directive to some estimators
2283,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: gabrieldonadel/rn-material-ui-textfield#23 (comment) </desc> <cmt> updated spelling to textfield prop </cmt> <cmt> updated codeowners and version bump </cmt>,fix prop misspelling for rn-material-ui-textfield
2284,"<desc> this pr, implements a new submenu in the control menu: advanced settings it is going to be more populated on the future, but now, has five items, submenu home offsets, submenu probe offsets (only visible when exist a leveling probe), hotend pid, bed pid and powerlost recovery enabler. ender 3v2 with a dwin display, but could be user with any ender with a dwin display a new submenu, where to put special settings not available to the user in stock firmware. configurations.zip </desc> <cmt> merge with upstream marlin bugfix 2.0.x </cmt> <cmt> merge upstream bugfix 2.0.x </cmt> <cmt> merge upstream bugfix 2.0.x </cmt> <cmt> implement menu advanced settings </cmt> <cmt> probe offsets </cmt> <cmt> hotend pid </cmt> <cmt> bed pid </cmt>",new advanced settings menu for ender3v2 with dwin display
2285,"<desc> updated parsing of the runtime version to allow reading version from other runtimes like crun as discussed on containers/crun#77. used ""version"" as the separator. added test case for new scenario. docker daemon correctly parses the runtime version for runtimes different from runc. (yep, it's my cat again... ) </desc> <cmt> parse runtime name </cmt>",change version parsing to support alternate runtimes
2286,"<desc> currently the custom onerror handler for httpproxymiddleware only logs proxy error on the console (#502).  this amends the onerror handler so it will also send proper error response to the client. otherwise the client will wait for the response and eventually timeout with err_empty_response, instead of the proper proxy error.  see two screenshots before/after this pr. no proper error response  (timeout after up to 2 min): proper error response (with this pr): note the error response to the client also mirrors the error logged on the dev console: proxy error: could not proxy request /api/login from localhost:3000 to </desc> <cmt> change http-proxy-middleware loglevel from silent to error </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> provide onerror handler for httpproxymiddleware </cmt> <cmt> send proper error reponse upon proxy error. </cmt> <cmt> merge with latest upstream </cmt>",send proper error response upon proxy error
2287,"<desc> i recently went through all 8 steps of the gatsby tutorial pages and thought the documentation was fantastic. but i did come across a very small number of lines that i thought with a tweak could have saved me a couple of minutes, so have made them here and added them in as a pr. they are pretty simple: made the localhost:9000 a link in part-eight (which i found super useful in the early parts) made a dummy .png icon for part-eight to enable people to run through the tutorial if they don't have a 512x512 png handy. amended some code block highlighting in part-four, where two lines differ from previously mentioned code in the tutorial, but aren't highlighted. added a restart the development server note to part-seven, where it wasn't obvious it was needed. amended contents of the part-eight code blocks + highlighting to make it feel like the parts are joined together, given they all point to the requirements needed for lighthouse & pwa's. </desc> <cmt> amended code highlights for staticquery section </cmt> <cmt> i noticed running through the tutorial that lines 306 and 353 do actually change, but were not highlighted in the code block. </cmt> <cmt> the beginning of the export has a curly brace at the front at this point, as does the end, but earlier in the tutorial it opens and closes with parentheses. the code worked when copying and pasting but i was typing in the highlighted changes, in an attempt to learn through doing, so i'm updating the documentation, just in case anyone is doing the same and would like it to be a little clearer! </cmt> <cmt> i've also removed a redundant //highlight-start and //highlight-end at 318 and 319 </cmt> <cmt> added note to restart the development server </cmt> <cmt> i got caught on this for a few minutes, as it doesn't explicitly say you need to restart the development server to verify whether this worked or not. added a note. </cmt> <cmt> made localhost a link and clearer tutorial code blocks </cmt> <cmt> as i was reading this, it felt like the sections in the tutorial were less linked to each other than in the previous sections, given the three packages mentioned all related to the lighthouse auditing tool. so i made the code-blocks include the same continual code, with highlighting to add what changed in each block, rather than the blocks in isolated. </cmt> <cmt> i also made the localhost:9000 a proper link, and added a dummy gatsby coloured icon to the tutorial so people could test this out better without having to source one. </cmt> <cmt> localhost:9000 as url </cmt> <cmt> last commit wasn't formatted correctly. </cmt> <cmt> adding dummy icon file </cmt> <cmt> tweaked offline-plugin note relating to order </cmt> <cmt> as this section refers to the offline plugin, it feels like it makes sense to denote where it goes, rather than what comes before it. </cmt> <cmt> updating icon image path </cmt> <cmt> updating icon img path </cmt>","update tutorial documentation part 4, 7 & 8"
2288,"<desc> removes some parser functions that were moved into the go-connections package. </desc> <cmt> upgrade vendored github.com/docker/go-connections to latest version, which includes new nat parse functions. </cmt> <cmt> remove unused parser functions that were replaced by go-connections/nat. </cmt>",update go-connections vendor to pickup addition of parser functions
2289,"<desc> no intended functionality change; this just makes things easier to read and makes the encapsulation for helper functions a little clearer. serializer equivalent of #22610. </desc> <cmt> [serialization] start splitting up decl serialization using a visitor </cmt> <cmt> there's a big switch now; separate functions will make this a little </cmt> <cmt> easier to read. the writing side of f637c754. </cmt> <cmt> [serialization] finish factoring the switch out to declserializer </cmt> <cmt> [serialization] factor out common code for {pre,post}fixoperatordecl </cmt> <cmt> [serialization] push more of writedecl into declserializer </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] move attribute serialization into declserializer </cmt> <cmt> [serialization] move a bunch of helpers to declserializer </cmt> <cmt> ...and off of the main serializer class. no functionality change. </cmt>",replace 'switch' in writedecl with a declvisitor
2290,"<desc> dsu_path_compression.cpp : using path compression o(1) dsu_union_rank.cpp : using union rank to keep track of parent[i] in o(logn). class based to provide accessibility to operations efficiently. also housekeeping for maximal and minimal elements of each set(chunk). documentation and explanation of the concept as code progresses with test case and implementation. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines this a pretty detailed implementation of disjoint set unions, which is very useful in competitive programming . using class based structure, this file can be directly imported and is ready to be used in other programs. ps: if you want to import this, the main function has to be removed first, i have included it because of the guidelines for pr. </desc> <cmt> add files via upload </cmt> <cmt> # class based dsu </cmt> <cmt> -using path compression to get the best time complexity o(1) </cmt> <cmt> -using union rank to keep track of changes using parent(p) o(logn) </cmt> <cmt> class based dsu : path compression o(1) and union rank o(logn) </cmt> <cmt> class based dsu : path compression o(1) & union rank o(logn) </cmt>",add class based dsu  for path compression o(1) & union rank o(logn)
2291,<desc> demo video clip and formal documentation are available at: </desc> <cmt> finished buildpointlist </cmt> <cmt> added houghcircles in ocl.hpp </cmt> <cmt> removed useless comments in buildpointlist_gpu() </cmt> <cmt> finished ocl::houghcircles </cmt> <cmt> fixed a typo in ocl.hpp </cmt> <cmt> added unit test for houghcircles </cmt> <cmt> added performance test </cmt> <cmt> added documentation for ocl::houghcircles </cmt>,added houghcircles in ocl module
2292,"<desc> fix for problem that emerged from #16226 (.active class not actually being applied) and expansion of the script to also correctly handle keyboard interaction with checkboxes in data-toggle=""buttons"" groups also includes removal of an apparently broken/vestigial unit test which tested a scenario not covered by our documentation (and logic) </desc> <cmt> fix radio and checkbox keyboard handling </cmt> <cmt> fix for problem that emerged from #16226 (.active class not actually </cmt> <cmt> being applied) and expansion of the script to also correctly handle </cmt> <cmt> keyboard interaction with checkboxes in data-toggle=""button"" groups </cmt> <cmt> remove broken/vestigial unit test </cmt> <cmt> overall logic for this test appears broken, possibly relating to an </cmt> <cmt> older version of bootstrap that did not require explicit </cmt> <cmt> data-toggle=""button"" on single toggle buttons? </cmt>",fix radio and checkbox keyboard handling in .btn-group
2293,"<desc> i found it useful to filter out all the fast tcp connects so that i can only see slow ones that were causing issues. to solve this i added -m and -u options to tcpconnlat. the latency filter is only added when the min latency is set to something greater than zero. i also added the -v option to print out the bpf program. i know this was already controlled with the debug setting in the python script, but this makes it a bit more consistent with some of the other scripts here. </desc> <cmt> adding a couple of optional parameters to tcpconnlat. </cmt> <cmt> 1. adding -m and -u parameters for filtering tcp connects with greater the specified minimum latency. </cmt> <cmt> 2. adding -v option to print out the bpf program. this is helpful for debugging and is a bit more consistent with some of the other bpf tools. </cmt> <cmt> the latency check is only added if -u or -m have been set to greater than 0. </cmt> <cmt> re-using already calculated delta_us in tcpconnlat </cmt>",adding minimum latency filter to tcpconnlat
2294,<desc> merge-insertion sort algorithm from abandoned pr #246 with due credit given to its original author. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines </desc> <cmt> create merge-insertion sort.cpp </cmt> <cmt> fixed file path </cmt> <cmt> working code </cmt> <cmt> added documentation </cmt>,added merge-insertion sort from #246
2295,"<desc> on master (c8bae2b), the size of the vcpkg binary cache is potentially unbounded. the reason of such behavior is the internal caching logic, following which, any change in the set of parameters defined by the vcpkg implementation will cause compiling of a new binaries following by adding them to the current cache. this pr defines two obvious cases when the vcpkg binary cache will be invalidated. </desc> <cmt> ci, refactor: rename vcpkg_tag variable and vcpkg_cache script </cmt> <cmt> the vcpkg_tag variable renamed to ci_vcpkg_tag to prevent any possible </cmt> <cmt> name clash with vcpkg-specific variables. </cmt> <cmt> the vcpkg_cache script renamed into more meaningful one. </cmt> <cmt> ci: improve vcpkg binary cache settings </cmt> <cmt> this change comes with two improvements: </cmt> <cmt> 1) using the vcpkg_default_binary_cache variable drops dependency on </cmt> <cmt> vcpkg default cached archives location, and improves readability </cmt> <cmt> 2) two obvious cases when binary cache is invalidated are defined, that </cmt> <cmt> guaranties it won't grow boundlessly when, for example, vcpkg has being </cmt> <cmt> updated. </cmt>",define cases when invalidate vcpkg binary cache
2296,"<desc> the main goals of this pr include: improving consistency on how strict the test suite is -- jelle has seen cases where a test did not fail to an incomplete test setup even though it should've simplifying tests for both ease of creation and reading via parametrization and helpers reorganizing the test suite by grouping more tests dropping test suite dependencies that aren't strictly necessary the test suite could definitely do with more refactoring, but this is a good first pass. anyway it would've gotten too big to review effectively if i did continue on this pr. add a changelog entry if necessary? -> n/a add new / update outdated documentation? -> n/a -- i'll add test suite docs later review notes i strongly suggest reviewing commit-by-commit as the total diff is rather big due to the various moves i did. the first commit will probably be still annoying to review (as i didn't split the move and the refactor into two commits) but everything else should be well scoped -- i hope. </desc> <cmt> drop parameterized dep and refactor format tests </cmt> <cmt> since the test suite is already using pytest-only features we can drop </cmt> <cmt> the parameterized test dependency in favour of pytest's own offering. </cmt> <cmt> i also added an utility function called assert_format that makes it </cmt> <cmt> even easier to verify black formats some code correctly. we already </cmt> <cmt> have great tooling if the case is very simple in test_format.py but </cmt> <cmt> any sort of complication makes it hard to use. also if you're writing </cmt> <cmt> a non-standard test case, you have to be careful to include all of </cmt> <cmt> the steps so issues don't go undetected. assert_format aims to </cmt> <cmt> 1) improve consistency, 2) avoid wasted cpu cycles, and 3) avoid </cmt> <cmt> logical errors that hide issues. </cmt> <cmt> finally, quite a few tests were either moved and/or simplified with </cmt> <cmt> the new setup. </cmt> <cmt> move file collection tests </cmt> <cmt> add assert_collected_sources helper function </cmt> <cmt> testing source collection involves a lot of repetitive boilerplate, </cmt> <cmt> something that black.files.get_sources's signature does not help with. </cmt> <cmt> so to cut down on boilerplate like report=black.report() i added </cmt> <cmt> a convenience function to tests/test_black.py which wraps </cmt> <cmt> black.get_sources. its signature is designed to be much more lax to </cmt> <cmt> make it much easier to use. somehow this leads to cutting 100 lines! </cmt> <cmt> also imo the test cases are much easier to read since it's more </cmt> <cmt> declarative than really procedural now. </cmt> <cmt> run isort on some test files </cmt> <cmt> move cache tests </cmt> <cmt> use pytest-style asserts & add parametrization </cmt> <cmt> drop now unnecessary test dependencies </cmt> <cmt> *pytest-cases might be interesting for further refactoring but i </cmt> <cmt> haven't been able to wrap my head around it for the time being. we </cmt> <cmt> can always revisit anyway. </cmt>",remove unnecessary test deps + some refactoring
2297,<desc> several things this code review addresses: partial overload resolution for signature help recognize trailing comma in more places simplify calls for new language service api fixes to syntactically driven overload selection rules in signature help. </desc> <cmt> fix arity checking for partial overload resolution </cmt> <cmt> record trailing comma even for incorrectly terminated lists </cmt> <cmt> remove getcurrentargumentstate </cmt> <cmt> add test for empty arguments and arity filtering </cmt> <cmt> parse omittedexpression for missing arguments followed by commas </cmt> <cmt> fix argumentcount and selecteditemindex </cmt>,various small fixes related to signature help
2298,"<desc> it does this in the parser instead of piecemeal in the checker. this means that the checker has some unused error checking code, so i took the opportunity to move the type predicate checking code into checktypepredicate instead of checksignaturedeclaration where it was previously. fixed #5903 and #5731. obsoletes prs #5936 and #5977. @ahejlsberg and @weswigham, can you take a look? </desc> <cmt> parse type predicates only in return types. </cmt> <cmt> fix lint </cmt> <cmt> add tests and accept baselines </cmt> <cmt> move type predicate checking to checktypepredicate </cmt> <cmt> also remove now-unused ""type predicate is only allowed as a return type"" </cmt> <cmt> diagnostic. </cmt> <cmt> accept baselines </cmt>",allow type predicates as return types only
2299,"<desc> description: this pull request adds a state to rfxtrx cover entities (open/closed). rfxtrx covers didn't had a state, like lights and switches. the state is also updated when using a remote, if the rfxtrx433 transceiver is able to receive commands for the specific protocol. this can be checked in the rfxtrx433 manual, for example, the rfy protocol won't be able to update the state when using the remote, as it only supports transmitting signals, not receiving. also fixed some small black formatting issues. related issue (if applicable): fixes #24658 (this issue was already closed with a workaround, but i assume the workaround won't be needed anymore) pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: </desc> <cmt> add state to rfxtrx cover </cmt> <cmt> add state to rfxtrx cover (cover.py) </cmt> <iss> google assistant - bug with stateless cover </iss>",add state to rfxtrx covers
2300,"<desc> due to the missing archunit. prefix, the ci would not fail if violations were removed with a change; this creates unnecessary and unrelated changes to the violation store for anyone running the tests. see also  dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? not applicable </desc> <cmt> [flink-25241][architecture] add missing prefix for archunit </cmt> <cmt> this fails the ci if violations are removed, ensuring that the violation </cmt> <cmt> store is updated properly. </cmt> <cmt> [flink-25241][hotfix] remove resolved violations </cmt>",ensure ci fails when violations are resolved
2301,"<desc> obviously the font-class is still very large, given particularly how truetype fonts are handled, however this patch-series at least improves things by moving a number of functions/classes into their own files. as a follow-up it might make sense to try and re-factor/extract the truetype parsing into its own file, since all of this code is quite old, however that's probably best left for another time. for e.g. gulp mozcentral, the built pdf.worker.js files decreases from 1 620 332 to 1 617 466 bytes with this patch-series. </desc> <cmt> move the opentypefilebuilder from src/core/fonts.js and into its own file </cmt> <cmt> enable the no-var rule in the src/core/opentype_file_builder.js file </cmt> <cmt> these changes were made automatically, using gulp lint --fix. </cmt> <cmt> convert src/core/opentype_file_builder.js to use standard classes </cmt> <cmt> move the identitytounicodemap/tounicodemap from src/core/fonts.js and into its own file </cmt> <cmt> enable the no-var rule in the src/core/to_unicode_map.js file </cmt> <cmt> these changes were made automatically, using gulp lint --fix. </cmt> <cmt> convert src/core/to_unicode_map.js to use standard classes </cmt> <cmt> move some constants and helper functions from src/core/fonts.js and into their own file </cmt> <cmt> - fontflags, is used in both src/core/fonts.js and src/core/evaluator.js. </cmt> <cmt> - getfonttype, same as the above. </cmt> <cmt> - macstandardglyphordering, is a fairly large data-structure and src/core/fonts.js is already a *very* large file. </cmt> <cmt> - recoverglyphname, a dependency of type1fontglyphmapping; please see below. </cmt> <cmt> - seac_analysis_enabled, is used by both type1font, cfffont, and unit-tests; please see below. </cmt> <cmt> - type1fontglyphmapping, is used by both type1font and cfffont which a later patch will move to their own files. </cmt> <cmt> enable the no-var rule in the src/core/fonts_utils.js file </cmt> <cmt> these changes were made *mostly* automatically, using gulp lint --fix, with the following manual changes: </cmt> <cmt> diff </cmt> <cmt> diff --git a/src/core/fonts_utils.js b/src/core/fonts_utils.js </cmt> <cmt> index f88ce4a8c..c4b3f3808 100644 </cmt> <cmt> --- a/src/core/fonts_utils.js </cmt> <cmt> +++ b/src/core/fonts_utils.js </cmt> <cmt> @@ -167,8 +167,8 @@ function type1fontglyphmapping(properties, builtinencoding, </cmt> <cmt> glyphnames) { </cmt> <cmt> } </cmt> <cmt> // lastly, merge in the differences. </cmt> <cmt> -  let differences = properties.differences, </cmt> <cmt> -    glyphsunicodemap; </cmt> <cmt> +  const differences = properties.differences; </cmt> <cmt> +  let glyphsunicodemap; </cmt> <cmt> if (differences) { </cmt> <cmt> for (charcode in differences) { </cmt> <cmt> const glyphname = differences[charcode]; </cmt> <cmt>  </cmt> <cmt> move the cfffont from src/core/fonts.js and into its own file </cmt> <cmt> enable the no-var rule in the  src/core/cff_font.js file </cmt> <cmt> these changes were made automatically, using gulp lint --fix. </cmt> <cmt> convert src/core/cff_font.js to use standard classes </cmt> <cmt> move the type1font from src/core/fonts.js and into its own file </cmt> <cmt> enable the no-var rule in the src/core/type1_font.js file </cmt> <cmt> these changes were made *mostly* automatically, using gulp lint --fix, with the following manual changes: </cmt> <cmt> diff </cmt> <cmt> diff --git a/src/core/type1_font.js b/src/core/type1_font.js </cmt> <cmt> index 50a3e49e6..55a2005fb 100644 </cmt> <cmt> --- a/src/core/type1_font.js </cmt> <cmt> +++ b/src/core/type1_font.js </cmt> <cmt> @@ -38,10 +38,9 @@ const type1font = (function type1fontclosure() { </cmt> <cmt> const scanlength = streambyteslength - signaturelength; </cmt> <cmt> let i = startindex, </cmt> <cmt> -      j, </cmt> <cmt> found = false; </cmt> <cmt> while (i < scanlength) { </cmt> <cmt> -      j = 0; </cmt> <cmt> +      let j = 0; </cmt> <cmt> while (j < signaturelength && streambytes[i + j] === signature[j]) { </cmt> <cmt> j++; </cmt> <cmt> } </cmt> <cmt> @@ -248,14 +247,14 @@ const type1font = (function type1fontclosure() { </cmt> <cmt> return charcodetoglyphid; </cmt> <cmt> } </cmt> <cmt> -      let glyphnames = ["".notdef""], </cmt> <cmt> -        glyphid; </cmt> <cmt> +      const glyphnames = ["".notdef""]; </cmt> <cmt> +      let builtinencoding, glyphid; </cmt> <cmt> for (glyphid = 0; glyphid < charstrings.length; glyphid++) { </cmt> <cmt> glyphnames.push(charstrings[glyphid].glyphname); </cmt> <cmt> } </cmt> <cmt> const encoding = properties.builtinencoding; </cmt> <cmt> if (encoding) { </cmt> <cmt> -        var builtinencoding = object.create(null); </cmt> <cmt> +        builtinencoding = object.create(null); </cmt> <cmt> for (const charcode in encoding) { </cmt> <cmt> glyphid = glyphnames.indexof(encoding[charcode]); </cmt> <cmt> if (glyphid >= 0 </cmt> <cmt>  </cmt> <cmt> convert src/core/type1_font.js to use standard classes </cmt> <cmt> enable the no-var rule in the src/core/fonts.js file </cmt> <cmt> these changes were made automatically, using gulp lint --fix. </cmt> <cmt> given the large size of this patch, the manual fixes are done separately in the next commit. </cmt> <cmt> fix the remaining no-var failures, which couldn't be handled automatically, in the src/core/fonts.js file </cmt> <cmt> convert src/core/fonts.js to use standard classes </cmt> <cmt> obviously the font-class is still *very* large, given particularly how truetype fonts are handled, however this patch-series at least improves things by moving a number of functions/classes into their own files. </cmt> <cmt> as a follow-up it might make sense to try and re-factor/extract the truetype parsing into its own file, since all of this code is quite old, however that's probably best left for another time. </cmt> <cmt> for e.g. gulp mozcentral, the *built* pdf.worker.js files decreases from 1 620 332 to 1 617 466 bytes with this patch-series. </cmt> <cmt> remove unnecessary missingdataexception check from getheaderblock </cmt> <cmt> it shouldn't be possible for the getbytes-call to throw a missingdataexception, since all resources are loaded *before* e.g. font-parsing ever starts; see </cmt> <cmt> furthermore, even if we'd *somehow* re-throw a missingdataexception here that still won't help considering where the type1font-instance is created. note how in the font-constructor we simply catch any errors and fallback to a standard font, which means that a missingdataexception would just lead to rendering errors anyway; see </cmt> <cmt> all-in-all, it's not possible for a missingdataexception to be thrown in getheaderblock and this code-path can thus be removed. </cmt>","split the functionality in src/core/fonts.js into multiple files, and use standard classes"
2302,"<desc> description: #30653 added config flow support, and per the review, i added support to update options values during import if they had changed since the last import. as part of trying to add zeroconf discovery in #30949, i realized i didn't actually test for this change , so i added a test and realized it was broken. this pr fixes the update options logic and adds the corresponding tests. note: this should get merged to master along with #30653 related issue (if applicable): fixes issue in #30653 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> fix options update logic during import </cmt> <cmt> add missing tests </cmt> <cmt> fix abort reasons and strings, add missing test </cmt> <cmt> combine steps when testing esn already exists </cmt>",fix options update during import config flow step for vizio component (bugfix for #30653)
2303,"<desc> fixes #9035 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> update my fork with lastest </cmt> <cmt> first commit </cmt> <iss> improve coverage of the documentation </iss>",improve documentation coverage for herbert
2304,"<desc> i have read and agreed to the rethinkdb contributor license agreement </desc> <cmt> 2.4 release notes draft </cmt> <cmt> fix buster and future debian packaging config </cmt> <cmt> use --jobs=auto or -j7 with dpkg-buildpackage, depending on platform </cmt> <cmt> revert changes from dc825eaddcb in create_dmg.py </cmt> <cmt> they break stuff, and python 2.7 is a fine minimum version for macos. </cmt>",v2.4.x packaging config fixes and release notes.md draft
2305,<desc> const enums should be allowed to be exported using an export declaration. the fix is to remove an incorrect check that restricts exporting const enums in export declarations to work only when --preserveconstenums is true. fixes #33060 </desc> <cmt> allow export declaration to reference const enums </cmt> <cmt> update baselines </cmt> <iss> cannot export const enum in export declaration </iss>,fix error when exporting const enums (#33060)
2306,"<desc> issue: #4007 configureviewport was failing if ""viewports"" field was not defined defaultviewport was not persistent with navigation p.s. navigating between stories will always reset to the ""defaultviewport"" value, imo it's a strange behavior when manually changing the viewport and navigating to a different story. p.p.s the branch is called addon-jest/fix-configureviewport but i meant addon-vieport/fix-configureviewport </desc> <cmt> fix ""defaultviewport"" is being not persistent </cmt> <cmt> fix few deprecations </cmt>","addon viewport - fix ""defaultviewport"" configuration"
2307,"<desc> the purpose of this update is to refine the idle timeout functionality on the keymap as well as add layer dependent rgb colors so i can tell at a glance if i left the keyboard in gaming mode or not. idle timeout changes there are now two separate places checking for idle timeout. one is in matrix_scan and it handles switching back to default layer and powering off/on the leds. the other one is still in oled_task but concerns itself with oled functionality. yes there is still a final led powerdown there, just to make triple sure it turns off. layer dependent colors i kept getting tripped up with the gaming layer so now i have it set to purple. that way i can more easily tell if i have left the gaming layer on and need to turn it off. cleaned up the keymap.c a little by splitting some of the layer functions into their own files updated keybinds to remove most of the rgb stuff except for toggle. its the only function i really use. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> added kidbrazil custom keymap for crkbd </cmt> <cmt> -custom font </cmt> <cmt> -custom oled output </cmt> <cmt> added missing readme </cmt> <cmt> oled timeout update for kidbrazil keymap (#1) </cmt> <cmt> * setup oled timeout based on simple timer </cmt> <cmt> * cleaned up comments and added timeout for leds </cmt> <cmt> * fixed some small errors </cmt> <cmt> * updated oled timout with matrix scan </cmt> <cmt> * updated oled timout with matrix scan </cmt> <cmt> * update withou eeprom </cmt> <cmt> * update timer code </cmt> <cmt> * use process user instead of keymap </cmt> <cmt> * added ifdef to protect oledtimer </cmt> <cmt> * updated with half timeout state for logo </cmt> <cmt> * removed middle tier timer </cmt> <cmt> final cleanup of unused files </cmt> <cmt> updated code as per suggestions & requests </cmt> <cmt> second round of revisions </cmt> <cmt> updated keymap to better handle led timeout </cmt> <cmt> - added boolean to hold led state </cmt> <cmt> - added init function to set rgb to known state </cmt> <cmt> - modified rgb_tog to work with noeeprom commands </cmt> <cmt> finished adding the timeout for oled and testing on crkbd </cmt> <cmt> updated documentation </cmt> <cmt> fixed the timeout logic so it works as intended </cmt> <cmt> added initial limits to color settings </cmt> <cmt> added layer reset as part of the iddle timeout process </cmt> <cmt> split keymap into more manageable files </cmt> <cmt> finalizing rgb layer status on crkbd </cmt> <cmt> - refactored oled timeout to deal only with oled </cmt> <cmt> - if user remains iddle on game layer for too long it will switch to </cmt> <cmt> default </cmt> <cmt> - led / oled iddle working </cmt> <cmt> - minor changes to _sym layer </cmt> <cmt> - removed some rgb controls from keyboard due to layer dependent rgb </cmt> <cmt> colors </cmt>",|  crkbd/kidbrazil adding layer dependent rgb & better idle timeout.
2308,"<desc> original pull-request #30230 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> allow identifiers staring with numbers in multiple joins </cmt>",allow identifiers starting with numbers in multiple joins
2309,<desc> convert bench scripts to esm add many_updates bench to ci runs add tachometer-reporter-action to ci workflow upload npm package to github artifacts add deopt script to run v8-deopt-viewer against benches </desc> <cmt> upgrade bench-infra </cmt> <cmt> update ci workflow to upload/download base npm package of preact </cmt> <cmt> add many updates to ci benches </cmt> <cmt> add tachometer-reporter-action to ci workflow </cmt>,upgrade bench infra and add tachometer pr reporter
2310,"<desc> related: #19891 read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> [16185] added localkubernetesexecutor to breeze supported executors </cmt> <cmt> revert ""[16185] added localkubernetesexecutor to breeze supported executors"" </cmt> <cmt> this reverts commit a1c532eacfeddcbefaa3e565a0522e25315286c4. </cmt> <cmt> fix mypy errors in airbyte provider </cmt>",fix mypy airbyte provider errors
2311,"<desc> according to official documentation, the tags should be treated as a string array. the change modifies the type of the tags property and adds it to the render method as documentation follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> parameter update according to mustache documentation </cmt> <cmt> correction in comment </cmt> <cmt> version </cmt>",tags should be a string array
2312,"<desc> first 2 commits revert a wrong fix for a race condition which crashed when switching tv channels. that wrong fix introduced the regression reported in the forum here:  the real fix for the crash is in the 3rd commit. the crash during tv channel switching was because the principal of ""1 consumer, 1 producer"" was broken. the used lockfree ringbuffer implementation is only thread safe if only 1 thread reads and another thread writes to it. in the tv channel switching use case the dvdplayeraudio thread flushs the stream which is a read - this happens while the coreaudio thread still pulls frames from the buffer. we end up in invalid buffer state leading to crash in some racy cases. the solution is to move the flush of the buffer into the coreaudio thread. </desc> <cmt> revert ""[ae/ca] - ooppps - typo in last commit (note to self - commit on the same host you compiled it)"" </cmt> <cmt> this reverts commit 1c7791d9cfa51c469c876324ade7b037bf2d391a. </cmt> <cmt> [ae/ca] - fix regression (stuck ringbuffer after 46min, 62min, 180min - depending on the stream setup). </cmt> <cmt> revert ""[ae/ca] - fix a possible overflow in the ringbuffer during readsize calculation (yes we hit this in pvr branch in internalflush - when zapping channels)"" </cmt> <cmt> this reverts commit e447c4bb34bbc10e1a97ea779eaaafd54a76e3f7. </cmt> <cmt> [ca/ae] - fix race in 2 threads consuming the ringbuffer (dvdplayeraudio calls flush and ca thread still pulls frames) by moving the flush to the ca thread instead - fixes crashing when switching tv channels (this was the real issue the 2 reverted commits before wanted to fix...) </cmt>",fix problem where 2 threads read from our lockfree ringbuffer which is not allowed
2313,<desc> sonar bug fixes using yoda condition in equals expression when comparing string literal with string object. using try-with-resources if we use scanner to close the underlying stream is a good practice to handle resources. minimal refactor. </desc> <cmt> sonar bug fixes using yoda condition in equals expression when comparing string literal with string object. </cmt> <cmt> using try-with-resources if we use scanner to close the underlying stream is a good practice to handle resources. </cmt> <cmt> minimal refactor. </cmt> <cmt> sonar bug fixes using yoda condition in equals expression when comparing string literal with string object. </cmt> <cmt> using try-with-resources if we use scanner to close the underlying stream is a good practice to handle resources. </cmt> <cmt> minimal refactor. </cmt>,sonar quality bugfix and minor refactor
2314,"<desc> use the actual arg parser that creates actual command instances when run via the cli during unit tests, an amazing concept. our artificial constructor arguments have led to several bugs, most recently (and egregiously) #989 (from #960). this also drastically simplifies the tests and makes them much more readable. a whole bunch (the first push will intentionally fail with a #989 repro) i have read the contributing document. </desc> <cmt> fix ambiguous snapshot tests from #960 </cmt> <cmt> add test/helpers/yargsrunner </cmt> <cmt> command: run() returns a promise; better validation errors </cmt> <cmt> diffcommand: migrate tests to yargsrunner </cmt> <cmt> publishcommand: migrate tests to yargsrunner </cmt>",use yargs parser in unit tests for greater fidelity
2315,"<desc> based on discussions in #1181, i've unified the behavior among the subjects. behaviorsubject doesn't seem to exhibit issue #658 and #1184. a second pair of eyes would be great to confirm the correctness and check if the removal of the countdownlatch was the correct approach. </desc> <cmt> behaviorsubject subscription timegap fix </cmt> <cmt> behaviorsubject subscription timegap fix 2 </cmt> <cmt> going lite </cmt> <cmt> some performance improvements </cmt> <cmt> publishsubject to match behaviorsubject </cmt> <cmt> unified the subject management. </cmt>",behavior subject time gap fix 2
2316,<desc> closes #7213. + added some entries in api.rst </desc> <cmt> doc: add some missing entries to api.rst </cmt> <cmt> doc: fix docs after disabling datetime-like series-ops (gh7213) </cmt> <iss> doc: fix doc errors from removing datetime-like series ops </iss>,fix datetime-like series ops in docs + some extra api docs
2317,"<desc> this pr adds an option ignore_comments to the parse and accept family that allows to ignore // and /* */ style comments. ps: i still think there is a good reason json has no comment support. but it was by far the most popular request, and i understand that the lack of comments was a problem for a lot of folks that use json as configuration format. however, comments are still treated as parse error by default. closes #2061 closes #1513 closes #597 closes #376 closes #363 closes #294 related to #2090 #348 (comments only, no full json5 support). related to #311 (comments only, no json schema support) </desc> <cmt> :sparkles: ignore comments </cmt> <cmt> :zap: improve comment parsing </cmt> <cmt> :construction: extend api </cmt> <cmt> :white_check_mark: add tests for comment skipping </cmt> <cmt> :children_crossing: improve diagnostics </cmt> <cmt> :hammer: clean up </cmt> <iss> strip comments / minify </iss> <iss> optional comment support. </iss> <iss> support for comments. </iss> <iss> feature request: comments </iss> <iss> support for comments </iss> <iss> add support for jsonc </iss>",add option to ignore comments in parse/accept functions
2318,<desc> currently only jpeg is allowed add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see </desc> <cmt> allow using jpg as format </cmt> <cmt> currently only jpeg is allowed </cmt> <cmt> update sharp-tests.ts </cmt> <cmt> add  a test for jpg format </cmt>,allow using jpg as a format in sharp package
2319,<desc> the existing code that was being used to prevent seeking to a cut doesn't look like it would have worked ever since the code was changed to use the dts time and flushed seeking rather than the clock time and normal seeking. there's also another small change the prevents the seeking dialog showing for automated seeks by using the trickplay feature for seeking that was added to dvd player some time ago. </desc> <cmt> fixed problem with automatic edl cuts being seeked to multiple times. </cmt> <cmt> change the automatic edl skips so they use the new trickplay api so the gui doesn't show the seeking dialog. </cmt>,edl fix for seeking multiple times to same cut
2320,"<desc> addresses #613 by adding the button in the center of the left border of the primary screen that opens the side panel, and also close button at the bottom of the side panel. the button can be removed via config option. </desc> <cmt> add sidepanel toggle button and close button #613 </cmt> <cmt> add side panel toggle button option </cmt>","add sidepanel button to make ui more intuitive and accessible without keyboard (tablets, etc.)"
2321,"<desc> fixes #7948 implements repeatedkfold and repeatedstratifiedkfold for previous discussion on this, please refer to #7960 </desc> <cmt> add _repeatedsplits and repeatedkfold class </cmt> <cmt> add repeatedstratifiedkfold and doc for repeated cvs </cmt> <cmt> change default value of n_repeats </cmt> <iss> repeated k-fold </iss>",repeated k-fold and repeated stratified k-fold
2322,"<desc> fixed local, roaming and temp definitions on winjs.application object. these should be instances on iohelper as defined in winjs. changed querycollection to be an interface instead of class so that it can extend array interface. in winjs implementaion, querycollection extends array and all array members should be available on querycollection. made element parameter optional in winjs.utilities.query as it is optional in winjs implementation. </desc> <cmt> fixed local, roaming and temp definitions on winjs.application object. these should be instances on iohelper as defined in winjs. </cmt> <cmt> changed querycollection to be an interface instead of class so that it can extend array interface. in winjs implementaion, querycollection extends array and all array members should be available on querycollection. </cmt> <cmt> made element parameter optional in winjs.utilities.query as it is optional in winjs implementation. see </cmt>",fixed type definitions for winjs
2323,<desc> resolves #6075 i have added a new folder with cpp code and a readme file. the pull request somehow got merged with my previous pr so i closed the whole set (as it was not merged) and made a new one. @adichat kindly review it. thanks </desc> <cmt> create wildcard.cpp </cmt> <cmt> create wildcard.md </cmt> <iss> wildcard matching (dynamic programming question) </iss>,new question wildcard matching dp
2324,"<desc> #72533 introduced a regression, causing transforms to timeout/fail. with this change transform only waits for 1 active shard(primary) as waiting for all can block during rolling upgrade fixes #72617 relates #72533 backport #72666 non-issue as #72533 is unreleased, however blocker for 7.13/7.12.2 </desc> <cmt> only wait for 1 active shard(primary) as waiting for all can block during </cmt> <cmt> rolling upgrade </cmt> <cmt> fixes #72617 </cmt> <cmt> unmute #72617 </cmt>",fix rolling upgrade regression introduced in #72533
2325,"<desc> i was able to reproduce the 3x3 avx winograd error on the squeezenet example @nihui . turned out that one of the tile processing loops (the one which only process one tile at a time to be precise) was incorrect. however this was never picked up by the ctest as it was not covering the tiles != 4 test cases. in increasing the ctest coverage it also uncovered some other failing code paths, most notably the forwarddilation_x86 path. for now i have disabled that path, but it seems some kind of memory issue is at fault but i'm not 100% sure. one other problem it uncovered was that the fp16 3x3 winograd implementation for large inputs would deviate by more than 0.2f from the reference implementation. the reason this is happening is that while the reference weights are converted to and from fp16, it doesn't actually go through the same winograd kernel transformation before being used in the forward pass. the fp16 avx 3x3 winograd path actually applies a transformation on the kernel before converting it to fp16, and it seems that the values this transform outputs simply don't convert well to fp16. (probably because the transformed kernel weights are laying further from zero which doesn't work well with the smaller exponent of fp16) i have disabled the forward dilation and fp16 winograd 3x3 kernel for now. i may revisit in a future pr. </desc> <cmt> fix winograd 3x3 avx and extend test converage </cmt> <cmt> fix ctest on non-avx path </cmt>",fix avx wino 3x3 and improve convolution test converage
2326,<desc> r? @nikomatsakis i screwed up the promotion stability checks. big time. they were basically nonexistant. we had tests for it. i also screwed up said tests. this is in stable already :( basically stability checks of promotion only worked if you tried to use a const fn defined in the same crate. </desc> <cmt> properly prevent the promotion of unstable const fns </cmt> <cmt> check cross crate stability of const fn </cmt>,fix promotion stability hole in old borrowck
2327,"<desc> bug currently, when resizing an editor with a markdown preview, the preview shifts all around. add some custom js to handle this better. the js maintains the relative offset when resizing the window. this simple solution isn't perfect because page reflows can cause the elements to shift around relative on the page. i find it better than the current behavior though, and will investigate further improvements with the scrolling sync work. </desc> <cmt> proto </cmt> <cmt> continue proto </cmt> <cmt> basic implementation </cmt>",maintain markdown preview scroll position on window resize
2328,"<desc> for #2144 add springboot configuring method for orchestrationencryptdatasource add springnamespace configuring method for orchestrationencryptdatasource </desc> <cmt> synchronize properties for orchestrationencryptdatasource </cmt> <cmt> synchronize properties for orchestrationencryptdatasource </cmt> <cmt> move unit test to correct package </cmt> <cmt> for #2144, add springboot configuring method for orchestrationencryptdatasource </cmt> <cmt> add unit test for orchestrationencryptdatasource springboot configuring method </cmt> <cmt> for #2144, add springnamespace configuring method for orchestrationencryptdatasource </cmt> <cmt> add unit test for orchestrationencryptdatasource spring namespace configuring method </cmt> <cmt> for checkstyle </cmt>",add spring configuring method for orchestrationencryptdatasource
2329,"<desc> description: there where some type problems when compiling envoy with the default androidndk cpp toolchain version 19. this pr addresses those problems. risk level: medium, some static typing to more concrete types takes place. testing: current test suite. docs changes: n/a release notes: n/a </desc> <cmt> types: fixing some type problems against other architectures </cmt> <cmt> fmt </cmt>",fixing some type problems when compiling against other targets
2330,"<desc> adds ""mathematical formulation"" section to calinski harabasz index and davies-bouldin index, and updates citation for chi and improves mathematical information. note: the dbi information makes a dubious claim: ""a good value reported by this method does not imply the best information retrieval."" without any further information. i was tempted to remove this as i could not find any support in the reference material besides exactly the same sentence on wikipedia, but as i am not totally certain i decided to leave it in. i would be happy to remove that with a further commit if desired. </desc> <cmt> improve / reorganize and clarify docs for calinski-harabasz index </cmt> <cmt> - corrects grammer and adds punctuation </cmt> <cmt> - adds ""mathematical formulation"" subsection </cmt> <cmt> - improves math description and symbols </cmt> <cmt> correct reference for calinski-harabasz index </cmt> <cmt> create math section for davies-bouldin index information </cmt>",improve documentation for chi and dbi clustering metrics
2331,"<desc> add a small walkthrough tutorial to run a project. also add the ray session commands command. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> start project tutorial </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> add output </cmt>",add small tutorial for projects
2332,"<desc> this adds a qmk implementation to run on the excellent 3d printable streamdeck available here:  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add misterdeck handwired 3d-printed streamdeck with potentiometers </cmt> <cmt> add glp2 licences to .h and .c files </cmt>",add misterdeck 3d-printed handwired stream deck with potentiometers as joystick axes
2333,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> initial types </cmt> <cmt> typescript types for recoil </cmt> <cmt> fix lint errors </cmt> <cmt> fix tests </cmt> <cmt> remove unused types </cmt> <cmt> fix prettier error </cmt>",add type definitions for recoil
2334,"<desc> candybar r3 pcbs are using atmega32u4 due to the supply constraint around stm32. the same switch matrix has been maintained so the source is largely unchanged aside from implementing the correct mcu defines and row and column pins. same vid and pid are used so that it will utilize the same via definitions. this has been tested on a preproduction sample and works as intended. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> candybar: added round 3 pcb support </cmt> <cmt> a few pre-merge updates </cmt> <cmt> missed one </cmt> <cmt> two more </cmt>",initial support - tkc candybar r3
2335,<desc> i updated the readme.md regarding issue about globpatterns caching everything in public folder docs can be found in packages/gatsby-plugin-manifest & packages/gatsby-plugin-offline this pr fixes #24480 </desc> <cmt> update globpatterns for manifest plugin </cmt> <cmt> update globpattern for offline plugin </cmt> <cmt> update globpattern for offline plugin </cmt> <iss> (docs): update globpatters for offline & manifest plugin </iss>,update docs about globpatterns in manifest & offline plugin
2336,"<desc> add an implementation of transportsocketcallbacks which does nothing when setreadbufferready() or raiseevent() is call. this implementation is supposed to be used in transportsocket implementation which wraps another socket object. in this case, the underlying socket's callbacks should be suppressed. also add callbacks() in transportsocket interface which is used to get the callbacks passed to settransportsocketcallbacks(). risk level: low (not enabled in main) testing: bazel test //test/... docs changes: n/a release notes: n/a </desc> <cmt> add getter for callbacks in transportsocket which is set via </cmt> <cmt> settransportsocketcallbacks(). </cmt> <cmt> add a new class nooptransportsocketcallbacks. </cmt> <cmt> add a utility class nooptransportsocketcallbacks to hold back callbacks </cmt> <cmt> from underlying socket in a transportsocket implementation which wraps another socket. </cmt> <cmt> move files around </cmt> <cmt> add some implementation to mock class </cmt> <cmt> format </cmt> <cmt> header order </cmt> <cmt> format </cmt> <cmt> format again </cmt>",add an unused implementation nooptransportsocketcallbacks
2337,"<desc> our nightly builds are reporting quite a lot of issues due to use of uninitialized bytes, as reported in #5394. the root cause is inconsistencies between our normal and our nightly pipelines, where our nightly jobs missed ""-dvalgrind"". we thus didn't use the sanitizing macro provided by valgrind for these bytes, causing the warnings. this pr fixes two issues: first, it consolidates -dvalgrind into -duse_leaks_checker=valgrind to avoid above errors going forward. fixing this breaks our bionic builds, though, as they use openssl 1.1, which made struct ssl opaque. the second commit thus switches us over to using our own allocator that initializes all bytes and sets it up for use by openssl, removing the old valgrind macros. added benefit is that this works generically across leaks checkers, even though it's not yet wired up for the others. closes #5394. </desc> <cmt> cmake: consolidate valgrind option </cmt> <cmt> openssl doesn't initialize bytes on purpose in order to generate </cmt> <cmt> additional entropy. valgrind isn't too happy about that though, causing </cmt> <cmt> it to generate warninings about various issues regarding use of </cmt> <cmt> uninitialized bytes. </cmt> <cmt> we traditionally had some infrastructure to silence these errors in our </cmt> <cmt> openssl stream implementation, where we invoke the valgrind macro </cmt> <cmt> valgrind_make_memdefined in various callbacks that we provide to </cmt> <cmt> openssl. naturally, we only include these instructions if a preprocessor </cmt> <cmt> define ""valgrind"" is set, and that in turn is only set if passing </cmt> <cmt> ""-dvalgrind"" to cmake. we do that in our usual azure pipelines, but we </cmt> <cmt> in fact forgot to do this in our nightly build. as a result, we get a </cmt> <cmt> slew of warnings for these nightly builds, but not for our normal </cmt> <cmt> builds. </cmt> <cmt> to fix this, we could just add ""-dvalgrind"" to our nightly builds. but </cmt> <cmt> starting with commit d827b11b6 (tests: execute leak checker via ctest </cmt> <cmt> directly, 2019-06-28), we do have a secondary variable that directs </cmt> <cmt> whether we want to use memory sanitizers for our builds. as such, every </cmt> <cmt> user wishing to use valgrind for our tests needs to pass both options </cmt> <cmt> ""valgrind"" and ""use_leak_checker"", which is cumbersome and error prone, </cmt> <cmt> as can be seen by our own builds. </cmt> <cmt> instead, let's consolidate this into a single option, removing the old </cmt> <cmt> ""-dvalgrind"" one. instead, let's just add the preprocessor directive if </cmt> <cmt> use_leak_checker equals ""valgrind"" and remove ""-dvalgrind"" from our own </cmt> <cmt> pipelines. </cmt> <cmt> streams: openssl: switch approach to silence valgrind errors </cmt> <cmt> as openssl loves using uninitialized bytes as another source of entropy, </cmt> <cmt> we need to mark them as defined so that valgrind won't complain about </cmt> <cmt> use of these bytes. traditionally, we've been using the macro </cmt> <cmt> valgrind_make_mem_defined provided by valgrind, but starting with </cmt> <cmt> openssl 1.1 the code doesn't compile anymore due to struct ssl having </cmt> <cmt> become opaque. as such, we also can't set it as defined anymore, as we </cmt> <cmt> have no way of knowing its size. </cmt> <cmt> let's change gears instead by just swapping out the allocator functions </cmt> <cmt> of openssl with our own ones. the twist is that instead of calling </cmt> <cmt> malloc, we just call calloc to have the bytes initialized </cmt> <cmt> automatically. next to soothing valgrind, this approach has the benefit </cmt> <cmt> of being completely agnostic of the memory sanitizer and is neatly </cmt> <cmt> contained at a single place. </cmt> <cmt> note that we shouldn't do this for non-valgrind builds. as we cannot </cmt> <cmt> set up memory functions for a given ssl context, only, we need to swap </cmt> <cmt> them at a global context. furthermore, as it's possible to call </cmt> <cmt> openssl_set_mem_functions once only, we'd prevent users of libgit2 to </cmt> <cmt> set up their own allocators. </cmt> <iss> httpclient: reads on uninitialized memory </iss>",fix valgrind issues in nightly builds
2338,<desc> this hops on the bandwagon by removing the cgamesettings global and moving its settings registration into the class. also provided are two commits that replace access to services through cservicebroker by passing references to the peripherals subsystem upon creation. this removes the possibility of circular dependencies. snes games still play. will test changing settings soon. bug fix (non-breaking change which fixes an issue) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) </desc> <cmt> games: register setting handlers inside gameservices </cmt> <cmt> peripherals: replace use of global input manager </cmt> <cmt> peripherals: replace use of global game controller manager </cmt>,register setting handlers inside cgamesettings
2339,"<desc> original pull-request #20211 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix cte in insert-select </cmt> <cmt> another fix </cmt> <cmt> update 01711_cte_subquery_fix.sql </cmt> <cmt> fix cte in insert-select </cmt>",cherry pick #20211 to 21.2: fix cte in insert-select
2340,"<desc> a bit easier way of enabling non default query runners, by creating an env variable with only them, instead of repeating all the default ones as well. </desc> <cmt> allow setting only the additional query runners instead of overriding whole list </cmt> <cmt> update docs </cmt>",allow setting only the additional query runners you need
2341,"<desc> simd is used to accelerate the computation in the farthest point sampling. through my local tests, the optimized algorithm is twice as fast as the original using the avx2 instruction set. the comments on the code also describe the program in more detail. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work </desc> <cmt> add several 3d point cloud sampling functions: random, voxelgrid, farthestpoint. </cmt> <cmt> made some code detail changes and exposed the random number generator parameters at the interface. </cmt> <cmt> add simple tests for sampling. </cmt> <cmt> modify interface output parameters. </cmt> <cmt> modify interface return value. </cmt> <cmt> the sampling test is modified for the new changes of function interface. </cmt> <cmt> improved test of voxelgridfiltersampling </cmt> <cmt> improved test of voxelgridfiltersampling and fps. </cmt> <cmt> add test for the dist_lower_limit arguments of fps function. </cmt> <cmt> optimization function _getmatfrominputarray. </cmt> <cmt> optimize the code style and some details according to the suggestions. </cmt> <cmt> clear prefix cv: in the source code. </cmt> <cmt> change the initialization of mat in the sampling test. </cmt> <cmt> 1. unified code style </cmt> <cmt> 2. optimize randomsampling method </cmt> <cmt> 1. optimize code comments. </cmt> <cmt> 2. remove unused local variables. </cmt> <cmt> rebuild the structure of the test, make the test case more reliable, and change the code style. </cmt> <cmt> update test_sampling.cpp </cmt> <cmt> fix a warning. </cmt> <cmt> use simd to optimize the farthest point sampling. </cmt>",accelerated 3d point cloud farthest point sampling calculation using simd.
2342,"<desc> update amqp_trx_plugin to not declare queue. instead it will assume queue exists. add --amqp-queue-name to cleos to allow user specification of queue instead of hard-coded ""trx"" epe-1190, epe-1192 pr #10618 select one: select any that apply: --amqp-queue-name to cleos </desc> <cmt> update to not automatically create amqp exchange and queue </cmt> <cmt> update tests to create queue via curl </cmt> <cmt> escape %2f </cmt> <cmt> correctly escape %2f </cmt> <cmt> enable rabbitmq_management for tests that use an amqp queue </cmt> <cmt> # conflicts: </cmt> <cmt> #	programs/rodeos/streams/rabbitmq.hpp </cmt> <cmt> #	tests/cluster.py </cmt> <cmt> #	tests/nodeos_run_test.py </cmt>",amqp_trx_plugin don't declare queue - 2.2.x
2343,"<desc> the cover algorithm requires a single buffer of 4x the input size, so in 32-bit mode, the maximum input size is 1 gb. document the memory requirements for the cover dictionary builder. make error messages on oom or too large input clearer. </desc> <cmt> use cover_memmult when training with cover. </cmt> <cmt> handle large input size in 32-bit mode correctly </cmt> <cmt> document memory requirements for cover algorithm </cmt>",handle cover dictionary builder maximum input size for 32-bit mode
2344,"<desc> jenkins-35098 see jira for motivation. also took the opportunity to clean up some ancient form binding. the fewer weird tricks we have floating around the source base, the better. @reviewbybees </desc> <cmt> [fixed jenkins-35098] deleting autobrowserholder. </cmt> <cmt> normalizing form binding scheme for abstractproject.scm. </cmt>",disable autobrowserholder by default to improve the changelog rendering performance
2345,"<desc> when build java doc with jdk11, we got the code being documented uses modules error. this pr fix it by using jdk8 and upgrade java doc plugin version. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> use jdk8 </cmt> <cmt> fix java doc </cmt> <cmt> upgrade maven java doc plugin version </cmt>",fix java doc building error
2346,<desc> this pr walks the vardeclusagechecker on sourcefile.decls to generate warnings for statements that aren't contained in abstract function declarations. this also disables the unused variable warnings for global variables since tracking global variables is complicated and felt like it was outside the scope of this bug. resolves sr-2115. i force pushed over my first attempt at this (#6971) to clean up history. i forgot it would kill the pr. </desc> <cmt> run the vardeclusagechecker on top level declarations </cmt> <cmt> fix warnings in top level statements </cmt>,generate unused variable warnings in top level statements
2347,"<desc> implement restoring screencast sessions using portals. do so by storing the restore token received by the portal in the source data, and using it next time the source is loaded. this feature is only available in the v4 version of the screencast portal [1] - if an older version is running in the host system, the current behavior is preserved. currently obs studio has to recreate screencast sessions from scratch each time a pipewire source is loaded. this can be annoying, use the new screencast restore options provided by xdg-desktop-portal to restore previous sessions. have xdg-desktop-portal and xdg-desktop-portal-gnome  installed from the master/main branches [2] run this branch of obs studio on wayland, or x11 with obs_use_egl=1 add a pipewire source, and select a window or a monitor close obs studio open it again notice that the sources were restored automatically tweak (non-breaking change to improve existing functionality) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> linux-capture: add getter to screencast portal version </cmt> <cmt> this will be used by the next commit to verify whether or not </cmt> <cmt> to pass the restore token and persist mode options. </cmt> <cmt> linux-capture: implement stream restoration </cmt> <cmt> with the version 4 of the screencast portal, it is now possible </cmt> <cmt> to request and use restore tokens [1] so that apps can restore a </cmt> <cmt> previously configured screencast session without user interaction. </cmt> <cmt> add the corresponding code to linux-capture's pipewire source. </cmt> <cmt> store the restore token in the source data, since each restore </cmt> <cmt> token corresponds to an obs source, and use it as soon as we try </cmt> <cmt> to create a new session. implement the obs_source_info.save vfunc, </cmt> <cmt> and save the restore token when it's received by the start() </cmt> <cmt> response using obs_source_save(). </cmt> <cmt> [1] </cmt>",screencast session restore for wayland / pipewire
2348,"<desc> as discussed, this adds a few small changes to documentation and plugin template: introduce package.json with peerdependencies specified for plugin template introduce a simple readme.md with a few resources on how to build a plugin or how to share it remove references to subcommands in plugins (in relation to recent discussion about removing support for subcommands altogether) add notes regarding development of plugins for serverless framework 2.x (and potential further majors) i also considered moving the general doc outside of aws provider section - what do you think? do you have any other suggestion to the structure of our current information and/or proposed changes? </desc> <cmt> feat(templates): add package.json to plugin template </cmt> <cmt> docs: improve plugins documentation </cmt> <cmt> feat(templates): add a simple readme for plugin template </cmt>",improve docs and template for plugins
2349,"<desc> fixes #2556. this pr implements the textarea normalization that react performs in preact/compat. thanks @marvinhagemeister for pointing out where to make this change, it's been super helpful for getting to understand the codebase better! </desc> <cmt> add failing test to demonstrate textarea bug </cmt> <cmt> fix textarea handling of value prop (#2556) </cmt> <iss> textareas are not initialized correctly during hydration </iss>",normalize value prop on textareas in compat
2350,"<desc> related to: #21079 rfc link: #26850 added loader dangerously-unoptimized which basically returns the src url, this would also allow next export to run without errors and images without a custom loader specified can fallback to the static loader. todo: add integration tests update documentation </desc> <cmt> add support for static loader </cmt> <cmt> update existing test </cmt>",add dangerously-unoptimized loader for next/image
2351,<desc> followup to #17279 to also prevent editing of core axes which are not supported for backlash compensation at this time. </desc> <cmt> have debug_current use pstr </cmt> <cmt> prevent editing backlash on core axes </cmt>,limited backlash editing with core kinematics
2352,"<desc> i believe the issue with #16039 was the loss of the semantics provided by the ""b"" part of the mode in fopen(). this is a nop on unix-like systems, but appears to be significant on windows. the equivalent functionality on windows in open() is the o_binary flag. this adds that to the open() call, and provides compat for it on platforms without the flag by defining it to 0. while here, fix an fd leak in new_file_source() if the buffer allocation fails. tests added / passed passes git diff upstream/master --name-only -- '*.py' | flake8 --diff whatsnew entry </desc> <cmt> revert ""bug: revert gh-16039 (#16663)"" </cmt> <cmt> this reverts commit c550372910435bcfa8ce35d134c0a4ba761fc084. </cmt> <cmt> always treat files as binary to cope with windows and eof. </cmt> <cmt> on windows, eof can appear ""in band"" if the file is considered text. when </cmt> <cmt> moving from fread() to read(), i lost the ""b"" part of the mode. at the </cmt> <cmt> time i believed this was a nop, since unix doesnt treat files differently </cmt> <cmt> based on that flag. </cmt> <cmt> this adds o_binary to the flags to open to restore the behaviour lost </cmt> <cmt> when taking ""b"" away from fopen. if a platform doesn't provide o_binary, </cmt> <cmt> this defines it to 0 so it can still be used without effect later on in </cmt> <cmt> the code. </cmt> <cmt> dont leak the fd in new_file_source() if buffer allocation fails. </cmt>","revert #16663, which was a revert of #16039"
2353,"<desc> adds the ansi-color tool, completing #6470. what started out as an experiment to see the support of ansi support to conhost, i wanted to write a windows equivalent of daniel crisman's bash script on tldp.org. i didn't like how the bash script hard coded in whitespace and i thought windows could do better. i applied techniques to speed up the execution and tried to use the command script batch language in ways that pushed the limits for what i thought it could do. running this from withing powershell, &cmd /c ansi-color.cmd, i found out that the active code page is already 65001, but when ran from a command prompt, the active code page depends on the regional settings and i would have a dependency on chcp to detect the active code page, change to 65001 if necessary, and restore the previous code page after running. i found it useful for designing color schemes and writing shaders, and i started using an earlier version for logging bugs. initially it was a single script which i would dump every sgr combination i could think of, and many which weren't implemented yet, but as i was looking at other tools which had been written i wanted to mimic the same output so i could do side-by-side comparisons. first i wrote crisman.def and then colortool.def. so i had to align text. then output was slow for big tables so i wrote to an outbuffer and made use of macros. i wanted to handle flags instead of needing to change settings every time, so i added argument parsing and loading external files. it's a batch file that has some really useful purposes and does nothing i've seen before. i've ran every definition in a command prompt, with cp 437 and cp 65001 to make sure it works. posted as a gist on my account for about year, a portuguese (brazilian as i recall), speaking user tried the gist and it was failing because chcp is localized. i've taken an approach to try and make it work for different localizations, but this is a potential problem. i also ran every definition in powershell 7, shelling down to cmd to actually run it. lastly, i went through using the flags and made sure that help would be shown. error messages generate error levels when the script exits, so those could be used to use this in an automated test and catch if there was a problem with the script executing. it won't be able to validate if the generated output shows correctly, but it would fail if a definition file is missing or if it needed to switch to unicode and wasn't flagged or configured to do so. for trying to build the table stub and headers, there is some debug code which will output what was parsed. this is the last debug code in the script itself, but i found it to be useful at times, so there is a configuration setting which can turn that debug output back on. technically there is also a debug statement to break after adding the macros and parsing the arguments, but before it does any configuration changes, changes the code page, or anything. this was useful for making changes to macros and being able to test them as well as making sure that flags and arguments are parsed correctly. it was a rather cryptic discovery to call cmd /c exit -1073741510 to break out, so in part that was my reason to leave this in. the definition files themselves could be cleaned up further, but in both of them there are a lot of unicode codepoints that could be useful when defining division lines for the headers so i opted to just comment them out. i initially had the default definition to require unicode, but now it just changes to a non-unicode output if it can't. and this brings up the last concern. the way certain settings are set, is that they are defined in the __table__ section of the definition file.  with parse_table_data, the script looks line by line for set * or if * and if found it will effectively eval that line. the definition files are written so that for instance set ""cell= gyw "" could be used to set the code which is used. if was allow so that there could be a test if unicode were available and set something different for ascii and unicode. but it also opens the possibility that a rogue actor could create a ansi-color.cmd definition file something like set ""foo=bar"" & dosomethingbad.exe. first of all i'd be flattered that anyone would use this very niche tool, but it is something i think which needs to be called out. essentially the definition files are just batch files, but they are extremely limited to executing only one line at a time and only supporting if and set commands. i think this is a minimal risk because at that point batch files would already be more effective, but there should also be an expectation that a batch file will run something and the same may not be true for the heavily degraded definition files. i think the risk is minimal but it is a risk i wanted to make clear. this really showcases some interesting techniques and ideas, and i hope that it is useful. all told, there are a couple years of incremental changes in this pr. closes #6470 </desc> <cmt> add ansi-color.cmd tool and several definitions </cmt> <cmt> add readme.md </cmt> <cmt> satisfy check-spelling-bot </cmt> <iss> command shell script to generate and display all combinations of sgr properties which can be applied as ansi escape sequence control characters to text </iss>","add rbeesley's ansi-color.cmd, a cmd-based color tool (& more)"
2354,"<desc> closes #15072 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry afaict the fact that rollinggroupby could not use agg with a list of functions is simply due to the fact that the groupbymixing it inherits from could not handle the reduction in dimensions that occurs via the normal aggregation functions. </desc> <cmt> added test for rolling </cmt> <cmt> fixed groupbymixin class constructor with seriesgroupby </cmt> <iss> bug/enh: groupby.rolling.agg / column(s) low already selected </iss>",fixed issue preventing agg on rollinggroupby objects
2355,"<desc> this pr bring back the serialization_addon mechanism from #12478 and use it to register custom serializers for pydantic and starlette. additionally, this pr make sure ray client will use the same mechanism. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [core] zero-copy serializer for pytorch (#12344) </cmt> <cmt> * zero-copy serializer for pytorch </cmt> <cmt> * address possible bottleneck </cmt> <cmt> * add tests & device support </cmt> <cmt> (cherry picked from commit 0a505ca83d18a340e7e2dd270d82aeff620ebc77) </cmt> <cmt> add environmental variables </cmt> <cmt> . </cmt> <cmt> update doc </cmt> <cmt> clean up </cmt> <cmt> move file </cmt> <cmt> fix test </cmt> <cmt> ray client </cmt> <cmt> serve cleanup </cmt>",pydantic -> serialization_addons.py and ray client support.
2356,<desc> i hereby agree to the terms of the cla available at:  detailed description / documentation draft: added russian translation by following pr: #12009 allow tabseparatedraw as an input format #12170 introduction for special table engines #12175 introduction for third-party interfaces #11793 update replacingmergetree.md </desc> <cmt> docsup-2035: (ru) added updates in replacingmergetree.md by pr#11793 </cmt> <cmt> docsup-2035: added third-party description by pr#12175. </cmt> <cmt> docsup-2035: updated translation in third-party/index.md </cmt> <cmt> docsup-2035: (ru) added translation to table-engines-for-integrations. </cmt> <cmt> docsup-2035: (ru) added translation to table-engines-for-integrations by pr#12170. </cmt> <cmt> docsup-2035: added special table engines and engines for integration sections by pr#1270 </cmt> <cmt> docsup-2035: (ru) added allow tabseparatedraw description in interfaces/formats.md by pr#12009. </cmt> <cmt> docsup-2035: added footer with link to original pages. </cmt> <cmt> docsup-2035: update note block. </cmt> <cmt> docsup-2035: update attention block. </cmt>,edit and translate to russian some pr.
2357,<desc> read our contributing guidelines </desc> <cmt> add 4 course on free-courses-id.md </cmt> <cmt> fixing linter failed on courses </cmt> <cmt> merge with remote branch </cmt> <cmt> add 4 course on free-courses-id.md </cmt> <cmt> remove kotlin free course on free-courses-id.md </cmt> <cmt> remove unused line on kotlin </cmt> <cmt> merge with master </cmt> <cmt> add 2 kotlin resources on free-courses-id.md </cmt> <cmt> fixing number of lines on end of section </cmt> <cmt> merge with master </cmt> <cmt> add 4 course on free-courses-id.md </cmt> <cmt> merge branch </cmt> <cmt> add 4 git course on free-courses-id.md </cmt>,add 4 git course on free-couses-id.md
2358,"<desc> this is relanding of #70277 the diff with #70277: let defaulttextstyle of selected item use theme.disabledcolor when the button is diabled. cc/: @shihaohong, thanks very much for all your hard work on this change. related issues fixes #71562 i added the following tests: see files. </desc> <cmt> revert ""revert ""improve the behavior of dropdownbutton.disabledhint (#70277)"" (#71559)"" </cmt> <cmt> this reverts commit 25986102c141513939fac49c824568c478610b52. </cmt> <cmt> selected item use disabledcolor when disabled </cmt> <iss> improve the behavior of dropdownbutton.disabledhint </iss>","reland ""improve the behavior of dropdownbutton.disabledhint"""
2359,"<desc> some memory leaks have slipped through during the various contortions required for the api freeze: the updates to gitrepository subscriptions introduced a bug that caused to not unsubscribe correctly from textbuffers when they were destroyed. the jquery shims weren't having cleandata called on them when the underlying custom element was removed, causing handlers which are held by global jquery data structures to leak. </desc> <cmt> fix memory leak in gitrepository and convert to compositedisposables </cmt> <cmt> we were calling @unsubscribe with the textbuffer, which previously </cmt> <cmt> unsubscribed from that object. the problem is that we were no longer </cmt> <cmt> subscribing to that object directly, but only adding subscriptions to </cmt> <cmt> that object. this caused us to never unsubscribe from buffers. </cmt> <cmt> :arrow_up: space-pen to call cleandata in callremovehooks to stop leaks </cmt> <cmt> only spacepen callremovehooks on removed pane item view if destroyed </cmt> <cmt> trigger editor:will-be-removed from spacepen shim, not component </cmt> <cmt> by the time the component is getting unmounted, we have already called </cmt> <cmt> remove hooks on the spacepen shim so subscriptions to the event have </cmt> <cmt> been removed. </cmt>",fix memory leaks introduced by changes for api freeze
2360,<desc> add/remove libprotobuf_export to support dll on visual studio. modify one arena test to fit win32. disable test for generate dependency files on windows. add new files to *.vcproj </desc> <cmt> add missing files for test to *.vcproj files </cmt> <cmt> fix c++ on windows </cmt> <cmt> fix bugs on windows. </cmt>,3.0.0 alpha 3 windows fix
2361,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add new supported plugins from 0.7 </cmt> <cmt> add missing option: enabled </cmt>",update dd-trace types to 0.7
2362,"<desc> hello, i made the unit tests for the crc and the hash algorithms. i have found some smaller bugs during this, which have been fixed. there is a significant question about the hex::crypt::encode16 in which the function mbedtls_mpi_read_binary ignores the initial null bytes from the input and so the result of the encode16({0x00, 0x2a}) is ""2a"". technically (as mbedtls_mpi_ is a bignum library) this is true (as mathematically writing zeros before a number does not change it's value), but it makes the encoding lossy (the information about the length of the input can be lost), and it could make decode16(encode16(x)) == x false, what (i think) is mostly unexpected. at this moment the test samples affected by this are skipped and a single last case makes the test case to fail (so the other tests will run). (i have not come up with a good fix yet which is not ugly (eg. prepending the output of encode16 before return) without implementing the whole thing by hand.) i would like to get your opinion about this: is this the expected result from the conversion / should it be checked by the tests / should it be fixed? </desc> <cmt> update test_assert to do nothing if condition is true </cmt> <cmt> the test_assert should not return if the condition is true, because: </cmt> <cmt> - it prevents the usage of multiple test_assert in a single test case, </cmt> <cmt> - that behavior differs from how the assert in the standard library </cmt> <cmt> works, and thus may give unexpected results. </cmt> <cmt> make the test_assert to print an error message (with an formatted </cmt> <cmt> optional user part) when it fails to make debugging easier. </cmt> <cmt> fix some bugs in testprovider, add unit tests </cmt> <cmt> use pointer-to-vector in testprovider so writes can be tested, too. </cmt> <cmt> add test encodedecode16, fix some encode16 bugs </cmt> <cmt> the function mbedtls_mpi_write_string needs a bit longer buffer than the </cmt> <cmt> resulting string actually will be. </cmt> <cmt> known bug: mbedtls_mpi_read_binary ingores initial null bytes </cmt> <cmt> add test encodedecode64, fix some bugs </cmt> <cmt> the functions mbedtls_base64_encode and mbedtls_base64_decode needs a </cmt> <cmt> bit longer buffer than the resulting string actually will be. </cmt> <cmt> remove check for empty data from testprovider </cmt> <cmt> it can be valid to get the hash of empty string. </cmt> <cmt> add tests for crc calculation </cmt> <cmt> two type of thests: </cmt> <cmt> - compare the result of the crc calculation to a known to be good </cmt> <cmt> results, </cmt> <cmt> - generate random data as message, calculate of it's crc and append that </cmt> <cmt> to the message, the crc of this new data should be 0. </cmt> <cmt> add test for hash algorithms </cmt> <cmt> add includes in tests </cmt> <cmt> remove the use of c++20 ranges </cmt> <cmt> it seems that apple clang does not support range-based constrained </cmt> <cmt> algorithms at this time. </cmt>",tests for the crc and hash algorithms
2363,<desc> exhaustive_integer_patterns slipped 1.32; merged in 1.33 -- #56362 macro_literal_matcher isn't stable on current stable (1.31) but is on beta (1.32). r? @varkor </desc> <cmt> macro_literal_matcher was stabilized in 1.32; not 1.32. </cmt> <cmt> exhaustive_integer_patterns slipped 1.32; stabilized in 1.33. </cmt>,fix stabilization version numbers (exhaustive_integer_patterns + macro_literal_matcher)
2364,"<desc> regarding #1975. this adds the option of using https for gatsby develop, thanks to devcert. the implementation is heavily inspired by what preact-cli has done, minus the fallback to simplehttp2server. wondering if that's necessary? so using -s or --https would give you: it appears that only localhost is verified, so it probably won't work well together with --host. same behavior can be seen at preact-cli. </desc> <cmt> add https option using devcert. </cmt> <cmt> use \n instead of new log. </cmt>",add --https option for gatsby develop
2365,"<desc> implement name mangling, type metadata, runtime demangling, etc. for global-actor qualified function types. ensure that the manglings round-trip through the various subsystems. implements rdar://78269642. </desc> <cmt> test runtime demangling of concurrency standard substitutions </cmt> <cmt> implement (de-)mangling and type metadata for global actor function types. </cmt> <cmt> implement name mangling, type metadata, runtime demangling, etc. for </cmt> <cmt> global-actor qualified function types. ensure that the manglings </cmt> <cmt> round-trip through the various subsystems. </cmt> <cmt> implements rdar://78269642. </cmt>",@douggregor implement (de-)mangling and type metadata for global actor function types
2366,"<desc> tested as part of #35907 </desc> <cmt> .cirlceci: remove python 2.7 builds, switch libtorch to 3.7 </cmt> <cmt> .circleci: bump libtorch builds to 3.7 </cmt> <cmt> the image is actually using python 3.7.2 so we should reflect that </cmt> <cmt> within our circleci configs </cmt> <cmt> (cherry picked from commit b3f2572aaf83d1f5383369187f6263e6f926103b) </cmt>","bump libtorch to 3.7, remove python2"
2367,<desc> updating ctrl and alt readme for make command example to reflect directory change </desc> <cmt> massdrop keyboards readme update </cmt> <cmt> massdrop keyboards readme update for flashing instructions </cmt> <cmt> ctrl and alt keyboard readme update </cmt> <cmt> updating make command in massdrop ctrl and alt keyboard readme files to reflect directory change </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>,update ctrl and alt keyboard readme
2368,<desc> issue: temporarily relieves #2303 forked all the komposer/mantra deprecated packages and published version without peer dependency warning is this testable with jest or storyshots? </desc> <cmt> #2303 use our own published packages </cmt> <cmt> new lock file </cmt>,use @storybook published deprecated dependencies
2369,<desc> corrected bug when adding multiple radiotherm hosts via configuration.yaml added new configuration parameter hold_temp to control if setting the temperature from home-assistant is set to hold.  setting hold_temp to true is useful if the thermostat will be treated as  a dumb device and all temp adjustments will be controlled by a home-assistant component.  setting hold_temp to false can be used if you just want home-assistant to make temporary thermostat adjustments (temperature change when all people leave the house) but return to thermostat program. added configuration example and docs to radiotherm.py </desc> <cmt> fix configuration for multiple hosts and add example configuration.yaml section </cmt> <cmt> add hass configuration parameter hold_temp & config documentation </cmt>,radiotherm platform bug fix and configuration parameter
2370,<desc> support caching of dynamic properties to avoid unnecessary remote interaction costs. </desc> <cmt> report migration status </cmt> <cmt> migration status </cmt> <cmt>  conflicts: </cmt> <cmt> 	dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/utils/configvalidationutils.java </cmt> <cmt> 	dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/migration/migrationinvoker.java </cmt> <cmt> support caching of dynamic properties to avoid fetching from remote every time. </cmt> <cmt> delete duplicate class </cmt>,support caching of dynamic property
2371,"<desc> there are a couple minor additions in this pr: add a new test for window store, to range query upon receiving each record. in the non-windowed state store case, add a get call before the put call. enable caching by default to be consistent with other join / aggregate cases, where caching is enabled by default. </desc> <cmt> add state processor with window store on range query </cmt> <cmt> enable caching for stateful operations by default </cmt>",add window store range query in simple benchmark
2372,"<desc> this does profile munging in the harness, installs a user.js file, and the specialpowers extension so the harness page can quit the browser. specialpowers is mpl 1.1, but that doesn't change the license of other files in the project, and mozilla owns the copyright for all of it anyway (jesse, clint, and i are the original authors). i moved all of the test stuff into a test/ directory, since it was already getting a little messy. there are some capabilities that are firefox-only right now, but it should be straightforward to adapt things for other browsers. i also don't yet enforce names like ""firefox5"", but i can do that in a followup. sayrer$ python ./test.py --help usage: test.py options: -h, --help            show this help message and exit -m, --mastermode      run the script in master mode. --manifestfile=manifestfile a json file in the form of test_manifest.json (the default). -b browser, --browser=browser the path to a single browser (right now, only firefox is supported). --browsermanifestfile=browsermanifestfile a json file in the form of those found in resources/browser_manifests </desc> <cmt> change test.py to use an external browser_manifest.json file, and use optionparser to handle the command line. </cmt> <cmt> remove some accidental print statements. </cmt> <cmt> add new test directories. </cmt> <cmt> move some files around. </cmt> <cmt> modify paths of web resources to work with test resources more buried. </cmt> <cmt> merge upstream. </cmt> <cmt> add pdf.pdf to .gitignore </cmt> <cmt> add a user.js file firefox profile. change http server to run on background thread. </cmt> <cmt> add specialpowers extension to allow the browser to quit from content, and a bunch of other exciting things. </cmt> <cmt> add sample manifests. also make a browser path argument, so you can just specify one browser without messing with a manifest. </cmt> <cmt> merge remote branch 'upstream/master' </cmt> <cmt> cleanup newlines and fix a mistakenly symlinked file. </cmt>","let the browser quit, add automation into harness rather than rely on shell scripts"
2373,"<desc> i'll also try to backport #21977 to 1.27.x before the next tag, which i believe is needed to upload python artifacts to the interop matrix. </desc> <cmt> bump version to 1.27.2 </cmt> <cmt> regenerate projects </cmt>",bump 1.27.x branch to 1.27.2
2374,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #38895 </desc> <cmt> fixes a broken link to 'undefined is a keyword' </cmt> <cmt> fixes a broken link to 'undefined is a keyword' by replacing the wrong link with the correct one. </cmt> <cmt> fixes a broken link to 'undefined is a keyword' closes #38895 </cmt> <iss> link to ""undefined is a keyword"" is broken </iss>",fixes broken link to 'undefined is a keyword'
2375,"<desc> qpalette::background is obsolete causing deprecated build error using qt5 from homebrew, so changed to use qpalette::window, which is same value. qpalette::background was already deprecated more than 15 years ago. ui/replay isn't triggered to build on macos, so added to run build. one of the std::max was called with unsigned long vs uint64 causing unknown function error, so casted to match type. build succeeded, and i was able to run binary on both intel and arm macos 11. no change to other devices and os. </desc> <cmt> fixed deprecated enum value </cmt> <cmt> changed to build qt replay on macos </cmt>",fixed build issues on macos
2376,"<desc> i looked through this a little bit, and i can't find any mathematica code at all; it appears to just be a math book. </desc> <cmt> this book doesn't seem to have anything to do with mathematica. </cmt> <cmt> this book doesn't seem to have anything to do with mathematica. </cmt>","this book should be in mathematics, not mathematica"
2377,"<desc> to fix the doc issue raised in #42014, hence changed the name of infoblox_client to infoblox-client which is the actual name of the wapi infoblox client. nios ansible version 2.6 </desc> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt> <cmt> change infoblox_client to infobblox-client </cmt>",infoblox list requirements as infoblox_client and should be infoblox-client
2378,"<desc> document the methods to convert strings to rawarrays, and back. </desc> <cmt> correct retvals of string::to_ascii() and string::to_utf8() </cmt> <cmt> both return rawarray, not string. </cmt> <cmt> my fault from commit f83f96cb44a5c4f65c6271d0a98606b489adc488. </cmt> <cmt> document byte conversion methods for strings </cmt>",document string <-> byte conversion methods
2379,"<desc> converted cornersubpix, getrectsubpix, moments, distancetransform, houghlines, floodfill. </desc> <cmt> converted flood fill, getrectsubpix & cornersubpix to c++ </cmt> <cmt> converted watershed + pyrmeanshiftfilter to c++ </cmt> <cmt> converted moments function to c++ </cmt> <cmt> almost finished distance transform conversion (discrete voronoi diagram mode is not ready yet) </cmt> <cmt> finished distance transform; fixed warnings </cmt> <cmt> converted houghlines to c++ </cmt>",converted several more imgproc algorithms from c to c++
2380,<desc> none. cheetah 1.2 is a variant with few changes compared to original cheetah tmc2208 instead of tcm2209 no rgb output use of sw instead of hw uart for tmc com * a tmcstepper patch is required to allow sw uart with stm32f1 see fysetc/tmcstepper@3114260 adds foundation to fysetc cheetah 1.2 board </desc> <cmt> feat: fysetc cheetah 1.2 board and pins definition </cmt> <cmt> fysetc cheetah 1.2 sample configurations </cmt>,fysetc cheetah 1.2 board/pins definition
2381,"<desc> adds support for: %{...}t in which ... is passed to strftime(3) %{sec}t, %{msec}t, %{usec}t, %{msec_frac}t, %{usec_frac}t does not implement: begin: and end: modifier (pull requests are welcome) see </desc> <cmt> implement %{...}t compatible with apache http server </cmt> <cmt> add tests </cmt>",support %{...}t compatible with apache http server
2382,<desc> i hereby agree to the terms of the cla available at:  added possibility to restore mergetree parts to 'detached' directory for disks3 detailed description / documentation draft: added possibility to move mergetree parts to 'detached' directory during restore disks3. reworked revision number storing & searching (the previous approach wasn't correct and may lead to wrong revision found on start). added replicatedmergetree coverage to restore disks3 tests. </desc> <cmt> disk s3 possibility to restore parts to 'detached' directory. </cmt> <cmt> disk s3 possibility to restore parts to 'detached' directory. </cmt> <cmt> rework disk s3 revision number storing / searching. </cmt> <cmt> disk s3 restore test improvements. </cmt>,disks3 possibility to restore parts to detached directory
2383,<desc> @rocketchat/core this pull request adds the ability for the twilio integration to accept mms attachments and display the attachment in the livechat window. </desc> <cmt> added ability for mms messaging to push through attachments </cmt>,twilio mms support for livechat integration
2384,"<desc> add optional support for configuring prometheus scrape via prometheus-operator servicemonitor the beat-exporter was recently added for exporting prometheus metrics from filebeat. this pr adds support for configuring the scraping of those metrics in prometheus using the prometheus-operator servicemonitor. this is entirely optional via values but will only be available if you have the prometheus-operator apiversion installed in kubernetes. (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed </desc> <cmt> add optional support for configuring prometheus scrape via prometheus-operator servicemonitor </cmt> <cmt> bump chart version </cmt>",add optional support for configuring prometheus scrape servicemonitor
2385,"<desc> remove duplicated ntpd entry sort modules in alphabetical order to reduce chance of appearance of duplicated records in future component name python.d.conf </desc> <cmt> remove duplicated ntpd entry </cmt> <cmt> sort modules in alphabetical order to reduce chance of appearance of </cmt> <cmt> duplicated records in future. the only exception is nginx_plus, which </cmt> <cmt> left where it was, close to nginx module. </cmt>",remove duplicated entry and put modules in order in python.d.conf
2386,"<desc> the run_translation.py does not support fine-tuning mbart-50 and m2m100 as we need to set src_lang and tgt_lang attributes, but the script only checks for mbarttokenizer, this pr adds the multilingual_tokenizers list where we can add all tokenizers which require setting src_lang and target_lang attributes, this avoids having multiple if/else statements (thanks sylvain!) adds the --forced_bos_token argument which is used to set the config.forced_bos_token_id attribute which is required for mbart-50 and m2m100 during generation to be able to force the target language token as the first generated token. we could use the --target_language argument to set this, but this attribute shouldn't be set auto-magically as generations change completely depending upon the forced id, so imo it's better to ask the user to explicitly provide it. </desc> <cmt> keep a list of multilingual tokenizers </cmt> <cmt> add forced_bos_token argument </cmt>",support mbart-50 and m2m100 fine-tuning
2387,"<desc> break out runtime into the runtime variable allows runtime to be set by the user decides on docker or podman if docker isn't avaible rewrote check for docker-machine to account only for docker runtime put --user arg into a variable only to be used with docker this is not needed with podman as podman maps the containers root id to the users id. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add podman support to docker_build.sh script </cmt> <cmt> * break out runtime into the runtime variable </cmt> <cmt> * allows runtime to be set by the user </cmt> <cmt> * decides on docker or podman if docker isn't avaible </cmt> <cmt> * rewrote check for docker-machine to account only for docker runtime </cmt> <cmt> * put --user arg into a variable only to be used with docker </cmt> <cmt> this is not needed with podman as podman maps the containers root id </cmt> <cmt> to the users id. </cmt> <cmt> add podman to getting_started_docker documentation </cmt>",add support for using podman to util/docker_build.sh
2388,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). i am making the lodash merging style the default merging style (which is array-preserving) for all merging utilities on the ts-toolbelt: type t0 = merge<{ a: number[] b: {a: 1}[] c: {a: [0]} }, { a: string[] b: {b: 2}[] c: {a: [0, 1, 2]} }, 'deep', 0> // { //     a: (string | number)[]; //     b: { //         a: 1; //         b: 2; //     }[]; //     c: { //         a: [0, 1, 2]; //     }; // } atm, merge uses ramda's merging style by default (which disassembles lists and their methods) but i don't want this any longer as a default. i am not willing to mark this a a breaking feature because i see it as an upgrade or patch of ts-toolbelt's merge utility that never worked properly (ie. we can now merge nested arrays and objects efficiently). </desc> <cmt> chore: set option for mergeup for upcoming breaking changes in ts-toolbelt </cmt> <cmt> chore: set option for assignup for upcoming breaking changes in ts-toolbelt </cmt> <cmt> chore: cleanup </cmt> <cmt> fix(mergeall): wrong type param </cmt> <cmt> fix: disable ts-lint rule </cmt>",preparing for breaking change in ts-toolbelt
2389,"<desc> while writing an article on how to use the upcoming modular underscore release, i realized that the division between the underscore.js and underscore-oop.js modules that i made in #2849 was a bit unnatural. as it was, the underscore.js module exported a _ function that could wrap a value, but the resulting wrapper had no unwrapping methods. to have the unwrapping methods, you needed to import underscore-oop.js for its side effects, but that also added all the array proxy methods. people who cherry-pick from the library may sometimes want to have wrapping and unwrapping but no array methods. i reorganized this slightly so that underscore.js already packs the unwrapping methods. the remaining underscore-oop.js has only one job, i.e., to add the array methods, so i renamed it accordingly. the impact on the monolithic build is minimal because the unwrapping methods have no dependencies of their own. i don't expect anyone to object to this change so i'm not going to ask for a review, but i'm creating this pr anyway in order to leave a trace. i will also hold off from merging until the travis build has completed, to make sure that nothing breaks. </desc> <cmt> move unwrapping methods to the primary underscore module </cmt> <cmt> rename the underscore-oop module to underscore-array-methods </cmt>",move unwrapping methods to the primary underscore.js module
2390,"<desc> see the previous versions of this change: #30069 and #33794 this reland version includes minor performance fixes in textpainter.setplaceholderdimensions(). we now ignore placeholderdimensions when there are no placeholders in the textspan tree. </desc> <cmt> merge in changes for inline widgets </cmt> <cmt> make analyzer happy, fix tests </cmt> <cmt> fix analyzer </cmt> <cmt> add missing doc </cmt> <cmt> docs on richtext </cmt> <cmt> fix analyzer some more </cmt> <cmt> remove whitespace at end of line </cmt> <cmt> update goldens </cmt> <cmt> text fixes </cmt> <cmt> analyzer </cmt> <cmt> merge with upstream </cmt> <cmt> fix performance regression </cmt>","reland ""text inline widgets, textspan rework"""
2391,"<desc> this fixes a few issues with emitting of deallocators/destroyers for objc. with this, the objc_dealloc test passes the ownership verifier. rdar://33358110 </desc> <cmt> [silgen] when checking we check if a failable initializer that we delegated to returned null, reload self using the normal semantics. </cmt> <cmt> we have already finished the delegation sequence at this point, so we should go </cmt> <cmt> through normal semantics. </cmt> <cmt> rdar://33358110 </cmt> <cmt> [silgen] update silgen objc deallocators and enable ownership on objc_dealloc.swift </cmt> <cmt> rdar://33358110 </cmt>",semantic sil objc deallocator fixes
2392,"<desc> backport two memory-leak fixes (#5974 and #5953) (see also 2.1: #5979, 2.0: #5980, 1.1: #5981  ) it looks like we already had the parentsensors fix in 1.0 and lost it in 2.0. the change in this pr just tidies it up a little for consistency with later branches. </desc> <cmt> kafka-7660: tidy up parentsensors removal (#5953) </cmt> <cmt> kafka-7660: fix child sensor memory leak (#5974) </cmt> <cmt> a heap dump provided by patrik kleindl in </cmt> <cmt> this pr fixes it and adds a test to be sure. </cmt> <cmt> reviewers: jason gustafson <jason@confluent.io>, guozhang wang <wangguoz@gmail.com> </cmt>",fix streams and metrics memory leaks
2393,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. these types only cover node creation. types for the most commonly used api calls when creating custom node-red nodes are provided. </desc> <cmt> basic node creation api </cmt> <cmt> tests and fixes </cmt> <cmt> minor linting fix </cmt>",@types/node-red new set of types for node-red node creation api.
2394,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> added type definition for the missing onrowdoubleclicked() in types/react-data-grid </cmt> <cmt> fixed the format issues cause by my local vscode formatter. </cmt>",added type definition for the missing onrowdoubleclicked() in react-data-grid
2395,<desc> fix browse webcontrol in py3 rename version to readme in lib </desc> <cmt> fix browse webcontrol through proxy </cmt> <cmt> browse webcontrol will cause error through proxy when using mobile </cmt> <cmt> browser. </cmt> <cmt> rename version to readme </cmt>,browse webcontrol cause error through proxy when using mobile browser.
2396,"<desc> in the past, there was a regression the placement group creation time gets slower as time goes. i believe the issue is fixed in the master, but this pr verifies if that's actually fixed. this pr adds a long running test for the placement group. there are 2 purposes of the test. make sure the placement group creation / removal doesn't get slower as time goes. the test basically measure the first 20 iteration p50 creation time and run very long iteration. after all iteration, it checks if the p50 creation time is not too slow compared to the initial round. make sure placement group removal / creation works consistently for a long time without an issue. q: should we make it a real long running test? (that runs for a day?) closes #19098 part of #18919 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> done </cmt> <cmt> done </cmt> <iss> [bug] [placement group] placement group performance gets slower as time goes </iss>",placement group long running test
2397,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <#82, #86> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [lozad] update types </cmt> <cmt> [lozad] update tests for version 1.2 </cmt>",update types according to library changes
2398,<desc> what's in this pull request? this adds documentation for a few more request types that sourcekit supports. there are no code changes so ci does not need to be run. resolved bug number: (sr-2117) this does not completely resolve sr-2117 but it does knock a few more off the list. it also gives @modocache a chance to say if i am continuing his work appropriately before i spend more hours doing the rest of them. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [sourcekit] document source.request.protocol_version </cmt> <cmt> [sourcekit] document source.request.cursorinfo </cmt>,add documentation for sourcekit request types
2399,"<desc> add rgblight mode 35 (r,g,b cyclic mode) into quantum/rgblight.[ch], etc update docs </desc> <cmt> add rgblight mode 35 (rgb cyclic mode) into quantum/rgblight.c </cmt> <cmt> update docs, add rgblight mode 35(rgb cyclic) </cmt>","add rgblight mode 35 (r,g,b test mode)"
2400,"<desc> fixes #17380. </desc> <cmt> network: address: do not adjust user specified scope </cmt> <cmt> this reverts cd1caf30c0bd0d0c6e8df7610c614f52a7345c40. </cmt> <cmt> i cannot remember why such change was made. </cmt> <cmt> at least, the kernel does not refuse to set ipv4 localhost address with </cmt> <cmt> non-host scope, e.g. global. </cmt> <cmt> network: address: also adjust scope when address is link local address </cmt> <cmt> but again only when scope= is not explicitly specified. </cmt> <cmt> network: address: add scope in debugging logs </cmt> <cmt> network: wireguard: allow to run ndisc and radv when ipv6ll address is manually configured </cmt> <cmt> fixes #17380. </cmt> <iss> no router advertisements sent out over wireguard link </iss>",wireguard: allow to start ndisc or radv
2401,"<desc> c.f. #6675. </desc> <cmt> man: journal-remote: active mode without --url option requires output filename </cmt> <cmt> closes #6675. </cmt> <cmt> journal-remote: show error message if output file name does not end with .journal </cmt> <cmt> journalctl -o export | systemd-journal-remote -o /tmp/dir - </cmt> <cmt> gives the following error messages. </cmt> <cmt>  </cmt> <cmt> failed to open output journal /tmp/dir: invalid argument </cmt> <cmt> failed to get writer for source stdin: invalid argument </cmt> <cmt> failed to create source for fd:0 (stdin): invalid argument </cmt> <cmt>  </cmt> <cmt> and these are hard to understand what is the problem. </cmt> <cmt> this commit makes journal-remote check whether the output file name </cmt> <cmt> ends with .journal suffix or not, and if not, output error message. </cmt>",improve man page and error message
2402,"<desc> this should fix issue #4233: the pin io behaviour for the esp8266 dht driver is reverted to before the change made in 033c32e, which should get dht working more reliably (since it gets back the old behaviour).  it also retains the current io behaviour for all other uses of pins in open-drain mode (eg i2c), so shouldn't break anything else. </desc> <cmt> drivers/dht: allow open-drain-high call to be dht specific if needed. </cmt> <cmt> some ports (eg esp8266) need to have specific behaviour for driving a dht </cmt> <cmt> reliably. </cmt> <cmt> esp8266/esp_mphal: provide mp_hal_pin_od_high_dht so dht works reliably. </cmt> <cmt> the original behaviour of open-drain-high was to use the open-drain mode of </cmt> <cmt> the gpio pin, and this seems to make driving a dht more reliable.  see </cmt> <cmt> issue #4233. </cmt>",make dht more reliable by reverting to open-drain mode of the gpio
2403,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. fixes #19536. </desc> <cmt> add: some test cases. </cmt> <cmt> fix: onvalueclickhandler type now gets option<tvalue> as first parameter, not a </cmt> <cmt> string value. </cmt>","fix #19536 - onvalueclickhandler string ""value"" type to option<tvalue> ""option"" type"
2404,"<desc> this replaces 5144 in addition to the aforementioned reasons, i am using these events for ""undoable"" change tracking in my application.  too many objectchanged events fire when dragging around the gizmo to effectively track a single transform action. i have added a commit of the math-only js file for two reasons: a) all tests now pass immediately after pulling b) the math functions are useful, and someone might want to use them on their own </desc> <cmt> added event for start gizmo drag </cmt> <cmt> adding math for test </cmt> <cmt> conflicts: </cmt> <cmt> examples/js/controls/transformcontrols.js </cmt> <cmt> adding event on gizmo click </cmt> <cmt> change name </cmt> <cmt> updating math </cmt> <cmt> adding math for test </cmt> <cmt> adding event on gizmo click </cmt> <cmt> updating math </cmt> <cmt> adding clickdone event triggered on completion of gizmo use in transformcontrols </cmt>",adding click and clickdone events to transformcontrols for gizmo interaction
2405,"<desc> added a new common client configuration parameter socket.connection.setup.timeout.ms to the networkclient. handle potential transportation layer timeout using the same approach as it handling potential request timeout. when no connected channel exists, leastloadednode() will now provide a disconnected node that has the least recent connection attempts. clusterconnectionstates will keep the connecting node ids. now it also has several new public methods to provide per connection relavant data. a unit test for the basic functionality of the new configuration a unit test for optimized leastloadednode() use docker scenarios for system tests. may add a duckertape test. </desc> <cmt> adding client configs and change the signature of networkclient </cmt> <cmt> clean the config names and types </cmt>",configurable tcp connection timeout and improve the initial metadata fetch
2406,"<desc> fixes #14583 . on get started page when navigating back in session history through browser back button, the ""installing mxnet"" options block does not update while the url was cut shorter. after the fix, when navigating back session history, the install options selection will be updated to previous state. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) update install options section when navigating back history avoid install options section buttons' default css style, the blue outline, when losing focus during selection update preview: </desc> <cmt> fix install option block history broke </cmt> <cmt> when history goes back, avoid button default css blue outline </cmt> <iss> install page history broken </iss>",fixed install page history broken
2407,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. the current typings are for react-form 1.3 which is rather out of date now. i've rewritten them from the ground up and changed the tests to all the code from the documentation. </desc> <cmt> rewrite the typings for react-form 2.12.1. </cmt> <cmt> fix linting issues </cmt>,update react-form typings to support 2.12.1
2408,"<desc> description: remove uvloop from dockerfiles add warning when requesting a stream not to use uvloop in combination with shell_command to avoid #22999 related issue (if applicable): #22999 </desc> <cmt> add warning about uvloop and shell_command </cmt> <cmt> remove uvloop from docker files"" </cmt>",remove uvloop from default install and warn about stream+shell_command
2409,"<desc> issue: #11721 don't denormalize params before sorting, as this has a perf cost that we don't want to pay. this is a breaking change but hopefully not a huge deal. notes: i didn't update the docs because that is happening in the 6.0-docs branch. we should probably just merge that to next now? do you think we should type / restrict the second entry in the array, as hinted at by the comment? </desc> <cmt> pass normalized record to the story sort function </cmt> <cmt> add migration notes </cmt>",pass normalized parameters to the story sort function
2410,"<desc> renamed set_active_producers intrinsic to set_proposed_producers and return an int64_t instead of a bool. the return value initially indicated whether the intrinsic was successful in proposing a new producer schedule. now -1 is returned to indicate failure and a non-negative number is returned to indicate success. if successful, set_proposed_producers returns the version of the new proposed producer schedule. this is a hard forking change. </desc> <cmt> rename set_active_producers to set_proposed_producers </cmt> <cmt> fix typo </cmt>",rename set_active_producers intrinsic to set_proposed_producers
2411,"<desc> fixes #19316 backports from #19403 npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fix crash with --inspect-brk under electron_run_as_node flag </desc> <cmt> fix: ensure that the node env is not bootstrapped before running inspector </cmt> <cmt> fix: ensure we wait for the inspect to disconnect </cmt> <cmt> this re-orders our node clean up so that we free the environment before </cmt> <cmt> the task runner is cleaned up as node uses the task runner during clean </cmt> <cmt> up.  it also calls waitfordisconnect() to ensure that inspector agents </cmt> <cmt> are notified that the context is going down. </cmt> <cmt> chore: update spec to catch sigabrt </cmt>",crash with --inspect-brk when running under electron_run_as_node
2412,"<desc> simply switching to the public api killed three nasty bugs. then i corrected the ""is it a video or a playlist"" mismatch by making youtubeie.suitable first run youtubeplaylistie.suitable and return false on positive. trust me, current behavior can't be reproduced with sane regexes. (plus some other pl-related changes and the definition as @classmethods of ie.working and ie.suitable) </desc> <cmt> switch ytplaylistie to api (relevant: #586); fixes #651; fixes #673; fixes #661 </cmt> <cmt> modified youtube video/playlist matching; fixes #668; fixes #585 </cmt>","playlists (i give up, implemented on the api)"
2413,<desc> i hereby agree to the terms of the cla available at:  changelog category: documentation for #10379 described always_fetch_merged_part added plausible to adopters fixed #11754 </desc> <cmt> revolg docsup-998 document the always_fetch_merged_part setting (#123) </cmt> <cmt> * add always_fetch_merged_part setting </cmt> <cmt> * revolg-docsup-998-add_always_fetch_merged_part_setting link fixed </cmt> <cmt> * apply suggestions from code review </cmt> <cmt> * add always_fetch_merged_part setting. updates. </cmt> <cmt> * update docs/en/operations/settings/settings.md </cmt> <cmt> * add always_fetch_merged_part setting. updates. </cmt> <cmt> clickhousedocs-605: minor fixes. </cmt> <iss> sql: grant all *.* in wrong order </iss>,description for the always_fetch_merged_part setting
2414,"<desc> we want to move away from using the deprecated mailplugin, and also merge @jeffkwoh's work from #17571. at the moment that pr feels risky, so my plan is to take the mailadapter concept, migrate the existing functionality from mailplugin into it and have mailplugin just use mailadapter. then when we're confident that work well, we can add in jeff's changes and move towards deprecating mailplugin entirely. this first step just adds the mailadapter and ports over get_send_to and anything related it needs to work, and has mailplugin start using the adaptor. i've set up this pr so that there are two commits - the first commit just blanket copies things in an unworking state from mailplugin. the second commit has all the modifications needed to make things work, so for easy of review it's probably best to just look at the diff of the second commit. tests are duplicated from mailplugin. we'll eventually remove the mailplugin tests once we deprecate, but they help make sure it's still working as expected for the moment. </desc> <cmt> initial commit for mail project. </cmt> <cmt> - include new mailadapter </cmt> <cmt> - add get_send_to method, copy/pasted from mailplugin. customizations in next commit </cmt> <cmt> - make get_send_to work as expected. </cmt> <cmt> - migrate get_sendable_users across </cmt> <cmt> - migrate tests into test_adapter.py. these are mostly just copy/pasted from the previous tests. </cmt> <cmt> we'll eventually remove the tests from the plugin once we remove it. </cmt>",create mail sub-project and migrate get_send_to out of mailplugin
2415,"<desc> for whatever reason, we often have users who create a reference directory (eg, refs/heads/foo/bar) and then try to create a new reference in one of those components (eg, refs/heads/foo). our error message in that case is not very actionable - since we use a git_filebuf, we will successfully create the lockfile, but then we will likely fail to create the reflog (since there's a directory in its place). as a result, the error message looks something like: could not open 'c:/temp/testrepo.git/logs/refs/heads/new-dir' for writing: access is denied. this adds some tests to ensure that we clean up around empty directories properly.  (we do!  but i didn't see anything testing this directly and i wanted to make sure that this was legitimately user error and not us failing to clean something up.) this updates git_filebuf so that it will check for the existence of a directory in place of the target file.  it will fail early (with git_edirectory) in that case. now the reference creation code will check for that - so a non-empty directory in place of the reference will emit an error (with error code git_eexists): cannot lock ref 'refs/heads/new-dir', there are refs beneath that folder and reflog creation when a non-empty directory exists in place of the reflog file location will also emit an error (again, with error code git_eexists): cannot create reflog at 'refs/heads/new-dir', there are reflogs beneath that folder this is roughly in line with git.git's messages for both of these cases. </desc> <cmt> reflog: test reflog is deleted when ref is deleted </cmt> <cmt> filebuf: detect directories in our way </cmt> <cmt> when creating a filebuf, detect a directory that exists in our </cmt> <cmt> target file location.  this prevents a failure later, when we try </cmt> <cmt> to move the lock file to the destination. </cmt>",improve error messages when dirs prevent ref/reflog creation
2416,"<desc> this adds environment filtering on group tag details, previously environments were ignored. closes  adds an error message when the current environment selection has no results. this gif shows: navigating to a specific tag details changing environment to one that returns results changing environment to one with no results with new error message </desc> <cmt> pass environments to grouptag values and details </cmt> <cmt> add tags not found error when filtering by environment </cmt> <cmt> group tag accept environments as an array </cmt>",add environment filtering on issue tag details page
2417,"<desc> what did you implement: closes #3073 added support for async sources in the variable system, beginning with the file source. your js files can now perform async operations and return a promise that would be resolved by the variable system. how did you implement it: previously, the variable system was completely sync, so i had to control the flow of the entire system and it's methods and make it promise-ready. all methods now return a promise to assure everything is running in the correct flow. i've also ditched the traverse module since it doesn't work smoothly with promises and instead i'm using a lodash based implementation for object traversal and updates. how can we verify it: i've tested 17 different cases for the variable systems that covers pretty much everything the variables system can do, including the new promises in files support. here's the config i used, but feel free to get crazy creative: # serverless.yml service: serverless-async-vars provider: name: aws runtime: nodejs6.10 custom: data: # some data to reference zero: 0 nooo: false vara: ${env:testing} # env vars varb: ${opt:stage} # opts vars varc: ${self:provider.name} # self vars vard: ${env:testing}-${opt:stage} # two vars in a string vare: ${opt:${env:testing}hoo} # nested vars varf: ${opt:region, opt:stage} # overwrite functionality varg: ${file(./vars.js):hello} # js file running sync varh: ${file(./vars.js):promised} # js file running async/promised new!!! vari: ${file(./vars.json):hoo.hoo2} # deep json file varj: ${file(./vars.yml):hee.hee2} # deep yaml file vark: my stage is ${opt:stage} # vars sub string varl: your account number is ${opt:number} # number vars as sub string varm: ${opt:number} # preserving data type varn: ${self:plugins, self:package, self:service} # multiple overwrites when empty object and undefined varo: ${self:custom.data.zero, self:service} # shouldn't overwrite 0 values varp: ${self:custom.data.nooo, self:service} # shouldn't overwrite false values varq: ${self:} # referencing the entire config file functions: hello: handler: handler.hello you'll need the testing env var to be set, and also the following vars files in your service root dir: vars.js module.exports.hello = () => { // sync code return {nested: 'world'}; module.exports.promised = () => { // async code return promise.resolve('world'); vars.yml hee: hee2: haa vars.json ""hoo"": { ""hoo2"": ""hum"" you'll need to run the following command against this service for full test coverage: sls package --stage dev --yahoo hi --region us-east-1 --number 1234 todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> supported promises in the variable system </cmt> <cmt> renamed promises </cmt> <iss> support promises in variables referencing javascript ( ${file(file.js):value} ) </iss>",added support for promises in the variable system
2418,"<desc> my main sources of information are rfc401, the rust irc channel, and a bunch of experiments to figure out what rustc currently supports. note that the rfc calls for some coercion behaviour that is not implemented yet (see #18469). the documentation in this pr mostly covers current behaviour of rust and doesn't document the future behaviour. i haven't written about receiver expression coercion. i would be happy to rewrite/adapt the pr according to feedback. r? @steveklabnik </desc> <cmt> extend rust reference with a section about subtyping </cmt> <cmt> extend rust reference with a section about type coercions </cmt>",extend rust reference with section about subtyping and type coercions
2419,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update inline-style-prefixer-tests.ts </cmt> <cmt> update index.d.ts </cmt> <cmt> update index.d.ts </cmt>",update type definitions for the latest version of inline-style-prefixer
2420,"<desc> this pr fixes a bug where user could set vertical value of anchororigin to center, which is not supported. closes #13234 </desc> <cmt> remove 'center' value from anchororigin proptype </cmt> <cmt> [snackbar] remove 'center' value from anchororigin proptype </cmt>",remove non supported property anchororigin.vertical=enter
2421,<desc> handles part of #10733 (loosely following conventions found in #13902) closes #15486 adds as_frame functionality for the california housing dataset loader (fetch_california_housing) continuing work begun by @gitsteph at sf scikit sprint (nov 2019) </desc> <cmt> adding as_frame functionality for california housing dataset loader </cmt> <cmt> fixes for as_frame to fetch_california_housing </cmt> <cmt> minor change </cmt> <cmt> forgot to rename feature_names to columns here </cmt> <cmt> changes to use pandas concat and make conversion to df more generalizeable </cmt> <cmt> moved _convert_data_dataframe to _base.py </cmt> <cmt> breaking at 79 chars </cmt> <cmt> added test_fetch_asframe </cmt> <cmt> moved test to test_california_housing.py </cmt> <cmt> moved return_x_y handling below as_frame check </cmt> <cmt> fixed linting issues caught by flake8 </cmt> <cmt> using pytest.importorskip to handle test environments without pandas installed </cmt> <cmt> skip test if dataset is not available in test env </cmt> <cmt> update sklearn/datasets/tests/test_california_housing.py </cmt> <cmt> removed unneeded parens </cmt> <cmt> update sklearn/datasets/tests/test_california_housing.py </cmt> <cmt> removed unneeded parens </cmt>,enh adding as_frame functionality for ca housing dataset loader
2422,"<desc> previous pr was reverted due to bad merge. this pr fixes the conflict and reland the previous commit related issues #43780 </desc> <cmt> reland ""refactors global key duplication detection (#46183)"" </cmt> <cmt> this reverts commit d2b66dbfcfdad68473fc4366e3042cd2e17706ac. </cmt> <cmt> fix test </cmt>",reland refactors global key duplication detection
2423,"<desc> original pull-request #15667 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> trying to fix race in amqp-cpp </cmt> <cmt> fix cmake </cmt> <cmt> fix race in amqcpp </cmt>",cherry pick #15667 to 20.8: fix race in amqcpp
2424,"<desc> i ordered some atmega328-pu chips by mistake not realising they weren't supported in qmk. with money scarce and the coronavirus delaying postage i decided it was worth adapting qmk to work with it. i compile the atmega328 usbasploader bootloader separately on my machine, i don't know how to integrate a custom bootloader in qmk, but this much works for me and it shouldn't break anything. i want to avoid making a keyboard that i don't know how to program in 5 years time. that's why i submitted the change. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> update config_common.h </cmt> <cmt> added support for the older pin compatible atmega328 mcu, which is cheaper than the atmega328p </cmt> <cmt> update bootloader.c </cmt>",adds support for the atmega328
2425,"<desc> this pr changes (delete as applicable) i have fixe types on input, gameobjects, animation and display. next: i end types on matter.js :) </desc> <cmt> update jsdoc on input </cmt> <cmt> update jsdoc on gameobjects </cmt> <cmt> update jsdoc on animation </cmt>","update jsdoc on input, gameobjects, animation and display"
2426,<desc> update docs based on legal review demote docs links from latest to v2.2 fix broken docs links in readme select one: select any that apply: </desc> <cmt> disable how to add/remove participants from privacy explainer :doc </cmt> <cmt> update privacy feature explainer with legal edits :doc </cmt> <cmt> demote eos/latest to eos/v2.2 links :doc </cmt> <cmt> demote welcome/latest to welcome/v2.2 links :doc </cmt> <cmt> fix broken links in readme file :doc </cmt>,"update docs, fix links, add legal feedback - 2.2"
2427,"<desc> supersedes #5162 (for now). fixes #4157, #4451, #4672, #4119. this pr brings 2 changes. fix for private npm packages fixes unauthed requests to yarnpk.com by treating yarnpkg.com as requests to npmjs.org in isrequesttoregistry. feature - simpler support for multipath registries before, if you wanted to use something like artifactory, nexus or vsts where meta url's differ from tarball urls, you had to configure like so: @scope:registry= //artifactory.example.com/api/npm/registry/:_authtoken=xxxx custom-host-suffix=artifactory.example.com but now you can do this instead: @scope:registry= //artifactory.example.com/api/npm/registry/:_authtoken=xxxx //artifactory.example.com/api/tarballs/:_authtoken=xxxx this way we don't introduce a new option, we're just saying, aha, when accessing this kind of url, make sure to authenticate it. i personally find it slightly more intuitive. i've added a new test case to requestistoregistry unit test. i've redone the request authorisation tests. it's a small hit to the ergonomics of the tests (harder to comment some of them or use skip/only feature). but compacting them all from code to data means we can be a lot more thorough with all the different cases. the intention was to preserve all of the existing test cases, but add many more. in particular, here are the different common scenarios i tested: using npm as default registry and using private registry for scoped packages using scoped packages in both npm and private registry using authenticated npm and using private registry for scoped packages using npm with always-auth and using private registry for scoped packages using private registry as default registry and using scoped packages on npm registry and then also tested registry url and request url path sensitivity using custom-host-suffix for registries where pathnames for meta and tarballs differ using multiple authtoken entries for registries where pathnames for meta and tarballs differ the pr is split into somewhat independent commits if that helps. </desc> <cmt> add more thorough tests for registries.npm.request authorisation </cmt> <cmt> fix the bug where npm private packages where not authed correctly </cmt> <cmt> remove the old tests that have now been compacted into test gen </cmt> <cmt> clarify the naming of the request url check </cmt> <cmt> alternative approach for supporting registries with multiple paths </cmt> <cmt> improve the naming and order of the test suites </cmt> <iss> yarn writes registry.yarnpkg.com to lockfile when private scoped packages is from registry.npmjs.org </iss>",fixes authentication conditions and logic with registries
2428,"<desc> fixed cluster page show not consistency bug change implementation for fixed bug ok format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> fixed(cluster): fixed raft cluster state </cmt> <cmt> chore(cluster): delete no used note </cmt>",fixed cluster page show bug
2429,"<desc> in the existing code, gcs_client_->disconnect() is called right after io_service_.stop is called, but the io thread hasn't been fully stopped yet. ray/src/ray/core_worker/core_worker.cc lines 534 to 540 e72838c void coreworker::disconnect() { io_service_.stop(); if (connected_) { connected_ = false; if (gcs_client_) { gcs_client_->disconnect(); } in servicebasedgcsclient::disconnect(), gcs_pub_sub_ and redis_gcs_client_ are released, which means the underlying redisasynccontext instances are destructed. ray/src/ray/gcs/gcs_client/service_based_gcs_client.cc lines 90 to 98 e72838c void servicebasedgcsclient::disconnect() { ray_check(is_connected_); is_connected_ = false; detect_timer_->cancel(); gcs_pub_sub_.reset(); redis_gcs_client_->disconnect(); redis_gcs_client_.reset(); ray_log(debug) << ""servicebasedgcsclient disconnected.""; } redisasyncfree is called in ~redisasynccontext(). ray/src/ray/gcs/redis_async_context.cc lines 31 to 36 e72838c redisasynccontext::~redisasynccontext() { if (redis_async_context_ != nullptr) { redisasyncfree(redis_async_context_); redis_async_context_ = nullptr; } } in the implementation of redisasyncfree, the cleanup function of the event lib is invoked ( ray/src/ray/gcs/asio.cc line 111 e72838c void redisasioclient::cleanup() {} that is to say, asio is not detected from the redisasynccontext instance. before the io thread stops, and if the redisasynccontext instance is freed by redisasyncfree, the io thread may continue calling redisasioclient::handle_io. furthermore, because redisasioclient instances are declared after rediscontext, the redisasioclient instances are destructed before redisasynccontext instances (included by rediscontext). ray/src/ray/gcs/redis_client.h lines 96 to 103 e72838c // the following contexts write to the data shard std::vector<std::shared_ptr<rediscontext>> shard_contexts_; std::vector<std::unique_ptr<redisasioclient>> shard_asio_async_clients_; std::vector<std::unique_ptr<redisasioclient>> shard_asio_subscribe_clients_; // the following context writes everything to the primary shard std::shared_ptr<rediscontext> primary_context_; std::unique_ptr<redisasioclient> asio_async_auxiliary_client_; std::unique_ptr<redisasioclient> asio_subscribe_auxiliary_client_; in short, the memory of redisasioclient is freed before redisasyncfree is called, and the io thread may continue trying to access redisasioclient via redisasioclient::handle_io, which leads to crash. this pr applies a quick fix by moving the position of gcs_client_->disconnect() to make sure the io thread has been stopped before invoking it. the fix has been verified by #10674, which adds a while loop to run java test indefinitely until it fails. travis ci log shows that the java test ran successfully for 9 times before the job was killed by travis due to timeout. an once-for-all fix would be: to make sure asio is detached from a redisasynccontext instance when the instance is about to be freed. make sure the memory of redisasioclient is always valid while accessing it in the io thread. we've done it in ant financtial's internal repository, but it requires a lot of code changes. especially that redisasioclient::cleanup() needs to be invoked in the io thread, which seems impossible to me if we don't refactor upper-level classes like redisclient. closes #10693 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> test java ci crash </cmt> <cmt> update .travis.yml </cmt> <cmt> update .bazelrc </cmt> <cmt> update code </cmt> <cmt> debug log </cmt> <cmt> update listener </cmt> <cmt> update listener </cmt> <cmt> update test.sh </cmt> <cmt> while true </cmt> <cmt> update test.sh </cmt> <cmt> apply fix </cmt> <cmt> revert test changes </cmt> <cmt> revert test changes </cmt> <iss> [java] a fatal error has been detected by the java runtime environment </iss>",fix java ci crash caused by incorrect destruction order in core worker
2430,"<desc> the packet api introduced a breaking change in their device.operating_system object while referencing the slug property. this needed to be moved from a property notation device.operating_system.slug to a dict notation device.operating_system['slug'] packet dynamic inventory script error 1 # ./packet_net.py --list traceback (most recent call last): file ""./packet_net.py"", line 273, in get_devices_by_project self.add_device(device, project) file ""./packet_net.py"", line 354, in add_device self.push(self.inventory, device.operating_system.slug, dest) attributeerror: 'dict' object has no attribute 'slug' error: ""'dict' object has no attribute 'slug'"", while: getting packet devices error 2: # ./packet_net.py --list traceback (most recent call last): file ""./packet_net.py"", line 273, in get_devices_by_project self.add_device(device, project) file ""./packet_net.py"", line 382, in add_device self.inventory[""_meta""][""hostvars""][dest] = self.get_host_info_dict_from_device(device) file ""./packet_net.py"", line 404, in get_host_info_dict_from_device device_vars[key] = value.slug attributeerror: 'dict' object has no attribute 'slug' error: ""'dict' object has no attribute 'slug'"", while: getting packet devices </desc> <cmt> fixed 'slug' bug in packet_net.py that was caused by a breaking change in the packet api. </cmt> <cmt> removed some debugging and comments i had left. </cmt>","fix packet dynamic inventory ""slug"" issue."
2431,"<desc> ref kubernetes/kubectl#83 which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): use k8s.io/api/core/v1 replace k8s.io/kubernetes/pkg/api use k8s.io/client-go/kubernetes/typed/core/v1 replace k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/core/internalversion release note: </desc> <cmt> remove dependency from service generator </cmt> <cmt> remove dependency from top command </cmt> <cmt> remove dependency from kubectl/metricsutil </cmt>",remove kubectl dependency internal version
2432,"<desc> replaced """" with "" after ftc532 related issue (if applicable): fixes # the pull request is done against the latest dev branch the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc4 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> update local repo </cmt> <cmt> update local repo </cmt> <cmt> fixed a typo in languages </cmt>",fixes a typo in languages
2433,<desc> address part of #15440. address numpydoc validation to gradientboostingclassifier and gradientboostingregressor no. </desc> <cmt> doc fix numpydoc requirements for gradientboostingregressor </cmt> <cmt> doc fix numpydoc requirements for gradientboostingclassifier </cmt> <cmt> doc fix numpydoc requirements for gradientboostingregressor </cmt>,doc address numpydoc validation to gradientboosting*
2434,"<desc> what did you implement: switched from using fs directly to graceful-fs in lambda packaging logic. after #3924 was taken in, high concurrency may occur in file system operations (due to that, users may encounter emfile or enfile errors, as e.g. reported by @pmuens) how did you implement it: replaced require to fs to graceful-fs in corresponding places how can we verify it: run tests, and @pmuens please verify it fixes issue you observed in your setup. is this ready for review?: yes is it a breaking change?: no </desc> <cmt> cleanup unnecessary promisification </cmt> <cmt> use graceful-fs for concurrent file operations </cmt>",rely on graceful-fs for concurrent file operations (lambda packaging)
2435,"<desc> this pr fixes #102261 first time contributor here, let me know if there's a better approach to this. i essentially added new settings for scroll sensitivity outside of the editor and terminal, and propagated those settings down through the updateoptions methods on the various view objects. my testing showed this worked at least for the explorer and find panels. sorry for not commenting on the issue and coming in hot with a pr, i did not expect to have a solution as timely as i did. </desc> <cmt> add scroll options to list view options </cmt> <cmt> add scrollable options to list view options </cmt> <cmt> add and propogate new sensitivity options </cmt> <iss> list: provide `list.mousewheelscrollsensitivity` setting </iss>",add settings for list scroll sensitivity outside of the editor and terminal
2436,"<desc> refactoring using existing tests if relevant, link to documentation update: n/a summary this piece of code was very complicated and hard to read due to all the chaining. it seemed like a good use case for a reduce instead of all extra array iterations. no other information n/a </desc> <cmt> chore: fix yarn lock </cmt> <cmt> refactor: collapse several array iterators into single reduce </cmt>",collapse several array iterators into a single reduce
2437,<desc> xbmc turkish translation update: based on english strings commit f0e75fa confluence skin turkish translation update: based on english strings commit 72696c4 </desc> <cmt> turkish translation update: </cmt> <cmt> based on english strings commit f0e75fab88 </cmt> <cmt> confluence turkish translation update: </cmt> <cmt> based on english strings commit 72696c450c </cmt>,xbmc and confluence skin turkish translation update
2438,<desc> no more typed_this() in libjs :^) </desc> <cmt> libjs: remove leftover typed_this() declarations </cmt> <cmt> libjs: convert intl.displaynames.prototype to be a prototypeobject </cmt> <cmt> libjs: convert intl.listformat.prototype to be a prototypeobject </cmt> <cmt> libjs: convert intl.locale.prototype to be a prototypeobject </cmt> <cmt> libjs: convert intl.numberformat.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.calendar.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.duration.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.instant.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.plaindate.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.plaindatetime.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.plainmonthday.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.plaintime.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.plainyearmonth.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.timezone.prototype to be a prototypeobject </cmt> <cmt> libjs: convert temporal.zoneddatetime.prototype to be a prototypeobject </cmt>,make intl and temporal prototypes a prototypeobject
2439,"<desc> fixes #1130 </desc> <cmt> adding testcase for the incorrect eliding of the import declarations </cmt> <cmt> instead of setting fresh value, or the value with existing one of if alias is referenced in value position </cmt> <cmt> fixes #1130 </cmt> <iss> incorrectly elided import declaration (tsc 1.1) </iss>",fix the incorrect eliding of import declaration
2440,"<desc> discussion is in #3436 this allows people using the :head method to pass content_type as an option. the other issue in #3436 is what the value should be set to by default. as i note, according to the rfc the head method content-type value should be set to the value which would be received under content-negotiation for a get request to the same resource. as this is a much more complicated and separate issue, i do not attempt to solve it here. </desc> <cmt> add failing test re #3436 which demonstrates content_type is not respected when using the :head method/shortcut </cmt> <cmt> if content_type is explicitly passed to the :head method use the value or fallback </cmt>",address actionpack head method not respecting explicitly set content-type #3436
2441,"<desc> closes #41839 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry screenshot below for updated docs </desc> <cmt> update io.rst </cmt> <cmt> modifying dataframe.to_csv to reflect location. </cmt> <iss> doc: input/output page contains only input functions </iss>",add .to_xyz to io docs
2442,"<desc> in deploy notifications, we currently truncate the name of the release to 12 characters. this makes sense when the release name is a long string of hexadecimal but can cause problems when for users with different formats. for example if you had a previous release release@v1.9 and then deployed release@v1.10, you'd only see release@v1.1 which could be really bad. this pr just removes the truncation. </desc> <cmt> fix typos </cmt> <cmt> do not truncate version </cmt> <cmt> fix strings </cmt>",do not truncate version string
2443,"<desc> closes #9930 when you change the username of a user through the administration, the web interface was failing to load the user data in the userinfo view. </desc> <cmt> fixed issue with empty panel when changing user's username </cmt> <cmt> lint </cmt>",empty panel after changing a user's username
2444,"<desc> this change adds a ld script for the chitu f103 based boards (and the same encryption scheme is used on pretty much all chitu boards), and a script to encrypt the resulting firmware so sd based updates can be used. allows users to update via sd card, meaning they can revert to chitu firmware if they so desire. when a pr is submitted to update the sd/lcd pins, this should allow full functionality with the user's choice of firmware. note the ld script length doesn't match the offset, but it does match the value the bootloader checks for. #7264 #14655 </desc> <cmt> add support for chitu bootloader encryption. </cmt> <cmt> save off chitu pins. </cmt> <cmt> rename the encryption script. </cmt> <cmt> add support for chitu bootloader encryption. </cmt> <cmt> rename the encryption script. </cmt> <cmt> update ld script </cmt> <cmt> pretty things up. </cmt> <cmt> remove a library from the ignore list. </cmt>","chitu board support (e.g., tronxy x5s)"
2445,"<desc> fixes some unused parameter warnings. xcode (apple clang version 13.0.0 (clang-1300.0.29.3)) yelled at me. macos 12.0.1, still compiles and warnings are gone. also still compiles on windows and linux ci. code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> ui: fix unused lambda capture warning </cmt> <cmt> obs-filters: fix unused parameter warnings with speex disabled </cmt> <cmt> text-freetype2: fix unused parameter warning </cmt>",fix some unused parameter warnings
2446,"<desc> for java worker, we generate a uuid string as the namespace if a job is not specified a namespace by user. #16474 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> support anonymous namespace implicily. </cmt> <cmt> fix lint </cmt>",support generating a uuid string as the anonymous namespace for java worker.
2447,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. fix for issue #29444 </desc> <cmt> fix typo for startfragprefetch </cmt> <cmt> add startfragprefetch to test </cmt>",hls.js  fix typo for startfragprefetch config
2448,<desc> changes are as follows: minor refactor on some of the files not touching any of the backlight or rgb stuff yet fixes configurator json file adds support for ortho_4x4 layout checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> correct configurator info.json </cmt> <cmt> refactor to support ortho_4x4 </cmt> <cmt> refactor to support ortho_4x4 - remove commented out code </cmt>,refactor jj4x4 to enable ortho_4x4 layout
2449,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldnt have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add types for audio-context and audio-play </cmt> <cmt> test fixes </cmt> <cmt> more test fixes </cmt>",add types for audio-play and audio-context
2450,"<desc> added lots of punctuation, correction of grammar/expression etc. (only for 2 files so far...) </desc> <cmt> added commas, used html code for umlaut </cmt> <cmt> corrected grammar, punctuation, expression... (not entirely done) </cmt> <cmt> corrected grammar, punctuation, expression... </cmt> <cmt> some more corrections (also: markup) </cmt>",corrected (parts of) german translation
2451,"<desc> this pr uses a different mechanism for getting the scope of completion by looking at the context token (here called the previoustoken). we then climb up the ast through parent references from that token and find a node that ""embraces""/""encompasses"" the current position. the logic is shared (i.e. ripped out of) the smart indenter and augmented to be more complete. fixes #1410, #1429, #1674, and #2292. </desc> <cmt> fixed harness. </cmt> <cmt> added tests for completions before a new scope. </cmt> <cmt> tests for #2292. </cmt> <cmt> added tests. </cmt> <cmt> added tests for #1410. </cmt> <cmt> fixed up tests. </cmt> <cmt> moved logic from smart indenter; use 'scope nodes' for completions. </cmt> <cmt> fixed missing marker. </cmt> <cmt> removed negations from test. </cmt> <cmt> fixed up more tests. </cmt> <cmt> added completion check for prefix-unary, binary, and conditional expressions. </cmt> <cmt> conflicts: </cmt> <cmt> src/services/formatting/smartindenter.ts </cmt> <cmt> added index signature case. </cmt> <cmt> account for typeof expressions, added test. </cmt> <cmt> more cases and tests for them. </cmt> <cmt> start using nodeismissing. </cmt> <cmt> start handling element access expressions. </cmt> <iss> arrow function parameters do not show in completion list when in an unclosed call site </iss>",better completions in incomplete constructs
2452,<desc> i hereby agree to the terms of the cla available at:  added support for custom settings section in dictionaries. also fixes issue #2829. detailed description / documentation draft: documentation added. </desc> <cmt> raw add of direct dictionaries (doesnt work) </cmt> <cmt> added settings parsing and initialisation to dictionarystructure </cmt> <cmt> some fix for errors with shadowing name </cmt> <cmt> added support of custom settings to filedictionarysource </cmt> <cmt> added support of custom settings to all sources that needed having them </cmt> <cmt> fixed bug with clickhousedictionarysource & test for all sources added </cmt> <cmt> documentation edit </cmt> <cmt> minor changes </cmt>,add custom settings support for certain dictionary sources
2453,<desc> this pr adds a working example of next.js forms that i wrote with the next.js forms guide. related issues linked using #32525 make sure the linting passes by running yarn lint fixes #32538 </desc> <cmt> feat: forms example </cmt> <cmt> docs: deploy button </cmt>,working example for building forms with next.js
2454,<desc> use extended attribute on files to track which files have been uploaded (unfortunately os.getxattr() and os.setxattr() do not get compiled into python on android) </desc> <cmt> cffi xattr function wrapper </cmt> <cmt> xattr wrapper error handling </cmt> <cmt> xattr tests </cmt> <cmt> use xattr for tracking files uploaded </cmt>,do not delete files after uploading
2455,"<desc> description: this pr adds the x-envoy-attempt-count header to downstream responses. risk level: low, used via new config value that defaults to false. testing: updated tests to verify that the header is being set. new unit tests docs changes: updated docs release notes: added. </desc> <cmt> router: add x-envoy-attemp-count on downstream responses </cmt> <cmt> spelling </cmt> <cmt> missed version </cmt> <cmt> docs </cmt> <cmt> docs </cmt>",add x-envoy-attempt-count on downstream responses
2456,"<desc> relates to #3846 adds a minimal example to the isolationforest class. the example is very artificial and the data is not that reflective of common anomaly detection examples like here: plot_anomaly_comparison. however, i found the make_blob() examples with many data points hard to comprehend without plots. </desc> <cmt> add minimal example to isolationforest class. </cmt> <cmt> add fit to assignment to avoid output being printed to the console </cmt> <cmt> remove left-over, unecessary code </cmt>",doc add minimal example to ensemble.isolationforest class
2457,"<desc> aside from during compilation, templates need way to retrieve their source, in order to report template errors. however, we'd prefer not to keep the source code of templates in memory, so the source was removed after template compilation. previously (rails <= 5.2), this was handled by template#refresh, which would try to round-trip a new copy of the template from the resolver. this worked in most cases, but was brittle, wouldn't necessarily find the correct template, and relied on being able to disable cache and get a different copy of the template (which hadn't been compiled!, so the source was still around). i also think this assigned more meaning to the template having a virtual_path than i think it should have. @tenderlove improved this in #35119, by introducing actionview::filetemplate, which doesn't need to be refreshed and can always retrieve its source from disk. this pr introduces the concept of a ""template source"", an object which responds to #to_s to return the source code of a template and should be marshallable. plain strings are valid template sources. we introduce one template source class (other than strings), template::source::file, which reads a file from disk. this replaces actionview::filetemplate, as we can just use that source in template. this also no longer removes the @source from the template after compilation, and therefore makes refresh a no-op (and deprecates it). in a standard (without custom resolvers) application, all cached templates will use template::source::file, source code is only kept around for temporary templates (ex. from render inline:). applications with custom resolvers can implement their own source to allow if they have the ability to be reloaded, otherwise they will work as they used to, other than keeping the source in memory. this should allow us to cache more aggressively (and hopefully eventually eager load) in the template resolver, since we don't need the ability to retrieve an uncached, uncompiled version of the template. </desc> <cmt> don't discard source after rendering </cmt> <cmt> previously, we would discard the template source after rendering, if we </cmt> <cmt> had a virtual path, in hopes that the virtual path would let us find our </cmt> <cmt> same template again going through the resolver. </cmt> <cmt> previously we discarded the source as an optimization, to avoid keeping </cmt> <cmt> it around in memory. by instead just reading the file every time source </cmt> <cmt> is called, as filetemplate does, this is unnecessary. </cmt> <cmt> don't call template#refresh </cmt> <cmt> now that template#source will always return a source, this is </cmt> <cmt> unnecessary. </cmt> <cmt> add actionview::template::sources::file </cmt> <cmt> deprecate template#refresh </cmt>","introduce template::source::file, replacing filetemplate and template#refresh"
2458,"<desc> follow-up for #13142. </desc> <cmt> networkctl: show carrier in green for loopback iface </cmt> <cmt> we don't ever expect anything different, so let's hightlight </cmt> <cmt> that carrier in this case is ok. </cmt> <cmt> networkctl: split out helper function </cmt>",networkctl support for ssid and bssid
2459,"<desc> adds project tagging for: nativescript ionic firebase aws amplify </desc> <cmt> update workspacestats.ts </cmt> <cmt> add nativescript project tagging. </cmt> <cmt> revert ""update workspacestats.ts"" </cmt> <cmt> this reverts commit fb66be506b2c16042ad9d7d27fc04339231f5735. </cmt> <cmt> add ionic tagging. </cmt> <cmt> update workspacestats.ts </cmt> <cmt> add aws project tagging. </cmt> <cmt> add firebase tagging. </cmt> <cmt> update workspacestats.ts </cmt>",add project tagging for new project types.
2460,"<desc> addresses part of #72795. this pr makes it such that if an l10n.yaml file exists in a flutter project, it will be used over the command line arguments for flutter gen-l10n. the rationale here is that giving the user the option to use flutter gen-l10n doesn't make sense and can be confusing. the second a flutter app runs or builds with the l10n.yaml file present, the existing generated files will be overwritten when flutter automatically regenerates the localization files based off of l10n.yaml. also did some refactoring for some function and class locations to tidy things up. i added the following tests: a test to ensure that the l10n.yaml file is used over the command line arguments a test to ensure that a message is logged to the user that the l10n.yaml arguments were used over the ones provided in the command line before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> reorganize files </cmt> <cmt> use l10n.yaml instead of command line args </cmt> <cmt> fix typo </cmt> <cmt> slight modifications </cmt>",use l10n.yaml file instead of command line arguments if it exists
2461,"<desc> this pr adds the script from @badsyntax at  during testing, found that i left the button and badge variants in there, as well as some other small variables from cards, forms, etc. fixes #18623. </desc> <cmt> cleanup offsets </cmt> <cmt> no need for offset, use justify-content-center </cmt> <cmt> add bash script to lint our variables </cmt> <cmt> no xs sizes being used </cmt> <cmt> button variants are generated from -colors sass map </cmt> <cmt> badge variants are generated from -colors sass map </cmt> <cmt> remove some unused vars, restore table-active variant </cmt>","add bash script for linting variables, remove unused ones"
2462,"<desc> force_builders=linux,windows,mac,docs </desc> <cmt> fix possible divided by zero and by negative values </cmt> <cmt> only 4 elements are used in these arrays </cmt> <cmt> fix uninitialized member </cmt> <cmt> use boolean type for semantic boolean variables </cmt>",fix some errors found by static analyzer.
2463,<desc> resolve issue #10323 dm=. and dm.* weren't added like discussed in that issue. i don't see any other currentaddr+r2 output modifier commands and implementing them would be hacky. </desc> <cmt> changed dm. to output rows like dm </cmt> <cmt> made dm. output like dm and added dmq. </cmt>,make dm. output like dm and add dmq.
2464,"<desc> this fixes #5610. works by adding a pyufunc_isfinitetyperesolver for isfinite ufunc. it does what pyufunc_isnattyperesolver does for datetime64 and timedelta64 objects, and calls  pyufunc_defaulttyperesolver for all other dtypes. </desc> <cmt> enh: allow datettimes in isfinite </cmt> <cmt> i am not quite sure whether this should be done somewhat more elegant </cmt> <cmt> especially with the typeresolver. </cmt> <cmt> maint: added missing return in pyufunc_isfinitetyperesolver </cmt> <cmt> tst: testing isfinite on datetime and timedelta objects. </cmt> <cmt> added test: test_datetime.testdatetime.test_isfinite. </cmt> <cmt> it just checks the reverse of test_isnat. </cmt> <iss> add `isfinite` support for `datetime64` and `timedelta64` </iss>",isfinite support for datetime64 and timedelta64
2465,"<desc> after reviewing #9193, i found a few issues with type resolution in async functions following the introduction of never. this change addresses these issues and adopts new typings for promise and promiselike that take advantage of other recent changes in the type checker to support never. fixes #9193. </desc> <cmt> updates type definitions for promise and promiselike, fixes issues in async functions due to introduction of never type. </cmt> <cmt> fixes #9193. </cmt> <cmt> fix linter warning </cmt>","update promise and promiselike, fix async functions issues with never."
2466,<desc> i have added support for the additional pins on the atmega2560 that are accessible on rambo. i also added the arduino hardware files to make compilation easier. this is to address issue #528 in marlin and #9 in rambo. thank you! </desc> <cmt> add additional pins to avr2560 for rambo lcd </cmt> <cmt> add pins for rambo lcd </cmt> <cmt> add rambo arduino addons </cmt>,"rambo lcd support, additional pins, and arduino add ons"
2467,<desc> this is the implementation and fixes associated with the safe nsnumber bridging changes; applied to the swift 4.0 branch </desc> <cmt> [foundation] nsnumber bridging and numeric types (se-0170) </cmt> <cmt> validate the exactly pattern of double from nsnumber to ensure proper ieee 754 non lossy conversions </cmt> <cmt> account for floating point exactly conversions and disable some tests that are caused by sr-4634 </cmt> <cmt> rename nsnumber bridge tests to be clear on what they do </cmt> <cmt> [foundation] work-around ambiguity of initializers by avoiding using bitpattern in literal cases that could be claimed as double values </cmt> <cmt> [foundation] disable more nsnumber test failures due to incorrect float representations </cmt>,se-0170 cherry pick for swift 4.0
2468,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> added names, fastpath parameters explaination to pandas.series in file series.py </cmt> <cmt> added names, fastpath parameters explaination to pandas.series </cmt>","added names, fastpath parameters explanation to pandas.series"
2469,"<desc> until now, the contents of err_data.c were just copy-pasted into the podspec template long time ago and there wasn't even a note that the contents need to be updated regularly.  as a result: the contents of err_data.c were very out of data (and possibly very broken), i'm surprised it still worked. i made the mako .template just spit out the contents of the existing err_data.c file into the podspec instead. it has the same result but it doesn't need any extra maintenance and it doesn't pollute the .podspec.template. (among all the ugly hacks i've seen, the original trick was one of the dirtiest i've seen and also the most broken). btw, the idea in the original todo to ""translate err_data_generate.go into a bash or ruby script"" is just crazy. </desc> <cmt> get rid of the copy-pasted err-data.c in boringssl podspec </cmt> <cmt> regenerate </cmt>",get rid of the boringssl podspec err_data.c hack
2470,"<desc> when the feature flag sqllab_backend_persistence is set to false, user data is currently saved in local storage. a recent change added roles information to the bootstrap user object. but with the flag off, local storage data ends up overwriting the bootstrap data, and the roles are lost, which breaks the page. this change removes user data from local storage, and prevents it from overwriting the bootstrap data. test plan turn the flag off checkout a commit from before a7a011cce5ea9a9ae6cebf40b6e5bc6257d7746d visit sql lab, execute a query (loads your user into localstorage) checkout this fix visit sql lab (user is removed from localstorage and page should show up) includes db migration (follow approval process in sip-59) </desc> <cmt> fix(sqllab): remove user info from localstorage </cmt> <cmt> filter out user data when loading localstorage </cmt>",don't store user in localstorage
2471,"<desc> onednn v2.2 wasn't released in time for the tf 2.5 branch cut, so we used an intermediate commit (after v2.2-rc) in the meanwhile. the final v2.2 release is out and has more fixes after the commit we initially used for tf 2.5. original pr (merged into master yesterday): #48248 </desc> <cmt> [intel mkl] update onednn version in tensorflow to v2.2 official release </cmt> <cmt> fix the mirror package path. </cmt>",update onednn to v2.2 official release
2472,"<desc> it bugged me for quite a while that we don't fsck images before mounting them, since some file systems require that, in particular that nspawn nowadays mounts the efi partition (which is vfat) if it exists. let's fix that. </desc> <cmt> dissect: complain if partition flags are set that we don't know </cmt> <cmt> dissect: optionally, run fsck before mounting dissected images </cmt> <cmt> some file systems want us to run fsck before mounting, hence do so, </cmt> <cmt> optionally. </cmt> <cmt> dissect: add --fsck= option to systemd-dissect tool </cmt> <cmt> let's expose this fsck behaviour directly. </cmt> <cmt> nspawn: fsck all images when mounting things </cmt> <cmt> also, start logging about mount errors, things are hard to debug </cmt> <cmt> otherwise. </cmt> <cmt> core: fsck images specified as rootimage= too before using them </cmt> <cmt> update todo </cmt>",various tweaks to the image dissection logic
2473,<desc> overrides the methods get_state() & set_state() to (respectively) export the content of the underlying data dictionnary and - if defined - the content of encodings. unittests added to covert the serialization & deserialization of all the exported properties. reimported from #4515 </desc> <cmt> added is_fast property on batchencoding to indicate if the object comes from a fast tokenizer. </cmt> <cmt> added __get_state__() & __set_state__() to be pickable. </cmt> <cmt> correct tokens() return type from list[int] to list[str] </cmt> <cmt> added unittest for batchencoding pickle/unpickle </cmt> <cmt> added unittest for batchencoding is_fast </cmt> <cmt> more careful checking on batchencoding unpickle tests. </cmt>,ability to pickle/unpickle batchencoding pickle (reimport)
2474,<desc> hopefully we'll actually get them all this time.  this fixes the known remaining causes and potential causes of #13843: explicit opt-in for analytics allows bots to send data flutter repo tests set explicit opt-in of analytics bot detection doesn't detect aws codebuild or jenkins </desc> <cmt> first version </cmt> <cmt> prevent modification of .flutter during analytics test </cmt> <cmt> pass in directory and override analyzer warning due to conditional import </cmt>,reduce the chances of bots reporting analytics
2475,"<desc> if the alternate scroll mode is enabled, the terminal generates up/down keystrokes when the mouse wheel is scrolled. however, the expected escape sequences for those keys are dependent on the state of the cursor keys mode ( decckm), but we haven't taken that into account. this pr updates the alternate scroll implementation to make sure the appropriate sequences are sent for both decckm modes. #3321 cla signed. if not, go over here and sign the cla requires documentation to be updated i've simply added a condition in the terminalinput::_sendalternatescroll method to send a different pair of sequences dependent on the state of _cursorapplicationmode  flag. manually tested in vim (although that required me enabling the alternate scroll mode myself first). also added a new unit test in mouseinputtest to confirm the correct sequences were generated for both decckm modes. </desc> <cmt> send the appropriate application sequences for alternate scroll events when decckm mode is enabled. </cmt> <cmt> add some unit tests for mouse wheel events in alternate scroll mode. </cmt>",fix the alternate scroll mode when decckm enabled
2476,"<desc> this pr did the following improvements: added amb, delay, delaysubscription in rxjava-scala. reimplemented the amb operator. </desc> <cmt> add amb, delay and delaysubscription in rxjava-scala </cmt> <cmt> reimplement the amb operator </cmt> <cmt> rename operationamb to operatoramb </cmt> <cmt> rename observer to subscriber and add a special logic to exit the loop </cmt> <cmt> fix docs </cmt>",rxjava-scala improvements and reimplemented the amb operator
2477,<desc> removed reliance upon x/y accel data when determining if garage door is open and eased the requirements for determining when door is closed by raising the threshold from 75mg to 100mg. log data also no longer contains x/y accel info. </desc> <cmt> dvcsmp-3657 removed checking x/y axes and increased open threshold </cmt> <cmt> dvcsmp-3657 remove x/y accel data from log </cmt>,dvcsmp-3657 smartsense garage door multi sensor not detecting closed garage door
2478,<desc> the puppeteer@next deployment was failing because the version can only be used once. this changes the version before we deploy to something like 1.0.0-next.1514509666103 </desc> <cmt> apply next version </cmt> <cmt> set puppeteer@next version with the timestamp </cmt>,use unique version for puppeteer@next
2479,"<desc> find subdirectories  by either the galaxy.yml or manifest.json only allow one source of metadata since building the collection will attempt to use the galaxy.yml but will be overridden by the dep resolver update documentation </desc> <cmt> add documentation about installing directories </cmt> <cmt> update documentation for metadata sources for installing git repositories </cmt> <cmt> add documentation for downloading directories and git repositories </cmt> <cmt> fix is_subdirs to allow a manifest.json or galaxy.yml, just like everything else </cmt> <cmt> allow one metadata source </cmt>",add some ansible-galaxy documentation and fix subdir searching
2480,"<desc> the test runs ok however the grammer logic for chinese is a little weird. for example we put ""am""/""pm"" before time, and we say ""midnight 2:00"" instead of ""2:00 pm""... etc. but i guess every language has its own grammer rule, it is too difficult to fit them all in one library. </desc> <cmt> add zh-tw test </cmt> <cmt> fix zh-tw mm bug </cmt>",add traditional chinese test zh-tw
2481,"<desc> the hash() in messageutil should ignore unknown field. most importantly ""original type"" is as unknown field is introduced by versionconverter. ignores unknown field is the implicit behavior in messageutil implemented std::equal_to, so hash() should align with this behavior.  risk level: low testing: unit test fix #11312 </desc> <cmt> utility test on protobuf </cmt> <cmt> add test case </cmt> <iss> version converter + protobuf::struct may break the convention of messageutil::hash() </iss>",hash() on proto message ignores unknown field
2482,"<desc> if s3.url is set in the user's config, ensure that it's an absolute url. an absolute url starts with either scheme:// or // -- if the configured url does not start with either prefix, prepend it with // to make it absolute. (if we don't do this, and the user enters something like url=myhost.com/reports, the browser will assume this is a relative url, and will prepend the hostname of the streamlit instance to the configured url.) fixes #802 </desc> <cmt> ensure s3.url is an absolute url </cmt> <cmt> give these tests more meaningful names </cmt> <cmt> test for s3.url absolute-making </cmt> <iss> incorrect `ahref` value in ""snapshot uploaded"" dialog </iss>",ensure that s3.url is an absolute url
2483,"<desc> please refer to the individual commit messages. </desc> <cmt> clean-up, and add jsdocs to, the pdfdocumentproxy.loadingparams method (pr 9830 follow-up) </cmt> <cmt> ensure that the locale viewer option is never defined in the (various) extension builds (pr 9493 follow-up) </cmt>","clean-up the pdfdocumentproxy.loadingparams method in the api, and the locale viewer option"
2484,"<desc> the pr #11359 made vm_publisher, vm_sku and sku_starts_with a required argument in azurebatchoperator. it's possible to run batch job using cloud service configuration or virtual machine configuration. both are mutually exclusive, making vm_publisher etc, a required argument will not allow anyone to run batch job using cloud service configuration. also, i moved service configuration argument from connection extra to operator. when i originally wrote this hook, i had very little experience of airflow and passed these arguments through the connection extra parameter. now, i think it's not ok, hence asking to correct it through this pr.  read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> move config args out of extra connection config to operators </cmt> <cmt> fixup! move config args out of extra connection config to operators </cmt>",fix incorrect typing and move config args out of extra connection config to operator args
2485,<desc> fixes #21917 @rick-anderson please review. i don't know why but i can't add you as a reviewer from github </desc> <cmt> razor pages model tutorial update </cmt> <cmt> doc update </cmt> <cmt> fixes for include markdown </cmt> <cmt> for sql server specific prefix </cmt> <iss> q: packages required for scaffolding in vsc version of razor pages tutorial </iss>,rp tutorial model doc update
2486,<desc> fix #18838 and improve user experience of python site. fixed double scroller added scroll aware animation to top nav bar reduce the height of the second top nav bar to hide it when scrolling down preview: </desc> <cmt> make python site header scroll aware and avoid double scroller </cmt> <cmt> add compiled assets </cmt> <cmt> adjust python site second header height </cmt> <cmt> add new line </cmt> <iss> double scroll on website </iss>,fixed python website double scroller and improve ux
2487,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).        increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> adds more id types and type prop to react-native-navigation navigatorevent. </cmt> <cmt> add tests. </cmt> <cmt> bumps version number. </cmt>",react-native-navigation navigatorevent adding more id types and type prop
2488,<desc> baseadapter should document the mandatory interfaces for implementing your own adapter from scratch for a different http library. currently requests requires all the parameters from httpadapter implementation of send to be defined so copying them and relevant documentation over to the base adapter. also adding relevant parts of documentation on what close is to the base class </desc> <cmt> baseadapter definition of send is missing mandatory params </cmt> <cmt> copy over relevant parts of the interface documentation </cmt>,make baseadapter describe the mandatory adapter interface
2489,<desc> also cleans up code that forwards webcontents methods to webframe apis. close #3930. </desc> <cmt> add webframe.inserttext api </cmt> <cmt> add inserttext to webcontents </cmt> <cmt> handle executejavascript in javascript </cmt> <cmt> handle default parameter of executejavascript in c++ </cmt> <cmt> docs: webframe.executejavascript </cmt> <cmt> change webview's zoom level on javascript side </cmt> <cmt> fix crash when closing page with webview </cmt> <cmt> unlisten the zoom-level-changed event when webview is detached </cmt>,"add inserttext api for webframe, webcontents and webview tag"
2490,"<desc> per node v6 docs the get and request methods should allow the options param to be a string. this is true for both the 'https' and 'http' modules. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> add string option to request methods. </cmt> <cmt> per [node docs]( </cmt> <cmt> add self to ""definitions by"" per readme recommendations </cmt>",allow option to be a string in node 6 request methods
2491,"<desc> re-land #48985 this pr ensures that renderfractionaltranslation calls markneedssemanticsupdate after its translation is set/changed, so that semantics are properly updated (for instance if a fractionaltranslation is animating). related issues closes #20449 i added the following tests: added test in proxy_box_test.dart to make sure that markneedssemanticsupdate is called when changing the translation value. added test in basic_test.dart to make sure that the semantics bounds get updated from a fractionaltranslation translation change before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> call markneedssemanticsupdate in transaltion setter, and add tests </cmt> <cmt> fix tests </cmt> <cmt> newline at end of proxy_box_test.dart </cmt> <iss> semantic boxes are incorrect inside fractionaltranslation </iss>",re-land make sure renderfractionaltranslation updates its semantics after the translation field is set
2492,"<desc> i haven't touched libstd though, it had a lot of tests and i'm not sure the people maintaining it want this. closes #61097 r? @mark-simulacrum </desc> <cmt> tidy: unconfigure tests during normal build </cmt> <cmt> compiletest: unconfigure tests during normal build </cmt> <cmt> libtest: unconfigure tests during normal build </cmt> <cmt> libterm: unconfigure tests during normal build </cmt> <cmt> libserialize: unconfigure tests during normal build </cmt> <cmt> libpanic_unwind: unconfigure tests during normal build </cmt> <cmt> librustc_lexer: unconfigure tests during normal build </cmt> <cmt> librustc_target: unconfigure tests during normal build </cmt> <cmt> libsyntax_pos: unconfigure tests during normal build </cmt> <cmt> librustc_incremental: unconfigure tests during normal build </cmt> <cmt> librustc: unconfigure tests during normal build </cmt> <cmt> librustc_data_structures: unconfigure tests during normal build </cmt> <cmt> librustdoc: unconfigure tests during normal build </cmt> <cmt> libsyntax: unconfigure tests during normal build </cmt> <cmt> liballoc: unconfigure tests during normal build </cmt> <cmt> remove additional libcore-like restrictions from liballoc, turns out the testing works ok if the tests are a part of liballoc itself. </cmt> <cmt> remove some more cfg(test)s </cmt> <iss> move unit tests into separate files unconfigured during normal build </iss>",unconfigure compiler unit test files during normal build
2493,"<desc> fix the crash caused by listener update when the any listener set bind_to_port to false. a listener does not bind to port has no io handle. close() already check it. now add the check to isopen(). also the tcp(or udp)listensocket::duplicate() creates parent listensocketimpl make it returning the derived listensocket, either tcplistensocket or udplistensocket testing: unit test on duplicate. integration test on bind_to_port. </desc> <cmt> listener: fix duplicate and isopen of the listener socket </cmt> <cmt> stash </cmt> <cmt> fixup </cmt>",fix a crash when updating any listener that does not bind to port
2494,"<desc> see commit titles/diffs for more details. the first commit is made possible by #53451 being fixed (almost a year ago). the last commit should remove the need for #[allow(improper_ctypes)] in #65134. </desc> <cmt> proc_macro: remove now-unnecessary ice workarounds from bridge::client. </cmt> <cmt> proc_macro: consolidate bridge::client::run_expand{1,2} into one helper. </cmt> <cmt> proc_macro: don't use rust abi fn pointers in a c abi fn signature. </cmt>","clean up bridge::client::__run_expand{1,2} a bit."
2495,"<desc> adding some shortcut keys for the amethyst window-tiling system to my keymap. none my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> fix missing vai </cmt> <cmt> add amethyst keybindings </cmt> <cmt> add amethyst bindings for planck </cmt>",add amethyst keybindings for some dcompact implementations
2496,<desc> the second layer encryption for data transport works implementing the ecdh algorithm where session keys are exchanged before the rest of the communication. this feature is enterprise only since it requires the micro-services architecture and it's in the early stage of tests as an alpha feature and documentation may not be available before the beta stage. </desc> <cmt> encypting websocket communication </cmt> <cmt> support rest </cmt> <cmt> support socket over xhr responses and remove logs </cmt> <cmt> fix name </cmt>,second layer encryption for data transport (alpha)
2497,<desc> this pr fixes two issues which were causing code lenses for assets and cached dependencies to not be properly handled.  the first bug was that tsc navigationtrees were not being calculated and the second was that the code lens resolution was not formatting the url properly to be consumed by an lsp client. </desc> <cmt> fix(lsp): handle tsc nav tree properly </cmt> <cmt> fix(lsp): resolve code lenses for non-docs properly </cmt>,handle code lenses for non-documents
2498,"<desc> implements reference counting for task submission in the direct call codepath. for inlined arguments, the reference is decremented once the argument is inlined (because we keep the cached task spec anyways). for plasma arguments, the reference is decremented when the task finishes or fails after retrying. note that this drops support for reference counting for submitted tasks for the raylet code path in order to simplify the code. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> remove ref counting dependencies on get() </cmt> <cmt> comment </cmt> <cmt> don't send ids when disabled </cmt> <cmt> tmp </cmt> <cmt> remove translation of transport type for direct call object id </cmt> <cmt> wip </cmt> <cmt> use task manager </cmt> <cmt> cleaner </cmt> <cmt> remove </cmt>",reference counting for direct call submitted tasks
2499,"<desc> merges unit test from @unquietcode and fixes bug that prevented getfallback from querying failure states such as  timeout, rejected, etc. see #144 </desc> <cmt> adds a failing unit test for isresponsetimedout() when accessed from within fallbacks </cmt> <cmt> record failure events before getfallback invoked so they can be queried. </cmt> <cmt> fixes </cmt>",allow getfallback to query failure states
2500,<desc> for changelog. remove if this is non-significant change. short description (up to few sentences): fixed a deadlock when a select query locks the same table multiple times (e.g. from different threads or when executing multiple subqueries) and there is a concurrent ddl query. fixes #4316 </desc> <cmt> allow acquiring read lock to a table out of order if it was already locked by the same query [#clickhouse-3789] </cmt> <cmt> this is important in preventing alter deadlocks </cmt> <cmt> rename lockhandler -> lockholder [#clickhouse-3789] </cmt> <cmt> add comment [#clickhouse-3789] </cmt> <cmt> move test script from bugs to tests [#clickhouse-3789] </cmt> <cmt> get rid of default query_id value in rwlock::getlock [#clickhouse-3789] </cmt>,fix deadlock of concurrent selects and ddl queries
2501,"<desc> this pr add option of ""null"" for the select filter in the dashboard's native filter. set ""dashboard_native_filters"": true in superset/config.py open dashboard with null var in db (i use ""video game sales"") open dashboard native filter with column publisher has associated issue: fixes #15291 includes db migration (follow approval process in sip-59) </desc> <cmt> fix: add null var to native filter (#15291) </cmt> <cmt> small fix </cmt> <iss> dashboard native filter: cannot filter null values </iss>",add null option to value filter
2502,"<desc> the export type pattern can be seen in angular-ui-boostrap  no version increase needed as its only making the types visible with a known pattern. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> angular-local-storage: improve main types visibility </cmt> <cmt> use the same export pattern as angular-ui-boostrap. </cmt> <cmt> its nearly the same, but in older typescript projects works its the only way to get those visible for importing. </cmt> <cmt> angular-gettext: improve main types visibility </cmt> <cmt> use the same export pattern as angular-ui-boostrap. </cmt> <cmt> its nearly the same, but in older typescript projects works its the only way to get those visible for importing. </cmt>",improve types visibility for angular-gettext and angular-local-storage
2503,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. example of how a hook is called from the runner to demonstrate the correct return values (promise return values are supported but the results ignored by the core framework)  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> export the configuration interface </cmt> <cmt> added class for the server instead of interface </cmt> <cmt> added ts lint file and fixed errors </cmt> <cmt> fix promise values for hooks </cmt> <cmt> merge of master </cmt> <cmt> minor change </cmt>",fix return values for webdriver config hooks
2504,"<desc> closes #4550,#4548 in [1]: s = pd.concat([series(list(range(3))),series(list(range(3)))]) in [2]: s out[2]: 0    0 1    1 2    2 0    0 1    1 2    2 dtype: int64 in [3]: s.where(s<2) out[3]: 0     0 1     1 2   nan 0     0 1     1 2   nan dtype: float64 in [4]: s[s<1] = 5 in [5]: s out[5]: 0    5 1    1 2    2 0    5 1    1 2    2 dtype: int64 in [6]: s[s<2] += 10 in [7]: s out[7]: 0     5 1    11 2     2 0     5 1    11 2     2 dtype: int64 </desc> <cmt> tst: (gh4550) where with a dup index in series </cmt> <cmt> bug: (gh4548) inplace updating of a duplicate series with a boolean aligning incorrectly </cmt> <iss> 'valueerror: cannot assign nan to integer series"" when calling `where` on series with non-unique index. </iss>",duplicate indexing ops with a series using where and inplace add buggy (gh4550/gh4548)
2505,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: se further down increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. reference for v2.2 (mongo-core 2.1.20)  reference for v3.x  won't change version number since it currently has the wrong spec, but not sure how that affects publishing of the typings. </desc> <cmt> fix swagger-schema-official security type </cmt> <cmt> merge </cmt>",@types/mongodb fix keep alive for v 2.2/3.x (wrong documentation)
2506,<desc> based on #17481 cmake .. -dwith_gpu=off -dwith_lite=on -dlite_with_x86=off -dlite_with_light_weight_framework=on -dlite_with_cuda=off -dwith_testing=on -dwith_mkl=off </desc> <cmt> add cmake </cmt> <cmt> update </cmt> <cmt> fix proto pd </cmt> <cmt> fix compile </cmt> <cmt> tmp save </cmt> <cmt> fix protobuf device version </cmt> <cmt> fix protobuf and host compile </cmt> <cmt> fix std c++11 support on android </cmt> <cmt> change array to vector to fix ndk c++_static </cmt> <cmt> fix rt and add dockerfile </cmt> <cmt> fix android compile issue with latest merge </cmt> <cmt> init arm kernels </cmt> <cmt> enable run on arm </cmt>,enable cross compile and run on mobile of lite
2507,"<desc> allows providing arbitrary string, bool, int, or double constants to all dart applications in run/build/drive mode. refactors code that used buildmode + additional arguments to instead only use buildinfo, which is a more complete collection of the current configuration. adds a devicelab test that runs with a string.fromenvironment provided by a define. removes dead code from simulator run logic fixes #44483 </desc> <cmt> refactor dart-defines to use build info, add support for ios, android, and macos </cmt> <cmt> finish the plumbing </cmt> <iss> plumb ""dartdefines` through gradle and xcode </iss>","allow providing dart-defines to android, ios, macos builds"
2508,"<desc> this is another attempt at enabling-by-default named lazy member loading. includes a fix for the problem discovered in the source-compat suite with the previous attempt (pr #12843). </desc> <cmt> [namedlazymemberloading] add ""loading members"" pretty stack trace when deserializing. </cmt> <cmt> [namedlazymemberloading] flip flag polarity: on by default, optionally off. </cmt> <cmt> [clangimporter] call addimplicitdestructor() on imported cf types. </cmt> <cmt> [namedlazymemberloading] bail on cases that interact with protocol member mirroring. </cmt> <cmt> [namedlazymemberloading] give up trying to break recursion on clang-imported init for now. </cmt> <cmt> [namedlazymemberloading] use per-idc recursion-breaking flag, not sentinel. </cmt> <cmt> the empty sentinel in the lookup table caused recursion-breaking to bottom </cmt> <cmt> out in slightly different order than the old eager code, making certain </cmt> <cmt> order-sensitive tests fail. </cmt> <cmt> [namedlazymemberloading] return empty vector rather than none on no-match. </cmt> <cmt> [namedlazymemberloading] support named loading from objc categories. </cmt> <cmt> [namedlazymemberloading] tolerate mid-flight getmembers() calls better. </cmt> <cmt> [namedlazymemberloading] update tests with improved output. </cmt> <cmt> [namedlazymemberloading] add testcase for categories. </cmt> <cmt> [namedlazymemberloading] handle nominals with mix of added/lazy members. </cmt>",force on named lazy member loading retry
2509,<desc> fixes issue: - add recursive factorial for java small edits to java style guide </desc> <cmt> update java style guide </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add recursive factorial for java </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix conflicts </cmt> <cmt> fix java factorial </cmt>,add a recursive factorial implementation for java
2510,<desc> pass temppath to modules via module arguments instead of an environment variable also make ansibleactiondone a private exception since we're going to get rid of this later. ansible version 2.5.0 followup to bcoca's temporary patchset. </desc> <cmt> pass tempdir via module args instead of the environment </cmt> <cmt> make ansibleactiondone a private exception </cmt> <cmt> we're going to remove this in the future so mark it private so people </cmt> <cmt> are less likely to use it. </cmt>,temporary pass temppath to modules
2511,"<desc> fix timebucket not taking effect in equalsandhashcode annotation fix timebucket not taking effect in equalsandhashcode annotation, because the hashcode and equals methods generated by equalsandhashcode do not contain the properties of the parent class, the data related to the topology map is inaccurate during aggregation. use  before fix: after fix: </desc> <cmt> fix entityid not taking effect in equalsandhashcode annotation. </cmt>",fix timebucket not taking effect in equalsandhashcode annotation.
2512,"<desc> this is a redo of #8068 todo use defineproperty with a getter closes #7696, #8132 </desc> <cmt> fix(vue-app): use mixin to provide this.$nuxt </cmt> <cmt> avoids prototype pollution on vue </cmt> <cmt> closes #7696 </cmt> <cmt> perf: use beforecreate hook and define with getter </cmt> <cmt> fix: define $nuxt on the app instance itself </cmt> <cmt> test: add ssr test for shared context </cmt> <iss> nuxt server $nuxt.context changed by latter request </iss>",use getter to provide this.$nuxt
2513,"<desc> tl;dr add support for unicode 9 grapheme breaking (i.e. emoji) by using icu. work around icu efficiency issues with thread-local storage. note: this is an update on a previous pr that had to be reverted due to the unfortunate dependencies introduced. this untangles some of them by forward declaring the functions we use on apple platforms, which will typically not be building corelibs-foundation and/or their own version of icu. what follows is from the original pr. introduce shims for using ubreakiterators from icu. also introduce shims for using thread local storage via pthreads. we will be relying on icu and ubreakiterators for grapheme breaking. but, ubreakiterators are very expensive to create, especially for the way we do grapheme breaking, which is relatively stateless. thus, we will stash one or more into thread local storage and reset it as needed. introduces a _threadlocalstorage struct to hold thread-local, but global resources. set it up to host a ubreakiterator and a cache key for resetting text. ubreakiterators are extremely expensive to create on the fly, so we store one for each thread. ubreakiterators are also expensive to bind to new text, so we cache the text it's currently bound to in order to help avoid it. the struct can be expanded with more functionality in the future, but the standard library should only ever use a single key, and thus everything should go on this struct. the _threadlocalstorage struct is not meant to be copyable, creatable (by anyone else except the once-per-thread initialize routine), and should accessed through the pointers it provides. future immediate directions could include cashing multiple ubreakiterators (e.g. avoid a text reset for mutual character iteration patterns, etc). test added in test/stdlib/threadlocalstorage.swift. use ubreakiterators to perform grapheme breaking. this gives unicode 9 grapheme breaking (e.g. family emoji) and provides a means to upgrade to future versions. it also serves as a model for how to serve up other advanced functionality in icu to users. this has tricky performance implications. some things are faster and a number of cases are slower. but, careful use of icu can help mitigate and amortize these costs. in conjunction with more early detection of fast paths, overall grapheme breaking for the average user should be much faster than in swift 3. note: this is incomplete. it currently falls back on the legacy tries for some bridged strings. there are many potential directions for a general solution, but for now we'll be interatively adding support for more and more special cases. </desc> <cmt> [stdlib] shims for ubreakiterator and thread local storage. </cmt> <cmt> introduce shims for using ubreakiterators from icu. also introduce </cmt> <cmt> shims for using thread local storage via pthreads. </cmt> <cmt> we will be relying on icu and ubreakiterators for grapheme </cmt> <cmt> breaking. but, ubreakiterators are very expensive to create, </cmt> <cmt> especially for the way we do grapheme breaking, which is relatively </cmt> <cmt> stateless. thus, we will stash one or more into thread local storage </cmt> <cmt> and reset it as needed. </cmt> <cmt> note: currently, pthread_key_t is hard coded for a single platform </cmt> <cmt> (darwin), but i have a static_assert alongside directions on how to </cmt> <cmt> adapt it to any future platforms who differ in key type. </cmt> <cmt> [stdlib] add icu.swift, to host icu helper functionality </cmt> <cmt> [stdlib] introduce thread local storage </cmt> <cmt> introduces a _threadlocalstorage struct to hold thread-local, but </cmt> <cmt> global resources. set it up to host a ubreakiterator and a cache key </cmt> <cmt> for resetting text. </cmt> <cmt> ubreakiterators are extremely expensive to create on the fly, so we </cmt> <cmt> store one for each thread. ubreakiterators are also expensive to bind </cmt> <cmt> to new text, so we cache the text it's currently bound to in order to </cmt> <cmt> help avoid it. </cmt> <cmt> the struct can be expanded with more functionality in the future, but </cmt> <cmt> the standard library should only ever use a single key, and thus </cmt> <cmt> everything should go on this struct. the _threadlocalstorage struct is </cmt> <cmt> not meant to be copyable, creatable (by anyone else except the </cmt> <cmt> once-per-thread initialize routine), and should accessed through the </cmt> <cmt> pointers it provides. </cmt> <cmt> future immediate directions could include cashing multiple </cmt> <cmt> ubreakiterators (e.g. avoid a text reset for mutual character </cmt> <cmt> iteration patterns, etc). </cmt> <cmt> test added in test/stdlib/threadlocalstorage.swift. </cmt> <cmt> [stdlib] unicode 9 here we come: use icu for grapheme breaking </cmt> <cmt> use ubreakiterators to perform grapheme breaking. this gives unicode 9 </cmt> <cmt> grapheme breaking (e.g. family emoji) and provides a means to upgrade </cmt> <cmt> to future versions. it also serves as a model for how to serve up </cmt> <cmt> other advanced functionality in icu to users. </cmt> <cmt> this has tricky performance implications. some things are faster and a </cmt> <cmt> number of cases are slower. but, careful use of icu can help mitigate </cmt> <cmt> and amortize these costs. in conjunction with more early detection of </cmt> <cmt> fast paths, overall grapheme breaking for the average user should be </cmt> <cmt> much faster than in swift 3. </cmt> <cmt> note: this is incomplete. it currently falls back on the legacy tries </cmt> <cmt> for some bridged strings. there are many potential directions for a </cmt> <cmt> general solution, but for now we'll be interatively adding support for </cmt> <cmt> more and more special cases. </cmt> <cmt> [stdlib] linux definition of pthread_key_t </cmt> <cmt> [stdlib] add unicode 9 grapheme break tests for flags, emoji, etc. </cmt> <cmt> [stdlib stubs] fix up linux build to know about pthread types. </cmt> <cmt> adds in linux platform support for our pthread tls. replace usage of </cmt> <cmt> pthread_keys_max with a sentinel value, as it's tricky to define </cmt> <cmt> cross-platform and was only lightly used inside sanity checks. </cmt> <cmt> [stdlib] disable unicode 9 test on linux, depends on icu version </cmt> <cmt> [stdlib] disable legacy unicode 8.0 regional break test. </cmt> <cmt> disables the portions of the regional break test file corresponding to </cmt> <cmt> unicode 8.0 vs 9.0 differences. once the compiler and stdlib are in </cmt> <cmt> sync with unicode 9.0, and the legacy tries are dropped, we should </cmt> <cmt> splat down newer versions of these test files. </cmt> <cmt> [stdlib] add prototypes to avoid dependency </cmt> <cmt> avoid a dependency on icu headers on apple platforms, rather than rely </cmt> <cmt> on corelibs-foundation being checked out. this simplifies the </cmt> <cmt> dependencies and unblocks build bots. </cmt>",unicode 9 and thread local storage (again)
2514,"<desc> see commit message. </desc> <cmt> synch with gambie </cmt> <cmt> changed header guard for format.h </cmt> <cmt> previously, if spdlog was being used in a project that also uses cppformat, this file (with it's custom namespace) would not be included.  this is because, while the definitions were added to the spdlog namespace, the include guard was left the same as in the actual cppformat library.  this change modifies the include guard by prefixing it with spdlog_. </cmt>",fixes usage of spdlog in a project that also uses cppformat
2515,"<desc> i hereby agree to the terms of the cla available at:  log engine support for s3 detailed description / documentation draft: introduced seekablereadbuffer, it contains only one virtual method seek. disk interface now returns seekablereadbuffer on readfile call. disks3 metadata file layout changed. now each file contains multiple references to s3 objects and their total size. this change optimizes getfilesize and writefile(with append) methods in disks3. log engine support for s3. </desc> <cmt> seekablereadbuffer initial implementation. idisk readfile should return seekablebuffer. </cmt> <cmt> seekablereadbuffer refactoring. </cmt> <cmt> store size and multiple references for s3 metadata file. </cmt> <cmt> log engine support for s3. </cmt> <cmt> # conflicts: </cmt> <cmt> #	dbms/programs/server/config.xml </cmt>",log engine support for s3 and seekablereadbuffer
2516,"<desc> performance optimization others remove tensorfromvector and avoid sync copy change tensorcopysync to tensorcopy remove useless wait() got 9880 tokens/s -> 12546 tokens/s, about 26.98%+ speed up on ernie model before after </desc> <cmt> enable async copy and  add wait before sync operation </cmt> <cmt> remove unneccessary wait </cmt> <cmt> add fillnputensorwithconstant </cmt> <cmt> refine </cmt> <cmt> fix fill_constant </cmt> <cmt> change tensorfromvector to fillnputensorwithconstant </cmt>",remove tensorfromvector and avoid sync copy in npu op kernel for better performance
2517,"<desc> sink more information down into solutionapplicationtarget so we can compute per-target two more bits of information that were previously flags passed down: expressiontypemustbeoptional: used to indicate when we want an optional type (e.g., for an if let). this can be recovered by storing the pattern in solutionapplicationtarget (we need it anyway) converttypeisopaquereturntype: used to note that the expression produces the concrete type for an opaque return type. </desc> <cmt> [constraint system] extend solutionapplicationtarget with an init pattern. </cmt> <cmt> initializer expressions are always type checked against a pattern, so also </cmt> <cmt> include the pattern in the solution application target and use that to </cmt> <cmt> compute the contextual type from the pattern type. </cmt> <cmt> [constraint system] remove typecheckexprflags::expressiontypemustbeoptional. </cmt> <cmt> this result can be computed from the pattern of an initializer expression, so </cmt> <cmt> do that instead. </cmt> <cmt> [constraint system] eliminate typecheckexprflags::converttypeisopaquereturntype </cmt> <cmt> we can compute this information based solely on the solutionapplicationtarget, </cmt> <cmt> so do it. </cmt>",remove yet more of typecheckexprflags
2518,<desc> the meraki_content_filtering module has support for modifying content filtering rules but not querying rules or the categories. this replaces #51191. new module pull request meraki_content_filtering </desc> <cmt> added querying functionality </cmt> <cmt> fix pep8 and documentation </cmt>,meraki_content_filtering - add support for querying
2519,"<desc> closes #6646 tests added/passed - added ut for filter matching documentation updated - irrelevant schema updated - irrelevant please be gentle - didn't touch xaml and c++ for 8 years created a viewmodel class in the command palette called filteredcommand, aggregating the command, the filter and the highlighted presentation of the command name this listview of the filtered commands is bound to the vector of filteredcommands introduced hihglightedtextcontrol user control with highlightedtext view model added this control to the listview item's grid bound the filteredcommand's highlighted command name to the user control ut for matching algorithm only manual tests searching in commandline, switchtab and nested command modes checking for bot matching an non matching filters dogfooding  like this </desc> <cmt> 6646: implement highlighted text control </cmt> <cmt> 6646: fix profanity </cmt>",bold matching text in the command palette
2520,"<desc> this moves  local mode (serial python execution) from separate python code to the c++ coreworker in order to make it more maintainable. closes #4147 closes #5013 closes #5379 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> kill actor ui addition </cmt> <cmt> formatted api.ts </cmt> <cmt> only killing if actor is alive </cmt> <cmt> displaying only if actor is alive </cmt> <cmt> initial pieces </cmt> <cmt> removing ray.psutil (buggy) </cmt> <cmt> modifed build.sh </cmt> <cmt> workinprogress </cmt> <cmt> sycning with master </cmt> <cmt> fixing merge conflicts </cmt> <cmt> up to date </cmt> <cmt> updating </cmt> <cmt> almost done </cmt> <cmt> undoing quotes </cmt> <cmt> work in progress...many problems </cmt> <cmt> despite all odds something works </cmt> <cmt> jeezus joseph and mary, large objects now work </cmt> <cmt> some well confirmed local_mode changes </cmt> <cmt> some more simple changes </cmt> <cmt> ref counting (and more is happening) </cmt> <iss> [local mode] ray.global_state.cluster_resources() fails </iss> <iss> attributeerror in signal api breaks local mode </iss> <iss> issue with passing pickled parameters when using local mode </iss>",moving local mode to c++
2521,"<desc> we've decided we don't want these sitting around in the code base since they're not currently used. if we do decide we need them in the future -- for example if we want to re-implement the evaluator cache as a heterogenous map with small-value optimizations -- we can bring them back. </desc> <cmt> ast: remove anyvalue type eraser now that it's no longer needed </cmt> <cmt> i'm keeping anyvalue.h around, since it has some useful overloads of </cmt> <cmt> hash_value() and simple_display() that don't have a good home at this </cmt> <cmt> time. </cmt> <cmt> ast: remove the 'legacy' request dependency graph implementation </cmt> <cmt> ast: remove anyrequest </cmt>",remove request evaluator's anyrequest and anyvalue type erasers
2522,"<desc> this pr add support for wwm (whole word mask) proxy when fine-tune bert like model. and it can be divided into two part : english model support and chinese model support for english, it's simple. the original tokenizer res contains symbols like '##ing'. i just use the same mask proxy in data_collator.py by google. for chinese, it's hard. we need to rely on (word level) tokenizer,  cause bert is char level in chinese. so i do things as follow to get word level tokens: add get info code in chinese_ref.py create a new dataset to keep ref info language_model.py create word level ref according to ref data_collator.py then, it's all same to english. and i add two parameters (wwm and chinese_ref_path ) to run lm. </desc> <cmt> add: add whole word mask proxy for both eng and chinese </cmt> <cmt> mod: adjust format </cmt>",# add whole word mask support for lm fine-tune
2523,<desc> add automaticnameprefix option allow automaticnamedelimiter on cachegroup level fix wrong priority handling when merging multiple cache groups by name feature + bugfix yes no automaticnameprefix was added automaticnamedelimiter is now possible on cache group level automaticnameprefix specifies the name prefix used when using name: true to automatically create a name. by default the cache group key is used. </desc> <cmt> add automaticnameprefix option </cmt> <cmt> allow automaticnamedelimiter on cachegroup level </cmt> <cmt> fix wrong priority handling when merging multiple cache groups by name </cmt> <cmt> add test case </cmt>,automaticnameprefix and name merging bugfix
2524,"<desc> this pr keeps asar archive opened so we don't need to reopen it for every fs operation on it, we can have potential performance boost from it. as a side effect, when the asar archive is overwritten or deleted due to auto-updating or something else, electron will still read the original archive. fixes #1219. </desc> <cmt> keep archive's file opened in the archive's whole life time </cmt> <cmt> add archive::getfd </cmt> <cmt> reuse archive's fd in node asar api </cmt> <iss> re-read asar package on page reload </iss>",keep asar archive's file opened in the archive's whole life time
2525,"<desc> this adds a new x-pack/qa test for tls on a basic license. it starts a 2 node cluster with a basic license, and tls enabled on both http and transport, and verifies the license type, ssl tessting and ssl certificates api. it also upgrades the cluster to a trial license and performs that same set of checks (to ensure that clusters with basic license and tls enabled can be upgraded to a higher feature license) relates: #37433 </desc> <cmt> support tls on basic licenses </cmt> <cmt> - always output ""ssl"" usage, even if security is not enabled </cmt> <cmt> - adds a qa test for running on basic with tls on transport and http </cmt> <cmt> switch to new ""wait-for-resource"" over ssl </cmt>",add test for http and transport tls on basic license
2526,"<desc> certain ops mix usage of boolean and string for boolean type oidc claims. for example, the same ""email_verified"" field is presented as boolean in idtoken, but is a string of ""true"" in the response of user info. this inconsistency results in failures when we try to merge them during authorization. this pr introduce a small leniency so that it will merge a boolean with a string that has value of the boolean's string representation. in another word, it will merge true with ""true"", also will merge false with ""false"", but nothing else. </desc> <cmt> support merging boolean oidc claims with mixed usage of boolean and string </cmt> <cmt> retain value from idtoken </cmt>",allow mixed usage of boolean and string when merging oidc claims
2527,"<desc> closes #33017 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> flip order </cmt> <cmt> test </cmt> <cmt> sort </cmt> <iss> unspecific error message when setting singular index with np dtype </iss>",raise a better error for numpy singletons in index
2528,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update index.d.ts </cmt> <cmt> change accordingly to datatable. </cmt> <cmt> update index.d.ts </cmt> <cmt> add style api </cmt> <cmt> update index.d.ts </cmt> <cmt> update index.d.ts </cmt> <cmt> not all events have the same args. </cmt> <cmt> update index.d.ts </cmt> <cmt> add api interface for select extension </cmt> <cmt> update index.d.ts </cmt> <cmt> update index.d.ts </cmt> <cmt> datatables api should be array-like, and accessable with index like array </cmt> <cmt> add typing for colreorder extension </cmt> <cmt> update index.d.ts </cmt> <cmt> add new line at the end of file </cmt> <cmt> update tsconfig.json </cmt> <cmt> add new line at the end of file </cmt>",change api according to datatable definition
2529,<desc> fixes #3268 identifier names with double underscores are reserved by c++ implementation per standard:  we don't really need double underscores any way. </desc> <cmt> avoid two consecutive underscores in macro name. </cmt> <cmt> fixes </cmt> <cmt> update generated code. </cmt>,avoid double underscores in macro name
2530,<desc> updates a broken link to the correct one. </desc> <cmt> [docs] updated link to cpp example on grpc.io website. </cmt> <cmt> [docs] changed variable names to be more accurate in readme for cpp helloworld example. </cmt> <cmt> [docs] updated readme with a correct c++ link. </cmt>,fix link to c++ guide
2531,<desc> unified formatting across files indent_style = space indent_size = 2 insert_final_newline = true each line within { } to specify single rule converted all the tabs into spaces fixed typo in the previous commit at source/attention_seekers/swing.css refactored gruntfile.js use grunt dev to trigger the watch task. watch in turn invokes the default task. _ps: each line within { } to specify single rule_ might be reverted back </desc> <cmt> unified formatting across files </cmt> <cmt> indent_style = space </cmt> <cmt> indent_size = 2 </cmt> <cmt> insert_final_newline = true </cmt> <cmt> each line within { } to specify single rule </cmt> <cmt> converted all the tabs into spaces </cmt> <cmt> and fixed typo in the previous commit </cmt> <cmt> at source/attention_seekers/swing.css </cmt> <cmt> refactored gruntfile.js </cmt>,unified formatting and refactored gruntfile.js
2532,"<desc> dear sir or madam, i added the thin prism distortion coefficients to the calibration model, being the distortion model: xd = xu (1+k1_r2+k2_r4+k3_r6)/(1+k4_r2+k5_r4+k6_r6) + (2_p1_xu_yu+p2(r2+2_xu^2))     +s1_r2+s2_r4; yd =yu (1+k1_r2+k2_r4+k3_r6)/(1+k4_r2+k5_r4+k6_r6) + (p1(r2+2_yu^2)+2_p2_xu_yu)    +s3_r2+s4_r4; i put a new flag cv_calib_thin_prism_model, to use the thin prism distortion parameters in the minimization, and also the flag cv_calib_fix_s1_s2_s3_s4 to fix them. i have done it because for my camera the results are improved by using the thin prism coefficients. hoping to be interesting for you, yours sincerely, aritz. </desc> <cmt> added thin prism distortion model </cmt> <cmt> only the code. </cmt> <cmt> thin prism distortion model added doc </cmt> <cmt> thin prism distortion model added to the </cmt> <cmt> camera_calibration_and_3d_reconstruction.rst </cmt>",thin prism distortion coefficients added to the calibration model.
2533,"<desc> we were modifying the incorrect variable when md5 was unavailable. that variable is a tuple which has no .pop() method. the intended variable to be modified was available_hash_algorithms which is a dictionary and has a .pop() method. fixes #51355 replaces #51357 reverts c459f04 lib/ansible/module_utils/basic.py </desc> <cmt> revert ""use list instead of tuple and remove md5 on valueerror (#51357)"" </cmt> <cmt> this reverts commit c459f040da88004b2fb0faa646cdd6530e99e2fe. </cmt> <cmt> modify the correct variable when determining available hashing algorithms </cmt> <iss> module_utils/basic.py fails with fips 140-2 enabled systems </iss>",modify the correct variable when setting available hashing algorithms
2534,"<desc> as noted on irc, the filenames of the gitian build results do not contain the 4th digit of the version number if it has one, e.g. 0.17.0.1 produces files with the number 0.17.0. furthermore, when rc's are built, the resulting filenames are of the release version and do not include rc in them. this occurs because configure.ac is written to create version numbers of the form major.minor.rev instead of major.minor.rev.build and without any rc version as it does not handle rc numbers. this pr changes configure.ac to include the build number if it is greater than 0. it will also include the rc number if it is greater than 0. so the filenames of the gitian builds will now contain the full version number. this behavior can be tested by setting _client_version_build and _client_version_rc to non-zero values and then doing make dist. a tar file should be created with the correct versioning. </desc> <cmt> build: if version_build is non-zero, include it in the package version </cmt> <cmt> when the build number (client_version_build) is non-zero, we want </cmt> <cmt> to include that in the package version number so the resulting binaries </cmt> <cmt> are named with the correct version. </cmt> <cmt> build: include rc number in version number </cmt>",include full version number in released file names
2535,"<desc> allow providing all debugging options to the desktop engine via the flutter_engine_switch_ environment variables. fixes #66532 fixes #46005 fixes #58882 the underling engine changes have already landed for windows, macos, but linux is still in progress </desc> <cmt> [flutter_tools] remove globals from desktop configuration </cmt> <cmt> fix imports </cmt> <cmt> fix all test cases </cmt> <cmt> [flutter_tools] support most desktop debugging options </cmt> <iss> desktop/embedder shells need an affordance for enabling dart profiling </iss> <iss> --cache-sksl cannot be provided to desktop embedders </iss> <iss> most debugging options are discarded for desktop </iss>",support all engine debugging options with flutter_engine_switch environment variables
2536,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fix parameteraddresses error in custom-functions-runtime/index.d.ts </cmt> <cmt> correct two req set numbers, update error code comments to match ui experience in types/custom-functions-runtime/index.d.ts </cmt> <cmt> fix whitespaces per npm lint </cmt> <cmt> adjust customfunctionsruntime 1.3 error code comments, match to docs and excel ui experience </cmt> <cmt> run npm lint, resolve errors </cmt>",update customfunctionsruntime 1.3 error code comments
2537,"<desc> fix #2148 try to resolve two problems: because javascript and ui are in different thread. it's possible that two text changed event are raised, but we are still processing the first event. we should drop the first response. m_nativeeventcount/m_mostrecenteventcount/eventcount is introduced to resolve this problem. onchanged carried eventcount(or m_nativeeventcount) to javascript, then javascript extract eventcount out and set mostrecenteventcount back and followed the text string. if there is another onchanged event happened, m_nativeeventcount is changed and mostrecenteventcount is invalid, so we can drop the message. problem introduced by textbox.textchanged. textchanged is implemented as async event in xaml. if javascript is like this: onchangetext={text => this.setstate({text})} and user type 'ab' very fast, then 'b' is possible to be lost in below situation. input 'a' -> textchanged for 'a' -> javascript processing 'a' -> input becomes 'ab' -> processing javascript response and set text to 'a' textchanged for 'ab' but textbox.text is 'a' -> javascript processing 'a' textchanging is used to drop the javascript response of 'a' and expect another textchanged event with correct event count. microsoft reviewers: open in codeflow </desc> <cmt> sync master </cmt> <cmt> merge </cmt> <cmt> sync </cmt> <cmt> sync </cmt> <iss> textinput sends change notification when setting value </iss>",avoid infinite updating loop for textinput and allow fast typing
2538,<desc> the clang memory sanitizers default behavior is to crash when a malloc that cannot succeed is called rather than returning an error.  lets just skip these tests under msan; not much value there. </desc> <cmt> skip test_constructor under msan. </cmt> <cmt> fix the others as well. </cmt> <cmt> reuse existing related news entry. </cmt>,skip test_io tests that'd cause a huge malloc under msan
2539,"<desc> take two of #14281 currently rgb/led matrixes for the various issi ics have ghosting issues with the leds. any leds used as indicators or just plain off in the matrix glow faintly which isn't ideal. i have added a option to be set in a keyboards config.h that allows for makers and users to enable the de-ghosting functions of the ics for all of the drivers on the board so that this ghosting is eliminated. i have set the default value to allow for ghosting (0 ohm resistor/de-ghosting settings off) so as to stay backwards compatible and not cause power issues with older boards. the datasheet recommends enabling the highest resistor possible during the blanking time so there shouldn't be any dimming with the leds when they are on. if you want me to set that as the default (would make sense that you wouldn't want ghosting on the matrix) i can do that as well. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> initial work for de-ghost enable </cmt> <cmt> dumb mistake with the redefine </cmt> <cmt> added copywrite stuff on source files </cmt> <cmt> fixed whitespace errors </cmt> <cmt> added support for all issi led drivers </cmt> <cmt> updated docs for support for issi led driver pull-up pull-down </cmt> <cmt> applied clang format </cmt>",enable de-ghosting for rgb/led matrix on all issi led drivers
2540,"<desc> migrated kbm settings tests. target pr: #5754 pr checklist applies to #xxx cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx validation steps performed ran tests and validated output on the ui. </desc> <cmt> added mstest project </cmt> <cmt> enabled settings tests run in the build pipeline </cmt> <cmt> migrated kbm settings </cmt>",kbm migrated kbm settings tests
2541,"<desc> the old code wasn't incorporating promoteds into the path, meaning other dot files could get clobbered. use the mir dump infrastructure to generate paths so that this doesn't occur in the future. </desc> <cmt> use mir dump interface for dataflow </cmt> <cmt> print to stderr when a graphviz file can't be written </cmt> <cmt> warn prints nothing by default </cmt>",use pretty::create_dump_file for dumping dataflow results
2542,"<desc> on further investigation, it seems that chrome os isn't processing media keys unless the usb endpoint with the consumer and system control devices also contains a keyboard or mouse device. mouse keys aren't useful to me, and they actually seem to cause a windows bug instead (#8323), so i'm switching to nkro. this functions as an equivalent workaround for chrome os, and is also at least theoretically useful to me. none my code follows the code style of this project. i have read the contributing document. </desc> <cmt> switch chrome os mouse keys workaround to nkro </cmt> <cmt> add nkro toggle to keymaps </cmt>",switch my chrome os media keys workaround from mouse keys to nkro
2543,"<desc> adds two tests. removes not needed link. slightly changes wording in tests description. partially related to #40896. tested on local fork. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. </desc> <cmt> feat: add two tests </cmt> <cmt> fix: missing backticks </cmt> <cmt> fix: improve wording in tests description </cmt> <cmt> fix: remove not needed link </cmt> <cmt> fix: unify test with description </cmt>",add two tests to challenge
2544,"<desc> what is this about? this pr adds in the following two scripts for resource conversion: convert-resx-to-rc.ps1: to convert resx files in a folder to a single rc file with language specific conditioning. this will be run pre-build for each c++ project with rc file. convert-stringtable-to-resx.ps1: to convert a file containing the rows of a string table to a resx file. since this script is to be used only once while creating the resx file the script is not very robust, i.e. the input is required in a very specific format. in addition to the scripts, resx files have been added and rc files replaced for the following projects: colorpicker (c++) imageresizerext microsoft.launcher (c++) keyboard manager powerpreview for the above projects, locproject.json files were added to enable cdpx localization pr checklist applies to #6055 cla signed. if not, go over here and sign the cla tests passed info on pull request what does this include? the conversion script uses resgen which is a vs tool to extract the resources from a resx to a plaintext file and vice versa. the resx to rc file script reads all the resx files in the argument directory and adds in string tables to a base rc file, and adds the language specific rc file syntax based on the resx file name. the language identifiers have been hardcoded in, since localization will be done on a limited set of languages and powershell doesn't have appropriate apis to auto-generate this information. the files are added to a generated files folder so that they are skipped by .gitignore a base resource.h and base rc file is required in order to add any basic syntax for the file as well as non-localizable resources. the script generates new .h and .rc files by adding the string tables to these base files in the generated files folder. the script has try-catch blocks in case a file read/write fails because of the file being in use by another process (such as vs) the script checks if the content to be written to the file is different from the existing file to avoid rewriting. this avoids unnecessary building of files which use resources when there is no file change on incremental builds. pending work the same work will be done for fz, powerrename and sg in separate prs to avoid conflicts with other prs. validation steps performed how does someone test & validate? validated that the solution builds, and the installer builds. validated that existing french resources in imageresizerext are loaded on switching os language validated with a duplicate resx file for french with a few strings modified that it works for keyboard manager as well. validated that english strings are loaded as a fallback when using french os language if the resources dont exist. validated on cdpx pipeline that all the localized resx files are created, and the msi works as expected </desc> <cmt> added localization code to pipeline and created one locproject json for settings </cmt> <cmt> fixed typo </cmt> <cmt> reordered nuget source </cmt> <cmt> moved nuget install to restore step </cmt> <cmt> added fz.rc file to locproj </cmt> <cmt> added fz resx file and modified rc file </cmt> <cmt> fixed file names </cmt> <cmt> changed to check folder for locproject files </cmt> <cmt> updated folder </cmt> <cmt> changed directory </cmt> <cmt> changed to src directory </cmt> <cmt> changed language set and name format, removed rc file localization </cmt> <cmt> added all projects with resx/resw files </cmt> <cmt> added newline to end of file </cmt> <cmt> removed nuget source as it is not used </cmt> <cmt> updated comments </cmt> <cmt> updated keyboard manager to use resx file </cmt>",move rc files to resx
2545,"<desc> currently any plugin initialization errors are reported as user errors (unless sls_debug=* flag is on). that makes reasoning about eventual programming errors  that happen at that stage difficult (e.g. good case is this crash:  i've refactored error reporting, taking into account following use cases which lead to current state of errors handling do not crash on unknown modules when running sls --help do not crash on unknown modules when running sls plugin commands distinguish plugin not found from plugin initialization errors new solution: do not crash on module_not_found in case of sls --help or sls plugin report module_not_found errors meaningfully (also fixed its detection, as error message changed with node.js v12) pass through plugin initialization errors (it's in plugin logic where it should be decied whether we deal with user error (so serverlesserror constructor should be used), or it's a programming error that's being thrown (which should be exposed with full stack trace) </desc> <cmt> in all cases rethrow original plugin error </cmt> <cmt> cover only plugin load with error handler </cmt> <cmt> fix module not found error detection </cmt> <cmt> improve help case handling </cmt> <cmt> skip in case of 'plugin' command only on not found error </cmt> <cmt> improve logic readability </cmt>",improve plugin loading error reporting
2546,<desc> closes #17438 do not register ct specific hook when importing @cypress/vue in e2e mode. see original issue for description of problem. has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> fix: do not register ct specific event in e2e mode </cmt> <cmt> chore: fix circle.yml </cmt>,do not register ct specific hook in e2e mode
2547,"<desc> if the user deletes the applied layout, ""no layout"" should be selected automatically. what is include in the pr: apply custom layout delete applied layout verify that on every monitor where that layout was applied it was reset to ""no layout"". linked issue: #9162 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> refactoring </cmt> <cmt> reset model to blank if deleted layout was applied somewhere </cmt>","reset applied layout to ""no layout"" if it was deleted."
2548,"<desc> pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: ""[component] fix leaky abstraction"". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( fixes #6361 removes the deprecated description and error props, which were supposed to have been removed in 17.0 refactored tests as the removal of the description and error elements caused the tests to fail. </desc> <cmt> [slider] remove deprecated error prop </cmt> <cmt> [slider] remove deprecated description prop </cmt> <cmt> [slider] update unit tests </cmt>",remove deprecated error and description props
2549,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation load raw query result data into a pyarrow.table structure, which handles nullable integer columns correctly. convert table to pandas.dataframe when necessary for data manipulation. fixes #8225 note: this pr also (re)sets the default configuration results_backend_use_msgpack = true based on the benchmarks below, and the coupling with pyarrow. todo finish porting .columns method to supersettable remove explicit dtype logic from prestoenginespec fix failing tests test plan ensure correct query operations in sql lab and explore views, via synchronous and async queries. test against columns including mixed integer + null values. has associated issue: #8225 requires db migration. confirm db migration upgrade and downgrade tested. reviewers @betodealmeida @john-bodley benchmarks (2019-12-30) all metrics below are averages over at least three runs on a local superset installation running with a postgres metadata and analytics db (macbook pro 2.6 ghz, 32gb). the queries run here are selecting 100k rows from the birth_names table in the example datasets. instantiation of the new supersettable object in sql lab was slightly faster than supersetdataframe at 99.72444661ms vs 124.0594076ms, respectively. memory usage for the pyarrow.table (5659776 bytes) was significantly lower than the pandas dataframe (22259209 bytes). serialization for async queries is where the biggest performance gains are. pyarrow performed better in nearly all metrics, with the following standouts: on master, serialization/deserialization of the dataframe via json takes an average of ~7750ms pyarrow (with msgpack disabled) reduces this cycle to ~2850ms enabling msgpack in the serialization workflow further reduces this to ~1700ms, representing a ~78% performance improvement. </desc> <cmt> use pyarrow table for query result serialization </cmt> <cmt> cleanup dev comments </cmt> <cmt> additional cleanup </cmt> <cmt> wip: tests </cmt> <iss> pandas casting int64 to float64, misrepresenting value </iss>",replace pandas.dataframe with pyarrow.table for nullable int typing
2550,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> adding typescript definitions for redux-infinite-scroll </cmt> <cmt> add new line characters. </cmt>",add type definitions for redux-infinite-scroll
2551,"<desc> fixes #17254 </desc> <cmt> core: add comment explaining unit_kill_context() vs. unit_kill_common() a bit </cmt> <cmt> core: correct handling of ""systemctl kill --kill-who=main-fail"" </cmt> <cmt> --kill-who=main-fail never worked correctly, due to a copy and paste </cmt> <cmt> mistake in ac5e3a505e49c80b56c971a8fc13bacac961640d, where the same item </cmt> <cmt> was listed twice. the mistake was </cmt> <cmt> later noticed, but fixed incorrectly, in </cmt> <cmt> 201f0c916d8f65ad2595a651b1371fcd39a4cf55. </cmt> <cmt> let's list all *-fail types correctly, finally. </cmt> <cmt> and while we are at it, add a nice comment and generate a prettier d-bus </cmt> <cmt> error about this. </cmt> <cmt> core: log about ""systemctl kill"" requests </cmt> <cmt> let's add informational logging about each client requested signal </cmt> <cmt> sending. while we are at, let's beef up error handling/log messages in </cmt> <cmt> this case quite a bit: let's log errors both to syslog and report errors </cmt> <cmt> back to client. </cmt> <cmt> fixes: #17254 </cmt> <iss> log a message when a signal was sent to a process via systemctl kill </iss>","log about processed killed due to ""systemctl kill"""
2552,"<desc> #2972 tried to fix a bug about flushing operation, but it was not complete, since findsessions(key, earliestend, lateststart) does not guarantee to only return a single entry since its semantics are to return any sessions whose end > earliestend and whose start < lateststart. i've tried various ways to fix it completely and i ended up having to add a single-point query to the public readonlysessionstore api for the exact needed semantics. it is used for flushing to read the old values (otherwise the wrong old values will be sent downstreams, hence it is a correctness issue) and also for getting the value for value-getters (it is for perf only). </desc> <cmt> first try </cmt> <cmt> add single point query </cmt> <cmt> unit tests </cmt>",part ii; add single-point query for sessionstore and use for flushing / getter
2553,"<desc> i hereby agree to the terms of the cla available at:  implement bitand, bitor, bitxor, bitnot for fixedstring(n) datatype. detailed description / documentation draft: right now, only numeric datatypes are supported for functions bitand, bitor, and bitxor, otherwise we can store a bitset on clickhouse and it could be useful on certain cases to do basic operations on it. a basic case would be for an user who store ipv6 as a fixedstring(16) and to filter on it based on its mask. this pr implement this feature, in the condition than both operands are fixedstring(n), with n being common for both columns. </desc> <cmt> can use bit(and|or|xor) using a bitset set as a fixedstring </cmt> <cmt> add tests </cmt>",implement bit operations for fixedstring datatype for doing bits operation on a bitset
2554,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description earlier, i had used kernel-docs documentation style for documenting new api functions created for the annotations in the decompiler. this pr replaces these documentations by doxygen. ... test plan make sure this compiles properly. read the documentation and make sure nothing is wrong. ... closing issues ... </desc> <cmt> update docs in r_annotated_code.h </cmt> <cmt> r_core.h </cmt>",update docs in annotate code api
2555,"<desc> actually two, but the second one by far eclipses the first :) with ""-k 'not remote'"" (<-- a bit overeager matching) it runs in 26 seconds vs. 73 seconds for me. without any -k (but still with --benchmark-skip) i get 200 seconds vs. 290 seconds. (all numbers without xdist). (xdist: without benchmark, without remote, they run in ~8 seconds @ 9 processes - and still have good coverage) while overall it doesn't make a large difference for travis (since a lot of time is spent on installing and compiling stuff): #1818: ============= 532 passed, 142 skipped, 2 xpassed in 382.75 seconds ============= #1820: ============= 532 passed, 142 skipped, 2 xpassed in 298.44 seconds ============= </desc> <cmt> don't rebuild command line parser for each invocation </cmt> <cmt> makes tests faster </cmt> <cmt> lower pbkdf2 iteration count for the tests </cmt> <cmt> this cuts testing time to about one third for me. </cmt>",improve testing speed with one simple trick
2556,"<desc> while trying to crack kdb (keepass 1.x), it appears that there are some in the wild that can be quite big (actually, i've experienced some of approximatively 250 kb). this increases capability to 300kb while capability of input hash is set to a max of 0x50000 bytes </desc> <cmt> -m 13400 increased max kdb size to 300kb </cmt> <cmt> increase max size of input line to 0x50000 </cmt>",-m 13400 increase max size of kdb cracking capability to 300kb
2557,"<desc> this fixes parsing unconventional kernel versions by just grabbing the digits from the version string.  #3628 is the immediate bug fixed here, but this should also make the version parsing more robust from future bugs similar to the already-fixed #455 and #1643. in this patch, i just removed the flavor string from kernelversioninfo, as it didn't seem to be used anywhere, and if it was supposed to be informative, it didn't seem to contain useful info in many cases (e.g. 1.2.3+-flavor or 1.2.3flavor).  parsing the version string now just grabs the first 3 digit groupings, ignoring anything non-numeric that comes after it.  if it's desirable to keep the flavor around, it wouldn't be too hard to re-add it, but it would seem that we need to define how it should look given all the different separators (or lack thereof) possible in kernel version strings in the wild. also i snuck in a typo fix.  :) </desc> <cmt> add failing test for odd kernel version </cmt> <cmt> docker-dco-1.1-signed-off-by: charles lindsay <chaz@chazomatic.us> (github: chazomaticus) </cmt> <cmt> remove flavor from kernelversioninfo </cmt> <cmt> also change to parsing it with regexp to keep things simple. </cmt> <cmt> docker-dco-1.1-signed-off-by: charles lindsay <chaz@chazomatic.us> (github: chazomaticus) </cmt> <cmt> fix apparent typo </cmt> <cmt> docker-dco-1.1-signed-off-by: charles lindsay <chaz@chazomatic.us> (github: chazomaticus) </cmt> <iss> strconv.parseint: parsing ""joyent"": invalid syntax </iss>",ignore non-numeric characters when parsing kernel version
2558,"<desc> adds dtype support for c predict api. fixes: #14159 and #13335 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> upgrade archive utility and add back fc improvement </cmt> <cmt> this reverts commit 65434886f6caa7210ed3ff39cd4e950c023d8328. </cmt> <cmt> change permissions for ubuntu ar </cmt> <cmt> extract and cd into binutils dir </cmt> <cmt> allow ar path to be chosen by user </cmt> <cmt> add ar path to build </cmt> <cmt> fix ar paths </cmt> <cmt> revert ar flag in makefile </cmt> <cmt> build from source doc updated </cmt> <cmt> commit for c predict api </cmt> <cmt> add fp16 predict support </cmt> <iss> [feature request] support fp16 for c predict api </iss>",fp16 support for c predict api
2559,"<desc> gatsby-theme-docz version 2 is currently in prerelease so @next needs to be specified when installing to get latest hottness!! so i updated docs to reflect that. #16286 </desc> <cmt> fixed reference to version of gatsby-theme-docz, since version 2 isnt released yet </cmt>",fix docz version in docs tutorial
2560,"<desc> based on #10055 by @thesfreader a pr in reply to #10001 it adds an option ""c"" parameter (current) to the m27 command to echo on the serial port the currently opened file's name. current file: keefe_~1.gco if the long filename is available (long_filename_host_support), it also echoes out the long file name. current file: keefe_~1.gco keefe_0002.gcode it allows a process/device connected to the serial port to retrieve the name/long name of a file after it was opened via lcd commands, by an other process on an other serial port, or before connection was established on this port. </desc> <cmt> allow null prepend in lsdive </cmt> <cmt> add c parameter to m27 to get the current filename </cmt> <cmt> in answer to #10001 </cmt> <cmt> add an option to retrieve the currently open file name (long filename if possible). </cmt>",add 'm27 c' to echo filename (and long name)
2561,"<desc> tl;dr some minor refactoring so that i can delete effect.tag |= hookhaseffect from the synchronous deletion path. we don't need to check hookhaseffect during a deletion; all effects are unmounted. so we also don't have to set hookhaseffect during a deletion, either. this allows us to remove the last remaining passive effect logic from the synchronous layout phase. (for deletions; there's still  some passive logic in the layout phase for mounts/updates that we've yet to remove.) </desc> <cmt> setcurrentfiber per fiber, instead of per effect </cmt> <cmt> re-use safelycalldestroy </cmt> <cmt> part of the code in flushpassiveunmounteffects is a duplicate of the </cmt> <cmt> code used for unmounting layout effects. i did some minor refactoring to </cmt> <cmt> so we could use the same function in both places. </cmt> <cmt> closure will inline anyway so it doesn't affect code size or </cmt> <cmt> performance, just maintainability. </cmt> <cmt> don't check hookhaseffect during deletion </cmt> <cmt> we don't need to check hookhaseffect during a deletion; all effects are </cmt> <cmt> unmounted. </cmt> <cmt> so we also don't have to set hookhaseffect during a deletion, either. </cmt> <cmt> this allows us to remove the last remaining passive effect logic from </cmt> <cmt> the synchronous layout phase. </cmt>",move passive logic out of layout phase
2562,<desc> what do these changes do? this demonstrates running the following policies in competition: (1) heuristic policy of repeating the same move (2) heuristic policy of beating the last opponent move (3) lstm/feedforward pg policies (4) lstm policy with custom safety loss closes #4789 linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add example </cmt> <cmt> add to docs </cmt> <cmt> fix </cmt> <iss> [rllib] add some more simple multi-agent examples </iss>,add rock paper scissors multi-agent example
2563,<desc> json_rpc_2 may throw exceptions into the zone bypassing try catch. use rungaurded to catch uncaught zone exceptions and redirect them into the normal exception flow. </desc> <cmt> try to catch sync zone issue </cmt> <cmt> zone nonesense </cmt> <cmt> add without test cases </cmt>,catch errors thrown into the zone by json_rpc
2564,"<desc> commit message: fix a heap-use-after-free in lds additional description: listensocketfactoryimpl stores a const std::string& to the first listener, which is destructed upon lds update. when reuse_port is enabled, listensocketfactoryimpl reads the stale reference which may be a huge garbage string depending on where std::string::size() is aligned to the garbage memory region. risk level: low testing: integration with asan to reproduce docs changes: n/a release notes: n/a </desc> <cmt> asan repro of heap-use-after-free in lds. </cmt> <cmt> fix the stale reference. </cmt>",asan repro of heap-use-after-free in lds and a single character fix
2565,"<desc> grabbed latest production and development off jquery.com replaced all occurrences of jquery 1.4.2 with 1.4.4 executed tests on test/index.html fixed modernizr 1.5 reference so it has 1.6 in test/index.html related to issue #208 cheers, jaime </desc> <cmt> implement async load for dd_belated </cmt> <cmt> added test image to see if ie6 actually apply transparency to a 24-bit ie logo </cmt> <cmt> added test image to see if ie6 actually apply transparency to a 24-bit ie logo </cmt> <cmt> removed test 32bit png from #main as i was testing whether dd_belated png could work through $.getscript(). </cmt> <cmt> updated jquery 1.4.2 to 1.4.4 in all occurrences of the project. </cmt> <cmt> fixed modernizr path issue. it was 404ing because it didn't have 'libs' </cmt>",upgraded jquery 1.4.2 to 1.4.4
2566,<desc> related issue = #2736 move the old gl runtime (opengl_api.cpp) to device api. this commit did not really change the runtime itself and therefore another pr is needed to decouple glsl codegen with gl runtime </desc> <cmt> move gl backend onto device api </cmt> <cmt> fix compile errors </cmt>,move old runtime onto device api
2567,"<desc> previously we weren't totally being accurate with how we were reporting memory usage to svcgetinfo. we were ignoring the main thread stack size and the size of the code being loaded into memory. this corrects that. technically we should also be reporting the memory used by map physical memory as well, however we currently don't handle that yet. this will be followed up by making our resource limits behave more properly so that we can properly indicate how much total physical memory is available instead of using a hardcoded constant in vmmanager. </desc> <cmt> kernel/process: ensure that given stack size is always page-aligned </cmt> <cmt> the kernel always makes sure that the given stack size is aligned to </cmt> <cmt> page boundaries. </cmt> <cmt> kernel/process: make run's stack size parameter a u64 </cmt> <cmt> this will make operating with the process-related svc commands much </cmt> <cmt> nicer in the future (the parameter representing the stack size in </cmt> <cmt> svcstartprocess is a 64-bit value). </cmt> <cmt> kernel/process: store the main thread stack size to a data member </cmt> <cmt> this will be necessary in order to properly report memory usage within </cmt> <cmt> svcgetinfo. </cmt> <cmt> kernel/process: store the total size of the code memory loaded </cmt> <cmt> this will be necessary to properly report the used memory size in </cmt> <cmt> svcgetinfo. </cmt> <cmt> kernel/process: report total physical memory used to svcgetinfo </cmt> <cmt> reports the (mostly) correct size through svcgetinfo now for queries to </cmt> <cmt> total used physical memory. this still doesn't correctly handle memory </cmt> <cmt> allocated via svcmapphysicalmemory, however, we don't currently handle </cmt> <cmt> that case anyways. </cmt>",report total physical memory used to svcgetinfo slightly better
2568,"<desc> nodejs has a core module named crypto, why we cant use that directly instead of a separate npm package. removes warning crypto@0.0.3 crypto is also the name of a node core module. add repository field to package.json removes warning package.json hackathon-starter@0.0.0 no repository field. </desc> <cmt> removed crypto pacakage </cmt> <cmt> nodes has inbuilt crypto module </cmt> <cmt> added repository field to package.json </cmt>",remove crypto module and add repository field
2569,"<desc> adds a difference function for the baseline returns the difference between a duration column and a number to be used with the baseline endpoint to find a transaction for comparisons that are closest to a computed value add a baseline endpoint first pass using p50 as the default optional parameter with baseline value, since there isn't any way to get this result without having to make two queries </desc> <cmt> feat(discover): add a difference function </cmt> <cmt> - returns the difference between a duration column and a number </cmt> <cmt> - to be used with the eventual baseline endpoint to find a transaction </cmt> <cmt> for comparisons that are closest to a computed value </cmt> <cmt> feat(perf-views): add a baseline endpoint </cmt> <cmt> - first pass at this with p50 as the default </cmt> <cmt> - optional parameter with baseline value, since there isn't any way to </cmt> <cmt> get this result without having to make two queries. </cmt>",add a first attempt at a baseline endpoint
2570,<desc> this separates the next.config.js property images.sizes into to properties: images.devicesizes and images.iconsizes. the purpose is for images that are not intended to take up the majority of the viewport. related to #18122 </desc> <cmt> separate config into devicesizes </cmt> <cmt> rename addtionalsizes to iconsizes </cmt> <cmt> update config and api to handle both props </cmt> <cmt> fix typo </cmt> <cmt> add tests for iconsizes </cmt> <cmt> add support for iconsizes in the component </cmt> <cmt> update docs </cmt>,separate config into devicesizes and iconsizes
2571,"<desc> build on travis ci can be speed up by running parallelized builds as suggested in travis doc. instead of setting an environment variable in .travis.yml as suggested by travis, i propose to use the more flexible change in the shell script travis.sh which we have anyway. </desc> <cmt> set makeflags to use multiple processors on travis ci </cmt> <cmt> limit processors to use in travis build to 4 </cmt>",run parallelized builds on travis ci
2572,"<desc> fixes #14820. the issue is that the code is split be \n and then put into a map. on windows the key has a trailing \r which means the lookups don't find any code. i made two changes: if the code is not found, display a message rather than leaving it as null (which keeps the spinner visible) trim the code label before putting into the map happy to tweak this if you don't think they're the best fixes. </desc> <cmt> if example code is not found, render a message instead of an endless spinner </cmt> <cmt> see #14820. </cmt> <cmt> trim codetags to avoid lookup issues with windows carriage returns </cmt> <cmt> fixes #14820. </cmt> <iss> animated images ""example code"" just hangs on spinner in gallery example app </iss>",fix example code just showing endless spinner when deployed from windows
2573,"<desc> this pr introduces a framework for creating static, inline and dynamic (xds) config providers. the intent is to create a shared foundation that simplifies implementation of envoy configuration, in particular xds config handlers with shared ownership semantics such that the underlying subscription, config proto and config implementation (i.e., the resulting data structures and business logic) are shared across providers and envoy worker threads. this pr generalizes the routeconfigprovider, routeconfigprovidermanager and associated *impls currently used for implementing http route configuration and the rds api. note that static route configuration and rds are not being transitioned to the generalized framework as part of this pr (see note below for details). note: this is pr 1 (out of 4) to implement the scoped http routing design introduced in #4704. the planned pr chain is as follows: introduce generalized config provider framework implement static and dynamic scoped routing configuration based on framework introduced in pr 1; the scoped routing business logic will not be part of pr 2 implement scoped routing business logic refactor rds to use generalized config provider risk level: low (this code is not yet in use; it will be enabled in a follow up pr) testing: new tests added. docs changes: n/a release notes: n/a </desc> <cmt> refactor routeconfigprovider{,manager} into a generalized framework. </cmt> <cmt> this commit introduces a framework for implementing configuration providers by generalizing the </cmt> <cmt> routeconfigprovider{,manager} which currently implement httpconnectionmanager routing configuration </cmt> <cmt> and the rds api. </cmt> <cmt> this is the first deliverable (out of a planned 4 or 5 prs) of the scoped rds implementation (#4704). </cmt> <cmt> add comments. </cmt> <cmt> minor cleanup. </cmt> <cmt> more comments. </cmt> <cmt> comments. </cmt>","scoped rds (pr 1/4): introduce {static,dynamic} config provider framework"
2574,<desc> add keyboard and mouse button bitsum to tray click events payload move getboundsfromrect: to common event_util_mac file update documentation and commits from #2337 . resolves issue #2336 tested mac windows linux </desc> <cmt> send bounding rect on tray double click events </cmt> <cmt> update tray double-click docs </cmt> <cmt> * mention bounds payload </cmt> <cmt> move event type functions to a common  event_util file </cmt> <cmt> add keyboard modifiers payload to tray click events </cmt> <cmt> * add keyboard and mouse button bitsum to tray click events payload </cmt> <cmt> * move getboundsfromrect: to common event_util file </cmt> <cmt> * update documentation </cmt>,"add keyboard modifiers payload to tray click events, resolves #2336"
2575,"<desc> closes: #7635 </desc> <cmt> merge serverless master </cmt> <cmt> handle api pagination for resource count </cmt> <cmt> revert ""handle api pagination for resource count"" </cmt> <cmt> this reverts commit 8a9f59d885d44f974c213c0deebab8eed37f8d6f. </cmt> <cmt> handle delete stack event on first creation </cmt> <iss> aws cloudformation rollback / delete, verbose mode doesn't show cf error. </iss>",better handle delete_complete on stack creation with verbose flag #7635
2576,"<desc> in pull request #9369, i noticed the following question: there are many other non-underscore methods in pdffindcontroller; should they be part of the public api? looking into this, i found that the private methods in this file are indeed not properly indicated. this patch series fixes that in order to clarify the interface. </desc> <cmt> prefix private methods with an underscore in web/pdf_find_controller.js </cmt> <cmt> move public methods above private methods in web/pdf_find_controller.js </cmt>",improve the interface for pdffindcontroller
2577,<desc> enable boringssl assembly optimizations for aarch64 crosscompiled wheels a bunch of other cleanup and improvements (see individual commits) </desc> <cmt> cleanup unnecessary deps from grpc_artifact_python_manylinux2014_aarch64 </cmt> <cmt> cleanup in grpc_artifact_python dockerfiles </cmt> <cmt> enable boringssl assembly optimizations when crosscompiling aarch64 linux wheels </cmt> <cmt> pin manylinux2010 images to keep python27 build </cmt> <cmt> avoid pip install --upgrade cython when not necessary </cmt>,assorted python wheel build improvements
2578,"<desc> we address  #522,  #230, #768, #786 and propose a solution that should cover most of those tickets. pr includes added pooling1d and pooling2d classes in convolutional maxpooling1d/2d and meanpooling1d/2d as derived classes implemented (instead of ""pool_mode"" flags) in particular, all existing examples change untouched (same api as before) extended tests and docs note: i didn't include sumpooling, bc there seems to be no implementation in tf (that i know of), but i included a suggestion for theano in comments. if wanted, we can pretty quickly implement other pooling modes later on. </desc> <cmt> added pooling1d base class & restructured maxpooling1d </cmt> <cmt> added pooling2d base class & restructured maxpooling2d </cmt> <cmt> removed gpl test part </cmt> <cmt> removed old maxpool2d layer </cmt> <cmt> fix for 2d pooling </cmt> <cmt> fixed get_config in pooling1d/2d </cmt> <cmt> generalized pooling in tf </cmt> <cmt> generalized pooling in theano </cmt> <cmt> renaming in test </cmt> <cmt> meanpooling1d/2d introduced </cmt> <cmt> docs for new meanpooling layers </cmt> <cmt> fixed formula for reshaping in image2neibs for theano </cmt> <cmt> fixed typo in tensorflow backend </cmt> <cmt> clean up in convolutional layer </cmt> <cmt> shape inference test </cmt> <cmt> adapted test for convolutional layers </cmt>",general 1d & 2d pooling layers
2579,"<desc> this pr always sets the job related timestamps in gcs to avoid timing inconsistencies and race conditions. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> . </cmt> <cmt> revert ""revert ""job timestamp should always be in milliseconds (#16455)"" (#16545)"" </cmt> <cmt> this reverts commit 5030ed858802bf3986626be8bf72b4bfe71013a9. </cmt> <cmt> . </cmt> <cmt> . </cmt>",job timestamp should always be in milliseconds (fixed)
2580,"<desc> 644c5aa makes _ and wrapper share a prototype so that wrapper.prototype is accessible and modifiable without using mixin, or a hack like new _().__proto__.  this may or may not be desirable to you.  in my own augmentations of underscore, i've found it helpful. none of the changes affect the outcome of any tests and are pretty well explained by the commit comments. </desc> <cmt> simplify _.clone a little bit. </cmt> <cmt> escaperegexp is no longer used. </cmt> <cmt> expose wrapper.prototype as _.prototype </cmt> <cmt> define aliases inline. </cmt> <cmt> changed reduceright to avoid unnecessarily cloning an array. </cmt> <cmt> toarray returns the first argument unmodified if it passes isarray. </cmt> <cmt> so if obj passes isarray, call slice on it directly, otherwise use toarray. </cmt> <cmt> escaped lts, gts and amps in the test case descriptions. </cmt> <cmt> updated templatesettings regexes in tests, replacing the . with [\s\s] </cmt> <cmt> ""cleaned up""? _.range (or maybe not) </cmt> <cmt> adding minified version. </cmt> <cmt> slice(0) is interchangable with slice() (in method clone) </cmt>","a few changes, pull as you see fit."
2581,"<desc> suggest translation for 7-api base readme </desc> <cmt> fix small typo, links and reference fr assignment </cmt> <cmt> fix small typo, links and reference french assignment </cmt> <cmt> fix: add loc param and reference fr assignment </cmt> <cmt> add localization parameter on quizzes links and reference fr assignment </cmt> <cmt> fix localization param </cmt> <cmt> fix localization param </cmt> <cmt> add french translation for 7-api base readme </cmt>",add readme.fr.md file for 7-api-readme
2582,<desc> reset failed allocation counter before executing allocation commands. fixes #39546 </desc> <cmt> reset max_retries counter before executing routing commands </cmt> <cmt> add license header </cmt> <cmt> avoid creating routingallocation on each counter reset </cmt> <iss> reset max_retries counter before executing routing commands </iss>,reset failed allocation counter before executing routing commands
2583,"<desc> description: there are currently some issues with gatttool not beeing found. on solution would be to not use the gatttool binary, but use the bluepy library instead:  i also upgraded to the latest version (1.1.4) of bluepy as they fixes some dependecy-issues with their binaries over the last months. this should avoid some problems when installing bluepy. advantage: no dependency to existence on gatttool command line tool. gatttool is deprecated in many os, so we need to replace it anyway disadvantage: bluepy binaries might not be available on all linux platforms and some platforms might not have build-essential available to build them on the go. does not work on windows (same as gatttool) not sure if it works on macos, i do not have a mac available... the solution with modifying the requirements is not the most elegant one. i'm happy to hear better ideas on setting the requirements depending on the current platform. it would also be nice to give the user the chance to select the bluetooth back-end that works best for him, but i have no idea how to do that in hass... concerning macos/windows support: we're happy to get contributions to support these platforms in the miflora library:  related issue (if applicable): fixes #3458 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4279 example entry for configuration.yaml (if applicable): no changes here checklist: documentation added/updated in home-assistant.github.io if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> updated bluepy to version 1.1.4 as some issues with the native code were fixed there. </cmt> <cmt> miflora - added support for bluepy backend. </cmt> <cmt> miflora - now using bluepy backend on linux platforms </cmt> <iss> mi flora sensor gattool not found </iss>",miflora - use bluepy on linux systems
2584,<desc> closes #23572 fixes the console error following oliver's suggestion. i modified: /users/nsl-intern/material-ui/packages/material-ui/src/useautocomplete/useautocomplete.js made some tests to make sure it worked in: /users/nsl-intern/material-ui/docs/src/pages/components/autocomplete/useautocomplete.js i have followed (at least) the pr section of the contributing guide. </desc> <cmt> issue #23572 fixes console error </cmt> <cmt> contribution commands </cmt> <cmt> delete unnecessary comments </cmt> <iss> [autocomplete] candidate.tolowercase is not a function </iss>,improve dx/ux when getoptionlabel is not configured correctly
2585,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. @loadable/server accepts an optional object with attributes in their getscripttags, getscriptelements, getlinktags, getlinkelements, getstyletags and getstyleelements now: </desc> <cmt> add attributes to get functions </cmt> <cmt> increase version number (minor) </cmt>",loadable__server - add attributes to the get functions
2586,"<desc> fixes #12518 previously, fitting a sgdclassifier instance in a multi-class setting involved modifying in-place its coef_ attribute in the workers created by a joblib.parallel call. however, this parallel call was not requiring shared memory. for this reason, calling sgdclassifier.fit from a context manager with a loky or a multiprocessing backend (where workers are processes, and memory is not shared)  was causing a segmentation fault in the worker processes. this pr fixes it by changing the soft constraint prefer='threads' into the hard constraint require='sharedmem' when instantiating the parallel instance. we also introduce a non-regression test that makes sure that fitting a sgdclassifier in a parallel fashion yields coefficients identical to those obtained from a sequential fit, and this for each backend (loky, threading, multiprocessing) </desc> <cmt> fix use shared memory for multi-class sgd </cmt> <cmt> tst test shared memory usage for each backend </cmt> <iss> bug sgdclassifier.fit segfaulting under loky and multiprocessing backend </iss>",impose shared memory when fitting a sgdclassifier
2587,<desc> it took me a while to figure out that this error was coming from the newest version of requests rather than somewhere in django. this updates the documentation to be more control-f friendly. </desc> <cmt> make json error on empty response more specific </cmt> <cmt> fix markdown </cmt>,add helpful error message to r.json() method
2588,"<desc> also cleaned up kubernetes-master charm to use the new method of determining a certificate has changed. adds an option for the load balancer charm to add extra san entries to the generated certificate used by nginx. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): release note: added extra_sans config option to kubeapi-load-balancer charm. this allows the user to specify extra san entries on the certificate generated for the load balancer. </desc> <cmt> adding extra_sans option to load balancer to allow custom san entries on the certificate </cmt> <cmt> adding support for restarting nginx on the load balancer </cmt> <cmt> added better support for knowing when certificates are written. this helps the master restart the apiserver appropriately. </cmt>",extra_sans option added to load balancer
2589,"<desc> fixed #883: fix a bug in spritetest. comment setisaccelerometerenabled( true ); in box2dview.cpp, box2dtestbed do not use accelerometer. </desc> <cmt> fixed #883: fix a bug in spritetest. </cmt> <cmt> comment setisaccelerometerenabled( true ); in box2dview.cpp, box2dtestbed do not use accelerometer. </cmt>",fix a bug in spritetest and comment one line of unused code
2590,"<desc> function optimization ops in similar spirit as pr #32922 conv2d bwd can recreate fwd pd, so we used functions acquireforwardprimitivenonblocking. apart from that refacgtoring of conv2d grad was made to have optimizations done. </desc> <cmt> snapshot of changes to convolution </cmt> <cmt> - first draft implemented </cmt> <cmt> - compilable and ut not crashing (still failing) </cmt> <cmt> - fix to ut </cmt> <cmt> cache.vim </cmt> <cmt> - refactoring of changes </cmt>",accesses to onednn cache optimized for conv2d
2591,"<desc> i had previously updated the typings for backbone-relational to reflect the latest version on the master branch of that project. the interface of this package is however very different from the version that is actually published to npm as 0.10: on master, backbone-relational is a standalone package, while the latest version on npm still acted as a plugin that extended backbone's namespace. @sandersn advised to revert these changes, because definitelytyped only supports published versions of packages. for this reason, i hereby revert the following changes of my own: b737dc1 mostly, except for bumping the version and adding my name. my name being in there is still justified by later changes that i've made. this was the only commit of #32883. 878409b entirely, but with fixes for several merge conflicts because of changes before and after it. this was one of several commits in my pr #32909. although i believe this pr does not change the contents of the interface, just the naming, and although i've changed the tests accordingly, i find myself hitting a nasty contravariance type mismatch due to my changes (i've checked that this test error doesn't occur on latest master). help with this would be much appreciated.  test the change in your own code. (compile and run.) i couldn't do this because my code relies on the unpublished changes in the master branch of backbone-relational. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. this failed, i'm looking for help. provide a url to documentation or source code which provides context for the suggested changes: #37926 (comment) and the next two comments. if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. not applicable </desc> <cmt> revert ""remove the unnecessary module declaration from backbone-relational"" </cmt> <cmt> this reverts commit 878409b6b4db06949016f4e75428b2ad53cd6e48. </cmt> <cmt> revert ""update backbone-relational to version 0.10.0"" </cmt> <cmt> this reverts commit b737dc1ea56951ca7d06907c6a2433f0bebe6f36. </cmt> <cmt> address linter errors in backbone-relational </cmt>",restore backbone-relational to the published version 0.10 (extending backbone instead of standalone)
2592,"<desc> currently a modal route is dismissed by callback ontap. this has 2 problems: it should be dismissed by tap down instead of tap up. after #31935, ontap* will only respond to primary buttons, which means secondary (and other) buttons will no longer able to dismiss modals. to fix this, we need a tap gesture recognizer that responds to any buttons. however, adding onanytap* as a public api to tapgr might not be a good idead for 2 reasons: it's the only occasion we've found onanytap* needed for now. might not worth the cost of adding a full set of public api, especially considering... onanytap* is easy to misuse (because it competes in all events) instead modalbarrier will use a private recognizer _anytapgesturerecognizer that claims victor and calls onanytapdown immediately after it receives any pointerdownevent. methods tap, press, and related ones in widgetcontroller support customizing buttons. add private classes _anytapgesturerecognizer and _modalbarriergesturedetector. modalbarrier uses _modalbarriergesturedetector.onanytapdown to dismiss. related issues none i added the following tests: modalbarrier pops the navigator when dismissed by non-primary buttons before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add buttons to widgetcontroller and testpointer </cmt> <cmt> add more buttons </cmt> <cmt> add tests </cmt> <cmt> revert ""revert ""redo: add buttons to gestures (#31819)"" (#31912)"" </cmt> <cmt> this reverts commit 60a1b2b9ea761b4785a7c416417e64da4501ec0e. </cmt> <cmt> remove print </cmt> <cmt> remove print </cmt> <cmt> modalbarrier use onanybutton. add buttons to test pointer. </cmt>",dismiss modal with any button press
2593,<desc> this fixes a bug in transformeddistribution whereby .sample() was accidentally reparameterized. it also fixes a couple other minor .sample() bugs and adds two tests to distinguish the behavior of .sample() and .rsample(). previous review by @alicanb at probtorch#125 </desc> <cmt> ensure .sample() result is detached </cmt> <cmt> add test that .rsample() requires grad </cmt> <cmt> use hasattr-detach more consistently </cmt>,ensure distribution.sample() result is detached
2594,"<desc> from now it is possible to specify registry, repository, and tag for the docker image. </desc> <cmt> [stable/dokuwiki] refactor image properties in values.yaml </cmt> <cmt> update image.pullsecrets property </cmt> <cmt> refactor pullsecrets </cmt> <cmt> delete duplicated key </cmt> <cmt> use rolling tag </cmt>",refactor image property in values.yaml
2595,"<desc> adds a new module setting module.sanitizer_use_color, which: when set to true, forces sanitizers to use coloured output. when set to false, forces sanitizers to not use colours. when unset, or set to null, makes sanitizers use colours if possible. currently, we consider using colours ""possible"" if the user is on node and stderr is a tty. </desc> <cmt> add colours to sanitizers on node if possible </cmt> <cmt> add setting module.sanitizer_use_color to control whether colour is used </cmt> <cmt> use em_asm_int instead of em_js </cmt>",add colours to sanitizers if possible or requested
2596,<desc> fixes #12707 test plan open a chart in explore observe the white space between the chart and the data panel observe the white space between the data panel title and the data panel tabs has associated issue: #12707 includes db migration (follow approval process in sip-59) </desc> <cmt> adjust white space </cmt> <cmt> adjust chart padding </cmt> <iss> [explore]cosmetic improvement suggestions </iss>,white space between chart and data panel in explore
2597,<desc> we can filter out null rules while initializing the instance of rulebasedipfilter so we don't have to keep checking for null rules while iterating through rules array in for loop which is just a waste of cpu cycles. added null rule check inside the constructor. no more wasting cpu cycles on check the null rule each time in for loop and makes the overall operation more faster. </desc> <cmt> update repo </cmt> <cmt> sync </cmt> <cmt> add null check in rules array and update javadoc </cmt>,add null rule check in rules array of rulebasedipfilter
2598,"<desc> this pr pushes foreignerror in silgenapply towards its actual usage sites and deletes any places where we could just pass in a scalar .none instead of passing down a .none stored in a foreign error. rdar://33358110 </desc> <cmt> [silgen] pass foreignerror to emitargumentsfornormalapply by const ref instead of ref. </cmt> <cmt> foreignerror is never written to in emitargumentsfornormalapply. </cmt> <cmt> rdar://33358110 </cmt> <cmt> [silgen] remove unused foreignerror parameter from emitargumentsfornormalapply. </cmt> <cmt> before we ever used the value, we were setting foreignerror to be none. this is </cmt> <cmt> another example of a mechanical refactoring of spaghetti code. the specific </cmt> <cmt> transformation here was most likely a flattening of a conditional in the </cmt> <cmt> original code. </cmt> <cmt> rdar://33358110 </cmt> <cmt> [silgen] sink foreignerror parameter into applyfirstlevelcallee. </cmt> <cmt> we were always passing in foreignerror as an out parameter initialized to none </cmt> <cmt> and then never used that value in the caller afterwards. so there is no reason </cmt> <cmt> to keep it as a parameter to applyfirstlevelcallee. </cmt> <cmt> rdar://33358110 </cmt> <cmt> [silgen] sink foreignerror into applyfirstlevelcallee leaf functions. </cmt> <cmt> again, we were not using foreignerror as an out parameter despite the convention </cmt> <cmt> and always passed in .none. in the places, where the leaf function was not </cmt> <cmt> setting the foreignerror before passing it off to another routine, i changed the </cmt> <cmt> code to just pass in .none so i can just eliminate the variable entirely. </cmt> <cmt> the only place where i had to actually sink instead of delete was </cmt> <cmt> emitnormalapply. </cmt> <cmt> rdar://33358110 </cmt>",cleanup how foreignerror is passed around in callemission.
2599,"<desc> reintroduce 1m check for grouprelease.last_seen updates (#29311). without the 1m optimization and with only 10s buffers processing schedule we don't benefit from buffering. </desc> <cmt> buffer grouprelease.last_seen once per minute </cmt> <cmt> reintroduce 1m check for grouprelease.last_seen updates. without the 1m </cmt> <cmt> optimization and with only 10s buffers processing schedule we don't benefit </cmt> <cmt> from buffering. </cmt> <cmt> revert ""remove no longer valid test asserts"" </cmt> <cmt> this reverts commit 26bd158c83206f8fbada5d60744c68bb256d5dad. </cmt>",buffer grouprelease.last_seen update per minute
2600,"<desc> this is related to #35975. when the shard restore process is complete, the index mappings need to be updated to ensure that the data in the files restores is compatible with the follower mappings. this commit implements a mapping update as the final step in a shard restore. </desc> <cmt> wip </cmt> <cmt> wip </cmt>",update index mappings when ccr restore complete
2601,"<desc> refs: #13380 the i18n package is deprecated. it is being replaced with the tpl package. the build will pass (run yarn test and yarn lint) more info can be found by clicking the ""guidelines for contributing"" link above. </desc> <cmt> replaced i18n.t w/ tpl in images.js for canary </cmt> <cmt> refs: tryghost#13380 </cmt> <cmt> - the i18n package is deprecated. it is being replaced with the tpl package. </cmt> <cmt> - important note: invalidfile error message does not have fields for variables, but it is being passed variables. </cmt> <cmt> replaced i18n.t w/ tpl in invitations.js for canary </cmt> <cmt> refs: tryghost#13380 </cmt> <cmt> - the i18n package is deprecated. it is being replaced with the tpl package. </cmt> <cmt> replaced i18n.t w/ tpl in invites.js for canary </cmt> <cmt> refs: tryghost#13380 </cmt> <cmt> - the i18n package is deprecated. it is being replaced with the tpl package. </cmt>","replaced i18n.t w/ tpl in image.js, invitations.js, and invites.js for canary"
2602,<desc> update changelog cherry picked from commit f26272a: do not compare result to unset parameter in sysvinit module fix misformed command in sysvinit module small none-comparison style fix in sysvinit module sysvinit ansible version 2.6.2 backport  #42786 which fixes #42620. </desc> <cmt> fix 2 issues in sysvinit module (#42786) </cmt> <cmt> * do not compare result to unset parameter in sysvinit module </cmt> <cmt> * fix misformed command in sysvinit module </cmt> <cmt> * small none-comparison style fix in sysvinit module </cmt> <cmt> (cherry picked from commit f26272a492b533ddad65f1fd4bbe8ca4c46b8bba) </cmt> <cmt> update changelog </cmt>,fix 2 issues in sysvinit module (backport/2.6/42786)
2603,"<desc> description: creates an access log filter named grpcstatusfilter that allows a set of configured grpc statuses to be passed though from logging. risk level: medium, adds a new filter. testing: added unit tests to //test/common/access_log:access_log_impl_test. docs changes: autogenerated docs changes from comments in //api/envoy/config/filter/accesslog/v2/accesslog.proto fixes #5567 </desc> <cmt> defined grpcstatusfilter proto </cmt> <cmt> added a function to convert from grpc name to status::grpcstatus </cmt> <cmt> implemented grpcstatusfilter </cmt> <cmt> added validation to grpcstatusfilter </cmt> <cmt> implemented validation-related tests </cmt> <cmt> added tests to check that the filter blocks the correct traffic </cmt> <cmt> added documentation to grpcstatusfilter </cmt> <cmt> finished testing on request headers, did heavy lifting to modify code to work on response trailers </cmt> <iss> grpc: add status access log filter </iss>",added grpc-based filter to access_log
2604,"<desc> instance-level: number of alive stream threads thread-level: avg / max number of records polled from the consumer per runonce, info avg / max number of records processed by the task manager (i.e. across all tasks) per runonce, info task-level: number of current buffered records at the moment (i.e. it is just a dynamic gauge), debug. </desc> <cmt> first pass </cmt> <cmt> fix unit tests </cmt> <cmt> add unit tests </cmt> <cmt> first pass </cmt> <cmt> should be info </cmt> <cmt> fix unit tests </cmt> <cmt> github comments </cmt> <cmt> rebase </cmt> <cmt> unit tests </cmt> <cmt> add a few more metrics </cmt>",a few more metrics to add
2605,"<desc> this patch allows parser to generate a refined token stream to satisfy tooling's need. for syntax coloring, token stream from lexer is insufficient because (1) we have contextual keywords like get and set; (2) we may allow keywords to be used as argument labels and names; and (3) we need to split tokens like ""==<"". in this patch, these refinements are directly fulfilled through parsing without additional heuristics. the refined token vector is optionally saved in sourcefile instance. </desc> <cmt> initial </cmt> <cmt> update </cmt> <cmt> foo </cmt> <cmt> foo </cmt> <cmt> foo: </cmt> <cmt> foo </cmt> <cmt> foo </cmt> <cmt> update sourcekit test. </cmt> <cmt> foo </cmt> <cmt> foo </cmt> <cmt> foo </cmt> <cmt> foo </cmt> <cmt> add comments. </cmt> <cmt> add comments. </cmt>",use parser to generate a refined token stream to help syntax coloring.
2606,<desc> partially addresses #36777. fixed the following files: doc/source/development/extending.rst doc/source/user_guide/duplicates.rst doc/source/user_guide/gotchas.rst doc/source/user_guide/scale.rst </desc> <cmt> doc: use black to fix development/extending.rst pandas-dev#36777 </cmt> <cmt> doc: fix flake8-rst errors in extending.rst </cmt> <cmt> doc: use black to fix code style in user_guide </cmt>,use black to fix code style in doc pandas-dev#36777
2607,"<desc> there is an error in step3 of maskgan. notfounderror (see above for traceback): restoring from checkpoint failed. this is most likely due to a variable name or other graph key that is missing from the checkpoint. please ensure that you have not altered the graph expected based on the checkpoint. original error: key critic/rnn/biases not found in checkpoint this is an issue with seq2seq model because it uses the attention mechanism. the issue arises if you saved the model with an earlier version (seq2seq is old) and restore with a recent one (saver.restore got updated). the naming convention for lstm parameters changed, e.g. cell_0/basic_lstm_cell/weights became cell_0/basic_lstm_cell/kernel. which is why you cannot restore them if you try to restore old checkpoints with recent tf. please edit the original maskgan readme file and add this information. the below script will help rename the variables and everything will work as expected.  i tested and it worked for me, please confirm if it does for you. </desc> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt>",update readme.md to fix the issue #7040.
2608,"<desc> the extent method can be used together with a time scale. but there was no definition for that type. there was also a typo in another extent method, where the output type was used instead of the input type. </desc> <cmt> updated extent - added [date, date] return type </cmt> <cmt> the interfaces for extent don't seem to cover the common date extent scenario - i can see there's one covering generics with a generic argument accessor but it's return type is still limited to 'primitive' (tostring()-able) or the original object type 'u' - not a date typed property of u. </cmt> <cmt> in any case the standard x.domain(d3.extent(data, d=> d.date)) where data is an array of objects currently gives type errors in typescript - maybe this fix is a very specific case and there's a better generic way to approach, but i can see there are already dedicated overloads for [number, number] and [string, string] </cmt> <cmt> d3 extent should take array t, not array u </cmt>",d3 - extent does not work with dates
2609,"<desc> fixes #75508. current more of a starting point for discussion. this pr expands the page about re-use and roles, discussing when to turn a playbook into a role. my basic take is ""when it gets complicated enough."" i also went back and looked at role docs from long-ago versions of ansible, when roles were still fairly new. docs.ansible.com roles n/a </desc> <cmt> first stab at 'why roles?' </cmt> <cmt> discuss complexity </cmt> <cmt> adds detail, wordsmithing </cmt> <iss> docs survey feedback: add tips on when to turn a playbook into a role </iss>",adds documentation about when/why to use roles
2610,"<desc> made the test list panel narrower, seems to ""fix"" the bad offsetting artifacts. added an ""others"" section with a ""multi window tests"" item. the page has 2 tests: clone rntester window: this can be good to detect what is not yet hardened for multi window, thread affinity wise. an open/close secondary window test. (note: a xaml related crash may be hit from time to time, we're in contact with them to find a solution) i promise i will delete this branch from github when merged, i got mixed up a little. </desc> <cmt> smaller panel, avoids the offset rendering bug </cmt> <cmt> first multi window test </cmt> <cmt> stress test </cmt> <cmt> lf </cmt>",rntester test additions for multi-window scenarios
2611,<desc> allows ints and booleans to be set as an environment key as well as special chars to be set on the environment key backport of #37215 ansible version 2.5 </desc> <cmt> win: handle non string as an environment value (#37215) </cmt> <cmt> * win: handle non string as an environment value </cmt> <cmt> * changed powershell environment handler to use .net function instead for special chars </cmt> <cmt> (cherry picked from commit 708869edd60abb1493c2cbc3b042b835544c3eb8) </cmt> <cmt> added changelog fragement for powershell environment handler fix </cmt>,backport environment string handler fixes 2.5
2612,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! a very useful book to start learning react. the whole book is written in markdown and open source in github. it's an open source gitbook not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> delete dead links </cmt> <cmt> add react book in german </cmt> <cmt> add author </cmt>","add react book in german ""react lernen und verstehen"""
2613,"<desc> when the remove-value or pop-value action is performed, then the removedvalue field in the action meta will contain the option that was removed.  this pr adds the removedvalue field to the actionmeta type definition. this pr also removed redundant jsdocs that was causing lint to fail due to the no-redundant-jsdoc rule. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes </desc> <cmt> adding missing field to actionmeta </cmt> <cmt> when the remove-value or pop-value action is performed, then the removedvalue field in the action will contain the option that was removed. </cmt> <cmt> remove redundant jsdoc which breaks  no-redundant-jsdoc-2 lint rule </cmt>",added removevalue field to actionmeta
2614,<desc> @fernetmenta ok? (its the similar approach in configure.ac like linux does) </desc> <cmt> [configure] - define have_sse and have_sse2 on osx when compiler says so </cmt> <cmt> [aeutil] - include config.h to pick up the sse flags </cmt>,fix sse flags when using autoconf/xcode
2615,"<desc> this pr has a little bit more vi cleanup, and more notably a small hack for booting commercial games. i added a const for fence_hack, which, when set to non-zero, will stub several parcel responses such that games think their is a valid fence. this will get them running much further. this also breaks libnx, which more stringently checks the responses. when zero, things will remain as-is in the world. why introduce this? by default, the hack is off - so hopefully there is no pollution several devs internally are using the same hack (but it's much broader scoped and they don't know what is actually happening, just that it helps games boot) - so this puts us all on the same page this scopes the root issue much more narrowly, so it's a step forward in a proper fix/implementation </desc> <cmt> transactparcel: move writeblock to narrowest scope. </cmt> <cmt> vi: stub transactparcel cancelbuffer. </cmt> <cmt> vi: add fence_hack, which is useful for booting botw. </cmt>",vi cleanup and add a hack for booting games
2616,"<desc> just added a link to a stylus version for the style sheets. moreover i've pulled the updated draggable module, as it checks the context and allows to use the framework now for server rendering as well. </desc> <cmt> update draggable dependency </cmt> <cmt> link stylus version </cmt>",link stylus version + draggable update
2617,"<desc> backport of #52756 and #52750. add :qa:os and :benchmarks to the list of automatically formatted projects, and apply some manual fix-ups to polish them up. in particular, i noticed that files.write(...) when passed a list will automaticaly apply a utf-8 encoding and write a newline after each line, making it easier to use than fileutils.append. it's even available from 1.8. in :benchmarks in the allocators class, a number of methods declared thrown exceptions that intellij reported were never thrown, and as far as i could see this is true, so i removed the exceptions. </desc> <cmt> opt-in :benchmarks to automatic formatting (#52756) </cmt> <cmt> also, in the allocators class, a number of methods declared thrown exceptions that intellij reported were never thrown, and as far as i could see this is true, so i removed the exceptions. </cmt> <cmt> opt-in :qa:os to automatic formatting (#52750) </cmt> <cmt> add :qa:os to the list of automatically formatted projects, and apply </cmt> <cmt> some manual fix-ups to polish it up. </cmt> <cmt> in particular, i noticed that files.write(...) when passed a list will </cmt> <cmt> automaticaly apply a utf-8 encoding and write a newline after each line, </cmt> <cmt> making it easier to use than fileutils.append. it's even available from </cmt> <cmt> 1.8. </cmt>",autoformat :qa:os and :benchmarks
2618,"<desc> hi, i've added plugins for maven and gnu screen, based mostly on code i found on the web. cheers, -- fredrik </desc> <cmt> maven plugin </cmt> <cmt> mvn plugin </cmt> <cmt> .gitignore </cmt> <cmt> added a plugin for gnu screen. </cmt> <cmt> fix to avoid parse errors if $term is empty </cmt> <cmt> figuring out home dir on unix systems as well </cmt> <cmt> merge ssh://spix-dev01/home/fredrik/.oh-my-zsh </cmt>",maven and gnu screen plugins
2619,"<desc> namely, replace the workaround from #1392 with upstream's solution. </desc> <cmt> revert ""fixed a bug in flann resulting in uninitialized accesses."" </cmt> <cmt> this reverts commit a9975b144a22e76228125eb0a25f78ec13db6815, to prepare </cmt> <cmt> for cherry-picking upstream's solution. </cmt> <cmt> cherry-picked mariusmuja/flann@b615f2694723fe402b8bbe50d77e622beff7f171. </cmt> <cmt> original author: alex wilson. </cmt> <cmt> cherry-picked mariusmuja/flann@8c8b0e0cb879666797ab2ac51b9ee438bf84a183. </cmt> <cmt> original author: me. </cmt>",update the fix for uninitialized memory accesses in flann for master
2620,<desc> unified linux package creation into single script 'setup/linux/createpackages.sh' that uses 'linuxdeployqt' for both linux packages. </desc> <cmt> setup </cmt> <cmt> package </cmt> <cmt> restructured setup/linux </cmt> <cmt> compressing </cmt> <cmt> fix </cmt> <cmt> script chmod </cmt> <cmt> one script </cmt> <cmt> single script </cmt> <cmt> moved icons creation to packages script </cmt> <cmt> removed cpack packaging </cmt>,migrate linux '.tar.gz' package creation from cpack to linuxdeployqt
2621,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix: make server config props optional </cmt> <cmt> feat: add type definitions for server config callback funcs </cmt> <cmt> test: modify test to reflect server callbacks </cmt>",expand server configuration type definitions
2622,"<desc> this blog post kicks off a new initiative - the 100 days of gatsby challenge. users who sign up for the challenge will be sent to a new email list, so i created a new form. </desc> <cmt> add layermodel and emailcaptureform to page </cmt> <cmt> add 100daysofgatsby blog, new email capture form </cmt>",add 100 days of gatsby and new email capture form
2623,"<desc> this pr contains a couple of small follow-ups to pr #5971. make pdfhistory optional in pdflinkservice currently pdflinkservice requires access to a pdfhistory instance in order for it to work correctly (and to avoid errors). if we want pdflinkservice to be more useful in custom viewers, i don't think that we actually want to force it to have a pdfhistory instance. hence this patch, which contains a very simply approach to make pdfhistory optional. fix a couple of function names in error messages in pdflinkservice edit: even simpler reviewing with </desc> <cmt> make pdfhistory optional in pdflinkservice </cmt> <cmt> currently pdflinkservice requires access to a pdfhistory instance in order for it to work correctly (and to avoid errors). if we want pdflinkservice to be more useful in custom viewers, i don't think that we actually want to force it to have a pdfhistory instance. </cmt> <cmt> hence this patch, which contains a very simply approach to make pdfhistory optional. </cmt> <cmt> fix a couple of function names in error messages in pdflinkservice </cmt>",tweak the pdflinkservice a bit
2624,"<desc> fix #10569 with padding: [10, 20, 30, 40] in this example, before fix: (wrong) after fix: (correct) </desc> <cmt> fix: axispointer label padding not working #10569 </cmt> <cmt> test: add test case for #10569 </cmt> <iss> axispointerlabel align label padding </iss>",fix axispointer label padding not working.
2625,"<desc> the default user id is now 1, which is the same id we tell the games via iapplicationfunctions::poplaunchparameter when we launch them. the default username for now is ""yuzu"". we should eventually allow the creation of users in the emulator and have the ability to modify their parameters (profile picture, username). </desc> <cmt> hle/acc: change the default user id to be consistent with what we tell games on startup. </cmt> <cmt> in iapplicationfunctions::poplaunchparameter we tell the games that they were launched as user id 1. </cmt> <cmt> hle/acc: return an iprofile that is consistent with what was requested. </cmt> <cmt> the default username for now is ""yuzu"". </cmt> <cmt> we should eventually allow the creation of users in the emulator and have the ability to modify their parameters. </cmt>",change the default user id and small improvements to the way we handle profiles
2626,"<desc> with #3516 it is now possible for a class to extend null as permitted by es6. this pr changes the __extends helper emitted for derived classes to properly support null base arguments in es5 environments: var __extends = (this && this.__extends) || function (d, b) { for (var p in b) if (b.hasownproperty(p)) d[p] = b[p]; function __() { this.constructor = d; } d.prototype = b === null ? object.create(b) : (__.prototype = b.prototype, new __()); }; since object.create is available only in es5, an exception will be thrown for a null base argument in an es3 environment. but that was already the case before, so we're no worse off. </desc> <cmt> use object.create(null) in __extends when base is null </cmt> <cmt> accepting new baselines </cmt>",support null in __extends helper
2627,"<desc> this pr implements the following features; allow a user to browse owncloud/nextcloud files in rocket.chat and add files directly from there to rocket conversation allow a user to upload an attachment from rocket conversation to webdav account. closes #7791 , #9745 things to do: write documentation i used owncloud and nextcloud as test webdav servers. for testing you can use  server url:  username: demo password:demo to easy test the features, add new server from here with given credentials: file picker screen: to remove webdav accounts, integrations section is added to my account page. save an attachment to webdav </desc> <cmt> create rocketchat webdav package for webdav integration </cmt> <cmt> add auth mechanism for webdav integration </cmt> <cmt> add foldar and go back icon for webdav file picker template </cmt> <cmt> add some love to webdav-integration templates </cmt> <cmt> add integrations section to account ui, implement remove webdav account </cmt> <iss> nextcloud integration </iss>",webdav integration (user file provider)
2628,"<desc> while working on some default keymaps for qmk configurator, i discovered that the layout macro for the gh60 rendered a layout that isn't physically possible to build. investigating that, i discovered that the macro implied some things that were untrue (specifically, the macro was implying incorrect locations for certain keys), even though the macro worked. as it didn't conform to qmk guidelines and affected the work i was doing in configurator, i decided to fix it, and make some modernizations along the way. 21bb4bc, 89421a6, and d9dfd13 are the most important commits here imo. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> convert gh60.h to #pragma once include guard </cmt> <cmt> lint gh60.h </cmt> <cmt> this commit only changes white space. </cmt> <cmt> convert info.json to debug linting </cmt> <cmt> making this file easier to read. </cmt> <cmt> put the label keys first for layout_60_ansi </cmt> <cmt> complete and correct key labels in info.json </cmt> <cmt> duplicate layout as layout_all </cmt> <cmt> doing this for backwards compatibility. has implications for user keymaps. </cmt> <cmt> update layout_all to make sense </cmt> <cmt> the original macro layout submitted for the gh60 gets a couple of things wrong: </cmt> <cmt> - k49 is placed between space and right alt, when it's actually the right half of a split backspace </cmt> <cmt> - k3c is assigned before k3d, when k3c is the 1u portion of a 1.75u/1u split right shift, and therefore k3d is actually to the left of k3c </cmt> <cmt> the layout_all macro corrects these issues, but the layout macro is unchanged, so as to not break user keymaps that depend on it. </cmt> <cmt> this commit also updates the default keymap to use the layout_all macro, and makes a minor change to the base layer to be more as a user would expect for the corresponding physical layout. </cmt> <cmt> correct the layout data for the layout macro in info.json </cmt> <cmt> gives proper configurator rendering. </cmt> <cmt> modernize default keymap </cmt> <cmt> update the default keymap to use more modern qmk conventions. </cmt> <cmt> modernize the led management code </cmt> <cmt> update the led management functions to use the gpio functions, and clean up the led_set_kb() function. </cmt> <cmt> update key labels in info.json for layout_60_ansi_split_rshift </cmt> <cmt> makes them consistent with the the rest of the file. </cmt> <cmt> update docs links in readme file </cmt>",gh60 configurator updates and modernization
2629,<desc> how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) changelog increase the 2fa remembering time from 5min to 30min add new setting to enforce 2fa password fallback (enabled only for new installations) require 2fa to save settings and reset e2e encryption keys </desc> <cmt> increase 2fa remember time from 5min to 30min </cmt> <cmt> add setting to enforce 2fa password fallback (enabled only for new servers) </cmt> <cmt> require 2fa to save settings and reset e2ee key </cmt>,password enforcement setting and 2fa protection when saving settings or resetting e2e encryption
2630,"<desc> bugfix yes if relevant, link to documentation update: n/a summary fixes #5769 updates format of statistics output to display file size in binary units - kibibytes, mebibytes and so on. 1 kibibyte = 1024 bytes. yes. some tools may expect output of webpack in original units. these tools should use --json argument and parse the resulting json file which contains size in bytes. other information i had to replace expected values for almost all tests in statscases folder. i do not undertand what these tests are expected to do. i've just replaced expected.txt with actual.txt. so if my commit broke any code covered by these tests we will not see this. </desc> <cmt> display file size in kibibytes in statistics. fix #5769 </cmt> <cmt> update tests to match file size in kibibytes. </cmt>",display file size in kibibytes fixes 5769
2631,"<desc> this is a low priority change, just making some code more self-explanatory, simpler to read and spreading best practices throughout the example code. (1) first off i shortened three.math.degreestoradians/radianstodegrees to degtorad/radtodeg as i figured the short name would be preferred by threejs maintainers.  i personally prefer the long version but i am okay with the short version. (2) i have changed patterns in the code and the examples such as this: phi = ( 90 - lat ) * math.pi / 180; theta = lon * math.pi / 180; to this: phi = three.math.degtorad( 90 - lat ); theta = three.math.degtorad( lon ); (2) i've tested each example that i have modified.  also, all unit tests pass. (3) there were some cases such as this: mesh.rotation.y = math.random() * 360 * ( math.pi / 180 ); that i instead changed to the following as it was both simpler/faster to stay in radians: mesh.rotation.x = math.random() * 2 * math.pi; </desc> <cmt> +box3.boundingsphere(), sphere.bounds()->sphere.boundingbox(), unit tests. </cmt> <cmt> boundingsphere -> getboundingsphere(), boundingbox -> getboundingbox() per @mrdoob </cmt>",adopt three.math.degtorad/radtodeg across the code base & examples.
2632,"<desc> edit has different buttons from create, this fixes that. also does some polish for the default db name and adding some margin-bottom to the alerts. includes db migration (follow approval process in sip-59) </desc> <cmt> fix: add icons (#15122) </cmt> <cmt> * added alerts </cmt> <cmt> * revisions </cmt> <cmt> * added icon </cmt> <cmt> editdbmodal footer </cmt>",add close/finish buttons to dbmodal on edit
2633,"<desc> what do these changes do? because the logic of generating taskid in java is different from python's, there are many tests fail when we change the ray core code. in this change,  i rewrote the logic of generating taskid in java which is the same as the python's. in java, we call the native method _generatetaskid() to generate a taskid which is also used in python. we change computeputid()'s logic too. #2608 </desc> <cmt> fix task id and object generated logic. </cmt> <cmt> clean uniqueidhelper code. </cmt> <cmt> generate taskid in native code. </cmt> <cmt> change the jni method name. </cmt> <cmt> clean uniqueidhelper code. </cmt> <cmt> fix lint and clean some code. </cmt> <cmt> clean code aften multi-return being merged. </cmt> <cmt> revert the check. </cmt> <cmt> remove some todos. </cmt> <cmt> some code style. </cmt> <cmt> address comments. </cmt> <cmt> address comments. </cmt> <cmt> address comment. </cmt> <cmt> add uniqueid test. </cmt>",fix the logic of generating taskid
2634,"<desc> here are my edits for this chapter. there are a few comments on the files changed page, but they're mainly typesetting notes for @michaeldibernardo. also: on line 262, perhaps the electronic versions of the chapter could link to the appendix here? on line 1055 there is a footnote to be typeset. and i wonder if it would be worthwhile to set the appendix in slightly smaller text, to set it off from the main text of the chapter? depending how much work it would be. :) </desc> <cmt> first pass edits </cmt> <cmt> first pass </cmt> <cmt> first pass edits (complete) </cmt> <cmt> final (?) edits </cmt>",copyedits on same-origin policy in alloy chapter
2635,"<desc> this pr adds dialog.showerrorbox api which uses the safest way to prompt the error message to user, so error dialog can still show before gui environment is initialized. fixes #785. </desc> <cmt> add dialog.showerrorbox api </cmt> <cmt> win: implement dialog.showerrorbox </cmt> <cmt> use dialog.showerrorbox for showing errors </cmt> <cmt> mac: implement dialog.showerrorbox </cmt> <cmt> linux: print error to console when gui is not ready </cmt> <cmt> don't print error to console in default_app </cmt> <cmt> linux: use gtk+ for error reporting when gui is ready </cmt> <iss> crash attempting to show error dialog box on win32 </iss>",fix crash when showing error dialog before gui environment is initialized
2636,<desc> they're getting smaller each time though! the highlight of this round is source files in documentation. still trying to figure out the best syntax-highlighting solution. </desc> <cmt> rustdoc: don't emit redirect pages for variants/fields </cmt> <cmt> it's just a waste of disk space and it can be done just as well in js. </cmt> <cmt> rustdoc: fix searching for default methods </cmt> <cmt> closes #9566 </cmt> <cmt> rustdoc: fix search for something on the same page </cmt>,another round of rustdoc fixes
2637,"<desc> this pr adds a new guide for enabling anomaly detection on a pi, plus some info about performance that users might have worried about otherwise. heads up, @andrewm4894! gave your post some quick revisions and put it into the guide formatting. component name area/docs </desc> <cmt> init guide </cmt> <cmt> tweaks </cmt> <cmt> finalize draft </cmt>",unsupervised anomaly detection for raspberry pi monitoring
2638,<desc> added a solution to the project euler 72 - counting fractions i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added problem 72 </cmt> <cmt> removed args from solution() </cmt>,hacktoberfest - added a solution to project euler 72
2639,"<desc> closes: #10048 this pr clarifies the recommendation for using gkestartpodoperator. if airflow is running on google kubernetes engine and the target cluster is the same cluster, the simpler choice would still be using kubernetespodoperator with in_cluster=true. </desc> <cmt> improve recommendation note for gkestartpodoperator </cmt> <cmt> improve phrasing </cmt> <iss> misleading note in kubernetespodoperator </iss>",improve docstring note about gkestartpodoperator on kubernetespodoperator
2640,"<desc> closes #38620 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> bug: assert_produces_warning() with none or false doesn't raise </cmt> <cmt> remove commented line </cmt> <cmt> honor extra warnings arg </cmt> <cmt> add test for none with false raise on extra </cmt> <cmt> refactor added tests </cmt> <iss> bug: tm.assert_produces_warning() doesn't work with expected_warning=none or false </iss>",assert_produces_warning(none) not raising assertionerror with warning
2641,"<desc> fixes #4658 the reasoning behind the previous change was stated at #3579. but after a closer look at the webpack documentation, i see that webpack is only against the process: { env: { node_env: json.stringify('production') } } style, which would break the process object mock, while, in vue cli's base config, only process.env is replaced, which has a much smaller impact. by providing the whole process.env object, use cases such as the abovementioned destructuring of process.env are now supported, which is more intuitive imo. what might be problematic is how users customize their env vars that not started with vue_app. if they follow our example, they may accidentally override the process.env object - we've made that mistake too vue-cli/packages/@vue/cli-service/lib/commands/build/resolvewcconfig.js lines 56 to 62 02859cf config .plugin('web-component-options') .use(require('webpack/lib/defineplugin'), [{ 'process.env': { custom_element_name: json.stringify(libname) } }]) letting users tap into our base config is not ideal, either. because such configuration is very tedious and tends to break between major versions like we already have done. for this issue, we can later add a section in the documentation guiding them on how to correctly define a custom environment variable - by adding another defineplugin instance and use the 'process.env.some_name': '""somevalue""' syntax. what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) </desc> <cmt> revert ""refactor: use environmentplugin instead of defineplugin"" </cmt> <cmt> this reverts commit 7117a096dffd8664e2fcf9e68880dd9ff3743ced. </cmt> <cmt> refactor: use the exported defineplugin </cmt> <iss> destructured env vars not replaced in --modern builds </iss>",use defineplugin (again) instead of environmentplugin
2642,"<desc> these are all the cases i could find on the codebase. </desc> <cmt> buffer: do not put anything if len is 0 </cmt> <cmt> attr_file: do not assume odb data is null-terminated </cmt> <cmt> that's a bad assumption to make, even though right now it holds </cmt> <cmt> (because of the way we've implemented decompression of packfiles), </cmt> <cmt> this may change in the future, given that odb objects can be </cmt> <cmt> binary data. </cmt> <cmt> furthermore, the odb object can return a null pointer if the object </cmt> <cmt> is empty. copying the null pointer to the strbuf lets us handle it </cmt> <cmt> like an empty string. again, the null pointer is valid behavior because </cmt> <cmt> you're supposed to check the *size* of the object before working </cmt> <cmt> on it. </cmt> <cmt> notes: do not assume blob contents are null-terminated </cmt> <cmt> blame: do not assume blob contents are null-terminated </cmt>",do not assume blob contents are null terminated
2643,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. this is a fix for this scenario: import * as got from 'got'; const client = got.extend({ json: true, baseurl: ' client('/example', { query: { foo: 'bar' } }); // errors, as the options don't include json: true </desc> <cmt> fix extended got instance requiring duplicate json: true </cmt>",fix for extended got instance when options are used
2644,<desc> this removes the need for specifying the kodi_home env var in xcode. @fetzerch ping - give this a shot please </desc> <cmt> [osx] - make gethomepath more intelligent - it should finde the kodi_home dir now even when no env var is set via xcode </cmt> <cmt> [osx/readme] - remove kodi_home bits from readme (not needed anymore) </cmt>,no need for kodi_home env in xcode
2645,"<desc> as of right now an api_domain with a subfolder doesn't work. some wakapi users that end up hosting their own server, may end up using a subfolder, instead of a subdomain, just like i did on mine. so following doesn't work api_domain=example.com/wakapi because currently it becomes api_domain=example.comwakapi giving the following output i already tested this on my forked repo, so i know it works.  i don't know if changes will need to be made to make the provided api_domain safe, but as of now it only removes a trailing / at the end of the value. fixes #1026 </desc> <cmt> add subfolder support for api_domain wakatime api </cmt> <cmt> add subfolder support for api_domain wakatime api </cmt> <iss> wakapi url (domain with subpath) does not work </iss>",add subfolder support in api_domain
2646,"<desc> this fixes the root level not rendering correctly e.g. it now renders [syntheticevent, event] instead of  [object, object] the constructor.name replacement which was done by the noderenderer is now done immediately using the reviver function during json.parse. </desc> <cmt> remove noderenderer </cmt> <cmt> use reviver to inject constructor.name </cmt>",improve rendering of 'types' in addon-actions
2647,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> adding progressbaroptions to exports for progress </cmt> <cmt> adding types for multi-progress </cmt>",adding type definitions for multi-progress
2648,"<desc> description: generate requirements_test_pre_commit.txt from pre-commit configs include other requirements contents with -r instead of duplicating sync single truth for flake8 and friends, update them #28490 for some background. related issue (if applicable): #28490 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> generate pre-commit test dependencies instead of duplicating </cmt> <cmt> upgrade/sync to flake8 3.7.9, flake8-docstrings 1.5.0, and pydocstyle 4.0.1 </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> include requirements_test.txt from *_all.txt instead of copying </cmt>","reduce test requirements duplication, sync flake8 and related"
2649,"<desc> this pr is to pay for the pizza at r2con. thanks pancake :) added new command on windows: dce: continue execution (pass exception to program) fixed the following commands on windows: .dmm* dmm (now reports sane paths) dmmj (when used from e.g. r2pipe) the dce command will instruct the debugged process to handle the raised exception (similar to shift+f9 in ollydbg). this is especially useful when debugging protected executables and malware that make use of anti-debugging techniques. dmm* did not generate valid commands on windows. i have found it extremely useful to quickly get the exports of all loaded dlls by using .dmm*. the dmm command worked but its output would include the name of the executable twice. the dmmj command was problematic when scripting r2 from e.g. python via r2pipe, because the backspaces in the paths were not properly escaped. </desc> <cmt> fix r2pipe.cmdj('dmmj') command on windows. report correct path when listing modules ('dmm') </cmt> <cmt> use double quotes to make .dmm* work on windows </cmt> <cmt> removed unused local variable </cmt> <cmt> added 'dce' command for windows </cmt> <cmt> cleaned up code </cmt> <cmt> escape backslashes for json output only </cmt> <cmt> do not include r_debug_native_continue() for __cygwin__ builds. removed </cmt> <cmt> unnecessary memset. </cmt>",added dce command. fixed dmm commands.
2650,"<desc> part of #43740 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> depr: dropping of silent columns in ndframe.agg with list-like func </cmt> <cmt> depr: dropping of silent columns in ndframe.agg with list-like func </cmt> <cmt>  conflicts: </cmt> <cmt> 	pandas/tests/resample/test_resample_api.py </cmt> <cmt> remove check_stacklevel=false </cmt> <cmt> minor refactor </cmt> <cmt> fixup for whatsnew </cmt>",silent dropping of nuisance columns in agg_list_like
2651,<desc> attempt to fix: #4285 scsi support change grouping/processing attributes (#4285 (comment)) component name smartd_log todo: attribute value preprocessing (like #4285 (comment)) readme update alarms hadle log rotation problems: netdata doesn't suppport deletion of dimension deletion in runtime </desc> <cmt> smartd_log: refactor plus scsi support init </cmt> <cmt> smartd_log: ata attr class fix </cmt> <iss> add scsi device support to smartd_log.chart.py </iss>,smartd_log refactor plus scsi support
2652,"<desc> since we try not to synthesize inherited initializers, we want to be explicit and print them in subclasses. since the default argument kind was inherited, though, we were printing them as: override public init(value: swift.int = super) which didn't parse. harlan initially tried fixing this by changing how we print the module interfaces (#23933) but that approach isn't always correct. this pr changes how we consume them by updating the parser to accept the = super syntax in module interface files to mean the argument kind is inherited. i also added diagnostics for = super showing up where it shouldn't, but maybe that's overkill since module interfaces are generated? resolves rdar://49789274 </desc> <cmt> add an attribute to inhert a param's default value from the overridden decl in module interfaces </cmt> <cmt> add diagnostics for the new @_inheriteddefaultvalue attribute </cmt> <cmt> change from using the @_inheriteddefaultvalue attribute to mark parameters with an inherited default argument to using '= super' </cmt> <cmt> update tests from @_inheriteddefaultvalue to '= super' </cmt> <cmt> add test for the swiftsyntax tree produced when parsing '= super' in a module interface </cmt>",support inheriting default arguments in module interfaces via '= super'
2653,"<desc> reduces the timeout issue for unix gpu by moving the imagenet inference pointed out by @aaronmarkham imagenet inference test (along with few others) involve downloading 1.5g of all changes have test coverage: code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change remove test from unix gpu cpp examples add test to nightly tested it on mxnet ci dev jenkins </desc> <cmt> move to nightly </cmt> <cmt> bracket fix </cmt> <cmt> test imgnet comment rest </cmt> <cmt> br </cmt> <cmt> change dir </cmt> <cmt> change lib </cmt> <cmt> uncomment other tests </cmt> <cmt> change lib for build </cmt> <cmt> remove extraneous libs </cmt> <cmt> add cd to access shell script </cmt> <cmt> ready to merge </cmt>",move imagenet inference to nightly
2654,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add missing parameter type in asynciterator's multitransformer </cmt> <cmt> make asynciterator methods public </cmt>",add missing asynciterator method argument and make all methods public
2655,"<desc> hi there, i released holmes v2.1.0 yesterday and would like to update the universe entry. thanks and best wishes from munich, richard </desc> <cmt> updated universe entry for holmes </cmt> <cmt> correction </cmt> <cmt> updated model name </cmt> <cmt> updated wording </cmt>",update to holmes universe entry
2656,"<desc> code this change adds non-telemetry logging infrastructure to the project, as well as moving the telemetry code into this shared lib.  logging and telemetry are intentionally separated, although we will have telemetry functions that log as well.  telemetry will be added specifically to collect data on measures and aid in finding and fixing bugs.  logs can be added for any reason, although they are intended to allow for debugging and diagnosing problems that are not directly repro'd on a developers machine. the default location for the log file is temp\aicli.log.  temp varies based on the runtime; if run as a standalone process, this is equivalent to %temp%; if run in a packaged context, it is the temp location for the package (%localappdata%\packages<family name>\tempstate). in addition, this change moves all internal strings to be utf8 (although since we do not yet have c++20, they are simply char for now).  there is still work to be done to properly output utf8 strings to the console, but for now ascii strings work. finally, several logs are added to existing code. test while new tests were not added specifically for the logging infrastructure, the tests have been updated to always enable all logging.  this will ensure that all log string construction is executed. in the future, we may also collect the logs during test runs to enable diagnosis of failures that are specific to the devops build. </desc> <cmt> move telemetry to the logging lib; everything builds. </cmt> <cmt> logger interface defined </cmt> <cmt> rename to common, convert everything to utf8 </cmt> <cmt> implement file logger </cmt> <cmt> add logging throughout existing code </cmt>",add logging infra and logs to existing code
2657,"<desc> @dandelionmane  this is an alternative to pr7891, since you mentioned you are considering alternative ways forward. it replaces the use of a moving average window with a simple first-order lag filter. it has a few advantages: 1) a bit less code. 2) it doesn't require visiting a potentially large number of values in the window to be averaged when computing each smoothed value. 3) the degree of smoothing doesn't change when you get near the end of the curve. i left the changes in the html file so you could just run it without having to rebuild. here's what it does on the same data shown in the other pr. </desc> <cmt> fix tensorboard smoothing. </cmt> <cmt> whitespace stuff. </cmt> <cmt> preserve small averating window width at start. </cmt> <cmt> review comments. </cmt> <cmt> alternative smoothing using first-order iir lag filter. </cmt> <cmt> whitespace and cleanup. </cmt>",tensorboard smoothing 1st order lag filter
2658,"<desc> the configuration for prophetnetforcausallm is overwritten at initialization to ensure that it is used as a decoder (and not as an encoder_decoder) for text generation. the initialization of the parent class for prophetnetforcausallm is done before this overwrite, causing the model.config.is_encoder_decoder to remain possibly true. this leads to an error if the generate method of the model is later called as the non-existing method get_encoder is called. fixes #9702 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> moved prophetnetforcausallm's parent initialization after config update </cmt> <cmt> added unit tests for generation for prophetnetforcausallm </cmt> <iss> prophetnetforcausallm text generation fails </iss>",allow text generation for prophetnetforcausallm
2659,<desc> existing chart lets you use a k8s service object but we'd like to reuse an existing ingress in the k8s cluster. hey @mumoshu can you take a look and let me know if this is ok. ingress will depend on the service object being enabled dco signed title of the pr contains starts with chart name e.g. [stable/chart] </desc> <cmt> add ingress object to the apm-server chart </cmt> <cmt> version bump </cmt> <cmt> added readme documentation for last checkbox tick </cmt>,add ingress object to the chart
2660,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  godoc.org:  goreportcard.com:  coverage service links: travis , gocover make sure that you've checked the boxes below before you submit pr: </desc> <cmt> added link to the ""transaction"". </cmt> <cmt> added link to the embedded database for accounts transactions. </cmt> <cmt> update readme.md </cmt>","added a link to the ""transaction"" library in the ""finance"" section."
2661,<desc> cherry-picked some commits. </desc> <cmt> iz: escape backslash </cmt> <cmt> (cherry picked from commit 31034de572f1facd04c6feacd06a1d02f210a0aa) </cmt> <cmt> don't show double backslashes in iz </cmt> <cmt> (cherry picked from commit 983e36558ed6435c29c336d989e4ebc6db47cb0d) </cmt> <cmt> extended str.escbslash to work with iz </cmt> <cmt> made code more efficient </cmt>,extend str.escbslash to work with iz
2662,"<desc> i updated the readme to display properly and updated config to show more information. as well as added my own keymap. </desc> <cmt> add my gherkin keymap, and update readme and config </cmt> <cmt> removed unneeded code from keymap </cmt>","add my gherkin keymap, and update readme and config."
2663,"<desc> these are tests for functions where: the intended behavior is somewhat obvious the lhs doesn't seen anything special (i.e. use rand instead of randn), specified as tensor instead of variable, etc. </desc> <cmt> add some scalar autograd tests for functions taking multiple tensors/variables. </cmt> <cmt> add skipifnoscalars. </cmt>",add some scalar test_autograd tests for multi-tensor functions
2664,"<desc> adds ansi and iso versions of the 64-key 60% layout, with 2u left shift and five 1u keys and the end of the bottom row. the layouts are similar to the 60_ansi_arrow layout (kprepublic xd60/xd64 pictured), but shrink the left shift from 2.25u to 2u so as to add the forward slash key back in to the shift row. also adds a readme file to the layouts/default/ directory, containing box drawings of the community layouts that are supported. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add 64_ansi community layout </cmt> <cmt> add 64_iso community layout </cmt> <cmt> add readme.md with layout drawings </cmt> <cmt> edit readme.md - fix layout drawings </cmt> <cmt> fix 65_ansi_blocker_split_bs and 65_ansi_blocker_tsangan drawings. </cmt>",add 64_ansi and 64_iso community layouts
2665,"<desc> this pr moves globalcheckpointtracker from the engine to indexshard, where it better fits logically: tracking the global checkpoint based on the local checkpoints of all shards in the replication group is not a property of the engine, but rather a property fulfilled by the current primary shard. the localcheckpointtracker on the other hand is driven by the contents of the local translog. by moving globalcheckpointtracker to indexshard, it makes little sense to keep the sequencenumbersservice class around - it would only wrap the localcheckpointtracker. this pr therefore removes the class and replaces occurrences of sequencenumbersservice in the engine directly by localcheckpointtracker. </desc> <cmt> remove sequencenumbersservice </cmt> <cmt> fix tests </cmt> <cmt> fix javadoc </cmt>",move globalcheckpointtracker and remove sequencenumbersservice
2666,"<desc> fix #3091. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> fix #3091 by empty auth manager. </cmt> <cmt> fix #3091 by empty auth manager. </cmt> <iss> deploying addressserver reported an error and could not start </iss>",fix address server can't start up by implement an empty auth manager.
2667,"<desc> our rbms used to take about 45% of their time just computing convergence information. this pr brings that down to a few percent. also, sparse matrices are no longer densified in score_samples, given a memory reduction of several orders of magnitude (for my typical data, that can be up to eight orders). finally, the reported figures should be more realistic because they reflect the actual change that occurred during an iteration. the downside is that the fit procedure requires a bit more memory now because it computes pseudo-likelihood for the entire input matrix. ping @vene, and maybe @issamlaradji will find this interesting too. </desc> <cmt> bug don't densify sparse matrix in bernoullirbm.score_samples </cmt> <cmt> also documented the non-determinism of this method. </cmt> <cmt> enh speed up progress reporting in rbm </cmt> <cmt> previously took up to 45% (!) of the time in training, not the 10% promised </cmt> <cmt> in the docstring, for the digits example. now down to at most 3%. </cmt> <cmt> pseudo-likelihood is now reported for the entire x, rather than batch-by-batch, </cmt> <cmt> which will take more memory. </cmt>",faster convergence reporting in rbms
2668,"<desc> when constants are required in a module, the following code could be added to the spec to enforce type checking: struct myturbomodulespec : winrt::microsoft::reactnative::turbomodulespec { static constexpr auto constants = std::tuple{ typedconstant<myturbomoduleconstants1>{0}, typedconstant<myturbomoduleconstants2>{1}, }; template <class tmodule> static constexpr void validatemodule() noexcept { constexpr auto constantcheckresults = checkconstants<tmodule, myturbomodulespec>(); react_show_constant_spec_errors( 0, ""myturbomoduleconstants1"", ""    react_get_constants(getconstants1) myturbomoduleconstants1 getconstants1() noexcept {/*implementation*/}\n"" ""    react_get_constants(getconstants1) static myturbomoduleconstants1 getconstants1() noexcept {/*implementation*/}\n""); react_show_constant_spec_errors( 1, ""myturbomoduleconstants2"", ""    react_get_constants(getconstants2) myturbomoduleconstants2 getconstants2() noexcept {/*implementation*/}\n"" ""    react_get_constants(getconstants2) static myturbomoduleconstants2 getconstants2() noexcept {/*implementation*/}\n""); } }; for each typedconstant<t>, it requires that, there must be one and only one react_get_constants method for such t, and it should be either t()noexcept or its static version. i have manually tested to ensured that error messages will be emitted as expected when the module doesn't match the module spec in all ways. microsoft reviewers: open in codeflow </desc> <cmt> update turbomoduletest.cpp </cmt> <cmt> react_show_constant_spec_errors </cmt> <cmt> checkconstants<tmodule, tmodulespec>(); </cmt> <cmt> fix syntax errors </cmt> <cmt> make turbomoduletest.cpp compiles against checkconstants </cmt> <cmt> ensure checkconstants fails in certain condition </cmt> <cmt> change files </cmt>","add checkconstants<tmodule, tmodulespec> for react_get_constants"
2669,<desc> i added documentation for the plyexporter using the gltfloader documentation as reference. update i also updated the gltfexporter page because it incorrectly showed that the constructor could take default options </desc> <cmt> add initial doc for ply exporter </cmt> <cmt> updates </cmt> <cmt> more changes </cmt> <cmt> grammar </cmt>,add ply exporter documentation page
2670,"<desc> this pr does the following: update documentation referencing @zeit/fetch to @vercel/fetch switch packages @zeit/fetch to @vercel/fetch fix browser.js to actually use @vercel/fetch, it was only using unfetch directly before update react to 17 change folder name and package name </desc> <cmt> update documentation referencing @zeit/fetch </cmt> <cmt> use @vercel/fetch </cmt> <cmt> - switch @zeit/fetch to @vercel/fetch </cmt> <cmt> - fix browser to actually use @vercel/fetch, it was only using unfetch </cmt> <cmt> update react and unfetch </cmt> <cmt> - get rid of message about next 11 </cmt> <cmt> update package name </cmt>",change zeit fetch to vercel fetch
2671,"<desc> what do these changes do? this pr exposes the cl option for using a config file. this is important for certain tests (i.e., ft tests that removing nodes) to run quickly. note that this is bad practice and should be replaced with gflags or some equivalent as soon as possible. #3239 depends on this. todo: add documentation to method arguments before merging. add test to verify this works? </desc> <cmt> first pass at allowing updatable values </cmt> <cmt> fix compilation issues </cmt> <cmt> full initialization </cmt>",expose internal config parameters for starting ray
2672,"<desc> fix up common features list convert avr pin functions to gpio commands fix eeprom example to use keyboard_post_init_user add additional supported commands to flashing doc add additional supported commands to newb flashing doc rearrange macro feature page, and add additional supported commands update process_record list rename best practices link in sidebar to git best practices expand faq build guide's zadig section add deprecation info to keymap doc basically, this is a collection of small changes that have been bugging me for a while. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fix up common functions doc </cmt> <cmt> add to extra commands to flashing doc </cmt> <cmt> rearrange and touch up macros </cmt> <cmt> expand newbs flashing guide </cmt> <cmt> update process_record documentation </cmt> <cmt> add git to best practices name in sidebar </cmt> <cmt> expand faq for build/flashing </cmt> <cmt> add deprecated info to functions </cmt>",smallish overhaul of the docs
2673,"<desc> hello, this pr relates to issue #3136 in order to refresh the corsican ressource files from transifex: resources.co.resx latest update on transifex on september 12th, 2020 resourcestooltips.co.resx latest update on transifex on september 11th, 2020 cheers, patriccollu. </desc> <cmt> update resources.co.resx from transifex on 2020-09-20 </cmt> <cmt> update resourcestooltips.co.resx from transifex on 2020-09-20 </cmt>",update corsican resources from transifex on 2020-09-20
2674,"<desc> this pr merges the default colors and cursor color into the main color table, enabling us to simplify the congetset and iterminalapi interfaces, with just two methods required for getting and setting any form of color palette entry. the is a follow-up to the color table standardization in #11602, and a another small step towards de-duplicating adaptdispatch and terminaldispatch for issue #3849. it should also make it easier to support color queries (#3718) and a configurable bold color (#5682) in the future. on the conhost side, default colors could originally be either indexed positions in the 16-color table, or separate standalone rgb values. with the new system, the default colors will always be in the color table, so we just need to track their index positions. to make this work, those positions need to be calculated at startup based on the loaded registry/shortcut settings, and updated when settings are changed (this is handled in calculatedefaultcolorindices). but the plus side is that it's now much easier to lookup the default color values for rendering. for now the default colors in windows terminal use hardcoded positions, because it doesn't need indexed default colors like conhost. but in the future i'd like to extend the index handling to both terminals, so we can eventually support the vt525 indexed color operations. as for the cursor color, that was previously stored in the cursor class, which meant that it needed to be copied around in various places where cursors were being instantiated. now that it's managed separately in the color table, a lot of that code is no longer required. some of the unit test initialization code needed to be updated to setup the color table and default index values as required for the new system. there were also some adjustments needed to account for api changes, in particular for methods that now take index values for the default colors in place of colorrefs. but for the most part, the essential behavior of the tests remains unchanged. i've also run a variety of manual tests looking at the legacy console apis as well as the various vt color sequences, and checking that everything works as expected when color schemes are changed, both in windows terminal and conhost, and in the latter case with both indexed colors and rgb values. closes #11768 </desc> <cmt> merge default colors into color table. </cmt> <cmt> eliminate default color apis in congetset and iterminalapi. </cmt> <cmt> standardize color table apis in congetset and iterminalapi. </cmt> <cmt> use index values when referring to default colors. </cmt> <cmt> cache the calculation of default color indices. </cmt> <cmt> merge cursor color into color table. </cmt> <cmt> simplify registry queries for special colors. </cmt> <cmt> silence the spelling bot. </cmt> <iss> simplify the color palette apis </iss>",consolidate the color palette apis
2675,"<desc> original pull-request #26545 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update entrypoint.sh </cmt> <cmt> we build clickhouse cluster in k8s by clickhouse-operator. </cmt> <cmt> clickhouse-server.log is mounted by emptydir on the path /var/log/clickhouse-server. </cmt> <cmt> it causes the file system error called necessary directory '/var/log/clickhouse-server' isn't owned by user with id '101'   when  clickhouse_do_not_chown is set to true(1). </cmt> <cmt> because emptydir file and dir is owned by root when it started, it has to do the chown cmd. </cmt> <cmt> but it will take a long time to run chown cmd when the cluster has much data (in table data dir), the cluster cannot even restart because of  initialdelayseconds </cmt> <cmt> so chown operation is necessary to check if the file owner and group is owned by user 101. </cmt> <cmt> update entrypoint.sh </cmt> <cmt> update entrypoint.sh </cmt> <cmt> update entrypoint.sh </cmt>",cherry pick #26545 to 21.8: update entrypoint.sh
2676,<desc> update sirit and its usage in vk_shader_decompiler. highlights: implement tessellation shaders for vulkan. implement geometry shaders. implement some missing features. use native half float instructions when available. </desc> <cmt> shader_ir/memory: implement patch stores </cmt> <cmt> shader: keep track of shaders using warp instructions </cmt> <cmt> vk_shader_decompiler: misc changes </cmt> <cmt> update sirit and its usage in vk_shader_decompiler. highlights: </cmt> <cmt> - implement tessellation shaders </cmt> <cmt> - implement geometry shaders </cmt> <cmt> - implement some missing features </cmt> <cmt> - use native half float instructions when available. </cmt> <cmt> shader_ir/other: implement s2r invocationid </cmt> <cmt> vk_shader_decompiler: reduce ynegate's severity </cmt>,add tessellation and misc changes
2677,"<desc> it is intended to optimize/beautify the code generated in a few trivial trait operations. let's take the following code as an example: trait stuff { fn bar(&self); } fn callbar(s: &stuff) { s.bar(); } struct foo; impl stuff for foo { fn bar(&self) { } } pub fn main() { let o = foo; callbar(&o as &stuff); } at present it is translated into something like: define void @_zn7callbar_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }*, { %tydesc*, i8* }*) #4 { ""function top level"": %__trait_callee = alloca { %tydesc*, i8* } %__auto_borrow_obj = alloca { %tydesc*, i8* } %2 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 0 %3 = load %tydesc** %2 %4 = getelementptr inbounds { %tydesc*, i8* }* %__auto_borrow_obj, i32 0, i32 0 store %tydesc* %3, %tydesc** %4 %5 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 1 %6 = load i8** %5 %7 = getelementptr inbounds { %tydesc*, i8* }* %__auto_borrow_obj, i32 0, i32 1 store i8* %6, i8** %7 %8 = bitcast { %tydesc*, i8* }* %__auto_borrow_obj to i8* %9 = bitcast { %tydesc*, i8* }* %__trait_callee to i8* call void @llvm.memcpy.p0i8.p0i8.i32(i8* %9, i8* %8, i32 8, i32 4, i1 false) %10 = getelementptr inbounds { %tydesc*, i8* }* %__trait_callee, i32 0, i32 1 %11 = load i8** %10 %12 = bitcast i8* %11 to { i32, %tydesc*, i8*, i8*, i8 }* %13 = getelementptr inbounds { %tydesc*, i8* }* %__trait_callee, i32 0, i32 0 %14 = bitcast %tydesc** %13 to [1 x i8*]** %15 = load [1 x i8*]** %14 %16 = getelementptr inbounds [1 x i8*]* %15, i32 0, i32 1 %17 = load i8** %16 %18 = bitcast i8* %17 to void ({ i32, %tydesc*, i8*, i8*, i8 }*)* call void %18({ i32, %tydesc*, i8*, i8*, i8 }* %12) ret void } ... define void @_zn4main_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }*) #4 { ""function top level"": %o = alloca %struct.foo %1 = alloca { %tydesc*, i8* } %__auto_borrow_obj = alloca { %tydesc*, i8* } %2 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 1 %3 = bitcast i8** %2 to %struct.foo** store %struct.foo* %o, %struct.foo** %3 %4 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 0 %5 = bitcast %tydesc** %4 to { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }** store { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }* @vtable1081, { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }** %5 %6 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 0 %7 = load %tydesc** %6 %8 = getelementptr inbounds { %tydesc*, i8* }* %__auto_borrow_obj, i32 0, i32 0 store %tydesc* %7, %tydesc** %8 %9 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 1 %10 = load i8** %9 %11 = getelementptr inbounds { %tydesc*, i8* }* %__auto_borrow_obj, i32 0, i32 1 store i8* %10, i8** %11 call void @_zn7callbar_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }* undef, { %tydesc*, i8* }* %__auto_borrow_obj) ret void } if you apply my patch, it would become way shorter and cleaner: define void @_zn7callbar_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }*, { %tydesc*, i8* }*) #4 { ""function top level"": %2 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 1 %3 = load i8** %2 %4 = bitcast i8* %3 to { i32, %tydesc*, i8*, i8*, i8 }* %5 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 0 %6 = bitcast %tydesc** %5 to [1 x i8*]** %7 = load [1 x i8*]** %6 %8 = getelementptr inbounds [1 x i8*]* %7, i32 0, i32 1 %9 = load i8** %8 %10 = bitcast i8* %9 to void ({ i32, %tydesc*, i8*, i8*, i8 }*)* call void %10({ i32, %tydesc*, i8*, i8*, i8 }* %4) ret void } ... define void @_zn4main_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }*) #4 { ""function top level"": %o = alloca %struct.foo %1 = alloca { %tydesc*, i8* } %2 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 1 %3 = bitcast i8** %2 to %struct.foo** store %struct.foo* %o, %struct.foo** %3 %4 = getelementptr inbounds { %tydesc*, i8* }* %1, i32 0, i32 0 %5 = bitcast %tydesc** %4 to { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }** store { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }* @vtable1081, { %tydesc*, void ({ i32, %tydesc*, i8*, i8*, i8 }*)* }** %5 call void @_zn7callbar_uuid.0e({ i32, %tydesc*, i8*, i8*, i8 }* undef, { %tydesc*, i8* }* %1) ret void } although this change doesn't increase the compilation speed much (i mentioned only about 1-2% boost on ""rustc -o -z time-passes syntax.rs""), but i still think it's a good thing to do as it greatly simplifies/clarifies ll generated in some cases which would definitely help in the future code generation investigations. i don't provide any new test cases in this patch as it is merely an optimization. sorry guys, i somehow messed my previous pr and i don't see any better way to fix as to recreate it here. </desc> <cmt> optimized trans_to_datum::auto_borrow_obj code generation in case some trivial cases where simple copying can be applied </cmt> <cmt> minor type::opaque_trait code cleanup </cmt> <cmt> will not copy trait_callee on stack if it's source expr is a plain borrowed ref </cmt> <cmt> pacified test/run-pass/core-run-destroy on win7x64 </cmt>",a couple trait method call optimizations
2678,"<desc> modifies the existing rle test to compress into two rle blocks instead of one, and now we also check that there is no significant size regression (arbitrarily set to 10% of 39 bytes) as a proxy for testing that the blocks were indeed compressed with rle (without rle it would compress to 47 bytes). curiously, the existing test for rle would compress to the same size regardless of whether rle blocks were enabled. also validated that previous patch will fail this test. </desc> <cmt> fixed main compression logic changes </cmt> <cmt> modified existing rle test to take compressed size into account </cmt>",rle test and re-enable rle in main compression loop
2679,"<desc> todo addres joel's comment #7808 (comment) document that multiple split calls may not return identical train/test sets if random_state is not set. there was a warning that suppressed a test. using np.testing.assert_equal to test for equality of nested lists fixes that. the word rank in the mock table view of cv_results_ is assumed as a link. fixed in #7388 address andy's comments refactor @lesteve's #7946 out of this pr @jnothman @amueller pl. review :) </desc> <cmt> doc add note that unless random_state is set, split will not be identical </cmt> <cmt> tst use np.testing.assert_equal for nested lists/arrays </cmt> <cmt> tst make sure cv param can be a generator </cmt>",add few more tests + documentation for re-entrant cross-validation estimators
2680,"<desc> previously you could only authenticate with the gcp using permanent service credentials. these were either the default credentials on your machine (specified through an env variable) or passed in through the gcp_credentials field in the cluster config yaml as a json string. this pr changes the gcp_credentials field to be a json object consisting of a type field and a credentials field. the type can either be ""service_account"" (which will have the same behavior as before) or ""credentials_token"" (i.e. a temporary oauth 2.0 authentication token). this change also adds support in the gcp autoscaler for authentication using these tokens. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) tested manually by starting and updating a cluster with both types of credentials. </desc> <cmt> add update to gcp_credentials structure in ray-schema, add support for tokens in config </cmt> <cmt> formatting </cmt>",gcp authentication using oauth tokens
2681,"<desc> backport of #19228. invalid dtypes comparison changes behavior of comparison to not raise typeerror when one of the operands cannot be converted to valid dtype. example: >>> dtype = pd.date_range(""2016-01-01"", periods=2, tz=""utc"").dtype >>> dtype == np.dtype(""datetime64[ns]"") false >>> np.dtype(""datetime64[ns]"") == dtype false # before: >>> np.dtype(""datetime64[ns]"") == dtype typeerror: cannot interpret 'datetime64[ns, utc]' as a data type resolves #19187 </desc> <cmt> bug: remove typeerror on invalid dtypes comparison </cmt> <cmt> tst: check invalid dtypes comparison </cmt> <cmt> bug: return notimplemented for unrecognized dtypes </cmt> <cmt> tst: check invalid dtypes for equality | check typeerror for comparisions </cmt> <cmt> bug: removed typing for == and != in dtypes </cmt>",invalid dtypes comparison should not raise typeerror
2682,"<desc> #341 #434 ...by setting svg style content to commandline css content, if available -- this overwrites clonecssstyles didn't change mermaidapi util clonecssstyles -- pending refactoring (branch refactor_mermaidapi_render) </desc> <cmt> add more tests in cli_test-samples: flowchart, sequence, gantt, gitgraph, load html in phantomjs and save screenshot png </cmt> <cmt> fix cli css style selector text lowercase problem by setting svg style content to commandline css content, if available -- this overwrites clonecssstyles </cmt>",added tests and fix cli css style selector lowercase problem
2683,"<desc> the issue: create timer with some repeat count scheduler::schedule(callback, target, interval, repeat, delay, paused, key); wait for last repeat executed in timer callback reschedule it again with the same key as result timer is broken and will never be executed reason: when we reschedule timer again from callback the scheduler just updates interval value: timer->setinterval(interval); after callback executed timer will be canceled: if (!_runforever && _timesexecuted > _repeat) {    //unschedule timer cancel(); return; } fix: scheduler will update interval only for not exhausted timers (still running). in our case, it will create new internal timer object and old one will be canceled after callback. the same fix i did for cocos2d-html5 here cocos2d/cocos2d-html5#3478 </desc> <cmt> merge from cocos </cmt> <cmt> fix reschedule issue </cmt>",fix reschedule issue with same key
2684,<desc> i hereby agree to the terms of the cla available at:  changelog category: documentation for #19204 </desc> <cmt> reads file as string - description of the new function. </cmt> <cmt> updated description </cmt> <cmt> reads file as a string </cmt> <cmt> link for see also </cmt>,documentation of the 'file()' function
2685,"<desc> commit log converter/ibm_5291: configurator support (7821491) added layout data to info.json file corrected keyboard_folder value converter/ibm_5291: readme cleanup (a6dcb0d) fixed ""image"" url (target of link was a web page; changed markdown formatting to text link) sentence capitalization fixes markdown formatting fixes for readability </desc> <cmt> converter/ibm_5291: configurator support </cmt> <cmt> - added layout data to info.json file </cmt> <cmt> - corrected keyboard_folder value </cmt> <cmt> converter/ibm_5291: readme cleanup </cmt> <cmt> - fixed ""image"" url (target of link was a web page; changed markdown formatting to text link) </cmt> <cmt> - sentence capitalization fixes </cmt> <cmt> - markdown formatting fixes for readability </cmt>",configurator support and readme cleanup
2686,"<desc> this pr implements #11609 by adding configuration options to enable/disable the default formatters vs code ships, namely javascript, typescript, html, and json </desc> <cmt> add [typescript|javascript].formate.enable </cmt> <cmt> fallback to next formatter when the previous didn't produce a result </cmt>",enable/disable toggles for default formatters
2687,"<desc> this pr makes the like= argument in array creation functions strict, meaning that dispatching on a reference object that does not implement the __array_function__ protocol will raise an exception, as per discussion in #17075 . i'm not sure if by only allowing objects implementing the __array_function__ here is excessively strict and we should instead consider having an exclusion list (e.g., lists, tuples, etc.) or if this is the appropriate approach here. </desc> <cmt> maint: add array_function_dispatch_like helper </cmt> <cmt> this helper is used to dispatch a python function with the like= </cmt> <cmt> argument or raise an error if the object passed doesn't implement the </cmt> <cmt> __array_function__ protocol. </cmt> <cmt> maint: make like= in python functions strict </cmt> <cmt> only allow objects that implement __array_function__ </cmt> <cmt> maint: make like= in np.array() strict </cmt> <cmt> only allow objects that implement __array_function__ </cmt> <cmt> tst: test strict like= </cmt>",make like= argument added in nep-35 strict
2688,"<desc> description: add dns_failure_refresh_rate to the dns cache, much like the strict and logical dns clusters. risk level: low. new functionality needs a config change to opt in. testing: added unit tests. docs changes: updated release notes: added entry adds functionality needed by envoyproxy/envoy-mobile#673 </desc> <cmt> introduce status to the callback and maintain prior functionality </cmt> <cmt> update validation resolver </cmt> <cmt> update dns impl test </cmt> <cmt> update upstream impl test </cmt> <cmt> update </cmt> <cmt> missing commit </cmt> <cmt> update and fix #9927 </cmt> <cmt> release notes </cmt> <cmt> fmt </cmt> <cmt> update test </cmt> <cmt> move line </cmt> <cmt> wip </cmt> <cmt> full except exception </cmt> <cmt> fmt </cmt> <cmt> ask and you shall receive </cmt> <cmt> compile me with gcc </cmt> <cmt> remove templatized test </cmt>",add dns failure refresh rate
2689,"<desc> issue: #8507 add component id to: csf loader mdx compiler codemods official-storybook (csf / mdx) documentation (after review) migration.md see included tests, plus official-storybook </desc> <cmt> core: add component id to csf loader </cmt> <cmt> code: verify component id in codemods </cmt> <cmt> official-storybook: add component id csf / mdx examples </cmt> <cmt> mdx: add component id to compiler & refactor tests </cmt>",add component id for permalinks
2690,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).     if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> less any, more hopefully correct types </cmt> <cmt> email-templates and nodemailer both accept arguments in variety of formats. </cmt> <cmt> usedtypes from nodemailer types and and read both email-templates and </cmt> <cmt> nodemailer documentation in orer to construct a better typedef </cmt> <cmt> somewhat typed preview </cmt> <cmt> some tests, pass the generics around </cmt> <cmt> contributor </cmt> <cmt> wrong type for views </cmt>","more accurate types, less any"
2691,<desc> this pr fixes the cleanup of the items created in /tmp during the execution of the tests. </desc> <cmt> pkg/system: fix cleanup in tests </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> pkg/archive: fix temparchive cleanup w/ one read </cmt> <cmt> this fixes the removal of temparchives which can read with only one </cmt> <cmt> read. such archives weren't getting removed because eof wasn't being </cmt> <cmt> triggered. </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> pkg/symlink: fix cleanup for tests </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> integ-cli: fix cleanup in test which mounts tmpfs </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> integ-cli: fix cleanup in build tests </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt>,fix cleanup of /tmp in tests
2692,"<desc> added support in abi_serializer to print out the contents of a block's header_extensions and block_extensions and a transaction's transaction_extensions. #8080 this will affect how the new extensions_type attributes are reported for signed_block, or block when represented in json. this will affect the following endpoint: /v1/chain/get_block the block json object will have an optional: ""new_protocol_features"" array of objects with a field of ""feature_digest"" which reports the feature's digest value (the same digest that is reported in logging when nodeos is started) ""new_producer_schedule"" object with: ""version"" number for the new schedule ""producers"" array of objects with: ""producer_name"" name of the producer ""authority"" block signing authority for the producer ""additional_signatures"" array of additional signatures provided on the block this will also affect how the new extensions_type attributes are reported for transactions (but not signed_transactions) when represented in json. this will affect the following endpoint: /v1/chain/get_scheduled_transactions the transaction json object will have an optional: ""deferred_transaction_generation"" object with: ""sender_trx_id"" sender transaction id ""sender_id"" id of the sender ""sender"" sender account name </desc> <cmt> added static methods for retrieving data from extensions_types. gh #8080 </cmt> <cmt> refactored existing code to use new extensions_type methods.gh #8080 </cmt> <cmt> add methods for signed_block and transaction so that ...gh #8080 </cmt> <cmt> ...extensions_type parameters will be reported as their actual data. </cmt>",report block extensions_type contents in rpc and eosio-blocklog tool - develop
2693,"<desc> split from #22743 this has just the docs changes, not the doc build / ci changes, so i don't have to keep fixing merge conflicts. </desc> <cmt> fixed link to resmpaler </cmt> <cmt> (cherry picked from commit 9f0a948947cf959a8750cbf11b2a52a1ccb47eaf) </cmt> <cmt> futurewarning from groupby. </cmt> <cmt> warning about elementwise comparison failing when we indexed </cmt> <cmt> a dataframe with boolean dataframe </cmt> <cmt> (cherry picked from commit 1168273efa0f941eae734645dc2d3d82ae778016) </cmt> <cmt> purge read_table </cmt> <cmt> (cherry picked from commit 41c8297142bc95522c199a0f623abcf77d45a8a5) </cmt> <cmt> removed nested list example </cmt> <cmt> (cherry picked from commit 2e76e845b23f036d96b80fa164d49b577481303e) </cmt> <cmt> fixed resample __iter__ </cmt> <cmt> (cherry picked from commit a70f86df6b57b67cf5c7035f1f0c4afd7642da31) </cmt> <cmt> old whatsnew </cmt> <cmt> (cherry picked from commit e4a8b064b9c93378430ebcf972e999349f84f05b) </cmt> <cmt> ecosystem </cmt> <cmt> (cherry picked from commit 693eead60d96d4297d9b55a6e86eeeb2b2797220) </cmt> <cmt> to_csv </cmt> <cmt> (cherry picked from commit e6b2c09284f2d68e38c1d5df06a966817a802d63) </cmt> <cmt> to_json </cmt> <cmt> (cherry picked from commit a7f0b3841367afc5ed641287e1bb971243477d0f) </cmt> <cmt> handle subpackages better </cmt> <cmt> (cherry picked from commit ff3d2dd7620eb9b4cf928dd4b66dadc7bb65b011) </cmt> <cmt> fixed unexpected indent </cmt> <cmt> (cherry picked from commit e54424981814f2ec5a5047e3ff33953340058b3a) </cmt> <cmt> fixed ""inline interpreted text..."" </cmt> <cmt> (cherry picked from commit 8bdb9202e95264f6e1009e8afb66c071c03b9f76) </cmt> <cmt> fixed ""malformed hyperlink target"" </cmt> <cmt> (cherry picked from commit ae0f8ff028076ece045736a847ced25ddc5f5086) </cmt> <cmt> fixed unexpected indentation </cmt> <cmt> (cherry picked from commit b1908660804fe897ebf38c71aa85e1811bc1e73a) </cmt> <cmt> newline after directive </cmt> <cmt> (cherry picked from commit a46e4c7b513e7930e6a5e1b6e530ce223f9613a6) </cmt> <cmt> maybe fix na_value not included in toctree </cmt> <cmt> (cherry picked from commit 74af53db4164670dbeafbd58ae45467d15eb8044) </cmt> <cmt> fixed no link to na_value </cmt> <cmt> (cherry picked from commit 1668c654422dd5841c32b789a556388d42182192) </cmt> <cmt> fixed ii ref </cmt> <cmt> (cherry picked from commit dda2bfc6741bb0d1b07a485cb0910d7e0425c313) </cmt> <cmt> revert make.py changes </cmt>",fix warnings in doc build
2694,<desc> here are a few patches to make changing the mcu clockrate a bit easier. i've rewritten the c code to generate speed_lookuptable.h in python and tried to make it a bit more self-explanatory. i've also added a few hints around the tree describing what how to change f_cpu. </desc> <cmt> add create_speed_lookup </cmt> <cmt> stepper: clarify comment on timer-counter configuration </cmt> <cmt> add instructions to regenerate speed_lookuptable when changing f_cpu </cmt>,make f_cpu dependence of stepper.cpp more explicit
2695,<desc> breaking changes -<box sx={{ borderradius: 'borderradius' }}> +<box sx={{ borderradius: 1 }}> // theme.shape.borderradius * 1 -<box sx={{ borderradius: 16 }}> +<box sx={{ borderradius: '16px' }}> closes #23188 </desc> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> fixed nan issue </cmt> <cmt> migration guide </cmt> <iss> [system] change the borderradius prop to use the theme.shape.borderradius as a multiplication value </iss>,make borderradius multiply a theme's design token
2696,"<desc> currently the nuget package's targets file filters out consuming projects, so that only uwp apps get the microsoft.reactnative.winmd reference. this prevents win32 apps that want to use the nuget package from building. fixes #8894 microsoft reviewers: open in codeflow </desc> <cmt> fix win32 apps referencing the m.rn nuget package so they can use rnw </cmt> <cmt> change files </cmt> <iss> cannot use nuget in win32 apps </iss>",fix win32 apps that want to use the rnw nuget package
2697,"<desc> added serverrequest.finalize():  consuming all unread body stream and trailers. this is cleanup method for reading next request from same keep-alive connection. needed when handler didn't consume all body and trailers even after responding. refactor: serverrequest._bodystream(), serverrequestbody are removed. now using bodyreader() and chunkedbodyreader() instead. fix: trailers should only be read transfer-encoding is chunked and trailer header is set and its value is valid. fix: use headers.append() on reading trailers. fix: delete trailer field from headers after reading trailers. reorg: several functions related to io are moved into http/io.ts adding more tests... </desc> <cmt> wip </cmt> <cmt> adding tests </cmt> <cmt> lint </cmt> <cmt> fix writetrailers </cmt> <cmt> fix: store trailers in existing headers </cmt> <cmt> assign empty reader if body doesn't exist </cmt>",consume unread body and trailers before reading next request
2698,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). include tests for your changes </desc> <cmt> fix/add some serverless types </cmt> <cmt> update test </cmt> <cmt> update version </cmt>,fix/add some aws serverless types
2699,"<desc> description: previously, rawstatdataallocator was not a full allocator implementation, but required alloc() and free() to be provided by hotrestartimpl, binding them together. splitting them out makes rawstatdataallocator easier to re-use for tests, and improves flexibility, which will help #4980 . risk level: low -- this is a pure refactor testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> checkpoint </cmt> <cmt> checkpoint </cmt> <cmt> get hot_restart_impl_test working with instantiated allocator. </cmt>",contain rawstatdataallocator in hotrestartimpl rather than as its superclass
2700,"<desc> fixes #15610 see b/109797594 and moby/moby#38491 for details about the workaround. the reason why the workaround isn't needed for run_tests.py tests but is needed for foundry is that (unlike run_tests.py) foundry runs each test in a new docker container, so ipv6 link local addresses might not be ready yet when the test is executing. </desc> <cmt> make tcp_server_posix_test pass on foundry </cmt> <cmt> reenable tcp_server_posix_test on foundry </cmt>",reenable tcp server posix test after applying workaround
2701,"<desc> a search might need to be cancelled. this pull does 2 things when project scan is run again, any previous search is cancelled project::cancelscan() function was added </desc> <cmt> terminate the old search if another is run. </cmt> <cmt> upgrade scandal@0.9.0 </cmt> <cmt> remove log line </cmt> <cmt> add cancelscan() </cmt>",add the ability to cancel project.scan
2702,"<desc> closes #34010 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> revert part ""cln: catch more specific exceptions in groupby </cmt> <cmt> #27909"" </cmt> <cmt> add test for 34010 </cmt> <iss> bug: valueerror: given date string not likely a datetime when grouping by periodindex level </iss>",bug in series.groupby would raise valueerror when grouping by periodindex level
2703,"<desc> we currently check whether translog files can be trimmed whenever we create a new translog generation or close a view. however #25294 added a long translog retention period (12h, max 512mb by default), which means translog files should potentially be cleaned up long after there isn't any indexing activity to trigger flushes/the creation of new translog files. we therefore need a scheduled background check to clean up those files once they are no longer needed. relates to #10708 </desc> <cmt> add time based trimming </cmt> <cmt> clean ups </cmt>",add a scheduled translog retention check
2704,"<desc> fixes #4260 actually, it was fixed some time earlier, so i just added a regression test to minimongo - basics. the test ensures that minimongo does not preserve properties from an inserted object's prototype or which are non-enumerable. the client behavior regarding prototype properties differed from the server behavior as recently as meteor 1.5.1. </desc> <cmt> sync fork </cmt> <cmt> regression test for #4260 </cmt> <cmt> expand test for non-enumerable properties </cmt> <iss> objects flattened only in localcollection </iss>",regression test for prototype and non-enumerable properties in minimongo
2705,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: (just look at #36184) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [@wordpres/components] run prettier on all files </cmt> <cmt> fix: navigable-container props extend htmldivelement </cmt> <cmt> fix: formfileupload should also accept ""icon"" prop for non-render variant </cmt> <cmt> fix: toolbar component ""label"" prop is not required </cmt> <cmt> fix: radiocontrol value can be any type, not just string </cmt>",quick hotfix from small issues found in #36184
2706,"<desc> hi, this pr fixes a small test issue when launched in a browser which default width is different than in phantomjs. in my case it was happening in firefox (npm run test-nolint -- --browsers firefox) </desc> <cmt> test(map): set div width for getboundszoom inside </cmt> <cmt> in particular firefox has a different default width than phantomjs, making the result different than the expected one. wider container => can zoom higher to fit the specified bounds. </cmt> <cmt> docs(map): getboundszoom add padding </cmt> <cmt> 3rd argument docstring. </cmt>","set div width for getboundszoom parameter inside, firefox"
2707,"<desc> original pull-request #13624 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> first attempt </cmt> <cmt> better </cmt> <cmt> add test </cmt> <cmt> update 00157_cache_dictionary.reference </cmt> <cmt> add locks to fix datarace </cmt> <cmt> better </cmt> <cmt> disable test with tsan because it is too slow </cmt> <cmt> update skip_list.json </cmt> <cmt> update test and bump ci </cmt> <cmt> update skip_list.json </cmt> <cmt> final fix </cmt> <cmt> cache-dictionary flap </cmt>",cherry pick #13624 to 20.7: cache-dictionary flap
2708,"<desc> what is this about? added in 6 keyboard manager events namely: keyboardmanager_keytokeyremapinvoked keyboardmanager_keytoshortcutremapinvoked keyboardmanager_oslevelshortcuttoshortcutremapinvoked keyboardmanager_oslevelshortcuttokeyremapinvoked keyboardmanager_appspecificshortcuttoshortcutremapinvoked keyboardmanager_appspecificshortcuttokeyremapinvoked these are fired when the key/shortcut remap is invoked, i.e. on the key down message after the sendinput statement so that the first input event gets fired before the telemetry event is sent. a combination of the above metrics can be used to check active usage of keyboard manager, i.e. if any of the above events fired recently, that means kbm is actively used. pr checklist applies to #6391 cla signed. if not, go over here and sign the cla tests passed validation steps performed how does someone test & validate? validated that there is no performance impact by running from signed msi with the following performance counter code in #44c6125 validated tests pass locally </desc> <cmt> added key remap invoked telemetry event </cmt> <cmt> added queryperformance call </cmt> <cmt> added in telemetry for key and shortcut remaps </cmt>",add in missing telemetry for keyboard manager usage
2709,"<desc> i love the dist/6to5.js build, but it does make a hard assumption that the host environment browser document context. it'd be great if just checked the module provided global local instead of hard coding window. then the script would work in web workers or in standalone cli environments besides node (i know node would prefer to use the lib/ files anyway). use global instead of window check before trying to call attachevent to install loading hooks thanks! </desc> <cmt> prefer module global reference rather than window </cmt> <cmt> check if attachevent is defined </cmt>",prefer module provided global rather than window reference
2710,"<desc> fix #1051, fix #1749 </desc> <cmt> save </cmt> <cmt> add retinanet and fix some inconsistent </cmt> <cmt> fix registry </cmt> <cmt> fix typos </cmt> <cmt> fix unmap bug </cmt> <cmt> fix some bugs </cmt> <cmt> clean </cmt> <cmt> minor fix </cmt> <cmt> fix k b </cmt> <cmt> add more cfgs </cmt> <cmt> fix detach </cmt> <cmt> merge v2.0 </cmt> <cmt> add some benchmarks </cmt> <cmt> add some comments </cmt> <cmt> add more comments </cmt> <iss> any plans for prime sample attention in object detection? </iss> <iss> when the source-code of pisa will be released? </iss>",prime sample attention in object detection (cvpr 2020)
2711,"<desc> add code for rev3 plaid-pad (support for ssh1306 oled display) move led pin assign for rev1-rev2 to the rev folders fix steady increasing volume problem add keymap with oled support and multiple layers my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add img for rev3 and bootmagic lite instructions </cmt> <cmt> fix steadily in/decrease volume </cmt> <cmt> move led pin assign into rev folders </cmt> <cmt> add ifdef to disable leds on rev3 </cmt> <cmt> add rev3 and change default folder to rev3 </cmt> <cmt> add oled keymap for rev3 and higher </cmt>",add plaid-pad rev3 and oled keymap
2712,"<desc> original pull-request #30244 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix [i]like function </cmt> <cmt> add test </cmt> <cmt> fix like function </cmt>",cherry pick #30244 to 21.8: fix like function
2713,"<desc> in 2.1.0 the snowflakehook/operator dropped support for parameters when passing sql as a string. this re-enables parameterization and keeps query splitting functionality using split_statements from snowflake (the same function used within execute_string) and then parameterizes and executes the individual queries. closes #16068 </desc> <cmt> fix: restore parameterizing sql when passed to snowflakehook as str </cmt> <iss> snowflake hook doesn't parameterize sql passed as a string type, causing snowflakeoperator to fail </iss>",restore parameters support when sql passed to snowflakehook as str
2714,<desc> backport prs: #13529 and #13503 to release 1.16. risk level: low testing: ci docs changes: no release notes: yes </desc> <cmt> examples: fix more deprecations/warnings in configs (#13529) </cmt> <cmt> examples: fix deprecations/warnings in configs (#13503) </cmt> <cmt> updated release notes. </cmt>,examples to use v3 configs
2715,"<desc> what did you implement: closes #5154 how did you implement it: extend cloudformation reference syntax to accept region in the form of ${cf.region:stackname.outputkey}, e.g. ${cf.us-east-1:my-service-dev.foobar}. if region is omitted, default region is used, as same as current ${cf}. how can we verify it: install custom build of serverless from this pr npm i -g exoego/serverless#cf-ref-region create a service to be referenced: sls create -t aws-nodejs --path my-service update serverless.yml of my-service service: my-service provider: name: aws runtime: nodejs8.10 region: ap-northeast-1 memorysize: 512 functions: hello: name: ${self:custom.functionprefix}hello handler: handler.hello custom: functionprefix: ""issue5154-"" resources: outputs: functionprefix: value: ${self:custom.functionprefix} export: name: functionprefix memorysize: value: ${self:provider.memorysize} export: name: memorysize deploy my-service: sls deploy create another service:  sls create -t aws-nodejs --path another update serverless.yml of another service: another provider: name: aws region: us-east-1 runtime: nodejs8.10 memorysize: ${cf.ap-northeast-1:myservice-dev.memorysize} functions: hello: name: ${cf.ap-northeast-1:myservice-dev.functionprefix}hello-usa handler: handler.hello deploy another service that reference my-service todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add region suffix support to cloudformation reference syntax </cmt> <cmt> add capability to request different region only if it is specified in options. </cmt> <iss> ${cf} for another region </iss>",extend ${cf} syntax to get output from another region
2716,"<desc> see #3377. </desc> <cmt> use name of command for ""virtual man page"" name </cmt> <cmt> this makes it slightly easier to debug manpage issues without removing </cmt> <cmt> the virtmanpage hack. </cmt> <cmt> fix build_man issues (fixes #3364) </cmt>",fix build_man issues (1.1 backport)
2717,<desc> taking a shot at the fixme comment in stdlibunittest to make some flags atomic. does not solve any sr. </desc> <cmt> addressing fixme comment making stdlibunittest flags atomic </cmt> <cmt> commenting store </cmt> <cmt> fix wrong change </cmt> <cmt> add comment </cmt>,addressing fixme comment atomic stdlib unit test flags
2718,"<desc> tasmota in a blank device, supports by default all the wi-fi modes available in the esp8266 that are ieee 802.11b/g/n. but, if the device is not blank or comes from another firmware, sometimes the supported modes are restricted like having only 11b or 11b/g. tasmota don't force the full support. that is why, this pr adds new options for the command wifi to force which modes are going to be used. the wifi command now have the following options with this pr: 0 - turn off wi-fi 1 - turn on wi-fi 2 - force the device to only connects as a 11b device 3 - force the device to only connects as a 11b/g device 4 - force the device to connects as a 11b/g/n device when changing modes, the device disconnects and reconnects to the router without restarting. because of that, sometimes you need to refresh your browser. (remember that if your router don't support 11b, or is configured to not support 11b and you force 11b, your device won't connect. in the serial console you see ap timeout no matter if the ssid and password are ok) besides that, with this pr, it has been added to show the actual mode in status 11, in the response of the wifi command and in the information menu of the webui, for user troubleshooting. also this pr have some code cleaning. forcing modes is useful to troubleshoot and solve issues like: a device that had another firmware before, a device that is far from a router (sometimes forcing 11b gives more range <- this depends on the router due to new routers have wide and better range on 11n), if in the users' network, there is a very old device that only supports 11b, sometimes old or cheap routers can't manage correctly different devices in different modes and put the entire network on 11b. with this, you can force to use 11n in tasmota and find which device is lowering the performance in the network, if a new device can't connect and from the serial interface it is being showed ap timeout, it can be checked now which modes are supported in the tasmotized device to match the router's. in the ap mode, the esp8266 supports only b/g modes. these code changes were tested too on esp32 and works fine. the esp32 have all mode enabled by default, so this pr don't provide the new options of the wifi command for esp32. it just provide showing the actual mode. the esp32 supports b/g/n/lr on both ap and sta modes. the lr mode (long range-low rate of 1km) is not supported in tasmota atm and can not be used. related issue (if applicable): na proposed changes to the docs: tasmota/docs#751 the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> wifi command: move wifi modes char to be global </cmt> <cmt> wifi command: move wifi modes char to be global </cmt> <cmt> add actual wi-fi mode (b/g/n) to status 11 </cmt> <cmt> add actual wi-fi mode (b/g/n) to status 11 </cmt> <cmt> add actual wi-fi mode (b/g/n) to information menu </cmt> <cmt> and some code cleaning </cmt> <cmt> add new options to wifi command </cmt> <cmt> actual options: </cmt> <cmt> 0 - turn off wi-fi </cmt> <cmt> 1 - turn on wi-fi </cmt> <cmt> new options added: </cmt> <cmt> 2 - force the device to only connects as a 11b device </cmt> <cmt> 3 - force the device to only connects as a 11b/g device </cmt> <cmt> 4 - force the device to connects as a 11b/g/n device </cmt>",add wi-fi modes control command
2719,"<desc> also adding support for goto def on  the alias (e.g:  a and b in import {a, b} from ""mod"";) </desc> <cmt> support getdefinitionlocation on module names and aliases for new import/export syntax </cmt> <cmt> accept baselines </cmt>",support for goto def on new import/export syntax
2720,"<desc> closes #6112 updated the gpg command for windows. updated the context stating the requirement of updation. i have reviewed my changes in staging (look for the deploy-to-heroku link in your pull request, then click view deployment). for content changes, i have completed the self-review checklist. </desc> <cmt> minor fixes </cmt> <cmt> minor fixes in command </cmt> <iss> update gpg creation guide on windows </iss>",updated reusables and gpg commands for windows
2721,<desc> the target folder in vnext contains the build output from the windows modules. it also contains the unittest temp locatoins. these can frequently generate long paths. it seems that flow.exe is not compiled with long path support for windows and fails on those folders. eslint also throws a bunch of warnings about the long paths if it encounters them. microsoft reviewers: open in codeflow </desc> <cmt> don't lint target folder and don't flow check node_modules packages </cmt> <cmt> change files </cmt>,don't eslint nor flow check the target folder
2722,"<desc> fixes #12264. change default auth rule configuration from native to all_privileges_permitted. add default transaction rule configuration spi. update test cases. </desc> <cmt> fixes #12264, change default auth rule configuration from native to all_privileges_permitted. </cmt> <cmt> add default transaction rule configuration. </cmt> <cmt> # conflicts: </cmt> <cmt> #	shardingsphere-mode/shardingsphere-mode-type/shardingsphere-cluster-mode/shardingsphere-cluster-mode-core/src/main/java/org/apache/shardingsphere/mode/manager/cluster/clustercontextmanagerbuilder.java </cmt> <cmt> merge from master. </cmt> <iss> shardingsphere-jdbc 5.0.0-rc1-snapshot throws  select command denied to user exception </iss>",update default global rule builder
2723,<desc> i got several of the examples fixed up to work with the new api; let me know whether there are any problems </desc> <cmt> update mnist_transfer_cnn for new api </cmt> <cmt> update mnist_siamese_graph.py for new api </cmt> <cmt> refactor example a little bit for clarity </cmt> <cmt> update mnist_irnn.py for new api </cmt> <cmt> fix variable name </cmt> <cmt> update mnist_heirarchial_rnn.py for new api </cmt> <cmt> fix a few api calls i missed </cmt> <cmt> update mnist_acgan.py for new api </cmt> <cmt> fix variable name </cmt> <cmt> update imdb_cnn for new api </cmt> <cmt> update benchmark.py to work with new api </cmt>,update several examples to work with the new api
2724,"<desc> handling empty string output. pluribus networks modules ansible 2.7.5 config file = /etc/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/dist-packages/ansible executable location = /usr/bin/ansible python version = 2.7.12 (default, nov 12 2018, 14:36:49) [gcc 5.4.0 20160609] </desc> <cmt> handling empty output string </cmt> <cmt> handling emply string output </cmt>",pluribus networks modules handling empty output
2725,<desc> 1 more patches for fixing the build system on windows for visual studio and one more for improved handling of linkflags and cflags </desc> <cmt> fix handling for cflags and linkflags like for ccflags </cmt> <cmt> previously cflags and linkflags were passed as a single </cmt> <cmt> quoted argument to the compiler or linker. this patch splits the </cmt> <cmt> paramters. </cmt> <cmt> fix for 64bit builds with vc from command line </cmt> <cmt> previously builds for 64 bit targets on the x64 native tools command </cmt> <cmt> prompt failed while trying to link the 64bit build godot objects with </cmt> <cmt> 32bit vc libraries. this was due to wrong library directories. </cmt> <cmt> since there are the environment variables include and lib which are </cmt> <cmt> containing the correct paths this patch uses those now to fix the linking </cmt> <cmt> issue. </cmt>,more fixes to the build system
2726,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> included types for registerpanoprovider opts </cmt> <cmt> removed an additional r from registerpanoprovider </cmt> <cmt> removed panoprovideroptions </cmt> <cmt> added correct panoprovideroptions </cmt>",adding missing opt types for registerpanoprovider method in @types/googlemaps
2727,"<desc> info.json files added for tada68, jc65(m65-a) and the whitefox. </desc> <cmt> support for tada68 ansi layout. </cmt> <cmt> avoiding the iso layout as it doesn't seem correct </cmt> <cmt> whitefox support for configurator </cmt> <cmt> configurator support for jc65 pcb featuring both the qmk and ps2avrgb versions </cmt>",info.json configurator support for popular 65% keyboards
2728,"<desc> reviewed and updated to f-string for: pandas/compat/pickle_compat.py pandas/_config/config.py pandas/core/arrays/boolean.py contributes to #29547 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry marking pickle_compat.py as done but i left the existing .format as is, as i believe this is a good use case for .format </desc> <cmt> cln: update old string formatting to f-strings </cmt> <cmt> reviewed and updated to f-string for: </cmt> <cmt> pandas/compat/pickle_compat.py </cmt> <cmt> pandas/_config/config.py </cmt> <cmt> pandas/core/arrays/boolean.py </cmt> <cmt> contributes to gh29547 </cmt> <cmt> ran black pandas </cmt> <cmt> styling fixes </cmt>",update old .format to f-string
2729,<desc> on master (0cda557) visual studio update in github actions ci virtual environment could break a build as the vcpkg cache is not updated accordingly (see #17788). this pr: force vcpkg cache update on msbuild update is an alternative to #17789 fixes #17788 </desc> <cmt> ci: update qt binaries for github actions </cmt> <cmt> on 2019-12-09 visual studio has been upgraded to 16.4.0 in windows </cmt> <cmt> server 2019 (windows-latest) virtual environment. </cmt> <cmt> ci: update vcpkg cache on msbuild update </cmt> <iss> ci: github actions update to visual studio 16.4.0 </iss>,update github actions ci vcpkg cache on msbuild update
2730,"<desc> review pooledbytebufallocator in respect of jemalloc 4.x changes and update allocate algorithm. for size from 512 bytes to chunksize, we use a buddy algorithm. the drawback is that it has a large internal fragmentation. modifications: add sizeclassesmetric and sizeclasses remove tiny size, now we have small, normal and huge size rewrite the structure of poolchunk rewrite pooled allocate algorithm in poolchunk when allocate subpage, using lowest common multiple of pagesize and elemsize instead of pagesize. add more tests in pooledbytebufallocatortest and poolarenatest reduce internal fragmentation. closed #3910 </desc> <cmt> review pooledbytebufallocator in respect of jemalloc 4.x changes and </cmt> <cmt> update allocate algorithm. </cmt> <cmt> motivation: </cmt> <cmt> for size from 512 bytes to chunksize, we use a buddy algorithm. the </cmt> <cmt> drawback is that it has a large internal fragmentation. </cmt> <cmt> modifications: </cmt> <cmt> 1. add sizeclassesmetric and sizeclasses </cmt> <cmt> 2. remove tiny size, now we have small, normal and huge size </cmt> <cmt> 3. rewrite the structure of poolchunk </cmt> <cmt> 4. rewrite pooled allocate algorithm in poolchunk </cmt> <cmt> 5. when allocate subpage, using lowest common multiple of pagesize and </cmt> <cmt> elemsize instead of pagesize. </cmt> <cmt> 6. add more tests in pooledbytebufallocatortest and poolarenatest </cmt> <cmt> result: </cmt> <cmt> reduce internal fragmentation. </cmt> <cmt> closed #3910 </cmt> <cmt> update commit and details </cmt> <cmt> fix defaultmaxpages = 2560 </cmt> <iss> review pooledbytebufallocator in respect of jemalloc 4.x changes </iss>",reduce memory fragmentation caused by pooledbytebufallocator
2731,<desc> replaced array_like with array-like in  sklearn/feature_selection/_mutual_info.py #17300 </desc> <cmt> replaced array_like with array-like in sklearn/feature_selection/_mutual_info.py </cmt> <cmt> edited line 353 359 431 437 which had a e501 flake8 error for being too long in sklearn/feature_selection/_mutual_info.py </cmt>,replace array_like with array-like in iss sklearn/feature_selection/_mutual_info.py
2732,"<desc> this mr adds the ability to configure the backup of old passwords in the passwordstore lookup. previously, the lookup always saved old passwords in the lookup_pass subkey of the password. with this mr, this is disabled by default (as password store provide git integration) and can be re-enabled with the backup=true parameter. passwordstore ansible version ansible 2.6.0 (passwordstore 05672a582d) last updated 2018/05/03 14:57:08 (gmt +200) config file = /home/stephane/.ansible.cfg configured module search path = ['/home/stephane/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /home/stephane/git/sparunakian/ansible/lib/ansible executable location = /home/stephane/git/sparunakian/ansible/bin/ansible python version = 3.6.5 (default, apr 14 2018, 13:17:30) [gcc 7.3.1 20180406] </desc> <cmt> add backup option in passwordstore lookup </cmt> <cmt> update passwordstore lookup documentation </cmt> <cmt> add precision regarding backup param </cmt> <cmt> fix empty line added at eof </cmt>",add backup option to passwordstore lookup (and improve doc)
2733,"<desc> all new protocols, v2, are available in  all new services are in language-agent-v2 and register. grpc is provided, no restful yet. @ascrutae i need you to make autotests ready for all these as soon as possible. please make the high priority of this task. @liuhaoyang @ascrutae this should be supported in new .net release and nodejs release </desc> <cmt> update new protocol </cmt> <cmt> support new protocol at agent side. </cmt> <cmt> fix test case. </cmt> <cmt> make backend supports new trace protocol </cmt> <cmt> fix tests. </cmt> <cmt> make all new services available in grpc. </cmt>",support new v2 protocol and make concept consistently
2734,"<desc> first i hope i followed the correct steps for this pr. i managed to get the readme.md translated to arabic while maintaining the formatting (hopefully). i also added a link in the original readme.md to the arabic version. </desc> <cmt> 40% arabic translation </cmt> <cmt> link to arabic version of readme.md </cmt> <cmt> complete arabic translation </cmt> <cmt> testing herf tags </cmt> <cmt> testing full html </cmt> <cmt> since github markdown doesn't play nice with arabic, i got the plain html from markdown </cmt> <cmt> another go at formatting </cmt> <cmt> formatting fixes </cmt> <cmt> formatting for arabic is fun </cmt>",adding arabic translation to readme.md
2735,"<desc> add my first name, last name, link to my github </desc> <cmt> add my name and my github link </cmt> <cmt> undo a mistake on the first line </cmt> <cmt> undo a mistake on the first line </cmt>",adding my first pull request
2736,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see the example  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. note: besides adding parameters with types to a bunch of onresult and onerror callbacks this pr primarily defines the interface of h.service.serviceresult by looking at the actual return values when using h.service.trafficincidentsservice, h.service.geocodingservice and h.service.routingservice. there is no proper documentation for that interface but it's used universally: </desc> <cmt> fix type for h.service.serviceresult </cmt> <cmt> fix typings, extend definition of h.service.serviceresult </cmt>","improve definition of h.service.serviceresult, add missing parameters to callbacks"
2737,"<desc> hi i found some properties had wrong or missing types :d, also sorry @tyler-zhang i ordered properties alphabetical, also fixed some callback types, reexported xdate as localeconfig to have also localeconfig support. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix wrong and missing properties in the 3 components, add localeconfig </cmt> <cmt> fix for <file name must be camelcase> </cmt>","react-native-calendars fix wrong type and missing properties in the 3 components, add localeconfig"
2738,"<desc> i'm working my way through trpl beginning at ""syntax and semantics"" as was recommended in a previous version. i'm expecting the chapter to incrementally build up my knowledge of the language section by section, assuming no prior rust experience. so it was a bit of a speed-bump to encounter references and the vector type in a code example long before they had been defined and explained. another commit in this pr tries to make consistent what is a ""chapter"" of trpl versus a ""section."" just a nit-pick, but not thinking about that stuff keeps my focus on the important material. my background: python programmer since ~2000, with moderate exposure to c, c++, assembly, operating systems, and system architecture in university several years ago. for your kind consideration, feel welcome to use or drop or rework any part of this. </desc> <cmt> explain surprising new syntax appearing in example code </cmt> <cmt> in a straight-through read of ""syntax and semantics,"" the first time we </cmt> <cmt> meet a generic, and the first time we meet a vector, is when a vec<t> shows </cmt> <cmt> up in this example. i'm not sure that i could argue that the whole section </cmt> <cmt> should appear later in the book than the ones on vectors and generics, so </cmt> <cmt> instead just give the reader a brief introduction to both and a promise to </cmt> <cmt> follow up later. </cmt> <cmt> link to references section when they first appear </cmt> <cmt> in a straight-through read of ""syntax and semantics,"" the concept of a </cmt> <cmt> ""reference"" is used here before it is explained. mention that and link to </cmt> <cmt> the section explaining references. </cmt> <cmt> link to section on references when we use the term prior to defining it </cmt> <cmt> be consistent about what is a ""chapter"" versus a ""section"" </cmt>",some minor docs improvements for trpl
2739,<desc> fill in description tags in: degtorad.js radtodeg.js rotate.js within.js roundawayfromzero.js iseven.js vector2.js has all filled except for methods: normalizerighthand cross lerp transformmat3 transformmat4 and the x and y properties under vector2like object - i assume these are the same as for vector2 </desc> <cmt> fill all description tags in degtorad.js </cmt> <cmt> fill all description tags in tadtodeg.js </cmt> <cmt> fill all description tags in rotate.js </cmt> <cmt> fill in remaining description tags for within.js </cmt> <cmt> fill all description tags in roundawayfromzero.js </cmt> <cmt> fill description tags in iseven.js </cmt> <cmt> update return statement description in degtorad </cmt> <cmt> update return statement description in radtodeg </cmt> <cmt> fix grammar in return statement description degtorad.js </cmt>,"docs for degtorad, radtodeg, rotate, within, roundawayfromzero and iseven"
2740,"<desc> splitting out some things from the 'tuner' branch (omp tuning) in order to make the tuner pr more palatable when it posts (smaller, simpler). since omp behavior has little to do with the engine classes themselves, and the omp logic will get more complex, move that code into its own class. passed code style checking (make lint) for user-facing api changes, api doc string has been updated. to my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change intersting edge cases to note here </desc> <cmt> different calls into omp class </cmt> <cmt> copy from 'tuner' branch </cmt>",move openmp calculations into its own class
2741,<desc> matrix keymap renamed to layout added layout_ortho_3x11 matrix aliased as layout_all keymaps refactored to use #include qmk_keyboard_h and matrix macros added info.json file fix formatting in readme.md </desc> <cmt> matrix refactor </cmt> <cmt> keymap refactor </cmt> <cmt> configurator support </cmt> <cmt> readme formatting update </cmt>,miuni32 refactor and configurator support
2742,"<desc> corrects expected answers in tests and test descriptions replaces sample solution with solution giving correct answers corrects small typo with missing space changes were tested on the local fork more information about problem can be found on the issue page, which this pull request can close. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #40055 </desc> <cmt> fix: correct answers in tests and descriptions </cmt> <cmt> fix: replace sample solution for correct one </cmt> <cmt> fix: missing space </cmt> <iss> rosetta code: knight's tour tests likely don't output correct values </iss>",correct rosetta code knight's tour solution
2743,"<desc> what is this about? this pr tweaks the code that checks keys to be ignored during shortcut remaps to be more generic. rather than ignoring the few problematic codes as issues are created (so far 0xf0, 0xf1, 0xf2, 0xf3), the pr ignores any key codes mentioned as unassigned, reserved, undefined or oem-specific on the official docs at  pr checklist applies to #6951 cla signed. if not, go over here and sign the cla tests passed validation steps performed how does someone test & validate? validate that shortcut to shortcut remappings work on en-us validate on japanese language that even after pressing shift+caps, alt+caps, ctrl+caps or alt+ the shortcut remaps still work. </desc> <cmt> updated list of key codes to be ignored </cmt> <cmt> added comments </cmt>",avoid checking reserved/unassigned/oem-specific/undefined key codes during shortcut remaps
2744,"<desc> @bpasero could you check out the changes in the accessibility services, or hand over to relevant person? i want to make sure i'm not going against the design by including the settings check in the accessibilityservice. not merging just yet, still getting feedback on the solution from accessibility team. fixes #76050 </desc> <cmt> xterm@3.15.0-beta70 </cmt> <cmt> diff: </cmt> <cmt> changes: </cmt> <cmt> - parser sub-parameters/colon notation </cmt> <cmt> - webgl simplify atlas/fix npe </cmt> <cmt> - move sound into browser </cmt> <cmt> - fix keyup event (related #76050) </cmt> <cmt> add commands for terminal navigation mode </cmt> <cmt> part of #76050 </cmt> <cmt> add commands for terminal navigation mode </cmt> <iss> add accesibility mode only keybindings to navigate up and down rows in the terminal </iss>","add a accessibility mode context key and a terminal ""line navigation mode"" and keybindings"
2745,"<desc> the v1 console doesn't know anything about ""default foreground"" or ""default background"" colors. so when the v1 console starts up, it leaves those members of the console_state_info zero'd. however, both the v1 and v2 console's share the same console.dll, the propsheet. when the user unchecks the ""use legacy settings"" checkbox and saves the settings, the propsheet tries to save the v2 settings that are totally inaccessible to the ""v1"" propsheet, and were zero'd to match the state of the console. this change makes is so that the propsheet only saves the ""terminal"" settings when the propsheet was launched from a v2 console. closes #2319 i work here this pr fixes the bug for both loading the settings from the registry and loading from the shortcut. copied my modified console.dll into system32. opened a v2 conhost from win+r, cmd (using the registry settings) opened the propsheet, confirmed it had a default fg/bg. used the propsheet to switch to legacy mode opened a v1 conhost with win+r opened the propsheet, confirmed there was no ""terminal"" propsheet unchecked the ""legacy"" checkbox opened a new win+r conhost it re-opened with the original default colors and then repeat steps 2-9 using the win+x, c conhost, which uses a shortcut instead of the registry. </desc> <cmt> this fixes the registry path </cmt> <cmt> what's happening is the console is writing the forcev2 setting, then the v1 </cmt> <cmt> console is ignoring those settings, then when you check the checkbox to save </cmt> <cmt> the v2 settings, we'll write the zeros out. that's obviously bad. so we'll </cmt> <cmt> only write the v2 settings back to the registry if the propsheet was launched </cmt> <cmt> from a v2 console. </cmt> <cmt> this does not fix the shortcut path. that'll be the next commit. </cmt> <cmt> fix the shortcut loading too </cmt> <cmt> fixes #2319 </cmt> <iss> toggling legacy console on and off enables terminal colors but sets them to all black </iss>","prevent the v1 propsheet from zeroing colors, causing black text on black background."
2746,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues #1202 new feature or improvement describe the details and related test reports. determine the log is enabled for the debug level before printing message. make the columns initialize to be static attribute. topology build optimize: cache query result to avoid repeating queries. add elasticsearch batch process setting into application.yml. use xcontentfactory to build source to insert into elasticsearch. </desc> <cmt> #1202 </cmt> <cmt> 1. determine the log is enabled for the debug level before printing message. </cmt> <cmt> 2. make the columns initialize to be static attribute. </cmt> <cmt> 3. topology build optimize: cache query result to avoid repeating queries. </cmt> <cmt> #1202 </cmt> <cmt> add elasticsearch batch process setting into application.yml. </cmt> <cmt> #1202 </cmt> <cmt> fixed check style error. </cmt> <cmt> #1202 </cmt> <cmt> use xcontentfactory to build source to insert into elasticsearch. </cmt>,"topology query tuning, batch process instead of bulk."
2747,"<desc> these two share a constructor signature, so they can share an aggregator supplier.  given that, it made sense to do them both in one pr. </desc> <cmt> wire up max aggregator </cmt> <cmt> wire up min aggregation </cmt>",wire up max & min aggregations
2748,"<desc> this is a part of #7179. i am merging it separately for the ease of backporting, so that the other pr contains only the bug fix. short description (up to few sentences): optimize some header files for faster rebuilds. </desc> <cmt> do not include field.h everywhere through settingscommon.h. </cmt> <cmt> move the methods of settingscollection<> that are dependent on field to </cmt> <cmt> a separate file, and include it once for each instantiation. this allows </cmt> <cmt> to work on field without always recompiling the entire project. </cmt> <cmt> include fieldvisitors.h in less files. </cmt>",include field.h and fieldvisitor.h into fewer files.
2749,"<desc> same as #27712, but generated automatically with the release_open_source.py script. let's double check the prs are identical before merging one of them. </desc> <cmt> update third_party/protobuf </cmt> <cmt> run tools/distrib/python/make_grpcio_tools.py </cmt> <cmt> regenerate protos for csharp, ruby, php </cmt> <cmt> update build_handwritten.yaml </cmt> <cmt> update protobuf-c++.podspec </cmt> <cmt> regenerate projects </cmt>",upgrade protobuf to 3.18.1 (automatically generated)
2750,"<desc> change panelalert to accept margin sizes rangeslider - allowedvalues + add tests refactor module paths of common ""styles"", and form ""controls"" storybook cleanup </desc> <cmt> refactor module paths of common ""styles"", and form ""controls"" </cmt> <cmt> rangeslider - allowedvalues + add tests </cmt> <cmt> change panelalert to accept margin sizes </cmt>",change rangeslider to have allowedvalues + cleanup
2751,"<desc> pep 8 compliance cleanups for python.d modules with names starting with p and r. relevant: #4167 postgresql module is handled separately in #4298. </desc> <cmt> python.d/phpfph.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals. </cmt> <cmt> python.d/portcheck.chart.py pep 8 cleanup </cmt> <cmt> fixed string quoting and container literal formatting. </cmt> <cmt> python.d/postfix.chart.py pep 8 cleanup </cmt> <cmt> fixed string quoting and container literal formatting. </cmt> <cmt> python.d/powerdns.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals. </cmt> <cmt> python.d/puppet.chart.py pep 8 cleanup </cmt> <cmt> fixed string quotation, use of blank lines, and formatting of block </cmt> <cmt> comments. </cmt> <cmt> python.d/rabbitmq.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals. </cmt> <cmt> also fixes a misplaced space (located after a quotation mark instead of </cmt> <cmt> before). </cmt> <cmt> python.d/redis.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals and quoting of string literals. </cmt> <cmt> python.d/rethinkdb.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals. </cmt> <cmt> python.d/retroshare.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of container literals. </cmt>","python.d pep 8 cleanup, modules p-r"
2752,<desc> currently this is windows only as i don't know how to do the equivalent on macos (i don't think it is actually needed). basically most people use squirrel.windows to install electron applications on windows.  when a user updates the app the stored default path is now wrong and instead of having to update the path during the update process it would be great if we could use the squirrel --processstart syntax as our launcher. if someone can point me at the direction to do this on macos would be much appreciated </desc> <cmt> allow client to specify exe file and args to set as default handler </cmt> <cmt> * optional path param to setasdefaultprotocolclient </cmt> <cmt> * optional args param to setasdefaultprotocolclient </cmt> <cmt> document the optional params </cmt> <cmt> clarify defaults </cmt>,allow settings of launch args when using defaultprotocol
2753,"<desc> this pr adds support for specifying a box shadow color using a composable api: <div class=""shadow-xl shadow-blue-500/20""> the motivation for this is to make it possible to tint your shadows to look better on colored backgrounds, which is a design principle that @joshwcomeau outlines beautifully in this blog post:  here you can see the default black-based shadow on the left, and a tinted shadow on the right: the difference is kind of subtle but the tinted ones look more natural when you get the values right. the composable api is very flexible (almost too flexible really), so this is sort of an advanced feature that non-designers might not have an easy time getting great results with. i hope to provide some guidance around how to approach using these apis in the documentation for v3 when it's released. under the hood, all colors in a shadow are replaced by the color you specify. for example, given this shadow in your config: boxshadow: { // ... fancy: '0 1px 3px rgba(24, 53, 76, 0.11), 0 2px 9px rgba(11, 22, 99, 0.42)' } ...if you write the following html: <div class=""shadow-fancy shadow-blue-500""> ...the final rendered box shadow will be this: box-shadow: 0 1px 3px #3b82f6, 0 2px 9px #3b82f6 notice that even though in the original shadow the two separate shadow layers had separate colors, in the final shadow both layers are the exact same color. this is the only practical approach i felt was reasonable after attempting to approach this feature from scratch like 12 times. this is a little weird because the default tailwind shadow use different alpha values for the shadow layers. for this reason, this pr also tweaks the default shadows to use the same alpha value for each layer. by doing this, when you specify a shadow color the colored shadow will have the same transparency and blending characteristics as the default shadow. we've tried to make the new shadows as visually identical to the old ones as possible, which you can preview in this play:  it's also worth noting that if you change a shadow at a different breakpoint, it will override any custom color. <!-- this shadow will not be red at md screens and above --> <div class=""shadow-lg shadow-red-500 md:shadow-xl""> to preserve the color, it needs to be respecified: <!-- this shadow will be red at md screens and above --> <div class=""shadow-lg shadow-red-500 md:shadow-xl md:shadow-red-500""> this is the only way we could make it possible to switch from a color back to the default shadow color at a different breakpoint. in the future we may come up with a terser syntax (like shadow-xl/red-500) to make this feel less annoying, but in practice i don't expect this to be a huge pain point anyways. all of the colors are available as shadow colors by default, and if you need to customize them separately you can do so under the boxshadowcolor key in your config. </desc> <cmt> wip </cmt> <cmt> add box shadow parser </cmt> <cmt> use box shadow parser </cmt> <cmt> update default shadows, add boxshadowcolor key, add shadow datatype </cmt> <cmt> update tests </cmt>",add support for colored box shadows
2754,<desc> description: this pr adds a new command to the zha web socket api to enable retrieving a single device by its ieee address. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> get single device web socket command </cmt> <cmt> test get single device </cmt>,add web socket api command to get a single zha device
2755,<desc> this is the example code for bael-963 by smatt382@gmail.com </desc> <cmt> added updated example codes </cmt> <cmt> fixed local conflict </cmt> <cmt> updated example code stringtocharstream </cmt> <cmt> deleted stringtocharstream.java locally </cmt> <cmt> merged pr locally </cmt> <cmt> removed redundant file </cmt> <cmt> added code for apache commons collection setutils </cmt> <cmt> updated local repo with upstream </cmt> <cmt> refactored example code </cmt> <cmt> added files for bidimapunittest </cmt>,code snippet for bidimap bael-963
2756,"<desc> this change adds the ability to attach annotative information for classes, methods, fields, static methods, class bindings, and instance bindings during painless whitelisting. annotations are specified as @annotation or optionally as @annotation[some info]. annotations open up the ability to specify whitelist objects as having a short name (no_import -> @no_import) or deprecated. </desc> <cmt> start to parse annotations in the whitelist </cmt> <cmt> finish parsing annotations </cmt> <cmt> finish annotation parsing </cmt> <cmt> add docs </cmt>",add annotations to painless whitelist
2757,"<desc> following the discussion at #11049 running the testsparsepartialflatten test would occasionally raise the following error: error: testsparsepartialflatten (__main__.partialflattentest) test _inner_flatten on sparsetensors. ---------------------------------------------------------------------- traceback (most recent call last): file ""/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/bin/bazel_pip/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/layers/python/layers/layers_test.py"", line 1434, in testsparsepartialflatten expected_indices, expected_values, _ = _sparsify(reshaped_random_) file ""/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/bin/bazel_pip/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/layers/python/layers/layers_test.py"", line 1399, in _sparsify values = array[non_zero] indexerror: index 3 is out of bounds for axis 1 with size 3 this seems to be due to inconsistent behaviour from numpy.nonzero when operating on an array of over 4 dimensions. reducing the size of the array in the test seems to eliminate the problem. note: as the problem would only arise in some test runs, and not others. it's important that this commit be tested several times to ensure elimination of the issue. </desc> <cmt> variable name change and documentation clarification </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> updated a test to eliminate an error it raises </cmt>",fix for contrib.layers test that was raising an indexerror
2758,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: beforeeach and usecavy increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add beforeeach and usecavy function types to cavy </cmt> <cmt> linting and version update </cmt>",update cavy types for beforeeach and usecavy functions
2759,<desc> dagre.graph has a method setextent. there was the (optional) option field missing. dagre-d3 had no exported module so there were problems with systemjs and atom's typescript package. </desc> <cmt> added the options field to dagre's setedge </cmt> <cmt> * added a test as well </cmt> <cmt> * changed some style issues according to linter (var -> let) </cmt> <cmt> exported dagre-d3 so it is possible to import it with systemjs </cmt> <cmt> * atom's typescript package now accepts the import </cmt> <cmt> * changed some style issues according to linter (var -> let) </cmt>,fixed dagre-d3 and extended dagre
2760,"<desc> the following ui lays out differently in react-native-windows than on android/ios.  this difference is due to android/ios configuring yoga to ""uselegacystretchbehaviour"". this change aligns the yoga config of react-native-windows to match the other platforms.  -- however, i also added a property to the propertybag that can be added to restore the previous behavior.  this should allow apps to keep the current behavior until they can fix any issues with moving to the same layout config as the other platforms. <view style={{ flex: 1, }}> <view style={{ flexdirection: 'row', alignitems: 'center', }}> <view style={{ flexdirection: 'row', alignitems: 'center', // flex: 1, // rnw requires this or the two boxes will be flush together, not flush to left/right edges of screen }}> <view style={{ height: itemsize, width: itemsize, backgroundcolor: 'red', }} /> <view style={{ flex: 1, backgroundcolor: 'red', }} /> <view style={{ height: itemsize, width: itemsize, backgroundcolor: 'red', }} /> </view> </view> </view> microsoft reviewers: open in codeflow </desc> <cmt> use yoga config to align with ios/android </cmt> <cmt> change files </cmt> <cmt> formatting </cmt>",fix difference in layout algorithm between windows and other platforms
2761,"<desc> here is the new rule for handling nulls: in the interface store, put(key, null) are handled normally and value serde applied to null. in the inner most store, null bytes after serialization will always be treated as deletes. in the interface store, if null bytes get returned in get(key), serde will be avoided and null object will be returned. more changes: update javadocs, add unit tests accordingly; augment mockcontext to set serdes for the newly added tests. fixed a discovered bug which is exposed by the newly added tests. use the new api to remove all old apis in the existing state store tests. remove serializedkeyvalueiterator since it is not used any more. this is originally contributed by @evis. </desc> <cmt> kafka-4750: rocksdbstore always deletes null values </cmt> <cmt> deletion occurs even if serde serializes null value </cmt> <cmt> to non-null byte array. </cmt> <cmt> checkstyle fix </cmt> <cmt> review changes suggested by @mjsax </cmt> <cmt> use new object to take appid </cmt> <cmt> add more logging </cmt> <cmt> rebase from trunk </cmt> <cmt> capture timeout exception inside condition </cmt> <cmt> avoid serde for null everywhere </cmt> <cmt> add unit tests </cmt>",bypass null value and treat it as deletes
2762,<desc> add a new field sts_service into googlegrpc call credential options which support envoy to exchange token. see grpc/grpc#19032 and grpc/grpc#19587. risk level: low testing: unit test </desc> <cmt> support fetching grpc call credential via sts </cmt> <cmt> support fetching grpc call credential via sts </cmt> <cmt> support fetching grpc call credential via sts </cmt> <cmt> format </cmt>,use grpc security token service (sts) to get call credentials
2763,<desc> remove builds which are not used. install estimator and tensorboard at their latest </desc> <cmt> pin estimator and tensorboard in common.sh instead of in build files </cmt> <cmt> remove builds which are not needed for the release </cmt> <cmt> remove py2 macos scripts </cmt> <cmt> cleanup macos builds </cmt> <cmt> cleanup the windows builds </cmt>,third attempt at fixing the release builds
2764,"<desc> trajectory view api prep pr for switching on by default across all rllib; plumbing only (new methods (not used yet), etc..). some cleanup and minor fixes. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip. </cmt>",trajectory view api (prep pr for switching on by default across all rllib; plumbing only)
2765,<desc> a number of our test cases are configured with multiple producers. add 1 producer runs for these existing tests. select one: select any that apply: </desc> <cmt> add 1 producer version of some of the multi-producer tests </cmt> <cmt> test assumes that node[0] is available so add one to total nodes to allow test to be run with 1 producer </cmt>,add 1 producer version of some of the multi-producer tests - 2.2.x
2766,"<desc> this pr contains a bunch of changes that are all nfc that i was able to split off from the larger commit that updates pmopt for ownership. this will enable us to separate the adding/validation of new functionality from the necessary refactoring which will ease committing this into tree. rdar://31521023 </desc> <cmt> [pred-memopt] add convenience begin/end borrow operation on silbuilder. </cmt> <cmt> these apis make it easy to create borrow/end_borrow operations in a pass that </cmt> <cmt> has to handle both ownership and non-ownership sil. </cmt> <cmt> rdar://31521023 </cmt> <cmt> [pred-memopt] reorganize file slightly to ease review of further changes. </cmt> <cmt> rdar://31521023 </cmt> <cmt> [pmopt] rename extractsubelement => nondestructivelyextractsubelement. </cmt> <cmt> in non-ownership sil, pmopt did not need to distinguish in between destructive </cmt> <cmt> and non-destructive sub element extraction. this allowed pmopt to just use the </cmt> <cmt> ""non-destructive"" sub element (i.e. extractsubelement) everywhere. in </cmt> <cmt> preparation for introducing this distinction (and a destructive sub element </cmt> <cmt> extractor), rename extractsubelement to be nondestructivelyextractsubelement for </cmt> <cmt> clarity. </cmt> <cmt> nfc. </cmt> <cmt> rdar://31521023 </cmt> <cmt> [pmopt] extract out a helper function from promoteload to make the method flow better when read. </cmt> <cmt> nfc. </cmt> <cmt> rdar://31521023 </cmt> <cmt> [pmopt] restructure aggregateavailablevalues as a class. </cmt> <cmt> this is in preparation for adding the distinction of destructive vs </cmt> <cmt> non-destructive extracts. </cmt> <cmt> nfc. </cmt> <cmt> rdar://31521023 </cmt> <cmt> [pmopt] add some more tests around geps. </cmt> <cmt> this is to ensure that when i add the destructive code when ownership is </cmt> <cmt> enabled, the non-ownership variant doesn't break. i have to move the rest of the </cmt> <cmt> pipeline to -onone at the same time. once that is done, i will remove more code. </cmt> <cmt> nfc. </cmt> <cmt> rdar://31521023 </cmt>",pmopt refactoring before big changes
2767,"<desc> 1.fix the bug that publishmetadata cmd does not work 2.delay scheduling should be used instead of scheduled scheduling 3.the delay unit should be seconds, not milliseconds </desc> <cmt> fix the bug that publishmetadata cmd does not work </cmt> <cmt> adjust the delay schedule and time unit </cmt> <cmt> 1.delay scheduling should be used instead of scheduled scheduling </cmt> <cmt> 2.the delay unit should be seconds, not milliseconds </cmt>",fix some bugs in publishmetadata command
2768,"<desc> remove new block id notify feature as it doesn't actually improve performance and actually causes issues with large # of connections. since this was the only new net protocol feature added in 2.0, the net protocol version has been reverted to 1.8 .. 1.0 version. do not send blocks when syncing with peer. fix first sync asking for less than lib. </desc> <cmt> remove new block id notify feature as it actually degrades performance rather than improve it. </cmt> <cmt> do not broadcast block if syncing with peer </cmt> <cmt> syncing can start without an updated sync_next_expected_num, so make sure it is at least lib </cmt> <cmt> always send a handshake on unlinkable block </cmt>",remove new block id notify feature - develop
2769,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. the tslint.json is explicitly modified to disable interface naming rules. the reason for this is that angularjs typings follow the pattern listed here. regarding documentation on the actual types, see:      also try some sample code: s = document.createelement('script'); s.src = "" i = angular.injector(); i.loadnewmodules(['ngaria']); aria = i.get('$aria'); console.log(aria); console.log(aria.config('tabindex')); console.log(aria.config('ariainvalid')); paste into  / </desc> <cmt> add definition for angularjs $aria service. </cmt> <cmt> add basic test for $aria config() method. </cmt> <cmt> add dependency on dom typings </cmt> <cmt> get angular-aria types linting correctly </cmt>",add types for angularjs $aria service
2770,<desc> 054e091 (gh 1697) 5a346d5 (gh 1714) eca7da0 (gh 1838) </desc> <cmt> bpo-30290: idle: add more tests for help_about dialog (#1697) </cmt> <cmt> increases coverage to 99% </cmt> <cmt> (cherry picked from commit 054e09147aaa6f61aca6cd40c7bf7ce6dc54a04b) </cmt> <cmt> bpo-30290: idle: refactor help_about to pep8 names (#1714) </cmt> <cmt> patch by cheryl sabella. </cmt> <cmt> (cherry picked from commit 5a346d5dbc1f0f70eca706a8ba19f7645bf17837) </cmt> <cmt> idle test_help_about: edit and add test. (#1838) </cmt> <cmt> coverage is now 100% </cmt> <cmt> (cherry picked from commit eca7da0f13c78013b924fe7306f3e2e59c0af40b) </cmt>,idle - pep8 names and tests for help-about
2771,"<desc> we fixed some edge cases for chararraystest#testconstanttimeequals() in 7.x and master. this pr brings those fixes to 6.8 in order to avoid some occasional test failures. original fixes: #47238 and #47346 closes #47076 </desc> <cmt> ensure char array test uses different values (#47238) </cmt> <cmt> the test of constanttimeequals could get unlucky and randomly produce </cmt> <cmt> the same two strings. this commit tweaks the test to ensure the two </cmt> <cmt> string are unique, and the loop inside constanttimeequals is actually </cmt> <cmt> executed (which requires the strings be of the same length). </cmt> <cmt> fixes #47076 </cmt> <cmt> fix chararraystests.testconstanttimeequals() (#47346) </cmt> <cmt> the change #47238 fixed a first issue (#47076) but introduced </cmt> <cmt> another one that can be reproduced using: </cmt> <cmt> org.elasticsearch.common.chararraystests > testconstanttimeequals failed </cmt> <cmt> java.lang.stringindexoutofboundsexception: string index out of range: 1 </cmt> <cmt> at __randomizedtesting.seedinfo.seed([dfca64fe2c786be3:ed987e883715c63b]:0) </cmt> <cmt> at java.lang.string.substring(string.java:1963) </cmt> <cmt> at org.elasticsearch.common.chararraystests.testconstanttimeequals(chararraystests.java:74) </cmt> <cmt> reproduce with: ./gradlew ':libs:elasticsearch-core:test' --tests </cmt> <cmt> ""org.elasticsearch.common.chararraystests.testconstanttimeequals"" </cmt> <cmt> -dtests.seed=dfca64fe2c786be3 -dtests.security.manager=true -dtests.locale=fr-ca </cmt> <cmt> -dtests.timezone=pacific/johnston -dcompiler.java=12 -druntime.java=8 </cmt> <cmt> that happens when the first randomized string has a length of 0. </cmt>",backport some fixes to chararraystest#testconstanttimeequals()
2772,"<desc> cherry-picks the fixes that resolved the following: rdar://82053644 rdar://60543202 rdar://68225196 rdar://79412011 rdar://76254761 rdar://78889410 </desc> <cmt> fix typo and spelling in asynciteratorprotocol. </cmt> <cmt> fixes rdar://78889410 </cmt> <cmt> (cherry picked from commit f1d87de1506b59ee93c9a7721165aee3a05efbd2) </cmt> <cmt> correct parameter names in doc comments. </cmt> <cmt> fixes rdar://76254761. </cmt> <cmt> (cherry picked from commit 36832a8d47c2e9f93ac29aefca8fc19eac4cce71) </cmt> <cmt> remove duplicate doc comment & clean up. </cmt> <cmt> fixes rdar://79412011 </cmt> <cmt> (cherry picked from commit 8ca0e30b05af1f8d653390a70a69f5179cc0f786) </cmt> <cmt> also fix parameter name in parameter docs. </cmt> <cmt> follow-on to commit 36832a8d47c. </cmt> <cmt> (cherry picked from commit 4c82b7705c6fd785d79c6c3ea6bd721daab785d8) </cmt> <cmt> hyphenate a two-word modifier. </cmt> <cmt> fixes rdar://68225196 </cmt> <cmt> (cherry picked from commit 00e18a2005514153de33f1e7da411fcfe796e598) </cmt> <cmt> call out the behavior for empty sequences. </cmt> <cmt> fixes rdar://60543202 </cmt> <cmt> (cherry picked from commit d0d4a88823317c4df8dc4e9b3b77d8720366e266) </cmt> <cmt> remove invalid markup. </cmt> <cmt> fixes <rdar://82053644>. </cmt> <cmt> (cherry picked from commit e48de1acda017df56565843db402b6cc73f0f0e3) </cmt> <cmt> revert ""remove duplicate doc comment & clean up."" </cmt> <cmt> let the later changes in stdlib/public/concurrency/task.swift win, since </cmt> <cmt> they contain and supersede this minor fix anyhow, instead of creating a </cmt> <cmt> merge conflict with 'main'. </cmt> <cmt> this reverts commit 1d63a5d94ad71b0a0bcde7da29ba43e9c1612121. </cmt>",cherry pick documentation fixes to 'main'
2773,"<desc> i ran into both of these issues this week trying to release v1.3.0-alpha.3: /build/push-official-release.sh requires being logged in as k8s.production.user, but it only checked if that user was in the list of credentialed accounts. now that we build approximately everything under the sun, my /tmp didn't have enough space; i needed to override it to use a different directory, hence tmpdir. </desc> <cmt> build/push-official-release.sh checks if proper account is active, not just present </cmt> <cmt> release scripts respect tmpdir </cmt>",proper account checking and respect tmpdir in release process
2774,"<desc> i hereby agree to the terms of the cla available at:  support for replicas in mysql/postgresql table engine / table function. added wrapper storage over mysql / postgresql storages to allow shards. closes #20969. </desc> <cmt> use pool with failover in mysql storage </cmt> <cmt> support shards </cmt> <cmt> make common class for external storages </cmt> <cmt> replicas/shards for postgres storage </cmt> <cmt> add namespace, simplify names </cmt> <cmt> better comments </cmt> <cmt> add proper settings </cmt> <iss> allow replicas in mysql engine </iss>",replicas and shards for mysql and postgres storages
2775,"<desc> @rocketchat/core closes #9766 this pr adds a new setting where the admin can choose what action to perfom with the user's messages when an user is removed. the possible options are: keep (don't remove any message), delete (removes all messages) and unlink (change the userid of all messages to the rocket.cat user). </desc> <cmt> right to be forgotten </cmt> <cmt> changed default action to delete </cmt>",gdpr right to be forgotten/erased
2776,"<desc> #5379 i tidied up the query error. if anyone can review and give me feedback on this, i'd appreciate it. it's my first open-source pull request, so please let me know if i'm doing anything wrong. thanks. </desc> <cmt> tidy up the query-runner error log </cmt>",improve formatting query runner error
2777,"<desc> @mihaimaruseac this pr refactors gcs to use the core implementation. the change is: get various envs use ram_file_block_cache tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc line 826 in 2629e4f file_block_cache_ = makefileblockcache(block_size_, max_bytes, max_staleness); this variable can be controlled by env so i drop it tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc line 788 in 2629e4f gcsfilesystem::gcsfilesystem(bool make_default_cache) { merge 2 randomaccessfile into one. tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc line 261 in 2629e4f class gcsrandomaccessfile : public randomaccessfile { and tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc line 289 in 2629e4f class bufferedgcsrandomaccessfile : public randomaccessfile { i am missing this part tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc lines 991 to 1003 in 2629e4f tf_shared_lock l(block_cache_lock_); gcsfilestat stat; tf_return_if_error(stat_cache_->lookuporcompute( fname, &stat, return uncachedstatforobject(fname, bucket, object, stat); })); if (!file_block_cache_->validateandupdatefilesignature( fname, stat.generation_number)) { vlog(1) << ""file signature has been changed. refreshing the cache. path: "" << fname; } will be added in later pr. </desc> <cmt> refactor tf_gcs_filesystem init </cmt> <cmt> refactor newrandomaccessfile </cmt>",refactor gcs part 1 random access file
2778,"<desc> hotthreads report type field is currently declared as a string, but internally it is used as an enum. this pr changes the report type to enum and does a small refactor to encapsulate the getter function with the accumulator class. i also extended the hotthreads unit tests to test some of the newly refactored code. note: this change introduces slight behaviour difference. previously when the hotthreads api was called with an incorrect report type, e.g. /_nodes/hot_threads?type=gpu we'd crash with invalidargumentexception, but after argument validation, therefore producing an empty 400 response. after this change we get a 400 with response: ""reason"": ""type not supported [gpu]"" </desc> <cmt> switch hotthreads request type to enum </cmt> <cmt> hotthreads report request type was declared as string, but used as an </cmt> <cmt> enum where only few values were allowed. this pr changes the type to </cmt> <cmt> enum allowing malformed requests to correctly report the error. </cmt> <cmt> this pr also introduces a small refactor to make the report getter </cmt> <cmt> function part of the accumulator class. </cmt> <cmt> remove automatic variable inference from tests </cmt> <cmt> fix missed type to string conversion </cmt>",use enum field for hotthreads report type
2779,"<desc> support spring.cloud.nacos.discovery.enabled and spring.cloud.nacos.config.enabled fixes #411 </desc> <cmt> nacos discovery endpoint support spring.cloud.nacos.discovery.enabled ,  polish #411 </cmt> <cmt> support spring cloud nacos config enabled , polish #411 </cmt> <iss> i want to close nacos/discovery when execute tests, it has some exception </iss>",support switch nacos  discovery/config enabled
2780,<desc> move flutterview and related rpcs to the package:vm_service implementation. update some getisolate calls with catcherror to match previous behavior. updates tests that were previously mocking flutterviews to use real views moves the flutterview cache from vm to flutterdevice catch sentinelexception during isolate.kill #52179 maybe #55552 </desc> <cmt> migrate flutterview to vm_service </cmt> <cmt> remove commented out code </cmt>,migrate flutterview to new vm_service
2781,"<desc> check the arguments in calls to gpr_log and gpr_asprintf. the arguments should be consistent with the printf style format string arguments. gpr_strpad pads a string to a given length. this function is introduced for the field width flag is not defined as a standard for printf. the following use of gpr_log cannot pass the argument check. gpr_log(gpr_info, ""% 7s"", str); instead, gpr_strpad could be used to set the field width. char *tmp = gpr_strpad(str, ' ', 7); gpr_log(gpr_info, ""%s"", tmp); gpr_free(tmp); </desc> <cmt> add format check for gpr_log and gpr_asprintf </cmt> <cmt> restricted the check to gunc </cmt> <cmt> fix gpr_log format mismatches in c++ tests </cmt> <cmt> fix type mismatch for type_size </cmt> <cmt> regenerate build files </cmt> <cmt> fix zookeeper_test </cmt>","add format check for gpr_log and gpr_asprintf, add gpr_strpad"
2782,"<desc> fixes #74690 fixes #72708 part of #74861 </desc> <cmt> replace vscode-xterm with xterm </cmt> <cmt> fix merge conflict </cmt> <cmt> add new search addon and adopt </cmt> <cmt> fix gulp-tsb issue </cmt> <cmt> adopt xterm-addon-web-links </cmt> <iss> the cls command doesn't clear the terminal (windows 10 1903, conpty) </iss> <iss> should we move to official xterm and how to deal with problem of new addon peer dependencies </iss>",replace vscode-xterm with official xterm
2783,<desc> this fixes double free crashes on the cat and get commands on the mount shell and the ed command on windows (awb is an invalid file open mode) </desc> <cmt> update shell.c </cmt> <cmt> update file.c </cmt>,fix mount shell and ed commands
2784,"<desc> description: in #18946, i hooked up the existing zoneminder entities with the availability of zoneminder. it would be useful to have this information available to automations. the simplest approach appears to be creating a new binary sensor platform. this should be rebased and then merged after #20182. pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#8206 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> embed zoneminder platforms into component </cmt> <cmt> add a binary sensor for zoneminder availability </cmt>",add a zoneminder availability sensor
2785,"<desc> this is somewhat similar to #69727 except that in this case, the final pipeline is set directly on an existing index rather than in a template. the root cause of the issue was looking for the ingest pipelines on index metadata before resolving any date math expressions in the index name. fixes #75047 </desc> <cmt> move resolvercontext class to permit reuse </cmt> <cmt> resolve date math expressions before retrieving index metadata </cmt> <iss> final pipeline not executed for indexing requests which include date math expressions </iss>",resolve date math expressions before looking up index metadata
2786,"<desc> upgrade eslint to 3.x, along with all the config and plugins. eslint 2 is getting kinda crusty, and we're aiming for babel-preset-env & async+await. synchronizing with the latest babel config for a little more consistency. lots of linting. internal i have read the contributing document. </desc> <cmt> deps: upgrade eslint </cmt> <cmt> deps: upgrade eslint-config-babel </cmt> <cmt> deps: add eslint-plugin-flowtype </cmt> <cmt> deps: upgrade babel-eslint </cmt> <cmt> deps: upgrade eslint-plugin-babel </cmt> <cmt> deps: remove eslint-plugin-flow-vars </cmt> <cmt> test/helpers: remove assertstubbedcalls </cmt> <cmt> test/helpers: remove stub </cmt> <cmt> fix(lint): automatic fixes </cmt> <cmt> chore(lint): remove custom overrides </cmt> <cmt> fix(lint): manual fixes </cmt>","update eslint, config, and plugins"
2787,"<desc> we always intended to ban inout varargs we can't support it seems, so ban them right away resolves rdar://85442872 </desc> <cmt> [distributed] ban inout, varargs from dist funcs </cmt> <cmt> [distributed] more descriptive kind usage for error messages </cmt>",more restrictions on distributed funcs based on serialization findings
2788,"<desc> what we already have... we already have optional 'lang' values for posts, e.g.: title: test english post lang: en --- # my first english post you can create them with hexo new ""test english post"" --lang en this will create a post in source/_posts/en/test-english-post.md what i missed and is in this pull request the page.lang can be referenced in the template - but only if it is specified in a post or page. if not the value is undefined. more than one language for i18n.__ i use the config.languages value to specify more than one language - to be exactly, all the languages my blog use: old (and still working) version: config.language = de new version (language can be an array): config.language - de - en the first language will be the default language, the i18n module will load all languages (and default.yml) as you can verify with __.languages in you theme. there is no need to specify a config.language, if you omit it, there will be no difference to hexo's default behavior! add an optional language parameter to __ the biggest problem was, that with the use of __ in your theme, you could only get a translation to the actual configured language (default.yml or config.language). i preserve this functionality for backward compatibility, but now you can add an optional parameter to the function call: __('code', 'language'), where language may be one of the configured languages in config.language (array or string) or default.yml. so now this works: themes/your-theme/languages/de.yml hello: hallo welt themes/your-theme/languages/en.yml hello: hello world __('hello', 'de')  => ""hallo welt"" __('hello', 'en')  => ""hello world"" __('hello') => ""hallo welt"" with config.languages - de - en with no config.languages default behavior, return code when no language file available __('hello') => 'hello' or use default.yml as fallback - 'foo' is no key in de.yml nor en.yml themes/your-theme/languages/default.yml foo: bar __('foo') => 'bar' __('foo', 'de') => 'foo' ensure a lang key with usefull values in page i added an ensurelanguage function to lib/theme/index.js to always have a lang key in the page object. additional there are two new configuration values, both boolean: config.language_detect_in_path (default, not defined, so false) config.language_detect_first_level (default, not defined, so false) the behavior is as follows: if a post or a page sets the lang value, use this (so, we can always override it in posts or pages) - this is like the actual hexo default bevavior new: 2) if no page.lang is defined, default it to config.language (if it is a single value) or the first language of the config.language array if config.language_detect_in_path is defined, the function will try to detect a language string configured in config.language in the actual page.path. e.g. : config.language - de - en path: /en/contact/index.html look for /en/ => found => page.lang = 'en' path: /my/blog/en/contect.html look for /en/ => found => page.lang = 'en' path: /de/ look for /de/ => found => page.lang = 'de' path: / look for /de/ => not found look for /en/ => not found default was config.language[0] => page.lang = 'de' this will even work for: path: /contact/ => page.lang = 'de' now you can guess how config.language_detect_first_level will alter the lookup: path: /en/contact ^/en/ => found => page.lang = 'en' path: /my/blog/en/contact config.language_detect_first_level = true ^/en/ => not found, ""first level"" is here /my/ => page.lang = 'de' (because it's config.language[0]) when you set config.language_detect_first_level to true it will only search the first level string (bevor the second /, with the first / as root). this is for the paranoid people, which may have posts, pages, tag, directories, and so on with the same name as their configured languages. but then you must set :lang as the first value of your config.permalink (but this ist even a recommendation for google). if no lang can be detected - not set in post or page, not in config, not in path - it will be filled with the default value default (to be compatible with default.yml) so... there will always be a page.lang available in themes what can we do with this? _config.yml: language: - de - en language_detect_in_path: true language_detect_first_level: true permalink_defaults: lang: de new_post_name: :lang/:title.md permalink: /:lang/:title/ have a blog with / or /de/ (optional) as the german version and /en/ as the english version. remember my last pull request for helper functions in hexo's list functions? use this: themes/your-theme/scripts/ extend.js hexo.extend.helper.register('category_transform', function(helper, lang) { console.log(lang); var f = function(s) { return helper('category_'+s, lang); }; return f; }); <div class=""sidebox widget""> <h3>{{__('categories', page.lang)}}</h3> {{ list_categories({ show_count: false, style: ""list"", class: ""category"", transform: category_transform(__, page.lang) }) }} </div> results /de/hallo-welt/ (or even) /impressum/ kategorien - it-sicherheit - deutsch /en/hello-world/ (or any other page under /en) categories - it-security - english the next step to a fully multi-lingual site in hexo. if it's ready, i'll write a full blog post and wiki page. </desc> <cmt> select language in __ with second parameter </cmt> <cmt> ensure 'lang' in page </cmt>",'lang' for every 'page' - next step to multilanguage sites
2789,"<desc> still to do is serializing the condition part of @supports, which currently lacks a spec. also our media-query serialization is not to spec either because i hadn't found the spec when i wrote it before.  that's a later-me problem. </desc> <cmt> libweb: move media-query-list serialization code to mediaquery.{h,cpp} </cmt> <cmt> it's not a complicated algorithm, but having it in one place instead of </cmt> <cmt> 2, and with spec comments, is nice. :^) </cmt> <cmt> libweb: add serialization code for css{media,supports}rule </cmt> <cmt> the cssmediarule::serialized() code is to spec. the </cmt> <cmt> csssupportsrule::serialized() code has no spec right now, but i'm </cmt> <cmt> fairly confident it will be almost identical to media's, so i copied </cmt> <cmt> that for now. </cmt> <cmt> libweb: implement cssstylerule::set_selector_text() </cmt>",serialize @media and @supports rules
2790,<desc> fixes #11721.  it also adds some unit test coverage for the remaining functions in stringutils. </desc> <cmt> added unit tests for stringutils generaterandomalphaonlystring and generaterandomasciistring </cmt> <cmt> fixes #11721  removed generaterandomstring </cmt> <cmt> gofmt </cmt> <iss> pkg/stringutils - remove randomstring function </iss>,fixes 11721 replace stringutils.generaterandomstring with stringid.generaterandomid
2791,"<desc> add support for disable_exception_catching and exception_catching_whitelist options for wasm. this patch generates invoke wrappers (functions like invoke_vi, which uses js try/catch to simulate exception behaviors) in wasm. also this enables all exception-related tests for wasm too. all of exception-related test cases are supposed to pass. and the exception whitelist tests should pass once #4471 and #4488 are resolved. the following prs or revisions are related to the exception handling for wasm: webassembly/binaryen#664 </desc> <cmt> exception handling support </cmt> <cmt> more </cmt>",implement asm.js style exception handling for wasm
2792,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. not changing an existing definition: not removing a declaration: </desc> <cmt> types for tabulator </cmt> <cmt> fixing tests </cmt>","new types for the ""tabulator"" npm package"
2793,"<desc> aws glue table has a key called storagedescriptor. this key is nullable on aws, but not on redash. therefore, if tables without storagedescriptor exist in glue, some schema refreshes will fail. as a solution, skip retrying tables with no storagedescriptor. </desc> <cmt> skip tables with no storagedescriptor </cmt> <cmt> add test_no_storage_descriptor_table </cmt>",skip tables with no storage descriptor
2794,"<desc> cherry-picks changes in #13835 which fix the playground transform and the pc macro so that they correctly instrument defer statements. (previously, both ignored defer entirely.) resolves sr-5641 / <rdar://problem/33764082>. </desc> <cmt> [playgroundtransform] implemented support for defer statements. </cmt> <cmt> added handling of defer statements in the playground transform. </cmt> <cmt> tests will be added in a follow-on commit. </cmt> <cmt> patch by roman levenstein! </cmt> <cmt> this addresses sr-5641/<rdar://problem/33764082>. </cmt> <cmt> (cherry picked from commit 0a9a4e7d6f267bfb1b52cdbd3d72bcc628e9e96d) </cmt> <cmt> [test] introduced tests of the playground transform and defer and nested functions. </cmt> <cmt> (cherry picked from commit 9ac03b7a1ad8bc25a83d23c58d5689440b4193e8) </cmt> <cmt> [pcmacro] implemented support for defer statements in the pc macro. </cmt> <cmt> as with the playground transform, defer statements were not supported in the pc macro. </cmt> <cmt> this commit addresses that oversight. </cmt> <cmt> this partially addresses <rdar://problem/29007242>. </cmt> <cmt> (cherry picked from commit 2c0405871030b96dafb8312cd1d9116bb4332e54) </cmt> <cmt> [test] introduced a test of the pc macro and nested functions. </cmt> <cmt> (cherry picked from commit 2f9ab4493e5c3c28886562946b3ae64426d4e0cc) </cmt> <cmt> added comments based on review feedback. </cmt> <cmt> (cherry picked from commit 1d602f2062102feebcbba5cb933d2ee6f8d8ad86) </cmt>",fix the handling of defer statements in the playground transform and pc macro.
2795,<desc> adds support for the kbd8x mkii keyboard. adds the kbd8x mkii my code follows the code style of this project. i have read the contributing document. </desc> <cmt> begin work </cmt> <cmt> make things a tad easier to read </cmt> <cmt> fix spacing </cmt> <cmt> get things compiling </cmt> <cmt> build a variety of generic keymaps </cmt> <cmt> correct rgb pin </cmt> <cmt> add configurator json </cmt>,add support for kbd8x mkii
2796,<desc> handling the new hud msgs separately in #23000 </desc> <cmt> add 2021 accord 2.0 touring & hybrid touring </cmt> <cmt> - create the honda_bosch_ext set for honda_bosch cars that utilize the new extended ids for lkas_hud </cmt> <cmt> remove ids added to the wrong car </cmt> <cmt> add comment </cmt> <cmt> fix undefined signal </cmt> <cmt> fix tests </cmt> <iss> merge accord 2021 back in </iss>,bring back accord 2021 + 2021 hybrid
2797,"<desc> this patch is going to further optimize dnn for rvv based on my gsoc work. the previous version is #20521. there are 3 changes in this patch. using vsetvl instead of a branch to handle vector tail (the last few elements of each row, which can not fill the entire vector register). i wrote an example on godbolt about the different between using vsetvl  and using if  to show that use of vsetvl eliminates conditional jumps and just introduce a statement (sub). unify the name of variables, which is about vl the variable naming in each function before is independent and unfriendly to readers. so i modified the variable name about vl with the same rule. for now, in all 4 functions: all the following variables are used for vl parameters in intrinsic, but different names have different meanings: vlm<lmul> :  the maximum value that vl can be set for a certain lmul. it is a constant value. vl :  the number of elements processed in each inner loop, which will be used to process tail in the final loop. unroll_tail : the number of elements processed in each outer loop, also used to process tail in the final loop, but this tail is caused by loop unrolling and there are new parameters intrudced by change 1 called avl, which represents the number of unprocessed elements, and used as the parameter of vsetvl. update the way function fastconv handles the matrix tail (the last few rows of the matrix, usually caused by loop unrolling, the vl for matrix tail is called unroll_tail in change 2). in previous version, i use both vl and mask for the matrix tail to handle the different sizes of the blocksize and here is the discussion at the time. however, mask usually takes a lot of costs and i find a new way to only use vl to handle that. with that, no mask, even no additional branch is needed. i have already tested this patch on qemu, the minimal dnn test data set show the same result on the patch and on the master branch: 3 failed tests to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work </desc> <cmt> optimize dnn on rvv by using vsetvl. </cmt> <cmt> rename vl. </cmt> <cmt> update fastconv by using setvl instead of mask. </cmt>",further optimize dnn for risc-v vector.
2798,"<desc> add convenience macros within and fixfloat. apply const and const float & where needed. make calls to print_line_from_here_to_there compatible with g92 / m206. make 3-point leveling compatible with g92 / m206. pass destination as an argument to retract_filament and un_retract_filament. pass no xyze arguments to ubl_line_to_destination, which always uses destination. rename probe_index to mbl_probe_index for mbl. reduce pstr storage cost for debug_current_and_destination. (pstrs are not coalesced!) add enable_leveling_fade_height to the travis ci tests. drop bad idea enqueue_and_echo_command_now. (concise diff) </desc> <cmt> clean up code, remove _now command function </cmt> <cmt> add and apply within macro </cmt> <cmt> mbl fiddle </cmt> <cmt> apply fixfloat macro </cmt> <cmt> have run_probe() return probe z, not nozzle z </cmt>",further adjustments to ubl code
2799,"<desc> title says it all, see also #62367. related issues #31931 i added the following tests: doc change only. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> ++ </cmt> <cmt> ++ </cmt>","fix ""unresolved doc reference"" in rendering layer"
2800,"<desc> hey, this pull request implements a dialog asking if the user want to restart the application when the theme changes. added necessary strings on resource file remove some unused imports only show the dialog when the selected theme it's not the current theme </desc> <cmt> add necessary strings </cmt> <cmt> implement restart dialog </cmt> <cmt> check if selected theme it's not the current </cmt>",add restart dialog on theme change
2801,"<desc> name:  new/updated documentation content about: adding a new docs page, or updating content in an existing docs page does this pr add a new page, or update an existing page? updates some existing pages checklist is there an existing issue for this pr? #4034 and #4096, partially have the files been linted and formatted? what docs page is being added or updated? section: introduction page: ""getting started"" and ""learning resources"" for updating existing content updated docusaurus to beta.0 added react-lite-youtube-embed lib added an embed of the ""learn modern redux"" episode into ""getting started"" and ""tutorials index"" updated the ""learning resources"" page: removed older tutorials that aren't how we want people using redux today moved dan's egghead videos into the ""how it works"" section and updated the course links added some newer tutorial article links </desc> <cmt> bump docusaurus to beta.0 </cmt> <cmt> add react-lite-youtube-embed </cmt> <cmt> add ""learning modern redux"" embed to getting started and tutorials </cmt> <cmt> update learning resources page </cmt> <cmt> - nuked a bunch of older links </cmt> <cmt> - moved dan's links into the ""how it works"" section </cmt> <cmt> - added some more recent links </cmt> <cmt> update dan's egghead course links </cmt>","add ""learning modern redux"" embeds and update learning resources"
2802,<desc> this pr fixes two somewhat unrelated issues: panic when connection to ws fails websocket connection errors are 'returned' via unhandled rejection rather than via error event </desc> <cmt> fix: panic on websocket connect </cmt> <cmt> fix(websocket): no panic on connect + errorevent </cmt>,no panic on failed connect + handle promise rejection via error event
2803,"<desc> reduce hive source parallelism when limit push down when limit push down ,set the parallelism to min(parallelism,limit) this change is already covered by existing tests, such as (please describe tests). manually verified the change by running a 4 node cluser with 2 jobmanagers and 4 taskmanagers, a stateful streaming program, and killing one jobmanager and two taskmanagers during the execution, verifying that recovery happens correctly. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector:no </desc> <cmt> test </cmt> <cmt> delete hotelorder2hdfsk8stest.java </cmt> <cmt> reduce hive source parallelism when limit push down </cmt>",[flink-16413]reduce hive source parallelism when limit push down
2804,"<desc> these changes could have been included in a meteor 1.9.1 release, but neither update is so urgent that they need to be released sooner than 1.10. </desc> <cmt> update node.js to version 12.14.1. </cmt> <cmt> update npm to version 6.13.6 and pacote to version 9.5.12. </cmt> <cmt> bump $bundle_version to 12.14.1.0 before rebuilding dev bundle. </cmt>",update node.js to v12.14.1 and npm to v6.13.6.
2805,"<desc> before, an attributeerror was raised due to trying to access an attribute that exists on specs but having received none instead for a non-existent module. </desc> <cmt> explicitly check if an attribute on a spec exists </cmt> <cmt> test against a non-existent module </cmt> <cmt> be more accurate about the exception raised </cmt>",raise modulenotfounderror in pyclbr when a module can't be found
2806,"<desc> this is the last planned round of deprecations for 5.1. tornado.web.asynchronous, the whole stack_context module, the callback argument to requesthandler.flush and tornadoreactor are all going away. asynctestcase.stop and wait are doc-deprecated but won't be removed. </desc> <cmt> web: add requesthandler.detach </cmt> <cmt> this method eliminates the need to use the asynchronous decorator on </cmt> <cmt> handlers that may call detach. </cmt> <cmt> web: deprecate asynchronous decorator </cmt> <cmt> web: deprecate callback argument to requesthandler.flush </cmt> <cmt> also deprecates callback arguments in httputil and http1connection </cmt> <cmt> stack_context: deprecate stackcontext class </cmt> <cmt> simple_httpclient: move _on_connect next to its caller </cmt> <cmt> pure cut-and-paste, will make the next diff more readable </cmt> <cmt> simple_httpclient: initial refactoring into coroutines </cmt> <cmt> eliminates the use of exceptionstackcontext. </cmt> <cmt> stack_context: deprecate exceptionstackcontext </cmt> <cmt> take extra care with the deprecation warnings since a few modules need </cmt> <cmt> to continue using exceptionstackcontext for backwards compatibility </cmt> <cmt> even though it is not needed in most cases and should not generate </cmt> <cmt> warnings unless it is relied upon. </cmt> <cmt> testing: deprecate stop/wait </cmt> <cmt> don't mark them for deletion in 6.0. they're used extensively in the </cmt> <cmt> test suite and it's fairly harmless to keep them around. </cmt> <cmt> twisted: deprecate tornadoreactor </cmt> <cmt> this is unnecessary when the asyncio event loop can be used instead. </cmt>","deprecate web.asynchronous, stack_context, and more"
2807,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> created host-validation typings. </cmt> <cmt> fixed tsconfig.json. </cmt> <cmt> added strictfunctiontypes to true in tsconfig.json. </cmt> <cmt> changed t[] to array<t> because it is non-simple type. </cmt>",added type definitions for host validation.
2808,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> created a guide about the mkdir command </cmt> <cmt> update index.md </cmt> <cmt> added a guide for the rm command in bash </cmt> <cmt> created a new guide for the chmod command </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> created the guide for the ssh command </cmt>",created a guide for the bash ssh command
2809,"<desc> when building grpc_csharp_ext, link libgrpc and libgpr statically. also, if openssl and zlib are not available to pkgconfig, link them statically as well. this makes grpc_csharp_ext shared library a monolith that only depends on libc (as a first step in trying to include precompiled grpc library in the grpc c# nuget package). </desc> <cmt> support static linkage for dependencies </cmt> <cmt> regenerate makefile </cmt>",statically link dependencies of grpc_csharp_ext
2810,"<desc> waitforrcpodsrunning not waiting until internal podstore is up to date clusterdns not waiting until frontend pod is running kube-ui e2e test waits for wrong labels note: the clusterdns example e2e test is marked with [conformance]. hence, this patch is also relevant for release-1.1 before tagging the new conformance test suite. </desc> <cmt> remove race of waitforrcpodsrunning running check and internal pod store </cmt> <cmt> remove race of clusterdns e2e frontend test and starting pod </cmt>",fix races in clusterdns e2e test
2811,"<desc> related #78889 this adopts the icon font in the tree widget: this also sets all of the icons inside of the tree widget to inherit the foreground of each element. for example, modifying the sidebarsectionheader.foreground color would apply the change to all icons in the sidebarsectionheader: and likewise, modifying the generic foreground will apply to all items: this also fixes #55857 ( ): and also works with file icon themes: would love for you to verify that this is working all of our tree widgets (i've already done my own verification). i also introduced a new element into the sidebar section header, rendertwisties, to have a container for the icon as there wasn't one there. </desc> <cmt> adopt icon font in tree </cmt> <cmt> update icon twisties to work with file icons </cmt> <cmt> update twistiescontainer </cmt> <iss> icons are hard to see in selected states </iss>",adopt icon font in tree widgets and panels
2812,"<desc> editbox doesn't popup a window for input, it uses the native edit ctrl to input. this pr also fix the system label overflow issue on windows. </desc> <cmt> refactoring windows editbox </cmt> <cmt> refactoring win32 system label </cmt>",refactoring editbox and  system label on win32 platform
2813,"<desc> this pr adds support for hive unit tests on travis. in addition, to make sure tests work, impyla is used instead of pyhs2. note: there are some things to fix with impyla still, stay tuned for the fixes. </desc> <cmt> issue-1123 use impyla instead of pyhs2 </cmt> <cmt> use gssapi instead of kerberos and provide backwards compatibility </cmt> <cmt> use kerberos_service_name = 'hive' as standard instead of 'impala'. </cmt> <cmt> add warning for deprecated setting </cmt> <cmt> this patch allows for testing of hive operators and hooks. sasl is used (nosasl in connection string is not possible). tests have been adjusted. </cmt> <cmt> add tests for hiveserver2 and fix some issues from impyla </cmt>",allow for (unsecured) hive unit tests and integrate impyla
2814,<desc> second draft for extracting reusable components from sql into their own project. related to #50049 </desc> <cmt> polishing </cmt> <cmt> wip: sql code + tests compile </cmt> <cmt> wip checkpoint: ql tests passing </cmt> <cmt> move over test resources </cmt> <cmt> tweaks </cmt> <cmt> wip checkpoint: ql module compiles (including tests) </cmt> <cmt> wip </cmt> <cmt> move execution package </cmt> <cmt> wip </cmt> <cmt> - moved expressions and functions </cmt> <cmt> - need to add separation layers inside functionregistry </cmt> <cmt> - move over logicalplan </cmt> <cmt> add missing painless module </cmt> <cmt> wip: initial draft for common eq project </cmt> <cmt> wip </cmt> <cmt> wrap up unit tests in sql project </cmt> <cmt> two test suits were disabled due to classpath differences between ides </cmt> <cmt> and gradle. </cmt> <cmt> polishing </cmt>,extract common parts into a separate ql project
2815,"<desc> cherry-pick of module interface fixes to 5.1 from: #24225 #24212 resolves rdar://problem/49856177 resolves rdar://problem/49856927 </desc> <cmt> [moduleinterface] allow non-mutable iboutlet instance properties in module interfaces </cmt> <cmt> if an iboutlet property is public private(set), it's interface only has a </cmt> <cmt> getter. consuming this interface was triggering a diagnostic that iboutlet </cmt> <cmt> properties must be mutable. this patch bypasses this check for module </cmt> <cmt> interfaces. </cmt> <cmt> resolves rdar://problem/49856177 </cmt> <cmt> [serialization] don't add an overrideattr if the 'overridden' decl is a convenience init when deserializing </cmt>",cherry-pick module interface fixes to 5.1
2816,"<desc> added support for the kintsugi keyboard; a board designed by me (arturo avila) with a 65%-ish layout, an oled, an encoder and underglow. as this is the first pr regarding the kintsugi keyboard, no issue has been fixed or closed. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added adpenrose/kintsugi </cmt> <cmt> embelished some snippets of code. </cmt> <cmt> added an image of the keyboard to the readme.md file </cmt> <cmt> added an image of the keyboard and a brief description to the readme.md file </cmt> <cmt> added an image of the keyboard and a brief description to the readme.md file </cmt> <cmt> solved a minor error regarding the keymap.c files. </cmt> <cmt> idk anymore </cmt> <cmt> eeprom cleaned and glitch with via solved </cmt> <cmt> tidied up general readme.md and keymap.c files on the default, via and franky keymaps. </cmt> <cmt> fixed some details regarding coding conventions. </cmt>","kintsugi keyboard with a 65%-ish layout, encoder, oled and underglow."
2817,"<desc> we are introducing a new page inside processing section of project settings called android mappings. proguard files (android mappings) are living now with other debug files, but we are starting to move them into their own page and later we will change their design a bit. this is behind the android-mappings feature flag. i am going to make it part of sentry-experiments team. </desc> <cmt> feat: add file type filter to debug files api endpoint </cmt> <cmt> feat(ui): new proguard navbar item, route, component wip </cmt> <cmt> feat(ui): proguard list, reused row component for now </cmt>",split proguard from other difs
2818,"<desc> backport of #16351. the error path leak i noticed randomly, since we did not have a test for it, otherwise a leak checker would have noticed it. the other leak is tricky, because tracemalloc should have notified us about it, but unfortunately it is public api that you are supposed to free that object, so that is not possible. thus it was only found with a full valgrind leak-check run, and without manually narrowing things down and controlling it, that takes 24 hours so i never bothered it (since i assumed pytest-leaks finds all things). in any case, these are trivial fixes, the only question would be if someone thinks the test is dangerous... </desc> <cmt> bug: fix reference count leak in array allocation memory path </cmt> <cmt> bug: add missing dimensions free in empty_like with shape </cmt>",fix small leaks in error path and empty_like with shape
2819,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> adds isjwt type def for validator </cmt> <cmt> increases the version number in the header </cmt>",add isjwt type def for validator package
2820,"<desc> textscalefactor depends on an existing fontsize to be multiplied with in order to be passed into dart:ui. textspans using richtext do not inherit styles from parents, and thus, fail to pass textscalefactor when style is null. here, we provide the default font size as a base font to be multiplied by. this does not change behavior other than fix the bug, since the default font size would have been applied at the engine level anyways. related issues fixes #66196 and #66197 </desc> <cmt> fix defaulting for textscalefactor </cmt> <cmt> fix defaulting for textscalefactor </cmt> <cmt> comments </cmt> <iss> richtext textscalefactor is ignored if the child textspan doesn't contain a textstyle </iss>",provide defaulting for textscalefactor when passing to dart:ui
2821,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. *** advice requested re: linting as get result: dt-header  header should only be in index.d.ts for the v15 version *** provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> initial commit of typings for openfin api </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> initial commit for v16 of openfin api </cmt> <cmt> moved v15 to v15 folder. </cmt> <cmt> updated both v16 and v15 with better separation of static and instance methods. </cmt>,openfin v16 - new version of api
2822,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation this pull request changes the way negative time delta's are displayed. the default python display of a negative timedelta is rather unintuitive for a user of a dashboard. for example, -6 minutes is displayed as '-1 day, 23:54:00. this basically requires users to make time calculations in their heads to interpret the number correctly. this pull request changes the formatting to  '-0:06:00' at the code level and -0 days 00:06:00 at the superset ui level to make it easier for users to interpret the time delta. more details on the issue and why this solution was chosen can be found in #8274 . the data in postgres looks like this: before this pull request the data looks like this in superset: afterwards it looks like this in superset: test plan the unit test for base_json_conv() has been enhanced to handle timedelta's as well a new function has been added in superset.utils.core named timedelta_f which is called in base_json_conv() (same module). a new test has been added to test this formatting function. has associated issue: #8274 requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> wip - add easily interpretable negative timedelta formatting </cmt> <cmt> add unit tests for utils.core.timedelta_f </cmt>",more intuitive display of negative time deltas (#8274)
2823,"<desc> by default, xaml enables both vertical and horizontal scrolling for the native scrollviewer. the scrolltoend method relies on checking whether horizontal scrolling is enabled to know if 'end' means 'bottom' or 'right'. setting horizontal scrolling to disabled by default - can be enabled with the 'horizontal rn prop. microsoft reviewers: open in codeflow </desc> <cmt> [fix] scrollview.scrolltoend not working for vertical lists </cmt> <cmt> change files </cmt> <iss> scrollview scrolltoend viewmanager command does not function </iss>",fix scrolltoend for vertical <scrollview>.
2824,<desc> with this change we will allow one to run ./gradlew -dtests.split=1/2 check ./gradlew -dtests.split=2/2 check to run tests in separate invocations possibly across separate machines. the way the tests are split is meant to be opaque and up to the build. the intent is to use this in ci to speed up pr checks. </desc> <cmt> add options to filter tests based on path prefix </cmt> <cmt> merge commit 'd85a654ebbdacb86ac0c51bf541d391d61a49ebd' into check-prefix-filter </cmt> <cmt> make split more generic </cmt>,implement a property to allow for splitting tests.
2825,"<desc> merge #3938. </desc> <cmt> added triangle, quad bezier, cubic bezier drawing to drawnode </cmt> <cmt> readded trimmed semicolon </cmt> <cmt> added triangle, cubic bezier and quad bezier tests to drawprimitivestest </cmt> <cmt> merge commit 'refs/pull/3938/head' of git://github.com/cocos2d/cocos2d-x into drawnode </cmt> <cmt> conflicts: </cmt> <cmt> cocos/2d/ccdrawnode.h </cmt>","drawnode supports to draw triangle, quad bezier, cubic bezier"
2826,"<desc> this patch fixes #1563 (comment). indeed, before this patch, the updater was not supporting a raw list of domains as input. changes: matches_exclusions(): (new) support for rule formatted as 'example.com' along with the pre-existing '0.0.0.0 example.com'. normalize_rule(): (edit) apply dry. (new) support the normalization of the rule formatted as  'example.com' along with the pre-existing '0.0.0.0 example.com'. strip_rule(): (new) complete rewrite in order to strip all possible lines. *.py (files): apply black & isort. setup.cfg: add black recommended/related settings. stay safe and healthy. nissar </desc> <cmt> introduction of the support of raw lines. </cmt> <cmt> this patch fixes </cmt> <cmt> indeed, before this patch, the updater was not supporting a raw (not </cmt> <cmt> hosts) list of domains as input. </cmt> <cmt> changes: </cmt> <cmt> matches_exclusions(): </cmt> <cmt> (new) support for rule formatted as 'example.com' along with </cmt> <cmt> the pre-existing '0.0.0.0 example.com'. </cmt> <cmt> normalize_rule(): </cmt> <cmt> (edit) apply dry. </cmt> <cmt> (new) support the normalization of the rule formatted as </cmt> <cmt> 'example.com' along with the pre-existing '0.0.0.0 </cmt> <cmt> example.com'. </cmt> <cmt> strip_rule(): </cmt> <cmt> (new) complete rewrite in order to strip all possible lines. </cmt> <cmt> apply black+isort </cmt> <cmt> add black recommended configuration. </cmt> <iss> cname-cloaked trackers </iss>",introduction of the support of raw lines/sources
2827,"<desc> this should fix the underlying problem of inefficient list initialization, which has led me to filing #657. by using a rvalue-aware proxy type inside all uses of std::initializer_list, simple, obvious usages such as return json { {""type"", ""polygon""}, {""coordinates"", std::move(coordinates)}, }; should just work without calling json copy constructor even once. possible downsides for this solution: it can increase the number of move constructor calls in some situations. i think it is a good trade-off to make, because moving json values should be very cheap (and possibly optimized into nothing). it is, strictly speaking, a breaking interface change, but it is only limited to somehow using an explicitly typed std::initializer_list values, which is not common in c++. all normal usage should remain unaffected (just a bit faster). it is certainly a hack </desc> <cmt> add some tests for std::move from std::initializer_list </cmt> <cmt> optimize json construction from rvalue string_t/array_t/object_t </cmt> <cmt> support moving from rvalues in an std::initializer_list </cmt> <cmt> this commit works around an issue in std::initializer_list design. </cmt> <cmt> by using a detail::json_ref proxy with a mutable value inside, </cmt> <cmt> rvalue-ness of an input to list initializer is remembered and </cmt> <cmt> used later to move from the proxy instead of copying. </cmt> <cmt> update tests while fixing possible ub </cmt> <cmt> std::initializer_list does not own the temporaries created in </cmt> <cmt> its initialization. therefore, storing it in an independent </cmt> <cmt> stack variable is unsafe. </cmt>",support moving from rvalues in std::initializer_list
2828,<desc> fixes #1813 also added a test to ensure public header files and protobuf generated code doesn't have these warnings. this test doesn't cover protobuf's own implementation code. we may want to update all of protobuf's code to be free of this warning in the future but right now there are just too many of them and require more work to cleanup. </desc> <cmt> add a test to catch sign-comparison warnings. </cmt> <cmt> grpc build treates them as errors and such issues (protobuf change </cmt> <cmt> breaks grpc) has been reported repeatedly. for example: </cmt> <cmt>  </cmt> <cmt> change-id: i077c4557cf3effd5195f88802c38999b884edc30 </cmt> <cmt> fix sign-comparison warnings in public header files. </cmt>,fix sign-comparison warnings and add a test for that.
2829,"<desc> i was seeing these tests fail locally for me on master from a mac (it passes on ci). the reason was that some of these tests were using the real artifacts and file systems. this pr modifies tests to properly mock the artifacts and use memory file systems. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> fix one test! </cmt> <cmt> fix more tests </cmt>",fix environment leakage in doctor_test
2830,"<desc> see #1759 for discussion (but scroll to the bottom, that ticket discusses like 3 separate bugs in one thread). in the case that x64dbg starts the debuggee process, it keeps two unneeded handles around with process_all_access and thread_all_access rights respectively. these are duplicated in nt!dbgkpopenhandles when the first debug event (create_process_debug_event) is sent. the latter two handles are automatically closed by kernel32 after exit_process_debug_event is handled. the original handles from createprocess (done by titanengine) are never closed however. you can check this by starting a debug session, stopping the process, restarting the session, and so on: process hacker will show a leaked process handle in x64dbg.exe to a non-existent process for each session that was started. this pr closes the initial handles received from createprocess just before calling debugloop(). cbcreateprocess then sets fdprocessinfo->hprocess and fdprocessinfo->hthread to the new handle values before doing anything else. this does mean there is a tiny window during which these handles are null, but as they aren't sent to plugins i don't think this is an issue. the call to safesymcleanup() has been moved to cbexitprocess, so that this always happens before the debuggee process has terminated. this fixes a crash that can occur if you close x32dbg (but strangely not x64dbg?) while the debuggee is still running. </desc> <cmt> remove static global handle 'hprocess' in debugger.cpp; it is only used in one place as argument to safesymcleanup(). use fdprocessinfo->hprocess instead </cmt> <cmt> fix duplicate debuggee process and initial thread handles being kept around in the case that x64dbg is not attaching: </cmt> <cmt> - closehandle() the fdprocessinfo->hprocess and fdprocessinfo->hthread handles and set them to null if createprocess was called (i.e. we are not attaching) just before entering the debug loop </cmt> <cmt> - cbcreateprocess(): set fdprocessinfo->hprocess, fdprocessinfo->hthread and varset(""$hp"") to the correct handles prior to doing anything else </cmt> <cmt> remove 2 occurrences of 'varset(""$hp"", fdprocessinfo->hprocess)', one of which was being called with the initial handle from createprocess(). cbcreateprocess is now the only place where this variable is set, for both types of debug sessions (attaching or creating) </cmt> <cmt> move safesymcleanup() call to cbexitprocess so it isn't called when the process may have already terminated </cmt> <cmt> debugloopfunction: set fdprocessinfo->hprocess and fdprocessinfo->hthread to null as these shouldn't be used after this point. the actual closehandle calls on these two handles are done by kernel32!continuedebugevent immediately after cbexitprocess </cmt>",do not keep duplicate process and initial thread handles around
2831,<desc> reland of #36465 with fixes to analysis </desc> <cmt> initial pass at removing version check based visibility </cmt> <cmt> update web config library </cmt> <cmt> add test cases for doctor inclusion </cmt> <cmt> remove deprecation for now </cmt> <cmt> testing and cleanup of feature flag </cmt> <cmt> update test values </cmt> <cmt> update flutter_command_test.dart </cmt> <cmt> add env variable for local test </cmt> <cmt> fix import error </cmt>,use flutter features for web and desktop
2832,"<desc> see #3028. the solution in this patch is pretty debateable. what we do is give the tokenc struct a .norm field, by repurposing the previously idle .sense attribute. it's nice to repurpose a previous field because it means the tokenc doesn't change size, so even if someone's using the internals very deeply, nothing will break. the weird thing here is that the tokenc and the lexemec both have an attribute named norm. this arguably assists in backwards compatibility. on the other hand, maybe it's really bad! we're changing the semantics of the attribute subtly, so maybe it's better if someone calling lex.norm gets a breakage, and instead is told to write lex.default_norm? overall i believe this patch makes the norm feature work the way we sort of expected it to work. certainly it's much more like how the docs describe it, and more in line with how we've been directing people to use the norm attribute. we'll also be able to use token.norm to do stuff like spelling correction, which is pretty cool. i have submitted the spacy contributor agreement. </desc> <cmt> add a tokenc.norm attribute. see #3028 </cmt> <cmt> add test for #2754 </cmt>",make norm a token attribute
2833,<desc> description: some tvs would end up turning off instead of sleeping checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> fixed an issue where sometimes the xiaomi tv wouldn't sleep correctly </cmt> <cmt> removed file that was added by mistake </cmt>,fixes an issue in xiaomi tv platform that would some tvs not sleep correctly
2834,"<desc> this fixes an issue with bfs expansion of trees, which overshoots the max_depth of a tree by 1. the output of the following two cases should be the same, but isn't: >>> from sklearn.datasets import load_iris >>> from sklearn.tree import decisiontreeclassifier >>> x, y = load_iris(return_x_y=true) >>> >>> clf = decisiontreeclassifier(random_state=0, max_depth=1, max_leaf_nodes=100) >>> clf = clf.fit(x, y) >>> clf.get_depth() >>> clf.get_n_leaves() >>> >>> clf = decisiontreeclassifier(random_state=0, max_depth=1) >>> clf = clf.fit(x, y) >>> clf.get_depth() >>> clf.get_n_leaves() this pr fixes the issue, and warns the user of the changed behavior if the code reaches that point of change. i'm not sure about the warning, but right now, this would be the output after this pr: >>> from sklearn.datasets import load_iris >>> from sklearn.tree import decisiontreeclassifier >>> x, y = load_iris(return_x_y=true) >>> >>> clf = decisiontreeclassifier(random_state=0, max_depth=1, max_leaf_nodes=100) >>> clf = clf.fit(x, y) .../tree.py:380: userwarning: due to a bugfix in v0.21 the maximum depth of a tree now does not pass the given max_depth! builder.build(self.tree_, x, y, sample_weight, x_idx_sorted) >>> clf.get_depth() >>> clf.get_n_leaves() >>> >>> clf = decisiontreeclassifier(random_state=0, max_depth=1) >>> clf = clf.fit(x, y) >>> clf.get_depth() >>> clf.get_n_leaves() </desc> <cmt> fix the issue with max_depth and bestfirsttreebuilder </cmt> <cmt> fix the test </cmt> <cmt> merge master </cmt> <cmt> fix max_depth overshoot in bfs expansion </cmt>",fix max_depth overshoot in bfs expansion of trees
2835,<desc> add bmm op implementation and create bmm api in tensor add unittest for bmm op create arange api </desc> <cmt> add bmm and arange op test=develop </cmt> <cmt> add bmm and arange op test=develop </cmt>,create bmm op and move several api from fluid.layers to tensor
2836,"<desc> ref #30999 tests added / passed passes black pandas passes git diff origin/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> beginning work on fixing the bare pytest raises </cmt> <cmt> within the test_eval.py file. i have been working </cmt> <cmt> on this for ~30 minutes so far. </cmt> <cmt> little over halfway done with this file now. </cmt> <cmt> almost done! </cmt> <cmt> finished the file! </cmt> <cmt> blacked </cmt> <cmt>  conflicts: </cmt> <cmt> 	pandas/tests/computation/test_eval.py </cmt> <cmt> adding message check to pytest.raises for test_upcast </cmt>",avoid bare pytest.raises in dtypes/cast/test_upcast.py
2837,<desc> explanation: this change helps resolve the ambiguities that started to arise after the recent constraint solver changes. scope of issue: additive. the operators being added have always been there in form of default impleemntations on protocol extensions. overloading them on concrete type takes advantage of certain shortcuts in the solver. risk: minimal reviewed by: pavel yaskevich testing: automated test suite + a case for the regression reported in sr-6634 directions for qa: n/a radar: rdar://problem/36113283 </desc> <cmt> [stdlib] adding derived equality/comparison operators to concrete integer types </cmt> <cmt> (cherry picked from commit c8b12ee28238d998669bde673c85f2b2f89c7b6e) </cmt> <cmt> add a test case from sr-6634 </cmt> <cmt> (cherry picked from commit 0fa300bae2389c553ad643a690659201625c6b27) </cmt>,add derived equality/comparison operators to concrete integer types
2838,"<desc> adds a new option for host identifier, which is to specify the value via the cli. also adds assigning the result status from each uuid generation function inside gethostidentifier() so we can log any non-ok results. built everything on windows via .\tools\make-win64-binaries.bat. this includes tests, which all passed. i tried running the osqueryi.exe shell with --host_identifier specified --specified_identifier and got an error from gflags that i needed to set a value for specified_identifier. i also tried running the shell with both values set, and osqueryi ran fine (but wasn't sure how to select the host identifier). i also ported this over to a local project where i'm including osquery as a library. specifying host_identifier via osquery::flags_host_identifier = ""specified""; and not assigning anything to specified_identifier results in the error message not ok host identifier: no specified identifier for host. the weird part was the scheduler seemed to not want to run anymore, likely because hostidentifier was set to the empty string... later, i added osquery::flags_specified_identifier = ""123456789""; and was able to observe this properly showing up in the hostidentifier field in (1) enrollment, and (2) machine logs. </desc> <cmt> adds a new specified_identifier flag and option to host_identifier </cmt> <cmt> capture and log results in gethostidentifier and change default value for specified_identifier </cmt>",add specified identifier via gflags
2839,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> initial commit for @react-native/assets </cmt> <cmt> format code </cmt> <cmt> update index.d.ts </cmt> <cmt> update tsconfig.json </cmt> <cmt> update tsconfig.json </cmt> <cmt> update tsconfig.json </cmt> <cmt> rename test file </cmt> <cmt> update tsconfig.json </cmt> <cmt> fix dslint </cmt> <cmt> fix dslint </cmt> <cmt> fix dslint </cmt> <cmt> fix dslint </cmt>",create type definitions for @react-native/assets
2840,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> adding anonymousutils definition </cmt> <cmt> fixing return type </cmt>",adding anonymousutils definition for parse
2841,"<desc> in these scenarios, qt's api only accepts a 32-bit value, so there's nothing we can do about these except explicitly cast the values. </desc> <cmt> yuzu/config: silence truncation warnings </cmt> <cmt> yuzu/configure_general: silence truncation warnings in loadconfiguration() </cmt> <cmt> the qpixmap api expects an unsigned int. </cmt>",fix truncation warnings within ui code
2842,<desc> add via support for wete. also fixed a incorrect key in the default ansi and iso layouts. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add via support for wete </cmt> <cmt> fix incorrect layout for ansi and iso </cmt>,"add via support for wete, fix layout error"
2843,"<desc> added child dth, which seems to be impossible with the devworkspace </desc> <cmt> sync with orgin </cmt> <cmt> sync </cmt> <cmt> devws for technisat digital gmbh containing containing technisat double-switch </cmt> <cmt> added child dth for serial switch </cmt>",devws for technisat digital gmbh containing containing technisat double-switch including child dth
2844,"<desc> to manage the server side encryption on a kinesis stream i have added an encryption action to enable or disable the encryption service feature. fixes #30269. the new arguments are: encryption_state: 'enabled'/'disabled' encryption_type: 'kms'/'none' key_id: 'guid or alias/aws/kinesis' it handles encryption use cases where: create new stream with encryption - it will be created and encryption enabled enable encryption on an existing stream with encryption disabled - encryption will be enabled disable encryption on an existing stream with encryption enabled - encryption will be disabled ansible version ansible 2.5.0 (30269_kinesis_stream_server_side_encryption 619c49e9c6) last updated 2017/09/21 12:09:48 (gmt +100) config file = none configured module search path = ['/users/sclark/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /users/sclark/ideaprojects/ansible/lib/ansible executable location = /users/sclark/ideaprojects/ansible/bin/ansible python version = 3.6.2 (default, jul 17 2017, 16:44:45) [gcc 4.2.1 compatible apple llvm 8.1.0 (clang-802.0.42)] example playbook - name: setup kinesis stream with encryption enabled connection: local hosts: localhost tasks: # basic creation example: - name: set up kinesis stream with 1 shard and enable encryption, wait for the stream to become active kinesis_stream: name: test-stream shards: 1 wait: yes wait_timeout: 600 state: present encryption_state: enabled key_id: alias/aws/kinesis encryption_type: kms register: testout - name: dump test output debug: msg: '{{ testout }}' </desc> <cmt> moved the encryption to its own action method. </cmt> <cmt> removed silly default value for encryption type. </cmt> <iss> amazon kinesis stream module to manage server side encryption </iss>",kinesis stream server side encryption - fixes #30269
2845,"<desc> this pr fixes a bug in contrib/maddpg where seemingly random policy names lead to shape errors due to a missing (policy) sort. closes issue #8483. closes #8483 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  this pr is not tested (please justify below) </desc> <cmt> bug fix for </cmt> <cmt> we need to pass in a framework explicitly with the new defaults. further, the actual bug was that policies were being sorted alphabetically in the maddpg init(), which led to incorrect initialization. </cmt> <cmt> linting </cmt> <iss> [rllib][bug] some policy-names lead to seemingly unrelated errors </iss>",maddpg bug fix (issue https://github.com/ray-project/ray/issues/8483)
2846,"<desc> this pr fixes #8293 . now importparserplugin returns true when creating context, which stops parser walking on param of import(), then defineplugin fails to change value of it. a bugfix yes no nothing </desc> <cmt> [importparserplugin] when need creating context, should return false instead of true </cmt> <cmt> add tests </cmt> <iss> defineplugin regression </iss>",fix return value when creating context for import()
2847,"<desc> addresses 2.7.1 from #8364 it's accompanied with serverless/dashboard-plugin#552 which ideally if is merged and published first (although going either way, is not breaking) additionally: introduce single point of true for all cli commands as configured in core and dashboard plugin resolve commands and options in  lib/cli/resolve-input.js on basis of introduced schema fixes discovered issues: categorization as service dependent on some commands (some commands were missing it and some have it set for no purpose) recognize --stage and --region for any service dependent and aws specific command help command message in some commands fill missing options (and remove unsupported options) in definition of some commands fix internal commands merge logic (it e.g. overriden plugin names which was output in help, resulting with parent command help being displayed with wrong plugin name) in help output do not state plugin:  by core commands generalize handling of container commands. invoking such command will now show command subcommands help (previously such behavior had to be explicitly configured in) generalize handling of conditional commands, which may not be supported in some environments refactor to async/await few methods in pluginmanager class </desc> <cmt> refactor(cli): fix ""config tabcompletion uninstall"" usage info </cmt> <cmt> refactor(cli): seclude schema of core commands </cmt> <cmt> fix(cli): fix categorization of service dependent commands </cmt> <cmt> fix(cli): recognize --stage & --region on every aws service command </cmt>",single point of true for core cli commands schema
2848,"<desc> follow up to #24315, this lets pytest to fail on warnings that are not ignored, and adds some ignore rules for ones i won't fix right now but will be fixed in the future. also synchronizes this warning ignoring across pytest warmup (before test session starts), and in the runner. </desc> <cmt> start by making all warnings fatal </cmt> <cmt> deprecationwarning: flags not at the start of the expression </cmt> <cmt> ignore removedindjango20warning </cmt> <cmt> deprecationwarning: the 'warn' method is deprecated, use 'warning' instead </cmt> <cmt> just ignore deprecationwarnings wholesale </cmt> <cmt> disable looponfailroots </cmt> <cmt> squelch warnings before pytest test session header, and synchronize </cmt>",enable pytest fail on warnings
2849,"<desc> added option_include_comments, option_include_nested_objects, option_include_permissions. fixed bug: postgres schema always showed it's description. </desc> <cmt> postgresql table comment  ddl. #9387 </cmt> <cmt> added table and column comments to ddl </cmt> <cmt> postgresql table comment  ddl. #9387 </cmt> <cmt> deleted useless row </cmt> <cmt> postgresql table does not show comment in ddl. #9387 </cmt> <cmt> added option_include_comments, option_include_nested_objects, option_include_permissions. fixed bug: postgres schema always showed it's description </cmt> <cmt> postgresql table does not show comment in ddl. #9387 </cmt> <cmt> deleted useless comments </cmt> <cmt> # conflicts: </cmt> <cmt> #	plugins/org.jkiss.dbeaver.ext.postgresql.ui/src/org/jkiss/dbeaver/ext/postgresql/ui/editors/postgresourcevieweditor.java </cmt>",postgre table comment ddl#9387
2850,"<desc> original pull-request #33061 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> native format parsing - integer overflow resizing arrays </cmt> <cmt> addressing review comment </cmt> <cmt> corrections </cmt> <cmt> merge #33024 </cmt>",cherry pick #33061 to 21.3: merge #33024
2851,"<desc> don't merge until we've had some discussion first the csharp.gitignore and vb.net.gitignore files are pretty much exactly the same. most of the settings in there mimic the existing global visualstudio.gitignore. i saw another pr to add an fsharp.gitignore that's almost exactly the same as these others. rather than have an ignore file for every .net language, i think we should just have one for visualstudio. for a moment, i thought it should be called dotnet.gitignore but if you're doing c++ development in visualstudio, that wouldn't apply. also, for all intent and purposes, visual studio is the de-facto ide for developers doing .net, c++, or windows rt development on windows. other development tools tend to adopt its conventions. if we learn that monodevelop produces build files we want to ignore that aren't included in this file, we can consider adding them here. remember, when you create a new repository on github.com, the list of gitignore files you can use is populated from this repository. questions what do you search for when using that dropdown? does visualstudio seem like the right name? if not, do you have a better name? </desc> <cmt> move visualstudio file from global to main list </cmt> <cmt> merge missing csharp/vb settinsg into visualstudio </cmt> <cmt> the visualstudio gitignore file was missing a few useful </cmt> <cmt> settings contained in the csharp and vb.net gitignore files. </cmt> <cmt> remove csharp and vb.net ignore files </cmt> <cmt> these files were redundant. they had almost exactly the same </cmt> <cmt> settings. they are being replaced by the visualstudio file. </cmt>",consolidate csharp and vb.net gitignore files into visualstudio one.
2852,"<desc> what is include in the pr: use list instead of dictionary for pluginmanager.nonglobalplugins. it allows showing results from more than one plugin for the action keyword removed search and terms arguments from query as they can be calculated from the other two removed ref form querybuilder.build querybuildershouldremoveextraspacesfordisablednonglobalplugin test is redundant as there is not consumers of querybuilder.build that expect querytext to be normalized when there is no plugins added querybuildershouldreturnallpluginswiththeactionword test for new functionality try to assign the same action keys for few plugins test for regressions linked issue: #9657 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> possibility to use same action keyword for few plugins </cmt> <cmt> do not pass redundant arguments to query </cmt>",possibility to use the same action keyword for more than one plugin
2853,"<desc> csi volume plugin should provide correct information in getattributes call so kubelet can ask container runtime to relabel the volume. therefore csi volume plugin needs to check if a random volume mounted by a csi driver supports selinux or not by checking for ""seclabel"" mount or superblock option. fixes #63965 release note: fixed selinux relabeling of csi volumes. @saad-ali @vladimirvivien @davidz627 @cofyc, fyi, i'm changing struct mountinfo. </desc> <cmt> add getselinuxsupport to mounter. </cmt> <cmt> add selinux support to csi </cmt> <iss> csi plugin should support selinux </iss>",enable selinux relabeling in csi volumes
2854,"<desc> #15761 cleans up parameter spec in gaussian_process, so it follows the convention outlined in the contributing guide only changes in docstrings. </desc> <cmt> doc cleaning parameter docstrings in _gpc.py (#15761) </cmt> <cmt> doc cleaning parameter docstrings in _gpr.py (#15761) </cmt> <cmt> doc cleaning parameter docstrings in classes kernel, compoundkernel, constantkernel, dotproduct of kernel.py </cmt> <cmt> doc cleaning parameter docstrings in kernel.py </cmt> <cmt> doc cleaning up minor issues in parameter docstring of _gpr and kernels </cmt>",doc cleaning parameter spec in docstrings for module gaussian_process
2855,"<desc> it was to fix the problem with ci machine setting cc and cxx to its own compilers, but as a result running bootstrap.py and update.py separately would cause the entire project to rebuild. this pr just ignores cc and cxx in ci machine so we don't have to overwrite them in bootstrap.py. </desc> <cmt> ignore cc and cxx in env </cmt> <cmt> no more need to overwrite env when running update.py </cmt>",do not overwrite cc and cxx in bootstrap
2856,<desc> fixes #11317. note: it does not solve the issue when user mounts a volume with a different case sensitivity settings </desc> <cmt> added detection for case sensitive file systems </cmt> <cmt> guard against cases when current file name is already in uppercase </cmt> <iss> detect fs case sensitivity based on it's real behavior </iss>,check case sensitivity of host file system.
2857,"<desc> light theme according to material specs we should use the 8% overlay color ( dark theme in a dark theme, states should use the same overlay values as their default (or light) theme ( light theme dark theme related issues closes #64314 i added the following tests: datarow renders default selected row colors datarow renders checkbox with colors from theme before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. </desc> <cmt> use primary color for selected rows in datatable </cmt> <cmt> add test for primary selected row color </cmt> <iss> update datatable to follow material specifications </iss>",use primary color for selected rows and checkboxes in datatable
2858,<desc> description: add support for config entries add support for config flow with authtoken generation keep legacy configuration.yaml config (all parameters optional now) move authtoken generation to async 3th lib package name renamed from homematicip.async.auth to homematicip.aio.auth first tests implemented pr for the config picture: home-assistant/frontend#1306 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> add homematicip cloud to config flow </cmt> <cmt> inititial trial for config_flow </cmt> <cmt> integrations text files </cmt> <cmt> load and write config_flow and init homematicip_cloud </cmt> <cmt> split into dedicated files </cmt> <cmt> ceanup of text messages </cmt> <cmt> working config_flow </cmt> <cmt> move imports inside a function </cmt> <cmt> enable laoding even no accesspoints are defined </cmt>,add homematicip cloud config flow and entries loading
2859,"<desc> closes #34603 closes #31330 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fix bug with ordering </cmt> <cmt> fix second case and add test </cmt> <cmt> add whatsnew </cmt> <cmt>  conflicts: </cmt> <cmt> 	doc/source/whatsnew/v1.2.0.rst </cmt> <iss> rows order when using slice(none) on multiindex dataframe.loc </iss> <iss> bug: dangerous inconsistency when setting values on slice of multi-index </iss>",bug in dataframe.loc returning elements in wrong order when indexer is differently ordered than object
2860,"<desc> the problem in #70 is that data['sentry']['versions'] is now set -- for instance for messages from the logging handler -- without  data['sentry']['exc']. but the views still assume that anytime data['sentry'] is present, data['sentry']['exc'] is too. this diff fixes that by making the views more defensive. </desc> <cmt> updated group view to handle display of messages where __sentry__ does not contain exc (for instance, messages from the logging handler). </cmt> <cmt> updated message details view to handle missing 'exc' in '__sentry__'. </cmt>",fix for keyerrors in group and message views
2861,"<desc> filling out this template is required. pull requests without a clear description may be closed at the maintainers' discretion. </desc> <cmt> bugfix 1.1.x </cmt> <cmt> move home all axis prototype to allow access from ubl.h </cmt> <cmt> remove home all axis command as it exists in marlin.h now </cmt> <cmt> reverse order of tool change and home </cmt> <cmt> race condition causes e0 carriage to move on e1 commands and crash into parked head if order is reversed. needs more research into permanent fix, but this will prevent damage to machines in the meantime. </cmt>",home axes after tool-change in ubl's g29
2862,<desc> see #10050 renamed binarytextureloader to datatextureloader added binarytextureloader  to three.legacy.js added binarytextureloader to docs/deprecatedlist renamed docs binarytextureloader to datatextureloader updated rgbeloader to use datatextureloader instead of binarytextureloader </desc> <cmt> deprecated binarytextureloader </cmt> <cmt> renamed doc page and updated rgbeloader </cmt>,deprecated binarytextureloader in favour of datatextureloader
2863,"<desc> fixes #9838 with the exception of dealing with the news section of index.rst. see #9838 (comment) this makes the listing of documentation versions dynamic by: using sphinx magic |version| using sphinx javascript variable documentation_options.version exploiting the current url to determine if it's looking at the official current dev or stable dir using circleci to construct a catalogue of all currently available documentation on scikit-learn.org, and to store it at  linking to versions.html instead of listing previous versions </desc> <cmt> make circle write a list of documentation versions </cmt> <cmt> use magic to list documentation versions </cmt>",maint use magic to list documentation versions
2864,"<desc> the boost-eigen branch does not compile for me. this is after the merge from kloudkl  (8d894f0) (i never tested it before that). boost::math::nextafter should only be parametrised on one type (or so says gcc here, and what i read on the boost docs). also, the tests for test_random_number_generator reference mean_bound and sample_mean but they need to be referenced as this->mean_bound (again, that's just what my gcc thinks). this branch contains those two fixes. after this, everything compiles and the tests run fine (except for some gpu tests) </desc> <cmt> nextafter templates off one type </cmt> <cmt> mean_bound and sample_mean need referencing with this </cmt>",compile errors in boost-eigen branch
2865,"<desc> @martijnkaijser as you requested, update to fix trac 15315. </desc> <cmt> win32util::powermanagement: real checks for privileges adjustment, do not adjust more then once </cmt> <cmt> win32util::powermanagement: update to use vista+ functions, fixes #15315 </cmt>",update of win32 power management functions
2866,"<desc> fixes #25751 this pr surmise return type and check the assignable the code fix handle follow 4 cases: function like with return type annotation call expression with a function like parameter, and argument is a function like expression assignment with a type annotation, and initializer is a function like expression jsx property assignment whitch can surmise the return type and surmise follow 3 rules: only one expression statement in block body and the type is assignable only one block in block body and the block only contains one labeled statement, make an object literal generated from label and statement, and that is assignable eg: function a () { { a: 'b' } } a => { { a: 'b' } } declaration is arrow function and only one labeled statement in block body, make an object literal generated from label and statement, and that is assignable eg: a => { a: 'b' } for first case, i try to get the return type from type annotation and compare with type of expression statement second case, i try to get the parameter from the signature and check the assignable with the fixed type( after insert the return type) third case, i try to get the type of the initializer and check the assignable type of from the variable declaration type annotation  ( after insert the return type) some thing need todo: add test case of fix all add test case of actions add more edge case for fix (eg. object literal or comma with the paren ) add more test for labeled statement fix add jsx support add property assign / class property declartion support </desc> <cmt> stash </cmt> <cmt> add surmise for return type </cmt> <iss> quick fix for function only contains one jsx element and have not the return statement </iss>",quick fix for functions lacking return expressions
2867,<desc> howto: generate folder data in root directory. copy your files in this folder. use from platformio sidebar menu project tasks the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc4 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> support littlefs with platformio </cmt> <cmt> add littlefs </cmt> <cmt> add littlefs </cmt>,add platformio littlefs upload support
2868,<desc> i also fixed a bug with physical where reflectivity wasn't defined in some cases. </desc> <cmt> add basic variations. </cmt> <cmt> fix bug in physical with reflectivity not always defined. </cmt> <cmt> add lambert variations. </cmt> <cmt> add variations with cubemap on phong. </cmt>,basic and lambert variations examples
2869,"<desc> this pr adds support for the newly released xl and xxl models for xlm-r, and . these models are described in the ""larger-scale transformers for multilingual masked language modeling"" paper. and thank you for @patrickvonplaten and @stefan-it, as the review i got from the #13210, i added modeling_xlm_roberta_xl.py and convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py for conversion script. i compared fairseq and transformers side by side, and managed output same. torch.size([1, 11, 250880]) torch.size([1, 11, 250880]) max_absolute_diff = 0.000186920166015625 do both models output the same tensors? saving model to converted_xlmr_xl configuration saved in converted_xlmr_xl/config.json model weights saved in converted_xlmr_xl/pytorch_model.bin since fairseq roberta to transformers conversion was made a long time ago, transformers architecture differs far from fairseq which originally started from, and it makes quite confusion to write right code. i synced transformers code to allow fairseq model structure. add test for xlm-r xl and xxl upload model for xlm-r xl and xxl to official repo </desc> <cmt> add xlm roberta xl </cmt> <cmt> add convert xlm xl fairseq checkpoint to pytorch </cmt> <cmt> fix init and documents for xlm-roberta-xl </cmt>",add support for xlm-r xl and xxl models by modeling_xlm_roberta_xl.py
2870,"<desc> background subsumes #5171. see jenkins-64650 and the corresponding mailing list thread. problem jenkins core uses a fork of commons fileupload 1.3.1 (which was released upstream on february 7, 2014). two changes were made to the jenkins fork: diskfileitem was made no longer serializable in commit 28d9977 as part of security-159 on september 27, 2014. upstream made the same change over 4 years later in 1.4 (which was released on december 23, 2018). the fix for cve-2016-3092 (originally released upstream in 1.3.2 on may 26, 2016) was backported to the jenkins fork in commit ea981a0 as part of security-490 on september 28-29, 2017. as of 2021, the latest upstream release (1.4) contains all the changes present in the fork; therefore, the fork is no longer necessary. furthermore, it prevents us from receiving upstream fixes. solution upgrade to the latest upstream release, commons fileupload 1.4. testing done all testing was done with mvn jetty:run or mvn hpi:run with remote debugging enabled to verify that all relevant code paths were being exercised. test jenkins core run jenkins core test suite with these changes build a job with a file parameter from a browser (to exercise fileparametervalue and filepath#copyfrom(fileitem)) build a job with a file parameter from the cli (to exercise fileparameterdefinition) upload a plugin from a browser (to exercise pluginmanager#douploadplugin) upload a fingerprint from a browser (to exercise multipartformdataparser) ensure that queuetest#fileitempersistence still works as intended test stapler functional test of multi-part form data (tested by uploading a fingerprint) run stapler test suite with these changes test credentials and plain credentials plugins upload a secret file credential from a browser (to exercise org.jenkinsci.plugins.plaincredentials.impl.filecredentialsimpl) upload a certificate credential from a browser (to exercise com.cloudbees.plugins.credentials.impl.certificatecredentialsimpl.uploadedkeystoresource.upload.doupload) run plain-credentials-plugin test suite with these changes test docker pipeline plugin run org.jenkinsci.plugins.docker.workflow.withcontainersteptest#filecredentials with these changes test active choices plugin run active choices plugin test suite with these changes test file parameters plugin run file parameters plugin test suite with these changes test maven release plugin create a job with a file parameter and click perform maven release (to exercise org.jvnet.hudson.plugins.m2release.m2releaseaction.staplerrequestwrapper) test scriptler plugin click upload new script from scriptler (to exercise org.jenkinsci.plugins.scriptler.scriptlermanagement#douploadscript) run scriptler plugin test suite with these changes test sidebar link plugin click upload an image file from additional sidebar links (to exercise hudson.plugins.sidebar_link.sidebarlinkplugin.doupload) jenkins now uses an updated version of the commons fileupload library without custom patches. changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @jeffret-b @jglick @timja </desc> <cmt> bump commons-fileupload from 1.3.1-jenkins-2 to 1.4 </cmt> <cmt> bumps commons-fileupload from 1.3.1-jenkins-2 to 1.4. </cmt> <cmt> work around fileupload-293 </cmt>",upgrade commons fileupload from 1.3.1-jenkins-2 to 1.4
2871,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. this pr contains some grammatical fixes, omissions, and code formatting for the lesson - ""serialization of a user object"" under ""advanced node & express"" </desc> <cmt> updates... </cmt> <cmt> updates </cmt> <cmt> update serialization-of-a-user-object.english.md </cmt>","grammatical fixes in ""serialization of a user object"" lesson in ""advanced node & express"""
2872,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added type definitions and tests for latlonvectors </cmt> <cmt> fixed common mistakes </cmt> <cmt> changed an array parameter reference to readonlyarray </cmt>",added definitions for the latlonvectors class
2873,"<desc> handle the == null (equals(null)) replacement with isnull() earlier in the optimization step so that the boolean expressions simplification (isnull => true/false) does catch the == null expressions properly. as such, a query of the form where null == 123 results in a no-op because null == 123 evaluates to false rather than evaluating to null (null == 123 is a three-value expression that results in a null value when one of the values is null). </desc> <cmt> replace [null equality] with [isnull/isnotnull] before simplifying </cmt> <cmt> boolean expressions. </cmt>",improve null handling in the optimizer
2874,"<desc> this pull request adds support of booleantype, floattype, doubletype, varchartype, varbinarytype, decimaltype, datetype and timetype for vectorized python udf. java tests arrowutilstest, baserowarrowreaderwritertest, rowarrowreaderwritertest and python tests pandasudfittests.test_all_data_types dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (no) the serializers: (no) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (no) if yes, how is the feature documented? (not applicable) </desc> <cmt> [flink-16608][python] remove the method which derives the logicaltype from the arrow valuevector </cmt> <cmt> [flink-16608][python] support booleantype in vectorized python udf </cmt> <cmt> [flink-16608][python] support floattype in vectorized python udf </cmt> <cmt> [flink-16608][python] support doubletype in vectorized python udf </cmt> <cmt> [flink-16608][python] support varchartype in vectorized python udf </cmt> <cmt> [flink-16608][python] support varbinarytype in vectorized python udf </cmt>",support primitive data types for vectorized python udf
2875,"<desc> this pr is for improving code coverage. inside the folder /superset-frontend/src/component  there is the loading.tsx component, which had no tests or storybook. in this pr, i am making the following changes: moving the file to the ""loading/index"" folder to maintain compatibility with imports that already exist. creating the storybook for the component creating unit tests for the component. ensuring that it is working properly in order to make the storybook work properly, it was necessary to insert a new prop (optional), which receives the path of the loading image. when creating the build, the images are placed in the folder /static/assets/images/ while in the storybook it is not possible to make this mapping and the images are in the ""/images/"" folder. the prop ""image"" has been inserted to make it possible to display the image correctly. however, the default value of this prop remains the original value, not changing the current behavior </desc> <cmt> moving loading.tsx to the loading folder </cmt> <cmt> creating storybook for loading component </cmt> <cmt> creating unit test for loading component </cmt>","adding test and storybook to ""loading"" component."
2876,"<desc> removes now cli reference from examples. converts this: deploy it to the cloud with now (download): now ...into this: deploy it to the cloud with zeit now (documentation). notes contributing.md is also updated: f122cc5 the link to ""zeit now"" uses filter=next.js and has the following tracking code: utm_source=github utm_medium=readme utm_campaign=next-example ""documentation"" is linked to the recently updated deployment doc for next.js:  the storybook example has slightly different wording because it has different output directory. see: 7caa34e did a more in-depth editing for the stripe typescript example: b384969 @lfades please take a look! </desc> <cmt> find/replace ""deploy it to the cloud..."" </cmt> <cmt> find/replace ""deploy it to the cloud..."" (no colon) </cmt> <cmt> find/replace ""deploy it to the cloud..."" for firebase </cmt> <cmt> convert remaining ones </cmt> <cmt> storybook deployment </cmt> <cmt> update with-stripe-typescript </cmt>",remove now cli reference from examples
2877,"<desc> move all keebio boards into keebio folder update vendor ids to 0xcb10 update code style of all the boards fix various keymaps to build properly update readme files to refer to new folder path checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> move boards into keebio folder </cmt> <cmt> rename keymap </cmt> <cmt> update bdn9 files </cmt> <cmt> update bfo-9000 files </cmt> <cmt> update chocopad files </cmt> <cmt> update dilly files </cmt> <cmt> update fourier files, collapse rev1 into main </cmt> <cmt> update iris files </cmt> <cmt> update laplace files </cmt> <cmt> update levinson files, fix buswerks keymap </cmt> <cmt> update nyquist files </cmt> <cmt> fix keymap issues </cmt> <cmt> update quefrency files </cmt> <cmt> update rorschach files </cmt> <cmt> update tf68 files </cmt> <cmt> update viterbi files </cmt> <cmt> update viterbi files </cmt> <cmt> update wavelet files </cmt> <cmt> reformat default layout </cmt>",move keebio boards to own folder
2878,"<desc> description: dependencies: update pallets/markupsafe (changes from 1.0) and standardize jinja2 versions risk level: low testing: bazel test //test/... and running on local instances docs changes: none required release notes: none required </desc> <cmt> update fmtlib/fmt, grpc, nanopb dependencies. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update pallets/markupsafe dependency and standardize on jinja2 versions. </cmt>",update pallets/markupsafe and standardize jinja2 versions
2879,"<desc> create the grid based on descriptors use moveview instead of addview and removeview. clean up that huge overloaded layout() call. layout should always be as cheap as possible. currently it is doing much more, like adding views when they aren't there or updating their visibility. make sure all view visibilities work make sure all state is saved and restored </desc> <cmt> grid: getviewcachedvisiblesize </cmt> <cmt> fixes #78228 </cmt> <cmt> wip: grid hydration first steps </cmt> <cmt> use more layout state </cmt> <cmt> grid: remember sidebar position </cmt> <cmt> layout: remove layoutgrid </cmt> <cmt> splitview: fix moveview invisible preservation </cmt> <cmt> grid: addviewat, moveviewto </cmt> <cmt> layout: handle sidebar position </cmt> <cmt> layout: remove unnecessary layout call </cmt> <cmt> layout: panel position </cmt> <cmt> restore strange loop </cmt> <cmt> layout: status bar and activity bar parts </cmt>",use grid descriptors for workbench grid layout
2880,"<desc> ansible version ansible 2.5.0 config file = /etc/ansible/ansible.cfg disabled complex list comparison because lists aren't easily comparable when containing dicts and there was still a bug when attempting to gracefully merge two lists containing dicts. this takes into account order of items in the list, but alternative would be to deep compare two lists to check if it contains the same items. this is also not desirable becuase sometimes the order of the list in os resource yaml actually matters. e.g. args field of container. </desc> <cmt> minor fix.  fixes #31196 </cmt> <cmt> disable complex list comparison and merge. fixes #31196 </cmt>",oc module - disable complex list merging. fixes #31196
2881,"<desc> make refreshindictor.onrefresh signature consistent with cupertinorefreshcontrol, the equivalent widget when matching ios platform. it allows to assign the same method for handling the refresh callback whether you start by implementing refreshindictor or cupertinorefreshcontrol; my understanding is since dart 2.0 the preferred way to describe a future returning no value is future<void>; no breaking changes because future<void> f = future<null>.value() is valid. </desc> <cmt> change material refresh indicator onrefresh signature from future<null> to future<void>. </cmt> <cmt> update authors. </cmt>",change material refreshindictor.onrefresh signature from future<null> to future<void>
2882,"<desc> fix no such file or directory when downloading jars. #9540 #9730 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> revert ""revert ""package and upload ray cross-platform jar (#9540)"" (#9730)"" </cmt> <cmt> this reverts commit 7740136b93117561edaf46b82e7e51f56e348ffe. </cmt> <cmt> fix no such file or directory </cmt>",fix package and upload ray jar
2883,"<desc> hello everyone, we got a working prototype that could solve this issue and allow us to support large files (>4gb)! exemple usage: #include ""simdjson/parsedjson.h"" #include ""simdjson/jsonstream.h"" simdjson::padded_string string; simdjson::get_corpus(filename).swap(string); //simdjson::jsonstream js{string}; //simdjson::jsonstream js{string, 1000000}; //simdjson::jsonstream js{string.data(), string.size()}; simdjson::jsonstream js{string.data(), string.size(), 1000000}; //where 1000000 represents the batch_size in bytes. //we load data in batch to speed things up a bit. (default = 1mb) int parse_res = simdjson::success_and_has_more; simdjson::parsedjson pj; //we re-use the same parsedjson as much as possible, to save allocation time. //this loop will run as long as the file contains valid json documents. while (parse_res == simdjson::success_and_has_more) { parse_res = js.json_parse(pj); } implementation the current implementation allows us to parse through large documents faster than the ""simple"" std::getline() alternative.  we still have many ideas to make it even faster, but right now it feels like a good starting point. what kind of file is supported? we opted for a more general case where a file could contain multiple json documents no matter the format, as long as it is json valid. therefore, we are not limited to ndjson and jsonline. we support any file that contains multiple valid json documents. api i would greatly appreciate some feedback.  from my point of view, it seems simple and easy to use, but i'm not an end user! does it fill your needs? is it clear, simple and complete enough? suggestions? @lemire @craiig @jplauri @nichtich #188 #147 #128 #177 cheers </desc> <cmt> rough prototype working.  needs more test and fine tuning. </cmt> <cmt> prototype working on large files. </cmt> <cmt> prototype working on large files. </cmt> <cmt> adding benchmarks </cmt> <cmt> jsonstream api adjustment </cmt>",streams of json documents + large files (>4gb)
2884,"<desc> #37710 attempted to split the tests for @types/ramda into separate files per function, but the pr was too large to be approved on its own. this pr is part of a new piecemeal approach to migrating the tests. i recommend stepping through the pr commit-by-commit to make it easier to check that no individual tests were dropped or changed substantively. this pr is the second of many to move the functions over in a more piecemeal fashion. it continues from the following pr: #38157 [ramda] split tests to separate modules - functions beginning with 'a' i'm splitting out the tests into separate files per function to make it easier to track what is and is not being tested. please read the descriptions for #37710 and #38157 for more details. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> move 'binary' tests to separate file </cmt> <cmt> move 'bind' tests to separate file </cmt> <cmt> move 'both' tests to separate file </cmt> <cmt> move 'chain' tests to separate file </cmt> <cmt> move 'clamp' tests to separate file </cmt> <cmt> move 'clone' tests to separate file </cmt> <cmt> move 'comparator' tests to separate file </cmt> <cmt> move 'complement' tests to separate file </cmt> <cmt> move 'compose' tests to separate file </cmt> <cmt> move 'composek' tests to separate file </cmt> <cmt> move 'composep' tests to separate file </cmt> <cmt> move 'composewith' tests to separate file </cmt> <cmt> move 'concat' tests to separate file </cmt> <cmt> move 'cond' tests to separate file </cmt> <cmt> move 'cond' tests to separate file </cmt> <cmt> move 'construct' tests to separate file </cmt> <cmt> move 'constructn' tests to separate file </cmt> <cmt> move 'contains' tests to separate file </cmt> <cmt> move 'converge' tests to separate file </cmt>",split tests to separate modules - functions beginning with 'b' - 'c'
2885,<desc> this changes validate_symbolsources so that the organizations:custom-symbol-sources flag is only checked if the user is trying to add new sources. deletion is always allowed. </desc> <cmt> fix: let free users remove asc sources </cmt> <cmt> fix logic </cmt>,always allow deletion of custom symbol sources [native-270]
2886,"<desc> this is a pr to add ""assigned attributes"" sections to pipeline components docs, following the pattern established with #8855. this is still a work in progress. new docs. i have submitted the spacy contributor agreement. </desc> <cmt> add textcat docs </cmt> <cmt> add ner docs </cmt>",document assigned attributes of pipeline components
2887,"<desc> fix #3958 #3979 as for array type case, v-model=""model[idx]"" binding uses model[idx]= internally, so the value change could not be reactive. the binding model expression maybe be as follows: test[idx] test[test1[idx]] xxx.test[a[a].test1[idx]] test.xxx.a[""asa""][test1[idx]] test[""a""][idx] so i use a modelparser to parse the model expression to two parts exp and idx, and if the exp is an array type, then use $$exp.splice($$idx, 1, value) </desc> <cmt> fix v-model with array binding </cmt> <cmt> add mutli selects test case </cmt> <cmt> add test case. v-bind with array </cmt> <cmt> add comments </cmt> <cmt> code refactor </cmt> <iss> vue 2.0.3 v-model not updating using an array </iss>","v-model binding with array.  (fix #3958,#3979)"
2888,"<desc> use prefixed macro names for the authoraddress function, support cyrillic characters and remove warnings when generating the pdf doc. the latex package for cyrillic encodings is available thanks to texlive-lang-cyrillic (in texlive-lang-all). </desc> <cmt> bpo-31423: fix building pdf documentation </cmt> <cmt> use prefixed macro names for the authoraddress function. </cmt> <cmt>  </cmt> <cmt> support cyrillic characters in the pdf documentation </cmt> <cmt> add t2a to the font encoding in latex sources. </cmt> <cmt> fix the font size warning when generating the pdf documentation </cmt> <cmt> the font_size sphinx key is deprecated and replaced by pointsize. </cmt>",fix building the pdf documentation
2889,"<desc> proposing a new function rotatedrectangleintersection that performs an intersection test between two rotated rectangles. if an intersection is found it will also return the vertices that make up the intersecting region. i've implemented the c/c++ (python automatic) interface, plus documentation and unit test code. i originally implemented this in conjunction with cv::minarearect to do some blob analysis. this function is useful for collision testing and calculating percentage of overlap. </desc> <cmt> new intersection function for rotated rectangles </cmt> <cmt> fixed ret </cmt> <cmt> changed from isnormal to isfinite, the prev ignored zero </cmt> <cmt> added c interface </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> keep up to date </cmt> <cmt> finished test code, added image to the doc </cmt> <cmt> merge </cmt> <cmt> keeping up to date </cmt> <cmt> added test cpp </cmt>",new rotated rectangle intersection function
2890,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> fix how modules are imported </cmt> <cmt> fix code style -- create type alias for html-minifier options </cmt>,fix imports; add type alias to html-minifier options
2891,"<desc> the ilambda user tree node is no longer necessary with the addition of the ir tree as it was only supporting writing the asm, but had no bearing on semantic checking. this moves the code necessary to build the def lambda recipes into the ir tree since we know that they are correct for compile time and the information necessary to do this is already known by the correct ir nodes. this change also splits up the ir reference nodes into defreferenceinterfacenode, typedinterfacereferencenode, and typedcapturereferencenode which covers all possible cases of known information at compile time for method references. each of these nodes is built by the user tree nodes as necessary. relates #53702 closes #54015 </desc> <cmt> remove statement, use read instead </cmt> <cmt> add tests for not a statement </cmt> <cmt> move isdefoptimized to output instead of as mutable state on the nodes </cmt> <cmt> remove astoreable and give individual nodes responsibility to check </cmt> <cmt> write </cmt> <cmt> clean up write messages and add tests </cmt> <cmt> elimate extraneous new array function reference ir node </cmt> <cmt> switch ir function ref nodes to different types </cmt> <cmt> remove ilambda in favor of ir tree calculating def method call recipe </cmt> <iss> remove remaining mutable state in painless user tree </iss>",remove ilambda user tree node from painless
2892,<desc> adding a new number pad keyboard by draytronics called scarlet. keyboard is described and available here scarlet </desc> <cmt> initial test version of scarlet keyboard </cmt> <cmt> rebase </cmt> <cmt> rebase </cmt> <cmt> first commit of delec scarlet </cmt> <cmt> change to new draytronics branding </cmt> <cmt> update to keyboard details </cmt> <cmt> update to keyboard details and link to draytronics website. </cmt> <cmt> rebase </cmt> <cmt> update kb_scarlet with latest master </cmt>,adding scarlet a number pad keyboard.
2893,<desc> fixes an infinite loop that occurred when generating logarithmic ticks. resolves #3381 also fixes a newly introduced (v2.5.0 dev) bug when the tick marks are not drawn but the labels are. the labels would be offset as if the tick marks were there which was incorrect. </desc> <cmt> fix newly introduced drawing bug when tick marks are not drawn </cmt> <cmt> fix infinite loop in logarithmic tick generation </cmt> <iss> out of memory error when logarithmic y-axis scale includes the range from 7e-11 to 9.999e-11 </iss>,prevent infinite loop while generating logarithmic ticks
2894,<desc> handwired/numpad20: refactor (e30d2c4) layout macro no longer auto-prepends keycodes with kc_ keymaps for this keyboard will now compile in qmk configurator keymap now uses #include qmk_keyboard_h deleted unused fn_actions code block handwired/numpad20: configurator support (0397f65) </desc> <cmt> handwired/numpad20: refactor </cmt> <cmt> - layout macro no longer auto-prepends keycodes with kc_ </cmt> <cmt> - keymaps for this keyboard will now compile in qmk configurator </cmt> <cmt> - keymap now uses #include qmk_keyboard_h </cmt> <cmt> - deleted unused fn_actions code block </cmt> <cmt> handwired/numpad20: configurator support </cmt>,handwired/numpad20 refactor and configurator support
2895,"<desc> this deletes most of the dead tensor code paths, including the tensormethods cwrap and generic/tensor.cpp. this also moves the thnn.cwrap/.cpp generation to generate_code which can use ninja if installed. </desc> <cmt> delete python tensor definitions </cmt> <cmt> clean-up thcpmodule_initextension </cmt> <cmt> * pyobject_setattrstring does not steal a reference </cmt> <cmt> * fix leak of imported module </cmt> <cmt> delete createtensor() in dynamictypes </cmt> <cmt> delete thpmodule_istensor </cmt> <cmt> remove stateless functions on _c module </cmt> <cmt> delete _tensorbase </cmt> <cmt> clean-up module.cpp initialization </cmt> <cmt> fix thcunn </cmt> <cmt> delete generic tensor code </cmt> <cmt> - delete cwrap code for tensor and generation </cmt> <cmt> - move thnn generation to generate_code.py (use ninja) </cmt>",delete dead tensor code paths
2896,"<desc> adding e2e tests for group policy. these tests read the admx to get the registry key path and the value names, and use that to set the policy. this ensures that the client code matches what the policy definition says. the changes include a helper for reading the admx and set the policy, and tests that use the helper to set the policy and validate that the client respects it. note that running these tests will edit (and remove) the registry keys controlling the policy in the machine. although this should be temporary if there is any actual gp set. also in this change: updated version used of microsoft.msix.utils. only difference is that it targets .net standard instead of .net framework, so it doesn't produce a warning when building. renamed some error codes in tests for consistency. microsoft reviewers: open in codeflow </desc> <cmt> add group policy test helper </cmt> <cmt> add e2e tests for group policy </cmt> <cmt> fix errors </cmt> <cmt> fix rebase errors </cmt> <cmt> update names </cmt> <cmt> update file name </cmt>",add group policy e2e tests
2897,"<desc> took me a while to figure out how to trigger self-push github actions test, so documenting how to do it right the first time. @sgugger, @lysandrejik </desc> <cmt> [testing] details of how to start self-push workflow </cmt> <cmt> style </cmt>",how to trigger a self-push workflow
2898,"<desc> this week's documentation merge update for v1.2.0 @jamtur01 @fredlf @ostezer </desc> <cmt> match docs to actual port range used in code. </cmt> <cmt> addresses #7985 </cmt> <cmt> docker-dco-1.1-signed-off-by: phil estes <estesp@linux.vnet.ibm.com> (github: estesp) </cmt> <cmt> (cherry picked from commit d6f4b2ebb40ac79c3ba21e7196bba3b83124cf16) </cmt> <cmt> docker-dco-1.1-signed-off-by: phil estes <estesp@gmail.com> (github: svendowideit) </cmt> <cmt> fixed a typo in docs (outpu -> output). </cmt> <cmt> (cherry picked from commit 7b1fdd6c0460931d458703e175cba157de9b0246) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/reference/api/docker_remote_api_v1.15.md </cmt> <cmt> docker-dco-1.1-signed-off-by: lakshan perera <lakshan@laktek.com> (github: svendowideit) </cmt> <cmt> fixed typo </cmt> <cmt> (cherry picked from commit ef3920278e6a07254a6dcd9502254ed25656d552) </cmt> <cmt> docker-dco-1.1-signed-off-by: marko tibold <marko@tibold.nl> (github: svendowideit) </cmt> <cmt> add notes about single-quotes </cmt> <cmt> (cherry picked from commit b47a2fbdc545d649a945e78a22da0c5dd9df0921) </cmt> <cmt> docker-dco-1.1-signed-off-by: doug davis <dug@us.ibm.com> (github: svendowideit) </cmt> <cmt> docs/reference/api: fix typo in docs </cmt> <cmt> (cherry picked from commit fe5b72e7bb4f7c043409196cb98d46796f2dc390) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/reference/api/docker_remote_api_v1.15.md </cmt> <cmt> docker-dco-1.1-signed-off-by: francisco souza <f@souza.cc> (github: svendowideit) </cmt> <cmt> override prettyprint's colour choice (red) for strings in quotes. </cmt> <cmt> i've moved the docs.css to last so it can tweak any existing css, and </cmt> <cmt> then set that to the same grey colour used for 'normal' text. </cmt> <cmt> while testing i found and fixed an over-zealous line wrap. </cmt> <cmt> docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@docker.com> (github: svendowideit) </cmt> <cmt> (cherry picked from commit df8dbfa45dee108c6bb002f49a5f36e7d911616d) </cmt> <cmt> update remote_api_client_libraries.md </cmt> <cmt> adding docker rust client lib. </cmt> <cmt> (cherry picked from commit c7310b64637ae29a6d7a07b7e533a546e3524654) </cmt> <cmt> docker-dco-1.1-signed-off-by: abhinav ajgaonkar <abhinav316@gmail.com> (github: svendowideit) </cmt> <cmt> modified:   userguide/dockerlinks.md </cmt> <cmt> fixes incorrect environment variable labeling in container linking guide </cmt> <cmt> (cherry picked from commit 78fe117076289695ab03c90d266c47438ab8db7a) </cmt> <cmt> docker-dco-1.1-signed-off-by: david gebler <davidgebler@gmail.com> (github: svendowideit) </cmt> <cmt> http status 201 not 200 </cmt> <cmt> the http status should be 201 not 200. </cmt> <cmt> docker-dco-1.1-signed-off-by: erik kristensen <erik@erikkristensen.com> (github: svendowideit) </cmt> <cmt> (cherry picked from commit c4db3b8075ab4b8bd0c6599cb19e09eb77c82946) </cmt> <cmt> append instead of replace file contents </cmt> <cmt> i think the docker_opts should be appended to /etc/default/docker and not replace the entire contents. </cmt> <cmt> (cherry picked from commit 81357e12e7a019c14d87dc491705ad92409293b7) </cmt> <cmt> docker-dco-1.1-signed-off-by: nicholas e. rabenau <nerab@gmx.at> (github: svendowideit) </cmt> <cmt> docs: shrink images </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> (cherry picked from commit 90dcc7c8405437a10b81e932b49a856502cee626) </cmt> <cmt> docker-dco-1.1-signed-off-by: unclejack <unclejacksons@gmail.com> (github: svendowideit) </cmt> <cmt> docs: change kernel version requirement </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> (cherry picked from commit 0619512582bada62681816e6cb9cdfe01bf2fdec) </cmt> <cmt> docker-dco-1.1-signed-off-by: unclejack <unclejacksons@gmail.com> (github: svendowideit) </cmt> <cmt> help new users if their selinux is not-upgraded yet. </cmt> <cmt> docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@docker.com> (github: svendowideit) </cmt> <cmt> (cherry picked from commit a3f51da98adf27d1f312edac04f0f9863019a8e8) </cmt> <cmt> the default name of the bridge created is called 'docker0'. </cmt> <cmt> (cherry picked from commit 140229677af2cf4865424e535b06440f043e163b) </cmt> <cmt> docker-dco-1.1-signed-off-by: michal jemala <michal.jemala@gmail.com> (github: svendowideit) </cmt> <cmt> added missing 't' from the end of the /images/{{id}}/get eg. </cmt> <cmt> docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@docker.com> (github: svendowideit) </cmt> <cmt> (cherry picked from commit 4352ea7b0a746f00c29fb1170e893242cb8612ef) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/reference/api/docker_remote_api_v1.15.md </cmt> <cmt> consistently use 'sudo docker' in examples </cmt> <cmt> docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@docker.com> (github: svendowideit) </cmt> <cmt> (cherry picked from commit fc9a3b1c1b835c170a4916362855e127a0e366e1) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/articles/registry_mirror.md </cmt> <cmt> docs/sources/reference/commandline/cli.md </cmt> <cmt> add some documentation for the restartpolicy feature. </cmt> <cmt> (cherry picked from commit d758da386a12598533f2388f2887091465c2efd8) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/reference/api/docker_remote_api_v1.15.md </cmt> <cmt> docker-dco-1.1-signed-off-by: jean-paul calderone <exarkun@twistedmatrix.com> (github: svendowideit) </cmt>",post 1.2.0 docs update 5
2899,<desc> in pure ssr mode (ie not nuxt-generate) its not needed to return a full nuxt app on redirecting. a header with location and empty body is plenty enough. while debugging a redirect issue yesterday i was confused by this for a long time because i wasnt expecting the full body to be present so was thinking that it had already rendered the next page. </desc> <cmt> feat(vue-renderer): dont use app.template when redirected </cmt> <cmt> test: redirect on ssr shouldnt return full nuxt app </cmt>,early return render when redirect happens
2900,<desc> commit log handwired/qc60: refactor and configurator update (d96c064) correct layout macro name (layout_ansi_default to layout_ansi_default) add layout data for remaining layout macros correct iso layout macros (neither had a split left shift) refactor layout_iso_alt (place kc_nuhs key on home row; consistent with layout_iso_default) proto.h refactored to use #pragma once include guard handwired/qc60: keymap refactor (a6d8cd9) delete redundant kc_trns and kc_no aliases handwired/qc60: readme update (ff03626) update header (made consistent with qmk template) update docs links (newbs guide; grammar) </desc> <cmt> handwired/qc60: refactor and configurator update </cmt> <cmt> - correct layout macro name (layout_ansi_default to layout_ansi_default) </cmt> <cmt> - add layout data for remaining layout macros </cmt> <cmt> - correct iso layout macros (neither had a split left shift) </cmt> <cmt> - refactor layout_iso_alt (place kc_nuhs key on home row; consistent with layout_iso_default) </cmt> <cmt> - proto.h refactored to use #pragma once include guard </cmt> <cmt> handwired/qc60: keymap refactor </cmt> <cmt> - delete redundant kc_trns and kc_no aliases </cmt> <cmt> handwired/qc60: readme update </cmt> <cmt> - update header (made consistent with qmk template) </cmt> <cmt> - update docs links (newbs guide; grammar) </cmt>,"refactor, configurator update, and readme update"
2901,"<desc> this is a nasty one: in order to fix #63194 and #57019, we needed to set some gfk_pixbuf env for our snap executable (pr from snap team: #70884): vscode/resources/linux/snap/electron-launch lines 24 to 29 d4da283 # gdk-pixbuf loaders export gdk_pixbuf_module_file=""$gdk_cache_dir/gdk-pixbuf-loaders.cache"" export gdk_pixbuf_moduledir=""$snap/usr/lib/$arch/gdk-pixbuf-2.0/2.10.0/loaders"" if [ -f ""$snap/usr/lib/$arch/gdk-pixbuf-2.0/gdk-pixbuf-query-loaders"" ]; then ""$snap/usr/lib/$arch/gdk-pixbuf-2.0/gdk-pixbuf-query-loaders"" > ""$gdk_pixbuf_module_file"" that caused a crash when opening uris in firefox (#85344), so in order to fix that, the snap team recommended we delete that env right after startup: 7d62a5b that now causes a crash when opening any native dialog in vs code in pretty much every linux distribution other than ubuntu (#100940) this pr takes the debacle even further by reverting 7d62a5b and making sure every single shell.openexternal call is wrapped with a unset-set env operation,when running as a linux snap. this hopefully fixes both the issue with firefox as well as the issue with the native dialogs. @bpasero: does the wrapping of shell.openexternal make sense and is it in the right place? @tyriar: does the approach generally make sense to you? i've triggered a build and i have vms ready to verify whether it works, will let you know asap. </desc> <cmt> update hygiene file </cmt> <cmt> snap: do not let gdk_pixbuf leak out </cmt> <cmt> fixes #100940 </cmt> <iss> snap: user fonts are missing </iss>",prevent gdk_pixbuf env from leaking out
2902,<desc> the appstore now requires launch screen to be a storyboard (#5904) which were introduced on ios 8. the new launch screen design is more minimal with the flat libgdx logo over a white background. </desc> <cmt> add launch screen storyboard on robovm backend </cmt> <cmt> replaced old static launchscreen resources on robovm backend </cmt>,replaced static launch screen images by storyboard
2903,"<desc> fix assertions of auto-generated activestorage js correct message on the assert_equal failure test actioncable's js files this commit adds app/javascript/channels/consumer.js, and app/javascript/channels/index.js to default_app_files in order to assert their existance in test_skeleton_is_created. assert no match javascript_pack_tag in application.html.erb since #33079 rails new generates application.html.erb file with javascript_pack_tag instead of javascript_include_tag. note that there some tests that asserting no matching javascript_include_tag in the application.html.erb file for newly generated rails plugins. it is related to #34009 and shouldn't be changed right now. related to #33079 </desc> <cmt> fix assertions of auto-generated activestorage js </cmt> <cmt> since #33079 </cmt> <cmt> correct message on the assert_equal failure </cmt> <cmt> related to #33079 </cmt> <cmt> test actioncable's js files </cmt> <cmt> this commit adds app/javascript/channels/consumer.js, and </cmt> <cmt> app/javascript/channels/index.js to default_app_files in order </cmt> <cmt> to assert their existance in test_skeleton_is_created. </cmt> <cmt> related to #33079 </cmt> <cmt> assert no match javascript_pack_tag in application.html.erb </cmt> <cmt> since #33079 rails new generates application.html.erb file </cmt> <cmt> with javascript_pack_tag instead of javascript_include_tag. </cmt> <cmt> note that there some tests that asserting no matching </cmt> <cmt> javascript_include_tag in the application.html.erb file </cmt> <cmt> for newly generated rails plugins. </cmt> <cmt> it is related to #34009 and shouldn't be changed right now. </cmt>",correct some tests related to changes in #33079
2904,"<desc> this pr adds some apis to give users ability to create window by setting the web page's size (or client size), so users can show the web page with exact same sizes on all platforms. </desc> <cmt> add use-content-size switch. </cmt> <cmt> mac: respect use-content-size when creating window. </cmt> <cmt> use content size in default_app. </cmt> <cmt> get browserwindow::getcontentsize api. </cmt> <cmt> gtk: respect use-content-size when creating window. </cmt> <cmt> add browserwindow::setcontentsize. </cmt> <cmt> gtk: fix setting content size. </cmt> <cmt> add spec on content size. </cmt> <cmt> :lipstick: fix cpplint warning. </cmt> <cmt> win: convert content size to window size. </cmt> <cmt> win: setting menu shouldn't change client area size. </cmt> <cmt> win: implement setcontentsize api. </cmt> <cmt> :memo: document content size related apis. </cmt>",provide ways to control window content's size
2905,"<desc> the aim of this pr was to standarize clicking magnifier action between dashboard filters and native filters. the implementation was created based on how it works for dashboard filers, so using directpathtochild. when users click filter indicator, the list of native filters and dashboard filters are presented. when users click magnifier next to a given dashboard filter, the component gets blue outline. the same should happen with native filters - when magnifier next to native filter is clicked, the given native filter input is focused. this implementation fully supports 'select inputs', as for now in filter bar there is viz_type: 'filter_select' . i have added a small support for range filters (by giving inputref prop), but focusing that type of inputs should be investigated once again when they are widely used. ( connected with issue #12703 after: simple native filter: with cascading popover: test plan verify manually. go to config.py and set ""dashboard_native_filters"": true go to a dashboard and create native filter. click an indicator presented on the charts (dark gray pill with a number). click magnifier and check how native filter input behaves. has associated issue: fixes #12703 requires db migration. confirm db migration upgrade and downgrade tested. @adam-stasiak could you test it? @junlin </desc> <cmt> add direct path to child to native filter components </cmt> <cmt> implement focus for cascading filters </cmt> <cmt> remove empty line </cmt> <iss> [dashboard]connect filter indicator magnifier with filter bar </iss>",connect indicator magnifier with filter bar
2906,"<desc> the logic behind the camper news email notifications now fits these requirements: as a person who posted the story, i want to receive a notification when someone comments on it. as a person who comments on a story, i want to receive a notification if someone replies to my comment. as a person receiving such a notification email, i can see who commented and click a link to go directly to the story. </desc> <cmt> trivial change for example </cmt> <cmt> conflicts: </cmt> <cmt> readme.md </cmt> <cmt> fix camper news email notification logic </cmt>",fixes #352 - camper news email notification
2907,"<desc> this pr adds support for ingress paths in sonarqube fixes #13257 i thought it might be useful to also automatically configure a few other properties in values.yaml, namely the sonarwebcontext in the liveness/readiness probes and extraenv: sonar.web.context, if an ingress path (other than the root /) is configured.  however, i didn't want to overcomplicate the pr or make superfluous changes without asking seeing as this pr was created to address an issue i created. dco signed </desc> <cmt> modify ingress template to be easier to --set </cmt> <cmt> update readme </cmt> <cmt> updated tls to match new ingress format </cmt> <cmt> fix trailing spaces </cmt> <cmt> additional readme info </cmt> <cmt> modified ingress template to allow path configuration.  bumped major version to reflect incompatible api change. </cmt> <cmt> sync fork </cmt> <iss> [stable/sonarqube] support ingress path configuration </iss>",ingress path configuration for sonarqube
2908,"<desc> currently, the users of the abstractstreamoperator class, are expected to complete the writing of rawkeyedoperatorstate and rawoperatorstate in the synchronous part of a snapshot (before the completion of snapshotstate method) but sometimes it is desirable to snapshot a custom data structure asynchronously (i.e. out side of the snapshotstate method) in a similar way that the other state backends allow. this pr adds the ability to suspend the closing of the raw states streams in snapshotstate outside of the snapshotstate method, and hence effectively support async snapshots for raw states. flink snapshotting logic already supports splitting the snapshot to sync and async parts for the various state backends, therefore the changes introduced in this pr mainly reuse that logic. add an interruptible close method to resourceguard (the default is still uninterruptible). add and use a resourceguard in nonclosingcheckpointoutputstream. modify the statesnapshotcontextsynchronousimpl#getraw*operatorstateoutput   to return a future that completes after all the leases were released. this change is already covered by existing tests. the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, yarn/mesos, zookeeper: (yes / no / don't know) </desc> <cmt> [flink-13326] add closeinterruptibly() </cmt> <cmt> [flink-13326] use resourceguard in nonclosingcheckpointstream </cmt> <cmt> this commit adds the ability for users to indicate to flink that the </cmt> <cmt> keyedstatecheckpointoutputstream / operatorstatecheckpointoutputstream should be closed </cmt> <cmt> at some point later in time. previously it was expected to be closed within the synchrouns </cmt> <cmt> part of abstractstreamoperator#snapshotstate. </cmt> <cmt> users might call keyedstatecheckpointoutputstream#acquirelease(), and at some point </cmt> <cmt> in the future might release the least. once the number of leases reaches 0, the stream </cmt> <cmt> would be closed. </cmt> <cmt> [flink-13326] support async rawstate checkpointing </cmt> <cmt> this commit adds the ability for users to obtain a lease for the </cmt> <cmt> rawoperator/rawkeyed output streams, during the synchronous part </cmt> <cmt> of a snapshot, thus preventing these streaming to close. </cmt>",support asynchronous writing to raw operator (and raw keyed) state
2909,<desc> this pr changes the way the argument object is created by 'convert parameters to destructured object' when refactoring a function call. when creating a property assignment of the argument object we now use shorthand property assignments when possible. this pr also adjusts the refactoring so that it is not offered on a function's jsdoc comment. </desc> <cmt> create shorthand property assignment in argument object when possible </cmt> <cmt> add shorthand property assignment test </cmt> <cmt> don't offer refactor on jsdoc comment </cmt> <cmt> add jsdoc test </cmt> <cmt> improve jsdoc test </cmt>,use shorthand property assignment in convert parameters to object
2910,"<desc> the spec file gets processed by configure, the version will be filled in automatically. to generate an rpm make sure to install rpm-build, then ""configure"" as you would usually do, run ""make dist"", then process the generated tarball with rpmbuild: rpmbuild -tb tox-0.0.0.tar.gz this will produce a tox and tox-devel package. i did not handle the dht daemon yet but i can add it if needed. tested on fedora 22. </desc> <cmt> fix dist target </cmt> <cmt> modify tar options to allow extra long filen and directory names, if not set </cmt> <cmt> souces under toxencryptsave might not end up in the tarball. </cmt> <cmt> add readme.md to the dist tarball </cmt> <cmt> add spec file for rpm generation </cmt> <cmt> the spec file gets processed by configure, the version will be filled </cmt> <cmt> in automatically. </cmt> <cmt> to generate an rpm make sure to install rpm-build, then ""configure"" as you </cmt> <cmt> would usually do, run ""make dist"", then process the generated tarball </cmt> <cmt> with rpmbuild: </cmt> <cmt> rpmbuild -tb tox-0.0.0.tar.gz </cmt> <cmt> tested on fedora 22. </cmt>",add spec file for rpm packaging
2911,"<desc> we were giving it an empty value, which shouldn't happen, ever - so now we set the window object as this value and enforce explicitly setting a this value when calling interpreter::call() by making this_value a required argument. also add a simple demo for setinterval() as we had nothing to showcase it :^) </desc> <cmt> libweb: set window object as this value in set{interval,timeout}() </cmt> <cmt> libjs: make interpreter::call() this_value a required argument </cmt> <cmt> right now the default is an empty value, which we accidentally exposed </cmt> <cmt> in set{interval,timeout}() by not providing a custom this value, which </cmt> <cmt> should't happen at all. let's just make it a required argument instead. </cmt> <cmt> base: add simple setinterval() test </cmt>","fix set{interval,timout}() callback this value"
2912,"<desc> backporting #4958 since we changed pipeline images since 0.61, i'm going to assume that if ci builds we're good to go :) microsoft reviewers: open in codeflow </desc> <cmt> work around vs16.5-16.6 regression in uwp packaging </cmt> <cmt> change files </cmt>",workaround for uwp packaging vs 16.5-16.6 regression backport to 0.61
2913,<desc> fixes #24952 fixes #25088 ensure fuchsia entrypoint allows passing device name and target </desc> <cmt> allow passing device argument for fuchsia attach </cmt> <cmt> add all commited code </cmt> <iss> fuchsia entrypoint for flutter tool should only scan for fuchsia devices </iss> <iss> flutter_attach requires a configurable target parameter </iss>,fuchsia multiple devices and target
2914,"<desc> 1.because the lua binding of the registerscripthandler and unregisterscripthandler of the skeletonanimation will override the lua binding of the registerscripthandler and unregisterscripthandler of the node,so rename registerscripthandler to registerspineeventhandler and unregisterscripthandler to registerspineeventhandler 2.fix:resolve the compile error of the cast_type on vs </desc> <cmt> issue #3863:rename the lua binding of the registerscripthandler and unregisterscripthandler of the skeletonanimation </cmt> <cmt> fix:resolve the compile error of the cast_type on vs </cmt>",issue #3863:rename the lua binding of the registerscripthandler and  unregisterscripthandler of the skeletonanimation
2915,"<desc> here's another round of clean ups, after the latest fixes that has taken place fix rpm build, after latest changes we need to pull netdata.spec in from the temporary location enable auto-build of available i386 packages sync distributions support matrix with a few misses and changes, after the latest round of bug fixes component name netdata/packaging netdata/doc n/a </desc> <cmt> netdata/packaging:[ci skip] bring over netdata.spec before removing the temp directory. we need it to resume rpm workflow </cmt> <cmt> [package amd64 deb] package build stable test </cmt> <cmt> netdata/packaging:[ci skip] add branch for testing </cmt> <cmt> [package amd64 deb] package build stable test </cmt> <cmt> [package i386 deb] package build stable test </cmt> <cmt> [package i386 deb] package build stable test </cmt> <cmt> [package amd64 deb] package build stable test </cmt> <cmt> [package i386 deb] package build stable test </cmt> <cmt> [package amd64 rpm] package build stable test </cmt> <cmt> [package i386 rpm] package build stable test </cmt> <cmt> netdata/doc: update distro support, due to lxc limitations we dont have those yet </cmt> <cmt> [package i386 rpm] package build stable test </cmt> <cmt> [package i386 rpm enterprise linux] package build stable test </cmt> <cmt> netdata/ci:[ci skip] yes, we must test rpm too </cmt> <cmt> [package i386 rpm] package build stable test </cmt> <cmt> [package amd64 rpm] package build stable test </cmt> <cmt> netdata/packaging:[ci skip] add i386 rpm and deb distro triggers </cmt> <cmt> netdata/packaging: [ci skip] remove the test branch info </cmt> <cmt> netdata/doc: [ci skip] fix doc </cmt> <cmt> netdata/doc: [ci skip] update doc more </cmt>",nits and fixes for packaging
2916,"<desc> what did you implement documentation on added support for python in the serverless framework pro ci/cd and a note about using package.json scripts for running scripts before/after tests and install. how can we verify it just docs, nothing executable to verify. i added rowell as reviewer to check for accuracy. </desc> <cmt> note on also supporting python in ci/cd </cmt> <cmt> details on installing requirements and running tests </cmt> <cmt> using the npm-scripts to run lifecycle hooks </cmt>",add docs on python support in ci/cd
2917,<desc> fixes #30502. this bug was one of the causes of the recent release of prettier 2.1.1 example type f1 = (num: [number])=>void; type isnumber<t extends number> = t; type t1 = f1 extends (...args: (infer t)) => void ? t : never; type t2 = f1 extends (args: [...(infer t)]) => void ? t : never; type t3<t> = t extends isnumber<(infer n)> ? true : false; current behavior test.ts:5:23 - error ts2370: a rest parameter must be of an array type. 5 type t1 = f1 extends (...args: (infer t)) => void ? t : never; ~~~~~~~~~~~~~~~~~~ test.ts:7:30 - error ts2574: a rest element type must be an array type. 7 type t2 = f1 extends (args: [...(infer t)]) => void ? t : never; ~~~~~~~~~~~~ test.ts:8:33 - error ts2344: type 'n' does not satisfy the constraint 'number'. 8 type t3<t> = t extends isnumber<(infer n)> ? true : false; ~~~~~~~~~ found 3 errors. new behavior no errors. </desc> <cmt> add tests </cmt> <cmt> consider parenthesized types in getinferredtypeparameterconstraint </cmt> <cmt> update tests </cmt> <iss> parentheses around `infer t` in rest parameter position leads to an error </iss>,fix missing constraints for parenthesized infer t
2918,"<desc> update basic fee-based tests to match doge, eliminate those which do not directly map to the doge fee schedule (to re-evaluate in a later release). </desc> <cmt> change amount tests to use rounded values </cmt> <cmt> disable legacy tests </cmt>",update or eliminate remaining tests
2919,"<desc> this pr fixes head masking for the cross-attention module in the following models: blenderbot_small, fsmt, led, m2m_100, mbart, pegasus. this pr also contains slight changes in docstrings so that it will be clear that head_mask is related to the config of an encoder and the shape of decoder_head_mask and cross_head_mask depends on the config of a decoder. this pr enables test_headmasking for m2m_100 model. reviewers: @patrickvonplaten @patil-suraj fixes: #10540 </desc> <cmt> fix cross-attention head mask for torch bart models </cmt> <cmt> * fix head masking for cross-attention module for the following </cmt> <cmt> models: bart, blenderbot, blenderbot_small, m2m_100, marian, mbart, </cmt> <cmt> pegasus </cmt> <cmt> * enable test_headmasking for m2m_100 model </cmt> <iss> bug in attention head mask for cross-attention module in encoder-decoder models </iss>",fix cross-attention head mask for torch encoder-decoder models
2920,"<desc> fixes warning messages like the below examples when using helm 2. warning: merging destination map for chart 'datadog'. the destination item 'confd' is a table and ignoring the source 'confd' as it has a non-table value of: <nil> warning: merging destination map for chart 'datadog'. the destination item 'resources' is a table and ignoring the source 'resources' as it has a non-table value of: <nil> (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #22428 dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> merge upstream </cmt> <cmt> pull upstream updates </cmt> <iss> [stable/datadog] warnings with v2 chart and helm 2.x </iss>","fixes ""merging map"" warning messages with helm 2"
2921,"<desc> core.construction intended for code to be shared between pd.array, series.__init__, and index.__new__.  the module should not need to be internals-aware. this only moves array and extract_array to keep the diff contained.  the next step would be to move internals.construction.sanitize_array, which is used in a number of non-internals places and satisfies the not-internals-aware condition. several functions from core.dtypes.cast would also make more sense here than in their current locations. update moved sanitize_array too, and updated imports </desc> <cmt> move array, extract_array to pd.core.construction </cmt> <cmt> put construction.py in the correct branch </cmt> <cmt> whitespace fixup </cmt> <cmt> de-runtime imports </cmt> <cmt> isort </cmt>",implement module for shared constructor functions
2922,"<desc> when using the copy module dest was only added to the result if the file checksum changed. fixes #31477 copy ansible version ansible 2.5.0 (copy_dest a0f7715187) last updated 2018/02/04 13:03:50 (gmt +200) config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/tomek/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/tomek/ansible/lib/ansible executable location = /home/tomek/ansible/bin/ansible python version = 2.7.14 (default, sep 23 2017, 22:06:14) [gcc 7.2.0] </desc> <cmt> copy tests: check the result of non-changing copy </cmt> <cmt> fix for #31477: return 'dest' from copy when file wasn't changed </cmt> <iss> incompatible change in copy resultset in 2.4 </iss>","""dest"" missing in copy result"
2923,"<desc> bumps opentelemetry version to 1.1.0. adds setup_tracing function to be used for integration with grafana tempo. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> modify enable_tracing </cmt> <cmt> add console span exporter </cmt> <cmt> update </cmt> <cmt> deprecate </cmt> <cmt> update version, bugs </cmt> <cmt> fix propagator </cmt> <cmt> delete comment </cmt>",bump opentelemetry version & bug fix
2924,<desc> i have followed (at least) the pr section of the contributing guide. fixes #28866 . codesandbox but i have no idea why clicking on the link does not redirect to home. i investigated a lot. </desc> <cmt> docs: fix createtheme syntax in global theme link demo </cmt> <iss> instructions for replacing default route component using typescript are incorrect </iss>,fix global theme link demo
2925,"<desc> issue #269 added length of lis solution in python </desc> <cmt> updating forked repo (#1) </cmt> <cmt> * header comment added </cmt> <cmt> * kruskal.cpp </cmt> <cmt> * adding c implementation </cmt> <cmt> * created new category </cmt> <cmt> * create magic_square.cpp </cmt> <cmt> * add radix_sort.go </cmt> <cmt> * rename kruskal.cpp to kruskal_minimum_spanning_tree.cpp </cmt> <cmt> * adding kruskal mst implementation in c </cmt> <cmt> * header comment added </cmt> <cmt> * stack implementation via go </cmt> <cmt> * titlingdynamicprog </cmt> <cmt> * adding magic square implementation in c </cmt> <cmt> * binary search tree in c </cmt> <cmt> * create exponentiation_by_squaring.cpp </cmt> <cmt> * delete exponentiation_by_squaring.cpp </cmt> <cmt> * added python code for lonely integer problem </cmt> <cmt> * header comment added </cmt> <cmt> * added the python code for ford-fulkerson algorithm </cmt> <cmt> * update magic_square.cpp </cmt> <cmt> * create exponentiation_by_squaring.cpp </cmt> <cmt> * adding minimum coins in javascript </cmt> <cmt> * delete magic_square.cpp </cmt> <cmt> * added queue implementation in c using linked lists </cmt> <cmt> * added edit distance in golang </cmt> <cmt> * added exponentation power in c </cmt> <cmt> * code for the lonely integer problem in python </cmt> <cmt> * added queue implementation in c using linked lists closes:#284 </cmt> <cmt> * fixed the algo </cmt> <cmt> works using recursion </cmt> <cmt> * longestbitonicseq in c++ </cmt> <cmt> * add catalan number java language </cmt> <cmt> * ai tsp added with test cases </cmt> <cmt> * exponent using square in java </cmt> <cmt> added algorithm to find exponent by squaring in java. </cmt> <cmt> * added main function </cmt> <cmt> * adding exponentiation by squaring in python </cmt> <cmt> * lonelyinteger in javascript </cmt> <cmt> * create fibonacci numbers in c </cmt> <cmt> * lonelyint in java </cmt> <cmt> * create catalan_number.cpp </cmt> <cmt> * delete magic_square.cpp </cmt> <cmt> * add sleep_sort in folder </cmt> <cmt> * add in folder </cmt> <cmt> * adding catalan number implementation in c </cmt> <cmt> * header comment added </cmt> <cmt> * header comment added </cmt> <cmt> * add files via upload </cmt> <cmt> * add files via upload </cmt> <cmt> * rename ford-fulkerson.cpp to ford_fulkerson_using_bfs.cpp </cmt> <cmt> * create leftistpriorityqueue.cpp </cmt> <cmt> * fixes several gcc warnings, typos and style issues </cmt> <cmt> * added fermat test </cmt> <cmt> closes: #265 </cmt> <cmt> * implementation of catlan number in scala </cmt> <cmt> catlan number in scala #300 </cmt> <cmt> * create binary_search_tree.c </cmt> <cmt> successfully added binary search tree in c. </cmt> <cmt> please take a look and merge, thanks. </cmt> <cmt> * changed the name of the file ford_fulkerson.py to ford_fulkerson_using_bfs.py </cmt> <cmt> * armstrong number </cmt> <cmt> * chnaged the name of ford_fulkerson.py and removed the old file </cmt> <cmt> * header comment added </cmt> <cmt> * added merge.js file by dhanush13-c </cmt> <cmt> * added merge_sort.js file by dhanush13-c </cmt> <cmt> * adding minimum coins in java </cmt> <cmt> * adds a readme.md to binary search </cmt> <cmt> * header comment added </cmt> <cmt> * header comment added </cmt> <cmt> * huffman coding initial commit </cmt> <cmt> * header comment added </cmt> <cmt> * create inversionusingdandc.cpp </cmt> <cmt> * revert ""binary search in python"" </cmt> <cmt> this reverts commit e032679299ecde3b3685df30113706cc1bd268f1. </cmt> <cmt> * revert ""adds a readme.md to binary search"" </cmt> <cmt> this reverts commit 33cc2a228da713dc8314dc27fa9633605bd3c66f. </cmt> <cmt> * revert ""revert ""binary search in python"""" because for some reason i reverted the wrong commit </cmt> <cmt> this reverts commit fc759a7f354c62d75428e623d6bcbcfdf5d3faf1. </cmt> <cmt> * added the code for 2 unique numbers in an array </cmt> <cmt> * first n catalan numbers using dynamic programming </cmt> <cmt> a simple self explanatory c++ program to print n catalan numbers using dynamic programming! </cmt> <cmt> kudos! </cmt> <cmt> * segment trees in java </cmt> <cmt> * header comment added </cmt> <cmt> * update readme.md </cmt> <cmt> * add linear search info to readme.md </cmt> <cmt> * int return main </cmt> <cmt> * header comment added </cmt> <cmt> * add info to binary search readme.md </cmt> <cmt> * add info to binary search readme.md </cmt> <cmt> * added input values </cmt> <cmt> for easy understability i have inserted test values and displayed the result. </cmt> <cmt> * added permutations of string in cpp </cmt> <cmt> * rearranging and cleaning </cmt> <cmt> * fixed location </cmt> <cmt> * added hashtable in java </cmt> <cmt> implementation of hashtable in java using array of linked lists with functions like get, put, remove etc. </cmt> <cmt> * header comment added, removed link </cmt> <cmt> * create binary search tree height(max depth).cpp </cmt> <cmt> a binary tree implementation in c++ for insertion of nodes and finding the depth(height) of the bst </cmt> <cmt> * adding binary search on golang </cmt> <cmt> * added code for bstheight in python </cmt> <cmt> * header and footer added </cmt> <cmt> * footer added </cmt> <cmt> * updated code for bstheight in python </cmt> <cmt> * footer added </cmt> <cmt> * add algorithm x </cmt> <cmt> * amicable numbers.cpp </cmt> <cmt> program to calculate amicable numbers under 10000 and find sum. </cmt> <cmt> an amicable pair of numbers consists of two different integers where the sum of the divisors of the first integer is equal to the second integer, and the sum of the divisors of the second integer is equal to the first integer. </cmt> <cmt> * added insertion.rs file </cmt> <cmt> an insert sort program in rust. </cmt> <cmt> * adding description in readme.md for the bubble sort algorighm </cmt> <cmt> * add missing footer in bubble sort readme.md </cmt> <cmt> * inversion count using divide and conquer approach </cmt> <cmt> inversion count of the array is calculated using merge sort </cmt> <cmt> * added merge_sort.php </cmt> <cmt> a php program for merge sort. </cmt> <cmt> o (n log n) comparison-based sorting algorithm. </cmt> <cmt> * add a c++ bridge and articulation points in graph </cmt> <cmt> * added c# mergesort </cmt> <cmt> * adding minimum coins in python </cmt> <cmt> * added c# heapsort </cmt> <cmt> * adding minimum coins in c++ and small fixes on python version </cmt> <cmt> * added merge sort in php </cmt> <cmt> * adding insertion_sort on golang </cmt> <cmt> * catalan no programs </cmt> <cmt> * added code for fibonacci number in scala </cmt> <cmt> #311 </cmt> <cmt> * python imp for queue using ll </cmt> <cmt> * update fibonacci.scala </cmt> <cmt> * adds ruby fibonacci </cmt> <cmt> * adds python fibonacci </cmt> <cmt> * added catlan number in python </cmt> <cmt> * fixes indentation </cmt> <cmt> * adds erlang fibonacci </cmt> <cmt> * find height of bst in c </cmt> <cmt> * java binarytree: added generics and fixed methods that should be private. also changed the name of the class to the name of the file </cmt> <cmt> * adding pascal_triangle.cpp and horner_polynomial_evaluation. </cmt> <cmt> * add subset sum generation solution in c++ </cmt> <cmt> * remove .ds_store; add readme.md </cmt> <cmt> * delete .ds_store </cmt> <cmt> * create merge sort.php </cmt> <cmt> * added insertion sort for php </cmt> <cmt> * adding segment tree - range minimum query - o(n*logn) </cmt> <cmt> * added bubble sort for php </cmt> <cmt> * addding subset sum implementation in c </cmt> <cmt> * create egyptian_fraction.cpp </cmt> <cmt> * added morse translator </cmt> <cmt> added the python implementation for morse code translator </cmt> <cmt> closes: #314 </cmt> <cmt> * added bucket sort php </cmt> <cmt> * binary search in swift </cmt> <cmt> * fixed std namespace </cmt> <cmt> * header comment added </cmt> <cmt> * removed package </cmt> <cmt> * header comment added </cmt> <cmt> * fixed folder name </cmt> <cmt> * fixed name </cmt> <cmt> * added bst implementation in ruby. </cmt> <cmt> * header comment added </cmt> <cmt> * fixed location </cmt> <cmt> * fixed name </cmt> <cmt> * header comment added </cmt> <cmt> * header comment added </cmt> <cmt> * changing dir for catallan number programs </cmt> <cmt> * added effective code for trie insetion and search in c++ </cmt> <cmt> * added nth magic number program in cpp </cmt> <cmt> * fixed typo </cmt> <cmt> * renamed contributors.md </cmt> <cmt> * automorphic numbers </cmt> <cmt> * header comment added </cmt> <cmt> * heigt of bst in c </cmt> <cmt> * header comment added </cmt> <cmt> * header comment added </cmt> <cmt> * fixed location </cmt> <cmt> * fixed location </cmt> <cmt> added longest increasing subsequence solution in python </cmt>",added longest increasing subsequence in python
2926,"<desc> i find that openml fetcher code is currently very difficult to read, there is a bunch of private functions with undocumented signatures and manipulating objects with non trivial types. this pr adds some type annotations for function signatures, to at least make it a bit clearer what is the expected function input and output. i'll contribute some of it to liac-arff upstream as soon as it drops python 2 support renatopp/liac-arff#107 </desc> <cmt> type annotations for openml fetcher </cmt> <cmt> more types </cmt> <cmt> fix merge conflicts </cmt> <cmt> more fixes </cmt>",mnt add type annotations for openml fetcher
2927,"<desc> close #12590 the edited action will be added for the issueevent and pullrequestevent. i have reviewed my changes in staging (look for ""automatically generated comment"" and click modified to view your latest changes). for content changes, i have completed the self-review checklist. </desc> <cmt> update pull_request_event_api_properties.md </cmt> <cmt> update issue_event_api_properties.md </cmt> <iss> the issue_event_api_properties.md and pull_request_event_api_properties.md lose the edited action. </iss>",patch the missing edited action type for xxx_event_api_properties.md
2928,"<desc> a ramps (or smart ramps) board with tmp2209 drivers used in uart mode requires serial pins.  hardware ones are available on ramps aux-4 header for pins 18 and 17.  serial1 (arduino pins d18 and d19) pins are already used on ramps z-min and z-max pins. mega2560 or due with ramps or smart ramps boards. working tmc drivers in uart mode!  also, allowing use of mega 2560 with smart ramps and the typical azsmz 12864 lcd. cons: note that display azsmz 12864 lcd has option for wifi on it.  not commonly populated but if it were there, it would also want to use pins 18 and 17 on the aux-4 header (these pins are routed to aux-3 header also). one must choose, tmc uart or wifi module for the last free hardware serial port.  i suggest this configuration is more common. configuration for testing this change is available at </desc> <cmt> mega 2560 can be used with smart ramps 1.4 </cmt> <cmt> uart with tmc220x drivers should be serial2 for ramps </cmt>",fix azsmz_12864 on smart ramps with mega2560
2929,"<desc> this commit is related to #73497. it adds two new settings. the first setting is transport.compression_scheme. this setting allows the user to configure lz4 or deflate as the transport compression. additionally, it modifies transport.compress to support the value indexing_data. when this setting is set to indexing_data  only messages which are primarily composed of raw source data will be compressed. this is bulk, operations recovery, and shard changes messages. </desc> <cmt> initial </cmt> <cmt> changes </cmt> <cmt> changes </cmt> <cmt> changes </cmt>",add additional transport compression options
2930,"<desc> proposed fix for #5879 . wimlds scikit-learn sprint. also fixed docstring for latentdirichletallocation. topic_word_prior should be eta, not beta. </desc> <cmt> add lda model doc update </cmt> <cmt> lda doc update 2 </cmt> <cmt> lda doc update 3 </cmt> <cmt> lda doc add new lines </cmt> <cmt> lda doc add new lines </cmt> <cmt> lda doc add new lines </cmt> <cmt> lda doc update image file name </cmt> <cmt> lda doc update 4 </cmt> <cmt> lda doc update 5 </cmt> <cmt> lda doc update 6 </cmt>",add parameter descriptions and additional documentation for lda model
2931,"<desc> use black for auto-formatting remove unused imports resolve duplicate test function names make tests compatible with pytest 4.0 i have submitted the spacy contributor agreement. </desc> <cmt> auto-format tests with black </cmt> <cmt> add flake8 config </cmt> <cmt> tidy up and remove unused imports </cmt> <cmt> fix redefinitions of test functions </cmt> <cmt> replace orths_and_spaces with words and spaces </cmt> <cmt> fix compatibility with pytest 4.0 </cmt> <cmt> xfail test for now </cmt> <cmt> test was previously overwritten by following test due to naming conflict, so failure wasn't reported </cmt> <cmt> unfail passing test </cmt>",tidy up and auto-format tests
2932,<desc> we need to use swift calling convention when dealing with boxpair on s390x. boxpair is expected to be returned in 2 registers but there is no native c type that is returned in two registers by the default abi on s390x. the second commit fixes the way enum payloads are packed for big endian order. (same fix already merged on master: #12778) both of these commits resolve test failures on s390x therefore no new test cases are added. </desc> <cmt> fix packing enum payloads on big endian </cmt> <cmt> use swift calling convention for boxpair on s390x </cmt>,fix enum payload on big endian
2933,"<desc> thanks @fk for spotting inconsistencies also adjusting cli help to use shortened link </desc> <cmt> doc: use opentracing name, not ""open tracing"" </cmt> <cmt> use shortened link </cmt> <cmt> don't change readme - that's fine - just change cli </cmt>",fix opentracing name usage inconstistencies
2934,"<desc> introduces%{delivery-rate}x that maps to tcp_info::tcpi_delivery_rate when tcp is used, or to quicly_delivery_rate_t::delivery_rate.latest when quic is used. also adds missing / new fields %{http3.stats}x to, including delivery-rate.latest, delivery-rate.smoothed, delivery-rate.variance. incorporates h2o/quicly#486 </desc> <cmt> [access-log] %{delivery-rate}x to report tcp_info.delivery_rate </cmt> <cmt> extract </cmt> <cmt> update project files </cmt> <cmt> [access-log] %{delivery-rate}x to report h3 delivery rate </cmt> <cmt> add new fields for %{http3.stats}x </cmt>",expose delivery rate to log
2935,"<desc> what do these changes do? this flushes all uncommitted tasks from the local lineage cache to the gcs after a node failure. this is to guarantee that all tasks are eventually flushed. follow-up to #4359, closes #4958. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add method to flush all uncommitted tasks from the lineage cache </cmt> <cmt> flush all uncommitted tasks on node failure </cmt> <cmt> add test case and unsubscribe before committing </cmt> <iss> flush lineage cache after a node failure </iss>",flush all tasks from local lineage cache after a node failure
2936,"<desc> issue:   #415 description:   our new mediafilemanager stores files for serving via http, but doesn't have any limits on how long those files will be kept. this pr introduces memory management for the mediafilemanager in the form of tracking which reportsession is using which files.  when all references to the files being used by different reportsession ids run out, those files are removed from the cache. to accomplish this, some piping of the reportsession id is done in scriptrunner and reportthread using the report_session_id attribute / keyword. </desc> <cmt> mediafile.refcount attrib counts down usages. route deletes at ref < 1. </cmt> <cmt> linting </cmt> <cmt> added questioning comment for placemarker </cmt>",expire media files when reportsession expires
2937,"<desc> when clickhouse-client is used in interactive mode with multiline queries, single line comment was erronously extended till the end of query. this fixes #13654. </desc> <cmt> fix parsing of multiline queries in interactive mode #13654 </cmt> <cmt> add a test </cmt> <iss> client interactive mode line comments (-- ) does not work anymore. </iss>",fix multiline queries with comments in interactive mode
2938,<desc> the image generation was complicated by several python dependencies. v1.36.1 includes a patch to core directpath #25569; v1.36.2 includes some infra fixes; v1.36.3 includes #25690 and infra fixes. </desc> <cmt> add 1.36.2 to interop matrix </cmt> <cmt> add v1.36.3 to the interop matrix </cmt>,add grpc 1.36.3 to the interop matrix
2939,"<desc> in order to enable or disable unreliable tests without making code changes (and thus, pull requests), we should annotate problematic tests so they can be filtered out by the azure devops build task. currently, vstest doesn't support filtering by custom arbitrary attributes (see microsoft/vstest#1763), so we use the owner attribute as follows: vstest.host.exe <path\to\test.dll> /testcasefilter:owner!=unstable microsoft reviewers: open in codeflow </desc> <cmt> mark rntesterintegrationtests::websocket as unstable. </cmt> <cmt> update azure devops tasks. </cmt>",set filtering metadata for rntesterintegrationtests::websocket
2940,"<desc> i apologize in advance, i realize how big of a pull request this is so i hope it isn't a pain to deal with. this is my first pull request ever, so please bare with me. added isy994 component for pulling in switches, sensors, and lights from isy994 lighting controllers. i think this one was rather straight forward and didn't involve anything too out of the box. added pyisy library to the requirements.txt file. created the ability to hide state cards in the frontend. individual components may, but don't have to, create suggestions to ha on if the card should be hidden. this is done by setting a _hidden property in the entity class. if no suggestion is made, it is assumed visible. then, the following attributes can be added to the configuration file: homeassistant: # control visibility of entity cards visibility: - sensor.forecast_snow                     : hide  #     forecast snow light.all_on_3                           : hide  #     all on light.foyer_2                            : show  #     foyer comments are obviously not needed. each entity can be set to either hide or show. this value overwrites the suggestion made by the component. groups were updated to support this feature as well. in order for this to be supported, the entity must inherit the entity helper class (sun, for example, doesn't inherit it and therefore is not supported). this feature was vital with the isy994 component as it imports many parameters (mine is somewhere around 100). while i was poking around the frontend, i also fixed the apple-touch icon so now iphones will have the pretty icon on their home screens when docking this web app. created a get_entities.py script in the scripts folder. this script will get all the entities from a running home assistant server and output them and any specified attributes in a pretty table to the stdout. this is extremely useful for manually hiding and showing components. let me know what you think, and, again, sorry for such a large pull request. </desc> <cmt> added isy994 weather data as sensors. </cmt> <cmt> addded light controls to isy994 component. </cmt> <cmt> cleaned up isy994 light and sensor code to use the same abstract class. </cmt> <cmt> added not dimming insteon devices on an isy controller as switches. </cmt> <cmt> added support for the creation of custom switches using the isy994 device. </cmt> <cmt> added custom program sensors to the isy994 component. </cmt> <cmt> added hidden_string and sensor_string properties to the isy994 configuration to allow nodes to be hidden and to be handled as sensors. implimented the sensor_string. any node name that contains the sensor_string in its name will be treated as a sensor instead of a switch or light. the hidden_string will be implimented later. </cmt> <cmt> updated the broken link to the apple-touch icon in the frontend. </cmt> <cmt> 1) added basic back-end framework for supporting hidden entities. 2) enabled hidden suggestions in the isy994 component entities. </cmt> <cmt> quick fix to the comparison to validate if an entity is hidden. </cmt> <cmt> added state card hiding to the state view on the frontend. </cmt> <cmt> 1) performed many pylint and flake8 fixes to clean up isy994 integration and hidden entities addition. 2) added necessary code to allow groups to also be hidden. 3) made most of the weather data from the isy994 component be hidden by default. </cmt> <cmt> updated isy994 component to hide any device with the hidden string in its ancestry. </cmt> <cmt> forced the isy994 component to treat underscores as spaces. </cmt> <cmt> added a script for listing entities in running home assistant server. usefule for creating visibility list in configuration file. </cmt> <cmt> on second thought, make that script use the specified order, not a sorted order. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> updated contributing documentation to include details about hidding states. </cmt> <cmt> updated requirements to include pyisy. </cmt> <cmt> pylint fix to isy switches. </cmt>",added support for isy994 insteon and x10 controller (and other updates)
2941,"<desc> added pyod and mars frameworks to the curated lists in python sections as follows: pyod - general-purposed machine learning section. mars - data analysis/visualization section. pyod - a comprehensive and scalable python toolkit for detecting outlying objects in multivariate data. this exciting yet challenging field is commonly referred as outlier detection or anomaly detection. since 2017, pyod has been successfully used in various academic researches and commercial products. pyod is featured for: advanced models, including neural networks/deep learning and outlier ensembles. optimized performance with jit and parallelization when possible, using numba and joblib. compatible with both python 2 & 3 (scikit-learn compatible as well). mars - a tensor-based unified framework for large-scale data computation released by alibaba cloud engineer for tremendous-sized matrix computation. </desc> <cmt> add pyod - python toolkit for outlier detection </cmt> <cmt> added pyod framework to general-purpose machine learning lists in python section. </cmt> <cmt> since 2017, pyod has been successfully used in various academic researches and commercial products. </cmt> <cmt> add mars tensor python framework </cmt> <cmt> added mars framework to data analysis framework in python section. </cmt> <cmt> mars is open sourced tensor-based framework released by the alibaba cloud in january 2019. it compliments numpy with ability to run matrix computation at a very large-scale, a forte that numpy does not share. </cmt>",pyod and mars tensor for machine learning in python
2942,"<desc> partial fix for #67484. updates various pages in the community and developer guides to reflect the collections ecosystem. docs.ansible.com collections </desc> <cmt> adds info on collections to dev cycle page </cmt> <cmt> updates docs page in community guide </cmt> <cmt> updates how to help page in community guide </cmt> <cmt> updates community toc for collections, plus minor fixes </cmt> <cmt> links to galaxy and repos for platform dev guides </cmt> <cmt> updates core page and flow page for collections </cmt> <cmt> updates local modules page for collections </cmt> <cmt> updates module utils page for collections </cmt> <cmt> updates modules tips and tricks for collections </cmt> <cmt> updates checklist for collections </cmt> <cmt> updates module docs docs for collections </cmt> <cmt> basic update of aci page for collections </cmt> <cmt> a few more collections refs for developing modules </cmt> <cmt> updates the should i develop a module page for collections </cmt> <cmt> basic update of developing plugins page for collections </cmt> <cmt> basic update of python2/3 page for collections </cmt> <cmt> updates rebase instructions for collections </cmt>","mentions ansible-base, adds collections pointers to community and dev guides"
2943,"<desc> fixes #64567 queries with a literal selection and a filter like select 1 from test_emp where gender = 'f' are currently erroneously optimised to use a local relation. this causes es to always return a single record, no matter how many records match the filter condition. this pr makes sure that skipqueryiffoldingprojection only skips the query if it's an aggregate with only constants (e.g. select 'foo' from test group by 1). this optimization seems to lead to another issue #74064 that's not yet addressed in this pr. besides this the ""skip query"" optimization, the skipqueryiffoldingprojection class also folds constants from localrelations and pushes the evaluated values into a new localrelation (e.g. for queries like select 1 + 2). </desc> <cmt> fix literal projections of es index with filter </cmt> <cmt> sql spec </cmt> <cmt> merge master into fix/literalprojectionwithcondition </cmt> <cmt> fix imports </cmt> <cmt> fix all imports </cmt> <cmt> replace asserts </cmt> <cmt> fmt </cmt> <iss> sql: wrong result on literal selection with condition </iss>",fix literal projection with condition
2944,<desc> removes the okhttp module examples into the existing spring-rest module as live test examples. </desc> <cmt> update from original </cmt> <cmt> code improvement </cmt> <cmt> code improvement </cmt> <cmt> add okhttp example </cmt> <cmt> add okhttp example </cmt> <cmt> add okhttp example </cmt> <cmt> delete okhttp project </cmt> <cmt> code improvement </cmt>,move okhttp examples to spring-rest
2945,"<desc> nightly binaries available at  so to fix the mkldnn header missing issue in nightly binaries, we need to cherry-pick it into 1.x branch cherrypicks #18608 @moisesher @mseth10 @leezu @szha </desc> <cmt> cherry-pick #18310 #18355 (#18608) </cmt> <cmt> * cherry-pick: fix missing mkldnn headers (#18310) </cmt> <cmt> * include all mkldnn headers in cd builds (#18355) </cmt> <cmt> * fix cmake mkldnn install target. previously mkldnn headers are installed to cmake_install_includedir instead of cmake_install_includedir/mkldnn </cmt> <cmt> * fix pypi_package.sh pip/setup.py for mkldnn builds </cmt> <cmt> * set cmake_cuda_compiler in aarch64-linux-gnu-toolchain.cmake (#18713) </cmt> <cmt> cmake_cuda_host_compiler will be reset if cmake_cuda_compiler is not set as of cmake 3.17.3 </cmt> <cmt> see </cmt> <cmt> remove linux-gputoolchain </cmt>",mkldnn header fix v1x for nightly binaries
2946,<desc> added @springbootapplication(exclude = mysqlautoconfiguration.class) in order for the pr to work. this is for the keycloak with spring boot blog post in progress: </desc> <cmt> michael.good703@gmail.com </cmt> <cmt> michael.good703@gmail.com </cmt> <cmt> michael.good703@gmail.com </cmt> <cmt> michael.good703@gmail.com </cmt> <cmt> michael.good703@gmail.com </cmt> <cmt> michael.good703@gmail.com </cmt> <cmt> update </cmt>,bael-1238 quick guide to using keycloak with a spring boot application
2947,"<desc> on bumping the time-machine: a few changes which are useful for us: 1. 'gnu: cross-gcc-arguments: enable 128 bit long double for power9.' is now merged into master. 2. gnutls is bumped to 3.6.15 and the temporal test failure in status-request-revoked is fixed. note that this does not fix the case where one has installed guix v1.2.0 and is running a substitute-less bootstrap build, since the guix time-machine command itself has a dependency on gnutls v3.6.12 (the one with the broken test) and will thus try to build it before attempting to jump forwards in time. this does however, mean that those who build a version of guix that also contains this fix will not go backwards in time to build the broken gnutls v3.6.12. on bumping the rest: bump glibc and linux-headers to match those of our gitian counterparts. we also require a glibc >= 2.28 for the test-symbol-check scripts to work properly. the default base-gcc-for-libc also has to be bumped since glibc 2.31 requires a gcc >= 6.2 this is a prerequisite for #20980 </desc> <cmt> guix: rebase on 95aca2991b (1.2.0-12.dffc918) </cmt> <cmt> a few changes which are useful for us: </cmt> <cmt> 1. 'gnu: cross-gcc-arguments: enable 128 bit long double for power9.' is </cmt> <cmt> now merged into master. </cmt> <cmt> 2. gnutls is bumped to 3.6.15 and the temporal test failure in </cmt> <cmt> status-request-revoked is fixed. note that this does not fix the case </cmt> <cmt> where one has installed guix v1.2.0 and is running a substitute-less </cmt> <cmt> bootstrap build, since the guix time-machine command itself has a </cmt> <cmt> dependency on gnutls v3.6.12 (the one with the broken test) and will </cmt> <cmt> thus try to build it before attempting to jump forwards in time. this </cmt> <cmt> does however, mean that those who build a version of guix that also </cmt> <cmt> contains this fix will not go backwards in time to build the broken </cmt> <cmt> gnutls v3.6.12. </cmt> <cmt> guix: bump glibc and linux-headers </cmt> <cmt> bump glibc and linux-headers to match those of our gitian counterparts. </cmt> <cmt> we also require a glibc >= 2.28 for the test-symbol-check scripts to </cmt> <cmt> work properly. </cmt> <cmt> the default base-gcc-for-libc also has to be bumped since glibc 2.31 </cmt> <cmt> requires a gcc >= 6.2 </cmt>","bump time-machine, glibc, and linux-headers"
2948,"<desc> we were treating an int as atomic, which is dubious at best it was possible to shutdown while an accept was being handled, and process that shutdown accept before the real accept finished, leading to a use-after-free up the stack </desc> <cmt> merge github.com:grpc/grpc into tcp_shutdown </cmt> <cmt> fix races on tcp server shutdown on windows </cmt> <cmt> - we were treating an int as atomic, which is dubious at best </cmt> <cmt> - it was possible to shutdown while an accept was being handled, and </cmt> <cmt> process that shutdown accept before the real accept finished, leading to </cmt> <cmt> a use-after-free up the stack </cmt> <cmt> clang-format </cmt>",fix tcp shutdown path on windows
2949,"<desc> in sharedselectautocompleteeditorparams, missing : sortvalueslist - if values property is set to true this option can be used to set how the generated list should be sorted. if ommitted the list will be in the order of rows in the table, when used it can have a value of ""asc"" or ""desc"". in label of linkparams of the formatter, missing the function type : label - a string representing the lable, or a function which must return the string for the label, the function is passed the cell component as its first argument add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add missing sortvalueslist attribute to sharedselectautocompleteeditorparams </cmt> <cmt> update label attribute of linkparams which may be a string representing the lable, or a function which must return the string for the label, the function is passed the cell component as its first argument. </cmt>",add sortvalueslist on sharedselectautocompleteeditorparams and update label on linkparams
2950,"<desc> yaml files in the .vsts-ci directory use old syntax.  issue #3164. this pr updates the yaml to use the latest syntax. it does so under a new directory name: .azure-pipelines. if/when this pr is merged, the pipelines can point to yaml in this new .azure-pipeines directory and the .vsts-ci directory can be deleted. a news fragment in the news/ directory to describe this fix with the extension .bugfix, .feature, .behavior, .doc. .vendor. or .trivial (this will appear in the release changelog). use semantic line breaks and name the file after the issue number or the pr #. </desc> <cmt> update yaml syntax </cmt> <cmt> added news file </cmt>",update yaml syntax for azure pipelines
2951,<desc> remove extra index when parsing errors to render to user. this was specfically happening when users would try to create a report without saving the chart includes db migration (follow approval process in sip-59) </desc> <cmt> don't maniuplate error message </cmt> <cmt> remove extra idx reference </cmt>,fix parsing onsaving reports toast when user hasn't saved chart
2952,<desc> backport of #56802 (cherry picked from commit 433c98e) yum </desc> <cmt> ensure we have enough values to split (#56802) </cmt> <cmt> avoid raising an exception if pkgstr does not complains with expected </cmt> <cmt> value. </cmt> <cmt> (cherry picked from commit 433c98eae0dfbc7f915c87c92423721bc19a5c79) </cmt> <cmt> add changelog </cmt>,yum: ensure we have enough values to split (#56802)
2953,"<desc> this continues the removal of automatic exporting of runtime methods, focusing on the filesystem support methods, in particular the ones that are used by loading file packages created separately (that is, created by running the file packager manually, then loading them at runtime, in which case the compiler does not see the filesystem usage, and we must export the things it needs so the package finds them). this is similar to the previous work in that in -o0 or assertions any used method not exported  will show an error explaining how to fix things. in addition, for these methods we also suggest using force_filesystem which will export all the filesystem methods in a convenient way. </desc> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> fix benchmarks </cmt> <cmt> cleanup </cmt> <cmt> fix </cmt> <cmt> test fix </cmt> <cmt> test </cmt> <cmt> improve test </cmt> <cmt> wip </cmt> <cmt> clean up fs_/fs. exporting, and add testing </cmt> <cmt> fix test_files </cmt> <cmt> fix </cmt> <cmt> also rundep funcs </cmt> <cmt> test update </cmt> <cmt> fixes </cmt> <cmt> test fixes </cmt> <cmt> test fix </cmt> <cmt> fixes </cmt> <cmt> update test </cmt>",don't export fs methods by default
2954,<desc> added spread functionality to checkboxes so now we can pass html checkbox attributes as properties of our checkbox component. styling has been changed to reflect attributes such as required and disabled. also changed checkbox transformation to reflect the updated google material design's version. minor text changes to the code example provided in pages/switches. </desc> <cmt> added spread functionality. had to use different styling for simplicity and am currentlty going back to the previous one. </cmt> <cmt> restored css positions </cmt> <cmt> restored styling and now working on new material design checkbox. </cmt> <cmt> fixed transition: now happens from center. </cmt> <cmt> changed font icon colors to reflect disabled and required attributes. </cmt> <cmt> minor text changes to code-example for switches </cmt>,checkbox spread functionality and style changes
2955,"<desc> started from 480 issues, after the current changes there are only 417 left... obviously, i'm not going to fix all of them in short-term. </desc> <cmt> [jenkins-36720] - findbugs. reduse threshold to medium </cmt> <cmt> findbugs: cli#connectviacliport() should not fail with npe if we somehow receive empty response </cmt> <cmt> findbugs: unclosed buffered reader in fullduplexhttpstream </cmt> <cmt> findbugs: suppress uuf_unused_public_or_protected_field in jna classes </cmt> <cmt> findbugs: null check related warnings in artifactarchiver </cmt> <cmt> findbugs: weaken the requirement of descriptor#newinstance() since staplerrequest in nonnull with few exceptions </cmt>",cleanup of some medium findbugs issues
2956,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> update: rename flyout to popover in gestalt </cmt> <cmt> update: add elementtiming attribute to image in gestalt </cmt>,update gestalt types to version 20.1
2957,<desc> added c solution for problem no. 4. median of two sorted arrays (difficulty: hard) beats 70% of total solutions in terms of both runtime and storage </desc> <cmt> added median of two sorted arrays </cmt> <cmt> fix with readme </cmt>,median of two sorted arrays no. 4
2958,"<desc> the goal of this pr is to move the resident runners closer to a state where enough of the implementation is shared to enable 1) profile/release/debug autodetect for flutter attach and 2) simultaneous connections to web and non-web devices. i also wanted to remove the vast amounts of duplicated test logic due to the web and non-web resident runners having different service extension impls as well as remove the mocks from the terminal handler test and re-imagine it as a fairly high level interaction test. changes in resident_runner.dart: creates a new class residenthandlers which contains the vm service delegation, make it easier to share with the web impl for now. this required exposing logger and filesystem as protected members. removes all of the wrapper vm service functionality from the flutterdevice class. now that the logic is in a single place it doesn't make as much sense to split it up. updates flutterdevice to conditionally use getvm's isolate list instead of listing the flutter views. the flutter view rpc is not supported on the web, but since there is only ever one isolate we can use the vm list. this required exposing the targetplatform field on flutterdevice, which was already part of the constructor. changes in resident runner testing: deleted all tests that only checked that service extensions were called correctly changes in resident_web_runner testing: deleted all tests that only checked that service extensions were called correctly changes in terminal_handler testing: updated the test set up to remove the use of mocks, and to extend most test cases to include a web case. clean ups: remove the requirement to inject fsutils to grab the unique file functionality, since all this needs is a filesystem. removes the feature flag check for debug target platform. i think its ok to let people toggle to macos . </desc> <cmt> refactor resident runners to use shared devfs interactions </cmt> <cmt> remove more flutterdevice methods </cmt>","remove web specific vm_service handlers, move handler tests to single location"
2959,"<desc> i've done sone minor optimization - mainly to avoid filesystem access where not necessary. also i've added some fingerprint asserts to the existing test i've could push this myself, but i thought it would be could if someone else could have a look on it first. </desc> <cmt> added test for maven fingerprinter </cmt> <cmt> - avoid filesystem access if file is already fingerprinted </cmt> <cmt> - remove usage of jvm-internal internalerror </cmt>",minor optimization for mavenfingerprinter + unit test for fingerprinter
2960,"<desc> this pr adds cross language in the streaming data transfer layer, to support the following cross-lang api(pr). in cross-lang design, the peer's actor type is uncertain, so the entry point function used by direct call should be configurable. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> add init parameters for java </cmt> <cmt> fix bug </cmt> <cmt> cython </cmt> <cmt> fix compile </cmt> <cmt> fix test_direct_tranfer </cmt> <cmt> comment </cmt>",[streaming]streaming data transfer support cross language
2961,"<desc> i have followed (at least) the pr section of the contributing guide. edit @eps1lon: closes #20568 fixes: buttonbase linearprogress slider switch </desc> <cmt> 'slider-switch-linnerprogress' </cmt> <cmt> 'button-base' </cmt> <iss> slider, linearprogress, and switch are invisible in print ink save mode </iss>",force visibility on a few components in ink save print mode
2962,"<desc> improved warning whenever lower priority events (ex. data fetching, page load) happen during a high priority update (ex. hover/click events) to include: 1.) name of component that triggered the high priority update or 2.) information that the update was triggered on the root </desc> <cmt> add suspense warning </cmt> <cmt> added flush sync test </cmt> <cmt> added code to run flushsync with immediatepriority </cmt> <cmt> added code to run flushsync with immediatepriority </cmt> <cmt> fixed flow error </cmt> <cmt> fixed flow error </cmt> <cmt> added some more code </cmt> <cmt> added some more code </cmt> <cmt> removed console.log and fixed tests </cmt> <cmt> fixed style errors and does not suspend for very long after a higher priority update test </cmt> <cmt> made low priority tests more descriptive </cmt>",update suspense priority warning to include component that triggered update
2963,<desc> fixes #904 . get tables rules from default datasource and put tables info metadata. modify some test cases. </desc> <cmt> optimize thread pool for initialing the metadata. </cmt> <cmt> using collection instead of list. </cmt> <cmt> get metadata from default datasource. </cmt> <cmt> get table metadata from default datasource for proxy. </cmt> <cmt> get table metadata from default datasource for proxy. </cmt> <cmt> close connection </cmt> <cmt> add mock for resultset. </cmt> <cmt> handle master slave datasource </cmt> <cmt> modify get table rules </cmt>,to put tables from default datasource into metadata .
2964,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> extending and fixing intercom api typings </cmt> <cmt> fix linter </cmt>",extending intercom types and fixing response type
2965,"<desc> added cacheless data source to allow hls livestream playback. added new async loader for media sources to correct hls livestream loading and enable better control over expired media sources. added custom cache key for extractor sources to allow more persistent reuse. added seamless shuffling. added toggleable fast inexact seeking. added toggleable auto-queuing when last stream on non-repeating play queue starts. added custom track selector to allow irregular caption text language names, until language normalization npe in exoplayer is fixed. added buffering strategy to enable faster playback start. fixed inconsistent audio focus when audio becomes noisy through unplugging headsets. fixes #1139. fixed search fragment long press dialog deletes item prior confirming. fixed potential transactiontoolargeexception when passing player intents. fixed main video player state saving on lifecycle events. updated exoplayer to 2.7.0. updated video player ui to no longer show interface after buffering and double-tap seeking. fixes #1151. updated main video player ui to use hidden translucent system ui (nav and status bars), similar to youtube app. updated extractor to allow hls extraction. removed livestream exceptions. removed debouncing time for stream selection on play queue. addendum: hls playlists really doesn't like loading and playing on demand, which means we can no longer use the existing deferredmediasource. therefore, the old loader is being replaced by a new async loading inside the mediasourcemanager. it works by first generating a list of placeholder media sources in order to create a playlist media source. when these placeholder are played, they stall the player until they are replaced with a  loadedmediasource. when loading is requested, outside the lifecycle of mediasource, the mediasourcemanager loads and builds the mediasource asynchronously and replaces the placeholdermediasource at the corresponding index on the playlist media source. if the loading fails for a particular media source, then a failedmediasource will be used for replacement. by doing this, hls livestream is now able to load the playlists properly and we can now have better control on the playlist to evict or update mediasources with expired urls. regarding the customtrackselector, it is mostly a copypasta from defaulttrackselector. a few lines are changed in order to allow us to use irregular caption language names. this will be removed once exoplayer properly nullchecks their language code normalization. currently, i have disabled track selection on livestreams since the manifest allows exoplayer to adaptively choose the quality according to the network status. of course, this adaptiveness can be overriden if needed, but this requires us to create a separate quality menu just for livestreams, which will make the video player more complex. let me know what you think. todos: add ui for livestreams to seek directly to live edge. change extractor version to latest once merged. </desc> <cmt> -updated exoplayer to 2.7.0. </cmt> <cmt> -poc for new seamless stream loading mechanism. </cmt> <cmt> -fixed media source update index check. </cmt> <cmt> -fixed media source manager excessive loading. </cmt> <cmt> -remove unneeded fields in loaded media source. </cmt> <cmt> -fixed inconsistent audio focus state when audio becomes noisy (e.g. headset unplugged). </cmt> <cmt> -fixed live media sources failing when using cached data source by introducing </cmt> <cmt> cacheless data sources. </cmt> <cmt> -added custom track selector to circumvent exoplayer's language normalization npe. </cmt> <cmt> -updated extractor to correctly load live streams. </cmt> <cmt> -removed deprecated deferred media source and media source manager. </cmt> <cmt> -removed livestream exceptions. </cmt> <cmt> -fixed failed media source not treated as ready. </cmt> <cmt> -fixed potential npe when obtaining broadcast receiver. </cmt> <cmt> -extracted expiration time in media source manager. </cmt> <cmt> -re-enabled long click on live stream info items. </cmt> <cmt> -fixed dash source building to use mpd instead of extractor. </cmt> <iss> newpipe start playing music again after beeing paused if a sms is received </iss> <iss> don't show overlay after resuming from buffering </iss>",live streaming and exoplayer shenanigans
2966,<desc> and to intersect even in the subtype case so keyof t narrows to keyof t & string and not string. fixes #25179 </desc> <cmt> for typeof narrow all union members prior to filtering </cmt> <cmt> revise narrowtypebytypeof to both narrow unions and applicable union members </cmt> <cmt> add repros from issue </cmt>,change typeof narrowing to narrow selected union members
2967,"<desc> #4806 and a part of #4389 refer to this change - people have been wanting to be able to disable emitting es6 module syntax when targeting es6 for awhile, and this allows them to do just that. while this could wait until we re-architect our emit for even more granular emit, even with our current emitter this wasn't a bad change to make. feelings about it? </desc> <cmt> add es6 module kind, stop using script version to infer it </cmt> <cmt> pair of new tests for the new flag </cmt>",support modules when targeting es6 and an es6 modulekind
2968,"<desc> this spec file generates an rpm. i used centos 6.3 to develop it, but i see no reason why it wouldn't work on other rpm-based distros. </desc> <cmt> rpm-generating spec file </cmt>",spec file for generating rpm
2969,"<desc> for runtime fields, we will want to do all search-time interaction with a field definition via a mappedfieldtype, rather than a fieldmapper, to avoid interfering with the logic of document parsing.  currently, fetching values for runtime scripts and for building top hits responses need to call a method on fieldmapper.  this commit moves this method to mappedfieldtype, incidentally simplifying the current call sites and freeing us up to implement runtime fields as pure mappedfieldtype objects. </desc> <cmt> wip </cmt> <cmt> move valuefetcher() from fieldmapper to mappedfieldtype </cmt> <cmt> tests </cmt>",move fieldmapper#valuefetcher to mappedfieldtype
2970,<desc> fixes issue#1415 (custom cameras and camera parameters not taken into account during initialization phase which leads to crashes when trying to request images from the api). proposes support (correct axis mapping) for an additional rc :  the flysky fs-sm100 rc to usb adapter which converts ppm signals typically outputted by a wide range of uav rcs to usb hid protocol (this should therefore offer a good support for a wide range of uav rcs) </desc> <cmt> fix for issue#1415 </cmt> <cmt> fixes the issue which leads the code to completely ignore custom cameras defined in the settings file </cmt> <cmt> added support for flysky fs-sm100 rc usb adapter </cmt> <cmt> modified the  axes remapping part of simjoystick to add support for the flysky fs-sm100 rc usb adapter </cmt>,fix for issue#1415 and additionnal rc support
2971,"<desc> add buttons customization to the following classes: testpointer's constructor and property testgesture's constructor widgetcontroller's movement methods it is needed because widgets might want to test their behavior under events with non-primary buttons. related issues n/a new tests: each of the following methods should respect buttons, i.e. the events yielded from it should have the correct buttons. widgettester.tap widgettester.press widgettester.longpress widgettester.drag widgettester.fling before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add buttons to widgetcontroller and testpointer </cmt> <cmt> add more buttons </cmt> <cmt> add tests </cmt>",add buttons customization to widgetcontroller and related testing classes
2972,"<desc> fixed the issue #7706. i add a new unit test class (org.apache.skywalking.oap.server.analyzer.agent.kafka.provider.handler.loghandlertest). this bug has been described in the #7706 . to fix it, i made loghandler extend abstractkafkahandler instead of kafkahandler and removed gettopic() in the loghandler. if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #7706. update the changes log. </desc> <cmt> fixed the issue #7706. make kafkaloghandler can recognize namespace by extending abstractkafkahandler. </cmt> <cmt> update changes.md </cmt> <cmt> add  fix loghandler of kafka-fetcher-plugin cannot recognize namespace in the  oap server part. </cmt> <iss> [bug] kafkaloghandler cannot recognize namespace </iss>",fixed bug #7706. make loghandler of kafka-fetcher-plugin can recognize namespace.
2973,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. keys in nextrelease:  possible values for type: </desc> <cmt> feat(semantic-release): add all release types supported by commit-analyzer </cmt> <cmt> feat(semantic-release): add other fields in nextrelease </cmt> <cmt> @see </cmt> <cmt> test(semantic-release): add test for prerelease type </cmt>,add missing fields in nextrelease
2974,"<desc> removes setting of core_lists in the driver (now should pass empty list unless configured in scenario beforehand) also removes setting of core affinity in c++ workers (previously based on core_list). looks like these are ignored currently for other languages that set core_limit in the scenario config: (seeing c++, c#, python, ruby) </desc> <cmt> ignore core counts and core lists in qps json driver </cmt> <cmt> remove limitcores in c++ benchmark </cmt> <cmt> re-run generate project to build qps json driver </cmt>",don't configure core lists in in benchmark driver
2975,<desc> make sure this property is set for index relation symbols also mark classes and their extensions with the property when appropriate </desc> <cmt> [swift-ide-test/test] print out symbol-info for index symbol relations </cmt> <cmt> this is to make sure we get the right symbol-info when forming a symbol relation </cmt> <cmt> [index] move determination of symbolproperty::unittest at index::getsymbolinfofordecl() </cmt> <cmt> otherwise symbol info for relations of such methods does not contain this property. </cmt> <cmt> [index] also mark unit test classes and their extensions with symbolproperty::unittest </cmt>,marking symbols with the 'unittest' property fixes
2976,"<desc> occurenceorderplugin is a typo, the webpack team already aware of this fact and it will be removed in webpack 2 in favor of occurrenceorderplugin. currently webpack supports both. this pull requests add occurrenceorderplugin which is missing. </desc> <cmt> add occurrenceorderplugin </cmt> <cmt> add deprectation notice </cmt>",add occurrenceorderplugin as webpack optimizer
2977,<desc> propagates the updated doc build command from #10480 to /docs/readme.md as well. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> update doc build command in readme </cmt> <cmt> fix typo in cluster docs </cmt>,update docs readme and fix typo
2978,<desc> toolchains for hardfp and softfp added; tbb support added; carma board support added. </desc> <cmt> video io perf tests guarded. </cmt> <cmt> tbb download and build option enabled for non android platfroms. </cmt> <cmt> cross compilation toolchain for arm linux added. </cmt> <cmt> tbb build defines for linux added. </cmt> <cmt> code review notes applied. </cmt> <cmt> toolchain for arm hardfp added. </cmt> <cmt> compiler and linker flags for arm cross compilation fixed. </cmt> <cmt> cuda toolkit support added to crosscompilation toolchain. </cmt> <cmt> tbb build for arm linux fixed. processors count detected correctly. </cmt> <cmt> carma board support fixed. </cmt>,cross compilation for arm linux implemented
2979,"<desc> merge after #14181 i thought that some changes there were needed (they ended up not being needed) to make this work so i branched off of that and it's not possible to get this pr in until that (due to squash and merge vs merge commit) fixes an issue where public projects would actually resolve to the remote version instead of the local version. since * literally means any version, it would use the version published to npm. in addition, a version of 0.0.0-development does not technically fall under the * rule which translates to >=0.0.0. we can actually use this rule to our advantage. from now on, all local packages will use version 0.0.0-development, regardless of whether they are public or private (for simplicity, private could stay the same but let's simplify the rules). this ensures that every time we try to use a package that is both local and published to npm, we are always using the local version if it exists. note: our semantic release tooling will replace 0.0.0-development with the actual correct version upon deployment to npm. this also updates the binary build process to use the local version of packages that are also published to npm. this ensures that the binary always ships with exactly what was tested locally and also decouples the binary release from the npm package releases. binary build implementation notes: we use yarn to install these packages locally through the file:... syntax: for example, server/package.json currently contains ""@cypress/webpack-preprocessor"": ""0.0.0-development"" which gets replaced with ""@cypress/webpack-preprocessor"": ""file:../../npm/webpack-preprocessor"". we do this replacement after copying the npm packages to the dist dir, so that way it only installs the necessary files (the stuff specified in package.json that we selectively copy from our private packages already) and doesn't blow up the binary file size. after they get installed to their respective @packages, we delete the npm directory in the dist dir. originally i had tried to implement copying + replacing the symlink with a relative path (as we do for @packages), but this would not properly work due to peer dependency requirements. also resolves a bunch of issues people have been having in development with @cypress/webpack-preprocessor which is really the only package right now that is used locally note: sometimes when developing locally with public packages that have peerdependencies (eg. webpack-preprocessor), you'll have to make sure to remove certain peerdependencies from  that package's devdependencies. for example, webpack-preprocessor has a peerdependency of typescript and for it to work properly it must use the same exact typescript that is used by its dependent (in this case, the binary). by removing it from the devdependencies we ensure that it always uses the hoisted version installed at the workspace root, which is the same version that the binary is using. this is essential to ensure that packages are using the same hoisted dependency since installing workspace packages creates a symlink rather than using the same install process as from the npm registry. (this isn't necessary for all peerdependencies, just when it involves something like monkey-patching the dependency, etc.) right now the pr title has build: which will not trigger a new release (even though a couple packages were changed). we can use fix: if we want to trigger a release (for npm packages) but since literally nothing public changed this feels redundant </desc> <cmt> fix: update @cypress/npm-webpack-batteries-included-preprocessor for monorepo </cmt> <cmt> fix circleci config </cmt> <cmt> build: fix resolution of packages for local development </cmt>",properly use local npm packages for development and binary build
2980,"<desc> description: in pyhomematic: set sabotage helper for hmip devices to channel 0 fix log-message for callbacks add support for hmip-fbl, hmip-swdm, hmip-smi55 in home assistant: fix #19619 ensure that the event we are processing is handeled by the correct entity. see this issue for further details: danielperna84/pyhomematic#193 @pvizeli do you see anything wrong with this approach? so far it seems to work. related issue (if applicable): fixes #19619 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> update pyhomematic + small fix </cmt> <cmt> add casting for illumination </cmt> <iss> non-numeric brightness value of homematic motion sensor hmip-smi </iss>",update pyhomematic 0.1.54 + small fixes
2981,"<desc> atm _tz_convert_dst handles iteration and masking differently (and more complicated-ly) than other related functions.  afaict the reasoning is that this implementation is performant when the passed vals have a high proportion of inats. by changing this special case to conform to the standard pattern, we allow other functions to call this without having to do any special casting, generally simplify things, and open the door to de-duplicating these functions (which this pr also starts doing by implementing _tz_convert) tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> de-duplicate tz_convert functions, make tz_convert_dst less of a special case </cmt> <cmt> clean up imports </cmt> <cmt> remove cnp dep from frequencies </cmt> <cmt> revert out of scope </cmt> <cmt> cleanup import </cmt>",standardize special case in tz_conversion functions
2982,<desc> this patch allows systemd-cryptsetup and dissect-image to unlock/activate luks2 devices if system cryptsetup library understands the format. the change itself doesn't enforce new cryptsetup library and it's backward compatible with libcrytpsetup 1.x </desc> <cmt> cryptsetup: support luks2 on-disk format </cmt> <cmt> allow cryptsetup utility to activate luks2 devices (with appropriate </cmt> <cmt> libcryptsetup) </cmt> <cmt> the change itself doesn't enforce new libcryptsetup 2.x and is backward </cmt> <cmt> compatible with versions 1.x </cmt> <cmt> shared/dissect-image: adapt to luks2 format </cmt> <cmt> load any luks format available (and recognized) by libcryptsetup </cmt>,luks2 support for systemd-cryptsetup and dissect-image
2983,"<desc> after #11050 some of regular expressions in cgroup-name.sh work incorrectly. we should use cg->id and fix the script, but we decided to make a simple temporary fix because the next release is coming. fixes #11760 component name cgroups plugin start as many different types of containers as you can. check if they are named correctly in the dashboard or charts api. </desc> <cmt> don't remove dots before renaming </cmt> <cmt> remove an outdated comment </cmt> <cmt> remove the previuos temporary fix </cmt> <iss> replacing `.` with `-` breaks some regex matches in cgroup-name.sh </iss>",temporary fix for cgroup renaming
2984,<desc> as mentioned in issue #802 this page provides useful links for the help of beginners and experts alike. @roshanjossey do review the content and people could keep adding to this list as they see fit. </desc> <cmt> useful links </cmt>,useful links in additional material
2985,"<desc> this pr bring a new type long long int to support 64bits integer. 2 vtables are migrate to this new type: users and groups. this commit is a first part for issue #284 </desc> <cmt> add support for long long int/bigint as a column type </cmt> <cmt> change groups table to used new long long int type for gid </cmt> <cmt> it is now possible to do a proper order on gid, ie: </cmt> <cmt> select * from groups order by gid; </cmt> <cmt> change users table to used new long long int type for uid and gid </cmt> <cmt> it is now possible to do a proper order on uid or gid, ie: </cmt> <cmt> select * from users order by uid; </cmt>",add new long type and migrate some vtables
2986,"<desc> profiler: subtract the kernel's base address when searching for symbols now that the kernel is compiled as a pie, all addresses are relative to the loaded base address, so symbolication::kernel_base has to be subtracted off from the absolute addresses if we want to symbolicate them. libx86: take load base address into consideration during disassembly since our executables are position-independent, the address values extraced from processes don't correspond to their values within the elf file. we have to offset the absolute addresses by the load base address to get the relative symbol that we need for disassembly. profiler: fix disassembling objects with a non-zero .text vaddr previously, we assumed that the .text segment was loaded at vaddr 0 in shared object, which is not the case with -z separate-code enabled. because we didn't do the right calculations to translate an address from a performance event into its value within the elf file, profiler would try to disassemble out-of-bounds memory locations, leading to a crash. this commit also changes librarymetadata to apply to a loaded library as a whole, not just to one of its segments (like .text or .data). this lets us simplify the interface, as we no longer have to worry about text_base. fixes #10628 </desc> <cmt> profiler: subtract the kernel's base address when searching for symbols </cmt> <cmt> now that the kernel is compiled as a pie, all addresses are relative to </cmt> <cmt> the loaded base address, so symbolication::kernel_base has to be </cmt> <cmt> subtracted off from the absolute addresses if we want to symbolicate </cmt> <cmt> them. </cmt> <cmt> libx86: take load base address into consideration during disassembly </cmt> <cmt> since our executables are position-independent, the address values </cmt> <cmt> extraced from processes don't correspond to their values within the elf </cmt> <cmt> file. we have to offset the absolute addresses by the load base address </cmt> <cmt> to get the relative symbol that we need for disassembly. </cmt> <cmt> profiler: fix disassembling objects with a non-zero .text vaddr </cmt> <cmt> previously, we assumed that the .text segment was loaded at vaddr 0 in </cmt> <cmt> shared object, which is not the case with -z separate-code enabled. </cmt> <cmt> because we didn't do the right calculations to translate an address from </cmt> <cmt> a performance event into its value within the elf file, profiler would </cmt> <cmt> try to disassemble out-of-bounds memory locations, leading to a crash. </cmt> <cmt> this commit also changes librarymetadata to apply to a loaded library </cmt> <cmt> as a whole, not just to one of its segments (like .text or .data). this </cmt> <cmt> lets us simplify the interface, as we no longer have to worry about </cmt> <cmt> text_base. </cmt> <cmt> fixes #10628 </cmt> <iss> profiler: disassembly view crashes with any input </iss>",unbreak disassembly with -z separate-code
2987,"<desc> tweaks the presentation of the task instance swatches within the tree view with very slightly rounded corners of the squares. the goal here being to give it a softer presentation that aligns closer to the other recent ui refresh updates. before after the following updates to the legends resulted in some refactoring of the markup/styles using more explicit patterns. i made necessary adjustments to the graph view scripting to ensure the hover/click interactions continued working as expected. tree view legend - before: tree view legend - after: adjusts spacing so it is more clear which label is associated with which swatch. removes the harsh black borders around the state items adds slight border-radius to match tis in the tree view graph the order is changed because the previous styling used floated elements that reversed the actual order graph view legend - before: graph view legend - after: the order is changed because the previous styling used floated elements that reversed the actual order read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> [pull] master from apache:master </cmt> <cmt> visual tweaking of ti swatches, legend refactoring </cmt>",tree view ti swatch and legend visual tweaks
2988,"<desc> relands #50609. turns out the function signature for _appwithalertdialog was changed in a recent pr. </desc> <cmt> add buttonbar.overflowbuttonspacing </cmt> <cmt> add alertdialog overflow button spacing functionality </cmt> <cmt> add default value, ddo not add spacing at the end of the button bar </cmt> <cmt> update api docs </cmt> <cmt> update tests </cmt> <cmt> revert to no default value </cmt> <cmt> improve button bar testing </cmt> <cmt> fix function signature in tests </cmt>",reland alert dialog overflow spacing
2989,"<desc> corrected what seems to be a automatic translation error in the examples file and added a tokenizer exception, which is used often in danish. change to the documentation. i have submitted the spacy contributor agreement. </desc> <cmt> fixing a translation error in examples.py </cmt> <cmt> adding an exception in the tokenizer_exceptions.py </cmt> <cmt> agreeing to the contributor agreement. </cmt>",two corrections in the da lan.
2990,"<desc> see jenkins-48157. actually it fixes two defects, let me know if i should file the second issue. i was playing with setupwizardtest fixes, but idea reported a nonnull violation in the instrumented code (though npe would not really happen there). the api for primaryviewname is not documented at all and not used in the plugins, but an improper call of the default constructor will cause the issue. it happens in the user creation reflection in my tests.  this is a ""regression"" after jenkins-38606 fd2009a by @stephenc 1 year ago. - fix jenkins-48157 - npe when migrating ""allview"" names for a property without primary view defined - fix npe when using the public myviewsproperty(string) constructor and almost any other class method after that - document nullness of the primaryviewname field according to the de-facto state. there is no affected external usages from what i see - unit test bug, jenkins-48157 - prevent nullpointerexception when migrating the default ""all view"" names for a my views property without primary view defined bug, todo - prevent nullpointerexception in myviewsproperty when it is initialized using public api. changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) @reviewbybees </desc> <cmt> [jenkins-48157] - reproduce the issue in test </cmt> <cmt> [jenkins-48157] - annotate and document nullness conditions in myviewsproperty and viewgroupmixin </cmt> <cmt> [fixed jenkins-48157] - prevent npes when using public api and when using null primaryviewname </cmt>",risk of npe when migrating myviewproperty without primaryview
2991,"<desc> this switches the test runner to bazel for tune tests, which automatically provides parallel testing and times out tests. see here for the timeouts enforced for each test size:  you can try this out by running: $ bazel test python/ray/tune/... info: analyzed 17 targets (0 packages loaded, 0 targets configured). info: found 1 target and 16 test targets... info: elapsed time: 437.721s, critical path: 338.90s info: 20 processes: 16 linux-sandbox, 4 local. info: build completed successfully, 11 total actions //python/ray/tune:test_automl_searcher                          (cached) passed in 3.6s //python/ray/tune:test_checkpoint_manager                       (cached) passed in 5.7s //python/ray/tune:test_cluster                                  (cached) passed in 160.8s //python/ray/tune:test_commands                                 (cached) passed in 8.8s //python/ray/tune:test_experiment                               (cached) passed in 3.4s //python/ray/tune:test_tune_restore                             (cached) passed in 193.0s //python/ray/tune:test_actor_reuse                                       passed in 56.4s //python/ray/tune:test_dependency                                        passed in 13.3s //python/ray/tune:test_experiment_analysis                               passed in 95.4s //python/ray/tune:test_logger                                            passed in 8.0s //python/ray/tune:test_ray_trial_executor                                passed in 75.4s //python/ray/tune:test_track                                             passed in 16.4s //python/ray/tune:test_trial_runner                                      passed in 338.6s //python/ray/tune:test_trial_scheduler                                   passed in 60.1s //python/ray/tune:test_tune_save_restore                                 passed in 3.0s //python/ray/tune:test_tune_server                                       passed in 75.4s executed 10 out of 16 tests: 16 tests pass. info: build completed successfully, 11 total actions hopefully, we can bazelify other travis tests in this way too, to improve test reliability with timeouts. </desc> <cmt> wip </cmt> <cmt> add travis </cmt>",bazelify tune tests in travis
2992,"<desc> when passing a component or an html tag in as or forwardedas the props of this component should appear and be allowed in the base component. for example consider the following situation: const button = styled.button; const wrappedbutton = styled(button); const homelink = () => <button as=""a"" href=""/home"">home</button>; const bloglink = () => <wrappedbutton forwardedas=""a"" href=""/blog"">blog</button>; both situations should allow the prop href to be passed. this is related to #50404 this enhances the behavior of pr #49239, which was also the origin of the issue pointed above. the inference of props is working for html tags and react.fc (or similar), i couldn't get the inference of required props of styled-components to work. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> enable as and forwardedas props to be linted </cmt> <cmt> rename component in test </cmt>",enable 'as' and 'forwardedas' props to be linted
2993,"<desc> almost all str functions already had #[inline]. </desc> <cmt> add #[inline] to the utf8error accessors. </cmt> <cmt> add #[inline] to some core::str functions. </cmt> <cmt> almost all these functions already had #[inline]. these were missing. </cmt> <cmt> add #[inline] to {&str, &mut str}::default. </cmt>",add #[inline] to some functions in core::str.
2994,"<desc> follow on to #6731, this pr adds broker-side support for kip-392 (fetch from followers). changes: all brokers will handle fetchrequest regardless of leadership leaders can compute a preferred replica to return to the client new replicaselector interface for determining the preferred replica incremental fetches will include partitions with no records if the preferred replica has been computed adds new jmx to expose the current preferred read replica of a partition in the consumer two new conditions were added for completing a delayed fetch. they both relate to communicating the high watermark to followers without waiting for a timeout: for regular fetches, if the high watermark changes within a single fetch request for incremental fetch sessions, if the follower's high watermark is lower than the leader a new jmx attribute preferred-read-replica was added to the kafka.consumer:type=consumer-fetch-manager-metrics,client-id=some-consumer,topic=my-topic,partition=0 object. this was added to support the new system test which verifies that the fetch from follower behavior works end-to-end. this attribute could also be useful in the future when debugging problems with the consumer. </desc> <cmt> copying work over from prototype pr </cmt> <cmt> don't check replica id when handling fetch requests </cmt>",kafka-8443 broker support for fetch from followers
2995,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues bug fix bug description. how to fix? new feature or improvement describe the details and related test reports. </desc> <cmt> add powered-by.md </cmt> <cmt> add xin.com </cmt> <cmt> update powered-by.md </cmt> <cmt> add xin.com </cmt>,add xin.com to powered-by page
2996,"<desc> closes #39178 tests added / passed ensure all linting tests pass, see here for how to run them </desc> <cmt> tst: groupby.aggregate with empty ndframes with multiindex </cmt> <cmt> remove non-multiindex test </cmt> <iss> bug: multiindexes are disappearing using an empty dataframe, groupby and aggregate using 'list' method </iss>",dataframegroupby.aggregate with empty frame with multiindex
2997,"<desc> prior this commit, 'docker images' and other cmd's, which used utils.humansize(), showed unnecessary whitespaces. formatting of progress has been moved to formatprogess(), justifing the string directly in the template(s). </desc> <cmt> revert ""client: better progressbar output"" </cmt> <cmt> this reverts commit 3ac68f1966222d9a1c0ff867515e3f5c2f83e422. </cmt> <cmt> *client: fix the progressbar, without manipulating other outputs </cmt> <cmt> prior this commit, 'docker images' and other cmd's, which used utils.humansize(), </cmt> <cmt> showed unnecessary whitespaces. </cmt> <cmt> formatting of progress has been moved to formatprogess(), justifing the string </cmt> <cmt> directly in the template. </cmt>","fix progressbar, without messing up other outputs"
2998,"<desc> this pr allows the ast to represent the pub(restricted) syntax from rfc 1422 (cc #32409). more specifically, it makes ast::visibility non-copy and adds two new variants, visibility::crate for pub(crate) and visitibility::restricted { path: p<path>, id: nodeid } for pub(path). plugin-[breaking-change] cc #31645 r? @pnkfelix </desc> <cmt> remove ast::visibility::inherit_from (it is unused and has obsolete semantics) </cmt> <cmt> make ast::visibility non-copyable </cmt> <cmt> add crate and restricted variants to ast::visibility </cmt>",add support for pub(restricted) syntax in the ast
2999,"<desc> format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> async update ip port client heart beat </cmt> <cmt> async push service data </cmt> <cmt> remove unused class </cmt> <cmt> judge ip port tag by server member ability </cmt> <cmt> remove unused codes in healthcheckcommon </cmt> <cmt> add metadata </cmt> <cmt> get client beat check timeout from metadata first. </cmt>",async some time-consuming operation and add metadata
3000,"<desc> currently, the lsp returns only messages from deno_lint; hints are omitted even when they are. some lint rules are very unfriendly in the sense that their diagnostic messages give no information about how the lint errors should be addressed properly without having to suppress them. one example is ban-ts-comment rule, as its message just tells that the directive is disallowed without comment - when seeing this, one may wonder what ""comment"" is. while the message is very unclear, the hint is so informative that it gives a concrete example of how to address it, like add an in-line comment explaining the reason for using @ts-expect-error, like // @ts-expect-error: <reason> therefore, it would be very nice to show not only messages but also hints from deno_lint. this pr appends hints to messages if any. after </desc> <cmt> feat(lsp): add hint to lint diagnostic messages </cmt> <cmt> test(lsp): add test for reference::to_diagnostic </cmt> <cmt> test(lsp): add test for get_lint_references </cmt>",show hints from deno_lint in addition to messages
3001,"<desc> added auto add the file extension in ""save as"" file dialog based on selected filter. the method "" qfiledialog::getsavefilename"" in linux envrionment  doesn't give this possibility, so here is added  ""showsavefiledialog"" class. this class performs what was needed in issue #1399: _- if a graphic format would be selected, the file name is completely ignored and the extension of the selected graphic format would be appended to the entered file name and will be saved in this format. if the filename is empty, the saving process would be aborted. if the file exists, it would be best to ask whether it should be overwritten, if not call the save as dialog again. it would only save the selected file extension entry in the save as dialog and restore this setting the next time._ please review and give remarks based on: </desc> <cmt> draft of saving with auto added extension </cmt> <cmt> taking care of file extension, prepared option to use, wip </cmt> <cmt> added save last used extension, cleaning needed </cmt> <cmt> cleaned </cmt> <cmt> some cleaning </cmt>",auto add file extension when save - issue #1399
3002,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> updating dagre </cmt> <cmt> cleaning up white space </cmt> <cmt> updates based on feedback </cmt> <cmt> fixing tests </cmt> <cmt> updating dagre types </cmt> <cmt> updatinge the dagre types </cmt> <cmt> removing object </cmt> <cmt> adding sinks function </cmt> <cmt> lint </cmt>,updating dagre types based on the wiki
3003,"<desc> the type of a function declaration is entirely determined by the type of its parameters and the type of its result. sema already knows how to calculate the function type from the parameters and result for parsed definitions. factor this out into a method on abstractfunctiondecl, and use it for synthesized and imported declarations. </desc> <cmt> move typechecker::configureinterfacetype() to {abstractfunction,subscript}decl::computetype() </cmt> <cmt> it doesn't actually depend on the type checker, and using </cmt> <cmt> it on synthesized declarations will eliminate a lot of </cmt> <cmt> boilerplate. </cmt> <cmt> ast: use abstractfunctiondecl::computetype() </cmt> <cmt> sema: use abstractfunctiondecl::computetype() </cmt>",factor out abstractfunctiondecl's interface type computation
3004,"<desc> we were already issuing an error for the cases where this cropped up, so this is not fixing any soundness holes. the previous diagnostic just wasn't accurately describing the problem in the user's code. fix #52059 </desc> <cmt> fine tune dianostics for when a borrow conflicts with a destructor that needs exclusive access. </cmt> <cmt> in particular: </cmt> <cmt> 1. extend writekind::storagedeadordrop with state to track whether </cmt> <cmt> we are running a destructor or just freeing backing storage.  (as </cmt> <cmt> part of this, when we drop a box<..<box<t>..> where t does not </cmt> <cmt> need drop, we now signal that the drop of t is a kind of storage </cmt> <cmt> dead rather than a drop.) </cmt> <cmt> 2. when reporting that a value does not live long enough, check if </cmt> <cmt> we're doing an ""interesting"" drop, i.e. we aren't just trivally </cmt> <cmt> freeing the borrowed state, but rather a user-defined dtor will </cmt> <cmt> run and potentially require exclusive aces to the borrowed state. </cmt> <cmt> 3. added a new diagnosic to describe the scenario here. </cmt> <cmt> updates to tests reflecting the diangostic changes in previous commit. </cmt> <cmt> it is worth pointing out that the reason that so few diagnostics are </cmt> <cmt> effected is because of the filter i put in where it only goes down the </cmt> <cmt> new path if the borrowed place is *not* a prefix of the dropped place. </cmt> <cmt> (without that filter, a *lot* of the tests would need this change, and </cmt> <cmt> it would probably be a net loss for the ux, since you'd see it even in </cmt> <cmt> cases like borrows of generic types where there is no explicit mention </cmt> <cmt> of drop.) </cmt> <cmt> regression test for this particular change. </cmt> <iss> nll: implicit reborrow hides error ""cannot move out of struct with destructor"" </iss>",report when borrow could cause &mut aliasing during drop
3005,"<desc> this pr fixes a flaw in the redirect handler included in h2o up to version 1.6.1 / 1.7.0-beta2. when redirect directive is used, this flaw allows a remote attacker to inject response headers into an http redirect response. h2o version 1.6.2 and 1.7.0-beta3 has been released to address this vulnerability. users are advised to upgrade their servers immediately. cve-id for the issue is cve-2016-1133. reported in #682. </desc> <cmt> add failing test </cmt> <cmt> uri-escape the redirect path </cmt>",uri-escape the user-supplied portion of the redirect path (cve-2016-1133)
3006,"<desc> adds multiply(rhs), premultiply(lhs), multiplymatrices(lhs, rhs), multiplytoarray(lhs, rhs, out) and equals(rhs) to matrix3, bringing its mathematical methods into parity with matrix4. code style, implementation and method ordering is modeled on matrix4 and the style guide. this is motivated by the use of matrix3 instances for calculating 2d affine transforms of the form xx yx tx xy yy ty 0  0  1 which can often go where three.js goes, for composing 2d overlays (ui or otherwise), texture transformation in uv space, or dynamically preparing textures with (say) canvasrenderingcontext2d. being generic mathematical operations, the 2d motivation remains incidental - it can of course be used for combining normal transforms, non-translated position transforms, etc. a further enhancement could be to add helper methods to initialize 2d translation / scale / rotate matrices, but i've stopped short of that. i'd leave it as an open question of demand, and should maybe be weighed against potential confusion to newcomers at 2d-oriented methods coexisting with the otherwise clearly 3d purpose of matrix3. 2d transforms are not so hard to create inline where needed. unit tests for the multiplymatrices method of both matrix3 and matrix4 have been added - the latter when i went to look for it as an example, but didn't find. </desc> <cmt> add equality and matrix multiplication methods to matrix3 </cmt> <cmt> add unit tests of multiplymatrices methods for both matrix3 and matrix4 </cmt>",add multiplication and equality methods to matrix3
3007,"<desc> the pull request fixes the following issues: added releasegltexture to cctexture2d.h and .cpp. cached textures need to make sure all of the cached textures on the cpu are released before attempting to create new textures on the gpu. since all of the exisiting textures on the gpu have been wiped out by the device due to an app context switch, the existing gl texture ids are no longer valid. updated the cpp-templates. updated angle libs. cocos2d/cocos2d-x-3rd-party-libs-bin#9 </desc> <cmt> updated app name to app </cmt> <cmt> added releasegltexture to release only the gltexture but leave the rest of the texture object intact. needed to reload cached textures </cmt> <cmt> fixed reloading of textures from volatiletexture cache </cmt> <cmt> release gltextures before reloading cached textures </cmt> <cmt> fixed reloading of cocos2d-x after app switch </cmt> <cmt> updated to latest version of angle to fix memory leak when switching apps </cmt> <cmt> updated fast resume code for app </cmt> <cmt> updated xaml resources </cmt> <cmt> updated template code </cmt> <cmt> added script to copy angle dlls for testing new versions of angle </cmt>",wp8 v3 template and missing texture after app switch fixes
3008,"<desc> continue of azure cross resource groups feature. this pr adds support for unmanaged nodes (such as on-prem or on other clouds) that are labeled with alpha.service-controller.kubernetes.io/exclude-balancer=true and kubernetes.azure.com/managed=false. azure cloud provider would exclude such nodes from loadbalancer backends and always assumes they are existing. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): see kep here. azure cloud provider won't provision network routes for on-prem nodes, so cluster admins should ensure the network (including pod-to-pod, pod-to-node and node-to-node connectivity) has been set up properly. release note: azure cloud provider now supports unmanaged nodes (such as on-prem) that are labeled with kubernetes.azure.com/managed=false and alpha.service-controller.kubernetes.io/exclude-balancer=true /assign @khenidak @andyzhangx /sig azure /milestone v1.12 </desc> <cmt> add on-prem nodes support to azure cloud provider </cmt> <cmt> on-prem nodes should register themselves with required labels, e.g. </cmt> <cmt> kubelet --node-labels=alpha.service-controller.kubernetes.io/exclude-balancer=true,kubernetes.azure.com/managed=false ... </cmt> <cmt> compose routes for on-prem nodes </cmt> <cmt> compose faked routes for unmanaged nodes so that node controller would </cmt> <cmt> assume the routes for them have already been created. </cmt> <cmt> add unit tests </cmt>",add support for unmanaged nodes for azure cloud provider
3009,<desc> performance improvements for meta data loading switched to databasemetadata.gettables for improved performance removed join to constraints from column retrival implemented on access retrieve for properties that take some time to retrieve consistent display of attributes disable script view for views as ddl is allready displayed switched to ddl display for scripts (procedures) add missing texts implement workaround for primary keys that show null column but are not nullable this is necessary for unique detection </desc> <cmt> merged identity column information with autoincrement info </cmt> <cmt> changed to oracle rowid style syntax </cmt> <cmt> performance increase through using metadata api </cmt> <cmt> hide sql text field -> is show in ddl </cmt> <cmt> add missing texts </cmt> <cmt> remove script view -> ddl. use ddl for scripts </cmt> <cmt> show enabled property on pks </cmt> <cmt> add dependencies </cmt>,performance improvement for exasol dbs with a large amount of objects + bugfixes
3010,"<desc> the rationale behind this pr is to expose liblineedit to userland programs, so as to...well, have a line editor, duh. the obvious next-step of this would be to extend liblineedit to support before-flush hooks to allow the program to customise what is displayed (e.g. for instance, to create a syntax-highlighted js repl hint hint) </desc> <cmt> liblineedit: add a new line editor library </cmt> <cmt> this library is moved over from shell/lineedit and has all its </cmt> <cmt> shell-specific functionalities stripped off. </cmt> <cmt> currently it exposes some internal things, for instance </cmt> <cmt> cut_mismatching_chars() and insert(); this behaviour is not the most </cmt> <cmt> acceptable, however, let's just roll with it for now :^) </cmt> <cmt> shell: move lineedit out and add it as a dependency </cmt> <cmt> this builds up on the 'new' liblineedit and overrides some of its hooks </cmt> <cmt> for instance, on_tab_complete_first_token </cmt> <cmt> liblinedit + shell: handle signals </cmt> <cmt> this allows the lineeditor to get notified about signals, since we </cmt> <cmt> cannot set signal handlers in a clean way within the lineeditor </cmt> <cmt> instance. </cmt>",move out lineedit and patch shell to use the new library
3011,<desc> i moved test_universe_json.py from spacy/test/universe/ to .github/ i moved test_universe_json.py and deleted the old file and all references referring to the old file. fixing the validation of universe.json </desc> <cmt> moved universe-test into .github folder </cmt> <cmt> cleaned code </cmt> <cmt> changed a file name </cmt>,moved test for universe into .github folder
3012,"<desc> fairly simple fix, only problem is, i can't see a way to stop this error we throw in the tests from bubbling all the way up:  not sure if nodeunit has a way to disregard errors thrown inside a test? </desc> <cmt> failing auto double callback on error test </cmt> <cmt> fix 'auto calls callback multiple times' issue #410 </cmt> <cmt> improve auto test comment </cmt>",auto final callback gets called too many times in case of exception
3013,"<desc> the plugin schema testing util was using separate functionality causing a diff between valid schemas and those that passed tests. this pr updates the testing util to use our production validation function and makes all existing tests compatible with this change. note it also includes an addition to the gatsby-plugin-typescript schema that was the reason this was uncovered. </desc> <cmt> fix default </cmt> <cmt> validate matching options, add associated test </cmt> <cmt> fix error test </cmt> <cmt> it's only the mismatch that matters </cmt> <cmt> remove test, the utility can't handle external calls yet </cmt> <cmt> use when instead of async </cmt> <cmt> remove keys now that we're not using external </cmt> <cmt> change plugin schema testing function to use validation function </cmt>",update plugin schema testing util and associated tests
3014,"<desc> moves it into the cpp file so any changes to it don't require rebuilds of everything else that includes the mm_u header. while we're at it, we can forward all of the old functions to passthrough to the implementations to make it consistent. </desc> <cmt> mm_u: move implementation class into the cpp file </cmt> <cmt> now if changes are ever made to the behavior of the class, it doesn't </cmt> <cmt> involve rebuilding everything that includes the mm_u header. </cmt> <cmt> mm_u: forward all old variants of functions to the new ones </cmt> <cmt> ensures both variants go through the same interface, and while we're at </cmt> <cmt> it, add finalize to provide the inverse of initialize for consistency. </cmt>",move interface class into the cpp file
3015,<desc> this commits adds support for the get roles api to the hlrc relates: #29827 </desc> <cmt> [hlrc] add support for the get roles api </cmt> <cmt> todo: implement getrolesresponse once suppporting classes for roles </cmt> <cmt> are commited </cmt> <cmt> finalize api support </cmt> <cmt> completes getroles api </cmt> <cmt> fix doc and doc tests </cmt>,add support for get roles api
3016,"<desc> previously we were passing the current theme object to lazily evaluated config closures, but this can lead to an unfortunate amount of boilerplate if you need to check for the presence of a given key before referencing it. this pr makes theme a function instead, where you specify the path to look up as the first argument (using dot notation), and specify a default value if that path doesn't exist as a second argument, just like the theme function available in your css . resolves #770. </desc> <cmt> pass theme to closures as function instead of object </cmt> <cmt> update defaultconfig to use theme function </cmt>",make theme a function instead of an object when passed to config closures
3017,"<desc> fix #9175 only added and verified float16 kernel for the inference mode of cudnn batch norm kernel, which is needed to run vgg/resnet inference. optest.np_dtype_to_fluid_dtype is to change the dtype of a numpy array from float16 to uint16 so that it can correctly bind with paddle float16 in tensor_py.h. </desc> <cmt> initial commit </cmt> <cmt> add python batch norm inference test </cmt> <cmt> add more tests </cmt> <cmt> fix test </cmt> <cmt> update test </cmt> <cmt> fix batch norm fp16 param type </cmt> <cmt> fix scaling param type </cmt> <cmt> update </cmt> <iss> float16 support for batch norm operator </iss>",add float16 support to batch norm operator
3018,"<desc> currently there are two issues with serializing bulkbyscrollresponse. first, when deserializing from xcontent, indexing exceptions and search exceptions are switched. additionally, search exceptions do no retain the appropriate reststatus code, so you must evaluate the status code from the exception. however, the exception class is not always correctly retained when serialized. this commit adds tests in the failure case. additionally, fixes the swapping of failure types and adds the rest status code to the search failure. </desc> <cmt> wip </cmt> <cmt> changes </cmt>",fix issues with serializing bulkbyscrollresponse
3019,<desc> add sources and further reading to http section fix caps and punctuation in rpc section change large scale -> large-scale in intro </desc> <cmt> add sources and further reading to http section </cmt> <cmt> fix caps and punctuation in rpc section </cmt> <cmt> change large scale -> large-scale </cmt>,"polish up http, rpc, and intro sections"
3020,<desc> allows for provider property to be an object to hold provider specific config as discussed in issue 1567 </desc> <cmt> provider property can now be an object </cmt> <cmt> fixed tests for provider config </cmt>,provider property can be an object
3021,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: lazy.js api docs increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. notes: chose to move from ""object"" to ""any"" rather than to ""object"" to support compatibility with typescript versions earlier than 2.2, per the advice of npm test ""lazy.js"". </desc> <cmt> fix lazyjs method return types </cmt> <cmt> revert bad lines </cmt> <cmt> add my name </cmt> <cmt> correction of common mistake: use of ""object"" datatype </cmt> <cmt> object -> any </cmt>","correct methods of lazy.js which return non-sequence values and remove ""object"" typings"
3022,"<desc> issue: #8342 #8444 work in progress for rendering jsx in the code snippet, based on   this solves the following issues: show controls/knobs values dynamically #8342 fix imported story functions from csf into mdx #8444 fix story.bind({}) source for args stories still to be done: expanded test cases handle large objects/arrays gracefully handle corner cases like memo and refs figure out source customization figure out framework compatibility path forward what i need feedback on the approach and test cases we need to worry about to make this robust volunteers to help port this to non-react frameworks see official-storybook </desc> <cmt> source: dynamic source snippet generation wip </cmt> <cmt> refactor useeffect code </cmt> <cmt> be careful to only setstate in useeffect </cmt> <cmt> update comment </cmt> <cmt> source: fix multiple stories overwriting each other </cmt> <cmt> source: add jsxdecorator from storybook-addon-jsx </cmt> <cmt> dynamic source: add test cases </cmt> <cmt> source: fix dynamic snippet updates </cmt>",dynamic source rendering for react
3023,"<desc> this adds basic support for clear linux to our installation process. of note, clear linux does not package libjudy, which means that as of right now dbengine support will not be available on clear linux systems unless the user manually installs libjudy. component name area/packaging description of testing that the developer performed verified that the basic required packages needed for an install of netdata are correctly installed with these changes added. fixes: #8137 @jptuomi if you could test this that would be greatly appreciated (let me know if you need instructions on how to test). to any reviewers who want to test this, be advised that setting clear linux up in a vm is a royal pain in the arse as it refuses to boot if the emulated cpu does not report certain instruction set extensions, refuses to install (even if the install iso boots fine) unless the vm is configured to use uefi for booting, and on top of that their standard setup violates quite a few conventional expectations about linux system administration.  their documentation has install instructions for setting up vm's, though they assume bog-standard usage of whatever hypervisor you're using. </desc> <cmt> disable shellcheck 2034 due to computed variable names. </cmt> <cmt> this particular check throws a large number of false positives in this </cmt> <cmt> file because it cannot see us using the mappings from packages to </cmt> <cmt> per-distro package names since we're accessign them through computed </cmt> <cmt> variable names. </cmt> <cmt> add clear linux support to install-required-packages.sh </cmt> <cmt> this adds preliminary support for clear linux to the </cmt> <cmt> install-required-packages script, which allows users to use the regular </cmt> <cmt> kickstart install script there. </cmt> <cmt> as of right now, this has a significant limitation in that clear linux </cmt> <cmt> does not provide a package for libjudy, meaning that users will not be </cmt> <cmt> able to use the dbengine. </cmt> <iss> install-required-packages.sh fails on clear linux </iss>",added support for clear linux in install-required-packages.sh.
3024,<desc> updated planck keymap to match yttyx niu mini keymap. tidied readme file. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> normalise layout and readme from yttyx niu keymap. </cmt> <cmt> correct case of readme. </cmt>,planck keymap and readme update
3025,"<desc> this adds a new package to the monorepo (gatsby-plugin-utils) that currently exposes a single method: import { validateoptionsschema } from ""gatsby-plugin-utils"" const validatedoptions = await validateoptionsschema(pluginschema, pluginoptions); // ignore ""external"" (i.e. async) validation rules const validatedoptions = await validateoptionsschema(pluginschema, pluginoptions, { validateexternalrules: false ]); </desc> <cmt> feat(gatsby-plugin-utils): initial setup </cmt> <cmt> chore(gatsby-plugin-google-analytics): add pluginoptionsschema </cmt> <cmt> bring joi to my life </cmt> <cmt> add ability to skip async validation rules </cmt> <cmt> more explicit api </cmt>",add package and methods to validate plugin options
3026,<desc> backports #52010 to 2.7 fixes #51481 flatpak_remote </desc> <cmt> flatpak_remote: handle empty output in remote_exists (#52010) </cmt> <cmt> flatpak remote-list -d can return an empty output on fedora 29 (version 1.2.0). </cmt> <cmt> (cherry picked from commit fcb6f136cde38dd562f89cf079abb2450b0d4622) </cmt> <cmt> adds changelog fragment for 52010 backport </cmt>,handle empty output in remote_exists (backport of #52010 to 2.7)
3027,<desc> implementation of #15952. let me know if there's anything i can improve/fix or if the desired api and behavior should change. thanks! </desc> <cmt> adding insertsnippet to texteditor extension api. </cmt> <cmt> fix hygiene error. </cmt> <cmt> texteditor.insertsnippet extension api. </cmt> <cmt> more robust type validation on ext side of insertsnippet. </cmt> <cmt> position/range check for snippet insertion was inverted. </cmt> <cmt> adding insertsnippet to vscode.d.ts. (should it be in vscode.proposed.d.ts?) </cmt> <cmt> adding extension api tests for insertsnippet. </cmt>,adding an overload to texteditor.edit for insertion of a snippetstring
3028,"<desc> whenever a date field is used in a <, >, <=, >= comparison, a range query is built. this includes any output from current_*/now/today functions. this pr adds the format parameter to these range queries and sets the value of the date constant as string. also, it changes the = and != operators to use a range query as well, to have the proper format for the literal used in the equality/non-equality condition. fixes #45139. </desc> <cmt> add format parameter to the range queries built for current_* functions </cmt> <cmt> used in comparison conditions </cmt> <cmt> it class for multi-node setup </cmt> <iss> sql: conditions involving date fields with custom format and sql-generated dates fail </iss>",adds format parameter to range queries for constant date comparisons
3029,"<desc> i've run the latest black with default args on new code. added a footer + footer_align subtitle + subtitle_align property for the panel class, so you can add footers subtitles to the bottom of a panel. examples: test results: </desc> <cmt> create footer + footer_align for panel </cmt> <cmt> update changelog </cmt> <cmt> update contributors </cmt> <cmt> add test </cmt>",create subtitle + subtitle_align for panel
3030,<desc> changes to ginkgo this pulls in: fixed an issue where a pending test within a focused context (or a focused test within a pending context) would skip all other tests. be more consistent about handling sigterm as well as sigint maybe a few other minor bugfixes? </desc> <cmt> update gingko to latest head release </cmt> <cmt> revert hack to handle sigterm in e2e tests. </cmt>,update gingko to latest head release and revert hack to handle sigterm in e2e tests
3031,"<desc> description: not sure how, but worked during testing, release gave me an issue iterating over state_attributes. fixed that and passed the display name as the host name for device tracker known devices. related issue (if applicable): fixes #3331 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io# example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.io if code communicates with devices, web services, or a: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> iterate over items </cmt> <cmt> pass display name as host name </cmt> <iss> automatic device_tracker component throws a traceback when 2 or more cars are tracked by automatic </iss>",automatic device tracker bug fix
3032,<desc> currently the compat src has vnode compat functions spread across a couple different functions making it hard to modify (should i add it normalizevnode? createelement? handleelementvnode?). this pr simplifies vnode compat by inline all of those disparate functions into the options.vnode hook. every vnode that is created (including cloneelement) goes through this options hook so it guarantees vnode compat is consistently applied. also saves some bytes! </desc> <cmt> inline applyclassname (-7 b) </cmt> <cmt> inline handleelementvnode (+1 b) </cmt> <cmt> inline createelement compat into vnode option  (-26 b) </cmt> <cmt> inline normalizevnode (-10 b) </cmt> <cmt> simplify classname compat (-5 b) </cmt>,consolidate vnode compat options (-62 b)
3033,<desc> how to test git clone -b branch  cd hexo npm install npm test </desc> <cmt> refactor(sinon): useful sinon.stub() </cmt> <cmt> refactor(sinon): useful calledwith**() </cmt> <cmt> refactor(test): useful destruct assign </cmt> <cmt> remove(package): remove no use packages </cmt>,replace from rewire to sinon.stub()
3034,<desc> merging #157 which had conflicts and needed a manual merge. </desc> <cmt> implemented single and singleordefault methods </cmt> <cmt> updated single/singleordefault according to review request </cmt> <cmt> merge remote-tracking branch 'mairbek/single' </cmt> <cmt> added @throws javadocs </cmt> <cmt> suppressed rawtypes warnings </cmt> <cmt> conflicts: </cmt> <cmt> language-adaptors/rxjava-groovy/src/test/groovy/rx/lang/groovy/observabletests.groovy </cmt> <cmt> rxjava-core/src/main/java/rx/observable.java </cmt>,manual merge of mairbek/single pull #157
3035,"<desc> this pr is the first batch of licensing updates for our connectors. it adds notice an licenses to the cassandra, es1, es2, es5 and kinesis connectors. manually verified. for a given module, compile the module and check that the jar does not contain license/notice files in the root directory check that the jar does not contain any license.txt/notice files in the root or meta-inf directory take the pom.xml (specifically the maven-shade-plugin configuration) and check that all (non-flink) dependencies that are included in the jar are listed in the notice file under src/main/resources/meta-inf for modules that do not explicitly list the included modules (i.e. use *:* for the artifactset) you can use mvn dependency:list -dincludescope=runtime to find out which dependencies would be bundled (beware of filters in the shade-plugin configuration!) check that we include the license under src/main/resources/meta-inf/licenses for each dependency that is not licensed under the aslv2 </desc> <cmt> [flink-11023] add license & notice files for flink-connector-cassandra </cmt> <cmt> [flink-11023] add license & notice files for flink-connector-elasticsearch </cmt>",add license & notice files for connectors (batch #1)
3036,"<desc> generate no_size_average criterion tests rather than specifying them explicitly double backwards support for softmarginloss, marginrankingloss test for crossentropyloss double backwards (it was already supported, just not tested). </desc> <cmt> generate no_size_average criterion tests by specifying check_no_size_average=true </cmt> <cmt> support double backwards for softmarginloss. </cmt> <cmt> support marginrankingloss double backwards. </cmt> <cmt> test crossentropyloss double backwards. </cmt>",double backwards loss function improvements
3037,<desc> i hereby agree to the terms of the cla available at:  fix build due to some missed includes. </desc> <cmt> add missed #include <optional> </cmt> <cmt> std::optional<> is used multiple times here. </cmt> <cmt> add missed #include <optional> </cmt> <cmt> this is required for std::optional<std::string> language; </cmt> <cmt> add missed #include <limits> </cmt>,fix some more missed includes
3038,<desc> this activates parallel builds when using msbuild (like on jenkins) (for main solution and pvr addons). it also increases the number of processes the mingw-make will spawn from numcpus to numcpus*1.5 (which is the recommended setting). @wsoltys i think this gives a couple of minutes speedup on our vm... </desc> <cmt> [win32/jenkins] - activate multi processing for win32 build </cmt> <cmt> [win32/jenkins] - add parallel compile for pvr addons and use 1.5 * cpu count for make </cmt>,speed up compilation by activating parallel builds
3039,<desc> supersedes: #22299 </desc> <cmt> remove link to join slack </cmt> <cmt> the atom slack channel will be winding down on july 1st 2021 </cmt> <cmt> this is in a bid to consolidate community activity on one platform github discussions </cmt> <cmt> remove link to discuss forum </cmt> <cmt> the atom discuss forum winded down on may 1st 2021. this is in a move to </cmt> <cmt> consolidate community activity on one platform github discussions </cmt>,update readme.md to match the move to github discussion
3040,<desc> need the correct initialization without which the verifier would reject the code. </desc> <cmt> updating my local repo </cmt> <cmt> fix issue 829 </cmt> <cmt> needed to make array initialized to null before bpf_probe_read as the </cmt> <cmt> verifier was rejecting the original code. will probably need to fix the </cmt> <cmt> tutorial as well </cmt>,fix for issue 829 i reported
3041,"<desc> this pull request implements idea covered in #1794 issue. now it is easier (at least in my opinion) to focus on the dump widget, instead of the disassembly widget which doesn't change when following some addresses </desc> <cmt> gui: added backgroundflickerthread class </cmt> <cmt> gui: added getattention method to cpudump </cmt> <cmt> gui: changed implemenation of getdumpattention in cpumultidump, implemented idea from #1794 </cmt>",flashing background instead of border when following reference in dump
3042,"<desc> xref #36833 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry extracted describe_series, describe_frame and select_column in pandas/core/describe.py. the next time i think i will introduce the classes seriesdescriber and dataframedescriber and will start moving the functions into the methods incrementally, if that is ok. </desc> <cmt> ref: make function public </cmt> <cmt> ref: extract functions in describe </cmt>",extract more functions in pandas/core/describe.py
3043,"<desc> currently the translog constructor is capable both of opening an existing translog and creating a new one (deleting existing files). this pr separates these two into separate code paths. the constructors opens files and a dedicated static methods creates an empty translog. this pr is part of a bigger refactoring in #28245 , so please ignore any ugliness in the engine code. </desc> <cmt> simplify translog opening </cmt> <cmt> lint </cmt> <cmt> fix testdifferenthistoryuuiddisablesopsrecovery </cmt> <cmt> fix 20_translog.yml </cmt> <cmt> eol </cmt> <cmt> eol2 </cmt> <cmt> 20_tanslog.yml take 2 </cmt> <cmt> fix docs </cmt>",simplify the translog constructor by always expecting an existing translog
3044,"<desc> it is an addition to an existing chart this pr adds the ability to specify the loadbalancersourceranges attribute on the service object of envoy. it is used by aws (and hopefully in the future by additional public cloud providers) to allow whitelisting the load balancer's inbound traffic to a set of cidr-formatted ip ranges. for example, to allow inbound traffic to the proxy from two specific ip ranges, write: service: loadbalancersourceranges: - 192.88.99.0/24 - 192.0.2.0/24 special comments for the reviewer: tested on a eks v1.17 cluster with a network load balancer dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> added loadbalancersourceranges to values.yaml </cmt> <cmt> added loadbalancersourceranges to service.yaml </cmt> <cmt> bump envoy's chart version to v1.9.2 </cmt> <cmt> added variable documentation to readme.md </cmt> <cmt> revised golang syntax to remove a redundant line </cmt>",added loadbalancersourceranges for service objects
3045,"<desc> we had been testing whether a user had passed a value for maxdirectmemorysize by parsing the output of ""java -xx:printflagsfinal -version"". if maxdirectmemorysize equals zero, we set it to half of max heap. the problem is that on windows with jdk 8, a jdk bug incorrectly truncates values over 4g and returns multiples of 4g as zero. in order to always respect the user-defined settings, we need to check our input to see if an ""-xx:maxdirectmemorysize"" value has been passed. it may seem that the logic here could be slightly tighter: we could check for the maxdirectmemorysize flag only on windows/jdk8. but in practice, i believe that on all other systems, maxdirectmemorysize == 0 will only be true when a user sets maxdirectmemorysize to 0 (or to a value greater than 8 exbibytes ((2^63)), which i believe not a presently realistic value). fixes #44174 relates #48365 </desc> <cmt> always pass user-specified maxdirectmemorysize </cmt> <cmt> we had been testing whether a user had passed a value for </cmt> <cmt> maxdirectmemorysize by parsing the output of ""java -xx:printflagsfinal </cmt> <cmt> -version"". if maxdirectmemorysize equals zero, we set it to half of max </cmt> <cmt> heap. the problem is that on windows with jdk 8, a jdk bug incorrectly </cmt> <cmt> truncates values over 4g and returns multiples of 4g as zero. in order </cmt> <cmt> to always respect the user-defined settings, we need to check our input </cmt> <cmt> to see if an ""-xx:maxdirectmemorysize"" value has been passed. </cmt>",don't drop user's maxdirectmemorysize flag on jdk8/windows
3046,"<desc> an updated version of #15081 which was reverted in #16456. the changes relative to the original pr, based on the discussion following #15081 (comment), are: the name of the socket file is now just atom-#{atominstancedigest}.sock with explicit version info removed. this way the socket file name will have a fixed length and should always fit within the limit. atom version and platform architecture information goes into the digest. the digest is now the first 12 characters of the base64 encoded hash (using the url and filename safe alphabet, so besides numbers and letters the digest may also contain -_=). i cherry picked the original commit and added the updates as a separate commit. the pr should probably be squashed when merging. </desc> <cmt> allow independent atom instances </cmt> <cmt> by having an $atom_home-dependent part in the socket name, atom </cmt> <cmt> instances that have different homes will run in independent processes. </cmt> <cmt> fixes the current behaviour where starting atom with a new $atom_home </cmt> <cmt> ""opens"" an atom window with settings and packages from the original </cmt> <cmt> $atom_home. useful for ides. </cmt> <cmt> make socketpath shorter </cmt> <cmt> to work around the limited socket file length on macos/bsd. </cmt>",independent atom instances (per $atom_home) v2
3047,"<desc> hi! as discussed on the issue #215, i modified, merged and cleaned the ""param-miner"" headers wordlists from @albinowax 's burpsuite extention. hit me up if you find anything wrong or if the directories are not following the logic of the hierarchy. cheers! </desc> <cmt> added the wordlists from param-miner extension of burpsuite by @albinowax </cmt> <cmt> deleted the params and functions wordlists. merged the boring_headers and headers file together then created a version with uppercases 1st letters (including after dashes) and a full uppercase version. every file have been sorted with -u option to delete duplicates. hit me up if you find something wrong. </cmt>",cleaned and added the headers from @albinowax's burpsuite param-miner extension
3048,"<desc> pagination and snapshots for get snapshots api, build on top of the current implementation to enable work that needs this api for testing. a follow-up will leverage the changes to make things more efficient via pagination. relates #73570 which does part of the under-the-hood changes required to efficiently implement this api on the repository layer. </desc> <cmt> bck </cmt> <cmt> sorting </cmt> <cmt> bck </cmt> <cmt> works </cmt> <cmt> limit </cmt> <cmt> bck </cmt> <cmt> bck </cmt> <cmt> works </cmt> <cmt> works </cmt> <cmt> bck </cmt> <cmt> bck </cmt> <cmt> better test </cmt> <cmt> works </cmt> <cmt> docs ... </cmt>",pagination and sorting for get snapshots api
3049,"<desc> draft because i'm not able to run tests / compile on this machine at the moment, but the code is pretty much done and ready for input. a problem with this approach is that after text is logged, if the user changes the theme, the logged text won't change color. one thing i considered was keeping the css rules but with css variables and dynamically changing the variables, but that seemed like it was introducing a lot of unnecessary complexity for an issue that isn't even much of an issue at all (the debug console is cleared often anyway). will fix #63986 and fix #42388. </desc> <cmt> pass ithemeservice to handleansioutput and add setbasiccolor method </cmt> <cmt> implement setbasiccolor function and change to switch statement </cmt> <cmt> use setbasiccolor in set8bitcolor </cmt> <cmt> update changecolor function to use only custom colors </cmt> <cmt> rename customcolor to color </cmt> <cmt> update tests to account for new styling method </cmt> <cmt> remove ansi color styling from repl css </cmt> <cmt> check colorindex explicitly against undefined (can be 0) </cmt> <cmt> add braces around switch cases and break default case </cmt> <iss> debug console should use theme-defined red/green colors </iss> <iss> support high intensity ansi colours in debug console </iss>",use active theme colors for styled text in the debug console
3050,<desc> new keycap for keebio.io/iris rev.4. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> create keymap.c </cmt> <cmt> create config.h </cmt> <cmt> update first revision </cmt> <cmt> enhance keymap </cmt> <cmt> enhance keymap </cmt> <cmt> update keymap </cmt> <cmt> make via compatable </cmt>,keymap for keebio/iris rev.4 supporting via
3051,<desc> addresses #21350 fixed docstring to allow linkage_tree docstring to pass numpydoc validation. work done with @fortune-uwha. #dataumbrella sprint @reshamas </desc> <cmt> doc numpydoc removed linkage_tree from function_docstring_ignore_list </cmt> <cmt> doc numpydoc fixed linkage_tree func docstring </cmt>,doc ensures that linkage_tree passes numpydoc validation
3052,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> updated types to version 3 </cmt> <cmt> added tests to version 3 </cmt> <cmt> added tests to version 3 </cmt>,updated types for lolex to the current version (3)
3053,"<desc> in case of a conjunction involving the same date field, the optimizer creates a single range query for that field with both from and to populated. in the specific case of date literals generated by es sql (now(), today(), current_timestamp() etc) we are enforcing the date format of the range query so that a potentially custom format for the date field is not used by default by elasticsearch instead. similar logic here fixes #48033. </desc> <cmt> add ""format"" to ""range"" queries resulted from optimizing a logical and </cmt> <cmt> set of conditions involving date/datetime literals. </cmt> <iss> sql: multi-conditionals on date fields with now() don't use the format for range queries </iss>","add ""format"" for ""full"" date range queries"
3054,"<desc> in preparation for the beta and ga launch of ""file system route api"" (or ""unified routes"" internally) i'm adding an example to our examples folder that can be a reference for the documentation and testing. while going through the doc to create the example i updated said doc and uncovered some issues which i'll also list internally. i updated the doc that we linked to in the first promotion and which we'll link to for the beta. once we move to ga status we need to rename that doc and change the documentation around docs/routing overall. but that's for another pr. </desc> <cmt> add example and first bits of change in docs </cmt> <cmt> rename example folder </cmt> <cmt> update doc a bunch </cmt> <cmt> add more examples </cmt> <cmt> fix doc link </cmt>","add ""file system route api"" example & update docs"
3055,"<desc> a new cisco aci module is needed, this fixes #43106 new module pull request aci_access_port_block_to_access_port ansible version goal is to add the new module and also the deprecation information with ansible 2.8. deprecation will be effective with ansible 2.12 like discussed in the issue #43106 this new module is needed so that we can also safely delete things (e.g. port blocks) without deleting a complete port selector/access port. we dont have 1:1 relationship between a port selector and an access port block. its 1:x ! </desc> <cmt> added new module aci_access_port_block_to_access_port </cmt> <cmt> changed documentation strings </cmt> <iss> aci_access_port_to_interface_policy_leaf_profile reports changed when child infraportblk exist </iss>",aci_access_port_block_to_access_port and deprecations in aci_access_port_to_interface_policy_leaf_profile
3056,"<desc> currently, the too many workers warning can occur due to many io workers (the default is 4*2 = 8), or due to a healthy amount of ray.get() calls. try to reduce the number of false positives for the warning by subtracting the io worker count, and increasing the threshold slightly. </desc> <cmt> warning loosen </cmt> <cmt> update </cmt>",be more conservative in warning about too many workers
3057,"<desc> i have found the previous explanation of manual gradient calculation a little confusing because we compute a vector of gradients with the size of number of neurons (with bias) and in the explanation it looks like we compute a scalar. propose more detailed variant if community finds it's better. excuse me if  it is convenient to write x_i even for bias unit, just discard this then. attach old and new variant of just last notebook text cell saved to pdf (cannot attach ipynb here). the differences in the description of second line of code. old.pdf new.pdf </desc> <cmt> merge remote-tracking branch 'refs/remotes/tensorflow/master' </cmt> <cmt> gradient calc description change </cmt> <cmt> i have found the previous explanation of manual gradient calculation a </cmt> <cmt> little confusing because we compute a vector of gradients with the size </cmt> <cmt> of number of neurons (with bias) and in the explanation it looks like we </cmt> <cmt> compute a scalar. </cmt> <cmt> propose more detailed variant if community finds it's better. excuse me </cmt> <cmt> if  it is convenient to write x_i even for bias unit, just discard this </cmt> <cmt> then. </cmt>",gradient calc description change it text cell
3058,"<desc> make sure you have checked all steps below. jira my pr addresses the following airflow jira issues:  this pr: adds a default _request_timeout in airflow.cfg, so that default installations will not hang indefinitely catches the errors in the scheduler, and retries scheduling the task, in a similar fashion to how apiexcptions are caught. ( airflow/airflow/executors/kubernetes_executor.py lines 800 to 803 46885cc except apiexception as e: self.log.warning('apiexception when attempting to run task, re-queueing. ' 'message: %s' % json.loads(e.body)['message']) self.task_queue.put(task) fixes a bug in the parsing of airflow.cfg. the notes state that a json dict is expected. this is parsed with json.loads, which returns a dict. but in the code, .iteritems() is called on this dict, which cannot work. .items() should be used instead. my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 </desc> <cmt> catch urllib3 httperror in kube executor </cmt> <cmt> fix parsing of kube_client_request_args </cmt> <cmt> change default timeout </cmt>",add default timeout on kubeclient & catch httperror
3059,"<desc> in the effort to make agent configuration easier, i'm continuing to reorganize how this information is connected and displayed on learn. this pr contains two new files, about starting/stopping/restarting the agent, and common configuration changes, and deprecates the old configuration guide, with information that's been reproduced and updated elsewhere, at /docs/configuration-guide.md. component name area/docs </desc> <cmt> finish new common config doc, delete old one </cmt> <cmt> small tweak to blockquote </cmt> <cmt> add new files </cmt>",improve configuration docs with common changes and start/stop/restart directions
3060,<desc> arrow layout_all renamed to layout_all left layout_ansi renamed to layout_ansi numpad matrix macro correction (keycodes were going to be received out of order) added support for community layouts numpad_5x4 and ortho_5x4 right layout_ansi renamed to layout_ansi layout_iso renamed to layout_iso layout_hhkb_ansi renamed to layout_hhkb_ansi layout_hhkb_iso renamed to layout_hhkb_iso global readme cleanup (minor grammar corrections) added configurator support for all four parts </desc> <cmt> arrow: matrix and keymap refactor </cmt> <cmt> left: matrix and keymap refactor </cmt> <cmt> numpad: matrix macro correction </cmt> <cmt> numpad: add support for community layouts numpad_5x4 and ortho_5x4 </cmt> <cmt> right: matrix and keymap refactor </cmt> <cmt> dc01 global readme cleanup (minor grammar) </cmt> <cmt> dc01 global configurator support </cmt>,dc01 refactor and configurator support
3061,<desc> this includes a small patch to allow running tests without llvm. also check if you are not trying to compile a dylib. cc #42932 r? @alexcrichton </desc> <cmt> less cfg's </cmt> <cmt> remove some more cfg's </cmt> <cmt> fix tidy errors </cmt>,"cleanup for ""support compiling rustc without llvm (try 2)"""
3062,"<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> multiply aggregate state </cmt> <cmt> test aggregation state multiply </cmt> <cmt> shift arguments, some problem seems found! </cmt> <cmt> fix and optimize multiplying aggregate states </cmt>",clickhouse-3723 multiply aggregate states. fix and optimize #2527.
3063,"<desc> i rebased #2888 onto master and was faced with mega conflicts.  in resolving these i: wanted the filelists to be part of the general iterator mechanism, instead of having a workdir iterator and a workdir+filelist iterator did not want a third diff path maching mechanism (pathspecs, non-pathspecs and slightly more literal iterator filelists). so this moves the filelists into the general iterator mechanisms, and it expands the filelist handling to deal with directory prefixes (eg, foo/) instead of requiring that patches be listed explicitly. note that this should be generally adequate and a huge perf benefit for index and workdir iterators (like the original was), and tree iterators are working, but they expand all trees unnecessarily.  we could perform tree iteration without necessarily expanding all trees (like we do with the filesystem iterator) but this should be correct and still more performant in that case.  we can handle that in the future, though with more aggressive refactoring in that iterator. </desc> <cmt> iterator: use an options struct instead of args </cmt> <cmt> move filelist into the iterator handling itself. </cmt> <cmt> racy-git: todo to use improved diffing </cmt> <cmt> iterator: sort subdirs properly with pathlist </cmt> <cmt> when given a pathlist, don't assume that directories sort before </cmt> <cmt> files.  walk through any list of entries sorting before us to make </cmt> <cmt> sure that we've exhausted all entries that *aren't* directories. </cmt> <cmt> eg, if we're searching for 'foo/bar', and we have a 'foo.c', keep </cmt> <cmt> advancing the pathlist to keep looking for an entry prefixed with </cmt> <cmt> 'foo/'. </cmt> <cmt> diff: better document git_diff_pathspec_disable </cmt> <cmt> document that git_diff_pathspec_disable is not necessarily about </cmt> <cmt> explicit path matching, but also includes matching of directory </cmt> <cmt> names.  enforce this in a test. </cmt> <cmt> diff: use new iterator pathlist handling </cmt> <cmt> when using literal pathspecs in diff with git_diff_disable_pathspec_match </cmt> <cmt> turn on the faster iterator pathlist handling. </cmt> <cmt> updates iterator pathspecs to include directory prefixes (eg, foo/) </cmt> <cmt> for compatibility with git_diff_disable_pathspec_match. </cmt> <cmt> tree_iterator: use a pathlist </cmt> <cmt> checkout: use pathlist-based iterators </cmt> <cmt> status test: brackets are now literal </cmt> <cmt> diff: drop filelist_match </cmt> <cmt> now that non-pathspec matching diffs are implemented at the iterator </cmt> <cmt> level, drop filelist_matching. </cmt>",provide path matching in the iterators (for faster diffs)
3064,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  godoc.org:  goreportcard.com:  coverage service link:  very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have an appropriate description with correct grammar. i know that this package was not listed before. i have added godoc link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> added ptrie </cmt> <cmt> added abstract file storage </cmt>","added abstract file storage (file,scp,gs,s3,mem)"
3065,<desc> closes: #8568 alb event path should have been optional. however omission of the path would result in a failure in deployment. this pr addresses the issue by excluding the path when it is not set </desc> <cmt> support optional path in alb event </cmt> <cmt> exclude alb event path condition when empty </cmt> <cmt> omit path conditions when null in alb events </cmt> <iss> alb listener path should be optional </iss>,make alb event path optional
3066,"<desc> this improves estimator method detection in the test_docstrings.py. previously all objects in the estimator class namespace were considered as methods (which kind of worked in most cases). this restricts method search only to callable objects, and also applies a fix for properties as inspect.signature doesn't work for those. this previously producing errors in the validator (see e.g. #15509) </desc> <cmt> maint improve method dectection in test_docstrings.py </cmt> <cmt> fix for properties </cmt>",maint improve method detection in numpydoc validation script
3067,"<desc> this is not really a book, but it shows history of programming languages nicely. </desc> <cmt> add a link to mother tongues of computer languages </cmt> <cmt> great poster! </cmt> <cmt> add mother tongues of computer languages poster </cmt>",add a link to mother tongues of computer languages poster
3068,<desc> this pr fixes the issue #2669 if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added floyds algorithm for linkedlist loop </cmt> <cmt> added merge sort algorithm with no extra space </cmt>,added merge sort with o(1) space
3069,"<desc> use getwidenedtypeforvariablelikedeclaration, instead of directly calling trygettypefromeffectivetypenode. this requires some changes in the former function since it can't assume that the declaration has an initializer. see below for details. isoptional now calls isoptionaljsdocpropertyliketag. isoptionaljsdocpropertyliketag now handles jsdocpropertytag (previously it was named isoptionaljsdocparametertag). getwidenedtypeforvariablelikedeclaration now handles @param and @property tags. i switched a couple of places to use type guards and added a call to hasexpressioninitializer. then, to avoid calling it twice, i moved a js-only check inside that block. i'm not certain it's the right thing -- the code is cleaner now, but i could have left it as-is and added casts instead. if performance is worse it's the first thing i'm going to try undoing. fixes #39111 </desc> <cmt> more consistent checking of @property/@param </cmt> <cmt> 1. use getwidenedtypeforvariablelikedeclaration, instead of directly </cmt> <cmt> calling trygettypefromeffectivetypenode. this requires some changes in </cmt> <cmt> the former function since it can't assume that the declaration has an </cmt> <cmt> initializer. </cmt> <cmt> 2. isoptional now calls isoptionaljsdocpropertyliketag. </cmt> <cmt> 3. isoptionaljsdocpropertyliketag now handles jsdocpropertytag </cmt> <cmt> (previously it was named isoptionaljsdocparametertag). </cmt> <cmt> rename to isoptionaljsdocpropertyliketag </cmt> <iss> jsdoc optional property </iss>",better checking of @param/@property tags
3070,"<desc> resolves devrel-947 updates cli options according to pr #9595 updates examples for various queries adds description to each query adds query results select one </desc> <cmt> replace -k,--key with -i,--index in cleos git kv_table reference :doc </cmt> <cmt> add remarks section in cleos get kv_table reference :doc </cmt> <cmt> add remaining rows explainer in remarks section of cleos get kv_table :doc </cmt> <cmt> update examples in cleos get kv_table reference, add query results :doc </cmt>",update cleos get kv_table reference
3071,"<desc> cut/paste timedelta and _timedelta methods into tslibs.timesdeltas._timedelta.  the moved methods are copied verbatim. timedelta._binary_op_method_timedeltalike and timedelta._op_unary_method do not use self, are moved out of the class definitions (but stay in tslib).  (in a follow-up _op_unary_method can be moved to tslibs.timedeltas, _binary_op_method_timedeltalike cannot.) most of the rest of _timedelta&timedelta can be moved into tslibs.timedeltas._timedelta after #17793. on the side, cleanup in core.indexes of redundant isinstance checks. tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> simplify redundant isinstance checks </cmt> <cmt> move pieces of timedelta and timedelta to tslibs.timedeltas; </cmt> <cmt> move _op_unary_method and _binary_op_method_timedeltalike out of timedelta namespace </cmt>",port timedelta implementation to tslibs.timedeltas
3072,"<desc> moves us two weeks forward. commits: facebook/react-native@d3c7e20...e612d3a in a stroke of luck, i couldn't find anything apparent that we should care about from upstream commits. </desc> <cmt> integrate 10-8-21 nightly build </cmt> <cmt> moves us two weeks forward. </cmt> <cmt> commits: </cmt> <cmt> in a stroke of luck, i couldn't find anything apparent that we should care about from upstream commits. </cmt> <cmt> change files </cmt>",integrate october 7 nightly build
3073,<desc> the scheduledevent class has never preserved the time zone so it makes more sense for it to store the start and end time using instant rather than zoneddatetime. closes #38620 </desc> <cmt> changing the zonedtimezone type to instant to address the issue </cmt> <cmt> refactoring the tests based on the changes in the scheduledevents </cmt> <cmt> removing unused imports </cmt> <iss> [ml] scheduledevent takes and stores zoneddatetime but then discards the timezone </iss>,refactoring scheduled event to store instant instead of zoned tme zone
3074,<desc> fixed progress bar not completing after video end before: see #6180 fixes #6180 i read the contribution guidelines. </desc> <cmt> fixed progress bar not completing after video end </cmt> <cmt> referenced issue in code </cmt> <iss> progress bar not matching short video </iss>,fixed seekbar not completed after video end
3075,"<desc> this is a kinda ugly special-purpose solution that will break if we suddenly add a fourth namespace, but i hope to come up with something more general if i get to import resolution refactoring this summer. fixes #50187 thus removing a blocker for stabilization of use_extern_macros </desc> <cmt> resolve (cleanup): get rid of option in perns </cmt> <cmt> better support for import resolution in 3 namespaces </cmt>",fix an unresolved import issue with enabled use_extern_macros
3076,"<desc> upstream llvm is planning to raise their minimum toolchain requirements, so they may start using c++14 features. this new policy has already landed in the form of a ""soft"" error.  for gcc, they will require at least version 5.1. this pr moves our crosstool-ng builders to their max gcc 5.2, with a few small patches to fix compatibility. the dist-x86_64-linux builder is updated to gcc 5.5 and llvm/clang 8.0.0-rc2, which also affects dist-i686-linux sharing the same scripts. r? @alexcrichton </desc> <cmt> [ci] update crosstool-ng builders to gcc 5.2 </cmt> <cmt> [ci] update dist-x86_64-linux to gcc 5.5 </cmt> <cmt> this also updates dist-i686-linux, since it borrows the same scripts. </cmt> <cmt> while we're at it, update llvm+clang+lld to llvm-project 8.0.0-rc2. </cmt>",update gcc in the dist-linux builders
3077,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. this is a recreation of #13024 on master. </desc> <cmt> pouchdb-core fixes. </cmt> <cmt> pouchdb-core fixes. </cmt> <cmt> pouchdb-mapreduce additions. </cmt> <cmt> # conflicts: </cmt> <cmt> #	pouchdb-core/index.d.ts </cmt> <cmt> # conflicts: </cmt> <cmt> #	pouchdb-core/index.d.ts </cmt> <cmt> #	pouchdb-core/pouchdb-core-tests.ts </cmt> <cmt> add semicolons. </cmt> <cmt> mapreduce fixes from code review. </cmt> <cmt> add third parameter to pouchdb.adapter() </cmt> <cmt> make pouchdb.adapter() third parameter optional. </cmt> <cmt> duplicate docs for overloaded functions. </cmt> <cmt> remove pouchdb.adapter(...) definition. </cmt>,pouchdb core fixes and mapreduce additions
3078,<desc> a first intermediate step in the query parsing refactoring proposed in #10217. it merges the current parser code from *queryparser into the corresponding builder & deleting the former. in some cases the current implementation of the parsers require a no-arg constructor for the guice injection. in cases where the original builder class has final fields these are set to either null or a default value where possible. </desc> <cmt> query parser refactoring: delete parser q-s </cmt> <cmt> query parser refactoring: delete parser t-z </cmt>,merging parser and builder classes
3079,<desc> eventually i'd like to get the structure of __setitem__ to parallel the structure of __getitem__.  some big improvements to both will be available following #33404. </desc> <cmt> type </cmt> <cmt> remove _is_unorderable_exception </cmt> <cmt> cln: remove unnecessary clauses from series.__setitem__ </cmt>,remove unnecessary branches in series.__setitem__
3080,<desc> here are some small unit-tests for the clock class (it's not complicated so there are just two tests). in addition there is a little update in the clock.js file where the now()-calculation is extracted in it's own function (dry and better to debug if there are lacks in native now() code). </desc> <cmt> extract now calculation in clock </cmt> <cmt> add unit tests for clock </cmt>,clock additions and unit-tests for clock
3081,"<desc> this is part of preparation for python support, and gets rid off runtime properties at the function and module levels. don't merge until austen has components automatically saving themselves to the state object at create-time, or this will break the component-create action. </desc> <cmt> use a passed-in runtime, but default to nodejs </cmt> <cmt> remove .runtime property from module </cmt> <cmt> typofix </cmt> <cmt> hide runtime at component-level behind a function on the serverlessfunction object </cmt> <cmt> propagate rename </cmt>",get rid of runtime property hardcoding
3082,"<desc> minor refactors to #13350 renames variables trying to use the same variables shown in the reference. uses lam and q when dealing with eigen decomposition, and u and v are used when using svd. always use n_samples first when comparing to n_features in comments. the goal of this pr is to make this code easier to read/maintain in the future. </desc> <cmt> cln renames variables to be more clear </cmt>",ridgecv minor refactor to improve readability
3083,"<desc> this fixes the uri's in the manual install documentation to point to the correct location for the install-required-packages.sh script (it got moved to the main repo and is not kept up to date in the demo-site repo anymore), as well as adding more explicit instructions for centos / rhel 6 about needing to enable epel and an additional repo. component name area/docs relevant to: #8081 </desc> <cmt> use correct uri for install-required-packages.sh </cmt> <cmt> it got moved into the main repo a while back, but this part of the docs </cmt> <cmt> never got updated. </cmt> <cmt> add info about prep for manual install on centos 6. </cmt>",update the manual install documentation with better info.
3084,"<desc> hi jens, i did a new pr with cleaned commits (+added a1 and a3 modes). i'm not sure how you use the tools/test.sh, i tested only tools/test.pl that seems to be fine. cheers, ps: for motivation/context i published a post in our corp blog here -- mathieu </desc> <cmt> implement 7701/7801 sap codvn half-hashes </cmt> <cmt> add tests for 7701/7801 </cmt>","poc for cracking sap ""half hashes"" codvn b+f/g"
3085,"<desc> import assets.json updates from master fix handling of 3-letter language codes </desc> <cmt> adress </cmt> <cmt> add more languages for list selection at install/reset time </cmt> <cmt> related issue: </cmt> <cmt> - </cmt> <cmt> also, the handling of 3-letter language codes has been fixed. </cmt> <cmt> forgot to add lij re. </cmt> <cmt> cater to legacy javascript engines </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> removed seemingly abandoned ""dnk: schacks"" list </cmt> <cmt> related discussion: </cmt> <cmt> - </cmt> <cmt> remove ""rus: adguard russian"" from stock filter list </cmt> <cmt> as per feedback from maintainers, adguard russian </cmt> <cmt> and ru adlist are incompatible and web site breakage </cmt> <cmt> can occur when both are used together. </cmt> <cmt> related issue: </cmt> <cmt> - </cmt> <cmt> rename ""fanboy cookie"" to ""easylist cookie"" + update list link </cmt> <cmt> related issue: </cmt> <cmt> - </cmt>",import assets.json updates from master to firefox-legacy
3086,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description listing imports on ld-uclibc results on 1 entry which is filled by zeros. maybe t shouldnt be there, but in case is there it shouldnt be asserting because of null strings. test plan i added a test which shows the current output closing issues fixes #16455 </desc> <cmt> fix asserts in iij for ld-uclibc with a null import ##bin </cmt> <cmt> add test for iij on ld-uclibc </cmt> <iss> error while parsing elf mips imports </iss>",fix #16455 - iij asserts for ld-uclibc with a null import ##bin
3087,<desc> this pr causes the entities created by zha to get updated when the associated zigbee device becomes available on the network. </desc> <cmt> correctly update device entity state </cmt> <cmt> update state when device becomes available </cmt>,update entity state when zha device becomes available
3088,<desc> this changes to allow open drain configuration of the rgb_di_pin pin. tested working with spi and bitbang modes on stm32f072. add open drain mode configuration to rgb pin my code follows the code style of this project. i have read the contributing document. </desc> <cmt> open drain </cmt> <cmt> ext65 initial </cmt> <cmt> clean up messy code </cmt> <cmt> clean up  init </cmt>,stm32 ws2812 open drain configuration
3089,"<desc> i fixed a typo and changed the code to use the rest parameter to allow the use of more than 6 %s in invariant, though i'm not sure if it'll ever be needed. </desc> <cmt> typo </cmt> <cmt> changed to use rest parameter </cmt> <cmt> 'bugfix' </cmt>",fix typo in a comment
3090,"<desc> there was a type in loggedinoptions. setredirectto isn't a valid loggedinoptions option, and it should be setreturnto. here's the source code add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> add it to notneededpackages.json. </desc> <cmt> typo fixed </cmt> <cmt> updated test </cmt>",replaced setredirectto with setreturnto in connect-ensure-login package
3091,"<desc> prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run tsc without errors.   increase the version number in the header if appropriate. there were several minor changes: minor formatting correction (spaces/tabs consistency) refactored away from interfaces with 'i' at the start of their names to match leaflet's conventions added l.draw.event namespace with all of the pre-defined event types included and there were changes necessary to get things working: ilayer -> layer, icontrol -> control to match leaflet typings removed generics from several interfaces to match leaflet typings (featuregroup, layergroup) added 'setdrawingoptions' interface declaration for l.control.draw added draw class with constructor specification and removed the 'controlstatic' and 'drawstatic' interfaces that were not needed anymore </desc> <cmt> updating to work with leaflet 1.x and leaflet draw 4.x </cmt> <cmt> removing the i in the interfaces to be consistent with leaflet </cmt>",fixes and updated to work with leaflet 1.x and leaflet draw 0.4.6
3092,"<desc> the commits explain this pr. in addition, the reason that i changed window(closings: () => observable[any]) to window(boundary: => observable[any]) is window(boundary: => observable[any]) can support both two overloads window(observable[u]) and window(func0[_ <: observable[_ <: tclosing]]) in rxjava. </desc> <cmt> add publishlast to rxscala </cmt> <cmt> add unsafesubscribe to rxscala </cmt> <cmt> add unsubscribeon to rxscala </cmt> <cmt> add share to rxscala </cmt> <cmt> add parallelmerge to rxscala </cmt> <cmt> add debounce variant to rxscala </cmt> <cmt> add toblocking to rxscala and deprecate toblockingobservable </cmt> <cmt> add timer variants to rxscala </cmt> <cmt> add amb variant to rxscala </cmt> <cmt> update completenesstest.scala </cmt> <cmt> add singleoption, singleorelse, headoption, lastoption, lastorelse to rxscala </cmt> <cmt> change 'window(closings: () => observable[any])' to 'window(boundary: => observable[any])' </cmt>",add more operators to rxscala
3093,"<desc> fileio.c used to exit() on decoding errors, which is a problem when decoding is ordered on a bunch of files (for example zstd -t *). a previous patch added the ability to continue processing the list of files in case of zstd decoding errors. this patch extends this capability to gzip, lzma and lz4 formats. </desc> <cmt> fileio : decoding malformed lzma frame does no longer exit() </cmt> <cmt> makes it possible to continue decoding file list </cmt> <cmt> decoding malformed lz4 frames does no longer exit() </cmt> <cmt> gzip decoding does no longer exit() on invalid input </cmt>",no exit() on decoding errors
3094,"<desc> changes rowvar param to a bool rather than an int in numpy.corrcoef (changes signature and doc string), see #8396. also modifies numpy.ma.cov to change int checking to bool checking. </desc> <cmt> change rowvar param to boolean from int in corrcoef </cmt> <cmt> change int check to bool check for rowvar in cov </cmt>",fix corrcoef and cov rowvar param handling
3095,"<desc> fixes #20089. we return to explicitly specifying legal code locations for autocompleting jsdoc comment templates, rather than allowing them everywhere besides clearly illegal locations. this change retains the original intended fix of #19544. </desc> <cmt> revert ""loosen restrictions on jsdoc completion locations"" </cmt> <cmt> this reverts commit 612616a1058d7aa9fc181126f83041549bfbe295. </cmt> <cmt> add type alias declarations to inclusion list docs </cmt> <iss> doccommenttemplate does not return newlines in empty template anymore </iss>",revert to inclusion list for jsdoc comment completion
3096,"<desc> started the process of supporting a windows 10 x64 and visual studio 2015 build environment. the platform identification logic from tools/provision.sh was extracted and made into a separate python file, get_platform.py. get_platform.py is currently only tested against windows 10 x64 and only partially supports linux distribution version detection (have yet to port the code over from tools/lib.sh). made many changes to the root cmakelists.txt to support windows. most of these changes consist of adding special cases for windows. for example, we swapped out tools/provision.sh get_platform for python tools/get_platform.py. currently, these changes allow a visual studio 2015 x64 solution to be generated (given a specific development environment). to automate the creation of a development environment, we used chocolatey and powershell as the backbones of our provisioning system. tools/provision.ps1 (and its wrapper, make-win64-dev-env.bat) provides the main provisioning logic. currently, our third party dependencies are pre-compiled blobs that we download and extract to third-party/. the provision script makes the following assumptions: git is already installed on the box visual studio 2015 is not already installed reproducing visual studio 2015 solution generation git clone  cd osquery as an administrator: make-win64-dev-env.bat mkdir build\windows10 cd build\windows10 cmake ..\.. -g ""visual studio 14 2015 win64"" closes #1984, #1985, #1987, #1988 </desc> <cmt> committing changes related to our experimentation with a ""pure"" win64 build </cmt> <cmt> placates cmake such that a visual studio 14 x64 solution is generated! </cmt> <cmt> updated changes to fix the issue of gflags not being found. </cmt> <cmt> added cases to handle win64 specific cmake options such as include/link </cmt> <cmt> directories and compiler options </cmt> <cmt> comment change in cmakelist.txt </cmt> <cmt> changed wording of get_platform error message. adding powershell </cmt> <cmt> provisioning script. </cmt> <cmt> finalized provision powershell script </cmt> <cmt> added a deployment xml file for insuring c++ support exists for vs2015 </cmt> <cmt> added admin check and resolved some potential path issues. </cmt> <cmt> fixed some potential bugs in vs2015 automated install </cmt> <cmt> adding a wrapper for provision.ps1 so people don't need to know obscure </cmt> <cmt> powershell syntax </cmt> <cmt> fixing a bug with third-party archive extraction </cmt> <cmt> ignoring the updating of pip for now... </cmt> <cmt> fix invocation of choco.exe </cmt> <cmt> resolved pip install issues </cmt> <cmt> removed some debugging residue </cmt>",initial support for building on windows
3097,<desc> this pr improves the annotations of various constants in the main numpy namespace. values were generally taken from their c-based ufunc_<x> or npy_<x> counterpart. </desc> <cmt> enh: use literals for int- & str-based constants </cmt> <cmt> maint: import tracemalloc_domain from np.core.multiarray </cmt>,use literals for annotating int- & str-based constants
3098,"<desc> starting with windows 10 1803, windows now includes a ssh client (openssh) by default. this minor pr simply expands the existing ssh_configs and user_ssh_keys tables to support windows. let me know if there are any issues. </desc> <cmt> support for builtin ssh on windows 10 </cmt> <cmt> add buck changes </cmt> <cmt> minor cmakelists fix </cmt> <cmt> buck cmakelist fix </cmt> <cmt> cmakelist fix </cmt> <cmt> fix formatting </cmt>",expand ssh tables to support windows
3099,<desc> also includes: updates to the installeddriver/k2storage unit test (to sync with the latest style). a mockkeyversion and associated proto for testing. javadoc comments requested by john. minor tweaks and bug fixes. </desc> <cmt> remove unnecessary throws. </cmt> <cmt> make info annotations inheritable. </cmt> <cmt> - more convenient for implementations. </cmt> <cmt> - modified unit test to work with this. </cmt> <cmt> add comments to intermediate constructors. </cmt> <cmt> add hashcode/equals and tweak api on keyversion. </cmt> <cmt> add mock key version and a testing proto. </cmt> <cmt> rename test proto to mock proto. </cmt> <cmt> - fields are too specific to the mock. </cmt> <cmt> catch runtimeexceptions when loading a key. </cmt> <cmt> - they may be thrown by keyversion.builders on invalid </cmt> <cmt> protobuf data. we interpret them as (proto) data errors. </cmt> <cmt> add unit test for registeredkeyversion. </cmt> <cmt> - similar to installeddriver unit test in structure. </cmt> <cmt> update installeddriver unit test. </cmt> <cmt> - syncing style with registeredkeyversion test. </cmt>,add unit tests for registeredkeyversion and keyversionregistry.
3100,<desc> i'm not sure if it's desired to maybe create a second set of scripts instead. the existing android build scripts don't work with the latest ndk. the latest ndk dropped support for arm prior to armv7a and mips. it is now recommended that prebuilt toolchains be used instead of creating a toolchain for each build (this also saves a lot of disk space.) i've tested this new script and it works on the latest development version of ubuntu and the latest version of macos. perhaps a different folder with android-legacy or something like that for the old architectures? </desc> <cmt> update android-armv7-a.sh </cmt> <cmt> update host_compiler variable to be compatible with updated android-build.sh that supports latest ndk and use of prebuilt toolchains. </cmt> <cmt> update android-build.sh </cmt> <cmt> update to allow use of prebuilt toolchains in latest ndk. the latest ndk does not support arm prior to armv7a and the host_compiler for armv7a must now be armv7a not just arm. </cmt> <cmt> delete android-arm.sh </cmt> <cmt> arm prior to armv7a is no longer supported by android ndk. </cmt> <cmt> update android-build.sh </cmt> <cmt> removing unneeded make_toolchain variable </cmt>,update android build scripts to support latest ndk version and prebuilt toolchains
3101,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff currently, grouby.rolling is implemented essentially as groupby.apply(lambda x: x.rolling()) which can be potentially slow. this pr implements groupby.rolling by calculating bounds with a groupbyrollingindxer and using the rolling aggregations in cython to compute the results. </desc> <cmt> prep rolling groupby </cmt> <cmt> figure out how to get a similar groupby result </cmt>",use indexers to implement groupby rolling
3102,"<desc> removed assert statement checking for negative min_width. this caused segfault in debug builds for some format string in float. reference for negative min_width : cpython/python/formatter_unicode.c line 529 59423e3 /* min_width can go negative, that's okay. format->width == -1 means add tests from </desc> <cmt> remove incorrect assert and add tests </cmt> <cmt> add news entry </cmt>",remove incorrect assert statement that caused segfault in debug builds
3103,<desc> add owners file update logo fix typo update persistence in line with helm best practices. none </desc> <cmt> add owners file </cmt> <cmt> add hyperledger fabric logo </cmt> <cmt> typo fix </cmt> <cmt> update persistence according to helm best practices </cmt> <cmt> bump version up </cmt>,update owners + bug fixes and best-practices
3104,"<desc> fixes #27336. also correcting documentation errors. nxos_gir_profile_management ansible version ansible 2.5.0 (nxos_gir_profile_management 7095cdee38) last updated 2017/09/08 15:33:22 (gmt -400) config file = none configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /root/agents-ci/ansible/lib/ansible executable location = /root/agents-ci/ansible/bin/ansible python version = 2.7.6 (default, oct 26 2016, 20:30:19) [gcc 4.8.4] </desc> <cmt> fixes #27336 </cmt> <cmt> correct documentation errors </cmt> <iss> (p2)nxos_gir_profile_management: creating a profile is not idempotent </iss>",fixes #27336 - nxos_gir_profile_management issue while creating profile
3105,<desc> also see comments about how the initial score options could be improved further. the initial score can be very important to get right in some cases and therefore the user needs good auto-tuning options but also the ability to set it manually. </desc> <cmt> created objectives and metrics xentropy and xentropy1 </cmt> <cmt> some coment and code cleanup. </cmt> <cmt> added kullback-leibler version of metric. changed some warning messages. </cmt> <cmt> fixed sign error in kl-divergence calc. </cmt> <cmt> removed __pretty_function__. </cmt> <cmt> fixed better name for alternative xentropy parameterization. </cmt> <cmt> documented details on the objectives / metrics in code comments. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> common code for label interval checks. cleanups. </cmt> <cmt> use common utility for various weight property checks. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added code for customizable initial average to boost from. </cmt> <cmt> fixed spelling error in aliases. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixed nullptr check error in custom average. </cmt> <cmt> added network code for customized init score. </cmt>,customized average fixes (nullptr and network)
3106,"<desc> what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where ""xxx"" is the issue number) if adding a new feature, the pr's description includes: #6436 </desc> <cmt> test(inject): add failing test for provide with vue.extend </cmt> <cmt> fix(provide): provide should default to parentval </cmt>","provide should default to parentval during merging, fix #6436"
3107,"<desc> this adds missing flags for gradle completion, reflecting what's in the latest gradle cli docs. before gradle -[tab] --continue              -- continues task execution after a task failure. --daemon                -- use the gradle daemon --gui                   -- launches the gradle gui app --no-daemon             -- do not use the gradle daemon --profile               -- profile the build time --refresh-dependencies  -- refresh the state of dependencies. --rerun-task            -- specifies that any task optimization is ignored --stop                  -- stop the gradle daemon -d                      -- system property -i                      -- specifies an initialization script. -p                      -- set a project property -a                      -- do not rebuild project dependencies -b                      -- specifies the build file. -c                      -- specifies the settings file. -d                      -- log at the debug level -g                      -- specifies the gradle user home directory. -h                      -- help -i                      -- log at the info level -m                      -- dry run -p                      -- specifies the start directory -q                      -- log at the quiet level (only show errors) -u                      -- dont search in parent directories for a setting -v                      -- print the gradle version info -x                      -- specify a task to be excluded after gradle -[tab] --build-file            -b  -- specifies the build file --configure-on-demand       -- only relevant projects are configured --console                   -- type of console output to generate (plain, auto --continue                  -- continues task execution after a task failure --continuous            -t  -- continuous mode. automatically re-run build aft --daemon                    -- use the gradle daemon --debug                 -d  -- log at the debug level --dry-run               -m  -- runs the build with all task actions disabled --exclude-task          -x  -- specify a task to be excluded --full-stacktrace       -s  -- print out the full (very verbose) stacktrace --gradle-user-home      -g  -- specifies the gradle user home directory --gui                       -- launches the gradle gui app (deprecated) --help                  -h  -- shows a help message --include-build             -- run the build as a composite, including the spe --info                  -i  -- set log level to info --init-script           -i  -- specifies an initialization script --max-workers               -- set the maximum number of workers that gradle m --no-daemon                 -- do not use the gradle daemon --no-rebuild            -a  -- do not rebuild project dependencies --no-search-upwards     -u  -- dont search in parent directories for a setting --offline                   -- build without accessing network resources --parallel                  -- build projects in parallel --profile                   -- profile build time and create report --project-cache-dir         -- specifies the project-specific cache directory --project-dir           -p  -- specifies the start directory for gradle --project-prop          -p  -- sets a project property of the root project --quiet                 -q  -- log errors only --recompile-scripts         -- forces scripts to be recompiled, bypassing cach --refresh-dependencies      -- refresh the state of dependencies --rerun-task                -- specifies that any task optimization is ignored --settings-file         -c  -- specifies the settings file --stacktrace            -s  -- print out the stacktrace also for user exceptio --status                    -- print gradle daemon status --stop                      -- stop all gradle daemons --system-prop           -d  -- set a system property --version               -v  -- prints gradle version info </desc> <cmt> sort gradle options for autocompletion </cmt> <cmt> this will allow us to more easily keep the options list up-to-date </cmt> <cmt> add missing gradle options to gradle plugin </cmt> <cmt> reflect documentation at </cmt> <cmt>  </cmt>",improved gradle options (arguments) completion
3108,"<desc> clean up ansible-test cloud plugins: improve code reuse. add missing type hints, fix existing ones and convert them to pep 484 style. add missing imports and clean up existing ones. add missing docstrings and clean up existing ones. ansible-test </desc> <cmt> improve code reuse in cloud plugins. </cmt> <cmt> cleanup type hints, imports and docstrings. </cmt> <cmt> add changelog. </cmt>",clean up ansible-test cloud plugins.
3109,"<desc> closes #3628 this should be the proper pull request to tst test the problem, bug the problem of panda fail to write a single column of integer to sqlite test successfully on travis ci </desc> <cmt> tst: issue (#3628) when writing a dataframe column of integers to sqlite </cmt> <cmt> bug : issue (#3628) when writing a dataframe column of integers to sqlite </cmt> <iss> systematic bug in pandas/io/sql.py when trying to write a dataframe of one column of integers into sqlite </iss>",io sql one column (issue #3628)
3110,"<desc> these are either not used at all today or they're super old and haven't been used in ages, so clean them out. </desc> <cmt> mk: remove all perf-related targets </cmt> <cmt> i don't believe these have been used at all recently, and i doubt many of them </cmt> <cmt> still work, so remove the stale support. </cmt> <cmt> etc: remove old mklldef.py script </cmt> <cmt> the compiler has since gained better support for this, so the script is no </cmt> <cmt> longer necessary </cmt> <cmt> etc: remove the mingw-fix-include directory </cmt> <cmt> this isn't used anywhere </cmt> <cmt> etc: remove old num/libc generation code </cmt>",remove some old mk/etc files
3111,"<desc> even after installing certs from mitm.it, it's not trusted by default, user need to enable this on their own. </desc> <cmt> add note for ios version 10.3 or up </cmt> <cmt> update spacing </cmt> <cmt> update style </cmt>",note to enable certificate trust settings in ios 10.3 or up
3112,"<desc> making xcontentparser aware of the compatible api version. this is a preparatory work for supporting compatible changes to named xcontent object parsing. xcontentparser#usecompatibleapi will not be used for surgical compatible implementations, it will be only used in the infrastructure to select a compatible namedxcontent registry. therefore information about the exact major version is not needed. relates #51816 </desc> <cmt> move rest compatible header parsing into server </cmt> <cmt> removing the rest compatible plugin and moving the version parsing logic </cmt> <cmt> into server module. </cmt> <cmt> relates #51816 </cmt> <cmt> javadoc and scope change </cmt> <cmt> fix test </cmt> <cmt> class rename </cmt>",make xcontentparser aware of compatible api version
3113,"<desc> fixes ts issue with box not respecting the props of the component used under the component prop. examples: <box component={paper} minheight={320} // <box /> prop square // <paper /> prop throws /> <box component=""img"" src="" alt=""material-ui"" // img prop throws /> closes #16843 </desc> <cmt> fixed ts issue </cmt> <cmt> prettier </cmt> <iss> [system] <box component={paper} square> throws unasignable type </iss>",fix typescript issue when component prop is used
3114,<desc> add auto-scrolling to tables add clear shortcut button add more shortcuts add menu entry for new thread display user-friendly name of the thread this change is </desc> <cmt> add auto-scrolling to tables. add clear shortcut button. fix bug with shortcut edit in favourites dialog. </cmt> <cmt> add more shortcuts </cmt> <cmt> gui for creating thread </cmt> <cmt> use thread name in the title bar </cmt>,add auto-scrolling to tables etc
3115,"<desc> part of #2120. requires #2236. </desc> <cmt> switch to grpc secure </cmt> <cmt> blaze dependency on //external:libssl_objc </cmt> <cmt> add build target for grpcclient </cmt> <cmt> add roots.pem bundle to the bazel target, and use a better bundle name. </cmt> <cmt> fix indents of rx_library blaze target </cmt>",add bazel target for the grpcclient library
3116,"<desc> this pr adds better typing for yup's oneof schema function, which asserts that the tested item is one of the given items. until now, the function was typed such that it did not refine the type of the schema. for example: const strschema = yup.string().oneof([""a"",""b""]); // has type stringschema<string> this is really frustrating when trying to make your schemas match your typescript types as you can't validate anything that has an enumerated type without a type assertion. this change fixes that, so now calling oneof will return the enumerated type schema: const strschema = yup.string().oneof([""a"",""b""]); // has type stringschema<""a"" | ""b""> note that the optionality of the schema is maintained as noted in the docs: note that undefined does not fail this validator, even when undefined is not included in arrayofvalues. if you don't want undefined to be a valid value, you can use mixed.required. const strschema = yup.string().notrequired().oneof([""a"",""b""]); // has type stringschema<""a"" | ""b""> also adds the equals() test as an exact alias for oneof (see documentation section title). this pr also updates the tests accordingly. this could be considered a breaking change; i'm not really sure if it counts since it's just more accurate typing. note: i had to update the ts version to 3.6 because one test was failing in 3.5 and below - somehow typescript couldn't infer the type of mixed schema fields on object schemas and was causing the inferred type to be key: unknown. technically it still works in 3.5 and below (just with looser types in rare scenarios), but that test would have to be removed. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add specific string values for regionoptions.axis </cmt> <cmt> add documentation for regionoptions </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add chartinternal interface </cmt> <cmt> add internalconfig interface with unknowns </cmt> <cmt> add additional methods to chartinternal </cmt> <cmt> add classes interface </cmt> <cmt> add better typing for oneof </cmt> <cmt> add support for maintaining optionality in oneof </cmt>",make typing for oneof work to refine the schema type
3117,"<desc> the new change in the official website's domain has broken all the logos, this fixes the logos for all readme files fixes #26449 for all readmes </desc> <cmt> chore(docs) : dead logo link </cmt> <cmt> chore(docs): updated logo link </cmt> <cmt> chore(docs): updates logo link in all readme files </cmt> <iss> readme.md has a dead link for the logo </iss>",#26449 update logo url in all readmes
3118,"<desc> in python 3.8, regex and expected_regex are invalid kwargs to assertraises. django.test.simpletestcase has a simpler and faster assertraisesmessage - we already have that in our base testcase but for tests that are using unittest.testcase, can just use simpletestcase. </desc> <cmt> expected_regex isn't available in unittest python 3.8, use this from django instead </cmt> <cmt> (cherry picked from commit 289a92213b66d9bd72b95df9ac7ae3c6d920465b) </cmt> <cmt> django's testcase will work but it's not necessary, use simpletestcase which still has assertraisesmessage </cmt> <cmt> also this regex isn't correct and always passes, lol </cmt>",replace invalid assertraises kwargs with simpler assertraisesmessage
3119,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. this pr fixes a couple of issues pointed out by various translators and proofreaders. </desc> <cmt> fix: added code tags around pink-text </cmt> <cmt> fix: add code tags around main </cmt>",add inline code blocks to for i18n
3120,"<desc> close #3602. close #5777. refactor the code to avoid force creating default browsercontext in c++, make webcontents.setuseragent only work for current webcontents. </desc> <cmt> do not force creating default session in c++ </cmt> <cmt> cache the browsercontext::getuseragent </cmt> <cmt> add ses.getuseragent()/setuseragent(...) apis </cmt> <cmt> docs: ses.setuseragent(useragent[, acceptlanguages]) </cmt>","add session.setuseragent(useragent[, acceptlanguages]) api"
3121,"<desc> i updated the pins.h, configuration.h file and ultralcd.h file to allow ramps 1.3 (and probably 1.4) boards to use an lcd (connected to aux-4) and rotary encoder (connected to aux-2).  optionally a momentary switch can be used to simulate sd card removal and reinsertion (pin 31 aux-4) by pulling the pin to ground. i have this tested and working on my own ramps board.  i hit one problem which is that the sdramps module does not have a card detect pin.  this leaves a couple of choices. option out the card detect by changing ultralcd.h to believe that the card is always inserted. i tried this first and it works ok.  it's a nuisance though if you are preheating your printer while the g-code compiles on your computer.  to insert a new card and have it detected, you must restart the arduino (changing the temps back to zero) wire an open/close switch to the front panel to simulate the sdcarddetect pin being pulled low or left high. this is ok in my book.  i just didn't have any suitable switches add a momentary closed switch to pull the sdcarddetect pin low for a second or two and then invert the logic in the code disable the sdcarddetect completely and alter the menu to allow a manual refresh when a card is inserted. i can see that for those whose hardware supports it, card detect is a useful feature.  but i will look into doing it this way as it looks more elegant for the ramps users i opted for the third, though it feels a bit cludgy, it offers the best convenience in the short term </desc> <cmt> updated the pin config for ramps 1.3 to include ultimaker new style lcd/rotary encoder interface </cmt> <cmt> added a workaround.  ramps sd card does not have sdcarddetect.  my temporary solution is to add a momentary swtich </cmt> <cmt> that pulls down the sdcarddetect pin and mimicking the pull and reinsert ofa a sd card </cmt>",updated to allow ramps boards to use ultimaker style pannels
3122,"<desc> currently, only bytes can be passed across different languages. this pr implements cross language serialization for primitive data types. the design doc:  this pr do: cross language serialization infrastructure. java and python serialize / deserialize data by messagepack. support language specific type. extension id: 101 primitive types can be transferred across different languages. optimized for pickle5 in python. raise exception if send non-deserializable data to another language. e.g. send python specific data to java is not allowed. example java call python # a.py @ray.remote def foo(x): return x rayobject<string> res = ray.call( new pyremotefunction<>(""a"", ""foo"", string.class), ""hello world!""); assert.assertequals(res.get(), ""hello world!""); rayobject<integer> res = ray.call( new pyremotefunction<>(""a"", ""foo"", integer.class), 123); assert.assertequals(res.get(), 123); python call java // org.ray.api.test.example.java public class example { public static object[] pack(int i, string s, object[] o) { return new object[]{i, s, o}; } } f = ray.java_function(""org.ray.api.test.example"", ""pack"") input = [100, ""hello"", [1, ""2"", 3.0]] r = f.remote(*input) assert ray.get(r) == input i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> cross language serialization for java and python </cmt> <cmt> use strict types when python serializing </cmt> <cmt> handle recursive objects in python; pin msgpack >= 0.6.0, < 1.0.0 </cmt> <cmt> disable gc for optimizing msgpack loads </cmt> <cmt> fix merge bug </cmt> <cmt> java call python use returntype; fix classloadertest </cmt> <cmt> fix raymethodstest </cmt> <cmt> fix checkstyle </cmt> <cmt> fix lint </cmt> <cmt> prepare_args raises exception if try to transfer a non-deserializable object to another language </cmt>",cross language serialization for primitive types
3123,"<desc> refs #9589 update code style and migrate encode, facebook_url and foreach helpers skipping migrating excerpt helper since it's probably going to get nuked in ghost 3.0 </desc> <cmt> updated encode helper to use newer code standards </cmt> <cmt> updated facebook_url helper to use newer code standards </cmt>","migrated encode, facebook_url and foreach helpers to es6"
3124,<desc> this makes space pen's flasherror method functional again and adds an option for a visual beep </desc> <cmt> add flasherror css </cmt> <cmt> add atom::visualbeep method </cmt> <cmt> atom::beep triggers visual and audio beep </cmt> <cmt> add core.audiobeep and core.visualbeep to core settings </cmt> <cmt> closes #996 </cmt>,add visual cues for errors and beeps
3125,"<desc> when the nodes info endpoint is pluggable, the nodeinfo objects will need to be able to hold more than just a known group of heterogeneous objects representing different kinds of information. to this end, this pr introduces a reportingservice.info interface, which each of the component info objects now inherits. the nodeinfo class can then replace its individual fields with a collection of reportingservice.info objects. for this collection, i've chosen a map keyed on object type, which gives us the ability to handle casting dynamically in the getinfo() method. i'm open to alternate approaches. i'm leaving the serialization of the nodeinfo object alone until i'm sure about how it should look in the long term. we don't want to get stuck supporting an intermediate serialization in future releases. (see #54305 for context.) relates #52975 </desc> <cmt> use flexible structure for osinfo in nodeinfo </cmt> <cmt> this is a first cut at giving nodeinfo the ability to carry a flexible </cmt> <cmt> list of heterogeneous info responses. the trick is to be able to </cmt> <cmt> serialize and deserialize an arbitrary list of blocks of information. it </cmt> <cmt> is convenient to be able to deserialize into usable java objects so that </cmt> <cmt> we can aggregate nodes stats for the cluster stats endpoint. </cmt> <cmt> in order to provide a little bit of clarity about which objects can and </cmt> <cmt> can't be used as info blocks, i've introduced a new interface called </cmt> <cmt> ""reportingservice."" </cmt> <cmt> add other info blocks to service info map </cmt> <cmt> use helper method to filter nulls </cmt> <cmt> remove unused imports </cmt> <cmt> remove transport refactor and hardcoded getters </cmt> <cmt> i tried a different serialization for nodeinfo that would allow writing </cmt> <cmt> flexible, arbitrary lists of node info blocks, but it seems too early in </cmt> <cmt> the process to commit to anything definite, so i've backed out the </cmt> <cmt> change. </cmt> <cmt> i have removed the hard-coded getters (e.g., getos()) in favor of a </cmt> <cmt> flexible method that can return heterogeneous kinds of info blocks </cmt> <cmt> (e.g., getinfo(osinfo.class)). taking a class as an argument removes the </cmt> <cmt> need to cast in the client code. </cmt> <cmt> reportingservice.info should just be writeable </cmt>",nodeinfo response should use a collection rather than fields
3126,"<desc> prevents excessive stack usage for oversized calls and literals. having a soft upper limit on stack usage allows us to design more efficient stack layouts without worrying about code that uses huge amounts of stack. as giant literals and calls are rare, this pr should have negligible effect on performance. </desc> <cmt> modify compiler to reduce stack consumption for large expressions. </cmt> <cmt> add more tests for stack usage. </cmt> <cmt> add news item. </cmt> <cmt> remove assertion and raise systemerror for truly excessive stack use. </cmt> <cmt> clarify comments for stack_use_guideline and max_allowed_stack_use. </cmt>",use less stack for large literals and calls
3127,<desc> this commit removes the x-pack specific enums sslclientauth and verificationmode and updates places where they were used to instead use the sslclientauthenticationmode and sslverificationmode enums from the ssl-config library. relates: #68719 </desc> <cmt> remove x-pack verificationmode </cmt> <cmt> this removes the x-pack specific verificationmode enum and updates all </cmt> <cmt> places where it was used to instead use the sslverificationmode enum </cmt> <cmt> from the ssl-config library. </cmt> <cmt> remove x-pack sslclientauth </cmt> <cmt> this removes the x-pack specific sslclientauth enum and updates all </cmt> <cmt> places where it was used to instead use the sslclientauthenticationmode </cmt> <cmt> enum from the ssl-config library. </cmt>,remove x-pack specific ssl enums
3128,<desc> this follows the discussion in issue #6882 by adding different solids in the loaded ascii stl file to geometry.groups. </desc> <cmt> implemented solid coloring for ascii stl files. </cmt> <cmt> each solid is assigned to a different group. </cmt> <cmt> groups can be used to assign a different color by defining an array of materials with the same length of geometry.groups and passing it to the mesh constructor. </cmt> <cmt> replaced tab with space in comment. </cmt> <cmt> update stlloader.js </cmt> <cmt> added multi-coloring capability for groups to js module. </cmt>,implemented solid coloring for ascii stl files with multiple solids
3129,<desc> fixes #5151 fixes #5152 </desc> <cmt> add children after configuration </cmt> <cmt> ensures the create handler is called </cmt> <cmt> don't discard config </cmt> <cmt> add missing config when passing children only </cmt> <iss> `children` passed to created group aren't added/removed correctly </iss> <iss> `children` passed to created physics group don't receive bodies </iss>,fix problems passing children to created group
3130,"<desc> description: the steam integration was not showing games properly as it was using the ""extra information"" field which in the majority of cases does not contain any data. this change will actually fetch the proper game name. there was also a small refactor to consistently use constants and use proper constant names and values and the ones that was there was misleading. related issue (if applicable): fixes #11240 ps. this is my first pr to the project, if there is anything that i'm doing that goes against the general guide lines please do tell. i read the documentation regarding doing prs to the project and could not see anything alarming myself regarding this update. breaking changes: game attribute no longer set in device_state_attributes if no game is currently being played connected to the one above:  the string ""none"" is no longer passed if no current game is being played, instead the game attribute is not present. states now use lower snake case the ""play"" and ""trade"" states has been renamed to ""looking_to_play"" and ""looking_to_trade"" checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> use constant for offline state </cmt> <cmt> use constant for no game name </cmt> <cmt> rename trade and play constant their proper names </cmt> <cmt> trade and play are not the correct names for the states. for instance </cmt> <cmt> play might be seens as the user is actually is playing, which is not </cmt> <cmt> correct as there is no such state is returned from the steam api. </cmt> <cmt> just having ""trade"" does not say much about what is happening and </cmt> <cmt> might be misintepreted that the user is currently trading, which is not </cmt> <cmt> correct either. </cmt> <cmt> we instead use the names from the underlying library for naming the </cmt> <cmt> states [1] </cmt> <cmt> [1] </cmt> <cmt> get the proper game name if no extra info is given from the api </cmt> <cmt> the third current_game parameter that was used before hold </cmt> <cmt> extra information about the game that is being played. this might </cmt> <cmt> contain the game name, it might also be empty. the correct way to </cmt> <cmt> get the game name is to fetch it from the api depending on the </cmt> <cmt> game id that might be returned in the current_game attribute if </cmt> <cmt> the user is playing a game. </cmt> <cmt> to not break existing implementations we keep the functionality </cmt> <cmt> to first go with the extra information and only then fetch the proper </cmt> <cmt> game name. </cmt> <iss> the steam component doesn't load the game </iss>",proper steam game names and small fixes
3131,"<desc> just adding my keymaps for two keyboards. they make and i'm typing this on one of them now. my code (mostly?) follows the code style of this project. i have read the contributing document. </desc> <cmt> trying to fix problems in my kyria steez </cmt> <cmt> repeating last commit..... </cmt> <cmt> repeating last commit on edit layer but swapping direction </cmt> <cmt> exit </cmt> <cmt> moving the reversed desktop moves to the symbol layers on the same hand, for easier activation </cmt> <cmt> adding mac desktop movement keys to kyria layout </cmt> <cmt> adding readmes to my keymaps </cmt>",adding my keymaps for ergodox_ez and kyria
3132,<desc> i noticed some formatting issues while looking over the performance checklist on the website that i missed during the initial review. fix list formatting remove unused link ref cc: @electron/wg-ecosystem pr title follows semantic commit guidelines notes: no-notes </desc> <cmt> docs: fix list formatting in performance checklist </cmt> <cmt> docs: remove unused link ref </cmt>,clean up performance checklist formatting
3133,"<desc> fixes #29658 and #29666 #29666: added readonly keyword to ""type keywords"" list. it caused one test to fail, which i had to fix. that test was failing because it relied on existing behavior, but was not testing this behavior. #29658: added new typeassertionkeywords filter to keywordcompletionfilters, which is resolved to type keyword + const keyword. const keyword is not valid type keyword, so i decided to have it in separate filter, instead of putting it into type keywords. formatting my autoformatter fixed some minor formatting errors. hope it is ok to keep them in this pr :) </desc> <cmt> added ""readonly"" to type keywords </cmt> <cmt> fixed failing test due to changed details </cmt> <cmt> added new keword compeltion filter for assertions </cmt> <iss> completion list doesn't suggest 'const' in type assertion </iss>",fix completion lists for 'readonly' and 'const' keywords
3134,"<desc> related to #18010 this pr adds the use of _validate_data to non-fit methods. n_features_in_after_fit_modules_to_ignore is used to ignore modules so that we can work on this issues with smaller prs.  currently, this pr only adds _validate_data to the neural_network module. while we work on the details of #18010, we can add _validate_data in non-fit methods concurrently. #18010 will be ""free"" if we can have _validate_data in non-fit methods. </desc> <cmt> enh enables validate_data for non-fit methods </cmt> <cmt> rev less diffs </cmt> <cmt> tst improves test </cmt> <cmt> tst improves test </cmt> <cmt> doc adds docs </cmt>",enh uses _validate_data in other methods in the neural_network module
3135,"<desc> removes custom sync code for pointing device report, and instead uses the core feature. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> make dpi and extern </cmt> <cmt> cleanup pointer sync code </cmt> <cmt> remove keyboard sync in favor of core syncing </cmt>",update tractyl manuform code to use split pointing device sync
3136,"<desc> see commit messages. </desc> <cmt> feat(project): make get by tag test unconditional </cmt> <cmt> before this commit, the test would pass even if </cmt> <cmt>  </cmt> <cmt> /articles?tag=dragons </cmt> <cmt>  </cmt> <cmt> returned empty, and i had a broken functionality in my implementation </cmt> <cmt> unnoticed due to this. </cmt> <cmt> however, this should not be possible, since the earlier create article </cmt> <cmt> test creates an article with the tag dragons: </cmt> <cmt>  </cmt> <cmt> \""taglist\"":[\""dragons\"",\""training\""] </cmt> <cmt>  </cmt> <cmt> presumably this check exists to help the test pass on the upstream api </cmt> <cmt> < </cmt> <cmt> fail even there would be for the data to fall off the 500 article cutoff, </cmt> <cmt> which is unlikely during the runtime of a test. </cmt> <cmt> feat(project): make get favorited articles pai test unconditional </cmt> <cmt> similar rationale to the previous commit. </cmt> <cmt> both: </cmt> <cmt>  </cmt> <cmt> ""name"": ""articles favorited by username with auth"", </cmt> <cmt> ""name"": ""articles favorited by username"", </cmt> <cmt>  </cmt> <cmt> are moved in the middle of: </cmt> <cmt> the pre-existing get favorited tests were moved in between: </cmt> <cmt>  </cmt> <cmt> ""name"": ""favorite article"", </cmt> <cmt> ""name"": ""unfavorite article"", </cmt> <cmt>  </cmt> <cmt> so that something will necessarily be favorited. </cmt> <cmt> the tests used to check for a randomly named user jane, but this patch </cmt> <cmt> modifies everything to be done under username. this way, we are certain </cmt> <cmt> that the favorite is supposed to be present. </cmt> <cmt> feat(project): test specific value on the articles by tag test </cmt> <cmt> i had a that was not caught previously because i was using the sql where </cmt> <cmt> result from the orm, directly, and it returned just the tag i was </cmt> <cmt> searching for. </cmt>",make get by tag and get favorites by user api tests unconditional
3137,<desc> added more complex scenarios and covered the test scenario #3. also made improvements to node and cluster and pulled in common code. select one: select any that apply: </desc> <cmt> moved parseproducers from cluster to node and made member function and added getparticipantnum method. </cmt> <cmt> added more senarios to test. </cmt> <cmt> cleaned up unused parameter. </cmt> <cmt> added method for identifying the node for the provided producer. </cmt> <cmt> improvement for activating features and allowing more control for block header state methods. </cmt> <cmt> added scenarios of adding and removing participants and covers scenario #2. </cmt> <cmt> adding more non-producing nodes for the test. </cmt>,added privacy test scenario #3 to privacy-simple-network.py
3138,<desc> closes #9193 add example of using 'group' cv iterator to split train test subset. train_test_split wraps around shufflesplit and thus cannot account for groups. </desc> <cmt> add ex </cmt> <cmt> add ex </cmt> <iss> add support for groups in train_test_split </iss>,doc add example of using cv iterator to split train test
3139,"<desc> this pr fixes completions for --namespace to override kubectl flags. due to not using __kubectl_parse_get, __kubectl_get_namespaces doesn't support to override kubectl flags. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # release note: </desc> <cmt> fix completions for --namespace to override flags </cmt> <cmt> due to not using __kubectl_parse_get, __kubectl_get_namespaces doesn't </cmt> <cmt> support to override kubectl flags. </cmt> <cmt> rename function to follow other similar functions </cmt>",fix completions for --namespace to override kubectl flags
3140,"<desc> the code which tried to setup the (non-existent) second dai link in .probe is dead and looks wrong (maybe a leftover from some earlier development version) so it's better to drop it. the driver has been switched to the modern dai-link style to fix build issues on kernel 5.3. so far this change has only been build-tested (for rpi4) @hifiberry can you please test this with your hardware? </desc> <cmt> asoc: hifiberry_dacplusadc: fix dai link setup </cmt> <cmt> the driver only defines a single dai link and the code that tries </cmt> <cmt> to setup the second (non-existent) dai link looks wrong - using dmic </cmt> <cmt> as a cpu/platform driver doesn't make any sense. </cmt> <cmt> the dt overlay doesn't define a dmic property, so the code was never </cmt> <cmt> executed (otherwise it would have resulted in a memory corruption). </cmt> <cmt> so drop the offending code to prevent issues if a dmic property </cmt> <cmt> should be added to the dt overlay. </cmt> <cmt> asoc: hifiberry_dacplusadc: use modern dai_link style </cmt>",cleanup and switch to modern dai-link style
3141,"<desc> continue of #66242. this pr updates azure go sdk to v19.0.0 (with compute api 2018-04-01) and gets availability zones for virtualmachinescalesetvm. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): release note: azure go sdk has been upgraded to v19.0.0 and virtualmachinescalesetvm now supports availability zones. /sig azure /assign @brendandburns @khenidak @andyzhangx </desc> <cmt> update compute api to 2018-04-01 </cmt> <cmt> update azure go sdk to v19.0.0 </cmt> <cmt> get availability zone for virtualmachinescalesetvm </cmt> <cmt> add unit tests for getzonebynodename </cmt>",update azure go sdk to v19.0.0 and get availability zone for virtualmachinescalesetvm
3142,<desc> this just adjust the hassingleinvalidcomponent key path expr method to only consider key path rooted on type expr because we only want to detect key paths without components e.g. \int because actually key paths with invalid components like the sr example \int.byteswapped.signum() are represented in the ast also with a single invalid component but rooted on the whole expression. also skips the fix for hole root key path if it has any invalid component as it would be already diagnosed. resolves sr-14644. </desc> <cmt> [ast] consider only rooted keypath as single invalid component </cmt> <cmt> [sema] do not record hole root fix for keypath with invalid component </cmt> <cmt> [tests] add regression tests for sr-14644 </cmt>,improving diagnostics for key path with invalid components
3143,"<desc> this demo should show an approach to get fog of war in 2d games. it has complete dark (opaque) fog for undiscovered territory and 80% transparent fog for discovered-but-not-active territory, like in usual rts games. it is realized with a tilemap that changes its tiles, depending on the players position. </desc> <cmt> added a demo for 2d fog of war </cmt> <cmt> added preview picture </cmt>",add 2d fog of war demo
3144,"<desc> this change adds a floatinglabelstyle parameter to inputdecoration. when the labeltext label is floating above the input field, it will use this style. when the labeltext label is sitting inline with the input field it will use labelstyle. related issues fixes #86389 fixes #21385 i added the following test: material/input_decorator_test.dart widget test to verify input decoration theme overrides are successful. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. </desc> <cmt> add floatinglabelstyle to inputdecoration and inputdecorationtheme </cmt> <cmt> add test for floatinglabelstyle </cmt> <iss> hintstyle of inputdecorationtheme not correctly applied </iss> <iss> add floatinglabelstyle to inputdecoration </iss>",add floatinglabelstyle parameter to inputdecoration
3145,"<desc> add or edit tests to reflect the change. (run with npm test mongoose-delete.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this fixes a simple error with the indexfields that is parsed using: function parseindexfields (options) { var indexfields = { deleted: false, deletedat: false, deletedby: false }; if (!options.indexfields) { return indexfields; if ((typeof options.indexfields === 'string' || options.indexfields instanceof string) && options.indexfields === 'all') { indexfields.deleted = indexfields.deletedat = indexfields.deletedby = true; if (typeof(options.indexfields) === ""boolean"" && options.indexfields === true) { indexfields.deleted = indexfields.deletedat = indexfields.deletedby = true; if (array.isarray(options.indexfields)) { indexfields.deleted = options.indexfields.indexof('deleted') > -1; indexfields.deletedat = options.indexfields.indexof('deletedat') > -1; indexfields.deletedby = options.indexfields.indexof('deletedby') > -1; return indexfields; </desc> <cmt> fix for indexfields in mongoose-delete </cmt> <cmt> fix for indexfields in mongoose-delete </cmt>",fix invalid indexfields in mongoose-delete
3146,"<desc> @jeffmo we'd like your final sign-off before merging this. </desc> <cmt> revert ""babylon: fix error location for class properties with a missing semicolon"" </cmt> <cmt> this reverts commit f31099f383b52cf4fe1786188f6421529dea865b. </cmt> <cmt> revert ""babylon: throw parse error if class properties do not have a semicolon (fixes t6873)"" </cmt> <cmt> this reverts commit 976edfc06740e434d1d5b136e28996a77f909403. </cmt>",revert to standard asi behavior for class properties
3147,"<desc> adds a new react-fresh top level package. name tbd, i just need somewhere to put my stuff in. adds a new react-fresh/babel entry point. this will be the babel plugin. it's a noop now. i added an empty snapshot test. adds a new react-fresh/runtime entry point. this will be the hot reloading runtime that manages component registration and families. it will be shared between web and rn implementations. the first version i'm checking in is extracted from what we used in the test suite. i want to keep it all in this repo so that i can write integration tests which run against latest react, and verify all pieces work together. this also makes it easier to ensure we actually fix this if we break it. the next follow-up will be to actually write the babel plugin, and add some kind of integration testing. </desc> <cmt> add a stub for react fresh babel plugin package </cmt> <cmt> move reactfresh-test into reactfresh top level directory </cmt> <cmt> add a stub for react fresh runtime entry point </cmt> <cmt> extract fresh runtime from tests into its entry point </cmt>",set up infra for runtime and babel plugin
3148,"<desc> because we need to draw content before scrolling to it, the editor's scrolling behavior is completely synthetic. we use translate3d to move the .lines div around and never actually set the scrolltop or scrollleft of the .scroll-view that contains them. however, if the hidden input field ever gets out of the visible area of the scroll view, the browser tries to be helpful and scroll it into view, which changes the scrolltop and scrollleft and ruins everything. this pr tries to stop that. if we do scroll, we log a warning and auto-correct the problem. i'd like to remove this stop gap once we don't see warnings for a long enough time, but it's better than leaving the editor in a busted state. when the editor is blurred, we always park the hidden input at 0, 0. this eliminates some cases where the editor could autoscroll after changing size while unfocused and then being focused. allow 2px for the hidden input when the cursor reaches the end of the longest line. this ensures we don't autoscroll to the right when moving the cursor to the right edge of the editor. </desc> <cmt> warn when scroll view gets accidentally scrolled and fix it </cmt> <cmt> i want this code to go away once we track down the causes of any </cmt> <cmt> unwanted autoscrolling by the browser </cmt> <cmt> position hidden input at 0,0 unless cursor is focused </cmt> <cmt> the editor's scroll view is getting autoscrolled when the editor is </cmt> <cmt> focused, so we won't position the hidden input until after the editor </cmt> <cmt> is focused, and will always return it to 0,0 when the editor is blurred. </cmt> <cmt> prevent autoscrolling scroll-view when cursor is at end of longest line </cmt> <cmt> if the longest line is longer than the width of the scroll view, we need </cmt> <cmt> to allow 2px horizontally to prevent the hidden input from </cmt> <cmt> autoscrolling. </cmt>",prevent react editor's scroll view from being auto-scrolled by chromium
3149,"<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance new feature or improvement the data collector protocol repository has been created for sharing the protocol with other language implementations. and use ui link for help users to download codes more easier. i will use another pr to add documents for helping people use the new project structure. to be honest, if developers are using git ui tools, such as sourcetree, they wouldn't need to change anything. fyi @liuhaoyang </desc> <cmt> add ui as a submodule </cmt> <cmt> add submodule links for protocol </cmt>",using submodule to link protocol and ui
3150,"<desc> studying this tutorial code i noticed that it stores the current users request for a page of results in class static variables then reads those variables to render the page. if we get two concurrent requests we could have a second request clobber the first requests passed values and render the wrong page to the first user. if i try to make those values local variables the compiler says that ""variable used in lamba expression should be final or effectively final"". intellij then suggests making them static, which is a concurrency bug, or atomic, and it performs the refactor to use local atomic variables which touches a lot of code to both declare, set and get the atomics. using orelse to default the value is less code and does the job. making them final also makes it clearer that they are parameters passed by the user and that allowing parameters to change in a method makes it harder to maintain code. </desc> <cmt> removed race condition between different requests </cmt> <cmt> use of atomics way too verbose </cmt> <cmt> orelse is cleaner </cmt> <cmt> may as well use final </cmt>",use of static variables is concurrency problem
3151,"<desc> this is mostly more comments, but i also renamed some things: boxmeup::box_me_up is not terribly descriptive, and since this is a ""take""-style method (the argument is &mut self but the return type is fully owned, even though you can't tell from the type) i chose a name involving ""take"". continue_panic_fmt was very confusing as it was entirely unclear what was being continued -- for some time i thought ""continue"" might be the same as ""resume"" for a panic, but that's something entirely different. so i renamed this to begin_panic_handler, matching the begin_panic* theme of the other entry points. r? @dylan-dpc @simonsapin </desc> <cmt> rename continue_panic_fmt to panic_handler, and make it the #[panic_handler] directly </cmt> <cmt> the ""continue"" in the name was really confusing; it sounds way too much like ""resume"" which is a totally different concept around panics. </cmt> <cmt> better comment and rename boxmeup::box_me_up to take_box </cmt> <cmt> more panicking comments </cmt> <cmt> panic_handler -> begin_panic_handler (and more comments) </cmt>",panic machinery comments and tweaks
3152,"<desc> this pr removes support for binary tags. we were going to use these for tracing support, but are going to make these a custom structure inside the context, and use protos for encoding (this will be a future pr). also add restrictions on allowable tag key and values to be printable ascii. </desc> <cmt> eliminate binary tags </cmt> <cmt> add checking of character values </cmt>","remove binary tags, restrict tag characters to ascii"
3153,"<desc> g_api render performance tests added: performance tests render g-api description: g-api render perforamance tests. these tests are very similar to g-api unit render tests. i agree to contribute to the project under opencv (bsd) license. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work force_builders=custom,armv7 build_gapi_standalone:linux x64=ade-0.1.1f build_gapi_standalone:win64=ade-0.1.1f build_gapi_standalone:mac=ade-0.1.1f build_gapi_standalone:linux x64 debug=ade-0.1.1f xbuild_image:custom=centos:7 build_image:custom=ubuntu-gapi-freetype:16.04 buildworker:custom=linux-1 build_gapi_standalone:custom=ade-0.1.1f </desc> <cmt> add render performance tests for bgrocv </cmt> <cmt> add render nv12 performance tests </cmt>",added g-api render performance tests
3154,"<desc> the gil change actually was one of the last changes i made on the prototype, but it's rather straightforward, and with some gil stuff already scattered across the code base i don't see a good reason to not just add it. </desc> <cmt> fix chunker holding the gil during blocking i/o </cmt> <cmt> add zeromq dependency </cmt>","add pyzmq dep, chunker gil"
3155,"<desc> adds a new bellstyle called window. when window is set and a bel is emitted, we flash the pane that emitted it. additionally, changes bellstyle in the sui to a list of checkboxes instead of radio buttons, to match bellstyle being a flag-enum. deprecates 'bellstyle::visual' in the schema, but still allows it to be set in the json (it maps to window | taskbar) #6700 cla signed. if not, go over here and sign the cla documentation updated. if checked, please file a pull request on our docs repo and link it here: #xxx i work here gif in teams </desc> <cmt> initial </cmt> <cmt> optional timer </cmt> <cmt> add setting </cmt>",add a setting to flash the pane when bel is emitted
3156,<desc> proposal for fix related to 1rst issue of #345 thread.sleep(wait) => thread.sleep((wait/10)*10) (see </desc> <cmt> proposal for fix related to 1rst issue of #345 </cmt> <cmt> thread.sleep(wait) => thread.sleep((wait/10)*10) </cmt> <cmt> (see </cmt> <cmt> proposal for fix related to 1rst issue of #345 </cmt> <cmt> thread.sleep(wait) => thread.sleep((wait/10)*10) </cmt> <cmt> (see </cmt>,3 proposal to fix 1rst issue presented in #345
3157,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. related </desc> <cmt> added type and handler for codebuild cloudwatch state event </cmt> <cmt> added type and handler for codebuild cloudwatch event </cmt> <cmt> added test for codebuild cloudwatch event </cmt> <cmt> extended definitions block </cmt>",aws-lambda added codebuild cloudwatch state event
3158,<desc> type: refactor description: converted annotated.jsx and sdk.jsx to typescript renamed sdk.tsx to eventsdk.tsx added the annotated tooltip in the eventsdk.tsx component you can read more about this refactor here:  result: </desc> <cmt> ref(ui): added annotated tooltip </cmt> <cmt> ref(ui): removed jsx files </cmt> <cmt> ref(ui): updated annotated comp </cmt>,added tooltip - datascrubbers v2 - part 1
3159,"<desc> this pr adds the importmixin base class to the savedquery model, as well as adding a db migration that adds and populates the column. n/a test plan ran superset db upgrade and verified that saved queries have a uuid ran superset db downgrade af30ca79208f and verified that column is removed. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> add uuid to saved_query </cmt>",add uuid column to saved_query for export/import
3160,"<desc> this is a fix for #71258 i've noticed that in this bug there are essentially two parts to it. if vs code tries to undo a commit where there was an empty commit message, or a commit message with only whitespace, the ""bad commit"" error occurs. furthermore, there is a way to make a commit with just whitespace through vs code. if you press the tick by source control: git, enter some whitespace, and then press enter, the commit goes through with the message being whitespace. if you try to undo this, the same error will occur. fix: cannot undo git commits with only whitespace fix: can make commits with only whitespace i have put this as an error because when filling out a message for a commit in the side bar if there is only whitespace, it will refuse commits. hence going by that, i am extrapolating that to mean that any commit messages drafted in the top bar should refuse whitespace too. i've removed the second as a requirement because the issue does not explicitly call for a fix on that. by testing with different commits it seems the regex matching expression is at fault. the string that goes into the regex match is as follows: emailaddress@domain.com the last part, the name of this commit, is optional, and is not present when there is an empty git commit, but the regex expression looks for it, and hence sees the expression as invalid. finally the change in commands.ts makes it so that when whitespace is added as a commit message, the function returns and the window is dismissed. this is the same behaviour as when enter is pressed (without typing anything) and the window is dismissed. below is a screenshot of the window. when enter is pressed, the window is dismissed. the above has been reverted to its original behaviour. </desc> <cmt> disallow making commits that contain only contain whitespace to be consistent across other methods of committing to git through vs code </cmt> <cmt> remove part of the regex matching expression for git commits, because previous it would think commits with empty messages were invalid when infact they are not </cmt>",fix microsoft #71258 - cannot undo empty commits
3161,"<desc> this pr is a continuation of #7391 (by @gunnarbeutner). most of the functionality comes from that pr. i also included a few style changes (east const) and added a basic test suite for htmltokenizer, since the tokenizer now has some more complex state (and is thus easier to break). when timing raw tokenizing (without interaction with an htmldocumentparser), the time needed to tokenize e.g. the whatwg bookmark has decreased by around 60 to 75 percent. :^) </desc> <cmt> ak: avoid allocations for the queue class </cmt> <cmt> previously the queue class used a singlylinkedlist to manage its queue </cmt> <cmt> segments. this changes the queue class to use the intrusivelist class </cmt> <cmt> instead which saves us one allocation per segment. </cmt> <cmt> ak: avoid pagefaults when repeatedly enqueing/dequeing items in a queue </cmt> <cmt> when repeatedly enqueing and dequeing a single item in a queue we end </cmt> <cmt> up faulting in all the pages for the underlying vector. this is a </cmt> <cmt> performance issue - especially where the element type is large. </cmt> <cmt> libweb: use an optional<string> to track the last html start tag </cmt> <cmt> using an htmltoken object here is unnecessary because the only </cmt> <cmt> attribute we're interested in is the tag_name. </cmt> <cmt> libweb: remove more unused stringbuilders in htmltoken </cmt> <cmt> these fields aren't read anywhere but i didn't feel like removing </cmt> <cmt> them outright. </cmt> <cmt> libweb: remove stringbuilders from htmltoken::m_doctype </cmt> <cmt> libweb: remove stringbuilders from htmltoken::attributebuilder </cmt> <cmt> libweb: remove stringbuilder from htmltoken::m_tag </cmt> <cmt> libweb: remove stringbuilder from htmltoken::m_comment_or_character </cmt> <cmt> libweb: use move() when enqueuing tokens in htmltokenizer </cmt> <cmt> we're not using the current token anymore once it's enqueued so let's </cmt> <cmt> use move() when enqueuing the tokens. </cmt> <cmt> libweb: change htmltokenizer.{cpp,h} to east const style </cmt> <cmt> libweb: change htmltoken.h to east const style </cmt> <cmt> libweb: remove unused htmltokenizer::m_input member variable </cmt>",remove stringbuilders from the htmltoken class
3162,"<desc> during investigation into black-primer test failures in #1949, the lines at black/src/black_primer/lib.py lines 63 to 64 71117e7 if returncode is none: returncode = 69 stood out as a workaround that it may be possible to remove. it's probably harmless to assign a placeholder exit code in these circumstances, but it seems better not to if we can avoid it; it's less confusing for future readers, and less likely to introduce unexpected bugs if the surrounding code changes in future. the reason the lines were originally added was to allow mypy type checks to pass by guaranteeing an integer process.returncode value. it should already be true that an integer return code is guaranteed by the point we reach this code path, as far as i can tell, but mypy is not able to determine that without some additional context.  an assert statement is introduced here to provide mypy with a suitable hint. builds upon #1887 and further resolves #1886. </desc> <cmt> revert ""bump mypy to 0.780 in pre-commit config (#1887)"" </cmt> <cmt> this reverts commit a497570fcb364b40e0d952d3133e8d4f2d329fea. </cmt> <cmt> pre-commit: update to mirrors-mypy==0.800 </cmt> <cmt> add assertion on process.returncode to assist mypy </cmt> <cmt> pre-commit: retain current mirrors-mypy==0.780 </cmt> <iss> in python 3.9, it doesn't seem to pass the mypy check in pre-commit </iss>",remove placeholder exit code in unreachable 'black-primer' subprocess handler
3163,"<desc> enabled pylint checks in api.py: refactored return statements in put method and enabled too-many-return-statements rule, removed disabled arguments-differ in put() and delete() methods since api matches. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> updated put method in datasets/api.py: </cmt> <cmt> - changed return statements in put method </cmt> <cmt> - removed disabled pylint rule too-many-return-statements </cmt> <cmt> - removed disabled pylint rule arguments-differ since arguments match </cmt> <cmt> removed disabled pylint rule arguments-differ in delete() method since arguments match </cmt>",changed disabled rules in datasets module
3164,"<desc> addition of the yolo loss function factory, darknet dynamic loss function, and the scaled yolo loss function. further updating all existing components to be up to date with the most performant model state. we fixed a bug with the dilated darknet that would cause the construction to crash as model size is scaled. finally, this pr adds updates to the detection generator in order to integrate shared loss utility functions required for decoding the models outputs. # loss and operation tests python3.8 -m official.vision.beta.projects.yolo.ops.box_ops_test python3 -m official.vision.beta.projects.yolo.losses.yolo_loss_test # layer tests python3 -m official.vision.beta.projects.yolo.modeling.layers.detection_generator_test python3.8 -m official.vision.beta.projects.yolo.modeling.layers.nn_blocks_test # model tests python3.8 -m official.vision.beta.projects.yolo.modeling.backbones.darknet_test python3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test python3.8 -m official.vision.beta.projects.yolo.modeling.heads.yolo_head_test test configuration: python3.8 or higher tf 2.6.0 1 gpu i have signed the contributor license agreement. i have read guidelines for pull request. my code follows the coding guidelines. i have performed a self code review of my own code. </desc> <cmt> backbone update </cmt> <cmt> backbone update </cmt> <cmt> decoder update </cmt> <cmt> decoder update </cmt> <cmt> head update </cmt> <cmt> head update </cmt> <cmt> nn_blocks update </cmt> <cmt> detection generator update </cmt> <cmt> yolo_model update </cmt> <cmt> math ops update </cmt> <cmt> box_ops update </cmt> <cmt> loss function and init/run test </cmt> <cmt> loss function test </cmt>",yolo family loss functions pr
3165,"<desc> dear jack, first and foremost thank you for your work on the qmk firmware! this pull request is about adding a swiss german layout for both the ergodox ez and the infinity. i made some small changes to the main event loop to prevent flickering and in case of the infinity enabled the background lights of the display to indicate the active layer using colours corresponding to the leds of the ergodox ez. the code used to send the html-macros in the symbol layer could probably be improved, in particular by removing the duplication between the two layouts and i am open to suggestions. thank you & best regards andreas </desc> <cmt> add swiss german layout for ergodox ez </cmt> <cmt> - add swiss german layout for ergodox ez based on default </cmt> <cmt> layout for ergodox ez. </cmt> <cmt> - minor changes in the event loop to prevent flashing of leds. </cmt> <cmt> add swiss german layout for ergodox infinity </cmt> <cmt> - add swiss german layout for ergodox infinity based on default </cmt> <cmt> layout for ergodox ez. </cmt> <cmt> - minor changes in the event loop to prevent flashing display </cmt> <cmt> background lights. </cmt>",swiss german layout for ergodox ez & infinity
3166,<desc> in reference to comment: #4309 (comment) this pr corrects app detection when 'react' has also been added to package.json and fixes detection of storybook configuration. </desc> <cmt> move ember app detection above react </cmt> <cmt> this ensures that an ember app will still be detected even after react dependencies are added </cmt> <cmt> add ember to list of supported frameworks to correctly detect if storybook is already setup </cmt>,fixes to cli ember support (followup on #4309)
3167,<desc> added documentation for learning rate schedules in main readme added some pictures for the readme in docs/imgs/ (not sure if it's the best place) updated some docs in code for optimization </desc> <cmt> - updated docs for new lr api </cmt> <cmt> - added some images for illustration </cmt> <cmt> - updated comments in optimization </cmt> <cmt> - replaced openaigptadam with openaiadam in docs </cmt> <cmt> - replaced openaigptadam with openaiadam in docs </cmt>,docs for new learning rate code
3168,"<desc> this pr: fixes some old school error issues, specifically #33559, #33543, #33366 improves wording borrowck errors with match patterns de-emphasize multi-line spans, so we don't color the single source character when we're trying to say ""span starts here"" rollup of #33392 (which should help fix #33390) r? @nikomatsakis </desc> <cmt> print secondary labels as notes in old skool mode </cmt> <cmt> de-emph minimized spans, add better debugging output </cmt> <cmt> improve a few errors and fix #33366 </cmt> <cmt> fix for #33559 </cmt> <iss> spurious json parsing failure on bots </iss>","fix for old school error issues, improvements to new school"
3169,<desc> this waits for the render to be committed to dom before we render the route change complete event (no longer sync in new react). we have tests that ensure this resolves. closes #12938 </desc> <cmt> wait until flush before resolving render promises </cmt> <cmt> rename variable to avoid shadowing </cmt> <cmt> fix lint issues </cmt> <cmt> increase sizes </cmt> <cmt> rework events and promise </cmt> <cmt> fix tests </cmt> <cmt> remove unnecessary events </cmt>,wait for flush before firing routing event
3170,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add types for aws-lambda dynamodb stream events </cmt> <cmt> add missing parameters </cmt> <cmt> aws-lambda dynamo tests </cmt> <cmt> add name to authors </cmt> <cmt> format as per styleguide </cmt>",add aws-lambda dynamodb stream event types
3171,<desc> edit text objects on double click add text preview info to the side panel </desc> <cmt> edit existing text objects </cmt> <cmt> (cherry picked from commit 3d6edca21b5615481d0ab409801baeafb523ce72) </cmt> <cmt> add 'info' to the panel for the text tool object </cmt> <cmt> (cherry picked from commit 2b633f560e46a0112d70653f6c55da5e97ce4cc8) </cmt>,nc/edit text objects on double click
3172,<desc> this adds the ml api for deleting an event from a calendar to the hlrc. relates to #29827 </desc> <cmt> hlrc: delete event from calendar </cmt> <cmt> adjusting tests </cmt> <cmt> adjusting code to make it more readable </cmt>,ml delete event from calendar
3173,"<desc> added stadium shape, updated tests and docs. resolves #723 </desc> <cmt> sync develop branch </cmt> <cmt> #723 add stadium shape for flowchart nodes </cmt> <iss> rounded corners shape should have completely round end-caps in mermaid flowchart. </iss>",add stadium shape for nodes
3174,"<desc> as discussed here: 5c7a19a#commitcomment-8220173 @topfs2 @fernetmenta for review </desc> <cmt> dvdinputstreamtv/dvdinputstreamfile: don't set eof in case of error to give player a chance to retry read. </cmt> <cmt> [vfs] pvrfile::read(): do not return negative values other than ""-1"" </cmt>",allow player to retry read in case of read errors
3175,"<desc> this pr proposes modifications to the existing camera recording process by moving it to a separate thread. the native unreal implementation of readpixels() contains a call to the function flushrenderingcommands(), which effectively blocks the game thread until the camera image has been rendered, thus reducing the frame rate to unplayable levels. to get around it, this version has a separate thread created as an unreal frunnablethread type. inside this thread, the drone's camera is accessed periodically, and the fpv render command is queued into the render thread. it also has a custom implementation of a 'rendercommandfence', which checks on the status of this render, and once it's done, compresses the image and saves the screenshot to the usual log folder, along with the ground truth (similar to the earlier implementation). all of this is fully unreal based; so i expect it to work on other os's as well, but i haven't tested it. on my computer, (i5-6600k, nvidia gtx 1070, win 10) this results in ~10 hz of image logging rate whereas the game runs at an almost constant ~120 fps (in a very simple environment) while recording. changes to existing code: hdr has been disabled in the fpv render target settings. this halves the size of the texture from ~7 mb to ~3.5 mb, thus making the render process quicker, whereas leaving hdr on seems to be putting too much load on the gpu. also, the gamma in image settings has been bumped up to fix the lighting (caused by turning off hdr). (still checking on whether a more optimized version can allow hdr to be on) methods such as apipcamera::getcapturecomponent() and asimmodebase::getphysicsbody() have been exposed as public so that the new thread can access them. please let me know if you have any suggestions to improve this further. edit: the first few commits on this branch can be ignored, the repo's been merged with a recent version before these new modifications were added. </desc> <cmt> spawn and control two drones </cmt> <cmt> added three vehicles; individual camera setup </cmt> <cmt> joystick support for three mavs </cmt> <cmt> merge with upstream </cmt> <cmt> update </cmt> <cmt> separate thread for recording </cmt>",multithreaded approach for recording camera images
3176,"<desc> problem: the styledimagecontainer is adjusting to the caption length, extending past the width of the image fix: added styling to styledcaption (width, wordwrap, & padding) to ensure captions stay within image width and are readable (even at smaller dimensions) added test to validate caption width is the same as the image width before: after: close #3530 </desc> <cmt> add options for image caption bug fix </cmt> <cmt> add spacing options </cmt> <cmt> update styling to caption </cmt> <cmt> add test to cover caption width </cmt> <iss> image caption beyond image width </iss>",fix to image captions extending beyond image width
3177,"<desc> this adds parsing of which type should be targeted when executing queries for rank evaluation, as well as actually using this information down the line. missing is a test that fails w/o that change - is that something that should be added to the rest test or is there some other means to check this integration works? @cbuescher your input would be most welcome. </desc> <cmt> move github review comments to todos </cmt> <cmt> use type information in request </cmt> <cmt> adds parsing of type and actually using it in transportrankevalaction. </cmt> <cmt> missing: a good idea how to actually test this in isolation... </cmt>",add parsing of type information
3178,<desc> $ mypy --strict scheduling/ --ignore-missing-imports success: no issues found in 4 source files related issue: #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> fix mypy errors for scheduling/first_come_first_served </cmt> <cmt> fix mypy errors for scheduling/round_robin.py </cmt> <cmt> fix mypy errors for scheduling/shortest_job_first.py </cmt>,add/fix type annotations for scheduling algorithms
3179,"<desc> greetings, a dynamic programming python approach on solving the longest palindromic sequence has been implemented. testing strings were added  into the main function. the solution was inspired by online resources, as recommended by @vitorvgc and targets the issue  #1319. </desc> <cmt> python dynamic programming longest palindrome sequence approach </cmt> <cmt> improved both inline and doc strings </cmt> <cmt> improved both inline and doc strings comments </cmt>",longest palindromic sequence python solution
3180,"<desc> extend lt support to all the random family operators please feel free to remove inapplicable items for your pr. all changes have test coverage: code is well-documented: to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change modified:   src/operator/random/multisample_op.h modified:   src/operator/random/pdf_op.h pdf ops >>> mx.nd.random_pdf_negative_binomial(sample=mx.nd.random_normal(shape=(1, 2**32 + 1)), k=mx.nd.random_normal(shape=(1)), p=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967297 @cpu(0)> >>> mx.nd.random_pdf_dirichlet(sample=mx.nd.random_uniform(shape=(2**32 + 1,5),low=0, high=1), alpha=mx.nd.random_uniform(shape=(5), low=0, high=1)) <ndarray 4294967297 @cpu(0)> >>> mx.nd.random_pdf_exponential(sample=mx.nd.random_normal(shape=(1,2**32 + 1)), lam=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967297 @cpu(0)> >>> mx.nd.random_pdf_normal(sample=mx.nd.random_normal(shape=(1,2**32)), mu=mx.nd.random_normal(shape=(1)), sigma=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967296 @cpu(0)> >>> mx.nd.random_pdf_poisson(sample=mx.nd.random_normal(shape=(1, 2**32 + 1)), lam=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967297 @cpu(0)> >>> mx.nd.random_pdf_uniform(sample=mx.nd.random_normal(shape=(1,2**32 + 1)), low=mx.nd.random_normal(shape=(1)), high=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967297 @cpu(0)> sample ops >>> mx.nd.sample_uniform(shape=(2**32), low=mx.nd.random_normal(shape=(1,)), high=mx.nd.random_normal(shape=(1,))) <ndarray 1x4294967296 @cpu(0)> >>> mx.nd.sample_poisson(shape=(2**32 + 1), lam=mx.nd.random_normal(shape=(1))) <ndarray 1x4294967297 @cpu(0)> >>> mx.nd.sample_normal(mu=mx.nd.random_normal(shape=(2**32 + 1)), sigma=mx.nd.random_normal(shape=(2**32 + 1))) [ 0.7192631   1.8029252  -3.1244457  ...  1.3172784  -0.44950533 0.5782782 ] <ndarray 4294967297 @cpu(0)> >>> mx.nd.sample_exponential(shape=(1), lam=mx.nd.random_normal(shape=(2**32 + 1))) ... <ndarray 4294967297x1 @cpu(0)> >>> mx.nd.sample_negative_binomial(k=mx.nd.random_uniform(shape=(2**32), low=0, high=1), p=mx.nd.random_uniform(shape=(2**32), low=0, high=1)) <ndarray 4294967296 @cpu(0)> >>> mx.nd.sample_generalized_negative_binomial(alpha=mx.nd.random_uniform(shape=(2**32), low=0, high=1), mu=mx.nd.random_uniform(shape=(2**32), low=0, high=1)) <ndarray 4294967296 @cpu(0)> >>> mx.nd.sample_gamma(alpha=mx.nd.random_uniform(shape=(2**32), low=0, high=1), beta=mx.nd.random_uniform(shape=(2**32), low=0, high=1)) [3.9847539e-05 9.7578183e-02 3.0167744e-04 ... 2.7813488e-03 5.8879163e-03 3.3052340e-01] <ndarray 4294967296 @cpu(0)> </desc> <cmt> fix random pdf normal </cmt> <cmt> fix remaining pdf ops </cmt> <cmt> add lt support to sample_* ops </cmt> <cmt> fix spelling mistake </cmt>",add support to random sample & pdf ops
3181,"<desc> update blockeditorprovider settings type. includes templatelock setting which was found to be missing: definitelytyped/types/wordpress__block-editor/index.d.ts lines 29 to 32 134bb19 export interface editorblocklistsettings { allowedblocks?: string[]; templatelock?: editortemplatelock; add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). component fires updatesettings action with settings prop:  this changes settings in state: action:  reducer:  templatelock selector reads from settings.templatelock:  does not apply if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. does not apply if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> include editorblocksettings in provider settings </cmt> <cmt> add tests </cmt>",add some settings to blockeditorprovider
3182,"<desc> add a db engine spec for firebolt. connected superset (running in docker-compose) to firebolt database using firebolt-sqlalchemy adapter. added database, dataset, queried from sql lab and created charts. also tested all the time grains. includes db migration (follow approval process in sip-59) </desc> <cmt> new branch from superset for integration with firebolt sqlalchemy adapter </cmt> <cmt> added db_engine_spec file for firebolt </cmt> <cmt> removed firebolt code from superset repo </cmt> <cmt> deleted virtual env commit </cmt> <cmt> adding time grain changes to firebolt.py </cmt> <cmt> updated readme.md </cmt> <cmt> added steps to install and run superset with firebolt sqlalchemy adapter </cmt> <cmt> update readme.md </cmt> <cmt> reduced installation steps. using pypi installation for adapter now </cmt> <cmt> revert ""update readme.md"" </cmt> <cmt> this reverts commit 5ed17c7a4545998ed07693c93738ebe7bff2580e. </cmt> <cmt> revert ""updated readme.md"" </cmt> <cmt> this reverts commit 45c5072649a7926fc4d15d2eb0b9cc5a89e5d7b2. </cmt> <cmt> added epoch methods, added test cases for firebolt db engine spec and edited setup.py </cmt>",add firebolt db engine spec
3183,"<desc> checklist closing issues: #issue i wrote some lines in the radare2book in arm architecture, the ldrd instruction was handled as ldrb by esil. a ldrb instruction loads an unsigned byte into a register. a ldrd instruction loads a word into a register, and the following word (first word address + 4) into a second register. the esil representation of ldrd was thus wrong. this pr fixes the esil and adds a few tests to ensure future non-regression. ldrb is ldr with b type: ldr{type}{cond} rt, [rn {, #offset}] ; immediate offset -> loads the byte [rn + offset] into rt ldrd is a separate instruction: ldrd{cond} rt, rt2, [rn {, #offset}] ; immediate offset, doubleword -> loads the word [rn + offset] into rt and the word [rn + offset + 4] int rt2 </desc> <cmt> add arm32 tests for ldrd ##emu ##test </cmt> <cmt> translate ldrd instructions into esil </cmt> <cmt> handle pre and post indexed ldrd </cmt> <cmt> add arm16 ldrd esil tests ##emu ##test </cmt> <cmt> format to coding style guidelines </cmt>",fix arm ldrd esil ##emu ##test
3184,"<desc> fixes #800 . pr #1299 works great for development environments, but in production build vuecomponent name got mangled thus will not work. </desc> <cmt> cache resolved layouts in resolvedlayouts </cmt> <cmt> app.vue: check resolvedlayouts in setlayout </cmt>",add resolvedlayouts to support class components in layouts
3185,"<desc> 5.3 cherry-pick of #31753. explanation: fixes a spurious compiler error, compiler crash, and fixes an ambiguity error with anyobject subscript lookup. scope: fixes 3 bugs that have previously shipped. the most important part of this change is the fix for the anyobject subscript ambiguity, which can be exacerbated by importing additional modules. radar: rdar://62906344. risk: fairly low. testing: added unit tests. reviewer: @xedin </desc> <cmt> [sema] don't diagnose dynamicsubscriptexpr's arg as tuple </cmt> <cmt> register dynamicsubscriptexpr's index expression </cmt> <cmt> as a call argument in miscdiagnostics to avoid it </cmt> <cmt> being diagnosed as a single element labelled tuple. </cmt> <cmt> resolves sr-12799. </cmt> <cmt> [sema] reject an @objc generic subscript </cmt> <cmt> previously we could allow such a declaration to be </cmt> <cmt> marked @objc, despite being incompatible. this </cmt> <cmt> caused crashes later down the pipeline as the </cmt> <cmt> subscript's accessors were correctly checked for </cmt> <cmt> generic params and were not marked @objc. </cmt> <cmt> resolves sr-12801. </cmt> <cmt> [sema] eliminate a subscript anyobject lookup ambiguity </cmt> <cmt> previously we would always consider an anyobject </cmt> <cmt> subscript lookup to be ambiguous if there was a </cmt> <cmt> candidate in both a class and protocol, even if </cmt> <cmt> the selectors and types matched. this was due to </cmt> <cmt> the protocol's generic signature preventing the </cmt> <cmt> signatures from being coalesced. </cmt> <cmt> tweak the logic to strip generic signatures when </cmt> <cmt> comparing for anyobject lookup, matching what we </cmt> <cmt> do for @objc methods. </cmt> <cmt> resolves sr-8611. </cmt> <cmt> resolves rdar://43645564 & rdar://62906344. </cmt>",fix a couple of anyobject lookup bugs
3186,<desc> this pr enables asset updates on ios. the ssziparchive changes are a result of adding an unzipping library to the project source. @lostintangent and i discussed and concluded that it will be simpler to ship ssziparchive together in this plugin instead of relying on another ios dependency manager like cocoapods on top of npm so as to keep our plugin installation simple. react-native 15.0 and above is required after this change. </desc> <cmt> asset-update </cmt> <cmt> remove keys </cmt>,enable asset updates on ios
3187,"<desc> this change makes arm64 work again in 4.10.  here is a summary of the changes. the change to fix overlays and bcmrpi3_defconfig has been cherry-picked from 4.9. a non-portable cast in vc04_services has been fixed. snd_bcm2835 has been fixed for arm64 now that vchiq works. hdmi audio and vchiq are now enabled in bcmrpi3_defconfig i tested the audio by playing some flac audio files and a dvd rip from vlc on debian sid with the xfce4 desktop.   i enabled audio and vc4 video with the following config.txt parameters: dtparam=audio=on dtoverlay=vc4-kms-v3d ideally i would be great if this could somehow be back-ported to 4.9 since that's probably going to be the long term support release.  that would require back-porting the upstream 4.10 of vchiq to 4.9 through. </desc> <cmt> arm64: make it work again on 4.9 (#1790) </cmt> <cmt> * invoke the dtc compiler with the same options used in arm mode. </cmt> <cmt> * arm64 now uses the bcm2835 platform just like arm32. </cmt> <cmt> * arm64: update bcmrpi3_defconfig </cmt> <cmt> arm64: fix bad cast in vc04_services </cmt> <cmt> the function vchiq_copy_from_user contains a non-portable </cmt> <cmt> cast to uint32_t.  convert this to a cast to unsigned long </cmt> <cmt> which is portable. </cmt> <cmt> arm64/snd_bcm2835: port it to arm64. </cmt> <cmt> in the messages sent to vchiq, snd_bcm2835 passes a callback </cmt> <cmt> and a context into two 32 bit pointers.  since this </cmt> <cmt> message is interpreted by the firmware, it can't be easily </cmt> <cmt> changed.  luckily only one of these fields is actual used, </cmt> <cmt> so on arm64 only use one of the fields to store the upper </cmt> <cmt> half of the 64 bit callback pointer. </cmt> <cmt> the kconfig is also changed to allow arm audio to work for arm64 </cmt> <cmt> as well. </cmt> <cmt> arm64: enable hdmi audio and vc04_services in bcmrpi3_defconfig </cmt> <cmt> arm64: run bcmrpi3_defconfig through savedefconfig. </cmt>",make it work in 4.10 + add hdmi audio and vchiq support
3188,<desc> this pull request adds the project files for windows 10.0 universal app (uwp). all cocos2d-x features are supported except curl and assetsmanager (which will be added next week). javascript support will be added in a separate pull request. the vs2015 compiler is more strict than vs2013. a few double to float warnings were fixed. this pull request depends on the win10 dependencies added in pull request cocos2d/cocos2d-x-3rd-party-libs-bin#152 </desc> <cmt> removed old winrt property sheets </cmt> <cmt> disable curl and assetsmanager for windows 10 uwp </cmt> <cmt> fixed compiler warning for double to float conversion </cmt> <cmt> check for existance of key_download_state entry before trying to read its value </cmt> <cmt> added winrt networking files </cmt> <cmt> added windows 10 uwp project files </cmt> <cmt> removed old wp8 files </cmt> <cmt> fixed double to float conversion compiler warning </cmt> <cmt> removed old wp8 files </cmt> <cmt> don't auto update version number for each windows app certification test </cmt> <cmt> added proj.win10 files </cmt> <cmt> added windows 10 uwp cpp template files </cmt> <cmt> updated properties </cmt> <cmt> keyboard events now available in windows universal apps </cmt>,windows 10.0 universal app (uwp) support
3189,"<desc> this patch fixes a few /contrib projects, namely seekable_format/examples and adaptive-compression. it ensures that these projects and pzstd are built when invoking make all, so that their ability to compile get continuously tested. make clean also includes them now. the patch removes the exploratory project long_distance_matching, which learning has already been integrated within zstd as the ""long range mode"" (--long). </desc> <cmt> removed lrm exploratory experiment </cmt> <cmt> fixed seekable format example </cmt> <cmt> added /contrib projects to make all </cmt> <cmt> fixed contrib/adaptive-compression </cmt>",/contrib projects as part of ci tests
3190,"<desc> closes  this pr made many changes, one of which was changing from the default document cache to graph cache. this introduced some bugs relating to reactivity due to graphcache's more aggressive caching policy. i fixed the bugs by ensuring the mutations return the correct fields to update the cache. i also made some other small fixes: do not re-initializing the plugins if they were already initialized added urql devtools support do not create the config file is ""create this manually"" is selected use <script setup> here's an example of a few of the bug fixed. it doesn't not create a new config file if i choose ""create manually"". it also only initializes the plugins once, even if you click ""back"" from the browser screen. finally, if the plugins have already been initialized, it'll just skip the initializing and detecting screen, going straight to the browser launch screen. bugfix3.mov </desc> <cmt> wip: graphcache bugs </cmt> <cmt> do not create config file un-necessarily </cmt> <cmt> naming </cmt> <cmt> setup script </cmt> <cmt> handle state transition correctly </cmt> <cmt> update navigation </cmt>",fix bugs introduced by urql/graphcache
3191,"<desc> bugs fixed: if the number of data points changed, the controller would not update to the correct number of bars. this is fixed & tested. allow setting data: { datasets: [{ hoverborderwidth: [1, 2, 3], // allowed to be an array or a number. used as the border width on hover }] } </desc> <cmt> initial bar controller tests </cmt> <cmt> finish up bar controller tests </cmt>",tests for the bar controller + bug fixes
3192,"<desc> added: hmackeyversion - class representing hmac hmackeyversiontest - junit tests for hmackeyversion signingexception - custom signing exception hashkeyversion - abstract class extended by hmackeyversion </desc> <cmt> added hmac key version, signingexception, and tests for hmac key version </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>","added hmackeyversion, hmackeyversiontest, signingexception, hashkeyversion"
3193,"<desc> this will fix two issues in the collada loader that i had trouble with: it would assume that each surface has only one texture. i had meshes with normal maps, where the loader would display those instead of the color texture. it would try to copy some color properties without checking if they were actually defined, which lead to errors; one example of a mesh file i used this with can be found here: </desc> <cmt> colladaloader: added correct surface/sampler sid mapping to support surfaces with multiple textures (e.g. color + normals) </cmt> <cmt> colladaloader: added check for existence of diffuse/emissive properties before material creation in shader </cmt>","adds support for collada meshes with multiple textures, adds some safety checks to avoid warnings"
3194,<desc> playbook cli unit test doesn't really test anything. this pr checks that: --flush-cache switch is doing something call to _flush_cache method is doing something testplaybookcli unit test ansible version ansible 2.5.0 (devel 145c6f953d) last updated 2017/12/11 11:22:10 (gmt +200) </desc> <cmt> testplaybookcli: '--flush-cache' were ignored </cmt> <cmt> check that using '--flush-cache' does something </cmt> <cmt> check that '_flush_cache' does something </cmt> <cmt> there isn't any fact by default: the assertion was true even if </cmt> <cmt> 'cli._flush_cache()' isn't called. </cmt>,fix playbook cli unit test
3195,<desc> i hereby agree to the terms of the cla available at:  continuation of #19007. closes #15889 </desc> <cmt> use pulling executor in globalsubqueriesmatcher </cmt> <cmt> update tests. </cmt> <cmt> fix test. </cmt> <cmt> fix test. </cmt> <cmt> update tests. </cmt> <iss> block structure mismatch in pipelineexecuting stream </iss>,continue fix for block structure mismatch in pipelineexecuting stream
3196,"<desc> found due to smelly code in inodefile::absolute_path. in particular, this replaces the following misleading methods: file::absolute_path this method never returns an actual path, and if called on an inodefile (which is impossible), it would verify_not_reached(). openfiledescription::try_serialize_absolute_path and openfiledescription::absolute_path these methods do not guarantee to return an actual path (just like the other method), and even if they do, they do not guarantee that the path is still up-to-date (just like custody::absolute_path). in particular, just renaming the method made a toctou bug in process::sys$fstatvfs obvious. the new method signatures use kresultor, just like try_serialize_absolute_path() already did. for this pr i'll consider the following things out of scope: fixing the already-existing toctou bug fixing the already-existing uses of stringbuilder where kbufferbuilder may be a better idea (primarily because kbufferbuilder does not return a kstring) </desc> <cmt> kernel: avoid openfiledescription::absolute_path </cmt> <cmt> kernel: enable early-returns from vfs::for_each_mount </cmt>","untangle {file,description}::absolute_path interface"
3197,"<desc> i think this will make it easier for delta users, as there are several defaults for deltas that are required and cause very odd issues if not set properly. if delta is not defined the defaults are exactly as they were,if delta is defined the defaults are set to the same as in johanns branch. this make sit easier for delta users at the expense of slightly cluttering up the configuration.h file. an alternative would be to make all the changes at the end of the configuration.h all gathered together and using #undef/#define for the delta relevant settings. if you would prefer that i can do it that way. </desc> <cmt> added default configurations for deltas when delta is defined </cmt> <cmt> update max pos </cmt> <cmt> fix zjerk being the same for delta as xy jerk </cmt> <cmt> add more delta defaults </cmt> <cmt> on delta make second home even slower </cmt> <cmt> enable soft endstops for delta </cmt> <cmt> disable delta by default </cmt>",setup default configuration for deltas if delta is defined
3198,"<desc> fixes #4099 links to the resources home rather than a particular module. uses the title of the course rather than the name of a module. appends authors. i noticed during this one that mit opencourseware is written differently in a lot of the repo. on the website itself, they refer to themselves as mit opencourseware. this pr seems a bit inconsistent, but later in a separate pr i'd like to fix that later by updating all the other instances ie mit ocw, or mit's opencourseware to match this one. (i can also add mit opencourseware to links that don't mention the vendor.) read our contributing guidelines put lists  in alphabetical order, correct spacing. followup check the output of travis-ci for linter errors! </desc> <cmt> fix #4099 </cmt> <cmt> remove redundant route in url </cmt>",add resource to free-courses-en.md#deep-learning
3199,"<desc> this solution grows the graph, but this is quite the corner case. r? @michaelwoerister </desc> <cmt> regr test </cmt> <cmt> fix case where some edges can't be recreated by expanding the graph </cmt> <cmt> cc #39569 -- almost certainly a fix for that </cmt>",handle the case where an intermediate node can't be recreated
3200,"<desc> i tested this with python 2.7.8 and python 3.4.1 on windows 7 </desc> <cmt> fix unicodeencodeerror with --write-info-json on python 2.7 + windows </cmt> <cmt> fixes #4244 </cmt> <cmt> fix ""error: cannot write metadata to json file"" on windows </cmt> <cmt> fixes #4246 </cmt>",fix #4246 and #4244 .info.json bugs
3201,"<desc> purpose this pr delivers the external editor section to the device settings page. it also adds a generic select component to support the external editor feature. this component is powered by headlessui, a style-agnostic and multi-framework component library that's focused on delivering accessible components. it was made to work well with tailwind -- which is what we're using. closes #unify-260 how to test open up the cypress component test runner within this branch. yarn workspace @packages/launchpad cypress:open # from the project root components external editor component the external editor component is ready to be picked up for plumbing into gql. closed state open state select component this pr does not refactor the previous select component components/select/selectframework.vue which should be refactored to use this generic select component, which is located under inputs/select.vue. the naming and placement of these components can be rehashed when the design system is formalized. for now, i'm keeping the name as that's what is used in tailwind ui (where i nabbed the styles from). while the tests written for the select component should largely be covered by headlessui itself... undoubtedly we will want to reuse these tests if we swap the internals out for our own select component, so i think it's valuable to maintain our own test suite for it for partial coverage. external-editor-select.mov </desc> <cmt> wip </cmt> <cmt> feat: adding the external editor and select components </cmt> <cmt> chore: fixing types </cmt> <cmt> chore: fixing linter and adding a ton of tests </cmt> <cmt> chore: fix types </cmt>","adding select component to the launchpad, adding external editor"
3202,"<desc> updates getting started, scales, line and bar chart docs. includes change from show to display in #1695 </desc> <cmt> update getting started docs </cmt> <cmt> initial update to scale documentation </cmt> <cmt> initial update to line and bar docs </cmt> <cmt> conflicts: </cmt> <cmt> docs/01-scales.md </cmt>",initial docs to get ready for beta1
3203,"<desc> with this pr indexed access types t[k] become proper type variables such that types of the form t[k1][k2][k3]... and keyof t[k1][k2][k3]... can be constructed. also, this pr enables type inference for recursive homomorphic mapped types. fixes #12544. fixes #12573. fixes #12606. </desc> <cmt> treat indexed access types t[k] as type variables </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",treat indexed access types 't[k]' as type variables
3204,"<desc> this pr: works around a bug with that beta that hides the top page headers tweaks some other descriptions </desc> <cmt> add dummy content to work around a docusaurus bug that hides headers </cmt> <cmt> for some reason, ds beta.0 is hiding our hardcoded headers unless </cmt> <cmt> there's any content at all above them. so, i'm adding &nbsp; as </cmt> <cmt> content at the start of each page to work around this. </cmt> <cmt> add descriptions to api ref pages </cmt>",work around a docusaurus header bug and add descriptions
3205,"<desc> closes #28466 we previously leveraged react bailing out when setting state that's referntially equal. but at the same time we tried to mutate that value (essentially breaking the assumptions that react has about referentially equal values). this causes errors in javascript's strict mode (""use strict""; not react.strictmode) if that value is frozen (which rtk does). i removed the shortcut since it probably has next to no benefit since we always fired a change behavior regardless. if we want to revisit the performance shortcut, we need to be diligent and measure. because i doubt there's much benefit when the slider would re-render anyway if the value is controlled. </desc> <cmt> [test] current behavior of ""almost change"" </cmt> <cmt> simulating user input that may lead to a change but doesn't because it's too small </cmt> <cmt> [slider] don't crash on minimal changes with readonly value </cmt> <iss> slider component issue with redux rtk throws error when the store is updated </iss>",don't error on minimal changes with readonly value
3206,"<desc> adds support for ""paths"" in both tsconfig.json or jsconfig.json. examples: single module alias { ""compileroptions"": { ""baseurl"": ""."", ""paths"": { ""mytheme"": [""components/mytheme.js""] } } } wildcard alias { ""compileroptions"": { ""baseurl"": ""."", ""paths"": { ""@c/*"": [""components/*""], } } } fallback behavior { ""compileroptions"": { ""baseurl"": ""."", ""paths"": { ""@mytheme/*"": [""themes/theme-a/*"", ""lib/theme-b/*""] } } } fixes #7779 </desc> <cmt> add support for tsconfig/json paths option </cmt> <cmt> add tests for paths in tsconfig.json </cmt> <cmt> don't apply aliases when paths is empty </cmt> <cmt> clean up unused methods and link to typescript license </cmt> <cmt> add tests for jsconfig </cmt> <cmt> put feature under an experimental flag </cmt> <cmt> enable to see if tests pass </cmt> <iss> automatically configure webpack to handle `tsconfig.json`'s `baseurl` and `paths` </iss>",add support for paths in tsconfig.json and jsconfig.json
3207,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> inital work </cmt> <cmt> converting requirement set and host tables </cmt>",removing html tables from requirement set and host descriptions
3208,"<desc> previously, we would fetch all requested objects simultaneously, including queued tasks' arguments and ray.get or ray.wait requests from local workers. if the total size was greater than the node's capacity, this could result in starvation. this adds admission control when choosing which objects to fetch to the local node. this makes a couple changes: pull requests are served in fifo order. the total size of objects actively fetched is kept under the node's current capacity (defined as the object store's total capacity - size of pinned objects). we do not start pulling an object until its size is known. this is to prevent flooding the object manager with incoming objects when many requests are made simultaneously for different objects. the algorithm is implemented by finding the longest contiguous prefix of the current request queue whose total size is known and under the current capacity. object size is now attached to all object table replies. the total set of objects needed by the chosen requests will be actively pulled or restored. the current capacity is dynamically and asynchronously updated at every objectmanager tick. closes #12663. i've run scripts/format.sh to lint the changes in this pr. to test this, the python tests submit tasks with several arguments, and there is only enough memory to run one task at a time. on master, this timed out, but the test would finish in ~5s if the python code is modified to manually submit and get one task at a time. with this pr, the run time now matches the version with manual admission control. </desc> <cmt> admission control, todo: tests, object size </cmt> <cmt> unit tests for admission control and some bug fixes </cmt> <cmt> add object size to object table, only activate pull if object size is known </cmt> <cmt> some fixes, reset timer on eviction </cmt> <cmt> doc </cmt> <iss> [object spilling] thrashing when there are large number of dependencies for many tasks </iss>",admission control for pulling objects to the local node
3209,<desc> i've updated all the redux examples with react dependencies to v15.5.0. </desc> <cmt> update async example with react v15.5.0 </cmt> <cmt> update counter example with react v15.5.0 </cmt> <cmt> update real-world example with react v15.5.0 </cmt> <cmt> update shopping-cart example with react v15.5.0 </cmt> <cmt> update todomvc example to react v15.5.0 </cmt> <cmt> update todos example with react v15.5.0 </cmt> <cmt> update todo-flow example with react v15.5.0 </cmt> <cmt> update todos-with-undo example with react v15.5.0 </cmt> <cmt> update tree-view example with react v15.5.0 </cmt> <cmt> update universal example with react v15.5.0 </cmt>,update examples with react v15.5.0
3210,"<desc> general punctuation 203d, 2047-2049, 2030(modified to look more like 0025), 204b, 2031  supplemental punctuation 2e2e, 2e18, 2e55-2e58, 2e26, 2e27  miscellaneous symbols and pictographs 1f3dc, 1f3dd, 1f4fa, 1f4f6, 1f4dc, 1f4a3, 1f4a4, 1f4a8, 1f4c8, 1f4c9, 1f4ca, 1f4cb, 1f4af, 1f41f, 1f374, 1f3c1, 1f4be, 1f500, 1f501, 1f503, 1f504, 1f508, 1f509, 1f50a </desc> <cmt> base: add general punctuation characters to font katica regular 10 </cmt> <cmt> 203d, 2047-2049, 2030(modified to look more like 0025), 204b, 2031 </cmt> <cmt> base: add misc supplemental punctuation chrs to font katica regular 10 </cmt> <cmt> 2e2e, 2e18, 2e55-2e58, 2e26, 2e27 </cmt> <cmt> base: add symbols and pictographs characters to font katica regular 10 </cmt> <cmt> 1f3dc, 1f3dd, 1f4fa, 1f4f6, 1f4dc, 1f4a3, 1f4a4, 1f4a8, 1f4c8, 1f4c9, </cmt> <cmt> 1f4ca, 1f4cb, 1f4af, 1f41f, 1f374, 1f3c1, 1f4be, 1f500, 1f501, 1f503, </cmt> <cmt> 1f504, 1f508, 1f509, 1f50a </cmt>",add characters to font katica regular 10
3211,"<desc> alternative to #8920 (i.e. one or the other). same use case - allowing sending of parameters using rules to binary serial devices e.g.  #5737. i've noted that the mqtt response formats in hex when serial is received after a binary message is sent - i don't think this should change so it's treated the same. example: serialsend6 255,85,5,5,220,10 an example rule that (should) allow the above device to work with vanilla tasmota + this pr: rule1 on dimmer#state=0 do event setdimmer=5 endon on dimmer#state>0 do backlog scale1 %value%,1,100,16,255; event udimmer endon on dimmer#boot do backlog baudrate 9600; scale1 %value%,1,100,16,255; event udimmer endon on event#udimmer do event setdimmer=%var1% endon on event#setdimmer do serialsend6 255,85,%value%,5,220,10 endon on power1#state=0 do event setdimmer=5 endon on power1#state=1 do event setdimmer=%var1% endon the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.2.1 the code change is tested and works on core esp32 v.1.12.2 no device to test sorry i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> serialsend6 </cmt> <cmt> * adds serialsend6, allowing sending of binary data with comma-delimited string of decimal numbers. </cmt> <cmt> serialsend6 - fixes </cmt> <cmt> forgot to fix top condition </cmt> <cmt> serialsend6 - more fixes </cmt> <cmt> oops </cmt>",serialsend6 - comma-separated decimal send as binary
3212,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: date range picker - date range add it to notneededpackages.json. </desc> <cmt> adds rangewithkey </cmt> <cmt> updates test </cmt>",adds rangewithkey which extends range with a key prop
3213,<desc> some gyb files end with a specially prepared local variables section that made emacs editors open the generated file in read-only mode. this is useful in preventing accidental edits that will get overwritten during the build. remove this section from degybbed sources and add it to all remaining .gyb files in the stdlib and the benchmark suite. nfc </desc> <cmt> [gardening][test] allow emacs to modify degybbed files in stdlibunittest </cmt> <cmt> [gardening][benchmark] don't let emacs modify gyb-generated benchmark sources </cmt> <cmt> [gardening][stdlib] don't let emacs modify gyb-generated sources </cmt>,clean up gyb-related emacs local variables
3214,"<desc> #317 issue (closed) hello! i'm working on elgamal cipher and this request is for my ""key generator"" code regards, </desc> <cmt> modify readme.md by psyas for just test </cmt> <cmt> elgamal cipher key generator code - (initial) </cmt> <cmt> elgamal cipher key generator code - (initial) </cmt>",create new cipher - elgamal cipher key generator
3215,<desc> this pr adds the functionality requested by ericsnowcurrently/multi-core-python#52.  automerge-triggered-by: @ericsnowcurrently </desc> <cmt> attempt at implementing channel_list_interpreters() </cmt> <cmt> fix some error cases </cmt> <cmt> fix issue with decreasing list items' references </cmt> <cmt> fix issue with reference to interpreter </cmt> <cmt> add ability to list interpreters on send or receive channels </cmt> <cmt> fix arg parsing in c code </cmt> <cmt> minor changes </cmt> <cmt> add channel_list_interpreters() tests </cmt> <cmt> fix docstring </cmt> <cmt> improve naming in tests </cmt> <cmt> add macros for int64_t max etc </cmt> <cmt> fix error handling </cmt> <cmt> expose _pyinterpreterstate_lookupid </cmt> <cmt> fix bad git rebase (use _xxsubinterpreters module name) </cmt> <cmt> remove decref of null </cmt> <cmt> fix leftover broken code from nested loop </cmt>,list interpreters associated with a channel end
3216,"<desc> with this change, we consider all exported members as 'visible' for declaration emit, and then use import types to reference them. this means, eg, this: // @filename: file1.ts export class foo {} // @filename: file2.ts export function foo(): import(""./file1"").foo { return null as any; } // @filename: file3.ts import {foo} from ""./file2""; export function bar() { return foo(); } emits these declarations: // @filename: file1.d.ts export class foo {} // @filename: file2.d.ts export function foo(): import(""./file1"").foo; // @filename: file3.d.ts export function bar(): import(""./file1"").foo; small todo/discussion point: based on discussions we've had internally, if there are other import statements preserved in the declaration emit (or maybe all the time? idk - i personally prefer the import types in many cases), we should coalesce repeated imports into a single synthetic import statement - this is just a style adjustment, as it would just cut down on repeated import types in favor of import x = require("""") declarations. however, from a ""makes the declaration authoring experience better"" pov, this is already usable as is. it'd be nice to know what people's preferences are here, though. fixes #9944 invalidates #22132 </desc> <cmt> stand up a simple implementation using import types for exports of modules which are otherwise inaccessible </cmt> <cmt> ensure references exist to link to modules containing utilized ambient modules </cmt> <cmt> accept baselines with new import type usage </cmt>",use import types to refer to declarations in declaration emit
3217,"<desc> mostly just refactoring, no real code changes. but it fixes one thing: previously, doing a uidmap mount in nspawn would cause us to call sync() even though we really shouldn't. </desc> <cmt> basic: move freeze() from shared/exec-util.h to basic/process-util.h </cmt> <cmt> that way we can use it in other code from basic/. it fits into both </cmt> <cmt> headers equally well or badly, hence let's just move this one function. </cmt> <cmt> namespace-util: introduce userns_acquire() as helper for allocating new unbound userns </cmt> <cmt> this returns a namespace fd, and takes a uidmap/gidmap as string. this </cmt> <cmt> is split out out mount-util.c's remount_idmap() logic, so that we can </cmt> <cmt> allocate a userns independently. </cmt> <cmt> process-util: move sync() out of freeze() </cmt> <cmt> we are using this for creating userns namespaces, and we really </cmt> <cmt> shouldn't try to sync there. moreover the use of free() in shutdown code </cmt> <cmt> doesn't need it anyway, since it just sync()ed right before anyway. only </cmt> <cmt> the third user of freeze() we have actually needs the syc(), hence do it </cmt> <cmt> there and nowhere else. </cmt>",split out userns allocation into new helper function
3218,"<desc> if a transform config got lost (e.g. because the internal index disappeared) tasks could not be stopped using transform api. this change makes it possible to stop transforms without a config, meaning to remove the background task. in order to do so force must be set to true. </desc> <cmt> make it possible to stop dangling transforms </cmt> <cmt> test task removal after internal index deletion </cmt>",improve force stop robustness in case of an error
3219,"<desc> cherry pick #6046 into the v1.5 branch in case it's useful for others not yet on 1.6. </desc> <cmt> view: recursively check mapped of view_child tree </cmt> <cmt> a subsurface may be set to mapped without its parent. </cmt> <cmt> (cherry picked from commit e7af5b630916c5620cb7806993530ef4ca965591) </cmt> <cmt> view: mark subchildren as unmapped in view_child_destroy </cmt> <cmt> the subchildren lose their parent association at this point, so they </cmt> <cmt> will not be able to see that the parent is unmapped. </cmt> <cmt> instead, just set the subchildren to be unmapped directly. </cmt> <cmt> (cherry picked from commit 79e43b19d795d68a3916a19d9afadc4ccbb7d4db) </cmt> <cmt> view: set parent for view_child subsurfaces on init </cmt> <cmt> view_child_init was calling view_init_subsurfaces, which did not set the </cmt> <cmt> parent attribute for the subchildren. this lead to the subchildren </cmt> <cmt> acting as standalone children. if the parent was an xdg_popup, this </cmt> <cmt> would make the subchild unaware of the popup position. </cmt> <cmt> introduce view_child_init_subsurfaces for view_child_init to use </cmt> <cmt> instead. </cmt> <cmt> closes: </cmt> <cmt> (cherry picked from commit 1a6471be172fc2da75bbc5b7e6e3b3c99dbafc51) </cmt>",backport subsurface parent fixes to v1.5
3220,"<desc> some python 3 incompatibilities existed in the website build pipeline. when ci was updated to run docs build in python 3 mode these surfaced. this pr addresses it and locks in the python dependency versions to help prevent future breakage. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change fixed sphinx plugin mxdoc.py python 3 issues by using six. added six to dependencies consolidated python requirements for docs to one file in ci/docker/install pinned dependencies to specific version numbers mock was not pinned upstream from docs, so we were getting a later version than what docs had been pinned to, so this is upgraded. ""upgraded"" a variety of packages that were not pinned to the latest in pypi. tests indicate things are good, and i'd rather pin things now to prevent future breakage. added a separate jenkinsfile-dev so i don't have to keep hacking the jenkinsfile every time i need to test something from my fork. this way i can just point to it from the test jenkins jobs directly, and no more code updates. updated ci's docker images to use the new python requirements file we can break out a separate requirements file if some split in deps appears between python 2/3. for now the packages are the same. </desc> <cmt> fixing python 3 print issue </cmt> <cmt> test setup jenkinsfile </cmt> <cmt> moved python reqs for docs to ci zone; added six; using six in for sphinx python 3 compatibility </cmt> <cmt> add dev jenkinsfile to not spam alert email; path fix </cmt> <cmt> copy requirement to docker image </cmt> <cmt> making docs_requirements available to docker </cmt> <cmt> full path needed </cmt> <cmt> reverting to production settings </cmt> <cmt> path fix to requirements </cmt>",fix website build pipeline python 3 issues
3221,"<desc> looking at #4368 turned up a mess of memory leaks in pyopenssl. however, pyca/pyopenssl prominently states that ""for anything other than making a tls connection you should move to cryptography and drop your pyopenssl dependency."" as such, instead of fixing pyopenssl, we just migrate and get rid of our problems. :) the cryptography api is much nicer, so we should use it everywhere where we currently use the pyopenssl objects. @linw1995, does this fix the memory leaks you are seeing? </desc> <cmt> add memory leak detect script for certificate generation, refs #4368 </cmt> <cmt> use cryptography to generate certificates </cmt> <cmt> this fixes #4368, but we are not done here. the goal is to replace most </cmt> <cmt> usages of pyopenssl's cert object with cryptography. </cmt>",use cryptography for certificate generation
3222,"<desc> diff reduction with the vw community port add some necessary pieces to support the volkswagen e-golf, which has no transmission and needs to find gearshift position from a different signal. also add support for manual transmission vehicles, which can be had with acc and lkas. test driven as a standalone change to upstream master. i myself can only test the auto trans branch of the code, but many others in the community have exercised this same code for months in the community port. 2018 volkswagen golf r: cae14e88932eb364|2021-03-05--18-47-48 </desc> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt> <cmt> support pieces for e-golf and manual trans </cmt>",support for other transmission types
3223,"<desc> i agree that my contributions are licensed under the {fmt} license, and agree to future changes to the licensing. #1928 </desc> <cmt> added check whether mingw has -mbig-obj flag </cmt> <cmt> added extra macro to determine whether compiler has ref qualifiers </cmt> <cmt> renamed macro to fmt_ref_qualifier </cmt>",added check for -mbig-obj and ref qualifier check
3224,"<desc> handles two scenarios: when the type is inferred, checker tracks if its writing first type argument so it can parenthesize generic function type. when the type is written in a file but isn't parenthesized but has used space to separate the type parameter from type argument's <. declaration emitter after looking up previous emitted character to be <, parenthesizes the function type with type parameters fixes #8105 </desc> <cmt> add the test case for #8105 </cmt> <cmt> parenthesize the fn or constructor type with type parameter when writing it in type argument </cmt> <cmt> fixes #8105 </cmt> <cmt> adding another test case to handle more generic scenarios </cmt> <cmt> fix declaration emit when first generic function type in type argument position specified using space </cmt>",fixes scenarios of generating declaration file when first type argument is generic function type
3225,"<desc> this feature was only needed for windows users. there will be no need to do this in unix like operating systems. let's suppose we have a gui program (.pyw) which uses selenium. from selenium import webdriver driver = webdriver.chrome() when the subprocess.popen(...) opens the chromedriver, a new console window will open up on windows system. to avoid this, we can use create_no_window creation flag (or possibly some other flags). this will call subprocess.popen(...,creationflags=self.creationflags). after the added feature, we will be able to do something like this: from selenium import webdriver from selenium.webdriver.chrome.service import service as chromeservice # similar thing for firefox also! from subprocess import create_no_window # this flag will only be available in windows chrome_service = chromeservice('chromedriver', creationflags=create_no_window) driver = webdriver.chrome(service=chrome_service) # no longer console window opened, niether will chromedriver output i had done this directly inside the webdriver class but the seniors asked to do this inside service or options class. so here i am again! anyway, i am open to alternatives you suggest and commit again, and eventually i will do better code contribution after learning the structure of project more. question: if this is okay, can i also proceed with the same strategy for other browsers as well? </desc> <cmt> added creationflags option for subprocess.popen, in common service class constructor </cmt> <cmt> added creationflags option in chromium service class constructor </cmt> <cmt> added creationflags option in chrome service class constructor </cmt> <cmt> added creationflags option in firefox service class constructor </cmt>","added new argument creationflags in service class for common, chrome, and firefox"
3226,<desc> 7.x backport for #73437 </desc> <cmt> [docs] create a new page for dissect content in scripting docs (#73437) </cmt> <cmt> * [docs] create a new page for dissect in scripting docs </cmt> <cmt> * expanding a bit more </cmt> <cmt> * adding a section for using dissect patterns </cmt> <cmt> * adding tests </cmt> <cmt> * fix test cases and other edits </cmt> <cmt> add doc type to response </cmt>,create a new page for dissect content in scripting docs #73437
3227,"<desc> closes #6108. before these changes, when a line contained multiple selections and deleteline() was called, two lines would have been deleted instead of just one. this happens because, when the line containing the first selection is deleted, the other selection doesn't get destroyed but it simply moves. this pr tries to fix this by merging selections that have intersecting rows. however, i do feel like there may be some other elegant solutions to this: i am thinking to something like marker invalidation, for example. /cc: @nathansobo </desc> <cmt> merge intersecting selections by row before deleting lines </cmt> <cmt> :memo: improve naming </cmt> <iss> delete line deletes more than one line if the line has multiple selections </iss>",fix deleteline() when multiple selections are on the same line
3228,"<desc> what did you implement added on failure destination for streams. destination arn can be provided as string or dynamically. if given dynamically, a valid type given. this code does not create the sns/sqs resource if it does not exist. closes #7236 how can we verify it functions: preprocess: handler: handler.preprocess events: - stream: arn: arn:aws:kinesis:region:xxxxxx:stream/foo destinations: onfailure: arn: fn::getatt: - myqueue - arn type: sqs resources: resources: myqueue: type: aws::sqs::queue todos useful scripts npm run test:ci --> run all validation checks on proposed changes npm run lint:updated --> lint all the updated files npm run lint:fix --> automatically fix lint problems (if possible) npm run prettier-check:updated --> check if updated files adhere to prettier config npm run prettify:updated --> prettify all the updated files write and run all tests write documentation enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add destinationconfig support and docs </cmt> <cmt> expand test coverage. remove debug comments </cmt> <cmt> chore - linting. </cmt> <cmt> chore - linting. </cmt> <iss> expose destination on failure prop for kinesis streams </iss>",expose destination on failure prop for streams
3229,"<desc> this is the first pr to rename the series of components in xla, per @cheshire request here. the aim of this series is such that all components shared by cuda and rocm have the prefix gpu instead of cudnn. to make the pr easy to review, i make following decisions: each pr only rename one component renaming is done by: $ find . -type f -exec sed -i ""s/foo/bar/g"" {} \ each commit handles the renaming of one symbol. i highly recommend reviewing by commit. 1st commit: file renaming only, no symbol change 2nd commit: rename only cudnnconvparams to gpuconvparams 3rd commit: rename only runcudnnconv to rungpuconv 4th commit: rename only include guard each commit verified by convlution_test_gpu note: this approach does not guarantees completely removing cudnn symbol from the source code, does not seek for perfectionism, but will purge the current code base in a gradual manner. the whole purpose of doing it is to make sure reviewer can review it easily, and that each pr can be merged as fast as it can, since renaming touch interface and runs into conflict often. i want to minimize the overhead of spinning after pr is submitted. </desc> <cmt> renaming cudnn_conv_runner to gpu_conv_runner </cmt> <cmt> rename cudnnconvparams to gpuconvparams </cmt> <cmt> runcudnnconv to rungpuconv </cmt> <cmt> rename include guard </cmt>",renaming cudnn conv runner to gpu conv runner
3230,"<desc> this pr is continuation of #9735 and is raised by #9732. note, that examples/create-react-app-with-jss example will not work until beta.27 is released, since jsspreset is not exposed in earlier versions. so it's better to not merge it until beta.27 is released. </desc> <cmt> remove unneded dependencies from create-react-app-with-jss example </cmt> <cmt> use jsspreset instead of jss-preset-default </cmt> <cmt> remove unneeded dependencies from create-react-app-with-flow example </cmt> <cmt> remove unneeded dependencies from nextjs example </cmt>",remove unneeded dependencies from examples
3231,"<desc> what did you implement: closes #3934 and #4235 changed config template from requested changes of @pmuens added supported for using existing resources how did you implement it: i organized rest api resources into n-ary trees with resourceid, then cut redundant branches and replaced new roots with existing resource id how can we verify it: service: name: sls-shared-api provider: name: aws runtime: nodejs6.10 apigateway: restapiid: 6fyzt1pfpk restapirootresourceid: z5d4qh4oqi restapiresources: '/users': 'sdafgkuopw' '/users/{userid}': { ref: apiresourceuserdetail } functions: userposts: handler: handler.userposts events: - http: get /users/{userid}/posts userinfo: handler: handler.userinfo events: - http: get /users/info tags: handler: handler.tags events: - http: get /tags todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> update share api gateway resource </cmt> <cmt> fixed method get restapiid </cmt> <cmt> capsule api gateway rest api id </cmt> <cmt> fixed api resources tree </cmt> <cmt> update predefined resources test </cmt>",wip - added support for using an existing apigateway and resources
3232,<desc> fixes issue: none changes: added the code for the travelling salesman problem using dynamic programming and bitwise operators </desc> <cmt> updating from main repo (#2) </cmt> <cmt> * add code and data gitignore </cmt> <cmt> * fix gitignore </cmt> <cmt> * train the model and save logs </cmt> <cmt> * repair paths to code/languages/cpp </cmt> <cmt> * optimize for partially sorted arrays </cmt> <cmt> added code for tsp in dp </cmt> <cmt> this code consists of the dp solution for tsp using bitwise operator along with the brute force approach. </cmt> <cmt> create readme.md </cmt> <cmt> updating the repo from the main repo (#3) </cmt> <cmt> * add code and data gitignore </cmt> <cmt> * fix gitignore </cmt> <cmt> * train the model and save logs </cmt> <cmt> * repair paths to code/languages/cpp </cmt> <cmt> * optimize for partially sorted arrays </cmt>,travelling salesman problem solution using dp
3233,"<desc> closes #5401 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this is a first draft of a cross method for merge operations. as suggested by @jreback i added a new column and dispatched to inner as a first naive implementation. i am currently wondering, if there would be a better place to adjust the arguments than the places i selected. i wanted to avoid to modify self in some method called within the constructor, so i modified the inputs before adding the parameters to self. this currently does not support the cross method for join. if we get a consensus where to put the modifications, i would add support for join. also have to add more tests probably and something to the userguide have to look into the performance afterwards. copies of the left and right frames may be a big performance hit for bigger frames? </desc> <cmt> first cross merge draft for merge operation </cmt> <iss> enh: cross join in merge() and join() </iss>",implement cross method for merge operations
3234,"<desc> fyi @thakeenathees </desc> <cmt> i18n: add header strings to translation catalog </cmt> <cmt> i18n: add makefile to extract classref strings </cmt> <cmt> change extract script path argument to support specifying multiple </cmt> <cmt> paths, like makerst.py. this prevents parsing invalid xml files while </cmt> <cmt> scanning the whole repository. </cmt> <cmt> i18n: generate translation template for class reference </cmt>","improve classref translation extractor, add makefile and generate .pot file"
3235,"<desc> the log directive for the purpose is %{error}x. also, a configuration directive named error-log.emit-request-errors is added to disable request-level logging to error log. </desc> <cmt> refactor </cmt> <cmt> store error messages in h2o_req_t, log it using %{error}x </cmt> <cmt> add test </cmt> <cmt> add error-log.emit-request-errors to control if request-level errors should be emitted to the error log </cmt>",provide option to emit request-level errors into access log
3236,"<desc> attempted to update information in this doc. removes a section of the doc that was relevant for electron 1 and below. seems like we're building on ubuntu 18.04 based on electron/build-images. is this accurate for all linux binaries? @jkleinsc @marshallofsound tried to update minimum version numbers for linux distros informed by chrome's minimum version requirements. npm test passes pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> docs: remove stale info from version support doc </cmt> <cmt> attempt to update binary info? </cmt>",update information on linux support
3237,<desc> closes #28659 published packages remain broken. for security reasons vscode no longer displays svgs. pngs were created with svgexport input.svg output.png 24:24 redirects from *.svg to *.png are not possible with netlify sending image/png from *.svg is not displayed in vscode </desc> <cmt> convert svg to png </cmt> <cmt> remove svgs </cmt> <cmt> display png instead of svg </cmt> <cmt> redirect old svgs to new pngs </cmt> <iss> use rendered graphics like png files instead of svg in documentation </iss>,use png instead of svg for color preview
3238,"<desc> as you know, this is not finished, but this completes the ""read/write/remove"" interface. i implemented ""fs.write()"" and ""fs.read()"" in the js shim (i.e. bootstrap.js) because it needs to file exception on fail, and so i'd have needed to do some js code anyway. check it out and it will be clear what i need. plus, in the ""header"" is now precisely defined what is going to be ultimately in the ""filesystem api"". ivan </desc> <cmt> note in the code what method i'm going to add to the ""fs"" object. </cmt> <cmt> note in the code what method i'm going to add to the ""fs"" object (update). </cmt> <cmt> implement ""fs.read"" and ""fs.write"" in the javascript shim. </cmt> <cmt> * i'd have to do it for throwing an exception in case of error anyway </cmt> <cmt> * updated a bit the code doc </cmt> <cmt> a bit more code doc </cmt>","completed implementation of ""fs"" basic modules"
3239,<desc> i'm exploring writing a babel plugin to convert property names to enable our tests to run against the minified builds. in the process of doing that i realized that our tests still used babel 6. this pr upgrades them to babel 7. </desc> <cmt> simplify istanbul config by specifying include array </cmt> <cmt> upgrade tests to babel 7 </cmt>,upgrade tests to use babel 7
3240,"<desc> cherry-pick all changes of azure_rm_common from devel to stable-2.4, so they can be released in 2.4.2.0 azure_rm_common ansible version ansible 2.4.2.0 (azure-common 88bf729af3) last updated 2017/11/07 11:26:28 (gmt +800) config file = none configured module search path = [u'/users/kevinzha/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/kevinzha/workspace/ansible/lib/ansible executable location = ./bin/ansible python version = 2.7.13 (default, dec 17 2016, 23:03:43) [gcc 4.2.1 compatible apple llvm 8.0.0 (clang-800.0.42.1)] </desc> <cmt> remove explicit provider reg from azure_rm (#31369) </cmt> <cmt> * now that it's handled automatically as of msrest > 0.4.9 </cmt> <cmt> add user-agent to azure api calls (#31872) </cmt> <cmt> * addi ansible user-agent in azure api calls </cmt> <cmt> * fix import error </cmt> <cmt> add user agent for cloud shell (#32332) </cmt>",cherry-pick changes of azure_rm_common from devel to 2.4
3241,"<desc> this is pr #4002, with some additional squishing of the code using macros. </desc> <cmt> 3 ms speedup for st7920 and delay for board_3drag </cmt> <cmt> and saving ~1k memory </cmt> <cmt> by limiting the #pragma gcc optimize (3) optimisation to ultralcd_st7920_u8glib_rrd.h. these optimisation was and is not done for all the other displays, is the reason for the big additionally use of memory, because the complete 'ultralcd.cpp' and 'dogm_lcd_implementation.h' was optimised (sadly i did not observe a change in speed). </cmt> <cmt> unrolling the loop in st7920_swspi_snd_8bit(), what i expected the optimiser to do, by hand, saved some speed by eliminating the loop variable (i) compares and increases. every cpu cycle in this loop costs at least 0.5ms per display update because it's executed more than 1k times/s. </cmt> <cmt> the delays are now pre-filled with the calculated values for 4.5v driven st7920. </cmt> <cmt> a way to simply add __your__ timing into the configuration was made. </cmt> <cmt> at 4.5v </cmt> <cmt> 1.) the clk signal needs to be at least 200ns high and 200ns low. </cmt> <cmt> 2.) the dat pin needs to be set at least 40ns before clk goes high and must stay at this value until 40ns after clk went high. </cmt> <cmt> a nop takes one processor cycle. </cmt> <cmt> for 16mhz one nop lasts 62.5ns. </cmt> <cmt> for 20mhz one not lasts 50ns. </cmt> <cmt> to fulfill condition 1.) we need 200/62.5 = 3.2 => 4 cycles (200/50 = 4 => 4). for the low phase, setting the pin takes much longer. for the high phase we (theoretically) have to throw in 2 nops, because changing the clk takes only 2 cycles. </cmt> <cmt> condition 2.) is always fulfilled because the processor needs two cycles (100 - 125ns) for switching the clk pin. </cmt> <cmt> needs tests and feedback. </cmt> <cmt> especially i cant test 20mhz, 3drag and displays supplied wit less than 5v. </cmt> <cmt> are the delays right? please experiment with longer or shorter delays. and give feedback. </cmt> <cmt> already tested are 5 displays with 4.9v - 5.1v at 16mhz where no delays are needed. </cmt> <cmt> decrease the needed nops to 1 </cmt> <cmt> by shitfing the left shift into the high phase. </cmt> <cmt>  </cmt> <cmt> 2	cbi 0x2,1 ;set clk                      // </cmt> <cmt> 1	in r18,__sreg__                         //1 </cmt> <cmt> 1-3	sbrc r24,7                              //2-4 </cmt> <cmt> 2	rjmp .l19                               //4 </cmt> <cmt> 1	cli                  .l19:              //5 </cmt> <cmt> 2	lds r25,258          lds r25,258        //7 </cmt> <cmt> 1	andi r25,lo8(-2)     ori r25,lo8(1)     //8 </cmt> <cmt> 2	sts 258,r25          sts 258,r25        //10 </cmt> <cmt> 1	out __sreg__,r18     out __sreg__,r18   //11 </cmt> <cmt> 2	.l3:                 rjmp .l3           //13     //2 </cmt> <cmt> 2	sbi 0x2,1 ;reset clk //                 //13-15  //2-4 </cmt> <cmt> 1	lsl r24	 ;  val      //1 </cmt> <cmt> 1	nop                  //2 </cmt> <cmt> 2	cbi 0x2,1 ;set clk   //4 </cmt> <cmt> ... </cmt> <cmt>  </cmt> <cmt> set testet delays for k8200, rambo, minirambo and st7920 </cmt> <cmt> squish code in st7920 </cmt>",fix up delays in st7920_swspi_snd_8bit
3242,<desc> add resource(s) | improve repo resolves #5693 read our contributing guidelines search for duplicates. #5693 </desc> <cmt> create free-courses-gr.md and added javascript course </cmt> <cmt> check_urls=free-programming-books.md free-programming-books-gr.md </cmt> <cmt> update free-courses-gr.md </cmt> <cmt> bumps review ebookfoundation#5693 </cmt> <cmt> recover deleted pr head: </cmt> <cmt> git fetch upstream pull/5693/head:pr/anneiric/5693 </cmt> <cmt> anneiric <69729163+anneiric@users.noreply.github.com> </cmt> <cmt> fix(listings): greek language code gr > el </cmt> <cmt> language code for greek is el not gr. see: ebookfoundation/free-programming-books#6070 </cmt> <cmt> applies </cmt> <cmt> feat(courses): add greek entry </cmt> <cmt> link recent created greek courses listing books/free-courses-el.md into readme.md </cmt> <cmt> resolves ebookfoundation/free-programming-books#5693 </cmt> <cmt> feat(courses): add greek entry </cmt> <cmt> link courses/free-courses-el.md into readme.md </cmt> <cmt> resolves ebookfoundation/free-programming-books#5693 </cmt>,recover pr #5693. create greek courses list
3243,"<desc> show class and function name when luaval_to_xxx failed. original error msg: argument #2 is 'nil'; 'number' expected. new error msg: cc.delaytime:create argument #2 is 'nil'; 'number' expected. sometimes, websocket.close will hang app due to join thread call. so i comment it out. disable sent & recv log for less annoying msg. </desc> <cmt> no use jointhread </cmt> <cmt> show detail class & function name on conversion error </cmt>",more details for conversion error msg
3244,"<desc> this request contains only improvements for already pushed soft cascade functionality. </desc> <cmt> first debug integration of newly trained cascade </cmt> <cmt> integrated 128x256 scale </cmt> <cmt> integrate 128x256 scale; remove log </cmt> <cmt> xml for soft cascade </cmt> <cmt> perf test </cmt> <cmt> a bit refactored soft cascade </cmt> <cmt> fix test for a new test data </cmt> <cmt> fix soft scade xml </cmt> <cmt> add two types of feature boxes support: </cmt> <cmt> - (left, top, width, height) </cmt> <cmt> - (left, top, right, bottom) </cmt> <cmt> fix typo </cmt> <cmt> fix python wrapping </cmt>",soft cascade refactoring and fixes
3245,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. additional information: i was not able to schedule a simple task due to the following unsupported/missing typings: ""parent"" is a required field on createtaskrequests (see the docs, for example the quickstart guide in the google tasks node.js readme) not all of the properties on appenginehttprequest are required, also observable from the quickstart like mentioned above. </desc> <cmt> fixes optional/missing parameters for google tasks api. </cmt> <cmt> ""parent"" is a required field on createtaskrequests (see the docs, for example the quickstart guide at </cmt> <cmt> not all of the properties on appenginehttprequest are required, also observable from the quickstart like mentioned above. </cmt>",fixes optional properties and adds missing property
3246,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. see </desc> <cmt> widen input types </cmt> <cmt> further widening </cmt> <cmt> make type generic instead of using any </cmt>,widen input types to support non-strings
3247,"<desc> this allows code signing certificates to be specified via atom_mac_code_signing_cert_path and atom_win_code_signing_cert_path on macos and windows, respectively. in that case, we don't try to download the certificate, and we also don't delete the certificate after signing is complete. this also fixes an issue where certpath wasn't in scope for the finally block in the macos case. / </desc> <cmt> allow macos signing cert to be specified by atom_mac_code_signing_cert_path </cmt> <cmt> allow windows signing cert to be specified by atom_win_code_signing_cert_path </cmt>",allow code signing cert to be specified at a local path
3248,"<desc> fixes #9568 part 8. use client side login username, hostname and selected database as user/host/db columns value support show processlist before use db info column value set maximum length </desc> <cmt> show user/host/db columns </cmt> <cmt> show processlist before use db </cmt> <cmt> info maximum length </cmt> <cmt> merge from apache master </cmt> <iss> [new feature] support to show execution process for running sqls by rql </iss>",optimize user/host/db columns for show processlist
3249,"<desc> additional changes add an overload to fsextra.symlink add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> merge from main repo </cmt> <cmt> ignore shrinkwrap.yaml </cmt> <cmt> set type of symlink parameter 'type' to a union </cmt>","set type of symlink parameter type to a union of ""file"" | ""dir"" | ""junction"" | undefined | null"
3250,<desc> fix #4988. @pooyadavoodi. </desc> <cmt> fix tensorrt test output and add int8 result. </cmt> <cmt> fix comments </cmt> <cmt> removing footnote declaration as well </cmt> <cmt> merge with upstream/master </cmt> <cmt> remove tf-trt examples and point users to new example repo </cmt> <cmt> update urls </cmt> <iss> broken link on tensrort page </iss>,remove tf-trt examples and point users to the new examples repo
3251,"<desc> this is a cherry picked verison or pr #5012. that pr was messed up by rebasing. since variable/tensor merging is almost completing, i think the tests should pass now. </desc> <cmt> check value type when registering buffer </cmt> <cmt> fix pep8 </cmt>",check value type for register_buffer
3252,"<desc> at this point the remaining pyupgrade diff is so small, so i've finally introduced it as a pre-commit hook and rerun it on everything. </desc> <cmt> pyupgrade_plugin_percent_format=1 pyupgrade --py36-plus src/sentry/integrations/**/*.py src/sentry/plugins/**/*.py src/sentry_plugins/**/*.py </cmt> <cmt> pyupgrade_fix_fstrings=1 pyupgrade --py36-plus src/sentry/integrations/**/*.py src/sentry/plugins/**/*.py src/sentry_plugins/**/*.py </cmt> <cmt> pyupgrade_fix_fstrings=1 pyupgrade_fix_fstrings_multiline=1 pyupgrade_fix_fstrings_inline_strings=1 pyupgrade --py36-plus src/sentry/integrations/**/*.py src/sentry/plugins/**/*.py src/sentry_plugins/**/*.py </cmt> <cmt> pyupgrade_plugin_percent_format=1 pyupgrade --py36-plus ./**/*.py </cmt> <cmt> pyupgrade_fix_fstrings=1 pyupgrade --py36-plus ./**/*.py </cmt> <cmt> pyupgrade_fix_fstrings=1 pyupgrade_fix_fstrings_multiline=1 pyupgrade_fix_fstrings_inline_strings=1 pyupgrade --py36-plus ./**/*.py </cmt> <cmt> remaining pyupgrade </cmt> <cmt> again, revert the mock </cmt> <cmt> pre-commit run pyupgrade --all-files </cmt>","introduce pyupgrade pre-commit hook, and make the rest of the code conformant"
3253,"<desc> currently the connection strategy used by the remote cluster service is implemented as a multi-step sniffing process in the remoteclusterconnection. we intend to introduce a new connection strategy that will operate in a different manner. this commit extracts the sniffing logic to a dedicated strategy class. additionally, it implements dedicated tests for this class. additionally, in previous commits we moved away from a world where the remote cluster connection was mutable. instead, when setting updates are made, the connection is torn down and rebuilt. we still had methods and tests hanging around for the mutable behavior. this commit removes those. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> changes </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> changes </cmt> <cmt> more testing </cmt> <cmt> work on tests </cmt> <cmt> wip </cmt> <cmt> checkstyle </cmt>","extract remote ""sniffing"" to connection strategy"
3254,<desc> fixes #18847 </desc> <cmt> make sure layer.find returns null on non-invertable transforms </cmt> <cmt> translation matrix does not need determinate check </cmt> <cmt> add test case for transform invert </cmt> <iss> transforming listview to x scale of 0 throws an exception </iss>,return null from layer.find when transform layer has a non-invertable transform
3255,"<desc> #65499 65499 the following simple fixes improve usability and accessibility with screen readers. i am currently working on an nvda screen reader add-on module to make more improvements. i am not a typescript developer, and therefore someone more knowledgeable will need to clean my code. i am available to give feedback and do testing. fixed the alert implementation, which was reporting how many times a particular spoken item occured. it is too verbose, for example when editing code and navigating possible choices by typing and removing item names to quickly hear what is suggested. fixed the suggestion controller, which was inserting an alert reporting accepted item, and also reporting that it was inserted into the document. it made the experience almost unusable for this sentence was read out on every insert. such information is easily reported by screen readers in much better way, for it is also integrated with braille display handling. fixes to the suggestion list pop-up and documentation. need review and further implementation: when suggestion appeard it reported with an alert the type of suggestion regular / snippet, and if the item had details - namely type information, or more expanded documentation. while sighted users are not much interrupted by such hints, for they can observe them in parallel, screen readers, report everything, and on every item change. providing the completion item label only is sufficient. further fixes to the documentation widget appearing with contents. case 1: the details are simple: just a type / a few words hint. it can be reported via the alert, ofr it is very breaif, and does not interrupt the flow. case 2: if the documentation details are longer, and rendered from markdown, or inserted from html documentation, the widget may/should have the aria-role=""dialogue"" added during the element creation. the focus should be placed at the beginning of the dialogue. read more / ** read less / close link buttons should have tabindex properties manually set, starting from 0 as it is in the specification. pressing either escape or keyboard activation of one of close button should return the focus to the last possition in the editor. important: we need to figure out how to split automatic reporting of short strings, and creating a dialogue when activating the documentation with a shortcut: ctrl+space. a temporary work-around is to disable automatic parameter hints, and use them on demand, which in many cases may be prefered by the screen reader users. </desc> <cmt> assigned an empty string to silence too verbose alerts, which try to handle function, much better handled by the screen readers, and therefore they should be removed. </cmt> <cmt> changed verbosity of code completion widget alerts to provide the current completion item without unnecesary snippet/regular hints, or if items have details. </cmt> <cmt> removed reporting the number of times alerted string appeared, which has no use for a blind user, and causes too much verbosity. </cmt> <cmt> changes to how documentation strings are presented. includes previous fixes to alerts. </cmt>",fixing intelisense verbosity with screen readers
3256,<desc> updated readme for how to build for winrt (windows 8.0) to use master branch instead of winrt branch. removed comments with error characters. </desc> <cmt> changed branch from winrt to master </cmt> <cmt> removed comments with error characters </cmt>,updated readme to use master branch. removed comments with error characters
3257,<desc> backport of pr #10566 to 2.2 resolves devrel-1560 - integrate updated diagrams into dev portal select one: select any that apply: </desc> <cmt> update eosio system components raster image :doc </cmt> <cmt> update single node testnet raster image :doc </cmt> <cmt> update multi node testnet raster image :doc </cmt>,integrate updated diagrams into dev portal - 2.2
3258,"<desc> fix #20248. the bug was caused by 2 reasons: serviceworker loader does not have webcontents associated, so it did not get custom protocols registered. registerschemesasprivileged is called after service worker schemes get registered, so the custom scheme could not be recognized as service worker scheme. npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fix service worker not working with custom protocol. </desc> <cmt> fix custom scheme not registered as service worker scheme </cmt> <cmt> serviceworker loaders do not have webcontents associated </cmt> <cmt> add test for service worker </cmt> <iss> cannot use service worker in html document served from custom protocol: the document is in an invalid state. </iss>",make sure service worker scheme is registered with allowserviceworkers
3259,"<desc> test crashes on tf_lite_report_error(error_reporter, ""%s"", line); most likely because the string arg matches two prototypes in this configuration of clang, and its picking the wrong one. ultimately it tries do dereference the literal string leading to a crash. this pr fixes the immediate issue in greedy_memory_planner by adding an explicit typecast: tf_lite_report_error(error_reporter, ""%s"", (const char *)line); it's just a workaround on an instance of this corner case, but a true fix would either involve a less portable code base where we don't support compilers who define va_list as void* or we would need to make more extreme re-factors up at the tf-lite level. </desc> <cmt> * 'master' of github.com:tensorflow/tensorflow: (10459 commits) </cmt> <cmt> go: update generated wrapper functions for tensorflow ops. </cmt> <cmt> improve layout related multi-output fusion heuristic. </cmt> <cmt> go: update generated wrapper functions for tensorflow ops. </cmt> <cmt> compat: update forward compatibility horizon to 2020-03-27 </cmt> <cmt> go: update generated wrapper functions for tensorflow ops. </cmt> <cmt> fixed a wrong reference to a variable. </cmt> <cmt> remove a duplicate check. </cmt> <cmt> add the target spec and cpu target spec </cmt> <cmt> tweak passes: fuse lstms & inline & dce before lower tensor list ops. </cmt> <cmt> adds asymmetric quantized inputs for hybrid ops in future models. </cmt> <cmt> add option to enable tfrt eager context </cmt> <cmt> simply put some utilities of gpu model builder into a separate header file. such utilities have been tested in the model builder unit test itself. </cmt> <cmt> add a benchmark for the index_lookup adapt call. </cmt> <cmt> adds asymmetric quantized inputs for hybrid ops in future models. </cmt> <cmt> add abstractcontextinterface to abstract runtime </cmt> <cmt> add fused rnn/lstm ops as legal ops in lower tensor list pass. </cmt> <cmt> more logical block size selection for convolution. </cmt> <cmt> optimize reduce float mean for reduce on the last dimension case. </cmt> <cmt> arena_planner: create tensor_order vector directly instead of using tensors_set </cmt> <cmt> fall back to shuffledatasetv1 when no seed generator is present. </cmt> <cmt> ... </cmt> <cmt> workaround for a matching ambiguity on some compilers in an overloaded function. </cmt>",fix crash in greedy memory planner test
3260,"<desc> backport of #18930. the changelog.py script was only recognizing fast forward merges  where the pr number was of the form ""(#xxxxx)"", but some people were merging with the ""(gh-xxxxx)""  or (typo) ""gh-#xxxxx"" form. also ignore dependabot-preview as an author. update the 1.20.0 changelog. update the 1.19.0 changelog. update the 1.18.0 changelog. update the 1.17.0 changelog. </desc> <cmt> bug: make changelog recognize gh- as pr number prefix. </cmt> <cmt> the changelog.py script was only recognizing fast forward merges </cmt> <cmt> where the pr number was of the form ""(#xxxxx)"", but some people </cmt> <cmt> were merging using the ""(gh-xxxxx)"" form. fix that. </cmt> <cmt> doc: update 1.20.0-changelog.rst. </cmt> <cmt> doc: update 1.19.0-changelog.rst. </cmt> <cmt> doc: update 1.18.0-changelog.rst. </cmt> <cmt> doc: update 1.17.0-changelog.rst. </cmt>",make changelog recognize gh- as a pr number prefix.
3261,<desc> what's in this pull request? after we merge pull request 3270 we will see a regression because ownerwithaddress will generate mark_dependence instructions. loads of these mark_dependence instructions will not get redundancy eliminated. this patch set teaches cse about mark_dependence instructions and lslocation to stop its underlying object search at mark_dependence instructions until we fix projectionpath to not bail on mark_dependence instructions. resolved bug number: rdar://27138023 </desc> <cmt> cse mark_dependence instructions </cmt> <cmt> this enables things like redundant load elimination and should fix the </cmt> <cmt> regression after changing managedbuffer(pointer) to use unsafeaddresswithowner. </cmt> <cmt> rdar://27138023 </cmt> <cmt> stop getunderlyingobject at mark_dependence instructions for lslocations </cmt> <cmt> this helps remove redundant loads from mark_dependence instructions while our projection path can't handle them. </cmt> <cmt> fix for rdar://27138023 </cmt>,cse and rle based of mark_dependence instructions
3262,"<desc> your submissions are formatted according to the guidelines. your additions are ordered alphabetically. your additions are free software, or if not they have been added to non-free. your additions are not already listed at awesome-sysadmin (it infrastructure management), staticgen.com or staticsitegenerators.net (static site generators). any licenses you have added are in our list of licenses. you have searched the repository for any relevant issues or prs. </desc> <cmt> added sessionrecord visitor recordings software to non-free analytics section </cmt> <cmt> removed sub category as this is the only listed under analytics </cmt>",add sessionrecord(visitor recording software) to non free list
3263,<desc> this change adds some randomness and cleanup step to timeserieslifecycleactionsit#testwaitforsnapshot and testwaitforsnapshotslmexecutedbefore tests in attempt to make them stable. reletes to #50781 </desc> <cmt> fix flaky timeserieslifecycleactionsit#testwaitforsnapshot test </cmt> <cmt> this change adds some randomness and cleanup step to timeserieslifecycleactionsit#testwaitforsnapshot and testwaitforsnapshotslmexecutedbefore tests in attempt to make them stable. </cmt> <cmt> reletes to #50781 </cmt>,increase timeouts in timeserieslifecycleactionsit#testwaitforsnapshot and testwaitforsnapshotslmexecutedbefore test
3264,"<desc> we currently remove a custom component's iframe from the render output when it times out, which means the component has no way of belatedly saying ""hey i've finally mounted"". this was discovered and fixed by </desc> <cmt> fix: re-ender iframe after component timeout </cmt> <cmt> componentinstance.test: fix componentinstace wrapper </cmt> <cmt> use update instead of setprops to re-render </cmt> <cmt> * lekev/develop: </cmt> <cmt> fix: re-ender iframe after component timeout </cmt>",don't unmount iframe after custom component timeout
3265,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add type definition for hsl-to-hex </cmt> <cmt> added newlines to files end </cmt> <cmt> fixed linting issues </cmt>",add type definition for 'hsl-to-hex' module
3266,"<desc> from the tempfile module's documentation it's not very evident how to use the file that the module creates. so i've added an example. that should make it easy to use the module. tempfile ansible version ansible 2.6.3 config file = /home/user/.ansible.cfg configured module search path = [u'/usr/share/ansible'] ansible python module location = /usr/lib/python2.7/dist-packages/ansible executable location = /usr/bin/ansible python version = 2.7.13 (default, sep 26 2018, 18:42:22) [gcc 6.3.0 20170516] </desc> <cmt> show in example how to use file created by tempfile module </cmt> <cmt> from the module's documentation it's not very evident how to use the file that the tempfile module creates. so i've added an example. that should make it easy to use the module. </cmt> <cmt> +label: docsite_pr </cmt> <cmt> fix my own patch </cmt>",improve usage example of tempfile module
3267,"<desc> checklist for the pandas documentation sprint (ignore this if you are doing an unrelated pr): pr title is ""doc: update the  docstring"" the validation script passes: scripts/validate_docstrings.py <your-function-or-method> the pep8 style check passes: git diff upstream/master -u -- ""*.py"" | flake8 --diff the html version looks good: python doc/make.py --single <your-function-or-method> it has been proofread on language by another sprint participant please include the output of the validation script below between the """" ticks: # paste output of ""scripts/validate_docstrings.py <your-function-or-method>"" here # between the """" (remove this comment, but keep the """") errors found: no extended summary found errors in parameters section parameters {'kwargs'} not documented unknown parameters {'**kwargs'} parameter ""**kwargs"" has no type if the validation script still gives errors, but you think there is a good reason to deviate in this case (and there are certainly such cases), please state this explicitly. median is pretty straightforward. maybe an extended summary is not really necessary? kwargs needs further review. </desc> <cmt> added docstring to core.window median </cmt> <cmt> using np.arange instead of np.random.randn </cmt> <cmt> new docstring for pandas.core.window.rolling.median </cmt> <cmt> proofreading led to changes. </cmt>",improve the docstring of pandas.core.window.rolling.median
3268,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. create it with npm run new-package package-name, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. result of krasimir/navigo#80 </desc> <cmt> added typings for navigo </cmt> <cmt> add missing header </cmt>",adds typing for navigo (npm package)
3269,"<desc> the changes to the buttons on jenkins 2.233 (#4658) did not include a proper indicator for the focus states. this pr aims to add better focus states for the buttons while taking the chance to enhance the customizability of the buttons. summary of the changes: change styling for button focus states. each button variant has their own outline color (taken inspiration from bootstrap). add extra css vars to theme the secondary button. add extra css vars to theme button font properties. screenshot: improve button focus states. changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @timja @uhafner @halkeye before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue must exist, be a bug or improvement, and be labeled as lts-candidate to be considered (see query). </desc> <cmt> extend customization for button font and colors </cmt> <cmt> add a bootstrapy focus state for buttons </cmt>",improve button focus states and customizability
3270,"<desc> just picking up the work @vltansky was doing since i have some time right now. i've created the template repo, so it's just a matter of making sure this works and it a tidy user experience. the fundamentals are there, i think. </desc> <cmt> ci: push to antoher repo </cmt> <cmt> ci: fixes to push-to-template workflw </cmt> <cmt> ci: change name </cmt>",push releases to template repo
3271,"<desc> some games call ldg at the top of a basic block and (on other circumstances) they set the base address if ldg conditionally. this pr lets the heuristic the decoded nodes as a whole instead of per basic blocks and also lets it search inside conditional nodes. this may lead to some false positives but allows the heuristic to track cases it previously couldn't. also renames basicblock to nodeblock since there were some cases where it didn't represent a basic block. this fixes xenoblade chronicles 2 boot sequence. </desc> <cmt> shader_ir: pass decoded nodes as a whole instead of per basic blocks </cmt> <cmt> some games call ldg at the top of a basic block, making the tracking </cmt> <cmt> heuristic to fail. this commit lets the heuristic the decoded nodes as a </cmt> <cmt> whole instead of per basic blocks. </cmt> <cmt> this may lead to some false positives but allows it the heuristic to </cmt> <cmt> track cases it previously couldn't. </cmt> <cmt> shader_ir: rename basicblock to nodeblock </cmt> <cmt> it's not always used as a basic block. rename it for consistency. </cmt> <cmt> shader/track: search inside of conditional nodes </cmt> <cmt> some games search conditionally use global memory instructions. this </cmt> <cmt> allows the heuristic to search inside conditional nodes for the source </cmt> <cmt> constant buffer. </cmt>",add a more permissive global memory tracking
3272,"<desc> closes #29265 closes #37433 closes #49544 r? @centril </desc> <cmt> add test for issue-29265 </cmt> <cmt> add test for issue-49544 </cmt> <cmt> add test for issue-37433 </cmt> <iss> ice: assertion failed: destty && ""gep indices invalid!"" compiling reference to static defined in another crate </iss> <iss> ice: unexpected non-scalars in register inputs of `asm!` </iss> <iss> internal compiler error caused if statements involving an iterator adapter function use an undeclared type or module. </iss>",add tests for some issues
3273,"<desc> see #1426 (comment) i agree that my contributions are licensed under the {fmt} license, and agree to future changes to the licensing. </desc> <cmt> improve fmt_always_inline </cmt> <cmt> 1. fmt_always_inline should imply inline; otherwise, there might be </cmt> <cmt> linkage problems </cmt> <cmt> 2. add specialization for msvc (__forceinline) </cmt> <cmt> merge </cmt> <cmt> change msvc version of clz & clzll to match __builtin_clz & _builtin_clzll </cmt> <cmt> merge </cmt>",fix msvc version of clz & clzll
3274,"<desc> this fixes several settings that have broke over the last few weeks: enable/disable mouse peripherals dialog peripheral drivers dialog controller configuration test rumble cec language locale add-on autoupdates enable/disable mouse and controller configuration guaranteed to be working. haven't tested the add-on autoupdates setting. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) </desc> <cmt> fix broken peripheral settings </cmt> <cmt> fix ""enable mouse"" setting </cmt> <cmt> fix broken add-ons autoupdate setting </cmt>",fix several settings that broke after the last few servicemanager refactorings
3275,"<desc> included the code inside spring-rest module deleted the newly created module </desc> <cmt> spring rest logging </cmt> <cmt> log incoming request </cmt> <cmt> updated custom logging implementation </cmt> <cmt> comment incorporation </cmt> <cmt> missing file commit </cmt> <cmt> comment incorporation </cmt> <cmt> missing file commit </cmt> <cmt> web logging code included in exisitng module namely ""spring-rest"" </cmt> <cmt> deleted the new module </cmt>",spring web request logging - pr
3276,"<desc> taskpool.completed_prefetch() is using a list internally to store prefetched completed tasks. however, it is relying on its generator to run to completion in order to clean up this list of tasks. if any error occurs actually fetching one of the returned object ids, then the generator won't complete and the taskpool._fetching list will contain stale object ids for objects that have already been fetched and freed. this change updates taskpool._fetching to use a deque rather than a list so that tasks can be yielded and removed while iteration is happening. this also ensures that the _fetching list is always up to date so that even if an error is raised, object ids that have already been yielded won't be yielded again. i've also added a new test file  /rllib/utils/tests/test_taskpool.py to verify expected behaviour of these changes. running these tests on the master version of 'taskpool' will produce a test failure in taskpooltest.test_completed_prefetch_yieldsremainingifiterationstops() which proves the presence of the original issue in master. closes #7106. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> added tests for taskpool changes </cmt> <cmt> made fix to actors.py to use deque() instead of a list </cmt> <cmt> fixed format.sh issues </cmt> <cmt> fixed ""bad quotes"" complained about by flake8 </cmt> <iss> [rllib] errors originating from environment workers cause training to stall </iss>",fix for #7106 - taskpool.completed_prefetch() no longer returns stale object ids after an error
3277,"<desc> fix for #6482 what did you implement: normalize paths before matching closes #6482 how did you implement it: i wrapped the paths in path.normalize how can we verify it: deploy a golang binary (built & packaged on windows with linux as target) to aws lambda and try to execute it. todos: none is this ready for review?: yes is it a breaking change?: no (this is my first contribution on github ever, feedback is much appreciated) </desc> <cmt> fix path matching issue </cmt> <cmt> fix for </cmt> <cmt> indentation issue fix </cmt> <cmt> revert ""fix path matching issue"" </cmt> <cmt> this reverts commit 9b496683 </cmt> <cmt> fix without diff issues (hopefully) </cmt> <iss> path error when deploying a go runtime from windows </iss>",fix invalid path char in golang packaging on windows
3278,"<desc> the error case of a stream event declaration declaring an unsupported event (type was never checked) was not handled in #2952.  adding it here. what did you implement: add fall-through case to detect and raise error in response to unsupported stream types. how did you implement it: make else into else if (streamtype === 'kinesis') and supply the user with an error case if the condition doesn't resolve to true. how can we verify it: see tests todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources enable ""allow edits from maintainers"" for this pr change ready for review message below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add error case detection </cmt> <cmt> the error case of a stream event declaration declaring an unsupported event (type was never checked) was not handled in </cmt> <cmt> add error case detection </cmt> <cmt> the error case of a stream event declaration declaring an unsupported event (type was never checked) was not handled in #2952.  adding it here. </cmt>",bug fix detect unsupported stream types
3279,"<desc> redux of #46288, which was merged and then reverted because of some failing bwc tests. i don't think this needs a review since it's just one line change, it was just easier to revert the old commit than mute / fix / unmute. i believe the issue in the tests was checking initialposition instead of initialindexerstate.  the original code just looked for state == null, and if we had a state then we started to resolve the details. #46288 checked the position, which theoretically could be null while the indexer state is non-null / has been persisted.  this is possible if the job is started and quickly stopped or shut down.  the indexer won't have returned a composite position yet, but will persist it's current running state. this led to failures in the multi-node tests where the assertion was expected started or indexing but the status was stopped (e.g. the default when initialization saw position was null). this pr is basically the old pr with the tweak to which part of the state we check. original pr description: this makes the allocatedpersistenttask#init() method protected so that implementing classes can perform their initialization logic there, instead of the constructor. rollup's task is adjusted to use this init method. this is a follow-on to #45300. rollup got in trouble for a few reasons (poison task due to bad validation, no error catching on task creation), but some of the trouble would have been avoided if we had used init() instead of the ctor to initialize potentially-exceptional state it also slightly refactors the methods to use a static logger in the allocatedtask instead of passing it in via an argument. this is simpler, logged messages come from the task instead of the service, and is easier for tests </desc> <cmt> move rollup logic from ctor to init() </cmt> <cmt> this makes the allocatedpersistenttask#init() method protected so that </cmt> <cmt> implementing classes can perform their initialization logic there, </cmt> <cmt> instead of the constructor.  rollup's task is adjusted to use this </cmt> <cmt> init method. </cmt> <cmt> it also slightly refactors the methods to: </cmt> <cmt> - provide the persistent task state as part of init() </cmt> <cmt> - use a static logger in the allocatedtask instead of passing it in </cmt> <cmt> via an argument.  this is simpler, logged messages come from the </cmt> <cmt> task instead of the service, and is easier for tests </cmt> <cmt> fix id being used in parenttaskassigningclient() </cmt> <cmt> this looks like it as a bug previously, but was masked because </cmt> <cmt> getpersistenttaskid() returns null until the init() method is called </cmt> <cmt> to set the task id.  since rollup was building this client in the </cmt> <cmt> ctor the string was null/empty and no malformed error was thrown </cmt> <cmt> address review comment </cmt> <cmt> address review comment </cmt> <cmt> check indexer state instead of position </cmt>","refactor allocatedpersistenttask#init(), move rollup logic out of ctor (redux)"
3280,"<desc> description: this pr adds a new configuration option to airvisual: show_on_map: when true (the default in order to preserve backwards compatibility), a marker is show on the map at the corresponding latitude/longitude. when false, the marker is not shown. to accomplish this, the latitude/longitude attribute names change depending on the value of show_on_map: true: latitude and longitude false: lati (lat is swallowed up by hass for some reason) and long related issue (if applicable): fixes #9591 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3492 example entry for configuration.yaml (if applicable): sensor: - platform: airvisual api_key: qepwfp2phop37txtx monitored_conditions: - us - cn show_on_map: false checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> removed lat/long attributes </cmt> <cmt> linting </cmt> <iss> sensor w/ latitude/longitude attributes showing up on the map </iss>",add show_on_map config option to airvisual
3281,"<desc> fixes #6403 . abstract abstractdynamicconfig add clientconfig use clientconfig to remove expired client. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> add abstractdynamicconfig </cmt> <cmt> add clientconfig </cmt> <cmt> use clientconfig to remove expired client. </cmt> <cmt> for checkstyle </cmt> <cmt> update application.properties </cmt> <iss> [enhancement] make the expired time of naming client be configurable in nacos-server </iss>",the expired time of naming client can be configured.
3282,<desc> we're not sure how this performs but re-writing save_aggregate to use double-entrant locking and db transactions seems to be a simple way to fix #5085. this is just there as discussion basis mostly. this adds the rewrite of save_aggregate under a featureflag. when testing this out we may want to use a sampling rate using sentry.options instead to measure perf impact. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <iss> possible race condition on group creation during large bursts of events within a single group. </iss>,fix group creation race using db transactions
3283,"<desc> adds a flag in platformviewscontroller that can be changed through the platformviewschannel which enables/disable changing the render surface when a platformview is added. framework side of #84742 and companion to flutter/engine#27038. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> add flag </cmt> <cmt> test </cmt>",create flag to enable/disable flutterview render surface conversion
3284,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> added types for passport azure ad strategy </cmt> <cmt> new line added at eof in index.d.ts </cmt> <cmt> typescript version fixed </cmt>",adding types for passport-azure-ad strategy
3285,"<desc> added all the necessary files to support the keyboard in the keyboards/sanctified/dystopia directory, added a default and a via keymap. tested that everything works on a prototype board and ran linting to make sure no glaring issues would be pushed my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> working first revision firmware, via compatible </cmt> <cmt> updated default layouts to make it easier </cmt> <cmt> added newlines and end of files </cmt> <cmt> fixed via keymap </cmt>",added support for dystopia keyboard
3286,"<desc> this is the initial pr for multiple worker types. it is not possible to use except through the request_resources() api. in the future, it will be integrated with the ray scheduler to act upon resource demands directly (i.e., based on queue and placement group stats). this pr builds on #9091 (please ignore changes from that) #8649 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> update </cmt> <cmt> debug state </cmt> <cmt> fix </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> fix test </cmt> <cmt> fix </cmt> <cmt> fix </cmt>",initial support for multiple worker types
3287,"<desc> added a default antiaffinity to kafka and zookeeper, since it's unlikely we will want to have them run on the same node, and these can be expanded with more specific affinities & antiaffinities. also fix an error in the zookeeper chart that suggests there exists an antiaffinity (soft/hard) flag, despite this not being used anywhere in the templates. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # fixes #5426 all charts lint correctly and launch to running on my aks 3 node cluster with the (new) default values). also, running: kubectl get pods -n ${k8s_namespace} -o wide | grep ${release_name} shows all pods running on different nodes. @benjigoldberg @lachie83 @kow3ns </desc> <cmt> issue_5426: fix mistake in values.yaml relating to zookeeper storage size for pvc </cmt> <cmt> issue_5426: add antiaffinity to kafka nodes </cmt> <cmt> issue_5426: add antiaffinity to zookeeper in kafka chart </cmt> <cmt> issue_5426: add anti-affinity to zookeeper chart </cmt> <cmt> issue_5426: correct readme.md of zookeeper chart </cmt> <cmt> issue_5426: correct readme.md of kafka chart </cmt> <cmt> issue_5426: correct antiaffinities to use app name </cmt> <iss> kafka & zookeeper stateful sets don't use anti-affinities by default (resulting in pod-node overlap) </iss>",add default antiaffinity example to kafka
3288,"<desc> ref #4482, by @nkt it doesn't let me fix merge conflicts from the website or push the branch up from my terminal so made this. </desc> <cmt> add support for @org shortcats, fixes #4362 </cmt> <cmt> add shortcut test </cmt> <cmt> fixes </cmt>",add support for preset organization shortcuts
3289,"<desc> description: when configuring wwlln via configuration.yaml, the window parameter (explicit or implicit) gets cast as a timedelta because we allow users to input any time_period schema   (for maximum flexibility). unfortunately, timedeltas can't be json-serialized, so they can't be saved in config entries as-is. this would cause an unhandled exception. related issue (if applicable): fixes #25099 pull request with documentation for home-assistant.io (if applicable): n/a example entry for configuration.yaml (if applicable): wwlln: window: 300 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> beta fix: handle window exception in wwlln </cmt> <cmt> fixed test </cmt> <iss> beta: wwlln throws unhandled exception </iss>",fix window exception in wwlln
3290,<desc> document the env variable: mxnet_enforce_determinism added in pr: #12992 </desc> <cmt> add env variable to choose deterministic cudnn alg </cmt> <cmt> set default value to false </cmt> <cmt> fix build failure in windows gpu </cmt> <cmt> revert the previous change </cmt> <cmt> only check determinism in cudnn 7.x release </cmt> <cmt> add cudnn version check </cmt> <cmt> fix lint error </cmt> <cmt> document env variable mxnet_enforce_determinism </cmt>,document the newly added env variable
3291,<desc> changes the config file to use the cross-platform testenvironment::nulldevicepath() instead of /dev/null in: rtds_integration_test.cc cluster_integration_test.cc redis_cluster_integration_test.cc mysql_integration_test.cc postgres_integration_test.cc rtds_integration_test.cc the test list is flaky on windows. i think it is related to #11793 and it will be less flaky when this change gets merged. risk level: n/a testing: n/a docs changes: n/a release notes: n/a </desc> <cmt> change /dev/null to testenvironment::nulldevicepath() </cmt> <cmt> removed whitespace change </cmt>,use testenvironment::nulldevicepath instead of /dev/null/
3292,"<desc> backport of #57963 this pr adds the cluster:admin/ilm/get and cluster:admin/ilm/put privilege to the remote_monitoring_agent built-in role. </desc> <cmt> docs correct audit emit_node_id default value as false (#56995) </cmt> <cmt> since version 7, the xpack.security.audit.logfile.emit_node_id setting defaults </cmt> <cmt> to false, yet the docs say otherwise. this commit fixes that. </cmt> <cmt> add ilm policy put and get for remote_monitoring_agent built-in role (#57963) </cmt> <cmt> without this fix, users who try to use metricbeat for stack monitoring today </cmt> <cmt> see the following error repeatedly in their metricbeat log. due to this error </cmt> <cmt> metricbeat is unwilling to proceed further and, thus, no stack monitoring </cmt> <cmt> data is indexed into the elasticsearch cluster. </cmt>",backport add ilm policy put and get for remote_monitoring_agent built-in role
3293,"<desc> let's propagate the bit when passing sensitive data around. </desc> <cmt> json: when making a copy of a json variant, propagate the sensitive bit </cmt> <cmt> let's make sure we never lose the bit when copying a variant, after all </cmt> <cmt> the data contained is still going to be sensitive after the copy. </cmt> <cmt> home: mark various bus messages we write user records to as sensitive </cmt> <cmt> let's make sure that when we append potentially sensitive data to a bus </cmt> <cmt> message we set the sensitive flag on the message object. </cmt> <cmt> home: make sure whenever we touch the 'secret' part of a user record, we set the the sensitive flag on it </cmt>",be more careful when setting json variant + dbus message sensitive flag
3294,"<desc> related to #62916 makes material daterangepicker state restorable. also made some drive-by additions to the state restoration property tests also added improvements to the existing date picker state restoration tests. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> make daterangepickerdialog public </cmt> <cmt> make date range picker state restorable </cmt> <cmt> restorable property tests </cmt> <cmt> add more tests </cmt> <cmt> more test updates </cmt> <cmt> add date range picker state restoration tests </cmt>","material daterangepicker, adds some general state restoration tests"
3295,"<desc> currently, existing analyses live in the same module as the traits and types used to define new dataflow analyses. this muddles the documentation for the dataflow module. after this pr, dataflow::impls will refer to concrete dataflow analyses, and dataflow to the generic interface. </desc> <cmt> export dataflow impls by name </cmt> <cmt> import dataflow impls via the impls submodule </cmt>",use the impls module to import pre-existing dataflow analyses
3296,<desc> added a width / coordinates test test suite and removed invalid overloads. </desc> <cmt> jquery: jsdoc'd height </cmt> <cmt> jquery: jsdoc'd innerwidth / innerwidth </cmt> <cmt> removed invalid overloads </cmt> <cmt> jquery: jsdoc'd width + added width test suite </cmt>,jsdoc'd width / height / innerwidth / innerheight / coordinates
3297,"<desc> rebase of #10620, retaining credit for @semifocused's work. for justification etc., see #10620. </desc> <cmt> allow tree-ish to be used for galaxy role version </cmt> <cmt> ensure that ansible-galaxy version can be a branch, a tag, or any tree-ish </cmt> <cmt> supported by git including specific commit ids.  for git scm roles, adds an </cmt> <cmt> explicit git checkout of the specified role_version prior to the git archive. </cmt> <cmt> this means that we'll always archive from head of whatever role_version is </cmt> <cmt> checked out. role_version can be a branch, a tag, or any <tree-ish> supported </cmt> <cmt> by git including specific commit ids.  these changes also ensure </cmt> <cmt> ansible-galaxy works for scm clones when specified version differs from </cmt> <cmt> repository default branch. </cmt> <cmt> add tests for #10620 </cmt>",allow tree-ish versions for ansible-galaxy
3298,"<desc> i found that the link in the current solution links to a reversestring function.  so i copied the code that was in the solution (not my code) and created a new repl.it with that correct code and inserted the link. i also added an intermediate solution. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> correct ""run code link"" </cmt> <cmt> currently when the user hits ""run code"" they are brought to a repl that shows a function for reversestring.  i just copied the code from the explanation into a new repl and linked that so when users click ""run code"" they are taken to the correct code. </cmt> <cmt> adds an intermediate solution </cmt> <cmt> since submitting my last pr on this page i have verified that my intermediate solution works, it eliminates the need for the for loop. </cmt>","adds intermediate solution and corrects ""run code"" link"
3299,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> make argument to getformatter optional </cmt> <cmt> see here: </cmt> <cmt> update tests </cmt>",make argument to eslint.cliengine.getformatter() optional
3300,"<desc> the integer id itself is not enough to correctly identify a symbol. we need to scope that somehow in order to prevent clashes. this can be observed in a multiple modules project where butterknife is used in modules that depend on other modules that also use butterknife. since ids can repeat across modules, we need to scope them according to the package name of the current element being evaluated. this pr fixes #779 </desc> <cmt> adds failing test for #779 </cmt> <cmt> fixes #779 by scoping symbols by package </cmt> <iss> butterknife generates viewbinding class with wrong resource id </iss>",scope symbol ids per element package name
3301,"<desc> correctly handle the <thead> and <tfooter> html tags within the <table> tag. these tags are treated the same as <tbody> in most cases. this also adds a html test page including a <thead> to verify the change. </desc> <cmt> libweb: properly handle thead and tfooter html tags </cmt> <cmt> as the spec for the table fixup algorythm says: </cmt> <cmt> > treat table-row-groups in this spec also encompass the specialized </cmt> <cmt> > table-header-groups and table-footer-groups. </cmt> <cmt> libweb: correctly calculate height of tablerowgroupbox </cmt> <cmt> as well as correctly calculating the height of tablerowbox, this change </cmt> <cmt> calculates the heights of tablerowgroupboxs also. </cmt> <cmt> as before, this does not correctly take into consideration the 'height' </cmt> <cmt> attribute. </cmt> <cmt> now the horizontal layout is approximately correct for the </cmt> <cmt> tablerowgroupboxs we can now see that the layout_row method will need </cmt> <cmt> updating to correctly calculate cell width across all rows, not just the </cmt> <cmt> current tablerowgroupbox. </cmt> <cmt> base: add html test page for cursor & table </cmt> <cmt> this page is useful for testing the css 'cursor' property, as well as </cmt> <cmt> html tables </cmt>",support thead & tfooter html table tags
3302,"<desc> protobuf was showing stackoverflow hits in the code base, primarily code written to calculate long division. this code was copied from a stackoverflow post, which means it would be licensed under cc by-sa 3.0. due to this license, ibm legal did not want to include this oss in our products and advised us to re-write this particular piece of code to avoid the license restriction. we have re-written the code for our own distribution, and are willing to merge it into the main code base for others who want to avoid the stackoverflow license issues to benefit as well. </desc> <cmt> rewrite int128 long divison to avoid stackoverflow hit </cmt> <cmt> protobuf was showing stackoverflow hits in the code base, primarily code written to calculate long division. this code was copied from a stackoverflow post, which means it would be licensed under cc by-sa 3.0. due to this license, ibm legal did not want to include this oss in our products and advised us to re-write this particular piece of code to avoid the license restriction. we have re-written the code for our own distribution, and are willing to merge it into the main code base for others who want to avoid the stackoverflow license issues to benefit as well. </cmt> <cmt> remove stackoveflow reference comment </cmt> <cmt> remove stackoverflow comment after re-writing long divison </cmt>",re-write int128 long division to avoid license impact from stackoverflow references
3303,"<desc> updates renovate.json5 to exclude breaking minor updates from minor update prs. should unblock #27092, #27134, #28358, #29380 once their manual override boxes are checked in #16840. </desc> <cmt> fix(renovate): add webpack-virtual-modules to major list </cmt> <cmt> fix(renovate): add mdx v2 to major list </cmt>",add breaking minor updates to major updates list
3304,"<desc> for performance and discover we'd like to trial out a new re-startable tour. if successful this would replace the guide anchor onboarding used in issues and the slide show tour used in releases. the component exposes two callbacks: onadvance lets a page know that the tour has advanced and gives it an opportunity to track metrics as required. the index and duration are included so that we know how long it takes users to get through a tour and where they are spending their time. onclosemodal lets the page know that the tour has concluded and that the modal has been closed. if people are generally happy with the api i'll add tests. demo related figma doc </desc> <cmt> fix menu position. </cmt> <cmt> feat(onboarding) add component to show new feature tours </cmt> <cmt> a new kind of feature tour is being trialed for performance, and if </cmt> <cmt> successful will replace the assistant guides we use on issues and the </cmt> <cmt> tour that releases uses. </cmt> <cmt> first pass at implementing the tour modal. </cmt>",feat(onboarding) add component for new tour designs
3305,"<desc> i've recently been struggling to keep a long-running feature branch (#49268) up to date with master due to some frequently-modified areas of code. in order to avoid having to point my branch at a moving target, i'm breaking out some changes into a separate pr. hopefully, this will simplify the diff for the feature branch and help us avoid merge-related issues. i'll summarize the specific changes once i've finished cleaning up here. </desc> <cmt> bring over changes from keystore branch </cmt> <cmt> aim to use consistent patterns in qa/os code </cmt> <cmt> i developed some patterns on a feature branch. in the meantime, we've </cmt> <cmt> written code to do similar things on the master branch. here, i'm trying </cmt> <cmt> to merge usages for simplicity. </cmt>",refactor utility code in qa:os: tests
3306,<desc> backports #24744 </desc> <cmt> add c# distribtest coverage for .net5 single file publish </cmt> <cmt> fix native extension loading in .net5 single-file deployments </cmt> <cmt> load native extension on .net core via differentiated dllimports </cmt> <cmt> simplify .net framework loading logic </cmt>,fix c# native library loading in .net 5 single-file apps (backport to v1.34.x)
3307,<desc> thanks so much again for the opportunity to do a write up and thanks for developing a very cool piece of tech. looking forward to building more sites with gatsby and contributing back where i can </desc> <cmt> pull latest gatsby to add blog post </cmt> <cmt> add site generating with the great gatsbyjs by david james cross post </cmt>,add 'site generating with the great gatsbyjs' blog post
3308,"<desc> just deleting dead code. definiteinitialization has the property that memoryinst is always a markuninitializedinst. so anything that will never run if memoryinst is a markuninitializedinst is trivially dead. </desc> <cmt> [definite-init] make definite_init_markuninitialized_var.sil a pure di test by moving raw sil lowering tests => raw_sil_inst_lowering.sil. </cmt> <cmt> rdar://i0332620 </cmt> <cmt> [definite-init] remove dead code. </cmt> <cmt> collectretaincountinfo bails early if our memory instruction is a </cmt> <cmt> mark_uninitialized... but our instruction is always a mark_uninitialized... so </cmt> <cmt> this code is dead. </cmt> <cmt> the origin of this code is from the flattening of the control flow in di that </cmt> <cmt> was necessary to be done to ""extract"" predictable mem opts from it. </cmt> <cmt> rdar://40332620 </cmt> <cmt> [definite-init] di only analyzes mark_uninitialized... so eliminate more dead code and conditional checks. </cmt> <cmt> rdar://40332620 </cmt>",delete dead code from di
3309,"<desc> based on pr #667 </desc> <cmt> fix trivial bug in field orderings. </cmt> <cmt> (shows the benefit of unit testing even code ""too simple to fail""...) </cmt> <cmt> fix json formatting to always emit fields in field order, including oneofs </cmt>",fix c# json field ordering
3310,"<desc> what did you implement: closes #3784 how did you implement it: this change adds a new option to help command, --verbose. sls help --verbose extracts the loaded commands and arranges them according to their plugin name and displays all the commands grouped under their plugin names. commit messages should be helpful enough to understand the incremental changes. how can we verify it: todos: write tests fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add generatecommandsbypluginhelp() </cmt> <cmt> format commands plugins help output with indents </cmt> <cmt> extract, sort and display plugin commands & test </cmt>",display plugin commands alphabetically under help
3311,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> [amap-js-api] update to v1.4.14 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add definition for non npm package: amap-js-api-district-search </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add type definition for non npm-package amap-js-api-line-search </cmt>",add type definition for non npm package amap-js-api-line-search
3312,<desc> setting line-height: 1 on .input-group-addon seems to fix the misalignment on ff and doesn't seem to affect other browsers </desc> <cmt> fix issue #8175 </cmt> <cmt> fix issue #8175 - remove lh for input-lg|sm </cmt>,fix issue #8175 - .input-group-addon broken in firefox
3313,<desc> added optional re-centering of geometry in colladaloader as well as optional progress callback. *this time a clean branch with only the two commits :) </desc> <cmt> added option to colladaloader to recenter all geometry so that they are centered around the local origin of their containing mesh. </cmt> <cmt> added progress callback to colladaloader. </cmt>,added re-centering and progress to colladaloader
3314,"<desc> the rstcheck sanity test is now limited to ansible-core and is no longer applied to collections. the results of rstcheck are dependent on the presence (or lack thereof) of sphinx, as well as the versions of rstcheck, sphinx and dependencies being used. since sphinx and its dependencies are not defined as test requirements this can result in different test behavior between environments. support for rstcheck and other documentation related tests may be added for collections in the future, once the necessary requirements have been defined. ansible-test </desc> <cmt> move rstcheck sanity test out of ansible-test. </cmt> <cmt> inline ignored substitutions. </cmt> <cmt> add missing sphinx requirement for rstcheck. </cmt> <cmt> add sanity config for rstcheck test. </cmt> <cmt> rewrite sanity test as code-smell test. </cmt>",limit rstcheck sanity test to ansible-core.
3315,"<desc> fixes #1715 (and others like it). this pr corrects our handling of union types for certain expression operators. specifically, where operators support operands of certain kinds of types we now also support unions of those kinds of types. for example, in an index access a[x] we now allow x to be a union type such as string | number or enum1 | enum2, and in an arithmetic operation such as x * y we allow the operands to be unions composed of enum types. </desc> <cmt> allow union types in indexing expressions. </cmt> <cmt> consistent handling of string-like and number-like values in expressions </cmt> <cmt> modifying and adding tests </cmt> <iss> union types are not allowed in indexers </iss>",correct handling of union types in expressions
3316,"<desc> master pr: #36161 modified messages in the check of default options for the adam optimizer. </desc> <cmt> corrected messages for check of default options </cmt> <cmt> added 0<= betas < 1 range check, match python messages for check of betas </cmt>",c++ adam optimizer - corrected messages for check of default options
3317,<desc> added function overrides for constructing layergroup to allow options object to be passed through and for layers to be optional. updated markerclustergroupoptions to extend layeroptions to ensure layeroptions can be set for leaflet.markercluster. provide a url to documentation or source code which provides context for the suggested changes; </desc> <cmt> * added function overrides for constructing layergroup to allow options object to be passed through and for layers to be optional. </cmt> <cmt> * updated markerclustergroupoptions to extend layeroptions to ensure layeroptions can be set for leaflet.markercluster. </cmt> <cmt> fixed dtslint errors cause by using tslint:disable </cmt>,fixed leaflet.layergroup constructor and leaflet.markercluster options.
3318,<desc> minor exception handling changes for kpi-470 illegalstateexception when provided testrecord does not have a timestamp and no timestamp overwrite was provided via time parameter. illegalstateexception when null keys with readkeyvaluestomap method </desc> <cmt> add illegalstateexception if no time provided and record timestamp null </cmt> <cmt> test for missing time </cmt> <cmt> illegalstateexception when null key with readkeyvaluestomap </cmt>,modified exception handling for kip-470
3319,<desc> update readme to reflect changes in firebase console and fix any outdated instructions. remove references to obsolete database url for firebase client config add sessions folder to prevent errors on first run </desc> <cmt> add sessions folder to prevent errors on first run </cmt> <cmt> update readme steps to reflect current firebase ui </cmt> <cmt> use default directory for sessions-file-store </cmt>,update example with firebase auth
3320,<desc> this brings in the code from eeb6967 that was lost in a feature branch merge. it shows the same image/text options for charts on the report modal from charts that we show on the alerts/reports modals. this also fixes a small bug where the dashboard needs to refetch reports on load. create a chart with one of these options and ensure that the proper format was sent. also the text options should only apply to tables. includes db migration (follow approval process in sip-59) </desc> <cmt> refetch reports on props update </cmt> <cmt> add chart types to reports </cmt>,add chart image info to reports from charts
3321,"<desc> hello i'm a noob! i don't see any ""porn"" related lists on your ""contact one of our hosts sources"". but even if there was, i wouldn't know how to contact them! also, i noticed that when you modify a large file, the raw.githubusercontent.com website does not show the new changes! it just loads the old file on the browser, but if you download the file, it's fine and the changes are there, does this happen to everybody else? i don't think it's my browser cache because i tried a different browser and also deleted my cache! </desc> <cmt> added 1 website </cmt> <cmt> added 1 website </cmt>",added 1 website to the list
3322,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). basically, this pull request solves this request #27250 </desc> <cmt> fix the broken fieldsarray type inheritance </cmt> <cmt> fix the broken test and improve upon the implementation </cmt>",redux-form - fix the broken type inheritance
3323,<desc> summary retry for #11672 having some trouble with ctc_decode_beam_search: i've explored the computed values by tensorflow gen_ctc_ops.ctc_beam_search_decoder and the returned log_probabilities are different between 1.10 and 1.11. investigating on this atm. related issues pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> rebase gabrieldem branch on master </cmt> <cmt> bump to 1.12 </cmt>,bump tf version to 1.12
3324,"<desc> refactor the scene collection importer to use getunusedscenecollectionfile to maintain consistency with other scene collection filenames and also to handle all special characters. to do this, i moved getunusedscenecollectionfile to ui/obs-app.cpp where getclosestunusedfilename and getfilesafename are also located.  i am not sure if this is the best solution.  perhaps we should create something more agnostic in obs-app like getunusedfileatpath and leave getunusedscenecollectionfile in-place, but have it call the new function. fixes #2566. i compiled on windows 10 64-bit 2004 (build 19041.685).  to test: open obs. create a scene collection with a name that has special characters. make a backup of the scene collection json file. delete the scene collection in obs. import the scene collection from the file backup created in step 3. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> ui: make getunusedscenecollectionfile usable elsewhere </cmt> <cmt> ui: refactor importer to use getunusedscenecollectionfile </cmt> <iss> [bug]: scene collections with special characters (""/"", ""|"") in their name cannot be imported </iss>",refactor importer to escape special characters in scene collection names
3325,<desc> for #5666 . add cluster state page & display node topology in ui </desc> <cmt> add load all instance states api for ui </cmt> <cmt> remove redundant code </cmt> <cmt> optimize code about load state failed </cmt> <cmt> add cluster state page </cmt> <cmt> support multiple proxy </cmt> <cmt> optimize code </cmt>,add cluster state page #control-panel-cluster
3326,<desc> progress toward getting dotnet cli generated nugets on par with nugets generated from .nuspec files. -- share version.cs file with assembly properties across all projects -- sign assemblies for all projects -- generate xml docs for all projects also update coreclr docker image to newly released dotnet sdk preview2 (and some associated fixes). </desc> <cmt> switch coreclr to preview2 </cmt> <cmt> fix coreclr linux build </cmt> <cmt> workaround not necessary in preview2 </cmt> <cmt> share version.cs among all project.json projects </cmt> <cmt> modify templates to sign c# coreclr projects and generate xmldoc </cmt> <cmt> regenerate files </cmt>,improvements to nugets generated by dotnet cli.
3327,<desc> this pr add the question answering task in the tensorflow trainer. for the moment the evaluation is not possible due to the complexity of the squad metrics but the training is working. </desc> <cmt> add qa trainer example for tf </cmt> <cmt> make data_dir optional </cmt> <cmt> fix parameter logic </cmt> <cmt> fix feature convert </cmt> <cmt> update the readmes to add the question-answering task </cmt>,question answering for tf trainer
3328,"<desc> with this pr we permit classes and interfaces to derive from object types and intersections of object types. furthermore, in intersections of object types we now instantiate the this type using the intersection itself. collectively these changes enable several interesting ""mixin"" patterns. in the following, a type is said to be object-like if it is a named type that denotes an object type or an intersection of object types. object-like types include named object literal types, function types, constructor types, array types, tuple types, mapped types, and intersections of any of those. interfaces and classes may now extend and implement types as follows: an interface is permitted to extend any object-like type. a class is permitted to extend an expression of a constructor type with one or more construct signatures that return an object-like type. a class can implements any object-like type. some examples: type t1 = { a: number }; type t2 = t1 & { b: string }; type t3 = () => void; type t4 = [string, number]; interface i1 extends t1 { x: string }  // extend object literal interface i2 extends t2 { x: string }  // extend intersection interface i3 extends t3 { x: string }  // extend function type interface i4 extends t4 { x: string }  // extend tuple type an interface or class cannot extend a naked type parameter because it is not possible to consistently verify there are no member name conflicts in instantiations of the type. however, an interface or class can now extend an instantiation of a generic type alias, and such a type alias can intersect naked type parameters. for example: type named<t> = t & { name: string }; interface n1 extends named<t1> { x: string } // { a: number, name: string, x: string } interface n2 extends named<t2> { x: string } // { a: number, b: string, name: string, x: string } interface p1 extends partial<t1> { x: string } // { a?: number | undefined, x: string } the this type of an intersection is now the intersection itself: interface thing1 { a: number; self(): this; } interface thing2 { b: number; me(): this; } function f1(t: thing1 & thing2) { t = t.self();  // thing1 & thing2 t = t.me().self().me();  // thing1 & thing2 } all of the above can be combined in lightweight mixin patterns like the following: interface component { extend<t>(props: t): this & t; } interface label extends component { title: string; } function test(label: label) { const extended = label.extend({ id: 67 }).extend({ tag: ""hello"" }); extended.id;  // ok extended.tag;  // ok } also, mixin classes can be modeled, provided the base classes have constructors with a uniform shape: type constructor<t> = new () => t; function identifiable<t>(superclass: constructor<t>) { class class extends (superclass as constructor<{}>) { id: string; getid() { return this.id; } } return class as constructor<t & class>; } class component { name: string; } const identifiablecomponent = identifiable(component); class box extends identifiablecomponent { width: number; height: number; } const box = new box(); box.name; box.id; box.width; box.height; we're still contemplating type system extensions that would allow the last example to be written without type assertions and in a manner that would work for arbitrary constructor types. for example, see #4890. edit: mixin classes are now implemented by #13743. fixes #10591. fixes #12986. </desc> <cmt> allow object intersection types as class/interface base types </cmt> <cmt> improve efficiency of union/intersection resolved property caching </cmt> <cmt> allow object intersection types in class implements clauses </cmt> <cmt> accept new baselines </cmt> <cmt> intersections as their own 'this' type </cmt> <cmt> allow base constructor types to be intersections </cmt>",allow deriving from object and intersection types
3329,"<desc> fixed flake8 issue in groupby.rst, see issue #24178 for more info. the following flake8 'errors' have been fixed: doc/source/groupby.rst:72:18: f821 undefined name 'obj' doc/source/groupby.rst:72:30: f821 undefined name 'key' doc/source/groupby.rst:73:18: f821 undefined name 'obj' doc/source/groupby.rst:73:30: f821 undefined name 'key' doc/source/groupby.rst:74:18: f821 undefined name 'obj' doc/source/groupby.rst:74:31: f821 undefined name 'key1' doc/source/groupby.rst:74:37: f821 undefined name 'key2' doc/source/groupby.rst:1306:42: f821 undefined name 'report_func' doc/source/groupby.rst:242:15: e225 missing whitespace around operator doc/source/groupby.rst:242:15: e999 syntaxerror: invalid syntax doc/source/groupby.rst:242:19: e225 missing whitespace around operator </desc> <cmt> doc: remove doc/source/groupby.rst from flake8-rst exclude section in setup.cfg (#24178) </cmt> <cmt> doc: fix e225 and e999 caused by .<tab> with # noqa: e225, e999 </cmt> <cmt> doc: fix doc/source/groupby.rst:1306:42: f821 undefined name 'report_func' (#24178) </cmt> <cmt> doc: fix the following 'errors' (#24178): </cmt> <cmt> doc/source/groupby.rst:72:18: f821 undefined name 'obj' </cmt> <cmt> doc/source/groupby.rst:72:30: f821 undefined name 'key' </cmt> <cmt> doc/source/groupby.rst:73:18: f821 undefined name 'obj' </cmt> <cmt> doc/source/groupby.rst:73:30: f821 undefined name 'key' </cmt> <cmt> doc/source/groupby.rst:74:18: f821 undefined name 'obj' </cmt> <cmt> doc/source/groupby.rst:74:31: f821 undefined name 'key1' </cmt> <cmt> doc/source/groupby.rst:74:37: f821 undefined name 'key2' </cmt> <cmt> bring branch up to date merge master </cmt> <cmt> doc: remove groupby from flake8-rst section exclusions (redo after merge with master) </cmt>",fix flake8 issue in groupby.rst
3330,<desc> this approach to displaying graphql compilation and runtime errors in the browser console utilizes the websocket connecting node running gatsby package responsible for executing graphql queries and the cache loaded and used on the browser side (thanks @pieh for helping in this). #5234 one more useful step would be to extract the error query and add a link to graphiql with the error query. </desc> <cmt> report graphql errors on browser </cmt> <cmt> print graphql query error in browser console </cmt>,show graphql compile errors in browser overlay
3331,"<desc> three small steps. </desc> <cmt> move more files into stack reconciler </cmt> <cmt> callbackqueue and transaction are specific to the stack </cmt> <cmt> reconciler. </cmt> <cmt> refactor respondereventplugin to not rely on _rootnodeid </cmt> <cmt> instead of relying on ids, we now use instances for everything so </cmt> <cmt> this should be reflected by the test. </cmt> <cmt> this still has a _rootnodeid to store the listeners which i will </cmt> <cmt> remove next. </cmt> <cmt> create reactgenericbatching injection wrapper around batchedupdates </cmt> <cmt> this moves calls that don't know if they're in a fiber or stack </cmt> <cmt> context to use reactgenericbatching.batchedupdates. </cmt> <cmt> the corresponding one will be injected from either the stack </cmt> <cmt> reconciler and/or the fiber reconciler if they're loaded at the </cmt> <cmt> same time. </cmt> <cmt> this lets them share the event system when they're both used </cmt> <cmt> at once. </cmt> <cmt> this can also be useful for libraries that call </cmt> <cmt> unstable_batchedupdates today but don't know which renderer to </cmt> <cmt> use. </cmt>",some early refactoring to be able to reuse the event system
3332,"<desc> motivation: when graphing functions that have sharp corners, the smoothing causes ringing near the corners which is undesired. the goal of the change is to allow turning smoothing off and on as desired. a few other people have run into this issue as well. my post u/mc_pm's post the fix was suggested by reddit user u/fieabus (thank you so much!) and i tested it locally. example that was previously broken: from manimlib.imports import * import math class graphing(graphscene): config = { ""x_min"": 0, ""x_max"": 3, ""x_tick_frequency"": 1, ""x_axis_width"": 5, ""y_min"": 0, ""y_max"": 2, ""y_tick_frequency"": 1, ""y_axis_height"": 5, ""graph_origin"": origin, ""function_color"": white, ""axes_color"": blue } def construct(self): self.setup_axes(animate=true) func_graph=self.get_graph(self.f1, self.function_color) self.play(showcreation(func_graph)) def f1(self, t): if(t < 1): return 0 elif(t < 1.1): return 10*(t - 1) elif(t < 1.9): return 1 elif(t < 2): return -10*(t-2) else: return 0 fix: added the new smoothing parameter to parametriccurve. when true, make_smooth is called in the generate_points function. when false, make_smooth is not called. the default is true so the functionality remains identical to how it is now, unless configured otherwise. now in the previous code the get_graph function can be changed to: func_graph=self.get_graph(self.f1, self.function_color, smoothing=false) this gives the result with smoothing disabled as desired. additional tests: confirm it works with smoothing explicitly set to true: func_graph=self.get_graph(self.f1, self.function_color, smoothing=true) confirm the default is smoothing to match previous functionality: func_graph=self.get_graph(self.f1, self.function_color) </desc> <cmt> add config parameter to allow disabling smoothing </cmt>",add config parameter to allow disabling smoothing on parametriccurve
3333,"<desc> rfc for issue #249 . please assist me in the rfc, i am not a developer and there are parts i cannot write due to lack of knowledge + understanding. thanks a lot for the templates @mmahmoudian  and @borgmanjeremy . </desc> <cmt> create rfc to add opacity slider for color-picker </cmt> <cmt> please see issue #249 </cmt> <cmt> update 0000-add-opacity-slider.md </cmt> <cmt> update 0000-add-opacity-slider.md </cmt>",add an opacity slider to the tool settings
3334,"<desc> submitting as a separate pr at the request of @defionscode; this is a trivial rebase of pr #9130 with the controversial inventory changes removed. see comments on that pr for more details. </desc> <cmt> allow ec2 inventory to use a boto profile </cmt> <cmt> this allows the ec2 inventory plugin to be used with </cmt> <cmt> the same configuration against different ec2 accounts </cmt> <cmt> profile can be passed using --profile variable or using </cmt> <cmt> ec2_profile environment variable e.g. </cmt> <cmt>  </cmt> <cmt> ec2_profile=prod ansible-playbook -i ec2.py playbook.yml </cmt> <cmt>  </cmt> <cmt> added documentation on profiles to ec2 dynamic inventory doc </cmt> <cmt> only tries to use profiles if --profile argument is given </cmt> <cmt> or ec2_profile is set to maintain compatibility will boto < 2.24. </cmt> <cmt> works around a minor bug in boto where if you try and use </cmt> <cmt> a security token with a profile it fails (boto/boto#2100) </cmt> <cmt> add an ec2 inventory option ""boto_profile"" that allows </cmt> <cmt> the use of boto profiles for separating credentials as </cmt> <cmt> specified in </cmt> <cmt>  </cmt> <cmt> combine ansible/ansible#5987 and ansible/ansible#8582 </cmt> <cmt> fixes merge conflicts and standardizes option naming </cmt> <cmt> fix security_token typo in ec2 inventory </cmt> <cmt> update ec2 inventory documentation to refer to aws_profile </cmt> <cmt> move connection handling failure to connect_to_aws </cmt> <cmt> make use of better error handling mechanism </cmt>",ec2 inventory boto profile support
3335,"<desc> pr for issue #26530 and #26532 added usage examples for tf.math.argmin and tf.math.argmax functions with this patch. updated docstring in tensorflow/python/ops/math_ops.py </desc> <cmt> added usage example for tf.math.argmax() in api_def_argmax.pbtxt </cmt> <cmt> updated usage example for tf.math.argmax(), addded doc in math_ops.cc </cmt> <cmt> added usage example for tf.math.argmin </cmt> <cmt> updated docstring for tf.argmax and tf.argmin </cmt>",updated documentation for tf.math.argmin and tf.math.argmax operations
3336,"<desc> add support to store data with zstd instead of zlib in nodestore. this extends the compression parameter to 1) accept a ""zstd"" string value 2) accept a callable that can inspect the event and decide based on project_id which compression should be used. we have observed slight compression ratio improvements using zstd on production data for specific large customers, and significant performance gains during compression. in the future this may help even more should we decide to store reprocessing payload compressed together with the original event, as zstd performs much better than zlib in compressing two concatenated versions of the same event (roughly the same size as zlib payload of single event). for details see  also refactor bigtable testsuite to run all tests against both real bigtable and a mocked stubbed client (going all-in on pytest because of parametrization) the added zstandard dependency is already part of getsentry master. </desc> <cmt> create mock bigtable api for bigtable tests </cmt> <cmt> add support for zstd to bigtable nodestorage </cmt>",feat(nodestore-bigtable): add support for zstd
3337,"<desc> at the moment, when external service is set to clusterip, we return ${internal-service-name} + ""."" + namespace as the address of the endpoint, which could be problematic since we don't create the internal service in zookeeper based ha setups.  according to flink-16602, we always use external service for rest communication so that this pr returns ${external-service-name} + ""."" + namespace as endpoint's address instead. fix incorrect returned address of endpoint for the external service of clusterip type port kubernetesutils.getinternalservicename to internalservicedecorator port kubernetesutils.getexternalservicename to externalservicedecorator fix code style this change hardens fabric8flinkkubeclienttest#testclusteripservice to add a test branch for endpoint's address. dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (no) the serializers: (no) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (no) if yes, how is the feature documented? (not applicable) </desc> <cmt> [flink-17230][k8s] fix incorrect returned address of endpoint for the external service of clusterip type </cmt> <cmt> [hotfix][k8s] fix code style </cmt> <cmt> [hotfix][k8s] port kubernetesutils.getinternalservicename to internalservicedecorator </cmt> <cmt> [hotfix][k8s] port kubernetesutils.getexternalservicename to externalservicedecorator </cmt>",fix incorrect returned address of endpoint for external service of clusterip type
3338,<desc> use bazel instead of automake to build protoc to generate test protos. more robust change detection for the extension makefile (we now compute a hash of the php binary rather than relying on its path as a unique identifier. added kokoro config and build scripts for testing several different versions of php. </desc> <cmt> wip. </cmt> <cmt> added build config for all of the tests. </cmt>,some more updates to php testing infrastructure
3339,"<desc> swift needed its own global context because llvm removed the concept of the ""global llvmcontext"" upstream a while ago. this context infected a bunch of the compiler infrastructure. this patch chases all of those global context dependencies back down to a single file: the builtins. notably, the integrated repl now allocates its own llvmcontext to start instead of using the global context. llvm-opt now parses ir into a separate context. the silremarkstreamer now allocates and owns its own scratch context. i also noticed a potential use-after-move in the silremarksstreamer construction code that i've fixed by just refactoring the construction interface. the builtins are still using a global context out of convenience. we could probably just refactor builtin lookup to be a service installed in the astcontext and give it its own context for scratch space. for now, i'll just preserve the managed static that was here in case there is a better option i'm overlooking. </desc> <cmt> [nfc] internalize the repl's llvmcontext </cmt> <cmt> there's no reason the repl needs to generate its starting module in the </cmt> <cmt> global llvmcontext. give it a local context. </cmt> <cmt> [nfc] internalize the llvmcontext for llvm ir code generation </cmt> <cmt> [nfc] internalize the llvmcontext for llvmopt </cmt> <cmt> [nfc] refactor the construction of silremarksstreamer </cmt> <cmt> the remarks streamer's installation seemed a bit overly complex, so simplify it in a few places: </cmt> <cmt> * refactor sil-opt to install the remarks options into the siloptions for the silmodule </cmt> <cmt> this reduces the parameter bloat in createsilremarkstreamer. all of this data is freely derivable from the silmodule alone. </cmt> <cmt> * refactor createsilremarkstreamer into silremarkstreamer::create </cmt> <cmt> with the new reduction in parameters, we can hide the internal constructor and introduce a smart constructor that vends a unique pointer to clients. </cmt> <cmt> * setsilremarkstreamer -> installsilremarkstreamer </cmt> <cmt> since the information to create a streamer is now entirely derivable from a module, remove a layer of abstraction and have the module directly construct a streamer for itself. </cmt> <cmt> * give silremarkstreamer its own llvmcontext </cmt> <cmt> the remarks streamer just needs scratch space. it's not actually ""installed"" in a given context. there no reason to use swift's global context here. </cmt> <cmt> * give the silremarkstreamer ownership of the underlying file stream </cmt> <cmt> the silmodule didn't actually use this member, and it seems like somebody needs to own it, so just give it to the remarks streamer directly. </cmt> <cmt> [nfc] drastically reduce the scope of the global context </cmt> <cmt> delete all of the formalism and infrastructure around maintaining our own copy of the global context. the final frontier is the builtins, which need to lookup intrinsics in a given scratch context and convert them into the appropriate swift annotations and types. as these utilities have wormed their way through the compiler, i have decided to leave this alone for now. </cmt>","drastically reduce the scope of the ""global llvmcontext"""
3340,<desc> fixes #63210. cc #60406 r? @petrochenkov </desc> <cmt> cleanup 'print_generic_params'. </cmt> <cmt> print outer attributes on formal params. </cmt> <cmt> test for printing attrs on formal params. </cmt> <iss> formal parameter attributes won't be passed into proc-macro </iss>,pretty print attributes in print_arg
3341,"<desc> when the -v or --verbose argument is passed the execute command will print the output it receives from sub processes. i'm not sure if this is the way to do this in python, i don't use python that much. </desc> <cmt> added a verbose mode to the bootstrap script </cmt> <cmt> fixed inconsistent newlines </cmt>",added verbose mode to the bootstrap script. closes #574
3342,<desc> fixes #6196 . remove attribute overwrite of orchestration:data-source revise examples of spring namespace with orchestration </desc> <cmt> remove attribute overwrite of <orchestration:data-source> </cmt> <cmt> revise examples of spring namespace with orchestration </cmt> <iss> the attribute overwrite  of <orchestration:datasource> tag is never parsed </iss>,remove useless overwrite attribute of spring namespace with orchestration
3343,"<desc> this pr fixed the second failed test case in #2737. the following line caused the failure, drop_idx = active.pop(idx) type of idx is numpy.ndarray, and pop operation raised deprecationwarning: converting an array with ndim > 0 to an index will result in an error in the future to fix it, just using active.pop(idx[0]). this pr also changed floating point division to floor division. floating point division caused numpy warning, deprecationwarning: using a non-integer number instead of an integer will result in an error in the future in python 3 </desc> <cmt> fix converting an array with ndim > 0 to an index deprecationwarning </cmt> <cmt> using floor division in python3 </cmt>",fix deprecation warning in python 3
3344,"<desc> today, silgenfunction::emitrvalue assumes the caller will create any cleanup scopes that are needed to cleanup side-effects relating to the rvalue evaluation.  the api also provides the ability for the caller to specify that a +0 rvalues is an ""ok"" result. the api then tries to produce a +0 rvalue and returns a +1 rvalue otherwise. these two properties create conflicting requirements on the caller since the caller does not know whether or not it should create a scope (if a +1 rvalue will be returned) or not (if a +0 rvalue would be returned). the key issue here is the optionality of returning a +0 rvalue. this change begins to resolve this difference by creating two separate apis that guarantee to the caller whether or not a +0 or a +1 rvalue is returned and also creates local scopes for the caller as appropriate. so by using these apis, the caller knows that the +0 or +1 rvalue that is returned has properly been put into the caller scope. so the caller no longer needs to create its own scopes anymore. emitplusonervalue is emitrvalue except that it scopes the rvalue emission and then pushes the produced rvalue through the scope. emitpluszerorvalue is currently a stub implementation that just calls emitplusonervalue and then borrows the resulting +1 rvalue in the outer scope, creating the +0 rvalue that was requested by the caller. rdar://33358110 </desc> <cmt> [silgen] teach scope::poppreservingvalue(rvalue &&rv) how to handle address only values. </cmt> <cmt> rdar://33358110 </cmt> <cmt> [silgen] begin splitting emitrvalue into two different apis: silgenfunction::emitplus{one,zero}rvalue(...). </cmt> <cmt> today, silgenfunction::emitrvalue assumes the caller will create any cleanup </cmt> <cmt> scopes that are needed to cleanup side-effects relating to the rvalue </cmt> <cmt> evaluation.  the api also provides the ability for the caller to specify that a </cmt> <cmt> +0 rvalues is an ""ok"" result. the api then tries to produce a +0 rvalue and </cmt> <cmt> returns a +1 rvalue otherwise. these two properties create conflicting </cmt> <cmt> requirements on the caller since the caller does not know whether or not it </cmt> <cmt> should create a scope (if a +1 rvalue will be returned) or not (if a +0 rvalue </cmt> <cmt> would be returned). </cmt> <cmt> the key issue here is the optionality of returning a +0 rvalue. this change </cmt> <cmt> begins to resolve this difference by creating two separate apis that guarantee </cmt> <cmt> to the caller whether or not a +0 or a +1 rvalue is returned and also creates </cmt> <cmt> local scopes for the caller as appropriate. so by using these apis, the caller </cmt> <cmt> knows that the +0 or +1 rvalue that is returned has properly been put into the </cmt> <cmt> caller scope. so the caller no longer needs to create its own scopes anymore. </cmt> <cmt> emitplusonervalue is emitrvalue except that it scopes the rvalue emission and </cmt> <cmt> then *pushes* the produced rvalue through the scope. emitpluszerorvalue is </cmt> <cmt> currently a stub implementation that just calls emitplusonervalue and then </cmt> <cmt> borrows the resulting +1 rvalue in the outer scope, creating the +0 rvalue that </cmt> <cmt> was requested by the caller. </cmt> <cmt> rdar://33358110 </cmt>",split emitrvalue into plusone pluszero variants
3345,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> updating directory.md </cmt> <cmt> chore(all-subsequence): added type hints [hacktober-fest] </cmt> <cmt> updating directory.md </cmt>,added all sub sequence type hints [hacktober fest]
3346,"<desc> description: sets the signing configuration to sign the universal package as well. fixes an oversight where universal was creating arm instead of arm64. we make 3 flavors: x86, amd64, and arm for the centennial one, so we should do that for the universal one too. how tested? i ran a release build and it happily spit out exactly what i wanted. </desc> <cmt> add sign config for universal. </cmt> <cmt> make arm64 build also build. </cmt>",enable signing and arm64 for universal terminal
3347,"<desc> between this and #28009, only lazyresolver::resolveimplicitmember exists and will soon be requestified away. to facilitate its speedy demise, drop the typechecker dependency out of the multi-conformance checker and fold resolveimplicitconstructors into resolveimplicitmember. </desc> <cmt> drop the type checker out of the multi-conformance checker </cmt> <cmt> fold resolveimplicitconstructors into resolveimplicitmember </cmt>",plot the demise of lazyresolver
3348,"<desc> this pr fixes a bug i introduced in #6346. if an @objc variable declared in a class is overridden in an extension with computed or observed blocks, multiple errors are generated -- one for each contained decl. there is a flag passed into recordoverride with the intent to restrict this warning for override_decl_extension, but i didn't realize its purpose. i fixed the check and added tests for the various scenarios. resolves sr-4024. </desc> <cmt> add tests for overridden variables that are computed or observed </cmt> <cmt> do not generate warning when recording the override for a func_decl contained in a variable </cmt>",do not report an override warning multiple times
3349,"<desc> update a few examples that did not look good close #2954 </desc> <cmt> update a few comments </cmt> <cmt> update more jsdocs </cmt> <cmt> update actions examples </cmt> <cmt> update a few more docs </cmt> <cmt> more jsdoc </cmt> <iss> intellisense comments are broken for some examples that use ""@"" </iss>",fix jsdoc examples and expand comments in typescript definition file
3350,<desc> add funtions to perform multilevel crop and resize. add multilevel_native_crop_and_resize. add multilevel_matmul_crop_and_resize change faster rcnn meta arch function that use _crop_and_resize_fn other (add functions support faster rcnn fpn feature extractor) simple unittest for both functions. test configuration: i have signed the contributor license agreement. i have read guidelines for pull request. my code follows the coding guidelines. i have performed a self code review of my own code. </desc> <cmt> add multilevel functions dealing with multilevel features. </cmt> <cmt> fix tiny errors. </cmt> <cmt> add multilevel function </cmt> <cmt> compute tensor once and change all values not belone to this level to zero </cmt> <cmt> fix bugs for multilevel_native_crop_and_resize </cmt> <cmt> add test for multilevel_native_crop_and_resize </cmt> <cmt> remove unused unit test </cmt> <cmt> add todo: consider more efficient approach to compute multilevel cropped features </cmt> <cmt> add unit test for multilevel_matmul_crop_and_resize </cmt> <cmt> remove unused import </cmt> <cmt> fix coding style </cmt> <cmt> fix coding style </cmt>,add multilevel crop and resize functions
3351,"<desc> this change introduces a new reference guide on modifying starters. topics include: choosing a starter exploring the folder structure adding content querying data customizing styles i'd love feedback on this, especially since it's my first gatsby pr! please let me know if you see parts that could be reworded or if i'm missing any important topics. i'd also particularly like to know if there are areas where my adherence to the style guide could be improved. thanks so much in advance! addresses #18116 </desc> <cmt> draft 'modifying a starter' </cmt> <cmt> link to 'modifying a starter' from parent page and tutorial </cmt> <cmt> add 'modifying a starter' to navigation menu </cmt>","add reference guide ""modifying a starter"""
3352,"<desc> causing it to evaluate indeterminate expressions like num > 0 && num < 100 to false (instead of undefined), and even determinate expressions (num > 0 && num < 100 preceded by var num = 5) to false (instead of true). (just waiting for the build to fail before pushing the fix)  1) evaluation should work with repeated, indeterminate identifiers: assertionerror: false === undefined ... 2) evaluation should work with repeated, determinate identifiers: assertionerror: false === true </desc> <cmt> babel-traverse: add test to demonstrate repeated identifiers being evaluated to false </cmt> <cmt> fix typo: value -> val </cmt> <cmt> path.evaluate: only mark item as resolved if we're confident </cmt>",fix bug where path.evaluate treats repeated identifiers as undefined
3353,"<desc> most of the new code is copied directly from the heart of the mir borrowchecker. i was expecting more fundamental structural changes, hence the copying. this appears to work as it stands, but i'd like to submit a follow-up pr to reduce code duplication. i figured that could wait though, since this is blocking a large amount of work in the borrow check repository and i'm out of time for tonight =). r? @nikomatsakis </desc> <cmt> framework and rough implementation for invalidates facts </cmt> <cmt> this probably doesn't compile and definitely doesn't work </cmt> <cmt> get closer to successful compilation </cmt> <cmt> complete implementation of invalidates facts </cmt>","generate ""invalidates"" facts when -znll-facts is passed"
3354,"<desc> the module would bail if the organization did not already exist and skip creating it, this should fix it. ansible version </desc> <cmt> fixes(#25299) don't fail when creating a foreman organization (#25396) </cmt> <cmt> (cherry picked from commit 2220362a5ffbef113fe1d33ecb46331a06d1d875) </cmt> <cmt> fix for foreman organization creation </cmt>",don't fail when creating a foreman organization fixes(#25299)
3355,"<desc> according to  change some functions in modules/_io/stringio.c and in modules/_io/bytesio.c to use _pyio_convertssize_t (which accepts integer types) change _io_bytesio_truncate_impl so that it would accept integer types (i ran the test module again on my ubuntu 16.04 vm, and none of the tests failed.) </desc> <cmt> patch init commit </cmt> <cmt> changed arg name of _io_stringio_readline_impl </cmt> <cmt> removed changes outside modules/_io </cmt>",make some bytesio methods accept integer types (only changes in modules/_io)
3356,"<desc> see #30642. drain is the only type left invariant. </desc> <cmt> make hashmap's rawbucket covariant </cmt> <cmt> fix the variances of hashmap and hashset iterators </cmt> <cmt> test that hashmap, hashset, and their iterators are properly covariant </cmt>","make hashmap, hashset, and their iterators properly covariant"
3357,"<desc> this makes innerhtml near spec compliant. it's missing attribute namespaces, the is value for custom elements and non-breaking spaces (as they have an extra byte before them for reasons unknown). this is a sample of the results of html/syntax/serializing-html-fragments/serializing.html wpt: (the vast majority of the failed tests are outerhtml tests, which we don't have) </desc> <cmt> libweb: implement html fragment serialisation and use it in innerhtml </cmt> <cmt> the previous implementation was about a half implementation and was </cmt> <cmt> tied to element::innerhtml. this separates it and puts it into </cmt> <cmt> htmldocumentparser, as this is in the parsing section of the spec. </cmt> <cmt> this provides a near finished html fragment serialisation algorithm, </cmt> <cmt> bar namespaces in attributes and the is value. </cmt> <cmt> libweb: make the innerhtml setter spec compliant </cmt> <cmt> this adds innerhtml to shadowroot in the process. </cmt> <cmt> libweb: implement parentnode.children </cmt> <cmt> required by web platform tests for the innerhtml/outerhtml tests. </cmt>",make innerhtml more spec compliant and add parentnode.children
3358,"<desc> chain/config.hpp changes tutorial's use of msig to update system contract caused a missed-block storm. these changes fix it. bios boot tutorial changes #3226: removed freeze, recall, and whitelist from token issue regenerated non-system account keys to make them all unique. producers had some shared keys, causing odd behavior. make eosio.msig privileged handle rounding issues from pareto. total stake is close to 1b. claim rewards proxy votes eosio resigns producers use msig contract to replace system contract random transfers new eosio.* accounts 3000 normal (non-producer, non-system) accounts todo: new script to reproduce the storm without replacing the system contract moving to separate pull request </desc> <cmt> bios-boot-tutorial: fix #3226, claimrewards, proxy votes, transfer funds </cmt> <cmt> bios-boot-tutorial: use unique keys </cmt> <cmt> bios-boot-tutorial: eosio resigns, make msig privileged </cmt> <cmt> bios-boot-tutorial: msig replace system contract </cmt> <cmt> adjust parameters to allow msig setcode eosio.system </cmt>","adjust chain/config.hpp, bios boot tutorial"
3359,"<desc> this adds freebsd support to osquery's build system, and only does it.  it could be the preliminary work of porting osquery to freebsd, and enables more people start to work on it without solving tedious build issues. build process: install dependencies: autoconf automake bison boost cmake gflags glog gmake libtool libunwind rocksdb snappy thrift thrift-cpp tools/provision.sh did not install build packages for freebsd, just skips them. for now, the implementations of following tables do not exist (yet): osquery/tables/specs/x/groups.table osquery/tables/specs/x/passwd_changes.table osquery/tables/specs/x/process_envs.table osquery/tables/specs/x/process_open_files.table osquery/tables/specs/x/processes.table osquery/tables/specs/x/routes.table osquery/tables/specs/x/users.table by removing them temporarily, osquery can be built under freebsd with just gmake. </desc> <cmt> let provision script know freebsd </cmt> <cmt> let freebsd has its own build dir </cmt> <cmt> set flags for freebsd's compiler and linker </cmt> <cmt> gnu make under freebsd is gmake </cmt> <cmt> $distro will be used for c macro, truncate unnecessary part </cmt> <cmt> use uname -s to determine non-linux platform </cmt> <cmt> add libraries and settings for freebsd </cmt> <cmt> include proper headers for freebsd </cmt> <cmt> no utmpxname() under freebsd </cmt> <cmt> no <uuid/uuid.h> under freebsd </cmt> <cmt> make room for freebsd events </cmt>",freebsd support of build infrastructure
3360,<desc> cleanup resolve and refactor away uses of the hir map (incorrectly named ast_map). r? @nrc </desc> <cmt> refactor away field vis of modules </cmt> <cmt> refactor field span of namebinding from option<span> to span. </cmt> <cmt> refactor away fallbackchecks and remove dead code </cmt> <cmt> refactor away is_static_method </cmt> <cmt> refactor away get_trait_name </cmt> <cmt> refactor resolve_crate_relative_path and resolve_module_relative_path </cmt> <cmt> to return a namebinding instead of a def </cmt> <cmt> refactor away a use of ast_map.span_if_local() </cmt> <cmt> avoid using the hir map when visibility checking in resolve </cmt> <cmt> refactor ty::visibility methods to use a new trait nodeidtree instead of the ast map. </cmt>,cleanup and groundwork for resolving the ast
3361,"<desc> closes #36293 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry as far as i know, isin needs a level input when only a string is given for a multiindex. if this should not change, we have to set level=0 in this case. </desc> <cmt> fix drop bug </cmt> <cmt> add test and whatsnew </cmt> <iss> bug: `dataframe.drop` fails when there is a multiindex without any level provided </iss>",dataframe.drop raising typeerror for string label with non-unique multiindex and no level provided
3362,"<desc> backport #7258 this fixes the problems with divmod in #7224 and brings divmod for numpy float64 scalars and arrays into agreement with divmod for python floats. tests are added to enforce the new behavior and assures that the results for small integers scaled by powers of two are exact. too keep the scalar and array math in sync, both the scalar math and loop code is based on a new npy_divmod function in npy_math. edit: i changed the name to npy_divmod. divmod example, python floats in [1]: a = 78 * 6e-8 in [2]: b = 6e-8 in [3]: divmod(a, b) out[3]: (77.0, 5.999999999999965e-08) before this commit numpy float64 gave in [4]: divmod(float64(a), float64(b)) out[4]: (78.0, 0.0) after this commit numpy float64 gives in [4]: divmod(float64(a), float64(b)) out[4]: (77.0, 5.9999999999999651e-08) </desc> <cmt> enh: add new npy_divmod function to npy_math. </cmt> <cmt> the new function is taken from the python version of float_divmod and </cmt> <cmt> computes the result of floor_division and modulus together so that they </cmt> <cmt> can be kept compatible. this should also result in the '//' and '%' </cmt> <cmt> operators applied to np.float64 and python float returning the same </cmt> <cmt> values. </cmt> <cmt> the intent is to implement the ufuncs floor_divide and remainder using </cmt> <cmt> the npy_divmod so that their results will also match those of '//' and </cmt> <cmt> '%' while providing consistency between the two. </cmt> <cmt> note that npy_divmod uses fmod, which is very slow. as a result, the </cmt> <cmt> floor_division and remainder functions are about 4x slower than the </cmt> <cmt> previous versions based on the floor function, but should be more </cmt> <cmt> accurate. </cmt> <cmt> enh: make numpy floating scalars consistent with python divmod. </cmt> <cmt> the following numpy scalar floating functions are reimplemented </cmt> <cmt> using the npy_divmod function. </cmt> <cmt> - remainder ('%') </cmt> <cmt> - floor_division ('//') </cmt> <cmt> - divmod </cmt> <cmt> note that numpy scalars warn on zero division rather than raise. </cmt> <cmt> divmod example, python floats </cmt> <cmt> in [1]: a = 78 * 6e-8 </cmt> <cmt> in [2]: b = 6e-8 </cmt> <cmt> in [3]: divmod(a, b) </cmt> <cmt> out[3]: (77.0, 5.999999999999965e-08) </cmt> <cmt> before this commit numpy float64 gave </cmt> <cmt> in [4]: divmod(float64(a), float64(b)) </cmt> <cmt> out[4]: (78.0, 0.0) </cmt> <cmt> after this commit numpy float64 gives </cmt> <cmt> in [4]: divmod(float64(a), float64(b)) </cmt> <cmt> out[4]: (77.0, 5.9999999999999651e-08) </cmt> <cmt> maint: remove floor function code no longer needed in scalarmath. </cmt> <cmt> the floor function is no longer needed in scalarmath as its use has been </cmt> <cmt> replaced by the new pymodf function. </cmt> <cmt> enh: make numpy ufuncs compatible with python divmod. </cmt> <cmt> the following numpy ufuncs are reimplemented using the npy_divmod </cmt> <cmt> function. </cmt> <cmt> - remainder ('%') </cmt> <cmt> - floor_divide ('//') </cmt> <cmt> example of differences </cmt> <cmt> currently </cmt> <cmt> in [1]: a = np.array(78 * 6e-8) </cmt> <cmt> in [2]: b = np.array(6e-8) </cmt> <cmt> in [3]: a // b </cmt> <cmt> out[3]: 77.0 </cmt> <cmt> in [4]: a % b </cmt> <cmt> out[4]: 5.9999999999999651e-08 </cmt> <cmt> previously </cmt> <cmt> in [1]: a = np.array(78 * 6e-8) </cmt> <cmt> in [2]: b = np.array(6e-8) </cmt> <cmt> in [3]: a // b </cmt> <cmt> out[3]: 78.0 </cmt> <cmt> in [4]: a % b </cmt> <cmt> out[4]: 0.0 </cmt> <cmt> the first agrees with the python values for the same operation and is a </cmt> <cmt> bit more accurate for the input values as represented internally. </cmt> <cmt> closes #7224. </cmt> <cmt> tst: add tests for '//' and '%' (floor_divide, remainder). </cmt> <cmt> add tests for some corner cases involving inf, zero, and nan. </cmt> <cmt> check that small integers are handled exactly. </cmt> <cmt> doc: document that floor_divide and remainder are complementary. </cmt> <cmt> the floor_divide (//) and remainder (%) functions are complementary </cmt> <cmt> in the sense that a ~= (a % b) + (a // b). </cmt>",fix divmod for numpy scalars and arrays.
3363,"<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance the dispatchers will create new objects for metrics, that is too much. so we need a light-weight object. </desc> <cmt> feature of database session </cmt> <cmt> make it configurable. </cmt> <cmt> change the metrics process flow. </cmt> <cmt> before: metrics entrance -> aggregate worker -> remote worker -> trans worker -> minute, hour, day, month persistence worker -> storage </cmt> <cmt> after: metrics entrance -> aggregate worker -> remote worker -> minute persistence worker ->  trans worker -> hour, day, month persistence worker -> storage </cmt> <cmt> # conflicts: </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/worker/metricspersistentworker.java </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/worker/metricsstreamprocessor.java </cmt> <cmt> intkeylongvaluehashmap instead of intkeylongvaluearray. </cmt> <cmt> make the oap server can't startup. </cmt> <cmt> finish </cmt> <cmt> # conflicts: </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/coremoduleprovider.java </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/worker/metricspersistentworker.java </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/worker/metricsstreamprocessor.java </cmt>",simplify the pxxmetrics and thermodynamicmetrics to improve performance
3364,"<desc> given that modern drives use 4k sectors, we should align everything to multiples of 4k. so far we used 1k (i.e. two 512 sectors), so increasing this might waste 2x3k at most, which i think we can live with. systemd-repart already aligns everything to 4k, this just adds the same logic to the partitioning of homed's per-user luks volumes, both when creating and resizing partitions. </desc> <cmt> homed: always align home file systems to 4k boundaries </cmt> <cmt> let's carefully align all home file systems to 4k sector boundaries. </cmt> <cmt> it's the safest thing to do, to ensure good perfomance on 4k sector </cmt> <cmt> drives, i.e. today's hardware. </cmt> <cmt> yes, this means we'll waste 3.5k when resizing home dirs, but i think we </cmt> <cmt> can live with that. </cmt> <cmt> this ensures both the offsets where we start and the sizes of the file </cmt> <cmt> systems/partitions/disk images are multiples of 4k always, both when </cmt> <cmt> creating a new image and when resizing things. </cmt> <cmt> note that previously we aligned everything to 1024, but weren't quite as </cmt> <cmt> careful. </cmt> <cmt> update todo </cmt>",round fs offset and sizes to multiples of 4k
3365,"<desc> hey i recently ran into some issues starting the project on mac: npm run start > edex-ui@3.0.0-pre start > node_modules\.bin\electron src --nointro sh: node_modules.binelectron: command not found npm err! code 127 i was able to find a work around when i updated the file pathing in the package.json to not include back slashes. i tested the start command on a windows machine and the current master version worked fine, so i broke out the commands to be seperate depending on the file path conventions and updated the readme to include them both. i notice that the build steps take a similar approach as the one i've provided, let me know if there is anything else we need to get this merged. ! </desc> <cmt> [master]: update for starting on non windows machines </cmt> <cmt> [master]: update for package json </cmt>",starting on non windows fix
3366,<desc> handle the issue #186 </desc> <cmt> remove the usage of the f-strings because the ci/cd infrastructure is using python 3.5 and f-strings require python 3.6 </cmt> <cmt> setup the generation of the rss feed in the ci/cd pipeline for travisci and circleci </cmt>,setup the generation of the rss feed into the ci/cd pipeline
3367,"<desc> followup of #6849 cocoapods' linter doesn't accept anymore listing header files outside of the headers_mapping_dir, which actually works without problem. but passing the linter is required for submitting the pod. a following pull request does the same for grpc-core.podspec. </desc> <cmt> boringssl: import all in the umbrella header </cmt> <cmt> boringssl: point to v3 tag in the repo </cmt> <cmt> boringssl: intf and impl subspecs. wip </cmt> <cmt> boringssl fixup: remove unneeded empty source file </cmt> <cmt> boringssl: document podspec hacks </cmt> <cmt> boringssl: move podspec to v4 </cmt> <cmt> boringssl fixup: pqueue.h is removed in v4 </cmt>",fix cocoapods linter issues with boringssl.podspec
3368,"<desc> i removed the auto-buildkite-pipelines:protocol-features-sync-nodes branch in pull request 7467 but then, in commit 2bcddd7fca4162f49db350ece8e27b49cd8e5080, someone incorrectly resolved merge conflicts and pointed the eosio-lrt and eosio-build-unpinned pipelines at this deleted branch without testing their changes. i have restored these pipelines to their state in pull request 7467. tested eosio-build-unpinned build 241 this build is expected to fail on amazon linux 2 np tests and ubuntu 18.04 np tests as seen in build 221. devops has an open story to address that failure. eosio-lrt build 549 none. none. none. </desc> <cmt> alphabetized environment variables for eosio pipeline </cmt> <cmt> fix eosio-lrt and eosio-build-unpinned pipelines, which pointed to a non-existant branch </cmt>",fix incorrectly resolved and untested merge conflicts in pipeline configuration file
3369,"<desc> this pr moves some of the docker-specific setup and teardown from dockertests up to packagingtestcase so that the keystoremanagement tests will run on docker. the main thing that needs to happen is setting the testing shell to be a dockershell. previously, the keystoremanagementtests were mostly ""passing"" on docker because they ran shell commands on the underlying system and then queried a docker installation. now, we can be more confident that the tests are doing the right thing in the docker case. fixes #49469 </desc> <cmt> add docker handling to packagingtestcase </cmt> <cmt> keystore tests need to be able to run in the docker case. we can do this </cmt> <cmt> by using a dockershell instead of a plain shell when docker is running. </cmt> <cmt> refactor cleanup to parent class </cmt>",run keystore management tests on docker distros
3370,<desc> this pr adds support for standalone jdk libraries and the necessary infrastructure for jdk libraries that depend on jvm.dll and/or java.dll such as awt.dll (actual support for awt.dll will be added in a follow-up pr). closes #3085 </desc> <cmt> refactor jniregistrationsupport to track all libs </cmt> <cmt> don't swallow checked exceptions in nativeimagegenerator.run </cmt> <cmt> copy required dynamic jdk libs next to image </cmt> <cmt> make shim dlls to satisfy deps of jdk libs </cmt> <cmt> make linking of shim dlls traceable </cmt> <iss> add support for dynamic linking of jdk libraries on windows </iss>,add support for dynamic linking of jdk libraries on windows.
3371,"<desc> what this pr does / why we need it: fixes various bugs and shellcheck lints in ./cluster/get-kube.* fixes #68305 special notes for your reviewer: now that we have a lint presubmit to prevent regressions (#68438), i think it is worthwhile to eliminate these bugs bit by bit. in particular we have a lot of incorrect string quoting throughout out shell scripts causing bugs like #68305. does this pr introduce a user-facing change?: </desc> <cmt> fix get-kube-binaries.sh shellcheck lints </cmt> <cmt> fix get-kube-local.sh </cmt> <iss> get-kube-binaries.sh: fails when there's space in path </iss>",fix bugs in get-kube scripts
3372,"<desc> this is the follow-up pr after #13222 that finalizes the conversion for the smaller and medium sized unit test files. only three unit test files remain with done callbacks after this pr, but since they are bigger they will be done in a follow-up pr. using the ?w=1 parameter will help during review for most commits. </desc> <cmt> convert done callbacks to async/await in test/unit/display_svg_spec.js </cmt> <cmt> convert done callbacks to async/await in test/unit/message_handler_spec.js </cmt> <cmt> drop obsolete done callbacks in test/unit/crypto_spec.js </cmt> <cmt> there is no asynchronous code involved here, so we can get rid of all </cmt> <cmt> done callbacks here and simply use the fact that if the function call </cmt> <cmt> ends without failed assertion that the test passed. </cmt> <cmt> drop obsolete done callbacks in test/unit/annotation_storage_spec.js </cmt> <cmt> there is no asynchronous code involved here, so we can get rid of all </cmt> <cmt> done callbacks here and simply use the fact that if the function call </cmt> <cmt> ends without failed assertion that the test passed. </cmt> <cmt> convert done callbacks to async/await in test/unit/cmap_spec.js </cmt>",convert done callbacks to async/await in more unit test files
3373,"<desc> this enables a web embedder to provide message ports that should be routed to extensions upon their activation. the embedder api is: readonly messageports?: readonlymap<extensionid, messageport>; the extension api is: declare module 'vscode' { export interface extensioncontext { readonly messageport: messageport | undefined; } } </desc> <cmt> wip: ipc api </cmt> <cmt> wip: send message ports upfront </cmt> <cmt> address both inside and outside iframe </cmt>",enable ipc api for web
3374,"<desc> mkhandle used to be responsible for exposing functions for remoteworkers, this pr updates this behaviour to work on local workers as well. this way we pave a way for a more universal/extendible workerfarm as we can just call mkhandle to register a new function on both local and remote workers </desc> <cmt> modify mkhandle to work for both local and remote worker </cmt>",minor change to mkhandle in workerfarm
3375,"<desc> another batch of deprecation removals warn_on_dtype parameter parameters to check_is_fitted parameters to all_estimators (in both places: init.py and _testing.py (which is private now)) n_components attribute change multioutput parameter value in baseestimator.score call to r2_score removed lots of useless decorators ""max_iter and tol parameters..."" changed default of copy parameter in quantile_transform removed six.py </desc> <cmt> removed warn_on_dtype </cmt> <cmt> removed parameters to check_is_fitted </cmt> <cmt> all_estimators parameters </cmt> <cmt> deprecated n_components attribute in agglomerativeclustering </cmt>",mnt removed deprecated attributes and parameters
3376,"<desc> this pr resurrects #23622 which has not been updated in a while. makes the image component handle blob: object urls. closes #23622 fixes #19291 credits: @sdn90 related issues linked using fixes #number errors have helpful link attached, see contributing.md related issues linked using fixes #number errors have helpful link attached, see contributing.md </desc> <cmt> test: add failing test </cmt> <cmt> feat: support blob urls in image component </cmt> <iss> [next/image] support blob url's </iss>",handle blob urls in image component
3377,"<desc> fix #335. </desc> <cmt> test/regress: add tests for evbuffer_add() breakage on empty last chain </cmt> <cmt> the evbuffer/add* tests currenly break on 2.0.21, 2.0.22 and 2.1 head </cmt> <cmt> due to issue #335. the evbuffer/reference2 test breaks on 2.0.21 and </cmt> <cmt> 2.0.22 due to commit b18c04dd not being applied. </cmt> <cmt> use the free-trailing-chains function in evbuffer_insert_chain too </cmt> <cmt> evbuffer_add: use last_with_datap if set, not last. </cmt> <cmt> evbuffer_add() would always put data in the last chain, even if there </cmt> <cmt> was available space in a previous chain, and in doing so it also </cmt> <cmt> failed to update last_with_datap, causing subsequent calls to other </cmt> <cmt> functions that do look at last_with_datap to add data in the middle </cmt> <cmt> of the evbuffer instead of at the end. </cmt> <cmt> fixes the evbuffer_add() part of issue #335, and the evbuffer/add2 and </cmt> <cmt> evbuffer/add3 tests, and also prevents wasting space available in the </cmt> <cmt> chain pointed to by last_with_datap. </cmt>",fix issue #335 and add unit tests.
3378,"<desc> #1322 </desc> <cmt> more accurate conversion to nullable type in function cast #1322 </cmt> <cmt> implemented toorzero, toornull functions for date and datetime arguments (incomplete) #1322 </cmt> <cmt> implemented more accurate cast from string to nullable of date and datetime #1322 </cmt> <cmt> added test #1322 </cmt> <cmt> added a test from silviu caragea #1322 </cmt>",more accurate parsing when cast to nullable
3379,"<desc> fixes #9568 part6. add logicsql in executioncontext, replace sqlstatementcontext add logicsql in executeprocessreporter.report, replace sqlstatementcontext persist logicsql.sql to zk show sql in info column when executing ""show processlist"" </desc> <cmt> prepare logicsql for executeprocessreporter </cmt> <cmt> persist logic sql and show in info column </cmt> <iss> [new feature] support to show execution process for running sqls by rql </iss>",show logic sql in execution process list info column
3380,"<desc> whenever a dev dependency is not in a registry but is hosted elsewhere, upgrading the package throws an error. e.g. if a package is hosted on a private github repository, it can be installed via yarn add git-url#sha --dev. the package is resolved correctly and set as a dependency (with a name). attempting to yarn upgrade <package name> throws an error indicating a missing package in the registries. this also mirrors yarn upgrade <package name> behavior for regular dependencies. see initial commit for failing test. </desc> <cmt> ensure test covers a dev dependency not in any registry </cmt> <cmt> ensure yarn upgrade also considers dev dependencies </cmt>",yarn upgrade any dependencies via protocol
3381,"<desc> we were previously using a framebuffer blit, which internally converts the formats, instead of using the raw data and interpreting it as the new format. this shouldn't have much impact on anything since most reinterpretations happen because games stopped using a texture and re-used the memory for another unrelated one that they're about to clear. </desc> <cmt> rasterizer: don't attempt to copy over the old texture's data when doing a format reinterpretation if we're only going to clear the framebuffer. </cmt> <cmt> rasterizer: reinterpret the raw texture bytes instead of blitting (and thus doing format conversion) to a new texture when a game requests an old texture address with a different format. </cmt>",use pbos to reinterpret texture formats when games re-use the same memory.
3382,"<desc> now including: fully-virtualized filesystem allowing for fancy fs-related stuff to be easier (updates, dlc, new formats, encryption, et cetera. keep your eyes peeled) virtualfile and virtualdir typedefs to reprent files and dirs respectively basic implementations: realvfsfile/realvfsdirectory for files on the user's computer, offsetvfsfile for a file at specified offset and size in another, readonlyvfsdirectory a partial implementation that defaults all methods that only make sense for writable dirs. move nca implementation to its own file content_archive.[h|cpp] a fix for nca file loading (they now boot -- it was an issue with the romfs offset) cleanup in the core/file_sys directory/namespace documentation is in vfs.h vfsdirectoryservicewrapper covers relevant vfsdirectory methods in ones that return resultcode/resultval for easier interoperability with the switch's fs services. fixes random save-data corruption issues (confirmed found in binding of isaac) remove unused path implementation from citra </desc> <cmt> virtual filesystem </cmt> <cmt> fix delete bug and documentate </cmt>",virtual filesystem 2: electric boogaloo
3383,<desc> adds some tests for #20748. they're based on existing tests we have for react events. i converted the old tests to hooks while i'm at it. see individual commits. </desc> <cmt> convert some old discrete tests to hooks </cmt> <cmt> i'm planning to copy paste so why not update them anyway. </cmt> <cmt> copy paste discrete tests into another file </cmt> <cmt> these are still using react events. i'll change that next. </cmt>,add tests for non-react discrete events flushing in a microtask
3384,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: look at the demo given from highcharts doc here and check the type of this.value in the example. --  --  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> add contextmenu event to simulate on testutils </cmt> <cmt> reverting format on save </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> s.ts </cmt>","axislabelformatteroptions property ""value"" is incorrectly typed as a number"
3385,"<desc> this pr adds stylesprovider with injectfirst option in both @material-ui/styled-engine and @material-ui/styled-engine-sc. the stylesprovider is exported from core as styledengineprovider and used in the docs, codesandbox example template & the argos testviewer. the usage of this provider will be necessary during the transition stage, where we have emotion components being overridden by jss styles. find issue with @material-ui/styled-engine-sc's generated style tag being ignored find issues with remaining argos differences </desc> <cmt> init </cmt> <cmt> wip </cmt> <cmt> reverted theme provider changes </cmt> <cmt> package.json </cmt> <cmt> prettier </cmt> <cmt> fix </cmt> <cmt> exported from core </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> new line </cmt> <cmt> fixed argos, prettier </cmt> <cmt> wip </cmt>",add stylesprovider with injectfirst option
3386,"<desc> fixes #307 </desc> <cmt> make quantization more strict. </cmt> <cmt> don't allow implicit or explicit time signature or tempo changes. </cmt> <cmt> this is in preparation for #307, so that when we switch to using </cmt> <cmt> notesequences, it's clear that time signature and tempo changes don't </cmt> <cmt> change and therefore don't need to be aligned. </cmt> <cmt> lint </cmt> <cmt> first test passes </cmt> <cmt> all sequences_lib tests pass </cmt> <cmt> melodies </cmt> <cmt> chords_lib tests pass </cmt> <cmt> drums_lib tests pass </cmt> <cmt> lead sheets tests pass </cmt> <cmt> pipeline tests pass </cmt> <cmt> all tests pass </cmt> <cmt> lint </cmt> <cmt> is_quantized_sequence helper method </cmt> <cmt> raise exception instead of assert </cmt> <cmt> lint </cmt>",removed quantizedsequence in favor of adding quantized time fields to notesequence
3387,"<desc> fixes kodi banner in /cmake/addons/readme.md adds kodi banner in /cmake/addons/bootstrap/readme.md for consistency fix missing banners noticed when building a binary add-on. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [doc] fix kodi banner in cmake/addons/readme.md </cmt> <cmt> [doc] add kodi banner to cmake/addons/bootstrap/readme.md </cmt> <cmt> - for consistency </cmt>",update kodi banner in cmake/addons docs
3388,"<desc> i am cleaning up markdown preview so it can be used as an example for package creators. while doing this i ran into a few things that i want to change in core. originally this was going to be several pull requests, but yada yada yada i'm just going to do it all in this pr. remove deferred package deserializers. markdown preview was the only package using this and it added unneeded complication to the code. add workspaceview::getactivepaneview (to replace workspaceview::getactivepane) add expect(something).tohavefocus() jasmine expectation remove workspace::opensingletonsync and add its functionality to workspace::open </desc> <cmt> make sure the filepath is never null or undefined </cmt> <cmt> add split and searchallpanes option to workspace::open </cmt> <cmt> update docs </cmt> <cmt> remove log </cmt> <cmt> cleanup split specs </cmt> <cmt> add tohavefocus jasmine expectation </cmt> <cmt> replace getactivepane with getactivepaneview </cmt> <cmt> remove deferred package deserializers </cmt> <cmt> conflicts: </cmt> <cmt> src/deserializer-manager.coffee </cmt> <cmt> src/workspace.coffee </cmt>",changes inspired by markdown preview
3389,<desc> fix setting c++ standard property for h2olog set_property can only one property replace gcc extension typeof with decltype ( gcc extensions are not available if -std=c++11(not gnu++11) option is specified and use using instead of typedef for readability </desc> <cmt> fix setting properties for h2olog </cmt> <cmt> replace gcc extension typeof with decltype </cmt>,fix c++11 configurations and replace gcc extensions
3390,"<desc> since #10810 was merged into release-1.8.4, which contains a lot of extraneous changes, i wanted to try recreating just the cordova-related parts, so that we can merge them cleanly into devel. </desc> <cmt> update cordova to 9.0.1. </cmt> <cmt> this is not a working version, it is just a base to test in real </cmt> <cmt> application and fix issues. </cmt> <cmt> update accounts-password to version 1.5.2. </cmt> <cmt> uses cordova-plugin-meteor-webapp@1.7.1-beta.0. </cmt> <cmt> use cordova-lib api to run cordova. </cmt> <cmt> update circleci docker image to android 28. </cmt> <cmt> use cordova plugin info for checking plugin installation. </cmt> <cmt> avoid false missing error on git tarballs that were having their ids parsed </cmt> <cmt> like </cmt> <cmt> it's easier if the id is just the plugin name like cordova-plugin-appsettings, </cmt> <cmt> which we can get from config.xml as plugininfo does. </cmt> <cmt> update cordova-plugin-meteor-webapp to 1.7.1-beta.1. </cmt> <cmt> update cordova-plugin-whitelist to 1.3.4. </cmt> <cmt> update cordova-plugin-wkwebview-engine to 1.2.1. </cmt> <cmt> update cordova-plugin-splashscreen from 4.1.0 to 5.0.3. </cmt> <cmt> included by mobile-experience > launch-screen. </cmt> <cmt> update cordova-plugin-statusbar from 2.3.0 to 2.4.3. </cmt> <cmt> included by mobile-experience > mobile-status-bar. </cmt> <cmt> beta versions for mobile packages. </cmt>",rebase pr #10810 (cordova 9) against current devel branch.
3391,<desc> supersedes: #12448 </desc> <cmt> fix trash from rabbitmq </cmt> <cmt> fix build </cmt> <cmt> tests: ignore *.dump (parquet tests) </cmt> <cmt> fix arrow deprecated api usage </cmt> <cmt> and also use fmt-style for exceptions </cmt> <cmt> do not suppress -wdeprecated* for arrow </cmt>,arrow deprecated api usage build fixes
3392,"<desc> the compute_single_action method allows for a default none value assignment to the state argument. however, the method body did not check if state was none, and instead performed an operation on the argument value. this fix includes the check that if state == none, then do not perform the aforementioned operation on the argument. the check is performed for all of the other arguments except for state. </desc> <cmt> fixes empty state parameter in compute_single_action method </cmt> <cmt> fixed style </cmt>",fixes empty state argument in compute_single_action method
3393,<desc> while i was messing around with the code a little with #1165 i triggered a few bugs where i didn't understand at first what went wrong. just add some asserts hopefully help in the future and a little bit of cleanup. </desc> <cmt> windowserver: use early return to reduce nesting </cmt> <cmt> windowserver: remove unimplemented header function </cmt> <cmt> windowserver: assert that a window is not being set as empty </cmt> <cmt> libgfx: assert that an empty bitmap is not created </cmt>,add some asserts and codecleanup
3394,<desc> improve admission webhook metrics. fixes #100871 - add a namespace label for all apiserver_admission_* metrics. - expand the histogram range to 0-10s for all apiserver_admission_*_duration_seconds metrics. </desc> <cmt> add a namespace label to admission metrics. </cmt> <cmt> extend the max of admission latency buckets to 10s. </cmt> <iss> admission webhook metrics improvement </iss>,add a namespace label to admission metrics and expand histogram range to 0-10s
3395,"<desc> most programming languages, including python 2 call all the destructor of global variables if the program exists successfully. python 3 is not guaranteed to. this can result in the arguments of file.write() not being written to the disk. the guys in this issue also released this problem and discussed if it should be this way, but apparently all of them were completely brain-dead idiots because they did not check if the documentation of python matches the actual behaviour. instead, the documentation stated that python will call f.close() (and i quote) ""eventually"", which is completely bs, because python may never call f.close(). i can't fix the (imho stupid) behavior of python 3 not calling destructors, but at least i can fix the documentation (this pr). especially for a programming language like python, that is supposed to be used by people with limited cs knowledge, it is important that no features in the programming language yields surprising behavior and good documentation that is correct is also very important. excuse me for my language, but if one of the most popular programming languages doesn't manage to fix a simple but important documentation error within a year after someone reports it, it is a disgrace and failure of the open source model. if you support this kind of misleading documentation, you are 100 % responsible to every bug written by someone who thought that f.close() is called when the program exists. and they are 0 % responsible for the bug, because they trusted the documentation. </desc> <cmt> fixed the documentation of the open() command </cmt> <cmt> simple documentation fix </cmt> <cmt> simple documentation fix </cmt>",fixed the documentation about closing files
3396,"<desc> closes #31256 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 17038 </cmt> <cmt> revert change </cmt> <cmt> revert change </cmt> <cmt> try fix 31256 </cmt> <iss> regression bugs when applying groupby aggregations to categorical columns </iss>",regression when applying groupby aggregation on categorical columns
3397,"<desc> the user-facing ray.init assumes that it will either start an entirely new cluster or connect to an existing one. this pr introduces an internal ray._init that takes in information about a partially started cluster. for example, a test may start a cluster with a plasma store of capacity 1gb by: node_ip_address = ""127.0.0.1"" redis_address = ray.services.start_redis(node_ip_address) plasma_store_memory = 10 ** 9 plasma_address = ray.services.start_objstore(node_ip_address, redis_address, objstore_memory=plasma_store_memory) address_info = { ""redis_address"": redis_address, ""object_store_addresses"": [plasma_address], } ray._init(address_info=address_info, start_ray_local=true, num_workers=1) </desc> <cmt> refactor ray.init and ray.services to allow processes that are already running </cmt> <cmt> fix indexing error </cmt>",allow ray.init to take in address information about existing services.
3398,"<desc> tracking issue: #5891 i am moving three linting steps from jenkins to github actions: lint, sphinx, and doxygen. also, reduce workload of r tests by half, since github actions has a usage cap per organization and we don't want to get our jobs throttled. todo. figure out how to run clang-tidy in github actions. </desc> <cmt> [ci] move lint to github actions </cmt> <cmt> [ci] move doxygen to github actions </cmt> <cmt> [ci] move sphinx build test to github actions </cmt> <cmt> [ci] reduce workload for windows r tests </cmt>",migrate linters to github actions
3399,"<desc> if the client doesn't send a certificate, then tornado turns into an infinite loop. (with the option ssl.cert_required )  iostream._handle_events needs a try/except block similar to the one in _run_callback.  i'm not sure whether this would replace the one in _run_callback or if we need one in both places. -ben </desc> <cmt> fixed iostream._handle_events (try/except block) </cmt> <cmt> fixed iostream._handle_events (try/except block) to prevent </cmt> <cmt> infinite loop when an unhandled exception occurs </cmt> <cmt> ssliostream._do_ssl_handshake ssl error check </cmt>",ssl error in iostream and infinite loop
3400,"<desc> as mentioned in #90, the restriction to object or array root elements has been dropped with the updated json rfc (rfc7159).  this pull-request removes the restriction from the rapidjson implementation. the unit tests are updated to check the new behaviour. @thebusytypist: could you please review the changes to the iterative parser (c9f2715)? (the whitespace changes have been fixed in 453eda5) </desc> <cmt> (pretty)writer: drop restriction to object/array roots </cmt> <cmt> drop object/array root restriction from recursive parser </cmt> <cmt> reader: drop object/array root restrction from iterative parser </cmt> <cmt> jsoncheckertest: skip ""fail1.json"", as it is now accepted by rapidjson </cmt> <cmt> writertest: add some roundtrip tests for non-compound root values </cmt> <cmt> readertest: drop object/array root restriction tests </cmt> <cmt> error/{en,error}.h: drop unused kparseerrordocumentrootnotobjectorarray error </cmt> <cmt> readme.md: reference rfc7159 instead of rfc4627 </cmt> <cmt> tutorial.md: lift restriction to object/array root values </cmt> <cmt> readertest.cpp: use top-level parse functions, instead of internal ones </cmt> <cmt> with the allowance of arbitrary root value types, the individual tests </cmt> <cmt> can use the top-level parse functions, instead of parsefoo() variants. </cmt> <cmt> secondly, some unneeded array wrappers have been dropped and non-singular </cmt> <cmt> tests starting with other values than objects or arrays have been added. </cmt> <cmt> basereaderhandler: allow overriding of default() implementation </cmt> <cmt> by adding an optional crtp template parameter, the basereaderhandler </cmt> <cmt> can call the ""overridden"" default() function from the derived </cmt> <cmt> class. </cmt> <cmt> see </cmt> <cmt> readertest.cpp: use crtp to activate ""add_failure()"" calls in handlers </cmt> <cmt> jsoncheckertest: add checks for iterative parser as well </cmt> <cmt> tabs to 4 spaces (following 0dbcc1cf) </cmt> <cmt> readertest.cpp: remove remaining use of private functions </cmt>",move to rfc7159 (closes #90)
3401,"<desc> refine query source implementation: extract some logic to hooks/utils, refine code, etc. implement proper permission checks. #4429 </desc> <cmt> refine query source: extract query flags, data sources and schema to hooks </cmt> <cmt> move hooks to own folder </cmt> <cmt> extract dialogs to hooks </cmt> <cmt> extract more hooks: query, parameters, autocomplete flags, more dialogs; refine previous changes </cmt> <cmt> query source page: extract formatquery function, simplify event handlers </cmt>",migrate query source page to react: refine code
3402,<desc> fixes #17714 (sphinx 3.2 uses jquery 3.5.1) related to #17564 this pr maps functions with a class name that is indistinguishable when case is ignore to another filename. </desc> <cmt> mnt update sphinx version </cmt> <cmt> doc support for case insensitive filesystems </cmt> <cmt> doc update comment </cmt> <iss> upgrade jquery to version 3.5 to solve cve-2020-11022 </iss>,mnt support for case insensitive filesystems
3403,"<desc> hi, i made an attempt to fix the current issues with insert() (#378 and #392). it should now work with all scalar types (not only integer types) and also with multidimensional inserts when the axis parameter is specified. (and added a few extra tests.) </desc> <cmt> bug: fix for issues #378 and #392 </cmt> <cmt> this should fix the problems with numpy.insert(), where the input values </cmt> <cmt> were not checked for all scalar types and where values did not get inserted </cmt> <cmt> properly, but got duplicated by default. </cmt> <cmt> tst: add extra test for multidimensional inserts. </cmt>",fix for issues #392 and #378
3404,"<desc> this pr moves the logging of storage fallback message and other error messages from individual operator's finferstorage to a common place, by checking the value of dispatch_mode and return code of finferstorage. @reminisce @anirudh2290 @cjolivier01 passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> refactor log message in infer storage </cmt> <cmt> fix bug. support imperative </cmt> <cmt> remove common:: prefix </cmt>",refactor logging in infer storage pass
3405,"<desc> this pr will allow a component to work without importing react each time, as discussed in #285 component.js before: import react from 'react' export default () => <div>my component</div> after: export default () => <div>my component</div> </desc> <cmt> add react-require </cmt> <cmt> add babel-plugin-react-require </cmt>",add react-require to avoid importing react
3406,<desc> added alias for pacman command to remove all files from cache that are not installed added the same for yay and  yaourt did not do the same for other aur helpers but more than willing to do the same for them </desc> <cmt> update readme.md </cmt> <cmt> update archlinux.plugin.zsh </cmt>,add aliases for cleaning package cache
3407,"<desc> because of #17015, concat op supports empty input now. if the first input is empty, then getdatatypeofvar will get error. in this pr, getexpectedkerneltype is adjusted to get type of the first non-empty input. </desc> <cmt> fix concat op vartype check, test=develop </cmt> <cmt> fix concat op vartype check, test=develop </cmt>",fix getexpectedkerneltype  in concat op
3408,<desc> closes #20705 fix verified in </desc> <cmt> [test] add failing test for inconistend textfield#outlined label </cmt> <cmt> [textfield] fix outlined label showing space when label does not indicate required </cmt> <iss> extra space in the label when setting inputlabelprops={{ required: false }} </iss>,fix required outlined label space with no asterisk
3409,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add showmutatedrequest prop </cmt> <cmt> update swagger-ui-react-tests.tsx </cmt>,add showmutatedrequest prop to swagger-ui-react
3410,"<desc> follow up of #14735 move destroy and create counter cache callbacks code inside the countercache model concern. the rationale is that the after_destroy callback need to access the affected_rows variable, and it's cleaner to be in the inheritance chain to access it than to leak it as yet another state on the model. this refactoring do not move the update part of counter caches because its way more complex and i prefer to do it in another pr. @tenderlove what do you think? </desc> <cmt> use inheritance chain instead of callbacks to increment counter caches after create </cmt> <cmt> use inheritance chain instead of callbacks to increment counter caches after destroy </cmt> <cmt> set _after_create_counter_called flag to make update counter cache work </cmt> <cmt> restore the destroy_by_association check in post destroy counter cache </cmt>",refactor counter cache create and destroy
3411,<desc> change docs for aws_batch_job_queue to use the right module name add missing register parameters use modern yaml syntax for debug tasks various aws/ec2 modules. just a few simple documentation improvements -- no code was changed. </desc> <cmt> fix register/debug in aws_batch_compute_environment </cmt> <cmt> fix aws_batch_job_queue doc errors </cmt> <cmt> * fix module naming: batch_job_queue > aws_batch_job_queue </cmt> <cmt> * fix missing register </cmt> <cmt> * update debug task to use modern yaml format </cmt> <cmt> fix missing register + debug for lambda_policy </cmt> <cmt> fix yaml syntax for elb_application_lb_info module </cmt>,fix doc errors in aws modules
3412,<desc> exposes: the $theme-colors and $colors to have the full bootstrap-picked palette the $grid-breakpoints to use in media queries the two $font-family-* stacks see #23349 supersedes #23446 </desc> <cmt> generate css variables </cmt> <cmt> see #23349 </cmt> <cmt> supersedes #23446 </cmt> <cmt> ignore _root.scss for linting </cmt>,"generate css variables for colors, breakpoints, fonts"
3413,"<desc> i found a typo in formula of gru in the document. plus i think using i for both suffix of input hidden state and input cell is difficult to understand so changed the latter to z. and like tanh, sigmoid should be in upright font thus i changed so. </desc> <cmt> fixed a mistake and changed input i to z for clearness </cmt> <cmt> changed sigmoid to upright type </cmt>",fixed typo in formula of  gru in doc
3414,"<desc> description: use new aioharmony instead of pyharmony. this provides the following benefits: full async support no more polling for updates, when an activity is changed from another source (i.e. remote) then hass will be updated through a notification set available state if for some reason disconnected from hub. automatic reconnect to hub if disconnected when sending a command with repeat it will be send done as 1 ""transaction"" preventing anything else from hass to send a command in the middle. automatic config update. if anything is changed on the hub (i.e. device added, rename, ...) then it is detected and configuration is updated. the harmony files with the configuration are automatically updates as well then. unique message identifications ensuring that hub responses are correctly identified and processed related issue (if applicable): fixes #19465, fixes #19466 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#7982 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> use aioharmony for async </cmt> <cmt> use aioharmony to interact with harmony hub. due to this following improvements: </cmt> <cmt> -) setting of available state for entity </cmt> <cmt> -) automatic config update if configuration changes (including updating file containing config) </cmt> <cmt> -) allow using of device name instead of number </cmt> <cmt> -) when sending command with repeat, nothing else will be able to put a ir command in between </cmt> <cmt> requirements updated </cmt> <cmt> version update for fix </cmt> <iss> harmony fails to update 0.85.0dev0 </iss> <iss> new (0.84.5) harmony component fails with ""websockets.exceptions.invalidstatuscode"" on 3 of 4 harmony hubs </iss>",use aioharmony for remote.harmony platform
3415,"<desc> will help on #3197 and fix #3620 cppwinrt generated huge .pch. this is an example to remove them from pipeline. i didn't apply them to projects in packages. if we still see disk usage issue, we can apply it too. ideas are from:  microsoft reviewers: open in codeflow </desc> <cmt> delete pch after build </cmt> <cmt> change files </cmt> <iss> optimize the pipeline by reduce the disk usage and build time </iss>",delete .pch after build on pipeline
3416,"<desc> hi, this pr add the psu-*request headers. source: stet framework documentation - section 3.6. stet interactions documentation - section 6.1.1.2. thanks in advance </desc> <cmt> add psd2 psu headers </cmt> <cmt> source: </cmt> <cmt> section 3.6 </cmt> <cmt> add psd2 spu headers </cmt> <cmt> source: </cmt> <cmt> section 6.1.1.2 </cmt>",add psd2 psu request headers.
3417,"<desc> closes #17629 there are 2 main reasons these tests were flaky after #16730: it's possible for the log to update before or after the response is received (on the order of milliseconds). this means that tests that assert on the log after a response sometimes have to wait for the log to be updated. xhr logs are created by the xhr.js code still since they can be totally stubbed by cy.route(), which will bypass #16730 entirely. but if the xhr does go out-of-browser, the xhr log will be updated with proxy logging metadata either before or after the xhr onload event fires. (similar to (1)) also bonus attempted to fix flake in net_stubbing_spec. </desc> <cmt> chore(tests): fix flake in proxy-logging-spec </cmt> <cmt> chore(tests): address flake in xhr_spec </cmt> <iss> address flaky proxy logging tests </iss>",fix flake in net stubbing/xhr/proxy logging tests
3418,"<desc> adds a github workflow to check if any .js or .jsx files were added in a pr, and adds a comment to the pr asking to change the files to use typescript. this check always passes and will never prevent merge. comments when a .js file is added: skips the comment step when no js files are added: test plan add a .js file to this pr and see the message appear. see the comment step skip when no js is added. also test the jq command locally to ensure it works will all file extensions requires db migration. confirm db migration upgrade and downgrade tested. to: @ktmud @john-bodley @kristw @nytai @graceguo-supercat </desc> <cmt> add workflow preventing non typescript files </cmt> <cmt> create comment_preferring_typescript.md </cmt>",add workflow preferring typescript files
3419,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> update readme badge for github ci </cmt> <cmt> run github ci everyday as was done in travis </cmt>,update related to the change in ci testing
3420,"<desc> previously the syntax serialization test printed each top-level decl individually. this now prints them as an array of top-level decls. </desc> <cmt> serialize topleveldecls as an array of raw syntax nodes, instead of one-after-another. </cmt> <cmt> add tests for multiple decls </cmt>",serialize top level decls as an array
3421,"<desc> we have git_treebuilder_insert and append_entry which are used by different codepaths to append entries to the tree we're about to create. the checks in the latter were deficient as it never learnt to verify the target exists like the former did. this can lead to creating a tree pointing to an invalid objects if the index was unonwed and thus it itself could not do the checks during the index entry insertion. extract a single function to do these checks and use it in both. in append_entry we still avoid checking those entries that already existed in a tree we read from disk to allow users to work with repositories which already have some invalid data. </desc> <cmt> index: add failing test for writing an invalid tree from an unowned index </cmt> <cmt> when the index does not belong to any repository, we do not do any checks of the </cmt> <cmt> target id going in as we cannot verify that it exists. </cmt> <cmt> when we then write it out to a repository as a tree, we fail to perform the </cmt> <cmt> object existance and type-matching check that we do in other code-paths. this </cmt> <cmt> leads to being able to write trees which point to non-existent blobs even with </cmt> <cmt> strict object creation enabled. </cmt> <cmt> tree: unify the entry validity checks </cmt> <cmt> we have two similar functions, git_treebuilder_insert and append_entry which </cmt> <cmt> are used in different codepaths as part of creating a new tree. the former </cmt> <cmt> learnt to check for object existence under strict object creation, but the </cmt> <cmt> latter did not. </cmt> <cmt> this allowed the creation of a tree from an unowned index to bypass some of the </cmt> <cmt> checks and create a tree pointing to a nonexistent object. </cmt> <cmt> extract a single function which performs these checks and call it from both </cmt> <cmt> codepaths. in append_entry we still do not validate when asked not to, as this </cmt> <cmt> is data which is already in the tree and we want to allow users to deal with </cmt> <cmt> repositories which already have some invalid data. </cmt>",check object existence when creating a tree from an index
3422,"<desc> fixes netdata/marketing#222 this pr adds a few links to the database engine calculator i built a few weeks ago. in netdata/learn#133, i changed up the navigation to surface all of this content better. in addition, i added some manual descriptions to these pages to help boost their seo value. component name database docs </desc> <cmt> add links and calculator .md </cmt> <cmt> refactor to learn </cmt>",add links to promote database engine calculator
3423,"<desc> this pr fixes a bug where pixelpaint would crash when opening a .pp file with layer options, like visibility, set. also clear layerlistwidget and layerpropertieswidget when closing the last tab. </desc> <cmt> pixelpaint: add layer to image before setting properties </cmt> <cmt> previously when opening an image with layers that had properties like </cmt> <cmt> visibility set, pixelpaint would crash when trying to trigger </cmt> <cmt> layer_did_modify_properties() without in image. avoid this by </cmt> <cmt> adding the layer to the image before setting the properties. </cmt> <cmt> pixelpaint: reset layer widgets when closing last tab </cmt> <cmt> when closing the last tab the layer list widget and layer properties </cmt> <cmt> widget did not reset since they still had a pointer to the image. </cmt>",don't crash when opening a .pp file with layer properties set
3424,"<desc> with this change, we apply the common test config automatically to all newly created test tasks instead of opting in specifically. for plugin authors using the plugin externally this means that the configuration will be applied to their randomizedtestingtasks as well. the purpose of the task is to simplify setup and make it easier to change projects that use the test task but actually run integration tests to use a task called integtest for clarity, but also because we may want to configure and run them differently. e.x. using different levels of concurrency. </desc> <cmt> apply common test config automatically </cmt> <cmt> with this change, we apply the common test config automatically to all </cmt> <cmt> newly created tasks instead of opting in specifically. </cmt> <cmt> for plugin authors using the plugin externally this means that the </cmt> <cmt> configuration will be applied to their randomizedtestingtasks as well. </cmt> <cmt> the purpose of the task is to simplify setup and make it easier to </cmt> <cmt> change projects that use the test task but actually run integration </cmt> <cmt> tests to use a task called integtest for clarity, but also because </cmt> <cmt> we may want to configure and run them differently. </cmt> <cmt> e.x. using different levels of concurrency. </cmt> <cmt> remove extensions to create integration tasks </cmt>",auto configure all test tasks
3425,<desc> related issue (if applicable): fixes # </desc> <cmt> added motordelay to enhance calibration </cmt> <cmt> some electronic shutters have up to 1sec before the motor starts. this can cause calibration issues </cmt> <cmt> update xdrv_27_shutter.ino </cmt> <cmt> update settings.h </cmt>,enhance calibration for shutters with delay in motorstart
3426,"<desc> confluence supports weather fanart by manually downloading, installing and configuration using the instructions found in a sticky on the forum. far from ideal imo. let's make things a bit easier, since we can use image resources in jarvis. </desc> <cmt> remove dead code </cmt> <cmt> update weather fanart support for jarvis </cmt>",update weatherfanart support for jarvis
3427,<desc> i added the axes helper temporarily because the model is inverted or flipped and i was trying to get a frame-of-reference. you can remove the helper if you want. :-) i did not otherwise alter the functionality of the example. </desc> <cmt> clean up </cmt> <cmt> update screenshot </cmt>,pcd loader example: clean up
3428,"<desc> closes #24966 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry because datetimeindex and timedeltaindex intersections are similar, i have moved the intersection function of both classes up into datetimelike after discussions with @reidy-p @jorisvandenbossche. at the same time for periodindex i have used index.intersection instead. additionally i have added some tests to timedeltaindex recycling some tests from datetimeindex. re-open from #25121 </desc> <cmt> moving intersection method from datetimeindex and timedeltaindex to datetimelike. point periodindex intersection to index.intersection </cmt> <cmt> add tests for timedeltaindex </cmt> <cmt> add whatsnew </cmt> <cmt> fixing isort issue </cmt> <cmt> isort issue </cmt> <cmt> update whatsnew </cmt> <cmt> update docstrings </cmt> <cmt> parametrize tests </cmt> <cmt> add compatibility of super with python2 </cmt> <iss> timedeltaindex.intersection has no `sort` option. </iss>",move intersection functions for datetimeindex and timedeltaindex to datetimelike and added new tests
3429,"<desc> due to it seems currently both azure pipeline and github actions cannot support the power-off/turn-on machines. even with the vm scale set in azure pipeline, it needs at least one machine stand by. i know there are some external solutions, but they seems to require my azure (microsoft) account permission, which seems to violate our policy. #3424 (comment) machine with nvidia gpu is always turned on and i don't see any reasons to not run cuda jobs on it for every pr in this case. running cuda jobs on a regular basis will make us sure that no one new pr breaks cuda source code. cuda jobs cannot be run in parallel but the duration of all 3 jobs i set in this pr are about 20 min. is it ok? </desc> <cmt> update setup.sh </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update readme.md </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update setup.sh </cmt> <cmt> update setup.sh </cmt> <cmt> update setup.sh </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt> <cmt> update cuda.yml </cmt>",improve and run cuda jobs for every commit and pr
3430,"<desc> 1) fix: markline symboloffset doesn't work bug resolves #9325 resolves #14106 resolves #4771 2) feat: markline.symbolrotate can be an array to specify symbol rotation at the two endpoints. related #12736, #12392, #12388 3) feat: add markline.symbolkeepaspect and fix symbolkeepaspect doesn't work bug. 4) feat: symboloffset can be a callback function resolves #12495 #4771 #9325 #14106 #12495 #12392 (comment) usage are there any api changes? the api has been changed. please refer to test/markline-symbolrotate.html and test/symbol3.html. please squash the commits into a single one when merge. </desc> <cmt> 1) fix: markline symboloffset doesn't work bug </cmt> <cmt> - resolves #9325 </cmt> <cmt> - resolves #14106 </cmt> <cmt> - resolves #4771 </cmt> <cmt> 2) feat: markline.symbolrotate can be an array to specify symbol rotation at the two endpoints. </cmt> <cmt> - related #12736, #12392 </cmt> <cmt> 3) feat: add markline.symbolkeepaspect and fix symbolkeepaspect doesn't work bug. </cmt> <cmt> 4) feat: symboloffset can be a callback function, close #12495. </cmt> <cmt> fix(markline): remove unexpected dev code. </cmt> <iss> marklinesymboloffset </iss> <iss> symboloffset not working in markline data </iss> <iss> symboloffset as callback function </iss> <iss> echart5.0.1 markline symboloffset </iss>",fix a bug that markline symboloffset doesn't work and some other issues.
3431,"<desc> addresses issue #5094 removed apparent duplication in test, included test table with default value using nonstandard sequence for primary key as seen in my postgres 9 environment tested using postgresql 9.0.4/ruby 1.9.3-p125/ps 0.13.1 </desc> <cmt> restored ability to identify id and sequence from tables relying on a nonmatching sequence default value for pk. </cmt> <cmt> removed commented line. 3434 tests, 10531 assertions, 0 failures, 0 errors, 31 skips </cmt>",restoring ability to derive id/sequence from tables with nonstandard sequences for primary keys
3432,"<desc> refs #9178 this moves the code that is related to managing the app lifecycle & sandbox into the /services/ folder, so that server/apps only contains internal apps. it also moves the individual app tests to the /tests/ folder. this is because those tests were assumed to be unit tests, but not all of them were. the subscribers tests were functional route tests. by doing this, we reveal the true level of unit testing of the apps code: before: after: this makes it clear that the app lifecycle needs deeper unit testing & probably should feed into the discussion about moving one set of tests (either integration or functional). note: 2 timezone-related tests are failing on my local machine this morning, which i guess is dst-change related. </desc> <cmt> moved app handling code into services/apps </cmt> <cmt> refs #9178 </cmt> <cmt> - apps is a service, that allows for the app lifecycle </cmt> <cmt> - /server/apps = contains internal apps </cmt> <cmt> - /server/services/apps = contains code for managing/handling app life cycle, providing the proxy, etc </cmt> <cmt> split apps tests into separate files </cmt> <cmt> moved app tests into test folders </cmt> <cmt> - problem: not all the tests in apps were unit tests, yet they were treated like they were in gruntfile.js </cmt> <cmt> - unit tests now live in /test/unit/apps </cmt> <cmt> - route tests now live in /test/functional/routes/apps </cmt> <cmt> - gruntfile.js has been updated to match </cmt>",moved apps to /services/ & moved individual tests
3433,"<desc> description: currently there is no support for some of the advanced (and highly custom) hobbyboards onewire sensors. some of us still use those.  additionally, this change adds support for a remote owserver instance.  this allows you to run your onewire on a pi in a remote location, and then connect to the owserver on port 4304 rather than require local access to the device. add support for hobbyboards sensors: hub, humidity, moisture, pulsecounter add support for an owserver running on a remote host related issue (if applicable):  na pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#11460 example entry for configuration.yaml (if applicable): sensor: - platform: onewire host: my.pi.net port: 4304 names: 1d.03a70d000000: 'sprinkler water usage' ef.f49020150000: 'lawn' ef.bca620150000: 'cave hub' ef.f06120150000: 'sprinkler box' checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> add support for hobbyboards sensors: hub, humidity, moisture, pulsecounter </cmt> <cmt> add support for an owserver running on a remote host </cmt> <cmt> cleanup and fixes for style/etc </cmt>",add onewire devices and owserver remote host support
3434,"<desc> this pr introduces a num-quic-threads option, which can be used to limit the number of threads that will do quic processing. this is a way for deployments to progressively switch to quic while mitigating the cpu impact in might have on a given node. </desc> <cmt> limit the number of cpus that will process quic traffic </cmt> <cmt> accept a negative value, to explicitely disable the limit </cmt> <cmt> simplify the code to avoid having to resort to atomic operations (thanks kazuho for the idea) </cmt>",restrict the cpus running quic to a subset
3435,<desc> detect and diagnose an attempt to convert non-class or class-constrained type to anyobject. </desc> <cmt> [constraintsystem] add a fix to allow conversion between non-class type and anyobject </cmt> <cmt> [diagnostics] improve diagnostic for invalid conversion to anyobject </cmt>,port invalid conversion to anyobject diagnostic
3436,<desc> adds the following: bank dataset (see #228) categorical feature preparation example (see #867) categorical feature rule preparation example (see #804) efficient training for many models (see #879) </desc> <cmt> add efficient demo for lightgbm </cmt> <cmt> add bank dataset and more examples </cmt>,add more examples and bank dataset
3437,"<desc> what do these changes do? linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [sgd] replaced class resources to the one in ray.tune.trial </cmt> <cmt> moved resources from ray.tune.trial to new file ray.tune.resources </cmt> <cmt> added new file ray/tune/resources.py </cmt> <cmt> fix bugs </cmt> <cmt> fixed bugs after running test_pytorch.py </cmt> <cmt> fix lint </cmt> <cmt> set use_gpu </cmt> <cmt> lint </cmt> <cmt> lint </cmt> <cmt> initial commit for trainable </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> added pytorch_trainable, not yet working code </cmt> <cmt> pytorch trainable now works. not yet tested distributed </cmt>",tune interface for pytorch multinode sgd
3438,<desc> here's my contribution to this wonderful workshop. you'll notice i: forked patchwork created a branch add-pacster collaborated with reporobot so that seems to be everything i need to request the pull. cheers. </desc> <cmt> pacster contributor added </cmt> <cmt> drew a picture :art: </cmt>,new name for the collection: pacster
3439,<desc> provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> :sparkles: add types and props for graph component </cmt> <cmt> :lipstick: change import back to double quote </cmt>,react-d3-graph type precisions for graph component
3440,<desc> related issue: fixed #21375 added a new condition to fire the hoveroff event </desc> <cmt> added a condition to catch the case where a hovered object doesn't get hoveredoff before a different object is hoveredon. </cmt> <cmt> dragcontrols fix for issue #21375 </cmt> <iss> dragcontrols not always hovering off objects </iss>,ensure hoveroff is fired correctly.
3441,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> started checkout finished pi </cmt> <cmt> finished? </cmt> <cmt> added checkout, updated api version and pi methods </cmt> <cmt> added checkout, updated api version and pi methods </cmt>","updated api in tests, updated ipaymentintentcreationoptions and added checkouts - stripe"
3442,"<desc> addresses point 5 in #14428 by modifying memory_summary to have more readable formatting when running with --no-format or when terminal size is not sufficiently large (e.g. > 137 characters). addresses point 6 in #14428 by adding a helper function in memory_utils.py that aggregates the amount of memory each reference type uses within a group. addresses point 7 in #14428 by adding support for unit conversions in displaying object sizes (e.g. b, kb, mb, gb) with ray memory --units=. addresses point 8 in #14428 by adding the ability to specify the number of entries displayed per group with ray memory --n. the full view now looks like the following: the unformatted view looks like the following: #14428 i've run scripts/format.sh to lint the changes in this pr. cc: @rkooo567 </desc> <cmt> better formatting when terminal size doesn't support tabular </cmt> <cmt> summary now displays size of reference types </cmt>",ray memory improvements: format and summary
3443,"<desc> add a yarn update-dictionary script to call scripts/update-dictionary.js for updating the dictionary with new words. add a message at the end of yarn lint:docs with instructions for adding words: found linting errors in the docs. to add new words to the dictionary, run yarn update-dictionary. fixes: #25268 </desc> <cmt> add better documentation for the dictionary </cmt> <cmt> add message saying what to do if misspellings </cmt> <iss> retext-spell failing ci on warnings </iss>",add better messaging on how to add new words to the dictionary for spell-check
3444,"<desc> restore the nacosconfigurationproperties yaml() method to be compatible with older clients format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> refactor(api): restore the yaml() method to be compatible with older clients </cmt> <cmt> docs(api): add details desc </cmt>",fix @nacosconfigurationproperties to support old version
3445,"<desc> the self-hosted build is still broken to me; it aborts with userspace(26) assertion failed: value >= 0 stdlib.cpp:690 in long long unsigned int strtoull(const char*, char**, int) i guess strtoull() is not supposed to do that when given -something as input. </desc> <cmt> build: ensure ""install"" is a phony target </cmt> <cmt> see </cmt> <cmt> ports: do not download sources if they're already present </cmt> <cmt> when running ./package.sh to rebuild an already installed port, we would not </cmt> <cmt> want to spend time re-downlodaing the same tarball again. ideally, this should </cmt> <cmt> use some sort of hash checking to ensure the file is not truncated or something, </cmt> <cmt> but this is good enough for now. </cmt> <cmt> ports: update gcc to 9.2.0 </cmt> <cmt> to keep the self-hosting build working (note that it's </cmt> <cmt> still broken even with this change). </cmt> <cmt> this reuses the patch from commit c73aa662bba17b50404d3820655847cc9c4c6a44. </cmt> <cmt> ports: build gcc with -j $(nproc) </cmt> <cmt> gcc is a huge project that takes a lot of time to build; let's at least </cmt> <cmt> make this a little less painful by using all the available cpu cores. </cmt>",upgrade the gcc port and misc stuff
3446,"<desc> seed all cuda devices when torch.manual_seed is called (issue #1615) </desc> <cmt> added checks to cudnn convolution for stride, dilation, kernel size and num input planes </cmt> <cmt> add convolution_shape_checks for cudnn convs </cmt> <cmt> torch.manual_seed now seeds all cuda devices too </cmt>",torch manual seed to seed cuda devices
3447,"<desc> i removed the theano dependency by using keras backend functions the tests methods failed because in settings we didn't specify the 'gru_encode' param - fixed it motivation and context this will allow us to use the model with tensorflow instead of theano only. how has this been tested? i ran the tests, all passing. types of changes breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. </desc> <cmt> fix parikh entailment test methods bug with settings </cmt> <cmt> remove theano dependency, using keras backend functions </cmt>",remove theano dependency from parikh model + small bug fix
3448,"<desc> fixes #6228. getrawdelta() has been deprecated as, at least for now, it's a duplicate of getdelta(). the line mean.clear() on setcontinuousrendering() can be safely removed because it was added to fix an issue caused by the smoothing ( </desc> <cmt> fix #6228 </cmt> <cmt> changes </cmt> <iss> smoothed delta times on android and overall improvements </iss>",fix #6228. removed delta smoothing on android backend
3449,<desc> bro (www.bro.org) is a network security monitor with its own scripting language (.bro) and the ability to provide functionalities from c/c++ (.bif) mixed with the own language. i only added these two filetypes to the lang.c and adjusted the related test. </desc> <cmt> add filetypes for bro. </cmt> <cmt> added the output of the bro filetype. </cmt>,add filetypes for the bro framework
3450,<desc> what do these changes do? this pr does some code scrubbing and removes compiler warnings. i'm also making the warnings fatal so they won't accumulate in the future. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix comparisons </cmt> <cmt> more warnings </cmt>,fix compiler warnings and make warnings fatal
3451,<desc> this pull request refactors the snapcraft.yaml and its associated electron-launch wrapper to address two bugs for the linux snap package. #63194 #57019 </desc> <cmt> electron-launch: use bash </cmt> <cmt> electron-launch: correctly map the /snap directory on fedora </cmt> <cmt> electron-launch: add architecture detection </cmt> <cmt> electron-launch: create $xdg_cache_home </cmt> <cmt> relocate $xdg_cache_home within the snaps common user data. </cmt> <cmt> electron-launch: abi compatible gdk pixbuf modules </cmt> <cmt> use abi compatible gdk pixbuf modules from within the snap and build gdk-pixbuf-loaders.cache in the snaps common user data. </cmt> <cmt> snapcraft.yaml: add the gnome 3.26 ppa. </cmt> <cmt> adds the ppa for the gnome 3.26 framework which is maintained by the ubuntu desktop team. </cmt> <cmt> this ppa includes gtk3 and gnome3 components used to create the gnome 3.26 framework snap for ubuntu 16.04. </cmt> <cmt> * fixes: </cmt> <cmt> * fixes: </cmt> <cmt> snapcraft.yaml: update stage-packages </cmt> <cmt> clean up the stage-packages: to drop any unnecessary libraries and ensure all required libraries to maintain abi compatibility are bundled in the snap. </cmt> <cmt> snapcraft.yaml: remove unnecessary data from the snap </cmt> <cmt> snapcraft.yaml: remove braces from ${snap} in command: </cmt> <cmt> snapcraft.yaml: fallback to xwayland if running in a wayland session </cmt> <cmt> snapcraft.yaml: source glib schemas from within the snap. </cmt> <cmt> snapcraft.yaml: add the url-handler </cmt>,snapcraft update. fixes #63194 fixes #57019
3452,"<desc> a few fixes for object.setprototypeof() (has a test now) and proper implementations of  reflect.isextensible() and reflect.preventextension(). </desc> <cmt> libjs: return specified object from object.setprototypeof() </cmt> <cmt> we were leaking an empty value. </cmt> <cmt> libjs: don't assume object.setprototypeof() prototype value is an object </cmt> <cmt> we're crashing otherwise. also it was not possible to set the prototype </cmt> <cmt> to null. </cmt> <cmt> libjs: disallow changing the prototype of non-extensible objects </cmt> <cmt> object::set_prototype() now returns a boolean indicating success. </cmt> <cmt> setting the prototype to an identical object is always considered </cmt> <cmt> successful, even if the object is non-extensible. </cmt>","object.setprototypeof() fixes & reflect.{isextensible,preventextension}()"
3453,<desc> i had issues with a project of mine where i'm trying to abstract a crappy backend with request. somehow i have to make a request with duplicate keys and querystring doesn't allow it. </desc> <cmt> added support for manual querystring in form option </cmt> <cmt> enables greater flexibility in setting the form for a post method. </cmt> <cmt> objects do not accept duplicate keys </cmt> <cmt> updated readme </cmt>,manually enter querystring in form option
3454,"<desc> xcode 10's build system will error out if you try to embed the same framework in two different build phases (which happens if you add flutter.framework from cocoapods to our default xcode template, e.g. when you add a plugin).  the error message that is given isn't very helpful - this script detects that condition and prints a more helpful error message. ideally, we would fix this for the user when cocoapods are added to the project, but we don't have a good way to do that right now without introducing more new depdencencies or writing a dart based xcode project parser/editor. </desc> <cmt> make it easier to add2app for ios </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> use local engine if xcconfig says so </cmt> <cmt> newline </cmt> <cmt> check for bad configuration in xcode10 </cmt>",check for duplicative flutter.framework emeddings when building for xcode 10
3455,"<desc> fix a case where test is sensitive to ""./"", which is removed in the swift-driver. since swift-driver outputs -driver-show-incremental as diagnostic remarks, fix tests to read stderr for those. </desc> <cmt> check stderr when looking for incremental remarks. </cmt> <cmt> fix another test </cmt>",fix test to be more compatible with swift-driver
3456,<desc> adds recording of close of a stand-by task to the task-closed metric adds unit tests to verify the recording </desc> <cmt> record close of standby task </cmt> <cmt> record close of stand-by task </cmt> <cmt> corrected and improved unit tests. </cmt>,add missing recording of close of stand-by task
3457,"<desc> added back type parameters for mongoose.model from the previous definitions so that: interface example { names: string[] } var m = mongoose.model<example>(...); m.findone({}, function (err, doc) { doc.names.foreach(...); }); provides correct type-checking. </desc> <cmt> adds type parameter for mongoose.model, fixes #10110 </cmt> <cmt> adds comments explaining modelquery </cmt> <cmt> adds test cases for model type parameters </cmt>",adds type parameter back to mongoose.model class fixes #10110
3458,<desc> fixes incorrect tests where distributed methods are not actually tested. extract histogram builder to be a reusable module. perf dataset train time accuracy before higgs 191.195842235989 0.7342790909090909 covtype 74.0480548529886 0.9398466476769103 after higgs 184.16188054496888 0.7342790909090909 covtype 68.06914013501955 0.9398466476769103 </desc> <cmt> try to replace the original impl. </cmt> <cmt> cache. </cmt> <cmt> remove. </cmt> <cmt> move into header. </cmt> <cmt> common. </cmt> <cmt> start moving tests. </cmt> <cmt> unused code. </cmt> <cmt> move more tests. </cmt> <cmt> dead code. </cmt> <cmt> pass build hist test. </cmt> <cmt> start working on sync test. </cmt> <cmt> get it to compile. </cmt> <cmt> cleanup. </cmt>,extract histogram builder from cpu hist.
3459,"<desc> adds via support to the kbdfans kbd6x. these changes are working perfectly on my board, but require the changes to core in pull #8663 to compile properly (related issue: #8604). my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add via keymap </cmt> <cmt> update vid/pid </cmt> <cmt> - update vid/pid to match other kbdfans keyboards </cmt> <cmt> - flesh out keyboard description </cmt> <cmt> add missing newline. whoops. </cmt>",via support for the kbdfans kbd6x
3460,"<desc> while the api are in swift modules and in the standard library, they are not included in the swift interface file because they are internal. by marking the api as @usablefrominline, they are included in the swift interface file. i added the ability to generate the declaration for _getmainexecutor in #39941, i missed _asyncmaindrainqueue, so i've added that here. it shouldn't be necessary when the compiler is paired up with the correct version of the standard library, but it appears that's not always happening, so this is taking care of both of those issues. i've manually inspected the resulting swift interface file generated locally and have ensured that the correct declarations are emitted: @available(macos 10.15, ios 13.0, watchos 6.0, tvos 13.0, *) @usablefrominline @_silgen_name(""swift_task_asyncmaindrainqueue"") internal func _asyncmaindrainqueue() -> swift.never #if compiler(>=5.3) && $builtinexecutor @available(macos 10.15, ios 13.0, watchos 6.0, tvos 13.0, *) @usablefrominline @_silgen_name(""swift_task_getmainexecutor"") internal func _getmainexecutor() -> builtin.executor #endif </desc> <cmt> conjure up asyncmaindrainqueue </cmt> <cmt> the asyncmaindrainqueue is also declared internal, so it won't show up </cmt> <cmt> in the swiftinterface file. </cmt> <cmt> the expected declaration is: </cmt> <cmt>  </cmt> <cmt> @available(swiftstdlib 5.5, *) </cmt> <cmt> @_silgen_name(""swift_task_asyncmaindrainqueue"") </cmt> <cmt> internal func _asyncmaindrainqueue() -> never </cmt> <cmt>  </cmt> <cmt> adding @usablefrominline to needed api </cmt> <cmt> getmainexecutor and asyncmaindrainqueue function declarations are needed </cmt> <cmt> to compile programs with the asyn-main function. the functions are </cmt> <cmt> declared internal, so they don't show up in the swift interface files. </cmt>",include missing _getmainexecutor and _asyncmaindrainqueue in concurrency swiftinterface
3461,"<desc> as discussed in #7372, this pr contains commits that change actiondispatch::session::cookiestore to inherit from rack::session::abstract::id instead of rack::session::cookie. </desc> <cmt> fix cookiestore middleware inheritance hierarchy s.t. it inherits from rack::session::abstract::id rather than rack::session::cookie. </cmt> <cmt> revert cb3181e - no longer required. </cmt>",modify cookiestore middleware inheritance to avoid subclassing rack::session::cookie [fix for #7372]
3462,"<desc> this is a minimum viable product for ray autoscaler integration with kuberay. it is not ready for prime time/general use, but should be enough for interested parties to get started (see the documentation in kuberay.md). i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add container for autoscaler </cmt> <cmt> add more files </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> add node provider </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> wip </cmt> <cmt> add __init__.py </cmt> <cmt> add import </cmt> <cmt> use right ray version </cmt> <cmt> update </cmt> <cmt> talk to k8s api server directly </cmt> <cmt> update </cmt>",ray autoscaler integration with kuberay (mvp)
3463,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> update index.d.ts </cmt> <cmt> update react-native-base64-tests.tsx </cmt> <cmt> update index.d.ts </cmt>,update type definitions for react-native-base64 v.0.2.1
3464,"<desc> this layout is different from the default keymap as follows: swaps the location of the esc, and tab keys. removes dvorak moves the backlight key to the lower, and raise layers where dvorak was. turns the enter key into a shift key when held, and an enter key when tapped. moved the control key to where the backlight key was located (bottom left key) created a tenkey layer toggle next to the lower key to git access to a tenkey. the tenkey is the right side of the keyboard, and the f1-12 keys are on the left. this allows me to start removing the f1-12 keys from the raise/lower layers if i desire to do so. the del, pgdn, pgup, home, end keys are on the tenkey layer. </desc> <cmt> adding my initial layout </cmt> <cmt> adding my initial layout </cmt> <cmt> added a tenkey layer and moved the del key </cmt> <cmt> added pageup, pagedown, home, and end keys </cmt>",a slightly different default layout
3465,"<desc> note: before submitting this pull request, please review our contributing guidelines. this pr migrates unittest from case to pytest. this pr does not remove case completely but just replaces the easy to migrate parts to pytest </desc> <cmt> migrate case to unittest.mock </cmt> <cmt> use pytest.importorskip instead of case.skip </cmt> <cmt> use pytest.mark.skip instead of case.skip.todo </cmt> <cmt> use pytest.importorskip instead of case.skip in t/unit/tasks/test_result.py and t/unit/security/case.py </cmt> <cmt> migrate skip.if_win32 and skip.if_pypy to pytest </cmt> <cmt> remove unused import </cmt> <cmt> remove @skip.if_jython since it does not support python2 </cmt> <cmt> replace skip.unless_environ with pytest.mark </cmt> <cmt> replace skip.unless_symbol with pytest.mark.skipif </cmt> <cmt> make flake8 happy </cmt>",migration of case to pytest
3466,"<desc> this pr fixturizes the last constants (base_functions and no_nan_functions) in consistencybase, and take corresponding tests out of class. after this one, only constants in base class needs to be fixed (if base is also wanted to be cleaned) </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 17038 </cmt> <cmt> revert change </cmt> <cmt> revert change </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixturize functions </cmt> <cmt> fixup </cmt>",fixturize constant functions in consistencybase
3467,"<desc> the second commit in this pr will stop printing the macro definition site in backtraces, which cuts their length in half and increases readability (the definition site was only correct for local macros). the third commit will not print an invocation if the last one printed occurred at the same place (span). this will make backtraces caused by a self-recursive macro much shorter. (a possible alternative would be to capture the backtrace first, then limit it to a few frames at the start and end of the chain and print ... inbetween. this would also work with multiple macros calling each other, which is not addressed by this pr - although the backtrace will still be halved) example: macro_rules! m { ( 0 $($t:tt)* ) => ( m!($($t)*); ); () => ( fn main() {0} ); } m!(0 0 0 0 0 0 0 0 0 0 0 0 0 0 0); on a semi-recent nightly, this yields: test.rs:3:21: 3:22 error: mismatched types: expected (), found _ (expected (), found integral variable) [e0308] test.rs:3  () => ( fn main() {0} ); ^ test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:2:23: 2:34 note: expansion site test.rs:1:1: 4:2 note: in expansion of m! test.rs:6:1: 6:35 note: expansion site test.rs:3:21: 3:22 help: run rustc --explain e0308 to see a detailed explanation error: aborting due to previous error after this patch: test.rs:3:21: 3:22 error: mismatched types: expected (), found _ (expected (), found integral variable) [e0308] test.rs:3  () => ( fn main() {0} ); ^ test.rs:2:23: 2:34 note: in this expansion of m! test.rs:6:1: 6:35 note: in this expansion of m! test.rs:3:21: 3:22 help: run rustc --explain e0308 to see a detailed explanation error: aborting due to previous error </desc> <cmt> make print_macro_backtrace non-recursive </cmt> <cmt> don't print the macro definition site in backtraces </cmt> <cmt> this halves the backtrace length. the definition site wasn't very useful </cmt> <cmt> anyways, since it may be invalid (for compiler expansions) or located in </cmt> <cmt> another crate. since the macro name is still printed, grepping for it is </cmt> <cmt> still an easy way of finding the definition. </cmt> <cmt> don't print duplicate macro backtrace frames </cmt>",make macro expansion backtraces shorter
3468,"<desc> should fix issue opencv/opencv_contrib#184 coupled with pr opencv/opencv_contrib#197 methods from base classes was not available in subclasses for objects put into nested namespaces. replaced classinfo.bases list with single classinfo.base value, since multiple base classes are not supported. store _-separated class name in classinfo.base field, because ::-separated value is not used added test calling methods from different inherited classes to check their existence (cv::stereobm and cv::ml::boost) note: the test should be split and moved to corresponding modules, but corresponding mechanism is not yet implemented for python wrappers, so it will be left as is for a while. </desc> <cmt> fix python submodules inheritance detection </cmt> <cmt> add python test for inheritance structure generation </cmt>",fix python wrappers for inherited modules
3469,"<desc> tasmota uses irremoteesp8266 for ir hvac functionality, the relevant code is in tasmota\xdrv_05_irremote_full.ino . specifically, iracutils::decodetostate and ac.sendac functions are used. those functions expect the caller to pass a previous ac state to them. this is required to support air conditioning devices that use a differential ir protocol (they send changes rather than state). without considering the previous state, for these devices, any irhvac instruction where power==on will be transmitted as ""toggle power"" by irremoteesp8266. this completely breaks all irhvac functionality for such vendors as whirlpool, airwell and others. this pr implements a working poc/feature where a state is added to the logic. the functionality can be implemented as an ""option"". also a poc for setting the initial state is implemented as a piggy-back on top of an existing ""model"" field. this is useful if one wants to sync the state with the actual state of the ac without generating an ir transmission. the code is relatively simple. state transitions are implemented in irremoteesp8266. tasmota merely needs to hold the structure and pass it around. if you wish to improve on this implementation i would suggest an additional ""option"" for enabling this state management (can be false by default). also a special field can be added to the irhvac command ( this was not tested functionally on an esp32. there is nothing in the code that seems to be platform specific. i don't have an esp32 based ir blaster, those are not common. the build passes though. if this is a big issue lmk. @crankyoldgit fyi </desc> <cmt> switch to a custom irremoteesp8266 branch </cmt> <cmt> implement state for acs with toggle properties </cmt> <cmt> try whirlpool fix </cmt> <cmt> add support for setting state without tx </cmt> <cmt> folder change </cmt> <cmt> folder change </cmt> <cmt> folder change </cmt> <cmt> ignores </cmt> <cmt> some cleanup for upstream </cmt>",add support for stateful acs using irremoteesp8266
3470,"<desc> as noted in #9086, emscripten_async_queue_on_thread is a misleading name since it is only async if calling another thread - if we are already on the same thread, we just do the call immediately. fixing that by making it actually async isn't an option, since if the current thread never returns to the main event loop, an async event would never happen. we have to fire it synchronously in that case, but we don't know if that is the case or not (it depends on user code). it would be less efficient for the common case. this pr renames emscripten_async_queue_on_thread to emscripten_call_on_thread_maybe_async. the maybe_async part indicates that it may be async but won't always be (again, it is async if we are going to run on another thread). for completeness, a new emscripten_call_on_thread_async is added which is always asynchronous, even on the main thread. that can be a simpler model to reason about for users. that is a breaking change for people using that api. i would guess not many have since while it is in threading.h it isn't documented elsewhere. and this pr should help some of those users (including the one that suggested this pr), so overall it seems worth a breaking change. fixes #9086 </desc> <cmt> fix #9086 </cmt> <cmt> fix </cmt> <cmt> cleanup and fix </cmt> <cmt> fixes </cmt> <cmt> update symbols </cmt> <cmt> fixes </cmt> <iss> emscripten_async_queue_call_on_thread is sync if on the same thread </iss>",refactor and rename confusing pthreads async functions
3471,"<desc> fixes #5389 includes a test that fails on master, passes before #5138, and now passes with included fix. </desc> <cmt> add failing test for named attribute </cmt> <cmt> fix test crudely </cmt> <cmt> remove comment </cmt> <cmt> add simplest possible failing test </cmt> <iss> modelserializer custom named field source evaluates to true instead of field_name </iss>",fix modelserializer custom named fields with source on model
3472,"<desc> this way we can use codeblock with any of the fisrt line number , e.g. by doing : {% codeblock lib/hexo/index.js first_line:418 %} hexo.prototype.execfilter = function(type, data, options) { return this.extend.filter.exec(type, data, options); }; hexo.prototype.execfiltersync = function(type, data, options) { return this.extend.filter.execsync(type, data, options); }; {% endcodeblock %} </desc> <cmt> add option for first line number to tag.js </cmt> <cmt> add option for first line number to test </cmt>",added first_line option to codeblock
3473,"<desc> add resources added raspberry pi meta list, added books made by al sweigart on scratch and minecraft programming. there are lot of books here, from raspberry pi, scratch and minecraft. raspberry pi magazine books are free obviously, and books by al sweigart are available on al's websites. there is one book list and two normal books. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> added books and book lists. </cmt> <cmt> moved meta-list to a section. </cmt> <cmt> moved book from smalltalk to scratch. </cmt>",added raspberry pi book list and two other books.
3474,"<desc> for scalability reasons, we want to make the memory view as usable as possible without rendering every memory entry as a row in a table. the way we've decided to do this is to make summary statistics more easily available to users, especially for two very important use cases: figuring out your memory utilization across nodes figuring out your memory utilization per stack trace (for tracking down memory leaks) this reorganizes the view so that each group renders as a pane that can be expanded to view details about the entries inside, and adds some new functionality to the backend to allow for grouping by stack trace. note, i still need to check test status on ci and change the docs before this will be ready to merge. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> go three stack frames deep after hitting a ray function in get_py_stack instead of only one frame for additional debugging context. </cmt> <cmt> wip </cmt> <cmt> memory view grouping by stack trace or by node ip address is now working. however, i need to change around the way the page is displayed so that the grouping criteria is better displayed. </cmt> <cmt> wip </cmt> <cmt> memory view can now be grouped by stack trace or node, and summary details will be visible in a pane on a per-group basis. </cmt>",memory view group by stack trace and ui overhaul
3475,<desc> adding change to move method adduseraccount out of conditional block which checks for constraint violations </desc> <cmt> adding code for bael-4957 - spring validation in the service layer </cmt> <cmt> moving spring service layer validation code </cmt> <cmt> adding code for bael-4957 - spring validation in the service layer </cmt> <cmt> moving spring service layer validation code </cmt> <cmt> update useraccountservice.java </cmt> <cmt> moving the call to adduseraccount method out of condition to check if violations exist. </cmt> <cmt> update useraccountservice.java </cmt> <cmt> reverting changes </cmt> <cmt> adding code for bael-4957 - spring validation in the service layer </cmt> <cmt> moving spring service layer validation code </cmt> <cmt> syncing with master </cmt> <cmt> moving method adduseraccount out of conditional block which checks for contraint violations </cmt>,bael-4957-spring validation in the service layer
3476,<desc> cleaning up serial macros and filament sensor code to isolate the meaningful changes in #20327. replace debug_print_p with debug_echopgm_p. replace serialprintpgm with serial_echopgm_p or debug_echopgm_p. use other serial_echo***_p macros where possible. add multi_filament_sensor conditional to flag multiple sensors. add extui::gettool and use for extui::getactivetool. </desc> <cmt> serial macros cleanup </cmt> <cmt> filament sensor cleanup </cmt>,serial and filament sensor cleanup
3477,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. apocas/docker-modem#132 apocas/dockerode#630 the docker-modem pr adds support to pass abortsignal in the dial() method. the dockerode pr adds the corresponding option to most methods there (in various cases changing the method signatures to allow optionally passing a new options param). </desc> <cmt> add abortsignal option to docker-modem </cmt> <cmt> add abortsignal option to most dockerode methods </cmt>,add abortsignal option to docker-modem & dockerode
3478,"<desc> summary: added options for compressed cache, cacheindexandfilterblocks and hashindexallowcollision to blockbasedtableconfig added getproperty() api to rocksdb make rocksdbjava make test reviewers: yhchiang, ljin, sdong, dhruba reviewed by: yhchiang cc: leveldb differential revision: </desc> <cmt> add block based table config options </cmt>",add remaining options to blockbasedtableconfig and add getproperty() api
3479,"<desc> fixes #19825 fixes #8612 fixes #5938 this was actually broken waaaaaay back in ts 1.6 by #3641; the real underlying issue which prompted that change has since been fixed by other changes, so all this line did was break things. </desc> <cmt> badness </cmt> <cmt> revert #3641, whose original bug has been fixed by other means </cmt> <iss> object detection for ""exported variable `` has or is using name `` from external module"" </iss> <iss> cannot be named when generating declarations for re-exported classes </iss> <iss> declaration emit for aliased exports used in export assignments is broken </iss>",fix declaration emit for imported export alias specifiers
3480,<cmt> bpo-45607: add __note__ field to baseexception </cmt> <cmt> add test_note in test_exceptions </cmt> <cmt> add to traceback </cmt> <cmt> add exception group test </cmt> <cmt> remove redundant assertion </cmt> <cmt> support multi-line notes as well. test for empty string in note </cmt>,make it possible to enrich exception displays via setting their __note__ field
3481,"<desc> related issue = #2736 sorry for the large pr, primary changes reside in program.cpp, cc_program.cpp and cc_program.h. </desc> <cmt> [refactor] refactor cc backend, compile part </cmt> <cmt> clear cc_program. cc runtime part. </cmt> <cmt> remove ccprogram and use ccprogramimpl instead. </cmt> <cmt> delete comments </cmt>","refactored and unified cc backend, removed ccprogram and use ccprogramimpl instead."
3482,"<desc> @teg please have a look at the sd-ipv4ll fix! </desc> <cmt> tree-wide: use right cast macros for uids, gids and pids </cmt> <cmt> core: don't generate warnings when write access to the cgroup fs fails in --user due to eacces </cmt> <cmt> after all, in the classic hierarchy that's pretty much the default case. </cmt> <cmt> coredump: modernize error logging a bit </cmt> <cmt> journald: trivial simplification </cmt> <cmt> sd-ipv4ll: fix error path if sd-ipv4acd allocation fails </cmt> <cmt> let's make sure the destructor cannot hit the n_ref == 0 case. </cmt> <cmt> remount-fs: modernize coding style a bit </cmt> <cmt> a) use _cleanup_ where it makes sense </cmt> <cmt> b) uniformly use negative errno-style errors internally, convert to </cmt> <cmt> exit_failure/exit_success only when actually exiting. </cmt> <cmt> c) use log_oom() where appropriate </cmt> <cmt> d) fix minor memory leak in hashmap addition error path. </cmt> <cmt> e) don't pretend we could continue sensibly on oom or fork() failure </cmt> <cmt> f) use pr_set_pdeathsig to make sure clients we don't kill on error are </cmt> <cmt> cleaned up. </cmt> <cmt> g) make use of strv_make() where it's pretty to do so. </cmt> <cmt> h) simplify error paths. </cmt> <cmt> tree-wide: make macros for converting fds to pointers and back generic and use them everywhere </cmt> <cmt> siphash: fix another alignment issue </cmt> <cmt> siphash: minor coding style fixes and modernizations </cmt> <cmt> only cosmetics really, doesn't change any actual logic. </cmt>","casting fixes, another siphash24 alignment fix, and more"
3483,"<desc> we don't support variadic tuples anymore, so remove some leftover dead code. </desc> <cmt> [astdemangler] remove 'isvariadic' parameter from 'createtupletype' </cmt> <cmt> [typedecoder] remove 'variadic' argument from 'createtupletype' call </cmt> <cmt> [reflection] remove support for variadic from tupletyperef </cmt> <cmt> [remote] remove 'variadic' argument from 'createtupletype' call </cmt> <cmt> [runtime] remove 'variadic' parameter from createtupletype in metadatalookup </cmt> <cmt> [test] remove variadic tuple typeref tests </cmt> <cmt> [reflection] restore accidentally deleted code from 'visitfunctiontyperef' </cmt>",remove some dead variadic tuple code
3484,"<desc> fixes a bad merge from the branch that had st.forms updates the visual design for st.expander makes fullscreen images have captions too fixes spacing in and around forms makes captions use themable text color makes captions inside st.image look like the ones from st.caption, plus adjusts spacing in and around images and captions. </desc> <cmt> clean up spacing inside forms </cmt> <cmt> update expander visual design </cmt> <cmt> make st.caption use correct gray color </cmt> <cmt> make image captions look like st.caption, and adjust spacing around captions and images </cmt> <cmt> make fullscreen images have captions too </cmt>","visual fixes for forms, captions, images, and expanders"
3485,"<desc> this pr is support for ie10 and 11 on css renderer and solve issue #10965 the problem is that ie doesn't support transform-style: preserve-3d and nested elements will be rendered in ""flat"". to solve it: place all css3dobjects in flat (and each object should have world matrix transform including camera transform) calc z-order for ie manually (with distance from camera) also, i removed cameraelement (no needed anymore) left: ie11 with current cssrenderer center: ie11 with modified cssrenderer right chrome with modified cssrenderer </desc> <cmt> css renderer: supports ie10, 11 </cmt> <cmt> manual zorder </cmt> <cmt> nested object / camera element is no needed anymore </cmt>",supports for ie10 and ie11
3486,"<desc> after this, python setup.py install should succeed and build ray without the ui if there is no python2 executable. fixes #1073. </desc> <cmt> allow building ray without ui by setting include_ui=0. </cmt> <cmt> fix bash. </cmt>",allow ray to be built without ui by setting include_ui=0.
3487,"<desc> resolves #16349 the current implementation of impute.iterativeimputer only allows the specification of a single pair of (min, max) values to which all imputed features will be clipped. however, in many practical applications, different features might vary over different ranges. this pr adds functionality to the iterativeimputer to allow the specification of a different pair of min and max values for each feature to be imputed. these changes allow the following: leave the default min_value and max_value as none (which is the current default). in this case min and max values for all features will be set to -np.inf and np.inf respectively. allow the user to specify a single pair of numbers as min and max values for all features. in this case, the scalar min_value and max_value will be broadcast to float arrays of shape = number of features. allow the user to specify a list/array of min values and another list of max values, one value for each feature being imputed. the user can leave the min and max values of some features as none in these arrays in which case those values will be changed to -np.inf and np.inf while being cast as float arrays. since these changes do not modify the default behavior of iterativeimputer, i do not expect them to break any tests. however, i have no experience with testing while contributing to sklearn, so let me know if there is some work that i need to do wrt testing. </desc> <cmt> use list of max and min values for the features </cmt> <cmt> allow users to specify either: a) scalar, b) array/list, c) none, as min and max values. changed documentation to reflect the same </cmt> <cmt> broadcast scalar int min and max values to float array of shape num_features </cmt> <iss> provide different max and min values for each feature with iterativeimputer </iss>",enh add the possibility to pass array-like for max and min in iterativeimputer
3488,"<desc> add the collapsedheight param to the sliverappbar, allowing for users to set the minimum height when it is collapsed. sliverappbar with collapsedheight set: floating sliverappbar with collapsedheight set: sliverappbar that is floating, pinned, has a bottom widget, with collapsedheight and expandedheight set: related issues closes #21298 i added the following tests: sliverappbar expandedheight, collapsedheight pinned && floating && bottom && extratoolbarheight != 0.0 ==> 1.0 opacity !pinned && !floating && !bottom && extratoolbarheight != 0.0 ==> fade opacity before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> add collapsed height argument to sliverappbar </cmt> <cmt> add test for collapsedheight </cmt> <iss> feature request: sliverappbar should have the ability to set minimum height </iss>",add collapsed height param to sliverappbar
3489,"<desc> description: add components to homematicip_cloud: binary_sensor: shutter contact, motion detector switch: power switch and measuring power switch light: measuring light switch related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#5248 example entry for configuration.yaml (if applicable): homematicip_cloud: - accesspoint: !secret homematicip_accesspoint authtoken: !secret homematicip_authtoken - name: loc2 accesspoint: !secret homematicip_accesspoint-loc2 authtoken: !secret homematicip_authtoken-loc2 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io if the code does not interact with devices: </desc> <cmt> add support for shutter contact and motion detector device </cmt> <cmt> add support for power switch devices </cmt> <cmt> add support for light switch device </cmt>",add more homematicip cloud components
3490,"<desc> created a styledcomponent to set hight and center numbers on the count-badge on dataset-tabs. also added inline css={{...align-items:center}} to parent div - centers badge and tab-title. removed inline css from editdatasetmodals's icon.trash. this icon now matches the sizing of the other trashicon on the datasets homepage(see screenshot). countbadge: modaltrashicon datasethompagetrashicon includes db migration (follow approval process in sip-59) </desc> <cmt> update trash icon size </cmt> <cmt> changed badge icon height to 16px (using gridunits and centered text inside via line-height </cmt> <cmt> changed badge icon height to 16px (using gridunits), centered text inside via line-height, aligneditems inside div w/flex </cmt>",update dataset count badge and tash icon sizing
3491,"<desc> this change should bring keras graph performance close to legacy graph. the major problem in current code is a large number of many h2d memory copies, and the main reason for that is in the normalization layer there's a cond op that triggers input_sizes being copied for each bn layer.  setting drop_remainder avoids triggering this logic and thus improves the performance. </desc> <cmt> config threadpool, cudnn persistent bn, and grappler layout optimizer properly for resnet56 </cmt> <cmt> add tweaked tests for resnet56 </cmt> <cmt> avoid triggering the last partial batch overhead by explicitly dropping remainder </cmt>",improve keras graph performance for resnet56
3492,"<desc> fixes github issue #16606. this is a correctly-formatted version of pr #17858. the core issue is that in the case of certain random tensors, the following two lines aren't the same: rand_0s_and_1s_ds = ... gather_ds = rand_0s_and_1s_ds.map(lambda i: tf.gather([0, 1], i)) tup_ds = tf.data.dataset.zip(gather_ds, rand_0s_and_1s_ds) rand_0s_and_1s_ds = ... tup_ds = rand_0s_and_1s_ds.map(lambda i: (tf.gather([0, 1], i), i)) note that this does not fix the underlying issue of drawing multiple sampes from the underlying distribution. tested: with the new test, bazel test :resample_test fails before and succeeds after. </desc> <cmt> fixes github issue #16606. </cmt> <cmt> the core issue is that in the case of certain random tensors, the </cmt> <cmt> following two lines aren't the same: </cmt> <cmt>  </cmt> <cmt> rand_0s_and_1s_ds = ... </cmt> <cmt> gather_ds = rand_0s_and_1s_ds.map(lambda i: tf.gather([0, 1], i)) </cmt> <cmt> tup_ds = tf.data.dataset.zip(gather_ds, rand_0s_and_1s_ds) </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> rand_0s_and_1s_ds = ... </cmt> <cmt> tup_ds = rand_0s_and_1s_ds.map(lambda i: (tf.gather([0, 1], i), i)) </cmt> <cmt> note that this does not fix the underlying issue of drawing multiple </cmt> <cmt> sampes from the underlying distribution. </cmt> <cmt>  </cmt> <cmt> tested: </cmt> <cmt> with the new test, bazel test :resample_test fails before and succeeds </cmt> <cmt> after. </cmt> <cmt> fixes github issue #16606. </cmt> <cmt> the core issue is that in the case of certain random tensors, the </cmt> <cmt> following two lines aren't the same: </cmt> <cmt>  </cmt> <cmt> rand_0s_and_1s_ds = ... </cmt> <cmt> gather_ds = rand_0s_and_1s_ds.map(lambda i: tf.gather([0, 1], i)) </cmt> <cmt> tup_ds = tf.data.dataset.zip(gather_ds, rand_0s_and_1s_ds) </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> rand_0s_and_1s_ds = ... </cmt> <cmt> tup_ds = rand_0s_and_1s_ds.map(lambda i: (tf.gather([0, 1], i), i)) </cmt> <cmt> note that this does not fix the underlying issue of drawing multiple </cmt> <cmt> sampes from the underlying distribution. </cmt> <cmt>  </cmt> <cmt> tested: </cmt> <cmt> with the new test, bazel test :resample_test fails before and succeeds </cmt> <cmt> after. </cmt> <cmt> undo a spurious git-induced change. </cmt>",fix dataset resampling bug introduced by a bug in datasets itself. fixes #16606
3493,"<desc> rayactor originally represents a java actor handle but inherited by raypyactor after cross-languages features were added. it's confusing that rayactor can represent both java and python actor handles but there's no dedicated interface for java actor handles. and in rayruntime interface we have rayobject callactor(rayfunc func, rayactor<?> actor, object[] args), which we can't tell whether the actor parameter accepts only a java actor handle based on the method signature. in this pr, add the base interface baseactor to represent an actor handle of any language. both rayactor and raypyactor inherit from it. rayactor now represents a java actor handle only. #7291 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> add interface rayjavaactor and it inhertits from rayactor </cmt> <cmt> update streaming code </cmt> <cmt> fix </cmt>",make both rayactor and raypyactor inheriting from baseactor
3494,"<desc> fixes #13035 and see there for details. in summary, this mitigates reading from a file while it is still being written to. the mitigation here is to actually do a debounce instead of what looked like a throttle, but was called a debounce (maybe i'm misreading the code or don't know my definitions though :p). this also seems to have improved the test flakiness as i can run the tests a bunch of times now and they don't fail in wsl whereas previously they would fail quite often. </desc> <cmt> chore: remove sleeps in watcher tests </cmt> <cmt> fix issue. </cmt> <iss> file watcher race condition where `modify` event occurs and file contents are empty when being read </iss>",mitigate race condition between file write by other process and watch read
3495,<desc> when slidestoshow is decimal value ie 3.5 we show 3 and 1/2 of a slide when we are at the end of the carousel and resize we get blank carousel. also in some cases the order of the slides are not correct. </desc> <cmt> _.currentslide can't be decimal value </cmt> <cmt> when we refresh we sometimes get a decimal value here if _options.slidetoshow is a decimal value rather than integer value. i.e 4.45 vs 4. </cmt> <cmt> update to 1.5.10 </cmt>,end of carousel and resize with decimal value for slides to show
3496,"<desc> fixes #8805 gethealthchecks gets called as part of config, which calls into the dependencies script, just to get a list of the dependencies requirements. however, calling the script to collect the list of requirements also checks whether they are valid (requirements met) or not, which is doing a lot of work that we don't need (gethealthchecks only returns what the checks are, not whether they passed). this change delays the checking part until it is needed (which it isn't when called as part of gethealthchecks). in my local tests this makes the incremental autolinking check go from 8-16 seconds to 4-5. microsoft reviewers: open in codeflow </desc> <cmt> delay checking whether dependencies are met until needed. this improves autolinking performance </cmt> <cmt> change files </cmt> <iss> gethealthchecks makes autolinking checks slower </iss>",improve autolinking check performance by delaying checking whether dependencies are met until it is needed
3497,<desc> fixes #7334 microsoft reviewers: open in codeflow </desc> <cmt> enable view managers to listen for js event attach/detach </cmt> <cmt> change files </cmt> <iss> view managers don't have a way to listen for js event/detach </iss>,enable view managers to be notified about js event handler attach/detach
3498,<desc> fixes #71152 </desc> <cmt> extract stamp testing for llvm </cmt> <cmt> the extracted function can be used by the rest of bootstrap to detect if we've </cmt> <cmt> already built an up-to-date llvm (and so it's safe for us to either request it </cmt> <cmt> or pretend it exists). </cmt> <cmt> don't skip building llvm if already built </cmt> <iss> rustc_llvm need to be rebuilt after ./x.py check </iss>,don't bust caches on x.py check/build switches
3499,"<desc> with this pr users can define custom dashboards as json files instead of inserting the raw json in the values.yml file. i have added an owners file, and added myself to the maintainers dco signed </desc> <cmt> [stable/grafana] extract raw json dashboards from values to files </cmt> <cmt> [stable/grafana] add owners file, add myself to maintainers </cmt> <cmt> [stable/grafana] bump chart version to 1.23.0 </cmt>","extract raw json dashboards from values to files, add owners, add new maintainer"
3500,"<desc> the function used in zipwithindex is mutable, which make the observable cannot be reused. fixed it using zip((0 until int.maxvalue).toobservable). make zip(that, selector) public and rename to zipwith. #1189 / </desc> <cmt> fix the bug that using mutable function in 'zipwithindex' </cmt> <cmt> make 'zip(that, selector)' public and rename to 'zipwith' </cmt>","fix bug in zipwithindex and set zip(that, selector) public in rxscala"
3501,"<desc> displays a warning alert when there are incompatibilities from the current query adds create alert button to the transaction summary page tracks success/error on clicking create alert </desc> <cmt> add alert messaging when a discover query is incompatible </cmt> <cmt> replace discover create alert with create alert button </cmt> <cmt> add alerts for create alert button, access available fields directly </cmt>",create alert from transaction summary
3502,"<desc> reading entries was a nightmare. we have too many changes and the user may have problems finding the entries that are relevant to him. i have grouped the entries into the following sections. cli changes database schema changes configuration changes changes to the core operators/hooks changes to the core python api changes in google provider package changes in amazon provider package changes in other provider packages other changes the fact that we have a mess in this file also means that some guides is added to the project documentation, which makes it difficult to find them.  read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> change the level of headings </cmt> <cmt> move cli chnages to new section </cmt> <cmt> move configuration chaanges to new section </cmt>",group updating.md  entries in into smaller sections
3503,"<desc> hi, i had changed for some patterns, please check. </desc> <cmt> [refactor] remove unnecessary declarations in command pattern. </cmt> <cmt> [refactor] separate out one method to call actions for workers. </cmt> <cmt> [refactor] extends action enum in mediator pattern. </cmt> <cmt> [refactor] update hairtype enum in builder pattern. </cmt> <cmt> [refactor] remove unnecessary declarations in servant pattern. </cmt> <cmt> [refactor] remove unnecessary declarations in service-locator pattern. </cmt> <cmt> [refactor] remove unnecessary declarations in observer pattern. </cmt>","makes a few improvements, basically unnecessary declarations, formatting"
3504,"<desc> improving coverity reports, no real impact or changes your great patch is much appreciated. we are considering to apply your patch into the softether vpn main tree. softether vpn patch acceptance policy:  you have two options which are described on the above policy. could you please choose either option 1 or 2, and specify it clearly on the reply? one preliminary declaration for future switch to a non-gpl license i hereby agree in advance that my work will be licensed automatically under the apache license or a similar bsd/mit-like open-source license in case the softether vpn project adopts such a license in future. </desc> <cmt> remove donothing function (improves coverity reports) </cmt> <cmt> resolve trivial coverity finding: </cmt> <cmt> assigning value 3000u to info->ostype here, but that stored value is overwritten before it can be used. </cmt>",resolve several trivial issues found by coverity
3505,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> types/hapi: servermethod doesn't have to return promise </cmt> <cmt> types/hapi: servermethod doesn't have to return promise </cmt>",servermethod does not have to return a promise
3506,<desc> acidanthera/bugtracker#1205 supports intel graphics only. </desc> <cmt> biosvideo: initial intel patching functions </cmt> <cmt> biosvideo: implement patch protocol </cmt> <cmt> biosvideo: read edid from vbe </cmt> <cmt> biosvideo: fix previous commits </cmt> <cmt> openduet: fix windows builds </cmt> <cmt> biosvideo: fix msvc warnings </cmt> <cmt> biosvideo: pull max resolution from edid </cmt> <cmt> biosvideo: patch based on pci vendor id </cmt> <cmt> biosvideo: fix more msvc warnings </cmt> <cmt> ocmisclib: try to fix openduet msvc compilation </cmt> <cmt> biosvideo: fix incorrect return status </cmt> <cmt> openduet: create ocdebugloglibnull library </cmt> <cmt> protocol: rename oc_vbios_patch_protocol to oc_force_resolution_protocol </cmt> <cmt> opencore: add forceresolution option </cmt>,vbios patching via forceresolution option
3507,<desc> the first commit should fix the 50min timeout in forked repos. similar to #19424. e.g.  the second commit should fix #19744 </desc> <cmt> ci: run valgrind fuzzer on cirrus </cmt> <cmt> ci: set cirrus ram to 8gb </cmt> <iss> intermittent ci failure: rpc_psbt.py --descriptors </iss>,move valgrind fuzzer to cirrus
3508,"<desc> 21eadc1 forced activerecord::base#[] and #[]= to use the default implementations of #read_attribute and #write_attribute respectively; if one of the latter methods is redefined, or wrapped with alias_method_chain, its alias will retain the default behaviour. i don't think this change in semantics was intentional, so i've added tests for the expected behaviour and reverted 21eadc1 to make them pass. </desc> <cmt> test activerecord::base#[]= as well as #write_attribute </cmt> <cmt> test that #[] and #[]= keep working when #read_attribute and #write_attribute are overridden </cmt> <cmt> revert ""base#[] and base#[]= are aliases so implement them as aliases :)"" </cmt> <cmt> this reverts commit 21eadc1b3f2eb818a4833381ee0a6cfa205f2955. </cmt>",#[] and #[]= are no longer interchangeable with #read_attribute and #write_attribute
3509,<desc> tutorials/tree/master/core-java - added 6 back-links to articles:       tutorials/tree/master/spring-boot-ops - added a readme.md file & added 1 link to article:  tutorials/tree/master/spring-boot - added 1 back-link to article:  tutorials/tree/master/ethereumj - added 1 back-link to article:  tutorials/tree/master/spring-mvc-java - added 1 back-link to article:  tutorials/tree/master/javax-servlets - added 1 back-link to article:  tutorials/tree/master/spring-data-rest - added 1 back-link to article:  tutorials/tree/master/gson - added 1 back-link to article:  tutorials/tree/master/persistence-modules/spring-jpa - added 1 back-link to article  10.tutorials/tree/master/spring-data-mongodb - added 1 back-link to article:  tutorials/tree/master/kotlin-js - added a readme.md file & added 1 link to article: </desc> <cmt> update readme.md </cmt> <cmt> create readme.md </cmt> <cmt> add relevant article </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> create readme.md </cmt>,add back-links and created new readme.md for the relevant articles
3510,<desc> @rocketchat/core closes #6336 </desc> <cmt> allow access to the models within integrations and fix a few issues with incoming webhooks </cmt> <cmt> update the history file to reflect the changes to the integrations </cmt> <iss> [q] how to access to models from outgoing webhook integration? </iss>,"integrations, both incoming and outgoing, now have access to the models. example: users.findonebyid(id)"
3511,"<desc> (open a new pr that sorts the old dom files first for better diff) the ie team started to issue new specs in the format of xml files instead of webidl files for upcoming api changes. the new dom.generated.d.ts and webworker.d.ts are generated from the new xml specs to be consistent with ie dom api changes. related to pr #2645. issues that would be fixed: #2437 missing properties: document.pointerlockelement and mouseevent.movement #2416 wheelevent constructor in lib.d.ts #2029 type definition of customevent constructor needs parameter(s). #1852 domstringmap is defined as an empty interface - this makes it awkward to use #1850 ""source"" #1618 ""getelementsbytagname('svg')"" does not returns nodelist of svgsvgelement, but generic nodelist. #1302 add declarations for html touch events to lib.d.ts #1224 eventlistener interface does not accept objects with a handleevent method (not sure) #1075 idbkeyrange definition is degraded #674 mouseevent constructor is missing parameters #314 sourcebuffer.appendbuffer() is missing overload for arraybufferview param in lib.d.ts </desc> <cmt> sort the old dom files </cmt> <cmt> updated dom files and removed some ie only types </cmt> <cmt> updated the dom files according to new ie spec. remove part of the ie </cmt> <cmt> only types in ""extensions.d.ts"" that are not used in the new spec. </cmt> <cmt> removed local gitignore change </cmt>",updated dom related reference files according to new ie spec
3512,"<desc> linked issue: #11963 description: the current init manager only knows how many registered targets are not ready via its count_ field. this pull request mainly helps init manager to check which specific targets are not ready. key idea: init manager stores the unready_target_name:count key-value pair in a hash map to check which registered targets are not ready. enable passing target name into watcher's callback function. when a new target is added into the targets list, increase the occurrence of the target's name in the hash map ++target_name_count_[target_name]. when a target is ready, it informs the manager's watcher and finally, the watcher notifies the manager(that's why we need to pass a string_view name parameter to the manager's callback). and decrease the count of the target's name by 1. --target_name_count_[target_name]. most recent update: in the current code base, watchers are basically constructed with std::function<void()>. in order to adopt the new feature(pass a string_view parameter to the manager's callback, i wrote a new constructor for watcherimpl with std::function<void(absl::string_view)> parameter. in addition, i added a ontargetreadysendtargetname(string_view) adopted from the original callback ontargetready(). so now both types of callbacks are supported. i've also updated code in the constructor of managerimpl, and now the watcher_ of a manager is constructed with the new type of function(with string_view parameter). therefore, the manager will always get target_name from the watcher's callback. followup: unready targets config dumps #12554 risk level: low the diagram below illustrates the outline of this pr </desc> <cmt> init-manager-query-unready-targets </cmt> <cmt> init-manager-query-unready-targets </cmt>",init manager checking unready targets with target-aware watchers
3513,"<desc> this pr replaces #23626 which i'm abandoning due to a bad merge, with this pr we transform keyof applied to a union type to an intersection of keyof applied to each union constituent. in other words, we rewrite types of the form keyof (a | b) to keyof a & keyof some examples: type a = { a: string, c: string }; type b = { b: string, c: string }; type t1 = keyof (a | b);  // ""c"" type t2<t> = keyof (t | b);  // (keyof t & ""b"") | (keyof t & ""c"") type t3<u> = keyof (a | u);  // (""a"" | keyof u) | (""c"" & keyof u) type t4<t, u> = keyof (t | u);  // keyof t & keyof u type t5 = t2<a>;  // ""c"" type t6 = t3<b>;  // ""c"" type t7 = t4<a, b>;  // ""c"" this pr is the mirror image of #22300 and finally brings symmetry to the type eqivalences: keyof (a & b) <==> keyof a | keyof b keyof (a | b) <==> keyof a & keyof b why it took so long to figure out i don't know! fixes #23618. </desc> <cmt> transform 'keyof (a | b)' to 'keyof a & keyof b' </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",distribute 'keyof' union types (take 2)
3514,<desc> see #9 -provided links for all arm instructions described in booting the kernel -cleaned up some grammar issues -provided extra resources for those new to the arm isa </desc> <cmt> cleaned up and linked arm instruction info </cmt> <cmt> cleaned up and linked arm instruction info </cmt>,provided links and clarified descriptions for arm instructions in sec 1.1
3515,"<desc> speed up is achieved by: saving (and especially loading) bottleneck arrays in binary files instead of .txt files caching already calculated bottleneck arrays in ram, instead of reading them every time from disk p.s. 2x speed up is achieved on ssd disks, on hdd disks speed up is even greater </desc> <cmt> bottleneck arrays are stored (and loaded) as binary files. </cmt> <cmt> expected training process performance improvement is about 2 times </cmt> <cmt> (measured on hdd - on ssd results probably will be less impressive). </cmt> <cmt> one more option would be to use numpy load/store instead of struct.pack. </cmt> <cmt> bottleneck values are read into ram from disk only once. </cmt> <cmt> before that we were reading them from disk everytime when we need them. </cmt>",speed up retraining times  approximately 2x
3516,"<desc> fixes #33839 when import declarations/specifiers are already sorted, we insert new declarations/specifiers in the appropriate location. the sort order of import specifiers is alphabetical (reusing the existing logic from organize imports). the sort order for import declarations is alphabetical by module specifier, with module specifier ties being broken by the secondary sort order: side-effect imports type-only imports namespace imports default imports named imports importequalsdeclarations require variable statements the organize imports logic has been updated to use that tiebreaker as well. </desc> <cmt> sort auto-imports </cmt> <cmt> avoid re-checking sort all the time </cmt> <iss> auto-import with alphabetized order by default </iss>",insert auto-imports in sorted order
3517,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> update type definitions for sharp 0.26.0 </cmt> <cmt> adds comment describing that using gif options for output image requires libvips custom compilation </cmt>",updates type definitions from sharp 0.26.0 to support animated gif and webp formats.
3518,"<desc> closes #12538 this implements hyper parameter search with successive halving this builds upon #13145, whose changes are required. this is a port of what we implemented in dabl with @amueller. main functional tests examples user guide better integration into user guide to avoid redundancy a few more doc here and there some more thorough tests about input checking, etc still wip but very advanced, and would appreciate some feedback before i start tackling the last few bullet points, so i'll mark as mrg. ping @ogrisel ;) benchmarks edit more recent benchmarks here please check out dabl benchmarks for source. on 20_news_group datset: training time   test score   best cv score --------------------------------------------------------------- gridsearchcv             19984.9 s      0.8567          0.9262 gridsuccessivehalving      598.4 s      0.8514          0.8811 --------------------------------------------------------------- best params gridsuccessivehalving {'clf__c': 1000.0, 'vect': tfidfvectorizer(), 'vect__ngram_range': (1, 1)} best params gridsearchcv {'clf__c': 1000.0, 'vect': tfidfvectorizer(ngram_range=(1, 2)), 'vect__ngram_range': (1, 2)} on digits dataset: training time successive halving 3.1159074306488037 test score successive halving:  0.9911111111111112 parameters successive halving:  {'c': 100.0, 'gamma': 0.1} training time grid search:  39.42753505706787 test score grid search:  0.9911111111111112 parameters grid search:  {'c': 10.0, 'gamma': 0.1} </desc> <cmt> more flexible grid search interface </cmt> <cmt> added info dict parameter </cmt> <cmt> put back removed test </cmt> <cmt> renamed info into more_results </cmt> <cmt> passed grroups as well since we need n_to use get_n_splits(x, y, groups) </cmt> <cmt> port </cmt> <cmt> pep8 </cmt> <iss> add successive halving for search? </iss>",successive halving for faster parameter search
3519,<desc> i received the following errors { error: cannot find module 'react/dist/react.min.js' at function.module._resolvefilename (module.js:485:15) at function.resolve (internal/module.js:18:19) at _callee2$ (/users/a.marchenko/downloads/using-preact/node_modules/next/dist/server/build/webpack.js:516:34) at trycatch (/users/a.marchenko/downloads/using-preact/node_modules/regenerator-runtime/runtime.js:65:40) at generator.invoke [as _invoke] (/users/a.marchenko/downloads/using-preact/node_modules/regenerator-runtime/runtime.js:303:22) at generator.prototype.(anonymous function) [as next] (/users/a.marchenko/downloads/using-preact/node_modules/regenerator-runtime/runtime.js:117:21) at step (/users/a.marchenko/downloads/using-preact/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /users/a.marchenko/downloads/using-preact/node_modules/babel-runtime/helpers/asynctogenerator.js:35:14 at promise (<anonymous>) at f (/users/a.marchenko/downloads/using-preact/node_modules/core-js/library/modules/_export.js:35:28) code: 'module_not_found' } the build requires react </desc> <cmt> corrected dependencies for the preact example. require react and react-dom </cmt> <cmt> corrected dependencies for the inferno example. require react and react-dom </cmt>,corrected dependencies for preact and inferno
3520,<desc> update discover and performance views to format durations as s/ms consistently across all charts. also use short forms for time units in tooltips and axis labels as they consume less space and are more consistent with how we show these values elsewhere. failure rate as % discover with durations performance overview performance summary </desc> <cmt> add tests for getduration. there weren't any before. </cmt> <cmt> improve formatting of axis and tooltip data. </cmt> <cmt> consistently use seconds and %ages for the relevant data. also update </cmt> <cmt> axis data to be less precise than tooltips so it takes up less space. </cmt> <cmt> there are still some problems with >0 and < 1000 that need to be </cmt> <cmt> addressed but with the new functions that will be easier to do. </cmt>,fix(discover) format y-axis and tooltips consistently
3521,"<desc> this adds getmutablesizeprefixedroot to flatbuffers.h and generates getmutablesizeprefixedxxx functions for c++. </desc> <cmt> flattests_cpp17 doesn't compile with visual studio 2017: warning c4100: 'indent': unreferenced formal parameter </cmt> <cmt> stringify_util.h(127): error c2220: warning treated as error - no 'object' file generated </cmt> <cmt> stringify_util.h(127): warning c4100: 'indent': unreferenced formal parameter </cmt> <cmt> stringify_util.h(85): warning c4100: 'indent': unreferenced formal parameter </cmt> <cmt> stringify_util.h(85): warning c4100: 'fbs': unreferenced formal parameter </cmt> <cmt> [c++] add getmutablesizeprefixedroot() and generate a getmutablesizeprefixed function </cmt> <cmt> when using the mutable api together with size prefixed buffers these functions should be present. </cmt> <cmt> clang-format </cmt> <cmt> cleanup branch for pr </cmt> <cmt> revert ""flattests_cpp17 doesn't compile with visual studio 2017: warning c4100: 'indent': unreferenced formal parameter"" </cmt> <cmt> this reverts commit a92055203e3c26b69df4896d6babd7714539307a. </cmt>",add getmutablesizeprefixedroot and generate getmutablesizeprefixedxxx functions
3522,"<desc> this pr adds large tensor checks to numpy unique, indices, and repeat. those ops are running very slowly on large tensors (>20mins) so we might just block such use cases. if in the future there is a valid lt use case we will need to consider optimize the performance and remove those size checks </desc> <cmt> add size checks to repeat and unique </cmt> <cmt> add size checks </cmt>",numpy unique repeat indices large tensor checks
3523,"<desc> two things are fixed: 1) when converting to numpy-compatible shape definition, we shouldn't have the check, 2) fix ill-written code in elementwisesum. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> fix. </cmt> <cmt> remove type conversion. </cmt> <cmt> remove type cast. </cmt>",fix a bug to pass the test in test_contrib_rnn
3524,"<desc> our epic matrix multiplication odyssey is drawing to a close... i've now finally got the blis linear algebra routines in a self-contained python package, with wheels for windows, linux and osx. the only missing platform at the moment is windows python 2.7. the result is at  thinc v7.0.0 will make the change to blis. i've put a thinc v7.0.0.dev0 up on pypi so that we can test these changes with the ci, and even get them out to spacy-nightly, before thinc v7.0.0 is released. this pr also updates the other dependencies to be in line with the current versions master is using. i've also resolved the msgpack deprecation problems, and gotten spacy and thinc up to date with the latest cython. the point of switching to blis is to have control of how our matrix multiplications are executed across platforms. when we were using numpy for this, a different library would be used on pip and conda, osx would use accelerate, etc. this would open up different bugs and performance problems, especially when multi-threading was introduced. with the change to blis, we now strictly single-thread the matrix multiplications. this will make it much easier to use multiprocessing to parallelise the runtime, since we won't have nested parallelism problems to deal with. </desc> <cmt> use blis </cmt> <cmt> use -2 arg to cython </cmt> <cmt> update dependencies </cmt> <cmt> fix requirements </cmt> <cmt> update setup dependencies </cmt>",use blis for matrix multiplications
3525,"<desc> i find very frustrating that we can't make profit of the incremental patches that the wine project makes : no regression testing, no way to revert a particular offending patch. when problems arise, the only thing we have is a monolithic patch, which is very inconvenient to fix. this requires the pygit2 module usage : ./winesync.py module for instance ./winesync.py d3dx9 wine-4.1 v4.1 this requires to have a wine git checkout and a wine-staging checkout configuration is done through yaml file named .cfg specifying the following: file mappings directory mappings latest wine version the module is synced with it then creates a local branch in the wine checkout, based on the given tag, and then the staging script is ran on top of it. thanks to the mappings defined in the module configuration file, it then create individual commits in the reactos git checkout with reworked path. in case of problem, it stops and lets you amend the latest commit and go along with the process once this is done. (makefile.in modified, new or removed files, patches not cleanly applied) staging patches are added into the _staging directory for the ease of reverting them later in order to be able to start a new upgrade cycle from clean base. (todo) @colinfinck : the patch author is 'winesync', maybe you can use this to not trigger the build bot, as this will likely clobber it with a lot of not-so-useful build request. the nice thing being that we can force-build one of the revision if needed. the latests commit is properly authored, though. upgrade for d3dx9 from wine-4.0 to wine-4.1 is taken as an example of what it will look like. </desc> <cmt> [d3dx9_xx] share source files </cmt> <cmt> just like wine does </cmt> <cmt> [d3dx9_36] revert wine staged patches </cmt>",introduce winesync.py and update d3dx9 modules from wine 4.0 to wine 4.1
3526,<desc> @sayanpa condensing commits for this issue (in ref to [#1952]) into one pr.  please let me know if anything needs amending.  thanks! </desc> <cmt> explicit import from cntk module </cmt> <cmt> removed an unnecessary cntk import </cmt> <cmt> removed an unnecessary cntk import </cmt> <cmt> fixed dicts in tutorial 101 </cmt> <cmt> clean up imports and execution count tutorial 101 </cmt> <cmt> merge with upstream/master to submit a pr for 101 tutorial </cmt>,update to more idiomatic python in tutorial 101
3527,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true.   increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. misc just not sure how the process moves to support each version of enzyme. i asked on their gitter, but they weren't really sure, either.  do i need to bump the version in the index.d.ts? module augmentation i made this pr since i had already done a module augmentation to support invoke.  for those interested, here is the augmentation for the shallowwrapper. i did not test this in my project using the (common|react)wrapper, however it should be trivial to make it work for them. import { component } from 'react'; declare module 'enzyme' { interface shallowwrapper<p = {}, s = {}, c = component> { /** * invokes a function prop. * @param invokepropname the function prop to call. * @param ...args the argments to the invokepropname function * @returns the value of the function. */ invoke<k extends keyof p>(invokepropname: k): p[k]; </desc> <cmt> [@types/enzyme] added invoke type definition and tests. </cmt> <cmt> fixing linting errors </cmt> <cmt> removing creating patch </cmt>",adding invoke definition to support enzyme@3.10
3528,"<desc> by default, rails will now let importmap-rails handle the javascript approach. the two other officially supported options are currently webpacker and esbuild-rails. these can be now be controller via the -j or --javascript option with webpack and esbuild as the choices. also remove all remnants of webpacker specific setup stuff. all configuration needed by webpacker should live in webpacker. </desc> <cmt> switch to a single controller option for choosing javascript approach </cmt> <cmt> remove remnants of webpacker specific work within rails </cmt>",javascript generator option with choices
3529,<desc> follow up to #31140 this improves diagnostics when applying a key path with a root type that cannot be applied to an instance base that has another non-convertible type.  resolves: sr-12425 resolves: rdar://problem/62200986 </desc> <cmt> [csdiagnostics] create keypathroottypemismatchfailure to diagnose key path root fail on key path application </cmt> <cmt> [csfix] create allowkeypathroottypemismatch to diagnose key path root fail on key path application </cmt> <cmt> [cssimplify] recording fix for keypath application root type mismatch </cmt> <cmt> [tests] adjusting sr-12425 diagnostics tests </cmt>,improving diagnostics for key path application on non-convertible root type
3530,"<desc> in current implementation, re:dash requests to idp to fetch metadata. i think re:dash should not communicate directly with idp, because idp may be on intranet. so i add new configuration 'redash_saml_local_metadata_path', and use local metadata instead of communication with idp. </desc> <cmt> use local metadata in saml </cmt> <cmt> add environment variable name in doc </cmt>",support for local saml metadata file
3531,"<desc> fixes #7876 improve speed of wifi.mode(wifi_resume) by passing the last known bssid to wifi.begin. move the wifishutdown example to the esp8266wifi library example folder. replace the wifishutdown example by a simpler one, showing the minimum use case. </desc> <cmt> improve resume speed by passing in last known bssid </cmt> <cmt> move wifishutdown example to esp8266wifi library </cmt> <cmt> provide a simpler example for wifi_shutdown/wifi_resume </cmt> <iss> connection speed problem with wifi_resume </iss>",wifi_resume improve speed and example
3532,"<desc> xref #37715 my apologies, i pushed hastily on my previous branch assign_err and did not check the diff of the files i was pushing. i accidentally pulled when i should have merged and i pushed a bunch of other peoples commits.  these are my previous changes. </desc> <cmt> changed cat_array to cat_array_list </cmt> <cmt> changed arr to arr_list </cmt> <cmt> pre-commit </cmt>",changed variable cat_array to cat_array_list in dtypes.py and arr_list in categorical.py
3533,"<desc> the se-0176 exclusivity rules kick in even when converting an l-value to a pointer.  this is generally good and right, because apis that work with pointers usually access the memory being pointed to.  however, there are notable exceptions, including == and the kvo registration/unregistration routines; enforcing exclusivity in these cases is wasteful and causes unwanted static and dynamic errors.  in the long run, we should properly design a minor language feature for this (probably a parameter attribute).  in the short term, we can just special-case these apis. this patch changes the compiler to stop enforcing exclusivity for certain expressions.  by design, it affects code generation by causing the compiler to stop using the exclusivity code-emission patterns, which are new in swift 4, and instead produce code more similar to swift 3.1. we are tracking this problem as rdar://33265254. the risk is low because it is written conservatively to selectively disable code paths. </desc> <cmt> add functions to check whether a declname is a specific compound name. </cmt> <cmt> also add an identifier::is(stringref), which is slightly nicer to use </cmt> <cmt> than 'ident.str() == string' without making it too easy to use this </cmt> <cmt> instead of identifier equality. </cmt> <cmt> suppress access enforcement when an l-value is converted to a pointer </cmt> <cmt> just for pointer identity. </cmt> <cmt> the current technique for deciding whether that's the case is *extremely* </cmt> <cmt> hacky and need to be replaced with an attribute, but i'm reluctant to </cmt> <cmt> take that on so late in the schedule.  the hack is terrible but not too </cmt> <cmt> hard to back out in the future.  anyone who names a method like this just </cmt> <cmt> to get the magic behavior knows well that they are not on the side of </cmt> <cmt> righteousness. </cmt> <cmt> rdar://33265254 </cmt>",allow pointer comparisons and kvo methods to avoid initiating formal accesses
3534,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! the mission of runestone interactive is to democratize textbooks for the 21st century. textbook prices are too high, and paper textbooks are too old fashioned. they are changing that. interactive the guide starts at the very beginning and delves into very complex topics you can simply access the website. this is an interactive tutorial not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> added kaggle python course </cmt> <cmt> merge with master </cmt> <cmt> merge with master </cmt> <cmt> add python runestone to interactive tutorials </cmt>",add runestone interactive python guide
3535,"<desc> fix two issues with the embedded plist for the back-deployed concurrency library: remove underscores from cfbundleidentifier of libraries, because they're not permitted in the reverse-dns name there. propagate swift version information to the back-deployed binaries, because it's better than leaving it empty. fixes rdar://84645973. </desc> <cmt> remove underscores from cfbundleidentifier of libraries. </cmt> <cmt> underscores aren't permitted in these identifiers. </cmt> <cmt> fixes rdar://84645973. </cmt> <cmt> propagate swift version information to the back-deployed binaries </cmt>",fix embedded plist of back-deployed concurrency library
3536,"<desc> currently, composite aggregation supports only string or numeric values for the fields in the sources part of the composite aggregation. although _tsid is encoded and stored as a byte array, it is formatted as map {""dim1"": ""value1"", ""dim2"": value2"", ...} for input/output. this pr adds support for composite aggregation on _tsid field. relates to #74660 </desc> <cmt> add support for composite agg on _tsid </cmt> <cmt> added support for ""after"" </cmt>",add support for composite aggregation on _tsid field
3537,"<desc> this finally works in visual studio 2017 15.3 preview. hopefully other debuggers add support. </desc> <cmt> win32: pthread: use the new thread naming api </cmt> <cmt> windows, as of the creators update, finally has a sane api for giving a </cmt> <cmt> name to a thread that can be used by debuggers. this is similar to </cmt> <cmt> pthread_setname_np on linux and some unixes. expose it in the pthread </cmt> <cmt> wrapper and use it for mpthread_set_name(). </cmt> <cmt> ao_wasapi: set name of event thread </cmt>",use the new thread naming api on windows
3538,"<desc> change points: seata-bom only manage the verion of 3rd jars, don't included the maven scope. seeta-server be dependent on none 3rd jars directly, which will be included by seata-config-,seata-discovery-,seata-core. </desc> <cmt> add all-in-one,  and move the 3rd jars to bom.xml </cmt> <cmt> add all-in-one,  and move the 3rd jars to bom.xml </cmt> <cmt> add junit-platform-launcher.version </cmt> <cmt> add copyright </cmt> <cmt> make seata-all to import seata-bom </cmt> <cmt> seata-bom all manage the verions of 3rd jars </cmt> <cmt> seeta-server be dependent on no 3rd jars directly </cmt>",optimization  the dependencies of seata-bom and seata-server
3539,"<desc> refs #15791. the registerhttpprotocol api can make arbitrary requests regardless of the cors settings. to keep this behavior, we need to explicitly download data from url and then pipe it to networkservice, like what we did for other types of protocol types. this pr implements the api by adding a urlpipeloader class that pipes the data from url to networkservice, instead of creating a new loader which was essentially a redirection. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> pipe data into http protocol handlers </cmt> <cmt> remove unused parameters </cmt> <cmt> remove ""sending request of http protocol urls"" test </cmt> <cmt> sending request to "" </cmt> <cmt> fail, before networkservice somehow chromium still sent a request even </cmt> <cmt> though the request failed with cors error, so the test passes while the </cmt> <cmt> test is not valid. with networkservice no request is sent at all and the </cmt> <cmt> test jsut fails. </cmt> <cmt> so this is an ancient invalid test, as sending http requests have been </cmt> <cmt> fully covered in other tests, i am removing this test. </cmt>",migrate protocol module to networkservice (part 11)
3540,"<desc> signal handling on windows is very unreliable, and may not accept multiple ctrl-c hits, or no ctrl-c hits at all in some environments (native executable under cygwin). by switching to the windows-own setconsolectrlhandler this is rectified. however, this adds some complexity as well, because the ""signals"" will now be dispatched to another thread. i also added a simple lock implementation, which, as the commit message correctly states, is a no-op on platforms other than windows. this isn't a problem, though, as the only code using it now is only potentially multi-threaded on windows. </desc> <cmt> implement a simple resource lock (threading) </cmt> <cmt> in this initial implementation locks are no-ops on platforms other than </cmt> <cmt> windows. </cmt> <cmt> win: use setconsolectrlhandler for sigint/sigterm </cmt> <cmt> define a type for signal handlers </cmt>",fix windows ctrl-c behavior (sigint + sigterm)
3541,"<desc> have you signed the contributor license agreement? users were hitting occasional collisions when both wingetdev and desktopappinstaller were installed due to both packages registering both the dev and prod guids once they ran, even though each package only put one set of guids in the manifest. this change uses build props to set a value so that only one set is defined and the server only registers the set that its package declares.  it will need to be done in sync with a change in desktopappinstaller source which i've tested that adds a directory.build.props file in the root to define the useprodclsids parameter so that the build for that package uses the other set of guids. since the currently shipping version of the desktopappinstaller package is still registering the existing dev guids, i've replaced all the dev guids, which makes this a breaking change for com callers expecting to use the com interface from the wingetdev package. i don't think there are any of those users at the moment though. if the guids can't be updated it will take longer to resolve the issue since it would require everyone getting a new flight of desktopappinstaller. microsoft reviewers: open in codeflow </desc> <cmt> merge microsoft/winget-cli changes. </cmt> <cmt> rest endpoint helper and json object field check - bug fix (#821) </cmt> <cmt> merge latest winget changes. </cmt> <cmt> fix wingetdev guids to prevent collision </cmt>",fix wingetdev guids to prevent collision when desktopappinstaller is also installed.
3542,"<desc> clicked around, validated that settings still behave the same (as far as i can tell with my limited terminal configuration expertise) closes #10387 </desc> <cmt> add percentage sign to opacity slider values </cmt> <cmt> switch to function binding instead of converter objects </cmt> <cmt> merge main </cmt> <cmt> merge main </cmt> <cmt> fix build errors and bugs and stuff </cmt> <cmt> fix missing bindbacks </cmt> <iss> replace class-based xaml converters with bound function converters </iss>",switch to function bindings instead of converter objects
3543,"<desc> description: add seek mode for to dlna dmr devices and upgrade to async_upnp_client==0.13.2 to better support media_image_url related issue (if applicable): fixes #18040 pull request in home-assistant.io with documentation (if applicable): not applicable example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> upgrade to async_upnp_client==0.13.2, now (better) providing media_image_url for dlna dmr devices </cmt> <cmt> add support_seek for dlna dmr devices </cmt> <iss> kodi auto detected and manually configured show differently </iss>",add support_seek for dlna dmr devices + now (better) providing media_image_url for dlna dmr devices
3544,"<desc> switch the es base docker image for the default and cloud images to ubuntu:20.04, as ubuntu has a more favourable posture on security updates. </desc> <cmt> use an ubuntu base for the default and cloud images </cmt> <cmt> cloud fixes </cmt>",switch to ubuntu docker base image
3545,"<desc> closes: #14384 this pr fixes two issues: a typeerror that would be raised from _emit_duration_stats_for_finished_state() when the scheduler transitions a dagrun from a running state into a success or failed state if the dagrun did not have a start_date or end_date set. an issue with the dagruneditform, which would clear the start_date and end_date for a dagrun, if the form was used to transition a dagrun from a failed state back into a running state (or any other state). in the event where the scheduler would determine the dagrun should've been in the failed or success state (e.g. because the task instances weren't cleared), then this would lead to a scheduler crash. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> handle unset dagrun.start_date and dagrun.end_date </cmt> <cmt> there may be edge cases in which a dagrun does not have a start_date, or </cmt> <cmt> an end_date set when it is being transitioned into the finished state. </cmt> <cmt> one scenario in which this may happen is when the dagrun was previously </cmt> <cmt> cleared through the /dagrun/edit/<dag_run_id> form. this form tends to </cmt> <cmt> reset the start_date and end_date whenever a dagrun object is </cmt> <cmt> transitioned back into the running state. </cmt> <cmt> fix start_date and end_date not being displayed in the dagrun edit view </cmt> <cmt> this causes both the start_date and the end_date to be cleared for the </cmt> <cmt> dagrun after editing it through the ui. by ensuring the fields are </cmt> <cmt> present, this should be avoided. </cmt> <iss> scheduler ocassionally crashes with a typeerror when updating dagrun state </iss>",gracefully handle missing start_date and end_date for dagrun
3546,"<desc> currently the backend will pass the granularity as a string that is engine dependent, e.g, ""30 seconds"". i changed the backend so that an iso 8601 duration is passed instead. this allows the frontend to handle the granularity better, eg, for the play slider. </desc> <cmt> add iso duration to time grains </cmt> <cmt> use iso duration </cmt> <cmt> remove debugging code </cmt> <cmt> add module to yarn.lock </cmt> <cmt> remove autolint </cmt> <cmt> druid granularity as iso </cmt>",pass granularity from backend to frontend as iso duration
3547,"<desc> the protocol conformance checker tries to delay the emission of diagnostics related to the failure of a type to conform to a protocol until the source file that contains the conformance is encountered, to provide redundant diagnostics. however, if a file produced only such delayed diagnostics, such that all diagnostics were suppressed, invalid asts could slip through to later stages in the pipeline where they would cause verification errors and crashes. this happens generally with whole-module-optimization builds, where we are re-using an astcontext when typing multiple source files. this is a narrow-ish fix to stop dropping diagnostics from one source file to the next in whole-module-optimization builds, along with another fix to detect cases where we're suppressing an error due to a conformance-related diagnostic that will be emitted in another file and emit something. resolves rdar://problem/29689007. </desc> <cmt> [type checker] don't drop ""delayed"" conformance diagnostics after a source file. </cmt> <cmt> the protocol conformance checker tries to delay the emission of </cmt> <cmt> diagnostics related to the failure of a type to conform to a protocol </cmt> <cmt> until the source file that contains the conformance is encountered, to </cmt> <cmt> provide redundant diagnostics. however, if a file produced only such </cmt> <cmt> delayed diagnostics, such that all diagnostics were suppressed, </cmt> <cmt> invalid asts could slip through to later stages in the pipeline where </cmt> <cmt> they would cause verification errors and crashes. this happens </cmt> <cmt> generally with whole-module-optimization builds, where we are re-using </cmt> <cmt> an astcontext when typing multiple source files. </cmt> <cmt> this is a narrow-ish fix to stop dropping diagnostics from one source </cmt> <cmt> file to the next in whole-module-optimization builds. part of </cmt> <cmt> rdar://problem/29689007. </cmt> <cmt> (cherry picked from commit 0c0517f997ec9ebc6074860a30c99160a4bab697) </cmt> <cmt> [type checker] emit a diagnostic for invalid cross-file type witness references. </cmt> <cmt> if we reference an invalid type witness (e.g., a type witness for </cmt> <cmt> which we ended up setting an error type because it couldn't be </cmt> <cmt> satisfied), but the diagnostic that complains about the broken type </cmt> <cmt> witness won't be diagnosed in this source file, complain that we're </cmt> <cmt> referencing a bogus diagnostic. since these diagnostics can be noisy </cmt> <cmt> for broken code, only do so if no other diagnostics have been emitted </cmt> <cmt> thus far. </cmt> <cmt> note that we need to produce *a* diagnostic here, otherwise we might </cmt> <cmt> continue on to later stages of the compiler with our invalid asts. </cmt> <cmt> fixes rdar://problem/29689007. </cmt> <cmt> (cherry picked from commit 871aefde6912941ec4a3f8d2198b95aca41ba338) </cmt>",emit delayed conformance diagnostics in multi-file scenarios
3548,<desc> @josevalim: as requested in #1508. please note that i've to cherry pick and edit the commits because 'plugin_new' doesn't exist in 3-0-stable. and rakefile in the top of the tree already had require rdoc/task and hence is not included in the diff. </desc> <cmt> fixes rake::gempackagetask deprecation warnings from rake 0.9.0 </cmt> <cmt> fixes rake::rdoctask deprecation warnings from rake 0.9.0 (cherry picked </cmt> <cmt> b921679 for 3-0-stable) </cmt> <cmt> cherry picked 24b28a2 for 3-0-stable. original author: amatsuda </cmt> <cmt> cherry picked 05adf524 for 3-0-stable. original author: amatsuda </cmt>,rake rdoc fixes cherry picks for 3-0-stable
3549,"<desc> similar to #17585 add new links to the ""see also"" section of the documentation: link to plot_confusion_matrix from confusion_matrix link to confusion_matrix from plot_confusion_matrix link to plot_precision_recall_curve from precision_recall_curve link to precision_recall_curve from plot_precision_recall_curve these are all ""see also"" links that i would personally find useful, which is why i added them! </desc> <cmt> add see also links to and from plot_precision_recall_curve </cmt> <cmt> add see also links to and from plot_confusion_matrix </cmt>","doc add ""see also"" links to and from new plotting functions"
3550,"<desc> @rafaelfranca @sgrif @tenderlove backport of #25341 to 4-2-stable. follow up to #25356. includes the related bug @rafaelfranca fixed in 5e77a70 backported as well. problem as explained in the original issue, the call to activesupport::logger#silence is not correctly delegated to broadcasted loggers. this was fixed by implementing the #silence method for logger broadcasting. this, along with rewriting the tests, was done on master. unfortunately, since on 4.2 in reporting.rb there are a number of kernel patches, which includes aliasing the kernel#capture method to silence: rails/activesupport/lib/active_support/core_ext/kernel/reporting.rb line 108 806e816 alias :silence :capture this means the respond_to? checks break because it duck-types to a logger which supports silence, but actually calls out to an unrelated method. solution it's nasty, but i also validate that the silence method is not on kernel. i'm open to further suggestions. there's not much prescient for this kind of check. up side is that this is only required in the backport as patch is deprecated and removed on master. if i'm going to refactor/reimplement logger broadcasting i'm not going to do it on the backport branch. </desc> <cmt> broadcast #silence on logger. rewrite tests. </cmt> <cmt> make sure the yielded variable is the logger </cmt> <cmt> check that we are not hitting kernel#capture aliased to #silence in the reporting patches. deprecated and removed in 5. </cmt>",broadcast #silence on activesupport::logger
3551,"<desc> the metrics api used the date range validation logic from sessions_v2 up until this pr, which does a lot of sessions-specific validation. remove these constraints by creating a simplified version of the same function for metrics. this might later be extended when constraints metrics-specific constraints pop up. </desc> <cmt> fix(metrics): allow more date ranges </cmt> <cmt> fix: revert accidental change </cmt>",allow more date ranges [ingest-542] [ingest-700]
3552,"<desc> reintroducing pr #26643, which was reverted in #27029 fixed a memory leak and added a test that would have caught it (asan build): ca0c8c4 </desc> <cmt> revert ""revert ""move resource_user ownership into chttp2 transport/server/connector (#26643)"" (#27029)"" </cmt> <cmt> this reverts commit f5d3ed2db1b2a8c3eba9bc13b629e5ec2ed3e2c9. </cmt> <cmt> fix tcp_client memory leak and add test for it </cmt>",move resource_user ownership into chttp2 transport/server/connector v2
3553,<desc> @vstinner noticed on python-dev that there is no what's new or porting entry for removal of asyncio loop parameter. this patch adds a basic guide.  automerge-triggered-by: gh:aeros </desc> <cmt> add to whatsnew in python 3.10 </cmt> <cmt> add note about 3.6 </cmt>,mention loop removal in whatsnew for 3.10
3554,"<desc> while trying to see if we have 1:1 mapping between foundry and kokoro tests, it turned out some tests are named in a way that makes it not obvious what their foundry counterpart it. a bit of cleanup in this pr (see commits for individual changes). memory_profile_test doesn't match it's .cc file name qualify handshake test with ""_ssl"" to better match the .cc file name rename a bazel test to match the .cc file name </desc> <cmt> rename bazel stream_compress_test to stream_compression_test </cmt> <cmt> rename memory_profile_test to memory_usage_test </cmt> <cmt> qualify handshake_client and handshake_server tests with ""_ssl"" </cmt> <cmt> regenerate projects </cmt>",align some build.yaml test names with bazel counterparts
3555,<desc> update next.js version to 10.0.0 update the other dependencies modify next.config.js to prevent circular __self and __sourcein dev env (ref: developit/nextjs-preact-demo#25) </desc> <cmt> upgrade dependencies </cmt> <cmt> prevent circular __self and __sourcein dev env </cmt>,update using-preact example's dependencies
3556,"<desc> this is effectively an un-revert of #11617 and #12024 (reverted in #12159). portions of those were merged in other prs (with lower risk) and this represents the remainder. note that i found 3 different bugs in the original prs and have fixed them here. i also tried again (with some tweaks) in #12360, which i ended up reverting in #12806.  for this attempt i am dropping the code that calls any remaining pending calls during runtime finalization.  we'll see if the freebsd buildbot still hates me. :) </desc> <cmt> ceval -> ceval_r </cmt> <cmt> _py_finishpendingcalls -> _pyeval_finishpendingcalls </cmt> <cmt> drop the gil_request macro. </cmt> <cmt> move pending calls from _pyruntimestate to pyintepreterstate. </cmt> <cmt> release the pending calls lock *after* updating the eval breaker flag. </cmt> <cmt> use the internal function. </cmt> <cmt> add a news entry. </cmt> <cmt> optionally lock a pending call to a specific thread. </cmt> <cmt> move core-only field to end of struct. </cmt> <cmt> add a todo. </cmt> <cmt> use _py_addpendingcall() for releasing shared data. </cmt> <cmt> check the result of adding the pending call (for releasing xid). </cmt> <cmt> make a copy of data-to-be-deleted. </cmt> <cmt> fix the pending-for-other-thread case. </cmt> <cmt> ignore any lingering pending calls. </cmt>","factor out a private, per-interpreter _py_addpendingcall()."
3557,<desc> description: this pr adds more functionality to the existing version sensor platform. it can track the published version from multiple sources: current locally installed version (like it does now) pypi for manual installations dockerhub for docker installs the files hosted on aws for hassio installations. this change utilizes pyhaversion to fetch new information. for hassio installations there is also some extra version attributes: hassos supervisor hassos-cli it defaults to track local so that current users of this sensor will not have any issues. pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#7305 example entry for configuration.yaml (if applicable): sensor: platform: version checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> added functionality to the version sensor. </cmt> <cmt> corrected typo. </cmt> <cmt> change default name to not cause a breaking change. </cmt>,add functionality to the version sensor
3558,"<desc> fixes #1070 by adding proxyheaderexclusivelist for list of headers that should be sent exclusively to proxy in tunnel mode. this also simplifies handling of proxy-authorization by avoiding old flow where: header was firstly removed in any case and temporarily stored to inner property; when in tunnel mode, it was added back to proxyheaders hash; when not in tunnel mode, it was added back to regular headers where it was firstly removed from. now any header from proxyheaderexclusivelist (incl. proxy-authorization) goes through simpler flow: if in tunnel mode, move it from regular headers to proxyheaders; that's it :p so it covers the same flow that proxy-authorization had, and at the same time gives ability to extend list with custom proxy-only headers. incorporates #1028 and #1050. </desc> <cmt> add support for proxy-only headers (destheaderblacklist). </cmt> <cmt> renamed new option to proxyheaderexclusivelist for clarity. </cmt> <cmt> updated docs. </cmt> <cmt> simplify proxy-authorization header handling </cmt> <cmt> deprecate mess with removing and re-adding proxy-authorization header in favor of proxyheaderexclusivelist. </cmt> <cmt> small refactoring. </cmt> <iss> allow specific headers to be sent exclusively to proxy </iss>",add proxyheaderexclusivelist option for proxy-only headers.
3559,"<desc> this should correct an issue with copying and pasting sections of tilemaps to different x/y coordinates. relates to this forum post:  i've added a qunit test for this change. as it is dealing with data manipulation i found it useful. the tests highlighted another possible issue with tilemap copy and paste. changing data in copied data will actually change the tilemap it is copied from. this is because the copy creates an array with the same tile references as the actual tilemap. not sure of the best solution there as memory could be an issue. i'd be interested in contributing further to phaser and i was wondering if adding some more unit tests might be useful, what are your thoughts? </desc> <cmt> added touch joystick example </cmt> <cmt> using clay.io's html5 virtual game controller </cmt> <cmt> add gamecontroller.js to view_lite.html for the side_view layout </cmt> <cmt> small link updates. </cmt> <cmt> added touch joystick example </cmt> <cmt> added bitdeli badge. </cmt> <cmt> conflicts: </cmt> <cmt> readme.md </cmt> <cmt> tilemap - reverse diffx and diffy equations in tilemap#paste. </cmt>",tilemap#paste diffx and diffy equations changed
3560,"<desc> ddpg produces inf actions when in an unbounded [-inf, inf] action space. this was due to a bug in the ounoise component (both tf and torch as well as the original non-exploration api version(s)). this pr fixes this bug. fixes issue #8135 closes #8135 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip and lint. </cmt> <cmt> docs. </cmt> <cmt> docs. </cmt> <cmt> fixes and lint. </cmt> <cmt> wip. </cmt> <iss> [rllib] model with continuous action space outputs inf </iss>","fix issue 8135 (ddpg inf actions when using [-inf,inf] action space)."
3561,"<desc> recently, i tried to read the codes to understand what the constrainedassign and generalassign method is doing, but it is so difficult and suffering due to the complexity of the algorithm. and then i traced back to the jira ticket and kip to get much more information about them. so, i think we should put at least the algorithm goal and main steps in the code comments, to let other developers better understand them and better do trouble shooting if any. reference for constrainedassign algorithm:  reference for generalassign algorithm: </desc> <cmt> add generalassign and constrainedassign algorithm description and high level executing steps </cmt>",add comments to constrainedassign and generalassign method
3562,"<desc> this pr adds and/or moves around the annotations of 9 ndarray/generic magic methods: __int__ __float__ __complex__ __abs__ __pos__ __neg__ __matmul__ __mod__ __divmod__ </desc> <cmt> enh: add annotations for ndarray / generic magic methods </cmt> <cmt> * __int__ </cmt> <cmt> * __float__ </cmt> <cmt> * __complex__ </cmt> <cmt> * __neg__ </cmt> <cmt> * __pos__ </cmt> <cmt> * __abs__ </cmt> <cmt> enh: add annotations for __mod__ & __divmod__ </cmt> <cmt> maint: add __complex__ to all numeric types </cmt> <cmt> in practice only complexfloating defines a __complex__ method, but this is the only make all numeric types compatible with builtins.complex. </cmt> <cmt> maint: removed a redundant protocol inheritance </cmt> <cmt> maint: removed unused imports </cmt> <cmt> tst: fixed the line number offset </cmt> <cmt> tst: added typing tests for __mod__ & __divmod__ </cmt> <cmt> tst: added typing tests for unary operations </cmt> <cmt> tst: add tests for conversions to builtin scalar types </cmt>",add annotations for 9 ndarray/generic magic methods
3563,"<desc> as per #1416 (discussed with @gihrig, now closed).  this has been reopened for issue #1406, but against the dev branch. </desc> <cmt> removed redundant lint:css </cmt> <cmt> remove lint:css references </cmt> <cmt> removed redundant lint:js reference </cmt>",#1406 remove lint:css documentation references
3564,"<desc> update of pr #18467 by @olehkss which was stalled. fixes #8781. work done in referenced pr above which commits were adopted: simpleimputer issues a warning when columns that are completely nan are removed during imputation by default. work contributed by me: update of depreciation version numbers, move from whatsnew file 1.0 to 1.1. thank you to the main contributor @olehkss to whose fork i  could not push/update. hence i created this new pr. #dataumbrella sprint @reshamas @thomasjpfan </desc> <cmt> deprecate verbose in simpleimputer. </cmt> <cmt> code review. </cmt> <cmt> sklearn.impute verbose  whatnew from v1.0 to v1.1 </cmt> <cmt> sklearn.impute verbose depreciation bump to 1.1 </cmt> <iss> issue a warning when columns that are completely nan are removed during imputation? </iss>",api warn upon removal of nan columns
3565,"<desc> the docker modules, kubevirt modules and the k8s module are moving to other collections: the docker modules are moving from community.general to community.docker (already in progress, new collection already released). the kubevirt modules are moving from community.general to community.kubevirt (in preparation, collection not yet published). the k8s module is moving from community.kubernetes to community.okd (already in progress, collection with module already released). the community.k8s collection will be renamed to kubernetes.core (already in progress, new collection already released). right now, support for the docker and k8s action groups / module default groups does need to know in which collection the affected modules / action plugins are contained. therefore, lib/ansible/executor/module_common.py needs to be updated (and this change backported to stable-2.10) for the moves to work flawlessly, and to avoid breaking playbooks and roles. the old names must not be removed either to avoid breakage with older (current) versions of the collections.  lib/ansible/executor/module_common.py </desc> <cmt> support docker and k8s action groups for moved modules in community.docker and community.kubevirt. </cmt> <cmt> also support k8s action group for community.okd. </cmt> <cmt> also add kubernetes.core. </cmt>",adjust action groups to moved modules
3566,"<desc> please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> refactor notebook </cmt> <cmt> notebook working with hybrid block </cmt> <cmt> more refactoring </cmt> <cmt> remove unnecessary use_np_compat </cmt> <cmt> use class decorator to initialize numpy ndarrays in parameter.py </cmt> <cmt> clear notebook outputs </cmt> <cmt> improve np decorator </cmt> <cmt> remove npe op from optimizer </cmt>",refactor np module (example runs through)
3567,"<desc> before this patch: when you click play button, ""output"" console always open, even if the debugger or other panel was open. this is very annoying imo. after this patch: let the users choose what panel they want, if the output console is open, then will stay opened, if the debugger is open, it will stay opened (only if you checked the option in the script panel), etc. i added a new option called ""run/always_open_output_on_play"" setted to true to keep the old behavior too. </desc> <cmt> fix visibility of bottom panel when start playing </cmt> <cmt> add new option to always open output on play </cmt>",fix bottom panel visibility on play
3568,<desc> much better i think: </desc> <cmt> badges are now non-cacheable; badges on alarms modal auto-refresh; chart refreshes stop when alarms modal is shown </cmt> <cmt> predict width and height of badges </cmt> <cmt> fix for double slash in health api urls </cmt> <cmt> increase dashboard.js version number to match current index.html </cmt> <cmt> alarms in alarm modal are sorted like the charts menu </cmt> <cmt> aesthetic changes to alarms modal - alarm definitions are properly rendered </cmt>,dashboard improvements related to health monitoring
3569,"<desc> i'm working on a small project using phaser and pyxel edit for coder-art. i was looking for a way to import my pyxel edit tilemaps as an atlas. after failing at lot, i stumbled upon this discussion. i then set out attempting to write a plugin that would provide this integration, though it didn't seem to be possible with the current plugin architecture. in the end i decided to fork, add feature support for it and offer it to the community if you, the maintainer, feel it appropriate. i attempted to follow your guidelines as best i could(jshint etc.) and can provide a test project to demonstrate the functionality if requested. nb: i accidentally made changes on the master branch but have since reverted and cherry picked said changes to master. you'll see that nothing too sinister has happened in the diff . </desc> <cmt> cherry pick commits from master. read: i'm not clever. </cmt> <cmt> some cleaning up and documentation polish </cmt> <cmt> cleaning up to obey jshint </cmt>",add support for loading single-layer pyxel edit tilemap as an atlas
3570,"<desc> shutdown of the service immediately destroys the global context, but parts of the context (astmanager, notificationcenter, editordocumentmap) are referenced by asynchronous ast builds, which could cause use-after-free.  the solution is to move these values under shared_ptr and weak_ptr to fix the lifetime. this issue was seen (rarely) when running under asan in ci, but can be made more likely to occur by calling sleep right before exiting.  this has always been an issue, but is unlikely to be detected without asan if your process exits immediately after shutting down sourcekitd, which seems to be common. rdar://problem/43121217 </desc> <cmt> [sourcekit] use a shared_ptr for the notificationcenter </cmt> <cmt> when the server shuts down we may still have outstanding async work that </cmt> <cmt> can attempt to trigger a notification, so use a shared_ptr + weak_ptr </cmt> <cmt> instead of unique_ptr + unowned references. </cmt> <cmt> [sourcekit] use a shared_ptr for the swiftastmanager </cmt> <cmt> when the server shuts down we may still have outstanding async work to </cmt> <cmt> build an ast, so use a shared_ptr + weak_ptr instead of unique_ptr + </cmt> <cmt> unowned references. </cmt> <cmt> [sourcekit] remove reference to global context from swiftlangsupport nfc </cmt> <cmt> while the swiftlangsupport doesn't currently outlive the global context </cmt> <cmt> it clarifies the ownership to just store the weak reference we care </cmt> <cmt> about instead of referencing the owning context. in the future we may </cmt> <cmt> want to ref-count the lang support, in which case we'd need to do this </cmt> <cmt> to avoid a cycle anyway. </cmt> <cmt> [sourcekit] stop storing a bare reference to langsupport in astmanager </cmt> <cmt> this fixes a use-after-free when an ast build finishes after shutdown(). </cmt> <cmt> [sourcekit] remove bare reference to swiftlangsupport in editor document </cmt> <cmt> while i'm not aware of this causing an issue in practice it was just </cmt> <cmt> begging to trigger a use-after-free if we ever used this reference in a </cmt> <cmt> new method since the editor document is accessed asynchronously. </cmt>",fix use-after free after sourcekitd_shutdown()
3571,"<desc> a set of of small peepholes to improve the performance of new integers: peepholes for comparisons with int.max peepholes for some variants of cond_br some overflow-check-removal improvements. </desc> <cmt> [sil-combine] canonicalize boolean equality checks </cmt> <cmt> convert i1_const != x to x != i1_const. </cmt> <cmt> convert i1_const == x to x == i1_const. </cmt> <cmt> [sil-combine] handle more patterns in cond_br conditions </cmt> <cmt> add the following peepholes: </cmt> <cmt> cond_br(x == 0), t_label, f_label -> cond_br x, f_label, t_label </cmt> <cmt> cond_br (x != 1), t_label, f_label -> cond_br x, f_label, t_label </cmt> <cmt> [constant-propagation] simplify comparisons with int.max </cmt> <cmt> make use of the following inequalities: </cmt> <cmt> 1) int.max >= x, x <= int.max are always true for any signed integer x </cmt> <cmt> 2) int.max < x, x > int.max are always false for any signed integer x </cmt> <cmt> 3) for any x of the same size as int.max and any n>=1 , (x>>n) is always <= int.max, that is (x>>n) <= int.max and int.max >= (x>>n) are always true. </cmt> <cmt> at the same time (x>>n) > int.max and  int.max < (x>>n) is always false. </cmt> <cmt> 4)  x < 0 is always false, if x is known to be a result of an unsigned operation with overflow checks enabled. </cmt> <cmt> x >= 0 is always true, if x is known to be a result of an unsigned operation with overflow checks enabled. </cmt> <cmt> redundundant-overflow-check-removal improvements </cmt> <cmt> - code-refactoring </cmt> <cmt> - support for comparison followed by a cond_fail </cmt> <cmt> - correctness fixes for relation propagation </cmt>",performance improvements for new integers
3572,"<desc> description: add support for hourly forecast, in addition to the existing daily forecast. this is controlled by a new ""mode"" config attribute. pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#11809 example entry for configuration.yaml (if applicable): weather: - platform: ipma name: home latitude: 123.123 longitude: -1.234 mode: hourly checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io </desc> <cmt> update ipma component for pyipma 2.0 </cmt> <cmt> fix wind speed; refactor forecast </cmt> <cmt> update requirements*.txt </cmt> <cmt> fix tests; update codeowners; update pyipma to 2.0.1 </cmt> <cmt> minor changes as suggested in pr </cmt> <cmt> make lint happy </cmt> <cmt> fix mocking coroutines </cmt>",allow hourly forecast in ipma
3573,"<desc> adjusted some x264 settings to make it behave more like ffmpeg. didn't touch b_filler and b_vfr_input because those seem scary, and didn't want to cause regressions. more confidence that ffmpeg tests match obs behavior. vlc playback was fine. inspected video recording frame-by-frame in avidemux. code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> obs-x264: set timebase </cmt> <cmt> matches values seen when encoding with ffmpeg. </cmt> <cmt> obs-x264: set sample aspect ratio to 1:1 </cmt> <cmt> matches values seen when encoding with ffmpeg. </cmt> <cmt> obs-x264: set crf value conditionally </cmt> <cmt> matches value seen when encoding with ffmpeg. </cmt>",x264 minor alignment with ffmpeg
3574,"<desc> imo, we should only show commands in the command palette when they are valid/actionable. this only displays the move terminal to the editor area / panel commands when it's viable to do so. it also declutters the command palette - there are so many commands, esp for the terminal </desc> <cmt> revert ""revert ""be sure that terminal target gets set for the instance (#138875)"""" </cmt> <cmt> this reverts commit 8605d7aeff46622320a70e577d0eba5c9b6557d9. </cmt> <cmt> fix #138876 </cmt> <iss> move terminal into panel resulted in an error (active editor is not a terminal) </iss>",only show commands when relevant
3575,"<desc> the vsts yaml syntax has evolved to use ""pool"" instead of ""queue"" and ""job"" instead of ""phase"".  additionally, this pr adds use of the ""ubuntu 16.04"" pool which has performance benefits over ""hosted linux preview."" </desc> <cmt> update .vsts-nightly.yml </cmt> <cmt> update .vsts-ci.yml </cmt>",update vsts yaml files with the latest syntax
3576,"<desc> ossreadme.json -> cgmanifest.json </desc> <cmt> test cgamnifests </cmt> <cmt> remove commit hash as tryout </cmt> <cmt> add all cgmanifests. still no commithash </cmt> <cmt> add commithash to cgmanifest </cmt> <cmt> cgmanifest: some commit hashes </cmt> <cmt> add repositoryurl to build/win32 cgmanifest, somehow got skipped </cmt> <cmt> add commit hashes for joaos hipster dependencies </cmt> <cmt> cgmanifest npm dependencies </cmt> <cmt> add cargo.lock </cmt> <cmt> only run component governance </cmt> <cmt> cgmanifest: npm versions </cmt> <cmt> remove build/win32/ossreadme.json </cmt> <cmt> adopt oss tool </cmt> <cmt> revert ""only run component governance"" </cmt> <cmt> this reverts commit 9c655689da433bfa95cc712b996cbb26f5d268e6. </cmt>",start using component governance for oss tracking
3577,"<desc> when profiling a large model, the trace cannot be successfully saved. gzip the traces to reduce its trace size. fix windows builds: use '' instead of '/' for paths. also don't use ':' for folder names in windows. also populate missing error message to end user to help with debugging. </desc> <cmt> save gzipped trace events json by default. </cmt> <cmt> piperorigin-revid: 298465129 </cmt> <cmt> change-id: i79bb7265d3e4ded84effd3218ecf62716df997c6 </cmt> <cmt> fix oss windows paths for profiler. </cmt> <cmt> piperorigin-revid: 298760340 </cmt> <cmt> change-id: i1ab94dd92fa80ec8b9268cbb422b78d5dc68b9cb </cmt> <cmt> clean up profiler when exception happens. </cmt> <cmt> piperorigin-revid: 298788827 </cmt> <cmt> change-id: ia420712cd0edf004aa4135cf45409d88528ed136 </cmt> <cmt> populate more error messages to the users. </cmt> <cmt> piperorigin-revid: 299445320 </cmt> <cmt> change-id: ia0d02c25ac3254444f7293d60c912989ad77ee3c </cmt>",cherry-pick request: fix profile traces too large and windows builds.
3578,"<desc> closes #33215 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry allows series.update() to accept objects that can be coerced into a series, like a dict. this mirrors the existing behavior of dataframe.update(). </desc> <cmt> enh: allow series.update() to accept coercible objects </cmt> <cmt> tst: test series.update() with non series object </cmt> <cmt> whitespace cleanup </cmt> <iss> [proposal] make series.update() accept a dictionary </iss>",make series.update() use objects coercible to series
3579,<desc> description: fixes missing strings for deconz magic cube rotation support #30472 . somehow the translations file didn't get merged. this might be because i forgot to add them to the strings.json checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> fix missing strings for deconz magic cube rotation </cmt> <cmt> fix missing strings for deconz magic cube rotation </cmt>,fix missing strings for deconz magic cube rotation support
3580,"<desc> google.maps.map.getprojection() can return null.  from the documentation: ""if the map is not yet initialized (i.e. the maptype is still null) then the result is null"" increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add imagemaptype properties. </cmt> <cmt> imagemaptypeoptions.tilesize is required </cmt> <cmt> add styledmaptype properties </cmt> <cmt> google.maps.map.getprojection() can return null. </cmt> <cmt> google.maps.map.getprojection() can return null. </cmt>",googlemaps - google.maps.map.getprojection() can return null
3581,<desc> change all string unit to theme.spacing change all multiple values to jss rule i have followed (at least) the pr section of the contributing guide. </desc> <cmt> improved sample code </cmt> <cmt> improve backtotop sample code </cmt> <cmt> update style with jss structure </cmt> <cmt> improve customizedbreadcrumbs sample code </cmt> <cmt> improve listdividers sample code </cmt> <cmt> updated with jss rule in customizedexpansionpanels style </cmt> <cmt> updated with jss rule in detailedexpansionpanel style </cmt> <cmt> use theme.spacing in interactivegrid style </cmt> <cmt> updated customizedmenus with jss rule </cmt> <cmt> updated servermodal sample code with jss rule </cmt> <cmt> updated simplemodal with jss rule </cmt> <cmt> springmodal update with jss rule </cmt> <cmt> transitionsmodal updated with jss rule </cmt> <cmt> customizedselects update with jss rule </cmt> <cmt> use theme.spacing in customizedslider style </cmt> <cmt> use theme.spacing and jss rule in customizedswitches </cmt> <cmt> use theme.spacing and jss rule in customizedinputbase </cmt> <cmt> use theme.spacing in filledtextfields style </cmt> <cmt> added theme interface in scrolltop </cmt>,improve custom styles of the demos
3582,"<desc> as described in #20366 - when the server is unable to spawn a new worker thread, this is silently ignored and leads to it being unable to respond, even if after some time new threads could be spawned. this pr proposes to solve this by checking the return-value of grpc_core::thread adjusting num_pollers, num_threads reporting resource_exhausted fixes #20366 @nicolasnoble </desc> <cmt> merging upstream changes </cmt> <cmt> check if workerthread could be spawned </cmt> <iss> c++ synchronous server unresponsive, after threadlimit was reached </iss>",c++ check if workerthread could be spawned
3583,"<desc> now when searching via the assistant it will index the whole file system and surface interesting results to select. when you activate a result, it will use the default handlers via the desktop::launcher to open the file or directory. </desc> <cmt> assistant: remove result::kind in favor of native typeid </cmt> <cmt> i was unaware of the typeid construct in c++ which can be used to </cmt> <cmt> achieve the same thing i was doing with this extra kind enum. </cmt> <cmt> libthreading: add ability to cancel ongoing backgroundactions </cmt> <cmt> handlers of the backgroundaction are responsible for checking if the </cmt> <cmt> action has been cancelled and returning early. </cmt> <cmt> assistant: add a new fileprovider to assist in searching the filesystem </cmt> <cmt> when searching in assistant, we now dispatch some background jobs to </cmt> <cmt> query the whole filesystem. activating a result will use the desktop </cmt> <cmt> launcher's default way of opening that file or directory. </cmt>",add a new fileprovider for searching the file system
3584,<desc> add tests for the previous behaviour (returning nmatched) i verified they pass on devel too before adding to this branch. fix a bug with upserting when it did not cause any change. </desc> <cmt> change update/upsert to return nmodified as numberaffected </cmt> <cmt> fix a bug with upserting documents that did not changed </cmt>,mongo 3.2 update/upsert returns nmatched as numberaffected
3585,<desc> adding: airtime ardor audacious audacity audio recorder cantata clementine cmus deepin google play music gpodder harmony hydrogen k3b kid3qt kxstudio libretime lmms lollypop lyricfier mixxx museek- </desc> <cmt> initial commit </cmt> <cmt> add portuguese translation for music applications </cmt>,adding portuguese translation for music applications
3586,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> types for meteor/dburles:collection-helpers </cmt> <cmt> new collection<t> now returns a collection<t>, not a collection<data<t>> </cmt>",types for meteor/dburles:collection-helpers [meteor-dburles-collection-helpers]
3587,"<desc> description: if several broadlink devices are used, the learn service should be given separate names. the learn service is also only needed for rm devices. the other bugs i have seen have to wait until @mjg59 has merged these prs:  related issue (if applicable): fixes parts of #4997 checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> solve some bugs in the bradlink switch </cmt> <cmt> style fix </cmt>",solve some bugs in the broadlink switch
3588,"<desc> example: in [8]: a = array([[0,1,2],[3,4,0]]) in [9]: a out[9]: array([[0, 1, 2], in [10]: norm(a, axis=0) out[10]: array([ 3.        ,  4.12310563,  2.        ]) in [11]: norm(a, axis=1) out[11]: array([ 2.23606798,  5.        ]) in [12]: norm(a, ord=np.inf, axis=1) out[12]: array([2, 4]) axis can be a 2-tuple: in [52]: a = np.arange(8).reshape(2,2,2) in [53]: a out[53]: array([[[0, 1], in [54]: norm(a, axis=(1,2)) out[54]: array([  3.74165739,  11.22497216]) this pr also fixes a bug that occurs when computing the norm of an integer array with a negative ord.  before this change, norm([1,3], ord=-1) returned the incorrect value 1.0.  now, in [13]: norm([1,3], ord=-1) out[13]: 0.75 </desc> <cmt> enh: linalg: add the axis keyword to linalg.norm. </cmt> <cmt> also fixed a bug that occurred with integer arrays and negative ord.  for example, </cmt> <cmt> norm([1, 3], -1) returned 1.0, but the correct value is 0.75. </cmt> <cmt> maint: linalg: removed unused imports from linalg.py </cmt>",linalg: add an axis argument to linalg.norm
3589,"<desc> collection of commits to instrument more kernel api's with [[nodiscard]]. ak/optional getters kernel/stdlib.h c api functions. kernel/lock getters kernel/kbuffer getters kernel/userorkernelbuffer getters kernel/kresult getters kernel/physicaladdress getters kernel/virtualaddress getters </desc> <cmt> kernel: mark more stdlib functions as [[nodiscard]] </cmt> <cmt> in the never ending journey to catch bugs, mark more functions </cmt> <cmt> as [[nodiscard]] to find incorrect call sites. </cmt> <cmt> kernel: mark physicaladdress/virtualaddress getters as [[nodiscard]] </cmt> <cmt> there is no reason to call a getter without observing the result, doing </cmt> <cmt> so indicates an error in the code. mark these methods as [[nodiscard]] </cmt> <cmt> to find these cases. </cmt> <cmt> ak: mark optional getters as [[nodiscard]] </cmt> <cmt> there is no reason to call a getter without observing the result, doing </cmt> <cmt> so indicates an error in the code. mark these methods as [[nodiscard]] </cmt> <cmt> to find these cases. </cmt> <cmt> kernel: mark kresult getters as [[nodiscard]] </cmt> <cmt> there is no reason to call a getter without observing the result, doing </cmt> <cmt> so indicates an error in the code. mark these methods as [[nodiscard]] </cmt> <cmt> to find these cases. </cmt> <cmt> kernel: mark userorkernelbuffer and it's getters as [[nodicard]] </cmt> <cmt> userorkernelbuffer objects should always be observed when created, in </cmt> <cmt> turn there is no reason to call a getter without observing the result. </cmt> <cmt> doing either of these indicates an error in the code. mark these methods </cmt> <cmt> as [[nodiscard]] to find these cases. </cmt> <cmt> kernel: mark lock getters as [[nodiscard]] </cmt> <cmt> there is no reason to call a getter without observing the result, doing </cmt> <cmt> so indicates an error in the code. mark these methods as [[nodiscard]] </cmt> <cmt> to find these cases. </cmt>",mark more apis as [[nodiscard]]
3590,"<desc> this pr is to update the version of opencv used in the maven released packages for os x. i missed making this change on the v1.2.0 branch earlier when v1.2.1 was announced. the pr was test on my local mac by running make scalapkg make scalatest last few lines of the test execution showing successful run. info] --- scalatest-maven-plugin:1.0:test (test) @ mxnet-full_2.11-osx-x86_64-cpu --- discovery starting. discovery completed in 74 milliseconds. run starting. expected test count is: 0 discoverysuite: run completed in 165 milliseconds. total number of tests run: 0 suites: completed 1, aborted 0 tests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0 no tests were executed. saving to outputfile=/users/wamy/nswamy/deepengine/workspace/mxnet_scala/scala-package/assembly/osx-x86_64-cpu/target/scalastyle-output.xml processed 0 file(s) found 0 errors found 0 warnings found 0 infos finished in 3 ms </desc> <cmt> use opencv3.4.1 for mac builds </cmt> <cmt> [maven-release-plugin] prepare release mxnet-parent_2.11-1.2.1 </cmt> <cmt> [maven-release-plugin] prepare for next development iteration </cmt> <cmt> update opencv@2 to opencv for v1.2.0 branch and update version to scala package versionto  1.2.2 </cmt>",update script used for building osx maven packages in v1.2.0
3591,"<desc> i have followed (at least) the pr section of the contributing guide. closes #9337 problem: as mentioned in the issue, change in the width of a tab container currently does not update indicator's width. rather, indicator's width updates only in response to the viewport's resizing. solution: use resizeobserver api to observe the tab containers and update the width of their corresponding indicators in response to their resizing. without the implementation of this pull request (when there is change in the width of a tab): with the implementation of this pull request (when there is change in the width of a tab): </desc> <cmt> implement useresizeobserver hook </cmt> <cmt> update indicator when tab container size changes </cmt> <iss> [tabs] update position when layout change (resizeobserver) </iss>",fix indicator position when tab size changes (resizeobserver)
3592,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment changed name of organisation using superset, from wp-semantix to timbr.ai test plan requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> latest apache superset (rc 0.33) </cmt> <cmt> latest changes from apache-superset </cmt> <cmt> update master branch </cmt> <cmt> update organisation name from wpsemantix to timbr.ai </cmt>",update superset organisation users in readme
3593,"<desc> this addresses issue #1947 the goal is that this: looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var + looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var >> looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var gets formatted to: looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var + looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var >> looooooooooooooooooooooooooooooooooooooooooooooooooooooooong_var i added a condition in visit_simple_stmt to wrap the first child in invisible parentheses in case it is one of arith_expr, shift_expr, xor_expr, or and_expr. i added some tests but i don't know if that's enough? also they seem to have messed up the expected diff files, should this be done any differently? looking forward to your feedback! </desc> <cmt> wrap some expressions in invisible parentheses </cmt> <cmt> add test for xor and binary and </cmt> <cmt> update expression.diff </cmt>",wrap arithmetic and binary arithmetic expressions in invisible parentheses
3594,"<desc> i found a few typos while going through the .rst files of this repo. although it's quite possible i missed some, this pr fixes the ones that i did stumble across. i also found some words which seem to be spelled in multiple ways throughout. some of the differences seemed typical of british vs american spelling but others i was unsure of. in any case, i did not modify examples like these. version 1 version 2 colour color parseable parsable referenceable referencable pickleable picklable focusses focuses parameterise parameterize </desc> <cmt> fix typos: standar -> standard, deprication -> deprecation </cmt> <cmt> fix typo: cirumstances -> circumstances </cmt> <cmt> fix typo: turle -> turtle </cmt> <cmt> fix typo: compabitility -> compatibility </cmt> <cmt> fix typos: endcoding -> encoding, oringally -> originally </cmt> <cmt> fix typos: enocded -> encoded, alphebet -> alphabet </cmt> <cmt> fix typos: cotnent -> content, compatibile -> compatible </cmt> <cmt> fix typo: oringally -> originally </cmt> <cmt> fix typos: udpate -> update, compabitility -> compatibility, haders -> headers, prefernec -> preference, oringally -> originally </cmt> <cmt> fix typo: endcoding -> encoding </cmt> <cmt> fix typo: sematnics -> semantics </cmt> <cmt> fix typos: greather -> greater, trasmission -> transmission, oringally -> originally </cmt> <cmt> fix typo: operater -> operator </cmt> <cmt> fix typo: mone -> mono </cmt> <cmt> fix typo: propmt -> prompt </cmt> <cmt> fix typo: awaitalbe -> awaitable </cmt> <cmt> fix typo: informations -> information </cmt>",fix typos in multiple .rst files
3595,"<desc> before, preprocess_input would sometimes write over images it processed. inadvertently, my commit (84e168b) from two days ago changed this so that instead of the previous behaviour, preprocess_input would always make a new copy of the input images to work with. this seems, to me, more intuitive behaviour. this pr gives the user explicit control over the behaviour by introducing copy keyword argument to the relevant functions. this way, the earlier behaviour can be regained if the user so wishes. also, it fixes my earlier commit so that the dtype of the input array is not changed unless necessary (i.e. when inputting other than float arrays). </desc> <cmt> add copy option for image preprocessing </cmt> <cmt> fix unnecessary import </cmt> <cmt> fix style </cmt> <cmt> fix test error </cmt>",preprocess_input copying/not copying the input arrays
3596,"<desc> fixes: #10175 as discussed in #10175 i added checks/tests for binary case. to do so, i created a helper function for check_classifiers_classes in order to be able to reuse existing code and support binary string and int labels: ['one', 'two'] and [1, -1]. i also added check for decision_function. </desc> <cmt> add common tests for binary case </cmt> <cmt> rename updatelabels method </cmt>",add common tests for consistent decision_function behavior in binary case
3597,"<desc> will have to see which issues this closes.  this is also a precursor to upcoming pr that dispatches dataframe ops to series (which in turn dispatches to index). fixes #7830 (the op's example is already fixed, this fixes examples in the comments to that issue) fixes dti half of #19804 closes #7830 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fix tzawareness compat with np.datetime64 </cmt> <cmt> fix dti comparisons against invalid strings </cmt> <cmt> whatsnew, de-duplicate test </cmt> <cmt> fix dti comparisons against tdi </cmt> <cmt> fix dti comparisons against object-dtype </cmt> <iss> equality comparison raises exception </iss>",fix various datetimeindex comparison bugs
3598,<desc> this pull request fixes a crash on scrolling down (overflow exception cramming the signed short upper word of the wparam into an actual signed short on x64) and a crash on key input caused by improper use of marshal.readbyte on an integer (instead of a memory address). manually did those things on x64. </desc> <cmt> wpf: fix incorrect use of marshal.readbyte in wm_key/char </cmt> <cmt> wpf: fix a crash on scrolling down </cmt>,fix two crashes and some fallout from the new key event handler
3599,<desc> koa-static-server type shape is different than the current implementation. the current implementation uses koa-send to support sending files. koa-send receives all the options from koa-static-server. koa-send receives brotli as an option. [xadd or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code that provides context for the suggested changes: package dependency on koa-send package package.json dependency version koa-send definitions </desc> <cmt> adding brotli parameter that is also available. </cmt> <cmt> adding tests for pr </cmt>,adding brotli option to koa-static-server
3600,"<desc> spdy: fixed parsing of http version. there is an error while parsing multi-digit minor version numbers (e.g. ""http/1.10""). nginx commit log:  spdy: fixed the data frame length handling in case of some errors. in our production, sometimes, the disk was full. in which case, the requests after the post request were handled wrongly in one spdy connection. because the input body (data frame) of post request could not be written to disk, then ngx_http_spdy_state_read_data() tried to skip this data frame with wrong sc->length, which broke spdy stream. nginx commit log: </desc> <cmt> spdy: fixed parsing of http version. </cmt> <cmt> there is an error while parsing multi-digit minor version numbers (e.g. </cmt> <cmt> ""http/1.10""). </cmt> <cmt> spdy: fixed the data frame length handling in case of some errors. </cmt> <cmt> there are a few cases in ngx_http_spdy_state_read_data() related to error </cmt> <cmt> handling when ngx_http_spdy_state_skip() might be called with an inconsistent </cmt> <cmt> state between *pos and sc->length, that leads to violation of frame layout </cmt> <cmt> parsing and resuted in corruption of spdy connection. </cmt>",spdy bugfix for parsing http version and handling data frame length
3601,"<desc> based on #1759, added some nitpicks to minimize changes. thank you for nice improvement, @rnsanchez </desc> <cmt> add global directive temp-buffer-threshold </cmt> <cmt> add a global directive in the configuration file, allowing the user to </cmt> <cmt> tune the threshold for file-backed temporary buffers.  the minimum value </cmt> <cmt> accepet is 1mb, and the current default of 32mb is preserved. </cmt> <cmt> to disable the use of temporary buffers, the user can set this directive </cmt> <cmt> to off. </cmt> <cmt> examples: </cmt> <cmt> temp-buffer-threshold: off </cmt> <cmt> temp-buffer-threshold: 1048576 </cmt> <cmt> temp-buffer-threshold: 67108864 </cmt> <cmt> use size_max for the off value of mmap_settings.threshold for simplicity </cmt>",knob to tune disk-based memory allocation threshold
3602,"<desc> i hereby agree to the terms of the cla available at:  changelog category: changelog entry: fixed issue when clickhouse-odbc-bridge process is unreachable by server on machines with dual ipv4/ipv6 stack; - fixed issue when odbc dictionary updates are performed using malformed queries and/or cause crashes; possibly closes #14489. detailed description: clickhouse-odbc-bridge now binds to 127.0.0.1 by default instead of localhost, this solves a problem when server tries to connect to ::1 while the bridge is listening to 127.0.0.1 when localhost resolves to those addresses. externalquerybuilder instance stores const-refs to members of enclosing object, and when that object is clone()'ed and the original object is destroyed, the instance of externalquerybuilder, that is stored in the new enclosing object, now refers to the destroyed members and builds queries with garbage in them, accessing the destroyed objects. fixes now closed #17215. seemingly a typo in readwritebufferfromhttpbase::call(). fixed. </desc> <cmt> use 127.0.0.1 as a default listen-host for odbc bridge </cmt> <cmt> store copies instead of refs in externalquerybuilder instances </cmt> <cmt> apply path workaround on actual uri_ argument </cmt> <cmt> print out actual uri_ argument being used </cmt> <iss> ""clickhouse-odbc-bridge is not responding"" during dictionary initialization: program startup sequence problems </iss> <iss> incorrect columns and segfault in odbc external dictionary updates </iss>",fixes in odbc dictionary reload and odbc bridge reachability
3603,"<desc> this also contains the request to transform flashactivity to a fragment. the navigation has been transformed to use navigationcomponents as the primary source. </desc> <cmt> added log as primary fragment </cmt> <cmt> updated the width of bottom navigation </cmt> <cmt> updated the app to use navigation components instead of custom solution </cmt> <cmt> welcome to mid 2018. </cmt> <cmt> fixed log not displaying back button when alternative view is shown </cmt> <cmt> added back button for modulefragment when displaying filter </cmt> <cmt> added requesting navigation being hidden when showing alternative view </cmt> <cmt> updated flash screen so it's a fragment </cmt> <cmt> the flashactivity has been removed and all of it's functionality has been transferred to the flashfragment. </cmt> <cmt> the flashfragment needs to be however launched in a different way than the activity using the mainactivity's stub and so seemingly massive changes had to be made. </cmt> <cmt> notably the remotefileservice didn't seem to be calling service.startforeground(), which has been crashing the application due to the system requirements, so that's been fixed. </cmt>",log as primary navigation destination
3604,<desc> implemented for windows and linux. edit: now also for mac thanks to @bruvzg. this code is donated by adpodnet. </desc> <cmt> unify x11 fullscreen setup </cmt> <cmt> add new window setting: always on top </cmt> <cmt> implemented for windows and linux. </cmt>,add new window setting: always-on-top (2.1)
3605,"<desc> this is my first attempt at writing an extractor. please feel free to point out any problems before merging it. </desc> <cmt> [br] add ""br"" extractor </cmt> <cmt> extractor for videos from the bayerischer rundfunk mediathek[1]. currently only </cmt> <cmt> supports videos. audio and podcasts do not work yet with this extractor. </cmt> <cmt> 1: </cmt> <cmt> [br] add basic test </cmt>",add extractor for br.de (bayerischer rundfunk mediathek)
3606,"<desc> this pr adds large tensor support to np.roll local run: ubuntu@ip-172-31-38-169:~/incubator-mxnet$ pytest tests/nightly/test_np_large_array.py::test_roll /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) /home/ubuntu/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: runtimewarning: numpy.ufunc size changed, may indicate binary incompatibility. expected 192 from c header, got 216 from pyobject return f(*args, **kwds) ================================================ test session starts ================================================ platform linux -- python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 rootdir: /home/ubuntu/incubator-mxnet, inifile: pytest.ini plugins: remotedata-0.3.2, openfiles-0.4.0, astropy-header-0.1.2, hypothesis-5.8.3, arraydiff-0.3, doctestplus-0.5.0 collected 1 item tests/nightly/test_np_large_array.py   .                                                                        [100%] ================================================ 1 passed in 24.10s ================================================= </desc> <cmt> initial </cmt> <cmt> fix more index </cmt> <cmt> tweak </cmt> <cmt> tweak </cmt> <cmt> add tests </cmt> <cmt> tweak </cmt>",numpy roll large tensor fix fix
3607,"<desc> similar to an old pr #3007, but instead of adding initializer into input and removing (sort of hacky), this pr uses a new node list for initializer and creates a value directly. enable node to find input from initializers: create addinitializernode function for adding new initializer, convert tensor (initializer,) into a value, add it into value_by_name_of. add a python test to test if the node inputs come from initializers solve input not found issue for version converter since initializers are not included in inputs for newer model (ir >= 4): #2873 </desc> <cmt> add init tensor as value </cmt> <cmt> nit: comments </cmt> <iss> version converter 11 -> 12 fails with ""indexerror: input s is undefined!"" </iss>",update node input from initializer directly
3608,"<desc> change the meaning of asyncify_imports: it now contains only new imports you add, and does not need to contain the list of default system imports like emscripten_sleep. there is no harm in providing them, though, so this is not a breaking change. this avoids the need for a way to append to asyncify_imports, which #10629 proposed as a new -s x+=[..] notation, but was too complex. </desc> <cmt> yolo </cmt> <cmt> flake8 </cmt>","do not require the default imports, just provide the new ones"
3609,"<desc> part of #1519, some round tripping behaviors do not function correctly. </desc> <cmt> rename serverop to operation in v1beta3 and internal </cmt> <cmt> add the appropriate rename logic internally. </cmt> <cmt> podstatus message needs to be round-trippable </cmt> <cmt> status should be a listmeta, not objectmeta internally </cmt>",fix internal -> v1beta3 round trip issues
3610,"<desc> i've taken clang's constantinitbuilder, enhanced it to satisfy swift's needs, and made it public api.  this pr changes swift to use it.  functionally nfc but does change irgen patterns. depends on a change to clang, obviously. </desc> <cmt> adopt constantinitbuilder in a few places. </cmt> <cmt> use constantinitbuilder in most kinds of metadata emission. </cmt> <cmt> this is nfc in intent, but i had to restructure the code to emit more </cmt> <cmt> of the lists ""inline"", which means i inevitably altered some irgen </cmt> <cmt> emission patterns in ways that are visible to tests: </cmt> <cmt> - genclass emits property/ivar/whatever descriptors in a somewhat </cmt> <cmt> different order. </cmt> <cmt> - an ext method type list is now emitted as just an array, not a struct </cmt> <cmt> containing only that array. </cmt> <cmt> - protocol descriptors are no longer emitted as packed structs. </cmt> <cmt> i was sorely tempted to stop using packed structs for all the metadata </cmt> <cmt> emission, but didn't really want to update that many tests in one go. </cmt>",replace swift's constantbuilder with clang's constantinitbuilder
3611,"<desc> first commit comes from ed's #20459, while subsequent commits make some refactoring changes, fix tests and backwards compatibility checks with existing jobs functionality. current logs api simply returns a str to unblock development and integration. we should add proper log streaming for better ux and external job manager integration. closes #19415 test plan ray cluster + dashboard from 1.9 public release, use cli code from this pr: ensure it works and there's no automatic log following. ray cluster + dashboard from source, use cli code from this pr: ensure it works and automatic following is enabled with finishing message. backwards compatibility test manually edit cli.py implementation of job_submit to use skip version check and call into version 1 only api: if not no_wait: cli_logger.print(""tailing logs until the job exits "" ""(disable with --no-wait):"") asyncio.get_event_loop().run_until_complete(_tail_logs(client, job_id)) ensure we can see compatibility exception thrown as expected with 1 return code:  # sdk version 0 does not have log streaming if not no_wait and int(sdk_version) > 0: cli_logger.print(""tailing logs until the job exits "" ""(disable with --no-wait):"") asyncio.get_event_loop().run_until_complete(_tail_logs(client, job_id)) change back to pr's implementation with version check and ensures shell script and pytest case passes. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add cli </cmt> <cmt> cherry-pick ed's first commit and resolve current head merge conflicts </cmt> <cmt> [docs] add a talks section for ray.data (#20444) </cmt> <cmt> cherry-pick </cmt> <cmt> [ci] don't test tune dashboard (#20452) </cmt> <cmt> [serve] add experimental pipeline docs (#20292) </cmt> <cmt> empty merge commit </cmt> <cmt> add error messages for missing tf and torch imports (#20205) </cmt> <cmt> cherry-pick allow empty </cmt> <cmt> add cli </cmt> <cmt> cherry-picking </cmt> <iss> logs streaming api in http server </iss>",add log streaming for jobs
3612,"<desc> the operation was not being flushed prior to reading it, causing the r_file_slurp to not return anything. this is part of the fix addressing some of the issues discussed in #9286 but it still is not enough to allow for remotely setting of the reg profile, due to it being replaced later (see my last comment in that issue). so just thought i'd submit the pr now, as i'm not sure how to resolve the rest. if i can get some details about it i'd be happy to try and fix the remaining issue. </desc> <cmt> flush before closing pipe </cmt> <cmt> fix formatting </cmt>",fix debug rap reg profile setup
3613,<desc> a follow-up for f00c366 </desc> <cmt> tmpfiles: downgrade log message when we can't write a file and failure is allowed </cmt> <cmt> tmpfiles: don't complain if we can't enable pstore in containers </cmt>,let's make pstore sysfs failure silent
3614,<desc> added a new plugin for composer: command completion alias added two alias to the symfony2 plugin </desc> <cmt> added two aliases to symfony2 plugin </cmt> <cmt> added composer completition and aliases </cmt> <cmt> added a comment to the composer installation alias </cmt>,added composer plugin and symfony2 alias
3615,"<desc> description: a required part of #8606 in order to move the redirection code into conn_pool.  however this change alone have significant performance improvement.   here's performance benchmark on creating the composite array respvalue vs copying to temp respvalue. run on (12 x 2900 mhz cpu s) cpu caches: l1 data 32k (x6) l1 instruction 32k (x6) l2 unified 262k (x6) l3 unified 12582k (x1) load average: 6.78, 5.23, 8.80 ----------------------------------------------------------------------------- benchmark                                   time             cpu   iterations ----------------------------------------------------------------------------- bm_split_compositearray/1/64             19.5 ns         19.4 ns     36299899 bm_split_compositearray/8/64              141 ns          140 ns      5232197 bm_split_compositearray/64/64            1140 ns         1130 ns       652024 bm_split_compositearray/100/64           1670 ns         1665 ns       386380 bm_split_compositearray/1/512            19.3 ns         19.3 ns     36146383 bm_split_compositearray/8/512             143 ns          142 ns      5301183 bm_split_compositearray/64/512           1067 ns         1052 ns       671862 bm_split_compositearray/100/512          1650 ns         1648 ns       430989 bm_split_compositearray/1/4096           19.7 ns         19.6 ns     36376864 bm_split_compositearray/8/4096            135 ns          135 ns      5027833 bm_split_compositearray/64/4096          1058 ns         1054 ns       651617 bm_split_compositearray/100/4096         1812 ns         1736 ns       429714 bm_split_compositearray/1/32768          20.5 ns         20.2 ns     33806136 bm_split_compositearray/8/32768           150 ns          149 ns      4676768 bm_split_compositearray/64/32768         1182 ns         1169 ns       577186 bm_split_compositearray/100/32768        1649 ns         1644 ns       355436 bm_split_compositearray/1/131072         18.6 ns         18.6 ns     36814785 bm_split_compositearray/8/131072          139 ns          139 ns      5344327 bm_split_compositearray/64/131072        1094 ns         1091 ns       633886 bm_split_compositearray/100/131072       1685 ns         1675 ns       409012 bm_split_copy/1/64                        377 ns          376 ns      1997820 bm_split_copy/8/64                        605 ns          602 ns      1097988 bm_split_copy/64/64                      2385 ns         2377 ns       319295 bm_split_copy/100/64                     3519 ns         3501 ns       217828 bm_split_copy/1/512                       387 ns          384 ns      1738146 bm_split_copy/8/512                       611 ns          608 ns      1066374 bm_split_copy/64/512                     2446 ns         2440 ns       278151 bm_split_copy/100/512                    3849 ns         3833 ns       190523 bm_split_copy/1/4096                      360 ns          359 ns      1893883 bm_split_copy/8/4096                      857 ns          849 ns       855997 bm_split_copy/64/4096                    6086 ns         5999 ns       123697 bm_split_copy/100/4096                   9800 ns         9752 ns        62226 bm_split_copy/1/32768                    1048 ns         1044 ns       754863 bm_split_copy/8/32768                    6433 ns         6413 ns       115586 bm_split_copy/64/32768                  59917 ns        59225 ns        12587 bm_split_copy/100/32768                101912 ns       101430 ns         5637 bm_split_copy/1/131072                   3044 ns         3040 ns       192319 bm_split_copy/8/131072                  31505 ns        31412 ns        21698 bm_split_copy/64/131072                376804 ns       375900 ns         1909 bm_split_copy/100/131072               783793 ns       781530 ns          824 risk level: medium testing: added unit tests docs changes: n/a release notes: yes </desc> <cmt> avoid string copy by creating a composite array respvalue type. </cmt> <cmt> fix format </cmt>",avoid string copy for redis command splitter
3616,<desc> test_car_interfaces.py and test_models.py weren't running at all for cars without a legacy can fingerprint. should fix ci passing incorrectly in cases like #21013. </desc> <cmt> start refactor of ci tests for fpv1 deprecation </cmt> <cmt> fix test_car_interfaces </cmt>,update ci tests for can fingerprinting deprecation
3617,"<desc> this checks for conflicts between tmc uart addresses at build time. this works for all supported axis, for both hw and sw serial. provides conflict messages at build-time. sample hardware serial error: marlin\src\module\stepper\trinamic.cpp:843:31: error: static assertion failed: x_slave_address conflicts with another driver using the same x_hardware_serial #define sa_no_tmc_hw_c(a) static_assert(no_tmc_hw_serial_conflict(tmc_hw_detail_args(a)), tmc_hwserial_conflict_msg(a)); ^ marlin\src\module\stepper\trinamic.cpp:844:5: note: in expansion of macro 'sa_no_tmc_hw_c' sa_no_tmc_hw_c(x);sa_no_tmc_hw_c(x2); ^~~~~~~~~~~~~~ sample sw serial error: marlin\src\module\stepper\trinamic.cpp:873:31: error: static assertion failed: x_slave_address conflicts with another driver using the same x_serial_rx_pin or x_serial_tx_pin #define sa_no_tmc_sw_c(a) static_assert(no_tmc_sw_serial_conflict(tmc_sw_detail_args(a)), tmc_swserial_conflict_msg(a)); ^ marlin\src\module\stepper\trinamic.cpp:874:5: note: in expansion of macro 'sa_no_tmc_sw_c' sa_no_tmc_sw_c(x);sa_no_tmc_sw_c(x2); ^~~~~~~~~~~~~~ n/a n/a </desc> <cmt> add build-time tmc conflict detection </cmt> <cmt> allow more than one space in opt_set </cmt>",build-time tmc address conflict detection
3618,<desc> backport of #17548. this fixed the issue for me on cygwin with gcc 7.4.0 by adding the compiler flags necessary to work around the issue as described in #14787. might also help with #16246. </desc> <cmt> bld: add new check_compiler_gcc and check_gcc_version_at_least configure </cmt> <cmt> commands </cmt> <cmt> replaces obsolete (no longer used anywhere afict check_compiler_gcc4 </cmt> <cmt> with some more general utilities for checking gcc version </cmt> <cmt> bug: workaround for #14787: on windows/cygwin add extra compiler flags </cmt> <cmt> when building the numpy.core._multiarray_umath module </cmt> <cmt> this adds the extra compile args to the extension needed to work around </cmt> <cmt> the bug but only in the known case where the bug is relevant. </cmt>,cygwin workaround for #14787 on affected platforms
3619,"<desc> for turning on exactoptionalpropertytypes recommended option introduced in typescript 4.4, cursoroptions interface's rangestart and rangeend field typings lead to incorrect extension of options interface. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> style: fix indentation according to editorconfig </cmt> <cmt> fix: cursoroptions for exactoptionalpropertytypes </cmt> <cmt> test[prettier]: add cases for formatwithcursor </cmt> <cmt> style: revert indentation according to prettier </cmt>",remove explicit undefined for cursoroptions optional fields
3620,<desc> description: trivial cleanup to define the conf_icon_template in consts.py instead of in each template file. there is no functionality change. checklist: if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add 'icon_template' to switch templates (similar to sensor template) </cmt> <cmt> add test for template switch 'icon_template' </cmt> <cmt> define 'conf_icon_template' constant centrally </cmt>,minor cleanup - define 'conf_icon_template' constant centrally
3621,"<desc> fixes #2787. this is a wip because we need to check if wrapping value with a ndarray at predict time is too expensive in time. if so, we can implement our own take using memcpy (which i'd rather over reverting to the version where predict duplicates apply) but for the moment i'm having trouble getting that to work... this also needs to be tested for any further memory leaks. </desc> <cmt> fix remove reference cycles from tree </cmt> <cmt> fix dtype refcount; block resizing after building </cmt> <iss> [regression] memory leak in decision trees </iss>",avoid reference cycles in tree
3622,<desc> improve the repo by fixing some grammer and restructuring sentences in the german howto and contribution files. resolves #5887. read our contributing guidelines </desc> <cmt> improve german howto file by fixing some grammar and restructuring some sentences to make it easier to read and understand </cmt> <cmt> improve german contributing file by fixing some grammar and fix some readability issues </cmt> <iss> improvement of the german (de) howto file </iss>,improvements to the german howto and contribution files
3623,"<desc> adjusts width and positioning of prev/next button text area, rotates arrows left/right on small screens. rotate text and remove arrow rotate on medium up. #18963 </desc> <cmt> rotates prev/next link text at medium bp, rotates arrows up to medium bp, adjusts prev/next img margins </cmt>",update details modal prev/next button transform
3624,"<desc> don't remove the downloaded ffmpeg, gnutls and libdvd source code and vcredist for every build on jenkins. speed up jenkins job and no need to redownload files that never change. run the commands execute by jenkins locally bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [buildsteps][windows] git clean optimizations </cmt> <cmt> - remove directories with .git subdirectory </cmt> <cmt> - don't remove vcredist </cmt> <cmt> [buildsteps][windows] download ffmpeg, gnutls & libdvd* to a location not cleaned by prepare-env </cmt>",optimize keeping of downloaded files
3625,<desc> the ce use an old version of the trt which do not support the new added interface. add an macro to skip this. </desc> <cmt> fix mask rcnn predictor </cmt> <cmt> 1. refine memory optim algorithm to support the model with the block op. </cmt> <cmt> 2. output diff : modify the affine channel fuse </cmt> <cmt> 3. add condition_block_infer op </cmt> <cmt> add interface for setting trt calib table dir </cmt> <cmt> test=develop </cmt> <cmt> add the missing files. </cmt> <cmt> test=develop </cmt> <cmt> 1 add trt fp16 support </cmt> <cmt> test=develop </cmt> <cmt> fix trt fp16 ce error </cmt> <cmt> test=develop </cmt> <cmt> test=develop </cmt>,fix the ce error which caused by paddle-trt version
3626,<desc> remove: react-window react-window-infinite-loader simplebar-react include: react-virtuoso rc-scrollbars </desc> <cmt> include react-virtuoso package </cmt> <cmt> [wip] add virtuoso to discussions list </cmt> <cmt> rewrite discussions component with react-virtuoso </cmt> <cmt> add react-virtuoso to threads list </cmt> <cmt> add react-virtuoso to roomlist component </cmt> <cmt> update svg attr to jsx attr </cmt> <cmt> add react-virtuoso to roomfiles component </cmt> <cmt> add react-virtuoso to roommembers component </cmt> <cmt> add rc-scollbars to the project </cmt> <cmt> fix loadmore problem from roomfiles and roommembers components </cmt> <cmt> change simplebar from rc-scrollbars on scrollablecontentwrapper component </cmt> <cmt> include custom scrollbar in components with react-virtuoso </cmt> <cmt> include custom scrollbar in components with react-virtuoso </cmt> <cmt> [wip] sidebar with virtuoso + rc-scrollbars </cmt> <cmt> rc-scrollbars + react-virtuoso in roomlist component </cmt> <cmt> rc-scrollbars + react-virtuoso in searchlist component </cmt>,replace react-window for react-virtuoso package
3627,"<desc> xref #18838. this pr improves the current any-based placeholder annotations within a number of modules, replacing them with explicit functions, classes or objects when appropiate. while parameters of the respective methods and functions remain unannotated (for now), these changes nevertheless provides a notable improvement over a plain any. part 1 in a series of 2 or 3 prs. </desc> <cmt> maint: add void.__getitem__ and __setitem__ </cmt> <cmt> enh: add improved placeholder annotations for np.emath </cmt> <cmt> enh: add improved placeholder annotations for np.ctypeslib </cmt> <cmt> enh: add improved placeholder annotations for np.char </cmt> <cmt> enh: add improved placeholder annotations for np.rec </cmt> <cmt> enh: add improved placeholder annotations for np.fft </cmt> <cmt> enh: add improved placeholder annotations for np.f2py </cmt> <cmt> enh: add improved placeholder annotations for np.testing </cmt> <cmt> enh: add improved placeholder annotations for np.matrixlib </cmt>",improve the placeholder annotations within sub-modules
3628,"<desc> modified beforeafterwrapper removed default style. new prop to enhancedtextarea textareastyle - replaces textareaclassname that was removed in a previous commit. removed use of ::after pseudo-elements. instead, a div is manually created. </desc> <cmt> refactored css for textfields. </cmt> <cmt> removed underline style props. </cmt> <cmt> removed unused dependency. </cmt>",refactored css into js for textfields
3629,"<desc> this fixes a bunch of minor stuff with our browser tests, including removing dump() calls (firefox-only) remove initkeyevent usage (deprecated on the web and removed from chrome already) a timing issue with reftests that don't render immediately (somehow it still worked in firefox due to timing differences). mark more tests that compile synchronously as no_chrome. with those, almost all tests pass for me locally on chrome. i had to skip a few (just 4) and open issues for them, on things that are related to gl and need further investigation. not sure passing locally means they'll pass on ci though, let's see... </desc> <cmt> use new keyboardevent(), as event.initkeyevent was deprecated and removed from chrome </cmt> <cmt> remove dump() calls </cmt> <cmt> more keyboardevent </cmt> <cmt> more keyboardevent </cmt> <cmt> test fixes </cmt> <cmt> run almost all browser tests in chrome </cmt> <cmt> mark a test as no-chrome </cmt> <cmt> add a mechanism to manually run a reftest, for tests that are async </cmt> <cmt> add circle skips and links </cmt>",get most chrome browser tests running
3630,<cmt> use call_soon_threadsafe() for _asyncgen_finalizer_hook(). </cmt> <cmt> should fix bpo-34769 in debug mode. </cmt> <cmt> add test for _asyncgen_finalizer_hook in normal conditions. </cmt> <cmt> tests whether async generators are finalized correctly when garbage collected in the same thread. </cmt> <cmt> fix whitespace. </cmt> <cmt> add comments and change test name. </cmt> <cmt> add test for buggy case: running gc in other thread. </cmt> <cmt> add news entry. </cmt> <cmt> fix a forgotten await. </cmt> <cmt> fix typo and condense comments. </cmt> <cmt> fix test for 3.6. </cmt>,thread safety for _asyncgen_finalizer_hook(). (gh-9716)
3631,"<desc> a fix for #7095. and some minor fixes around it. </desc> <cmt> loginctl: invoke sigbus_install() </cmt> <cmt> we show journal data, hence we should install the sigbus handler. </cmt> <cmt> similar for machinectl, where the same applies. </cmt> <cmt> pager: cache not only number of columns but also of lines before we open pager </cmt> <cmt> not that we need it, but let's do this as matter of completeness. </cmt> <cmt> tree-wide: use  _cleanup_(sd_bus_flush_close_unrefp) at various appropriate places </cmt> <cmt> let's shorten the code a bit. </cmt> <cmt> merge two lines in our get_output_flags() functions </cmt> <cmt> loginctl, machinectl, systemctl all have very similar implementations of </cmt> <cmt> a get_output_flags() functions. simplify it by merging two lines that </cmt> <cmt> set the same flag. </cmt> <cmt> string-util: when ellipsizing to a length if (size_t) -1, become a nop </cmt> <cmt> let's say that (size_t) -1 (i.e. size_t_max) is equivalent to </cmt> <cmt> ""unbounded"" ellipsation, i.e. ellipsation as nop. in which case the </cmt> <cmt> relevant functions become little more than strdup()/strndup(). </cmt> <cmt> this is useful to simplify caller code in case we want to turn off </cmt> <cmt> ellipsation in certain code paths with minimal caller-side handling for </cmt> <cmt> this. </cmt> <cmt> loginctl: rework sysfs tree dump, to honour --full and friends </cmt> <cmt> let's hook up the sysfs tree output with the output flags logic, </cmt> <cmt> already used when dumping log lines or process trees. this way we get </cmt> <cmt> very similar output handling for line breaking/ellipsation in all three </cmt> <cmt> outputs of structured data. </cmt> <cmt> fixes: #7095 </cmt>",fix loginctl seat sysfs tree ellipsation logic
3632,<desc> @rocketchat/core closes #7931 </desc> <cmt> fix emoji picker on firefox :ok_hand: </cmt> <cmt> fix emoji picker on firefox :ok_hand: </cmt> <cmt> fix emoji picker on firefox :ok_hand: </cmt> <iss> [bug] [redesign] can't post emoji on firefox 55 </iss>,broken emoji picker on firefox
3633,"<desc> fixed broken link for #5229. read our contributing guidelines put lists  in alphabetical order, correct spacing. followup check the output of travis-ci for linter errors! </desc> <cmt> fix contributing.md broken link </cmt> <cmt> fixed broken links in free-programming-books-pt_br.md </cmt>",removed broken link in free-programming-books-pt_br.md
3634,"<desc> when the project is empty and there are no specs cypress is saying ""please select specs from specs list"", but no specs is displayed. here we fix this. check ui change in percy snapshot  -> </desc> <cmt> implement no specs found message </cmt> <cmt> take care of config.projectroot </cmt>",show a hint if no specs were found in the list
3635,"<desc> original pull-request #11604 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update entrypoint.sh </cmt> <cmt> without -q option the database does not get created at startup </cmt> <cmt> update entrypoint.sh </cmt>",cherry pick #11604 to 20.3: update entrypoint.sh
3636,<desc> part of #58957 </desc> <cmt> storage - introduce workspacestoragehome to environment </cmt> <cmt> storage - reduce stat calls when creating workspace </cmt> <cmt> storage - workspace id computation fully from main.ts </cmt> <cmt> storage - extract loading of workspace payload </cmt> <cmt> storage - switch to a workspace storage </cmt> <cmt> storage - write workspace.json from renderer </cmt> <cmt> storage - update telemetry keys </cmt> <cmt> storage - migrate workspace keys over </cmt> <cmt> storage - ensure no errors on startup </cmt> <cmt> storage - have a whithlist of supported workspace keys </cmt> <cmt> storage  - cleanup </cmt> <cmt> storage - :lipstick: </cmt> <cmt> storage - implement migration when entering workspace </cmt> <cmt> storage - also log path </cmt> <cmt> storage - add test for migration </cmt>,migrate workspace storage into sqlite
3637,"<desc> the applicationprivilege class had a dual purpose of defining application privileges as stored in the security index, and also being the means by which those privileges were tested against roles. this made the class difficult to work with - in particular validation was dependent on which purpose it was being used for. this commit splits the index storage part into a new applicationprivilegedescriptor class </desc> <cmt> refactor privileges api/store to use seprate class </cmt> <cmt> the applicationprivilege class had a dual purpose of defining </cmt> <cmt> application privileges as stored in the security index, and also being </cmt> <cmt> the means by which those privileges were tested against roles. </cmt> <cmt> this made the class difficult to work with - in particular validation </cmt> <cmt> was dependent on which purpose it was being used for. </cmt> <cmt> this commit splits the index storage part into a new </cmt> <cmt> applicationprivilegedescriptor class </cmt> <cmt> add javadoc to method </cmt> <cmt> further cleanup after refactor </cmt>",refactor privileges api/store to use separate class
3638,"<desc> this reverts #28552, instead warning of the upcoming default change. the default change will occur instead in 15.x. npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: undo the nativewindowopen default change; delayed until 15.x. </desc> <cmt> revert ""feat: enable nativewindowopen by default (#28552)"" </cmt> <cmt> this reverts commit f8bdef5349a01033f1314e8a65b8441e8340e4d8. </cmt> <cmt> warn when nativewindowopen is undefined </cmt>","undo nativewindowopen default change, warn instead"
3639,"<desc> like the test added in this pull, when multi matches' value is ""aaa||bbb||ccc"", rule_line_add_token func will convert the value to ""aaa\0bbb\0ccc\0c"". so except empty string, the finally matches are aaa/bbb/ccc/c, and ""c"" is illegal. </desc> <cmt> udev: specify the end of value </cmt> <cmt> nulstr_foreach may read the illegal match </cmt> <cmt> test: add test case for multi matches when use ""||"" </cmt>","fix multi matches when use ""||"""
3640,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): checksums added to the system.parts_columns table. #5151 </desc> <cmt> done </cmt> <cmt> better gitignore with mrk2 </cmt>,add data checksums to system.parts_columns table. #5151
3641,<desc> i would like to add 30wer to the database of qmk supported keyboards. some background information on the keyboard can be found in the keebtalk thread. </desc> <cmt> preliminary 30wer firmware. not tested on real board yet. </cmt> <cmt> added a layer to default 30wer keymap. </cmt> <cmt> wrote readme for 30wer. </cmt>,add 30wer config and keymap
3642,"<desc> our ci builds have intermittent failures in our online tests, e.g. with the message ""a provided buffer was too small"". this is not a programming error in libgit2 but rather an error in the schannel component of windows. under certain circumstances involving diffie-hellman key exchange, schannel is unable to correctly handle input from the server. this bug has already been fixed in recent patches for windows 10 and windows server 2016, but they are not yet available for appveyor. manually pamper over that issue by disabling all ciphersuites using dhe via the registry. while this disables more ciphers than necessary, we really don't care for that at all but just want to avoid build failures due to that bug. see [1], [2] or [3] for additional information. 1: aws/aws-sdk-cpp#671 2: dotnet/corefx#7812 3: </desc> <cmt> util: fix missing headers for mingw environments </cmt> <cmt> there are multiple references to undefined functions in the microsoft </cmt> <cmt> builds. add headers to make them known. </cmt> <cmt> appveyor: disable dhe to avoid spurious failures </cmt> <cmt> our ci builds have intermittent failures in our online tests, e.g. with </cmt> <cmt> the message ""a provided buffer was too small"". this is not a programming </cmt> <cmt> error in libgit2 but rather an error in the schannel component of </cmt> <cmt> windows. under certain circumstances involving diffie-hellman key </cmt> <cmt> exchange, schannel is unable to correctly handle input from the server. </cmt> <cmt> this bug has already been fixed in recent patches for windows 10 and </cmt> <cmt> windows server 2016, but they are not yet available for appveyor. </cmt> <cmt> manually pamper over that issue by disabling all ciphersuites using dhe </cmt> <cmt> via the registry. while this disables more ciphers than necessary, we </cmt> <cmt> really don't care for that at all but just want to avoid build failures </cmt> <cmt> due to that bug. </cmt> <cmt> see [1], [2] or [3] for additional information. </cmt> <cmt> 1: </cmt> <cmt> 2: </cmt> <cmt> 3: </cmt>",workaround for intermittent test failures
3643,"<desc> this is mostly cosmetic changes; replacing references to $testdir/root with the already-existing $initdir variable, using the new create_empty_image_rootdir() function instead of manual steps, and replacing use of dd with truncate, which performs the same action without any noise to stderr. this also adds mkdir $initdir to import_initdir(), so that directory exists immediately after calling the function. </desc> <cmt> test/test-functions: avoid stderr noise, only umount on cleanup if mountpoint </cmt> <cmt> only umount it during cleanup if the $testdir/root dir is a mountpoint. </cmt> <cmt> this avoids adding noise to the stderr log such as: </cmt> <cmt> mountpoint: /var/tmp/systemd-test.waloft/root: no such file or directory </cmt> <cmt> test: test-33 and test-36 should use create_empty_image_rootdir </cmt> <cmt> this recently added function handles mkdir and mounting of the empty image, </cmt> <cmt> as well as umounting after test_setup. </cmt> <cmt> test: replace $testdir/root with $initdir </cmt> <cmt> the $initdir var is already set to $testdir/root, it should be used </cmt> <cmt> instead of direct use of $testdir/root. </cmt> <cmt> test/test-functions: add mkdir to import_initdir </cmt> <cmt> this dir is created by create_empty_image_rootdir, as well as indirectly </cmt> <cmt> by some other functions, but it should be created by import_initdir so </cmt> <cmt> the newly-exported $initdir exists and can be used immediately without </cmt> <cmt> relying on other functions to create it. </cmt>","minor/cosmetic changes to test/test-functions, some test.sh"
3644,"<desc> original pull-request #29063 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> 1. fix oveflow bug </cmt> <cmt> 1. fix format </cmt> <cmt> overflow bugfix </cmt> <cmt> added tests </cmt> <cmt> fixed style </cmt> <cmt> fixed tests </cmt> <cmt> merging #27963 </cmt>",cherry pick #29063 to 21.10: merging #27963
3645,"<desc> backport #7414. clip real and imag parts of result of corrcoef to the interval [-1, 1]. this doesn't really fix the issue with complex hermitean results, nor is the diagonal guaranteed to be one, but it does take care of issue #7392. i put it here pending a decision of the proper course to take. </desc> <cmt> maint/bug: clip real and imag parts of corrcoef return to [-1, 1]. </cmt> <cmt> the non-nan elements of the result of corrcoef should satisfy the </cmt> <cmt> inequality abs(x) <= 1 and the non-nan elements of the diagonal should </cmt> <cmt> be exactly one. we can't guarantee those results due to roundoff, but </cmt> <cmt> clipping the real and imaginary parts to the interval [-1, 1] improves </cmt> <cmt> things to a small degree. </cmt> <cmt> closes #7392. </cmt> <cmt> tst: check that result of corrcoef are clipped. </cmt> <cmt> this doesn't actually test much, as we don't have any inputs where that </cmt> <cmt> was not already the case. but at least it is there and perhaps a fuzz </cmt> <cmt> test can be added at a later date. </cmt>","backport 7414, bound result of corrcoef"
3646,<desc> the texs instruction now saves the texcoords in an extra subscope before sampling the texture and writing the output. this fixes binding of isaac. </desc> <cmt> shadergen: fixed a case where the texs instruction would use the same registers for the input and the output. </cmt> <cmt> it will now save the coords before writing the outputs in a subscope. </cmt> <cmt> shadergen: implemented the fmul32i shader instruction. </cmt>,fixed texs overriding its own texcoords and implemented fmul32i
3647,"<desc> (operation) within deleted title. modified: docs/cn/operation.md follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> update project </cmt> <cmt> (operation) within deleted title </cmt> <cmt> (operation) within deleted title. </cmt>",[rip-9](operation) within deleted title
3648,"<desc> hi sindre, i appreciate the opportunity to sponsor the awesome list!!! this pr provides a hard-coded sponsorship for code sponsor. thanks! eric </desc> <cmt> replace code sponsor banner with smaller version </cmt> <cmt> remove extra hr line </cmt>",replace code sponsor banner with a less obtrusive one
3649,"<desc> stable/spinnaker chart version 0.4.0 does not work on kubernetes version 1.9.4 or higher. it will work with the following fixes. update minio version in requirements.yaml change minio endpoints in spinnaker-config.yaml and create-bucketyaml change minio client image in create-bucket.yaml, and add command option 1. update minio version in requirements.yaml: maybe, in k8s 1.9.4 or higher version, minio 0.4.3 is not working. update stable/minio 0.4.3 -> 1.1.1 please refer to this: minio/minio#5725 2. change minio endpoints in spinnaker-config.yaml and create-bucketyaml: in minio chart version 1.0.0 or higher, service name(endpoint) is "" (in 0.4.0, endpoint is "" 3. change minio client image in create-bucket.yaml, and add command option: sometimes, ""create bucket"" job container goes into crash loop. your previous request to create the named bucket succeeded and you already own it. to avoid this, update mc version and use mc mb -p. ""-p"" option is like mkdir -p. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # no issue. tested on k8s 1.9.6 and 1.10.0 </desc> <cmt> update minio chart version </cmt> <cmt> change minio endpoint </cmt> <cmt> change minio client image for using mc mb -p option </cmt>",fix for k8s 1.9.4 or upper version
3650,"<desc> original pull-request #24285 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> allow empty http headers </cmt> <cmt> fix test </cmt> <cmt> allow empty http headers </cmt>",cherry pick #24285 to 21.5: allow empty http headers
3651,"<desc> 3 changes to better-sqlite3 in this pr: backup method transactions now have a return type instead of any prepared statements can optionally provide a bind parameter type add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). binding-parameters transaction return type note: transaction return types are not strictly documented, but they are implicitly documented by the signature .transaction(function) -> function backup method note: backup's promise including the backupmetadata is not strictly documented, but the behavior does exist in the code. i thought it was better to include the info than make it difficult to access in typescript. lmk which is better though! v5.4 version bump increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add transaction return type & statement bind typing </cmt> <cmt> add backup method </cmt> <cmt> bump better-sqlite3 version </cmt>","add transactions return type, statement bind paramater typing, backup method"
3652,"<desc> this fix was still missing in master (it is in 1.8.x, it maybe should still be backported to 1.7.x which seems not be in there yet, the correct commit for backporting are 79b094e and c57c417 -- the first here won't apply, since it is slightly different) </desc> <cmt> bug: fix np.insert with negative axis. </cmt> <cmt> in some cases a negative axis argument to np.insert would result </cmt> <cmt> in wrong behaviour due to np.rollaxis, add modulo operation to </cmt> <cmt> avoid this (an error is still raised due to arr.shape[axis]). </cmt> <cmt> closes gh-3494 </cmt> <cmt> tst: add test for negative axis values in np.insert. </cmt>",fix negative axis insert (issue 3494)
3653,"<desc> fixes #5545 fixes #11524 this pr creates a function sklearn.utils.init_arpack_v0(size, random_state) which goal is to be used each time eigs, eigsh or svds from scipy.sparse.linalg is called. it initializes the v0 parameter correctly with value sampled from the uniform distribution in [-1, 1] (like in arpack) to avoid convergence issues with another initialization. the v0 parameter is mandatory as it is the only way to render linalg functions behaviour deterministic. </desc> <cmt> arpack initialization modif </cmt> <cmt> fixes </cmt> <cmt> making function private and correcting typo </cmt> <cmt> with the svds correct init </cmt> <cmt> with pep8 flake8 and pytest corrections </cmt> <cmt> unit test on init_arpack </cmt> <cmt> pep8 correction </cmt> <cmt> change approx for allclose to pass travis </cmt> <cmt> with flake8 </cmt> <cmt> double init sadly </cmt> <cmt> changing _init_arpack_v0 location </cmt> <cmt> fix plsca docstring and add versionadded mention in plssvd </cmt> <cmt> add a whats_new. </cmt> <cmt> fixes the right docstring... and convert some weird tabs into spaces... </cmt> <cmt> adds :issue: and :user: entry </cmt> <cmt> i'm out of words... </cmt> <iss> enh: make consistent interface for scipy's eigs, eigsh and svds with random start </iss>",mnt initialize weights when using arpack solver with a utility
3654,"<desc> for #48453. first time contribution, so i'd really appreciate any feedback on how this pr can be better. not sure exactly what kind of documentation update is needed. if there is no pr to update the reference, i can try doing that this week as i have time. </desc> <cmt> split out termination_trait_test feature gate </cmt> <cmt> stabilize termination_trait </cmt> <cmt> this stabilizes main with non-() return types; see #48453. </cmt>","stabilize termination_trait, split out termination_trait_test"
3655,"<desc> this pr constructs the globalctxt as a member of the queries in librustc_interface. this simplifies the code to construct it, at the expense of added complexity in the query control flow. this allows to handle the arenas directly from librustc_interface. based on #66707 r? @zoxc </desc> <cmt> isolate compiler queries inside the queries type. </cmt> <cmt> move linking ouside the interface queries. </cmt> <cmt> tidy. </cmt> <cmt> fix test. </cmt> <cmt> remove wrong comment. </cmt> <cmt> pass queries by reference. </cmt> <cmt> simplify early exits. </cmt> <cmt> don't move stuff out of compiler::enter. </cmt> <cmt> superfluous lifetime. </cmt> <cmt> reduce righward drift. </cmt> <cmt> review nits. </cmt> <cmt> make the hir map own the definitions. </cmt> <cmt> have queries own the globalctxt. </cmt> <cmt> the construction of the globalctxt is moved from a generator's stack to </cmt> <cmt> the queries struct.  since the globalctxt requires the hir forest and the </cmt> <cmt> arenas to live longer, those are moved into queries the same way. </cmt> <cmt> the resulting handling of objects is more brittle, because consumers of </cmt> <cmt> the once objects need to be careful of their initialisation. </cmt> <cmt> formatting. </cmt> <cmt> move local arena to queries. </cmt>",handle globalctxt directly from librustc_interface query system
3656,"<desc> this is intended to solve the problem that @jameslamb defined in #3768 by running socket.bind('', 0) with client.run, which finds a random port for each worker. i've included a small test to check that the found ports are indeed different for a localcluster. happy to receive any feedback. </desc> <cmt> use socket.bind with port 0 and client.run to find random open ports </cmt> <cmt> include test for found ports </cmt>",use random ports in network setup
3657,"<desc> this is not for entrie *.nca files, only the extracted directory containing the main, romfs, etc.. files mainly: able to select 'main' files from load file without having to change extensions to all. added a 'load folder' to pick a extracted nca directory. game list looks for 'main' files now and uses the name of the directory they are in as display. </desc> <cmt> recognize main files in game list </cmt> <cmt> add support for main files in file picker </cmt> <cmt> add 'load folder' menu option </cmt>",add ui support for extracted nca folders
3658,"<desc> improves reliability of tests, to address following integration tests fails: </desc> <cmt> test(aws sns): remove ""bluebird"" dependency </cmt> <cmt> test(aws sns): refactor to async/await </cmt> <cmt> test(aws sns): improve tests reliability </cmt> <cmt> test(aws msk): improve tests reliability </cmt> <cmt> ci: increase allowed number of retries </cmt>",improve reliability of integration tests
3659,"<desc> to test: open the pdf from #6643. click on the attachment list. click on a pdf, and confirm that it opens in a new tab. tested with firefox 51 (generic target), chrome 56 (extension). fixes #6643 relevant for #4282 </desc> <cmt> recognize file name in reference fragment in getpdffilenamefromurl </cmt> <cmt> the regular expression incorrectly marked a group as capturing. </cmt> <cmt> for </cmt> <cmt> but instead ""document.pdf"" was returned. </cmt> <cmt> [crx] recognize blob and data-urls in the router </cmt> <cmt> when a blob or data-url is opened with the extension, viewer.html </cmt> <cmt> rewrites the url. but when the viewer is refreshed (e.g. f5), chrome </cmt> <cmt> would fail to display the viewer because the extension router was not </cmt> <cmt> set up to recognize such urls. </cmt> <cmt> now it is. </cmt>",open pdf attachments in the viewer instead of an unconditional download
3660,<desc> rllib currently crashes when [policy].global_timestep reaches 2^31 due to the respective tensor-types being of dtype=int32. this pr fixes this issue. issue #10810 closes #10810 closes #10810 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip. </cmt> <cmt> wip. </cmt> <iss> [rllib] how to train beyond 2^31 timesteps? </iss>,allow for more than 2^31 policy timesteps.
3661,"<desc> the light_subtype was updated after initializing the light engine, missing the white channel. **related issue (if applicable): #5869 the pull request is done against the latest dev branch only relevant files were touched (also remember to update changelog.ino file) only one feature/fix was added per pr. the code change is tested and works. the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> fix #5869 </cmt> <cmt> fix #5869 typo </cmt>","fix #5869, missing white channnel for ws2812"
3662,<desc> actors that were defined before connecting to or starting a ray cluster were not being traced correctly. safeguard retrieval of task/actor id. update tracing docs. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> bug fix </cmt> <cmt> cleanup </cmt> <cmt> safeguard task and actor id </cmt>,fix tracing bug when actors are defined before connecting to cluster
3663,"<desc> for #5094 we add unit tests by directory, module  nacos-core  directory remote/grpc. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> [issue #5904] add grpc directory unit tests. </cmt> <cmt> [issue #5904] add grpc directory unit tests, for grpcrequestacceptor.java. </cmt>",add unit tests in nacos-core.
3664,"<desc> addressing issue #7356. fixing the inconsistent naming, and following uwp guidelines. color mode selection now looks like this on the general, run and shortcut guide page: and adding a hyperlinkbutton that allows the user to open the windows color settings page. pr checklist applies to #7356. cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx </desc> <cmt> updated labels </cmt> <cmt> added windows color settings link </cmt>",fixing inconsistent theme/app mode naming
3665,<desc> add detailed information about breaking changes to the 2.11 porting guide. update the module_utils doc to include documentation for a lot more of the public interfaces. fixes #73983. docs/docsite/rst/porting_guides/porting_guide_core_2.11.rst docs/docsite/rst/reference_appendices/module_utils.rst lib/ansible/module_utils/common/arg_spec.py lib/ansible/module_utils/common/parameters.py </desc> <cmt> add argumentspecvalidator to docs </cmt> <cmt> improve docs for argumentspecvalidator </cmt> <cmt> document removal of private methods </cmt> <cmt> update module_utils documentation </cmt> <cmt> add docs for argument spec classes as well as validation and parameters files. </cmt> <cmt> update docs in arg_spec and paremeters </cmt> <cmt> this improves the generated documentation. </cmt> <cmt> document breaking changes in porting guide. </cmt> <cmt> update formatting in porting guide and add a deprecated section </cmt> <iss> argument spec refactoring breaks some things </iss>,add porting guide and documentation for changes to argument spec validation
3666,"<desc> everywhere: use default execpromises argument for core::system::pledge libcore: allow system::pledge execpromises argument to be omitted it appears that we don't have almost no cases of a callers passing exec promises when they call pledge(). to simplify the code a bit we add a default parameter that will pass nullptr for us to pledge(). libcore+cat: switch core::system::read/write to take a span of bytes in the spirit of the core::system name space having ""modern"" facades for classically c functions / kernel interfaces, it seems appropriate that we should take span's of data instead of raw pointer + length arguments. settings: convert to try + serenity_main(..) </desc> <cmt> settings: convert to try + serenity_main(..) </cmt> <cmt> libcore+cat: switch core::system::read/write to take a span of bytes </cmt> <cmt> in the spirit of the core::system name space having ""modern"" facades </cmt> <cmt> for classically c functions / kernel interfaces, it seems appropriate </cmt> <cmt> that we should take span's of data instead of raw pointer + length </cmt> <cmt> arguments. </cmt> <cmt> libcore: allow system::pledge execpromises argument to be omitted </cmt> <cmt> it appears that we don't have almost no cases of a callers passing </cmt> <cmt> exec promises when they call pledge(). to simplify the code a bit we </cmt> <cmt> add a default parameter that will pass nullptr for us to pledge(). </cmt> <cmt> everywhere: use default execpromises argument for core::system::pledge </cmt>",refine some core::system apis
3667,"<desc> these commits make the change to attribute access picked up during the review of #65, and adds 2 extra tests for a potential division-by-zero situation. as it happens, the code survives that division-by-zero as is, but it can't hurt to test for the situation anyway. </desc> <cmt> added extra test to check for potential division by zero. </cmt> <cmt> cleanup of accessor logic in boundaxis. </cmt>",cleanup and extra tests for min/max support
3668,"<desc> this pr fixes #101132 as you can see in the issue, this is how to test it: go offline (you can also open devtools in vscode and go to the network tab and change the ""online"" at the top to ""offline"") try to open the release notes using show release notes from the command palette. depending on whether you are on an official vscode build or a local build, the release notes page will be opened in your default browser. on a local build it should show an error stating that fetching the release notes failed and that this vscode doesn't have release notes online. go back online try to open the release notes again the release notes should open in a webview go offline again try to open the release notes again the release notes should open in a webview again, even though we're offline </desc> <cmt> retry getting release notes on failure, and show xhr failures </cmt> <cmt> improved release notes errors </cmt> <cmt> improve async code in loadreleasenotes </cmt> <iss> release notes can never be opened after you try to open them when offline </iss>","retry fetching release notes on failure, and display failures"
3669,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. in a forum thread i had a discussion with a camper regarding the fact that the only solution for the factorialize a number challenge used recursion and recursion is never introduced into the curriculum, except for the solution in the guide for the challenge.  i added an iterative solution which is very basic. also, in the same discussion, methods like split and join are first introduced in the functional programming section currently, yet the only guide solution for the reverse a string challenge involves using these.  i decided to add a basic solution which shows how to solve the challenge without these methods. i also took the liberty of shuffling things around in the same guide articles and hid the solutions along with removing external repl.it links and the challenge problem descriptions which is just duplicated from the challenge. </desc> <cmt> fix: added iterative basic solution </cmt> <cmt> fix: added another basic solution </cmt>",fix(guide) add solutions to factorialize a number and reverse and string challenges
3670,"<desc> i hereby agree to the terms of the cla available at:  for changelog. performance improvement for asof join and support for different asof column types. category: short description (up to few sentences): following the feedback on the previous pull request, it adapts the asof join strictness to support multiple column types (though not multiple columns in one go, still only the last column in the join is selected). furthermore, rather than inserting the rowrefs into a std::map, it pushes them into a podarray which only gets sorted once when required, which should give some quite good performance gains, both in inserting and looking up values. </desc> <cmt> asof join without using std::map, but still only on u32 </cmt> <cmt> working multi type asof join columns </cmt> <cmt> add test for multiple supported asof types </cmt> <cmt> fix style </cmt> <cmt> set default asof type value </cmt>",perform asof join with sorting podarray once and support multiple column types
3671,<desc> fixes #27854 the bug was in reduceeachchild where it was not reducing type arguments (recently introduced) of tagged template expressions. added a test case from the bug report. / </desc> <cmt> add broken test for issue #27854 </cmt> <cmt> fix bug in reduceeachchild (fixes #27854) </cmt> <cmt> - add reducing of type arguments in tagged template expression </cmt> <cmt> change cast to the proper type </cmt>,fix bug in reduceeachchild for tagged template expressions
3672,<desc> this pr implements support for keyof t with generic tuple types that was missing in #39094. </desc> <cmt> handle keyof t where t is generic tuple type </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>,handle 'keyof' for generic tuple types
3673,"<desc> #21807 merged without a thorough review of the new docs content, and without some changes to the css reverted or changed. this pr aims to take care of those things. this removes the css that was added for the justified and fill variants; that was tackled by requiring .nav-item on .nav-link in caebfcd. this way, we're not setting css just to override it in the following ruleset. the docs updates are relatively straightforward. some grammar fixes and minor tweaks here and there mostly. the biggest change was redoing the scrollspy's docs intro; i hate seeing huge callouts. instead of that, let's just lead with ""here's what you need."" might keep pushing some tweaks here, unsure yet if this is ready to go. still reading all the docs changes from that pr. / </desc> <cmt> tweak some copy </cmt> <cmt> fix up scrollspy docs </cmt> <cmt> remove nav styles that were added </cmt>",docs and css updates for #21807
3674,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> :pencil2: fix typo 'anot' </cmt> <cmt> :bug: fix wrong type for prop coordinates of method line </cmt> <cmt> :art: add namespace 'recipe' for interfaces and types </cmt> <cmt> :art: use double instead of single quote marks </cmt> <cmt> :art: rename namespace 'recipe' to 'hummusrecipe' </cmt> <cmt> :art: add types </cmt>,"added a namespace for types and interfaces, fixed a typo and a wrong type"
3675,<desc> this is related to #31835. this commit adds a connection manager that manages client connections to other nodes. this means that the tcptransport no longer maintains a map of nodes that it is connected to. </desc> <cmt> work on connection manager </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> at least fix checkstyle </cmt>,remove client connections from tcptransport
3676,"<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added neural network with 2 hidden layers </cmt> <cmt> revert ""added neural network with 2 hidden layers"" </cmt> <cmt> this reverts commit fa4e2ac86eceaae018cb18c720420665b485f3b7. </cmt> <cmt> added neural network with 2 hidden layers </cmt> <cmt> passing pre-commit requirements </cmt> <cmt> doctest completed </cmt>",adding 2-hidden layer neural network with back propagation using sigmoid activation function
3677,<desc> this updates the definitions with complete input options specified at  add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> extended options of qrcode-svg 1.1 </cmt> <cmt> prettier run </cmt>,qrcode-svg 1.1.0. completed input options. organized and documented from package readme.
3678,"<desc> this is a follow-up to #13794 and introduces gaq support to native filters. in addition to adding gaq support, this is a first step towards generalizing the filtervalue and defaultvalue components, with the ultimate goal of introducing a general purpose nativefilter component which encapsulates request handling, loader rendering and proper error handling. in the filter tab modal, filters render correctly: in the filter config modal, the default value component renders properly: in the filter tab, all filters show up as ""no results"": in the filter config modal, the default value component also shows up as ""no results"": test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix(native-filters): improve loading styles for filter component </cmt> <cmt> round up fractional grid unit </cmt> <cmt> fix(native-filters): add support for global async queries </cmt> <cmt> move form item out of default value component </cmt> <cmt> move default value hook declaration to form </cmt>",add global async query support to native filters
3679,"<desc> fall back to the assignment's declaration; don't use the property's valuedeclaration because that is not useful when the property comes from a spread. the fallback now happens when the property's valuedeclaration does not have the object literal's first declaration as an ancestor. fixes #16473 </desc> <cmt> improve excess property check for spread property </cmt> <cmt> fall back to the assignment's declaration; don't use the property's </cmt> <cmt> valuedeclaration because that is not useful when the property comes from </cmt> <cmt> a spread. the fallback now happens when the property's valuedeclaration </cmt> <cmt> does not have the object literal's valuedeclaration as an ancestor. </cmt> <cmt> test:error span for spread prop in excess prop check </cmt> <cmt> use first declaration, not valuedeclaration </cmt> <cmt> valuedeclaration is frequently not set </cmt>",improve excess property check error span for spread property
3680,<desc> #22960: trusty: support developer workflow on base image #22974: mesos: forward globally declared cadvisor housekeeping flags #23035: #23034 fix controller-manager race condition issue which cause endpoints flush during restart #23143: validate minimum cpu limits to be >= 10m #23167: add a sshkey sync check to the master's healthz (when using sshtunnels). #23141: kubelet: send all recevied pods in one update #23145: use versioned object when computing patch #23222: add a deployment example for kubectl expose. #23019: add a rate limiter to the gce cloudprovider #23246: update expose command description to add deployment #23079: trusty: support hybrid cluster with nodes on containervm #23160: copy annotations back from rs to deployment on rollback #23180: remove the restart-kube-proxy and restart-apiserver functions #23313: bump to container-vm-v20160321 #23325: fix hairpin mode #23234: removing url query param from swagger ui to fix the xss issue #23305: update kubectl help for 1.2 resources #22818: trusty: avoid reaching gce custom metadata size limit </desc> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 5cc2bb3c0c9318ac6168351252b50f1dba71a8c9) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 68892a3e59c63fa7de2582d20642498e8cab4132) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit cda4583984ada38e61aa1b907aae357c4a80a467) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 78adb885c41dcbb820b6e79c975e3ddb91ad5700) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 10204f8b31bdc0ab2accbb70cdca304df2231c82) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 61b9a21cfd7bca8fbedff875647d7b7e0aff5603) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 62399077d86cc116c8cc4570c399da726bcfb48d) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 2c5903acf1f814d5f4cb39056b75d82179b2d08f) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 0fe049f9ffb82b94e850270ccfa710ee3ed3ebd3) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit b077b685d97842449ecddaecfff9b67baa150bf8) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit d5316c21ef0603cc5e858284e7786e7647cb307f) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit edc35bfebaeecd6599110c490c1fb1f33289f209) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit f2d14990a51b7915ed0d15f65a5803047d304b9e) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 4d98abf26c38e5f77675fcd5821c104a3e5d0580) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 8f71655bcc3f06af162f16e8f87488fab438609b) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit b50e89e323977d365439fda42d75f0930310a517) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit 2f8986782178900425df02e32338981b6602d8ec) </cmt> <cmt> auto commit by pr queue bot </cmt> <cmt> (cherry picked from commit f8bb10b479bf6f6c3f8db5213edab766bc5fa873) </cmt>,cherry-picks for release 1.2 - 24 mar
3681,"<desc> closes #39732 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> remove _groupby object from class </cmt> <cmt> add test that groupby apply is not affected </cmt> <cmt> remove unnecessary groupby subclasses </cmt> <cmt> supress private variables in repr </cmt> <cmt> don't have window classes accept kwargs </cmt> <cmt> add whatsnew </cmt> <iss> bug: resulting index from groupby.apply is different depending on whether a rollinggroupby object is created </iss>",refactor basewindowindex so groupby.apply has a consistent index output
3682,<desc> warning module was used but not imported in numpy.polynomials.polyutils. tests were not catching this bug. increase test coverage to trigger and check the rankwarning (including check of error message) add missing import statement </desc> <cmt> add test to hit rankwarning in polyutils._fit </cmt> <cmt> add missing import warnings </cmt> <cmt> check also warning message </cmt>,missing warnings import in polyutils
3683,"<desc> this builds on #53168 and adds a commit that addresses #53176 -- or at least i think it does. i marked this as wip because i want to see the test results (and measure the performance). i also want to double check we're not adding in any unsoundness here. </desc> <cmt> compute liveness later </cmt> <cmt> update comment to more accurately describe the limitations </cmt> <cmt> promote liveness to a directory module </cmt> <cmt> move liveness_map into the liveness module </cmt> <cmt> liveness_map: rustfmt </cmt> <cmt> make it possible to customize the regiongraph direction </cmt> <cmt> avoid computing liveness when a variable doesn't need it </cmt> <cmt> in particular, we skip computing liveness for a variable x if all the </cmt> <cmt> regions in its type are known to outlive free regions. </cmt>",optimize redundant borrows and escaping paths in nll
3684,<desc> add type/shape inferencing for if. update infershapes to allow the outer scope types to be passed in so that the subgraph's in if can access that information. </desc> <cmt> add type/shape inferencing for the if operator. </cmt> <cmt> remove some temporary debug stuff. </cmt>,add type shape inferencing for the if operator
3685,"<desc> add new image segmentation tests to test suite, and expand object classification tests to test all supported models. </desc> <cmt> add end-to-end tests for image segmentation models. </cmt> <cmt> add additional obj classification models to end-to-end tests that we now support onnx export for. </cmt>",add image segmentation end-to-end tests and expand object classification tests
3686,"<desc> flink-17106 introduces create/drop view in flink sql. but we can't list views from tableenvironment or sql. this pr supports show views in flink sql. btw: we follows the hive style which lists all tables and views with show tables and lists only views with show views. 546d367 add show views syntax in sql parser fe6f4d9 add listviews interface in tableenvironment 39fb3f9 hotfix create/drop view in batch mode for legacy planner 05288fe support show views in blink planner 28223e2 support show views in legacy planner the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, yarn/mesos, zookeeper: (yes / no / don't know) </desc> <cmt> [flink-17111][table] add show views syntax support in parser </cmt> <cmt> [flink-17111][table] add listviews interface to tableenvironment </cmt> <cmt> [hotfix][table-planner-legacy] support create/drop view in batch mode </cmt> <cmt> [flink-17111][table-planner-blink] support show views in blink planner </cmt> <cmt> [flink-17111][table-planner] support show views in legacy planner </cmt>",support show views in flink sql
3687,"<desc> adds a new lib project that contains the port to java of basic functionality of the bar h3 library. the main functionality proved is: geotoh3(double lat, double lng, int res) : given point and a resolution, it returns the h3 cell the point belongs to. geotoh3address(double lat, double lng, int res): given point and a resolution, it returns the h3 address the point belongs to. h3togeoboundary(long h3): given an h3 cell, it returns the cell boundary h3togeoboundary(string h3address): given an h3 address, it returns the cell boundary h3tochildren(long h3): given an h3 cell, it returns the children cell h3tochildren(string h3address): given an h3 address, it returns the children addresses. h3toparent(long h3): given an h3 cell, it returns the parent cell h3toparent(string h3address): given an h3 address, it returns the parent address hexring(long h3): given an h3 cell, it return all neighbour cells. hexring(string h3address): given an h3 address, it return all neighbour addresses. </desc> <cmt> initial port of h3 </cmt> <cmt> iter </cmt> <cmt> support for geotoh3 </cmt> <cmt> added hexring </cmt> <cmt> iter </cmt> <cmt> add constant to the api </cmt> <cmt> license </cmt> <cmt> license part 2 </cmt> <cmt> fix method visibility </cmt> <cmt> update license to test files </cmt> <cmt> compress text resources </cmt>",java port of h3 hexagonal grid library
3688,"<desc> this is a temporary fix for #9605, which seems to be affecting a lot of users on google app engine. </desc> <cmt> disable libuv core changes in node library </cmt> <cmt> update version to 1.1.2 </cmt>",disable libuv core changes in node library and bump version number
3689,"<desc> this simplifies the block/unblock problem by allow available_resources to go negative in the new scheduler (overcommit). previously this wasn't allowed, which made it difficult to avoid two edge conditions: (1) infinite cpu acquisition by repeatedly block/unblocking a task, and (2) available_resources sometimes exceeding total_resources, requiring tracking of the overflow. by allowing available_resources to go negative, we can maintain the invariant that available_resources <= total_resources, and trivially prevent infinite resource acquisition. closes #12937 </desc> <cmt> wip </cmt> <cmt> rename </cmt> <cmt> update </cmt> <cmt> remove overflow </cmt> <iss> [core][new scheduler] actors borrowing cpus infinitely. </iss>",clean up block/unblock handling of resources in new scheduler
3690,"<desc> there are various parts of the flutter tooling that need to make use of a package config now. parse it once during getbuildinfo and re-use. move the null safe language determination here, using the same technique applied on the  web so that the tool can correctly track whether sound or unsound mode is used. removes null safety mode autodetect for all modes except test. it is still required here since each individual test file could be opted in or out of null safety. additional bonus points: tests that are setting up dummy package_config files can now just create a packageconfig object follow up to #70320 work towards #69601 fixes #70121 there are still more places where a package config is parsed in a bespoke manner - such as plugins. fixing that is a bit out of scope. </desc> <cmt> [flutter_tools] make getbuildinfo async </cmt> <cmt> fix import </cmt> <cmt> merge with master </cmt> <cmt> [flutter_tools] use initial package config </cmt> <iss> web: change sdk selection when nullsafetymode.autodetect is working </iss>","use initially parsed package config for language version, sound mode determination"
3691,<desc> bug fixes others </desc> <cmt> fix the dowanload bug in the case of multiple machines (#29551) </cmt> <cmt> * fix the dowanload bug </cmt> <cmt> * add sort for ips </cmt> <cmt> fix bug of matmul_v2 for broadcast case (#29599) </cmt> <cmt> * fix bug of matmul_v2 for broadcast </cmt> <cmt> rebuild group automatically in dynamic graph distributed (#29255) </cmt> <cmt> * add tensor_indices in assigngroupbysize </cmt> <cmt> * add rebuild group in reducer </cmt>,[cherry-pick]fix matmulv2 bug & add rebuild group & fix bug of download
3692,"<desc> allows for creating commands that iterate over the user's color schemes. also adds a top-level nested command to defaults.json that allows the user to select a color scheme (pictured above). i'm not sure there are really any other use cases that make sense, but it really makes sense for this one. #5400 - cmdpal megathread made possible by #6856, and support from viewers like you. all this is being done in pursuit of #6689 closes wait what? i could have swore there was an issue for this one... i work here requires documentation to be updated - okay maybe now i'll write some docs most of the hard work for this was already done in #6856. this is just another thing to iterate over. played with this default command. it works great. added tests. </desc> <cmt> this is the implementation, now i need tests </cmt> <cmt> fix the tests </cmt> <cmt> add a test for this too </cmt>",add support for commands iterable on color schemes
3693,"<desc> this removes the inf% from change alert graphs, we instead show nothing, because the alert ignores if comparison stats for an interval is 0. old tooltip: new tooltip: </desc> <cmt> n/a version </cmt> <cmt> nothing version </cmt>",remove inf percentage from change alert graphs
3694,"<desc> add default attribute values for leakyrelu and hardsigmoid. </desc> <cmt> update from origin </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add tests for math operators: clip,div,elu,hardsigmoid,leakyrelu,mul,pow,selu,sub </cmt>","clip, div, mul, pow, sub; elu, leakyrelu, selu, hardsigmoid"
3695,"<desc> pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: ""[component] fix leaky abstraction"". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( </desc> <cmt> [material-ui-icons] rename icon-builder to material-ui-icons, and add src dirctory to package </cmt> <cmt> [docs] use material-ui-icons package src icons instead of published package </cmt>",use local material-ui-icons/src rather than published package
3696,<desc> description: this is a minor maintenance pr. in pandora it solves an issue where the buffer from pexpect isn't empty when switching pandora stations (because the time-ticker updated before pexpect got its expected prompt). it also solves an issue where the pause/play status was sometimes wrong. also added proper media_content_type to get better display in frontend. there are also a few info->debug conversions in lirc and a new deinit to wrap up more properly when shutting down. checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> pandora cleanups and enhancements </cmt> <cmt> added media_content_type </cmt> <cmt> reduced debug messages </cmt> <cmt> made more robust station list </cmt> <cmt> eliminated auto-pause detection issue </cmt> <cmt> added proper de-init of lirc </cmt> <cmt> now won't re-spawn pandora client if turn_on command is sent twice </cmt>,stability improvement in pandora and proper shutdown in lirc
3697,"<desc> currently, only the first line of a contiguous block of text within a jsx element properly respects indentation when the document is formatted; all others are unaffected. this change inserts whitespace as needed so that all other lines indent properly as well. </desc> <cmt> indent all lines of single jsxtext node </cmt> <cmt> add jsxtext indentation test </cmt>",properly indent jsxtext on format document
3698,"<desc> this pr improve the tokenization of xlm. it's mostly the same as the preprocessing in the original xlm. this pr also add use_lang_emb to config of xlm model, which makes adding the newly release xlm-17 & xlm-100 easier since both of them don't have language embedding. details on tokenization: introduce api change: changing xlmtokenizer.tokenize(self, text) to  xlmtokenizer.tokenize(text, lang='en') new dependency: sacremoses: port of moses new optional dependencies: pythainlp: thai tokenizer kytea: japanese tokenizer, wrapper of kytea (need external c++ compilation), used by the newly release xlm-17 & xlm-100 jieba: chinese tokenizer * * xlm used stanford segmenter. however, the wrapper (nltk.tokenize.stanford_segmenter) are slow due to jvm overhead, and it will be deprecated. jieba is a lot faster and pip-installable. but there is some mismatch with the stanford segmenter. a workaround could be having an argument to allow users to segment the sentence by themselves and bypass the segmenter. as a reference, i also include nltk.tokenize.stanford_segmenter in this pr. example of tokenization difference could be found here. </desc> <cmt> tokenization behave the same as original xlm proprocessing for most languages except zh, ja and th; change api to allow specifying language in tokenize </cmt> <cmt> add custom tokenizer for zh and ja </cmt> <cmt> add use_lang_emb to config </cmt>",added cleaned configuration properties for tokenizer with serialization - improve tokenization of xlm
3699,"<desc> this assumes that runaddon() applies only to scripts, plugins, lyrics, weather which is what the code did before. imo we need to reconsider the existing multiple-addon support.  there's a number of issues with it, primarily that once you have an add-on object you have no idea if that add-on object has other things associated with it.  i.e. addon->type() is basically useless except to tell you the particular sub-addon that you have. i'm not sure that extending caddon so that you know the other types would be enough to resolve the existing issues (e.g.  @ronie, @bignoid, @black09 needs some decent testing :) </desc> <cmt> [addons] allow runaddon() to run plugin and script add-ons that have a service add-on in the metadata first. fixes </cmt> <cmt> [cosmetics] indenting </cmt>",runaddon fix - allows secondary extension points to be run
3700,"<desc> this change lerps the width in a sizedbox that is used as spacing in the extended nav rail, rather than using a constant value. this fixes a bug in the animation of the extended rail, which also can cause inconsistencies with the leading/trailing widgets. before (slowed down 15x): after fix (slowed down 15x): note that the change is subtle, but it is more apparent, and causes more issues, when there are animated widgets in the leading/trailing slots of the rail. related issues closes #65657 i added the following tests: i added 'extended rail transition does not jump from the beginning' to navigation_rail_test.dart before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: redbrogden i wrote a migration guide:  since the animation does not jump, the width of the rail is slightly different mid-animation, so one of the width values had to be updated. </desc> <cmt> lerp the padding of the extended rail </cmt> <cmt> uncomment </cmt> <cmt> uncomment </cmt> <cmt> remove print </cmt> <cmt> adjust and add tests </cmt> <iss> [navigation rail] extended animation jumps on initially frame </iss>",fix a jumping animation in the beginning of the extended navigation rail transition
3701,"<desc> we're planning to make a better fix, but this will mitigate the bug in the beta. </desc> <cmt> don't use _fs.realpathsync.native on windows, a semi-revert of #41292 (#43348) </cmt> <cmt> we're planning a real fix for ts 4.3, but port the workaround from 4.2 </cmt> <cmt> so the beta doesn't have this bug. </cmt> <cmt> (cherry picked from commit e462dfa34786859b6380ac73d77113c031dc2ef5) </cmt> <cmt> un-reverse condition </cmt>",port realpath workaround from release-4.2
3702,"<desc> modify the nginx config such that it does not attempt to eagerly resolve hostnames and can be started before relay will be started. also revert a commit from #18362 that attempted to simplify the devserver logic, but actually made it impossible to start arbitrary devservices as part of devserver. with this commit i can finally run nginx/relay/symbolicator/snuba ondemand. for service in sentry_devservices: sentry_devservices[service]['with_devserver'] = true # this is necessary for relay tests too and generally useful sentry_devservices['redis']['with_devserver'] = false # xxx: need to deselect this explicitly? is only_if ignored? sentry_devservices['bigtable']['with_devserver'] = false sentry_devservices['memcached']['with_devserver'] = false this makes my computer beachball when starting up devserver, but it works </desc> <cmt> ref: allow nginx to start even if relay is not started </cmt> <cmt> revert cafc274dee6f00dde3bcff827d7d33954c00ddf0 from #18362 </cmt>",start/stop relay ondemand with devserver
3703,"<desc> fixes #122534 fixes #123188 fixes #123479 fixes #123163 fixes #123732 fixes #121760 related microsoft/vscode-python#16175 todo: test env.shell clean up/todos resync main </desc> <cmt> wip to move fetching profile out of exthost </cmt> <cmt> part of #123188 </cmt> <cmt> part of #122534 </cmt> <cmt> clean up </cmt> <cmt> resolve variables on renderer </cmt> <cmt> fix layering </cmt> <cmt> fix imports </cmt> <cmt> wip </cmt> <cmt> get profiles detecting on pty host (local) </cmt> <cmt> wait for profiles before creating first terminal </cmt> <cmt> fixes #123188 </cmt> <cmt> get remote profiles working </cmt> <cmt> update distro </cmt> <iss> if terminal.integrated.shell doesn't have a matching terminal.integrated.profiles entry the shell path will be ' ' </iss> <iss> profile evaluation should happen on the pty host, not extension host </iss> <iss> vscode 1.56 - when start debuging, windows powershell terminal is opened instead of git bash </iss> <iss> terminal.integrated.defaultprofile.windows not working on startup </iss> <iss> default profile doesn't apply to tasks </iss> <iss> don't go to the ext host for default terminal shell/args in tasks </iss>",move profile resolving to pty service
3704,<desc> add base.gradle & kotlin.gradle for modules to apply and simplifying boilerplate. remove redundant .gitignore files. extrace version strings to ext block. add arg to optimizing gradle builds for jdk 11. add dependabot to automated dependency updates. </desc> <cmt> remove redundant .gitignore files </cmt> <cmt> add base.gradle to simplify gradle </cmt> <cmt> add kotlin.gradle to simplify gradle </cmt> <cmt> use new syntax to apply plugins </cmt>,optimize gradle & remove redundant .gitignore files
3705,<desc> @jreback i re-enabled flake8 checking for unused imports. we should be explicit about what imports are part of a module api (and those warnings explicitly suppressed with # noqa) and delete all unused imports. </desc> <cmt> ref: reorganize about half of test_frame.py into pandas/tests/frame and fix flake8 errors on that code </cmt> <cmt> bld: ship pandas/tests/frame </cmt>,break apart test_frame.py and fix all flake8 warnings
3706,"<desc> even after #17458, we still deal with setting fees of an outputgroup and filtering the outputgroup outside of the struct. we currently make all of the outputgroups in selectcoins and then copy and modify them within each selectcoinsminconf scenario. this pr changes this to constructing the outputgroups within the selectcoinsminconf so that the scenario can be taken into account during the group construction. furthermore, setting of fees and filtering for effective value is moved into outputgroup::insert itself so that we don't add undesirable outputs to an outputgroup rather than deleting them afterwards. to facilitate fee calculation and effective value filtering during outputgroup::insert, outputgroup now takes the feerates in its constructor and computes the fees and effective value for each output during insert. while removing outputgroups in accordance with the coineligibilityfilter still requires creating the outputgroups first, we can do that within the function that makes them - groupoutputs. </desc> <cmt> remove outputgroup non-default constructors </cmt> <cmt> move groupoutputs into selectcoinsminconf </cmt> <cmt> move fee setting of outputgroup to insert </cmt> <cmt> outputgroup will handle the fee and effective value computations </cmt> <cmt> inside of insert. it now needs to take the effective feerate and long </cmt> <cmt> term feerates as arguments to its constructor. </cmt> <cmt> move eligibleforspending into groupoutputs </cmt> <cmt> instead of filtering after the outputgroups have been made, do it as </cmt> <cmt> they are being made. </cmt>",refactor outputgroups to handle fees and spending eligibility on grouping
3707,"<desc> please answer these questions before submitting pull request why submit this pull request? new feature provided while the grpc implementation is not there yet, this pr imports protos from envoy data plane api to progress on making skywalking to have the capability to receive envoy metrics through metrics (grpc) service. </desc> <cmt> add envoy metrics service protos </cmt> <cmt> this patch imports protos from envoyproxy/data-plane-api and </cmt> <cmt> prometheus/client_model to enable metrics service service feature in </cmt> <cmt> skywalking oap. </cmt> <cmt> add envoy related docs </cmt> <cmt> update the license to include new protos license </cmt> <cmt> from: </cmt> <cmt> - envoyproxy/data-plane-api </cmt> <cmt> - prometheus/client_model </cmt> <cmt> add a complete config.yaml example </cmt> <cmt> add note on envoy dynamic config </cmt> <cmt> add protoc-gen-validate license </cmt> <cmt> add samples </cmt>",envoy metrics receiver plugin protos
3708,"<desc> closes #36032 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> add test for bug #36032 </cmt> <cmt> fix incorrect iso_year for certain dates </cmt> <cmt> pep8 </cmt> <cmt> pep8 fix </cmt> <cmt> black </cmt> <iss> bug: .dt.isocalendar().year </iss>",incorrect year returned in isocalendar for certain dates
3709,"<desc> updates the recent documents tutorial, removing references to the quick start guide, as well as the related unused index.html file. pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none cc: @erickzhao </desc> <cmt> port recent-documents fiddle to 12-x-y. </cmt> <cmt> update recent-documents tutorial. </cmt>","updated ""recent documents"" fiddle tutorial"
3710,"<desc> unit tests can be run with make test tests are run by travis as well, but i had to disable an assertion (related to #387) and friends_test ( </desc> <cmt> use ctest to run unit tests </cmt> <cmt> disable failing test assertion </cmt> <cmt> run unit tests with travis </cmt>",use ctest to integrate unit tests into cmake build system
3711,<desc> adds new settings for members modal customization to default settings membersjs_show_beacon controls the visibility of beacon in members modal membersjs_show_signup_name controls the visibility of name field in signup membersjs_allowed_plans controls the visibility of plans allowed for member to signup with </desc> <cmt> added new settings type for members modal settings </cmt> <cmt> no issue </cmt> <cmt> - adds new settings for members modal customization to default settings </cmt> <cmt> - new settings have type membersjs </cmt> <cmt> - show_beacon controls the visibility of beacon in members modal </cmt> <cmt> - show_signup_name controls the visibility of name field in signup </cmt> <cmt> - allowed_plans controls the visibility of plans allowed for member to signup with </cmt> <cmt> added stripe connect check on members site data </cmt> <cmt> no issue </cmt> <cmt> - adds stripe connect check to determine if stripe is setup or not </cmt> <cmt> added new members modal settings to members site data </cmt> <cmt> no issue </cmt> <cmt> - adds 3 new settings to members site data </cmt> <cmt> - the settings allow customization of members modal and is changed on admin </cmt> <cmt> updated setting name </cmt>,added new settings for members modal settings
3712,<desc> fixed invalid references and some more spelling errors. </desc> <cmt> corrected spelling anf grammar errors in docstring for heap. </cmt> <cmt> fixed method signature for remove_min by removing unused parameter i. </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> fixed grammar in min_child docstring. </cmt> <cmt> fixed spelling error. </cmt> <cmt> fixed spelling errors in matrix_exponentiation.py </cmt> <cmt> removed trailing semicolons in matrix_inversion.py. todo: check for possible type error in line 61. </cmt> <cmt> fixed spelling error in base_conversion.py. </cmt> <cmt> fixed incorrect reference in min_height.py </cmt> <cmt> fixed incorrect reference in max_height.py </cmt>,fixed some invalid references and more spelling errors.
3713,"<desc> this re-lands commit c594696. the pr was original pr was breaking the integration test as while the gesture was active the androidview's parent widget got rebuilt which disposed the _androidviewgesturerecognizer and dropped pointer events from that point on. this change adds a unit test that reproduces the failure case, and fixes it by not rebuilding the _androidviewgesturerecognizer if the list of gesture recognizers did not change. note that the diff from the original pr is just e54e5ba. i keep it separate for review convenience, will squash before merging. </desc> <cmt> reland make androidview participate in gesture arenas </cmt> <cmt> this relands commit c594696f0626e32dcd83d2a7d8c479460d475374. </cmt> <cmt> the pr was original pr was breaking the integration test as while the </cmt> <cmt> gesture was active the androidview's parent widget got rebuilt which </cmt> <cmt> disposed the _androidviewgesturerecognizer and dropped pointer events </cmt> <cmt> from that point on. </cmt> <cmt> this change adds a unit test that reproduces the failure case, and </cmt> <cmt> fixes it by not rebuilding the _androidviewgesturerecognizer if the </cmt> <cmt> list of gesture recognizers did not change. </cmt> <cmt> fix the bug introduced with #20917 and add a unit test for it. </cmt>","re-land ""make androidview participate in gesture arenas."""
3714,"<desc> fixes for #11625 and #11884. </desc> <cmt> resolved: don't follow cnames if we already noticed truncation </cmt> <cmt> resolved: don't let edns0 opt dgram size affect tcp </cmt> <cmt> fixes: #11884 </cmt> <cmt> resolved: if we can't append edns opt rr, then indicate truncation to stub client </cmt> <cmt> we do so for any other rr we can't add, do this here too. </cmt> <cmt> fixes: #11625 </cmt>",some resolved stub dns reply fixes
3715,<desc> this pr makes the following changes to our (implicit) browser support: ie 10 and below will now be explicitly unsupported; please see  android 4 and below will now be explicitly unsupported; please see  safari 7 and below will now be explicitly unsupported; please see </desc> <cmt> remove the webkiturl polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt> <cmt> remove the xmlhttprequest.response polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt> <cmt> remove the htmlelement.dataset polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt> <cmt> remove the imagedata.set polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt> <cmt> remove the input.type polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt> <cmt> remove the document.readystate polyfill </cmt> <cmt> this is only relevant for browsers that we don't intend to support with pdf.js version 2.0. </cmt>,"remove even more polyfills for old, and now unsupported, browsers"
3716,"<desc> since ldaps:// is deprecated, we use tsl over ldap:// with start_tsl on our ldap server; that case is not covered by the code. i added the option use_start_tls by sudo ./edit-config python.d/openldap.conf and managed them in  /usr/libexec/netdata/python.d/openldap.chart.py . component name python.d/openldap i tested it for tsl over ldap:// with start_tls; we should test if tsl over ldaps:// is not broken. related to issue 9004. </desc> <cmt> update openldap.conf </cmt> <cmt> update openldap.chart.py </cmt>",fix tls over ldap in the python.d/openldap collector
3717,<desc> what's there in this pr? completed the missing setspeed functionality in the reactnative android library. added documentation around the usage of setspeed according to the native implementation of lottieanimationview </desc> <cmt> added setspeed functionality. </cmt> <cmt> updated the api doc. </cmt>,added the functionality of setting the speed of the animation for android
3718,<desc> fixes #466 also added lsb init script and some documentation in mysql charts. </desc> <cmt> added lsb (old debian) init script </cmt> <cmt> fixed typo that fails to run mysql collector under certain conditions </cmt> <cmt> added mysql charts info on a few charts </cmt> <cmt> added shorten() plugin in index.html to allow shortening long information messages </cmt> <cmt> disabled animation for shorten plugin </cmt> <cmt> added css for shorten text links </cmt> <cmt> fixed memory leak in web_client_free() </cmt> <iss> possible memory leak </iss>,fixed memory leak in web client handling
3719,"<desc> dqn rainbow on pytorch was missing the ability to do distributional q-learning (num_atoms > 1). this pr adds this functionality. also implements noisylayer as a re-usable nn.module for pytorch. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt>  conflicts: </cmt> <cmt> 	rllib/agents/dqn/dqn_torch_policy.py </cmt> <cmt> 	rllib/utils/torch_ops.py </cmt> <cmt> wip. </cmt>",implement dqn pytorch distributional head.
3720,"<desc> fixes #4334 fixes #4328 fixes #4348 (follow-up to #4630, #4583). this gets several commands working when used in a workspace-enabled solution: outdated: when used in a workspace root or any child packages, it will show outdated packages across the entire workspace added ""workspace"" column to show where the outdated package is installed remove: when used in a workspace root, removes given package from the root only when used in a workspace child, removes given package from that child only upgrade: when used in a workspace root, upgrades given package in root only when used in a workspace child, upgrades given package in child only upgrade-interactive: shows outdated packages across entire workspace, and can upgrade any/all added ""workspace"" column to show where outdated package is installed this is slightly different from how @arcanis described in #4630, specifically with upgrade. i thought it would be less confusing/frustrating for users, especially if child workspaces have conflicting versions of the same dependency. rather than forcing them all to the same version, this allows for fine-grained control while offering a whole-workspace upgrade option with upgrade-interactive. added tests where appropriate existing tests pass screenshots of updated command output below: outdated with ""workspace"" column: upgrade-interactive with ""workspace"" column: </desc> <cmt> use lockfilefolder for cli check </cmt> <cmt> make ""upgrade"" work inside workspace packages </cmt> <cmt> executes ""fetchrequestfromcwd"" in actual cwd, which ensures </cmt> <cmt> ""outdated"" and ""upgrade"" commands in workspace packages </cmt> <cmt> operate on the correct dependencies and preserve unrelated lockfile </cmt> <cmt> entries. </cmt> <cmt> support workspaces in outdated and upgrade-interactive </cmt>",workspace support in several commands
3721,"<desc> previously the configs were using 1mhz i2c timings. however this was causing issues as the eeprom's were only rated for 400khz. hence it was crashing upon startup. tested and working on all boards. fix keyboard crashing by changing i2c to 400khz my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> 400khz fix </cmt> <cmt> fix valor rev2 timing </cmt>",xelus keyboards 400khz i2c fix
3722,<desc> resolves #5633 adds resource. new subject and a book why is this valuable? this is a freshman year college course but it's subject was missing. the book is nice and i have referred to it several times. the link carries you to the author's website where he says it's for free. yes read our contributing guidelines </desc> <cmt> update free-programming-books-subjects.md </cmt> <cmt> update free-programming-books-subjects.md </cmt> <cmt> update free-programming-books-subjects.md </cmt> <iss> add category computer organization and architecture </iss>,addition of subject computer organization and architecture
3723,"<desc> this is work in progress on issue #10815, packaged as a pr per @vvakame, but definitely not ready to be pulled.    the 'fix' as proposed has far-reaching implications on other modules that need review.  please see discussion in #10815. </desc> <cmt> test case for issue #10815: </cmt> <cmt> nodejs.eventemitter extended in node 6. </cmt> <cmt> initial fix for #10815, but... </cmt> <cmt> adding the new methods to the interface causes test failures in a number of other modules... </cmt> <cmt> back-out whitespace change </cmt>",trouble with new eventemitter methods
3724,"<desc> my personal keymap, is an example of a working backlight for rev 2 of the roadkit pcb. </desc> <cmt> create test </cmt> <cmt> add files via upload </cmt> <cmt> delete test </cmt> <cmt> add files via upload </cmt> <cmt> add files via upload </cmt> <cmt> add files via upload </cmt> <cmt> add files via upload </cmt> <cmt> update keymap.c </cmt>",roadkit keymap with working backlight
3725,"<desc> this pr implements multiple optimizations: use constituent maps when checking relations involving large discriminated union types on the target side. use constituent maps when reducing large discriminated union types that appear as contextual types. use constituent maps for in control flow analysis involving large discriminated union types. perform deduplication of structurally equivalent object and array literal element types in array literals. cache results of subtype reduction when constructing union types. use discriminant property checks to quickly disqualify types from subtype checks during subtype reduction. when feasible, constituent maps that map from discriminant unit types to corresponding constituent types are constructed for large union types. these maps allow matching constituents to be quickly identified through simple lookups instead of expensive linear scans. constituent maps are deemed feasible for unions with 10 or more constituents and less than 25% duplication in discriminant keys. the maps are purely a fast path optimization--all existing logic remains in place with unchanged semantics for cases where the maps don't apply. the optimizations reduce the check time of the worst case examples from #42522 close to 10x (from 1.6s to 0.18s). furthermore, the check times for the compiler-with-unions and monaco test cases are reduced by 32% and 6% respectively. fixes #42522. </desc> <cmt> no array literal subtype reduction when contextual type is present </cmt> <cmt> accept new baselines </cmt> <cmt> fast path in relations and filtering of pure discriminated union types </cmt> <iss> unexpected slowness initializing large array with discriminated union constituents </iss>",optimize checking involving large discriminated union types
3726,"<desc> added a starter that connects the default starter to microsoft's newly announces azure static web apps. this includes automatic ci/cd using github actions, as well as behind the scene staging environments etc. </desc> <cmt> added azure swa starter </cmt> <cmt> added azure categorie </cmt> <cmt> added azure tag </cmt>",chore(starters) add gatsby starter azure swa
3727,"<desc> as presented by me in this post:  the keyboard has a functional prototype, and is constructed with custom pcbs. it requires it's own matrix.c file, as it pulls the keystate matrix from an external rf microcontroller. </desc> <cmt> create temp </cmt> <cmt> delete temp </cmt> <cmt> first commit </cmt>",initial support for the mitosis keyboard
3728,<desc> description: adds support for operation modes in the ephember climate device checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> add operation mode support for climate.ephember </cmt>,eph ember support operation modes
3729,"<desc> this pr switches the implementation of ghost from before/after css classes to injected text. use editor.useinjectedtext: false to go back to before/after css classes. fixes #125742, #126537, #125324 and #125123. </desc> <cmt> improves diffing for inline suggestions. </cmt> <cmt> introduces editor.useinjectedtext (defaults to true) and changes ghost text implementation to use injected text if not disabled. </cmt> <iss> bracket border goes around inline editor decorations </iss> <iss> inlinecompletionitem doesn't honor wrapped text </iss> <iss> first class support for inline text (move away from ::after) </iss> <iss> weird suggestion completion blinking in settings.json </iss>",adopt injected text for ghost text
3730,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> feat(types): add initial @carbon/icons-react types </cmt> <cmt> chore(types): specify typescript version in carbon__icons-react definition </cmt> <cmt> fix(types): fix lint/testing errors in carbon__icons-react definition </cmt>",add carbon__icons-react types for @carbon/icons-react
3731,"<desc> original pull-request #29531 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix </cmt> <cmt> fix pathstartswith </cmt>",cherry pick #29531 to 21.7: fix pathstartswith
3732,"<desc> accelerates non-modifying transformations, e.g. closes #7383 dataframe.groupby(...).transform(np.max) ------------------------------------------------------------------------------- test name                                    | head[ms] | base[ms] |  ratio   | ------------------------------------------------------------------------------- groupby_transform_ufunc                      |   6.1977 | 215.6494 |   0.0287 | groupby_transform2                           | 155.9653 | 155.1824 |   1.0050 | groupby_transform                            | 167.5134 | 165.7823 |   1.0104 | ------------------------------------------------------------------------------- test name                                    | head[ms] | base[ms] |  ratio   | ------------------------------------------------------------------------------- ratio < 1.0 means the target commit is faster then the baseline. seed used: 1234 target [3d3715b] : wpi: fast tranform on dataframe base   [eb1ae6b] : merge pull request #7458 from sinhrks/intersection </desc> <cmt> perf: addtl transform vbenches </cmt> <cmt> wpi: fast tranform on dataframe </cmt> <iss> transform function is very slow in 0.14 - similar to issue #2121 </iss>",performance gains in dataframe groupby.transform for ufuncs (gh7383)
3733,"<desc> button_exists as a shortcut to check a button's existence button_pressed as a shortcut to check a button press get_button_states to combine reprapworld_keypad and regular button acquisition </desc> <cmt> rename local slow_buttons for clarity </cmt> <cmt> apply standard pin test to buttons </cmt> <cmt> this is the easiest way to make button pin testing consistent without </cmt> <cmt> renaming all the button pins. just make a macro especially for testing </cmt> <cmt> if button pins are set, since they are named consistently in the pins </cmt> <cmt> files. </cmt>","macros for buttons, some cleanup for slow buttons"
3734,"<desc> this is in a ""better than nothing"" stage. currently rebasing only cur bin: functions (and bbs) flags meta items (comments, etc) refs / xrefs </desc> <cmt> fix rebasing bin info when reopening in debug mode </cmt> <cmt> blind rebase everything </cmt> <cmt> fix double free </cmt> <cmt> reduce indentation level </cmt>",rebase things when reopening file in debugger mode
3735,<desc> makes sure to only run the pageconfig babel plugin for page files. fixes: #7834 </desc> <cmt> add test for pageconfig </cmt> <cmt> make sure pageconfig plugin is only run for pages </cmt> <iss> typeerror: declaration.init.properties is not iterable </iss>,fix pageconfig plugin running for non-pages
3736,"<desc> this pr cherry-picks two bug fixes from upcoming pr #2607. commit 5e0232c fixes a bug in the http1 protocol handler that disarms the idle timer without rearming it, when receiving bytes that consists of only the chunk header of a chunked encoding. commit 30cf4e0 fixes a bug in the http3 protocol handler that erroneously raises an assertion failure when receiving fin at the end of request body without any data being accompanied. </desc> <cmt> unarm the timer only when write_req.cb is to be invoked </cmt> <cmt> do not complain when receiving fin without data </cmt>",small fixes from pr 2607
3737,"<desc> this pr adds cancelid option for showmessagebox, which will be used as return value when user cancels the dialog instead of clicking the buttons of the dialog. fixes #876. </desc> <cmt> add cancelid option for showmessagebox </cmt> <cmt> set default cancelid in javascript </cmt> <cmt> on os x the ""cancel"" is always get selected when dialog is cancelled </cmt> <cmt> docs: cancelid </cmt>","add ""cancelid"" option for showmessagebox"
3738,"<desc> 4.0.6 fixes #2314 #2302 mistakenly used list.loose as a flag to end list items early if they start with two blank lines. technically that is a different scenario from being ""loose"", so legitimate loose lists were also hitting that flag and prematurely ending the list after the second item. this pr just adds a separate flag endearly to handle that case. squash and merge pr following conventional commit guidelines. </desc> <cmt> fix #2314 </cmt> <cmt> lint </cmt> <iss> sub-list items which are multiples of 3 are wrapped with pre/code blocks in version 4.0.6 </iss>",fix every third list item broken
3739,"<desc> this introduces a mechanism to slightly reduce the copy-and-paste-ness of the documentation for the high level rest client. it pulls out the entire ""execution"" portion of the page that we can include in every page. doing this requires the introduction of a few attributes. it then uses these attributes to further cut down on some copy-and-paste-ness. this also standardizes some of the ids in the search documentation to the naming scheme that we seem to be using in the newer docs. </desc> <cmt> anchors </cmt> <cmt> includes </cmt> <cmt> get settings </cmt> <cmt> more </cmt> <cmt> more </cmt>",cut down on high level rest client copy-and-paste-ness
3740,"<desc> hi, this should fix #59191! my friend and i are working on learning the rustc codebase through contributions, so please feel free to mention anything amiss or that could be done better. the code adds an explicit case for when a macro applied to the crate root (via an inner attribute) replaces it with something nonsensical, like a function. the crate root must be a module, and the error message reflects this. i should note that there are a few other weird edge cases here, like if they do output a module, it succeeds but uses that module's name as a prefix for all names in the crate. i'm assuming that's an issue for stabilizing #54726, though. </desc> <cmt> fix 59191 </cmt> <cmt> this adds an explicit error for when macros replace the crate root with </cmt> <cmt> a non-module item. </cmt> <cmt> add tests for issue 59191 </cmt> <iss> thread 'rustc' panicked at 'internal error: entered unreachable code', src/libsyntax/ext/expand.rs:289:18 </iss>",fix 59191 - ice when macro replaces crate root with non-module item
3741,"<desc> this pr introduces type definitions for google workspace add-on event objects (documentation), the first and only positional parameter of homepage and contextual triggers callbacks, as well as action callback functions. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> [google-apps-script] added addon event objects </cmt> <cmt> [google-apps-script] included addon event types in the index declaration file </cmt> <cmt> [google-apps-script] added tests for addon event objects </cmt> <cmt> [google-apps-script] fixed typo in triple-slash directive </cmt>",added addon event objects declarations
3742,"<desc> closes unify-505, unify-482 adds urql as a server-side cache for remote queries, using a stale-while-revalidate approach to query fetching. will refine this in the future, but it cuts down on load time after initial fetch adds cy.loginuser() to simulate being logged-in during e2e tests calls user.get during initial app startup stubs the fetch used to resolve queries against the remote schema, and mocks them using the mocks used in component tests, with a cy.remotegraphqlintercept that we will refine in the future if you need to tap in and modify the result values. </desc> <cmt> feat: adding a cache layer for remote queries </cmt> <cmt> add helper for login user, restore user login on open, use stubgql cloud types in e2e testing </cmt>","adding a cache layer for remote queries, e2e test helpers"
3743,<desc> since esp32 does not support gz firmware ota update the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc4 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> build gz only for esp8266 </cmt> <cmt> gz not build anymore for esp32 </cmt> <cmt> no gz build for esp32 </cmt>,build gz files only for esp8266
3744,"<desc> add a few command line arguments that simplify debugging of the upload_rbe_results.py script fix a bug where in some rare cases, some test results are not uploaded to bigquery as they should (e.g. for invocation </desc> <cmt> easier debugging for upload_rbe_results.py </cmt> <cmt> sometimes not all rbe results are uploaded </cmt>",fix bug in upload_rbe_results.py (which sometimes skips some test cases when uploading to bq)
3745,<desc> ref: #971 </desc> <cmt> faq / troubleshooting final draft release </cmt> <cmt> readme.md </cmt> <cmt> a01-espcomm_sync failed.md </cmt> <cmt> a02-my-esp-crashes.md </cmt> <cmt> a03-library-does-not-work.md </cmt> <cmt> total of five faq items </cmt> <cmt> emoji included </cmt> <cmt> pictures folder </cmt> <cmt> may need to read again in couple of days for another cleaning </cmt> <cmt> date:      sun jun 26 18:43:51 2016 +0200 </cmt> <cmt> frizing schematics added </cmt>,initial release of faq / troubleshooting section
3746,"<desc> around june 5, 2019, some of the existing tests that measured exact memory consumption across a series of operations started diverging based on platform. this pr adds new expect-style macros to help tests deal with this. expect_memory_eq only runs in 'release' builds on ci, where we expect stable, consistent behavior. expect_memory_le runs on any build with tcmalloc. on other platforms those expect macros print 'info' messages indicating that they are skipped. risk level: low testing: //test/... and a few platform variants fixes: #7216 </desc> <cmt> add macros and helper functions for doing approximate and exact memory tests. </cmt> <cmt> spelling fix attempt </cmt> <cmt> spelling </cmt> <cmt> spelling </cmt> <cmt> spelling </cmt> <iss> memory: test against exact value in ci, approximate at other times. </iss>","add macros for doing memory-usage tests of varying precision, based on platform"
3747,"<desc> this fixes an ancient bug where the selected item is always the top one in the list after you go back from a recording sub directory. the root cause is two-fold: we've called m_vecitems->setpath() manually before updating the window contents. this is wrong since the history manager excepts the item path to be that of the previous window, not the window we are about to enter. the first commit fixes that by removing the update() method override from cguiwindowpvrbase. the next issue cropped up after fixing the previous one. the problem now is that the view state which (among other things) controls whether the ""go to parent"" item should be shown at the top of lists held a reference to the previous directory's items at a time when it should have had the new list. this fixes that by simply moving the call a bit earlier in the chain. @montellese regarding the second one, do you know enough about this part to comment on it? i haven't tested all possible scenarios, just that the recordings window works @xhaggi @opdenkamp for the usual review @topfs2 for helix unless someone complains </desc> <cmt> [pvr] don't update the item list path before calling update(), </cmt> <cmt> otherwise the history will be incorrectly recorded since the the </cmt> <cmt> history expects m_vecitems->getpath() to be the ""old"" path, not the </cmt> <cmt> new one </cmt> <cmt> [gui] update the view state's list reference before the view state is </cmt> <cmt> consulted about whether the ""go to parent"" item should be added to the </cmt> <cmt> list </cmt> <cmt> without this the view state will always think the previous directory is </cmt> <cmt> the one you're currently in. this means that e.g. in the recordings </cmt> <cmt> window the ""go to parent"" was shown in the root directory (except the </cmt> <cmt> first time the window was entered since the path is set correctly then), </cmt> <cmt> but not in subdirectories. </cmt> <cmt> subdirectories. </cmt>",fix recording history (last directory not selected)
3748,"<desc> in several places in our code we need to get a consistent list of files + metadata of the current index. we currently have a couple of ways to do in the store class, which also does the right things and tries to verify the integrity of the smaller files. sadly, those methods can run into trouble if anyone writes into the folder while they are busy. most notably, the index shard's engine decides to commit half way and remove a segment_n file before the store got to checksum (but did already list it). this race condition typically doesn't happen as almost all of the places where we list files also happen to be places where the relevant shard doesn't yet have an engine. there  is however an exception (of course :)) which is the api to list shard stores, used by the master when it is looking for shard copies to assign to. i already took one shot at fixing this in #19416 , but it turns out not to be enough - see for example  the first inclination to fix this was to add more locking to the different store methods and acquire the indexwriter lock, thus preventing any engine for accessing if if the a shard is offline and use the current index commit snapshotting logic already existing in indexshard for when the engine is started. that turned out to be a bad idea as we create more subtleties where, for example, a store listing can prevent a shard from starting up (the writer lock doesn't wait if it can't get access, but fails immediately, which is good). another example is running on a shared directory where some other engine may actually hold the lock. instead i decided to take another approach: remove all the various methods on store and keep one, which accepts an index commit (which can be null) and also clearly communicates that the caller is responsible for concurrent access. this also tightens up the api which is a plus. add a snapshotstore method to indexshard that takes care of all the concurrency aspects with the engine, which is now possible because it's all in the same place. it's still a bit ugly but at least it's all in one place and we can evaluate how to improve on this later on. i also renamed the  snapshotindex method to acquireindexcommit to avoid confusion and i think it communicates better what it does. </desc> <cmt> add locking to store access </cmt> <cmt> fix some tests </cmt> <cmt> more logging </cmt> <cmt> add a direct access to the store, so engine maybe open or close </cmt> <cmt> tests ands some fixing </cmt> <cmt> fix shardow recovery </cmt> <cmt> move recovery target service to new indexshard.snapshotstore </cmt> <cmt> sigh </cmt> <cmt> sigh2 </cmt> <cmt> reduce unsafe methods in store </cmt> <cmt> fix npe </cmt>",tighten up concurrent store metadata listing and engine writes
3749,<desc> what do these changes do? this refactors the objectdirectory to only use callbacks where necessary and to post callbacks on an event loop instead of calling the callbacks in the same stack. #2959 </desc> <cmt> add event loop as member of objectdirectory </cmt> <cmt> post object subscription callback to event loop </cmt> <cmt> convert getinformation for a client to not use callbacks </cmt> <cmt> convert runfunctiononeachclient to not use callbacks and other cleanups </cmt> <cmt> todo </cmt>,refactor objectdirectory to reduce and fix callback usage
3750,<desc> close  #13628. this pr fixes the crash caused by #13599 when opening devtools for frameless window. </desc> <cmt> fix: use inspectablewebcontentsview as content view </cmt> <cmt> spec: opendevtools should not crash for frameless window </cmt> <iss> electron crash during open devtools on macos (v3.0.0-beta.2) </iss>,fix crash when opening devtools for frameless window
3751,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). i initially only wanted to fix comparator.value and add the minversion function. i fixed some parameter and return types to match the actual runtime behavior. i changed mutable arrays to readonlyarray where appropriate. i also changed loose?: boolean to looseoroptions?: boolean | options: all methods and classes take a final options object argument. all options in this object are false by default. the options supported are: loose be more forgiving about not-quite-valid semver strings. (any resulting output will always be 100% strict compliant, of course.) for backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includeprerelease set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. </desc> <cmt> semver: add missing functions and properties </cmt> <cmt> even more stuff </cmt> <cmt> add definition author </cmt>","add missing properties and functions, correct some parameter types"
3752,"<desc> while going through the basic classification tutorial i found myself wanting to see the prediction arrays. how confident was the prediction? when it was right, was it quite confident? when it made a mistake, was it confident or were two options a contender? to help me see that, i added a few charts to the tutorial. for a single image, i made charts like this to accompany the images. it some cases, there are other labels which the model deems somewhat likely, which we can see in the grey bars. when the prediction is wrong, it looks like this: i can also show these charts for the first x images. colab to run here. note - there were a few places where it was changing per-cell colab settings related to autoexec. i just left these in the pr for now, but feel welcome to remove. the main commit is ab347ae. the others were a merge from a branch to main on my repo, and accidentally saving a copy in the wrong place (and undoing it). let me know if i should try to remove these before merging? </desc> <cmt> created using colaboratory </cmt> <cmt> add graphs of percents for the prediction array </cmt> <cmt> add graphs of percents for the prediction array </cmt> <cmt> delete zan's_copy_of_basic_classification.ipynb </cmt>",adding illustrative charts to basic classification tutorial
3753,"<desc> remove android/mac and other keymaps from web bundles. reduces hello world app size from 881705 to 847524. #37796 i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. i updated/added relevant documentation (doc comments with ///). </desc> <cmt> treeshake keymaps for web </cmt> <cmt> restrict import </cmt> <cmt> update raw_keyboard </cmt>",treeshake keymaps for web (4% code size reduction in hello world)
3754,"<desc> supersedes #2693 fixes #2692 , feedback welcome, </desc> <cmt> unittests for isequal for typed arrays, some of which pass accidently </cmt> <cmt> fixes jashkenas/underscore#2692: isequals for typed arrays by doing byte checks </cmt> <cmt> support for arraybuffer and compatible with lodash </cmt> <cmt> cleanup </cmt> <cmt> return true (sooner) </cmt> <cmt> break isequals by feeding an object with a .buffer property </cmt> <cmt> instead of try/catch we test for typed array using arraybuffer.isview </cmt> <iss> isequal incorrectly compares dataview objects </iss>","support for typed array, dataview and arraybuffer in isequals: take 2"
3755,"<desc> due to previous prs, there is an issue with xlim wrongly plotted for lines. i digged into database a bit, and found it also affects plot(kind='area') because they share the same lineplot. and this issue is produced in both dataframe and series. now looks like the issue is gone: duplicated closed issue 27796 is solved as well: also looks like issue in #25160 is gone as well. the same to #24784 looks like issue is also gone closes #27686 , #25160, #24784 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 27686 </cmt> <iss> df.plot with two plots in the same axes and 2nd one is line plot makes different chart between 0.23.4 and 0.25.0 </iss>",plot('line') or plot('area') produces wrong xlim in xaxis in 0.25.0
3756,"<desc> backports fix for filenames with spaces (#9142) update to latest upstream (v2.29) completions (#8894) adds a new git zsh autocompletion to verify the script is running fixes issue with extra spaces in some completions (e.g 'git log ma') fixes issue with --options and --no-options (upstream didn't port it from bash script) the last commit of the series switches the source to git-completion, my new project where i've gathered all the patches. this way we can use the latest upstream without breaking support for older versions of git. fixes #9142 fixes #8894 closes #9362 </desc> <cmt> gitfast: backport fixes from git-completion </cmt> <cmt> there's a new tool to verify the user is running the script, simply do: </cmt> <cmt> 'git zsh<tab>', it should output v1.0. </cmt> <cmt> gitfast: update custom patch </cmt> <cmt> gitfast: update to upstream v2.29 </cmt> <cmt> gitfast: update to git-completion v1.0 </cmt> <cmt> git-completion is my new project where i gather all the outstanding </cmt> <cmt> patches and more, so there's no need to keep track of them any more. </cmt> <cmt> it's equivalent to the completions of git v2.29 plus some other fixes </cmt> <cmt> and older versions of git should also work. </cmt> <cmt>  </cmt> <iss> git switch and git restore completions removed from gitfast </iss> <iss> gitfast plugin: tab completion broken on filenames containing spaces (expected automatic quote/backslash) </iss>",update to latest upstream and more
3757,<desc> this task is requested by yandex cloud. change http response code in case of some parse errors to 400 bad request. this fix #10636 </desc> <cmt> fix http response code for some parse errors #10636 </cmt> <cmt> added a test #10636 </cmt> <iss> improper http status code on data parsing errors </iss>,fix http code in case of some parse errors.
3758,"<desc> remove tags and lemmas from tokenizer exceptions and tidy up language-specific data. make lookups_extra and omit_extra_lookups mechanisms redundant. simplify language data again and move defaults back to languagedefaults, rather than constructing all objects via config. vocab and lemmatizer now own their own relevant lookups. orth variants now live in lookups data. see the feature/spacy-v3 branch on spacy-lookups-data for the updated data:  enhancement i have submitted the spacy contributor agreement. </desc> <cmt> wip: move more language data to config </cmt> <cmt> remove omit_extra_lookups </cmt>",update language data config and lookups integration
3759,"<desc> original pull-request #30230 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> allow identifiers staring with numbers in multiple joins </cmt>",allow identifiers starting with numbers in multiple joins
3760,"<desc> attempts to make use of scipy.stats.mstats.mode withinsimpleimputer(strategy='most_frequent'). this was suggested in #14325 since a previous bug within the mstats.mode function has been fixed. i'm currently using the updated mstats.mode function to impute values for numeric inputs. however, it seems that mstats.mode will not work with alpha inputs because it requires that the inputs can be cast to floats. this happens here when mstats.mode internally calls find_repeats. my initial assumption was that mstats.mode would be able to handle all input types (since scipy.stats.mode can) and that the code block for strategy == 'most_frequent' could be cleanly handled with this single function. my current understanding is that any non-numeric inputs would have to be handled separately by passing them off to scipy.stats.mode -- however this is already the current behavior for all cases (numeric and otherwise). data are being passed into the internal function _most_frequent, which is using scipy.stats.mode. i could be overlooking something obvious but for now it seems to me that using mstats.mode might introduce more complexity into the code. request for feedback what do you think is the best way forward? do you think there is a simpler way that i could continue on  with mstats.mode that i might be missing or does it not seem worth it to include mstats.mode? </desc> <cmt> add stats.mstats.mode for numerics </cmt> <cmt> clean comments </cmt>",doc add comment about scipy.stats.mstats.mode for simpleimputer(strategy=most_frequent)
3761,"<desc> add abstract interface for reading or writing or subscribing actors to gcs client. through the abstract interface, gcs can be extended to support other storage systems. closes #5058 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> new class actorstateaccessorinterface </cmt> <cmt> rename to redisactorstateaccessor </cmt>",[gcs]add abstract interface of actor to gcs client
3762,"<desc> every method call and overloaded operator had a callee_id that was be used to store the method type and type substitutions, that information is now stored in the method_map, alongside the method's origin. </desc> <cmt> rename a few typeck method-related structures to uppercamelcase. </cmt> <cmt> replace callee_id with information stored in method_map. </cmt>",remove callee_id's from the ast.
3763,"<desc> adds integrations and legacy integrations into search </desc> <cmt> fix(cmd-pal): trim whitespace from search queries </cmt> <cmt> this fixes searches that have a trailing space, e.g. ""dsn "" </cmt> <cmt> add support to org plugins endpoint to list all plugins </cmt> <cmt> feat(ui-search): add integrations to search </cmt> <cmt> adds integrations and legacy integrations into search </cmt>",add integrations to search (app-707)
3764,"<desc> closes #22426 i'm not sure which is better: simply ""unexpected token <"" ""unexpected token <, expect one of =>, :, ("" but this pr is actually mergable now </desc> <cmt> fix issue #22426 #22447 </cmt> <cmt> fix tests </cmt> <iss> panic: ""internal compiler error: ident only path should have been covered already"" </iss>",fix ice for unexpected < in pattern
3765,"<desc> closes #35602 adds a top-level property optionalreplacementspan to completionsinfo, which contains the textspan representing the identifier or string literal-like content where completions were completions were requested, if they were requested on such a node. e.g. when requesting completions at the caret in console.clockwork //        ^ the optionalreplacementspan will be the span of the identifier clockwork. the editor can opt to use this span when accepting the completion entry clear to produce console.clear instead of console.clearockwork, as it would today. the span is also populated for string literal completions: array[""tospaghetti""] //        ^ the optionalreplacementspan here is the span of tospaghetti, excluding the quotes. as before, if an individual completionentry specifies a replacementspan, that span must be used. it is possible for an optionalreplacementspan to be populated even when some individual entries have a replacementspan that must receive priority. </desc> <cmt> add optionalreplacementrange to completions response </cmt> <cmt> get the name right </cmt> <iss> add inserting/replacing range to suggestion items </iss>",add optionalreplacementspan to completions response
3766,<desc> added brightness and contrast adjustment to manual color plugin </desc> <cmt> added sanity check for realface output size to be divisible by 32 </cmt> <cmt> pep8 amendments </cmt> <cmt> added contrast / brightness adjustment to manual balance plugin </cmt>,manual balance plugin - brightness contrast adjustments
3767,"<desc> centralizes the page table changing to one place instead of making all calling code manually handle it. we can also eliminate an unnecessary page table pointer variable within arm_dynarmic, since the current page table will always be that of the main running kernel process. </desc> <cmt> kernel: handle page table switching within makecurrentprocess() </cmt> <cmt> centralizes the page table switching to one spot, rather than making </cmt> <cmt> calling code deal with it everywhere. </cmt> <cmt> arm/arm_dynarmic: remove unnecessary current_page_table member </cmt> <cmt> given the page table will always be guaranteed to be that of whatever </cmt> <cmt> the current process is, we no longer need to keep this around. </cmt> <cmt> core/memory: remove getcurrentpagetable() </cmt> <cmt> now that nothing actually touches the internal page table aside from the </cmt> <cmt> memory subsystem itself, we can remove the accessor to it. </cmt>",minor simplifications to page table management
3768,"<desc> @rbuckton @mhegazy i was working on suspiciously similar code for doing extension profiling in #9038 - by splitting the performance tools framework from either pr, we can merge them in more quickly and start using a common framework across all prs. notable differences from the original code in the transforms branch: when the new extendeddiagnostics argument is supplied, all recorded perf buckets are reported under the friendly name they use as their key (unlike before, where they used a codename and had to be explicitly printed). this is very useful since extensions are likely to add extra perf buckets on the fly (and we have no idea what they'll be named, but would still like to report them in the summary). the counter and emit code is presently unused - @rbuckton uses them in profiling and inspecting transformations in his branch, but i don't yet have a need to insert profiling events or replace counters elsewhere in our codebase (and i may use them for extensions, too). the function used to mark internally is now chosen as one of performance.now, date.now, and () => new date().gettime() (in that order) - this way a higher resolution/performance marker is used when available, but falls back to a universal option if they are unavailable. (and as @rbuckton explained the other day, it doesn't try to use process.hrtime since that would allocate arrays.) it's in its own file, rather than in core.ts - it's an isolated set of work and is understandable/reusable. imo, it makes sense for it to be its own unit. </desc> <cmt> port performance tools from transforms branch </cmt> <cmt> use friendlier names, add compiler option to print all recorded measures </cmt> <cmt> always print total time </cmt>",add performance framework from transforms branch
3769,"<desc> this takes the checks that were already being done for configs with no actual files loaded in a couple of places and extends them to almost all the places where it could come into play. also, this adds some more config tests that exercise various combinations of existent and non-existent config files at the different levels. </desc> <cmt> more tests of config with various absent files </cmt> <cmt> plus a bit of extra paranoia to ensure config object has valid </cmt> <cmt> contents. </cmt> <cmt> more config code checks and cleanups </cmt>",extend checking for config with no files
3770,"<desc> refs tryghost/team#586 if a product inside ghost is deleted, we want to cascade delete all associated stripe products and prices as they need to refer to a ghost product. adds cascade delete for products -> stripe_products -> stripe_prices -> members_stripe_customers_subscriptions to avoid broken states </desc> <cmt> added cascade delete for stripe products </cmt> <cmt> refs </cmt> <cmt> if a product inside ghost is deleted, we want to cascade delete all associated stripe products as they need to refer to a ghost product. </cmt> <cmt> added cascade delete for stripe prices table </cmt> <cmt> refs </cmt> <cmt> if a stripe product is deleted from ghost db, we want to remove all associated stripe prices as well as they'll be left in weird hanging state otherwise </cmt>",added cascade delete for stripe products and prices
3771,"<desc> this pr brings a number of improvements to the std logger: logrecord is now immutable significant updates to readme introduce new rotatingfilehandler introduce 'x' and 'w' file modes on log creation (in addition to 'a') fix issue with async log writes for filehandler by making it synchronous, as the async version was dropping log messages in heavy load scenarios (and even hanging the process) </desc> <cmt> feature: add rotatingfilehandler, file mode and immutable logrecord </cmt> <cmt> added tests and formatted code </cmt> <cmt> fix: improve speed of filesize lookup by 20 percent </cmt>",log improvements and new log handler
3772,<desc> not finished yet# i added just a new route with a request handler for options </desc> <cmt> added ui for options menu </cmt> <cmt> update ui for options menu </cmt> <cmt> update ui for options v2 </cmt> <cmt> update ui for options v2 </cmt> <cmt> added new btn class </cmt> <cmt> little changes </cmt> <cmt> little changes </cmt> <cmt> merge </cmt> <cmt> deleted branch </cmt> <cmt> merge </cmt> <cmt> change menu button class </cmt> <cmt> added option route + added very incomplete handler class </cmt> <cmt> merge remote-tracking branch 'mitmproxy/master' </cmt>,start of developing server side for options
3773,"<desc> fix paddle cloud rolemaker change rpc retry times add value error in fleet distribute optimizer </desc> <cmt> fix paddle cloud role maker (#20860) </cmt> <cmt> * fix paddlecloud role maker & add warning in distribute transpiler  & change rpc_retry_times </cmt> <cmt> test=develop,test=release/1.6,cherry-pick </cmt>",[cherry-pick]cherry pick paddle cloud role maker
3774,<desc> case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. </desc> <cmt> add typings for api changes in 4.0.4 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update wdio typings semver to 4.0.4 </cmt>,update typings for webdriverio to 4.0.4
3775,"<desc> closes #1275 still need to write tests, but thought i'd let you guys take a look at this implementation before i go too far down that road in case i need to make major changes. adds the @mark decorator which allows users to mark tasks, then be picky about what tasks are executed in a test run using the --marks argument. tasksets can be marked too, but doing this doesn't actually apply the mark to the taskset, but instead to all the tasks defined within that taskset (recursively). then, in order to determine if a taskset should be executed, the locust_mark_set property of a taskset definition actually collects all the marks of its inner tasks (recursively). this is to avoid executing tasksets that don't have any appropriately marked tasks, even if there are nested tasksets. let me know what you think! </desc> <cmt> added mark decorator, marks argument, and functionality for both </cmt> <cmt> had to resolve a conflict with a comment being removed in argument_parser </cmt> <cmt> added marks attr to env, made 'marked' apply to all marks, made marked_tasks attr of taskset so that tasks is preserved, made apply_marks method of taskset </cmt> <cmt> implemented mark functionality for task sets and users </cmt> <cmt> changed locust_mark_names to set. made it so locust only runs tasksets with appropriate marks in its tasks </cmt> <cmt> implemented marks in sequentialtaskset, renamed locust_mark_names to locust_mark_set, fixed some tests </cmt> <cmt> added documentation for marks </cmt> <cmt> catch rescheduletask when no marks match at all </cmt> <iss> add @only decorator to tasksets </iss>",add task marking for running more specific tests
3776,<desc> fixed an error in the exasol plugin preventing the user from editing the result set </desc> <cmt> removed pseudoattributes - not supported in exasol </cmt> <cmt> implemented missing getchildtype method </cmt> <cmt> override gettypeid to deliver correct typeid results </cmt>,"can't obtain entity identifier"" in resultsetpersister for exasol"
3777,"<desc> make sure set the target branch to develop follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> fix the issue #2994 </cmt> <cmt> add the example for onewayproducer and scheduledmessageconsumer. </cmt> <cmt> remove a unused line and add notes. </cmt> <cmt> rollback </cmt>",[issue #3048]add example of onewayproducer and scheduledmessage
3778,<desc> @jreback @jbrockmendel recreated pickle file for 0.20.3 using python 3.5.2 on mac. created msgpack file anew (previously 0.19 was last version tested) lots of follow ups can be done here including: automatically generating one of these files as part of build process decoupling script from test requirements (fixturization and break off) can also add more platforms / versions here as required but this should be a good starting point </desc> <cmt> bumped version requirements </cmt> <cmt> removed old pickle legacy files </cmt> <cmt> removed legacy msgpack files </cmt> <cmt> fixed generation script for v0.20 msgpack </cmt> <cmt> updated pickle and msgpack files </cmt> <cmt> removed panel kludge from tests </cmt>,removed panel kludge from pickle/msgpack tests
3779,<desc> includes various other updates and patches for compatibility. tested on ubuntu 16.04. compiles on darwin but handbrakecli and hb.dll do not fully work as expected. build mingw-w64 using mingw-w64-build: cd handbrake/scripts ./mingw-w64-build i686 [install-dir] ./mingw-w64-build x86_64 [install-dir] # update path default install-dir if not specified is ~/toolchains/mingw-w64-<version>. instructions for updating path are printed by mingw-w64-build. be sure to open a new shell after updating .bashrc or .bash_profile. configure handbrake with --cross=i686-w64-mingw32 for a 32-bit build or --cross=x86_64-w64-mingw32 for a 64-bit build. </desc> <cmt> contrib: update to libiconv 1.14. </cmt> <cmt> contrib: explicitly use gnu89 with libiconv. </cmt> <cmt> contrib: add patch for building fontconfig with mingw i686. </cmt> <cmt> contrib: add patch for building harfbuzz with mingw i686. </cmt> <cmt> libhb: improve pthreads-win32 compatibility when ptw32_static_build isn't defined. </cmt> <cmt> as may be the case with newer mingw with pthreads precompiled. </cmt> <cmt> contrib: update to pthreads-win32 2.9.1. </cmt>,update to mingw-w64 5.0-rc2 and pthreads-win32 2.9.1.
3780,<desc> changes suggested by eugen in the final review. </desc> <cmt> string to char and vice versa initial article code </cmt> <cmt> updating personal fork </cmt> <cmt> junit test case for string conversion. deleting normal class. </cmt> <cmt> changes based on review. </cmt> <cmt> updating fork </cmt> <cmt> updating fork </cmt> <cmt> bael-591 : new java9 collectors code snippet </cmt> <cmt> updating fork </cmt> <cmt> deleting string conversion test </cmt> <cmt> bael-591 : changing to bdd style testcase names. </cmt> <cmt> resolving conflicts </cmt> <cmt> bael-591 : changes based on final review </cmt> <cmt> updating fork </cmt>,changes in the final review.
3781,"<desc> this pull request adds a new app.isaccessibilitysupportenabled() that can be used to detect if a screen reader or other assistive technologies are enabled for the application. it also adds an app accessibility-support-changed event for when this value changes, such as turning voiceover on/off (cmd+f5) on macos. closes #5709 </desc> <cmt> add api for accessibility state and changes </cmt> <cmt> implement accessiblity change events on mac </cmt> <cmt> implement accessiblity change events on windows </cmt> <cmt> update api to isaccessibilitysupportenabled </cmt> <cmt> add spec to verify app.isaccessibilitysupportenabled return type </cmt> <cmt> document accessibility support api </cmt> <cmt> isaccessibilitysupportenabled -> isaccessibilitysupportenabled </cmt>",add api for chrome's accessibility support state
3782,"<desc> what did you implement only return access-control-allow-credentials-header when allowcredentials is explicitly set to true. otherwise the header is omitted as described in the specifications. closes #6994 how can we verify it (taken from the examples) service: aws-java-simple-http-endpoint frameworkversion: "">=1.2.0 <2.0.0"" provider: name: aws runtime: java8 package: artifact: build/distributions/aws-java-simple-http-endpoint.zip functions: currenttime: handler: com.serverless.handler events: - http: path: ping method: get cors: true service: aws-java-simple-http-endpoint frameworkversion: "">=1.2.0 <2.0.0"" provider: name: aws runtime: java8 package: artifact: build/distributions/aws-java-simple-http-endpoint.zip functions: currenttime: handler: com.serverless.handler events: - http: path: ping method: get cors: origin: '*' # <-- specify allowed origin headers: # <-- specify allowed headers - content-type - x-amz-date - authorization - x-api-key - x-amz-security-token - x-amz-user-agent allowcredentials: false todos useful scripts npm run test-ci --> run all validation checks on proposed changes npm run lint-updated --> lint all the updated files npm run lint:fix --> automatically fix lint problems (if possible) npm run prettier-check-updated --> check if updated files adhere to prettier config npm run prettify-updated --> prettify all the updated files write and run all tests write documentation enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> omit access-control-allow-credentials header when not explicitly activated </cmt> <cmt> add remark in the documentation regarding omitting access-control-allow-credentials header </cmt> <iss> cors - allowcredentials: false - does not omit response headers access-control-allow-credentials </iss>",fix/cors omit access control allow credentials on false
3783,"<desc> formating issue (examples) n/a if relevant, link to documentation update: n/a summary see #4580 the inline code snippet inside of summary didn't read as markdown, used code tag instead code block before and after the closing details tag were breaking, added line breaks to fix no other information </desc> <cmt> updated examples </cmt> <cmt> fix gfm formating issue </cmt> <cmt> fixes #4580 </cmt>",edit fix gfm rendering issues in examples
3784,"<desc> in #17121, an assertion was added to catch when we calculated a position outside a file's bounds; however the pretty diagnostic printer relies on the fact that for a trailing newline we calculate a position one after the actual bounds of the file as the position for the first (nonexistant) character on that last line. an alternative was to adjust computelinestarts to not include trailing newlines in the list of things calculated, then also adjust the baseline code to not consider trailing newlines as lines for writing errors on, then updating all the baselines; but that seemed a little less elegant than just allowing the one-character overflow; seeing as the calculated position always works as intended with substring. also modifies the test harness a little bit to allow it to baseline pretty-formatted diagnostics. they don't look terribly pretty in the baseline since they have ansi escapes, but so be it. fixes #18216 </desc> <cmt> actually support baselining pretty in the harness </cmt> <cmt> test case from 18216 </cmt>",allow trailing newline to have fake position
3785,"<desc> as described in #304, async.memoize() currently turns asynchronous functions into a synchronous functions if the result is in the cache. this causes program flow to change unexpectedly on subsequent calls. it should be possible to detect on first run whether the call is synchronous or not and use that to determine the behaviour for the cached case, but that seems like it might belong in a library not called async. based on that, i made the assumption that the function being wrapped by async.memoize() should be assumed to be asynchronous. given that assumption, this pr: adds a test for async.memoize() to ensure cached results are still asynchronous (commits 1 & 2) updates existing tests to not assume synchronous behaviour (commits 3-5) finally, updates async.memoize() to pass the tests (commit 6) see also </desc> <cmt> add invalid passing async.memoize() test </cmt> <cmt> this demonstrates the problem described in #304 </cmt> <cmt> test for correct async callback behaviour </cmt> <cmt> refactor memoize test to use async function </cmt> <cmt> makes example async function async by using async.setimmediate </cmt> <cmt> refactor unmemoize test to use async example </cmt> <cmt> uses async.setimmediate to make example async </cmt> <cmt> refactor memoize custom hash test </cmt> <cmt> removes assumption that memoized result is synchronous </cmt> <cmt> async.memoize() preserves async nature of function </cmt> <cmt> async.memoize() should assume that the given function is asynchronous, </cmt> <cmt> and should maintain that when giving cached results by using </cmt> <cmt> async.nexttick(). </cmt> <cmt> see also </cmt> <cmt> fixes #304 </cmt>",make async.memoize() preserve async nature of function
3786,"<desc> as of version 4.0.0 the arch user repository is build out of one git repository per package. the .srcinfo files need to be included in those. moreover, i added several extensions of files that are regularly downloaded by pkgbuild scripts; these shouldn't be included in git repositories of package sources. </desc> <cmt> remove .srcinfo (and old .aurinfo) from .gitignore </cmt> <cmt> as of aur 4.0.0 contributors have to maintain a git repository per project; .srcinfo files need to be included in those </cmt> <cmt> add .jar, .exe and .msi </cmt> <cmt> these files are also regularly downloaded by pkgbuild scripts and should not be included in the repository </cmt>",add several downloaded files that should not be incorporated and remove .srcinfo
3787,<desc> new features others show the information from trt inspector when finish building an engine execute with dynamic shape (the format of tensor cannot be confirmed before we bind dimensions) there is no unit test because this feature only output information. </desc> <cmt> inspect the information inside a trt engine. </cmt>,use trt inspector to show the information inside an engine to verbose log
3788,<desc> this adds the ability to build and upload a  atom-amd64.deb file to the releases page. this will enable packages to setup ci on linux where they do a dpkg -i on the file downloaded from </desc> <cmt> remove linux check </cmt> <cmt> don't read env var files on linux </cmt> <cmt> log installed node version </cmt> <cmt> add .node-version file with 0.10.21 </cmt> <cmt> add initial linux ci build script </cmt> <cmt> log debug output </cmt> <cmt> set atom_access_token </cmt> <cmt> run mkdeb task on linux ci </cmt> <cmt> upload .deb asset during publish </cmt> <cmt> don't run specs on linux ci for now </cmt> <cmt> remove duplidate tasks in ci tasks array </cmt> <cmt> extensions should be an array </cmt> <cmt> log token </cmt> <cmt> remove token logging </cmt> <cmt> only publish on linux for now </cmt> <cmt> don't include version in .deb asset name </cmt> <cmt> copy .deb file to proper upload path </cmt> <cmt> add missing task helpers require </cmt> <cmt> restore only uploading from master </cmt>,add debian asset to releases
3789,"<desc> this pr makes it possible for plugins to add base styles using a new addbase helper. those base styles are rendered at a new @tailwind base directive. this sets the stage for converting our preflight styles into a core plugin, and removing @tailwind preflight in favor of @tailwind base. </desc> <cmt> test plugins can add base styles with object syntax </cmt> <cmt> test plugins can add base styles with raw postcss nodes </cmt> <cmt> load plugin base styles at @tailwind base </cmt>",allow plugins to register base styles
3790,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: yaireo/tagify@e02b901 yaireo/tagify@9050e09 yaireo/tagify@9c45b3b v4.1.0 v4.1.1 </desc> <cmt> beforepaste hook </cmt> <cmt> a11y.focusabletags settings </cmt> <cmt> getinputvalue() </cmt> <cmt> bump minor version 4.1 </cmt>,"new settings, bump minor version 4.1"
3791,"<desc> note this pr also pins eslint-webpack-plugin version to work around a cache issue. what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) </desc> <cmt> chore: some trivial dependency updates </cmt> <cmt> fix: pin eslint-webpack-plugin version due to weird cache issues </cmt> <cmt> fix: simplify the webpack-4 alias setting </cmt> <cmt> previously we applied a workaround for webpack-dev-server, now it seems </cmt> <cmt> redundant </cmt> <cmt> fix: should resolve to the same graphql instance </cmt> <cmt> fix: set webpack 4 alias for client side hmr code </cmt>",better dev server & webpack 4 compatibility and some trivial dependency updates
3792,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see comments in source code include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. for now only the violin plot is fully implemented as a separate type. it follows  due to lack of time, the box type implements only a few missing fields (required for the violin type) and otherwise extends plotdata. this is based on  ideally, we should start using new type definitions for each trace type instead of bloating plotdata. </desc> <cmt> run prettier for plotly.js </cmt> <cmt> update list of plots types and bump plotly.js version </cmt> <cmt> start splitting plotdata </cmt> <cmt> for now only the violin plot is fully implemented as a seperate type. </cmt> <cmt> it follows </cmt> <cmt> due to lack of time, the box type implements only a few missing fields and otherwise extends plotdata. this is based on </cmt>",plotly.js update traces types list and start splitting data types
3793,"<desc> in doing so, revert travis to not using a 3.5 build because it seems to be changing enough that it's breaking our c++ glue frequently enough. </desc> <cmt> rustc: get rustc compiling with llvm 3.{3,4} again </cmt> <cmt> the travis builds have been breaking recently because llvm 3.5 upstream is </cmt> <cmt> changing. this looks like it's likely to continue, so it would be more useful </cmt> <cmt> for us if we could lock ourselves to a system llvm version that is not changing. </cmt> <cmt> this commit has the support to bring our c++ glue to llvm back in line with what </cmt> <cmt> was possible back in llvm 3.{3,4}. i don't think we're going to be able to </cmt> <cmt> reasonably protect against regressions in the future, but this kind of code is a </cmt> <cmt> good sign that we can continue to use the system llvm for simple-ish things. </cmt> <cmt> codegen for arm won't work and it won't have some of the perf improvements we </cmt> <cmt> have, but using the system llvm should work well enough for development. </cmt> <cmt> travis: use llvm 3.3 from the official repos </cmt> <cmt> we can be certain that this version of llvm will not be changing, so we don't </cmt> <cmt> have to worry about api drift over time. </cmt>",enable rust to build with llvm 3.3/3.4
3794,"<desc> was bored on the plane. fixed a few subtle potential bugs too. why is ""driverview"" discussed in ""process.py""? can this be refactored better? </desc> <cmt> mypy passes </cmt> <cmt> a few more </cmt> <cmt> a few in manager </cmt> <cmt> more types, will lint </cmt> <cmt> more </cmt> <cmt> simple types </cmt> <cmt> events type </cmt>",add more types for mypy
3795,"<desc> fix #9829; this is the pr #9870 before i merge ""master"" </desc> <cmt> only error in non-declaration file </cmt> <cmt> add tests and baselines </cmt> <cmt> addess pr: get the first non-ambient external module file </cmt> <cmt> rename test file and update baseline </cmt> <cmt> add tests and baselines </cmt> <cmt> update baselines </cmt>","do not report error using import, export, module augmentation in d.t.s"
3796,"<desc> this adds screen size support for iphone xs, iphone xs max, iphone xr, ipad 6th generation, ipadpro 12.9"" 3rd generation, ipadpro 11"". fixes github issue #14994 not tested yet - need the user to test. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [dawrinutils/ios] - added screen scales for iphonexs, iphonexsmax, iphonexr, ipad 6th generation, ipad pro 11"", ipad pro 12.9"" 3rd gen - fixes #14994 </cmt> <cmt> [ios/launchimages] - added all needed launch images for all screen sizes (generated with xcode 10 and using a launchimage imageset xcasset) - fixes #14994 </cmt>",add support for new ios devices
3797,"<desc> code review: i am interested in suggestions on how to make this code stink less, or criticism that finds problems or bugs with this code. enhancements cross validation in parallel (with several cpus) works better. the gridsearchcv stores its scores on the grid. i don't like the data structure that they are stored in. i think it is something that will need to be revisited at some point. the score stored are now scaled even in the case iid=true. alex, could you check that the code is right. you are the number one person who wants iid=true to work well. bug fixes make clone work on pipelines the clone code is fragile. i don't like it. the alternative is to add a '_clone' method to an object that would enable to override the clone behavior. i think that we need to keep this option in mind (the con is that it makes the estimator 'contract' heavier, the pro is that it makes this contract more explicit. i still think that we need the clone behavior in order to cross validate. make sure that classifiers are indeed recognized as so even when wrapped in cv or pipeline objects i am very unhappy with this code (but i would still like it merged, because it gives a temporary solution). it raises the issue of how to recognize a classifier from a regressor. finding the duck-typing signature for classifiers is partly the problem, because once we have found it, we need to find a good way to 'propagate' in the case of nested objects, as this commit shows. </desc> <cmt> enh: gridsearchcv, pipelines and cross validation </cmt> <cmt> make it possible to pipeline gridsearchcv, </cmt> <cmt> give a meaningful scaling to the scores in gridsearchcv </cmt> <cmt> store the scores in gridsearchcv </cmt> <cmt> enh: make sure that pipeline and gridsearch objects are indeed recognized </cmt> <cmt> as classifiers, if they contain a classifier. </cmt> <cmt> enh: make sure clone works on pipelines </cmt> <cmt> and use clone in cross_val_func </cmt>",work on cross val and pipelines.
3798,"<desc> i am unable to exclude my previous commits from this pull request. hence you can see multiple reverts commits on this task. following files are relevant for the merge: staticvariabledemo.java staticvariableunittest.java </desc> <cmt> hexagonal architecture in java </cmt> <cmt> a quick and practical example of hexagonal architecture in java </cmt> <cmt> fixed code formatting issues </cmt> <cmt> when are static variables initialized </cmt> <cmt> sample class and test class. </cmt> <cmt> revert ""when are static variables initialized"" </cmt> <cmt> this reverts commit c781923093ccc88bc269bea276653169065cb17b. </cmt> <cmt> revert ""revert ""when are static variables initialized"""" </cmt> <cmt> this reverts commit 2bffdf401d4e7dc2cefd7eb16357b2d51271edad. </cmt>",bael-4135 - when are static variables initialized?
3799,"<desc> a subtle bug had been introduced with the delegated shadow nodes: we piggyback on reactshadownnode.hasnewlayout to compute/cache the ""has new layout"" from the delegated shadow node, as part of processing  reactshadownnode.hasupdates. relying on method with side effect proved to be bad choice, hasnewlayout can be easily shortcut if _nodeupdated is true (hasupdates => _nodeupdated || hasnewlayout || isdirty) the fix moves the relevant code to an independent step. </desc> <cmt> cache child layout state for delegated layouts cache before recursively applying new layout updates. </cmt> <cmt> made new method internal </cmt>",bug fix for delegated shadow nodes
3800,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> added type definition for blip-sdk </cmt> <cmt> - removed non used test file reference; </cmt> <cmt> - fixed lint rule errors. </cmt>",add type definitions for blip-sdk
3801,"<desc> it allows for update of apps using a zip file. when installing apps using the zip file, either by url or the file form, if the app was already installed, an error would be thrown stating the condition and forbidding the installation. now, when sending a zip file of an app that is already installed, the user is presented with the following modal: if the app also requires permissions to be reviewed, the modal that handles permission reviews will be shown after this one is accepted. this follows the apps cli convention of updating the app instead of throwing an error stating that the app already exists. </desc> <cmt> [wip] solving update via file upload </cmt> <cmt> appinstallpage </cmt>",unable to update app manually
3802,"<desc> checklist for the pandas documentation sprint (ignore this if you are doing an unrelated pr): pr title is ""doc: update the  docstring"" the validation script passes: scripts/validate_docstrings.py <your-function-or-method> the pep8 style check passes: git diff upstream/master -u -- ""*.py"" | flake8 --diff the html version looks good: python doc/make.py --single <your-function-or-method> it has been proofread on language by another sprint participant please include the output of the validation script below between the """" ticks: ################################################################################ ##################### docstring (pandas.dataframe.combine) ##################### ################################################################################ perform series-wise combine with other dataframe using given func. combines self dataframe with other dataframe using func to merge columns. the row and column indexes of the resulting dataframe will be the union of the two. if fill_value is specified, that value will be filled prior to the call to func. if overwrite is false, columns in self that do not exist in other will be preserved. parameters ---------- other : dataframe the dataframe to merge column-wise. func : function function that takes two series as inputs and return a series or a scalar, used to merge the two dataframes column by columns. fill_value : scalar value, default none the value to fill nans with prior to passing any column to the merge func. overwrite : boolean, default true if true, columns in self that do not exist in other will be overwritten with nans. returns ------- result : dataframe examples -------- combine using a simple function that chooses the smaller column. >>> from pandas import dataframe >>> df1 = dataframe({'a': [0, 0], 'b': [4, 4]}) >>> df2 = dataframe({'a': [1, 1], 'b': [3, 3]}) >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2 >>> df1.combine(df2, take_smaller) a  b 0  0  3 1  0  3 using fill_value fills nones prior to passing the column to the merge function. >>> df1 = dataframe({'a': [0, 0], 'b': [none, 4]}) >>> df2 = dataframe({'a': [1, 1], 'b': [3, 3]}) >>> df1.combine(df2, take_smaller, fill_value=-5) a  b 0  0  -5.0 1  0  4.0 however, if the same element in both dataframes is none, that none is preserved >>> df1 = dataframe({'a': [0, 0], 'b': [none, 4]}) >>> df2 = dataframe({'a': [1, 1], 'b': [none, 3]}) >>> df1.combine(df2, take_smaller, fill_value=-5) a  b 0  0  nan 1  0  3.0 example that demonstrates the use of overwrite and behavior when the axis differ between the dataframes. >>> df1 = dataframe({'a': [0, 0], 'b': [4, 4]}) >>> df2 = dataframe({'b': [3, 3], 'c': [-10, 1],}, index=[1, 2]) >>> df1.combine(df2, take_smaller) a    b    c 0  nan  nan  nan 1  nan  3.0  -10.0 2  nan  3.0  1.0 >>> df1.combine(df2, take_smaller, overwrite=false) a    b    c 0  0.0  nan  nan 1  0.0  3.0  -10.0 2  nan  3.0  1.0 demonstrating the preference of the passed in dataframe. >>> df2 = dataframe({'b': [3, 3], 'c': [1, 1],}, index=[1, 2]) >>> df2.combine(df1, take_smaller) a    b   c 0  0.0  nan nan 1  0.0  3.0 nan 2  nan  3.0 nan >>> df2.combine(df1, take_smaller, overwrite=false) a    b   c 0  0.0  nan nan 1  0.0  3.0 1.0 2  nan  3.0 1.0 see also -------- dataframe.combine_first : combine two dataframe objects and default to non-null values in frame calling the method ################################################################################ ################################## validation ################################## ################################################################################ docstring for ""pandas.dataframe.combine"" correct. :) for dataframe.combine_first ################################################################################ ################## docstring (pandas.dataframe.combine_first) ################## ################################################################################ update null elements with value in the same location in other. combine two dataframe objects by filling null values in self dataframe with non-null values from other dataframe. the row and column indexes of the resulting dataframe will be the union of the two. parameters ---------- other : dataframe provided dataframe to use to fill null values. returns ------- combined : dataframe examples -------- df1's values prioritized, use values from df2 to fill holes: >>> from pandas import dataframe >>> df1 = dataframe({'a': [none, 0], 'b': [none, 4]}) >>> df2 = dataframe({'a': [1, 1], 'b': [3, 3]}) >>> df1.combine_first(df2) a  b 0  1.0  3.0 1  0.0  4.0 illustrate the behavior when the axis differ between the dataframes. >>> df1 = dataframe({'a': [none, 0], 'b': [4, none]}) >>> df2 = dataframe({'b': [3, 3], 'c': [1, 1],}, index=[1, 2]) >>> df1.combine_first(df2) a    b    c 0  nan  4.0  nan 1  0.0  3.0  1.0 2  nan  3.0  1.0 see also -------- dataframe.combine : perform series-wise operation on two dataframes using a given function ################################################################################ ################################## validation ################################## ################################################################################ docstring for ""pandas.dataframe.combine_first"" correct. :) </desc> <cmt> added summary to dataframe.combine. corrected the extended summary. added descriptions to parameters. added examples to demonstrate quirks in usage. </cmt> <cmt> added summary to dataframe.combine. corrected the extended summary. added descriptions to parameters. added examples to demonstrate quirks in usage. </cmt> <cmt> added short summary to  and added examples to demonstrate behavior. </cmt> <cmt> pep8 formatting for the docstrings </cmt> <cmt> updated doctests so that they all pass for dataframe.combine and dataframe.combine_first </cmt> <cmt> updated docstrings on dataframe.combine and dataframe.combine_first for proper html formatting. </cmt>",update the dataframe.combine and dataframe.combine_first docstrings
3803,"<desc> fixes #3997. the bug there are a few execution paths in query.js and not all apply ""pending param changes"" before execution. in this scenario changes have not been applied, executing the parameter's initial value instead of the pending value. the fix instead of coding applypendingchanges() into every which way, made it so execution by button and shortcut are disabled when params are dirty. disable button (also bottom one) and kb shortcut when params dirty allow execution upon applying param changes from button and kb shortcut add relevant tests what is commit a02a2dc for? since the query page already listens to ctrl+enter, i previously had to disable the params listener to prevent multiple listeners from executing. but now that param dirty state disables the query shortcut, there's no risk of that happening, so the whole mechanism can be removed. </desc> <cmt> disable execute when params dirty </cmt> <cmt> removed special apply handling for query page </cmt> <iss> `null` passed as parameter value. </iss>",disable execute when params are dirty
3804,<desc> this intends to address problems reported here: #5299 i think these code changes reduce some repeated blocks and leverage the same pattern i added here:  #5499 i noticed that the two definitions of on_poll_start had a lot of duplication and so additionally i sought to represent them as a single method that accounts for their one logical difference. </desc> <cmt> merge remote-tracking branch 'refs/remotes/celery/master' </cmt> <cmt> make astimezone call in localize more safe </cmt> <cmt> make astimezone call in localize more safe; with tests </cmt> <cmt> catch up my fork to master celery/celery </cmt> <cmt> update to latest celery master version </cmt> <cmt> refactor the safety check for fds and reuse it to add safety to on_poll_start. </cmt> <cmt> also handle the filenotfounderror the same way and make log message generic. </cmt>,additional file descriptor safety checks with refactor of my prior work (issue #5299)
3805,<desc> issue: n/a get the release/4.0 changes back into master which is now the stable branch </desc> <cmt> remove alpha from readme </cmt> <cmt> set publish branch to 4.0 </cmt> <cmt> more 3.4 references </cmt> <cmt> 4.0 release cleanup </cmt> <cmt> remove migration ref until we're ready to publish it </cmt> <cmt> v4.0.0 </cmt> <cmt> update docs to 4.0 </cmt> <cmt> forgot the link to riot </cmt> <cmt> fix problems from reverted cleanup </cmt> <cmt> (bug) fix select array values showing k (fixes #4560) </cmt> <cmt> [ember] update ember ergonomics to not require any manual setup </cmt> <cmt> 4.0.1 changelog </cmt> <cmt> [ember] update ember ergonomics to not require any manual setup </cmt> <cmt> 4.0.1 changelog </cmt> <cmt> v4.0.1 </cmt> <cmt> 4.0.2 changelog </cmt> <cmt> v4.0.2 </cmt>,get release/4.0 changes into master
3806,"<desc> description of the change this pr implements tooltip#recalculateposition which resets the tooltip's position based on its current size. it also adds a mutationobserver that watches for the tooltip to change and calls the aforementioned method on the next animation frame when it does. alternate designs resizeobserver is not available until electron 1.6 (with a flag), so a mutationobserver covers the majority of the important use cases until then. i originally implemented this so the resizing operation took place in an atom.views.polldocument call, but this made the tooltip feel very jerky, so i put it in an raf instead. happy to hear other  s. / </desc> <cmt> add tooltip#recalculateposition which resets the tooltip's position </cmt> <cmt> reposition tooltips when they mutate </cmt>",recalculate tooltip positions when their contents change
3807,"<desc> for service inventory extension, i add an extension point in service inventory entity. it is in json format, but it could only be set once right now for performance consideration. also, i provide the default database service properties initialization codes. @liuhaoyang which you may want to extend. i just put the basic fields, which i think make sense. and all contributions around inventory extension should following the consistent rules. so i also provide a document in development guide. </desc> <cmt> add properties for service inventory </cmt> <cmt> fix code bugs </cmt> <cmt> provide develop doc for inventory extension. </cmt>",support service inventory extension fields in json format
3808,"<desc> bug fixes others python/paddle/tests/test_model.py: line129: undefine variable name self, use 'cls' instead of 'self'. python/paddle/fluid/tests/unittests/xpu/test_pool2d_op_xpu.py: line 57, 59, 97, 99, 203, 211: undefine variable name adaptive_start_index, line 58, 60, 98, 100, 204, 212: undefine variable name adaptive_end_index, from test_pool2d_op import adaptive_start_index, adaptive_end_index python/paddle/fluid/optimizer.py: line 1472: undefined variable 'value', use 'num_trainers' instead of 'value'. line 1926: undefined variable 'warnings', import warnings line 5687: undefined variable 'fluid' import paddle.fluid as fluid python/paddle/optimizer/optimizer.py line 313: undefined variable 'item' use 'model_np' instead of 'item'. line 317: undefined variable 'item' use 'model_np' instead of 'item'. python/paddle/distributed/utils.py line 387: undefined variable 'distutils' from distutils.util import strtobool python/paddle/fluid/tests/unittests/test_eager_deletion_delete_vars.py line 178: undefined variable 'persistables' use 'persistables' instead of 'persitables' in line 148 python/paddle/text/datasets/wmt14.py line 194, 195: undefined variable 'six' import six python/paddle/fluid/tests/unittests/mkldnn/test_conv2d_transpose_mkldnn_op.py line 158: undefined variable 'enable_static' from paddle import enable_static python/paddle/optimizer/lr.py line 1352: undefined variable 'loss' use 'metrics' instead of 'loss' python/paddle/fluid/dataloader/collate.py line 81: undefined variable 'outputs' remove return outputs </desc> <cmt> fix undefined variables </cmt> <cmt> fix undefined variables </cmt>",fix some bugs of undefined variable
3809,<desc> libgui: handle '#' comments in inilexer they are supported by libcore's configfile but were not higlighted. libgui: use consistent naming scheme in inilexer libgui: convert inisyntaxhighlighter to east-const </desc> <cmt> libgui: handle '#' comments in inilexer </cmt> <cmt> they are supported by libcore's configfile but were not higlighted. </cmt> <cmt> libgui: use consistent naming scheme in inilexer </cmt> <cmt> libgui: convert inisyntaxhighlighter to east-const </cmt>,handle '#' comments in inilexer (and more ini syntax higlighting fixes)
3810,<desc> as title. </desc> <cmt> gemm optional bias (#2330) </cmt> <cmt> * made the 'c' input of gemm (the bias term) optional. </cmt> <cmt> if missing it defaults to 0. </cmt> <cmt> also added a test case for no bias. </cmt> <cmt> updated the gemm op to version 11. </cmt> <cmt> * fixed a typo! </cmt> <cmt> * small tweaks to the gemm docs. </cmt> <cmt> * added a shape inference test for gemm with no bias </cmt> <cmt> * tweaked coding style slightly by adding braces to single line scopes. </cmt> <cmt> fix some backend tests  (#2335) </cmt> <cmt> * fix some node tests </cmt> <cmt> * pr comments and docs </cmt> <cmt> * update changelog.md </cmt> <cmt> update gen_doc script to validate proto3 files (#2122) </cmt> <cmt> * update gen_doc script to validate proto3 files </cmt> <cmt> * update cmakelists.txt </cmt> <cmt> update pybind (#2340) </cmt> <cmt> fix node test case model for gemm scalar bias case (#2342) </cmt> <cmt> * fix some node tests </cmt> <cmt> * pr comments and docs </cmt> <cmt> * update changelog.md </cmt> <cmt> * fix gemm scalar node test </cmt> <cmt> clarify behavior in convtranspose (#2343) </cmt> <cmt> * fix the wrong behavior in convtranspose </cmt> <cmt> * address comments </cmt>,sync master and 1.6.0 release for adding fixes and improvements
3811,<desc> i've added a new handwired keyboard with blackpill f401 board my code follows the code style of this project. i have read the contributing document. the 3d printable housing is still wip </desc> <cmt> add new handwired keyboard with f401 blackpill </cmt> <cmt> re-indent </cmt> <cmt> add readme.md </cmt>,add handwired 12*5 blackpill keyboard
3812,"<desc> this pull request brings tox test running on par with travis and bin/runtests.sh. i haven't checked if 'tox -e windows' actually works under windows; i also haven't checked that updated travis.yml work (but it should). </desc> <cmt> allow passing arguments to tox </cmt> <cmt> e.g. ""tox -- scrapy.tests.test_contrib_loader"" runs test_contrib_loader for python 2.6 and 2.7 </cmt> <cmt> use tox deps instead of ""manual"" pip install; add lucid and precise environments to tox.ini </cmt> <cmt> add django to test requirements and fix test_djangoitem for modern django versions </cmt> <cmt> make tox test running more consistent with bin/runtests.sh script </cmt> <cmt> reuse runtests.sh and runtests.bat scripts in tox.ini </cmt> <cmt> allow passing arguments to runtests script via tox </cmt>",improved tox test running & fixed django tests
3813,"<desc> closes #43442 closes #43440 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry this is the revised version of #42214. in fact, in xlsxwriter, all kwargs are passed like so: excelwriter(""path_to_file.xlsx"",engine=""xlsxwriter"",engine_kwargs={""options"":{""nan_inf_to_errors"":true}}) which then becomes internally: from xlsxwriter import workbook workbook(""path_to_file.xlsx"",options={""nan_inf_to_errors"":true}) so my initial fix was wrong in that sense, because i made engine_kwargs able to be passed in like this: excelwriter(""path_to_file.xlsx"",engine=""xlsxwriter"",engine_kwargs={""nan_inf_to_errors"":true}) and the resulted internals: workbook(""pat_to_file.xlsx"",{""nan_inf_to_errors"":true}) so #42214 was actually wrong (we want users to actually pass in kwargs. however, there was still the issue of #43442, where the following engines do have some options that were silently ignored: openpyxl can set iso_dates and write_only xlwt can set style_compression (not sure why anybody would want this, but people may) xlsxwriter has many options so i added tests for that in engine_kwargs. </desc> <cmt> passes  through now for openpyxl and xlwt </cmt> <cmt> added docs </cmt> <iss> doc: no docs for excelwriter `engine_kwargs` #42292 #42214 </iss> <iss> bug: excelwriter `engine_kwargs` not passed through to other engines than xlsxwriter #42292 #42214 #43440 </iss>",pass through engine kwargs in excelwriter
3814,"<desc> this pull request contains two fixes: fix test failures on linux on arm, which is a platform where ""char"" is unsigned (""char"" is signed on x86).  this causes ishex() to erroneously return true, and debian doesn't automatically move new versions of bitcoin to its testing distribution, due to the build failures on arm. fix a bug where the statically-defined phexdigits is missing an entry, because there's a newline with no comma between ""-1"" and ""-1"". cheers, dwayne </desc> <cmt> fix phexdigits[255] is undefined. </cmt> <cmt> fix bugs on 'unsigned char' platforms. </cmt> <cmt> in iso c++, the signedness of 'char' is undefined.  on some platforms (e.g. </cmt> <cmt> arm), 'char' is an unsigned type, but some of the code relies on 'char' being </cmt> <cmt> signed (as it is on x86).  this is indicated by compiler warnings like this: </cmt> <cmt> bignum.h: in constructor 'cbignum::cbignum(char)': </cmt> <cmt> bignum.h:81:59: warning: comparison is always true due to limited range of data type [-wtype-limits] </cmt> <cmt> util.cpp: in function 'bool ishex(const string&)': </cmt> <cmt> util.cpp:427:28: warning: comparison is always false due to limited range of data type [-wtype-limits] </cmt> <cmt> in particular, ishex erroneously returned true regardless of the input </cmt> <cmt> characters, as long as the length of the string was a positive multiple of 2. </cmt> <cmt> note: for testing, it's possible using gcc to force char to be unsigned by </cmt> <cmt> adding the -funsigned-char parameter to xcxxflags. </cmt>",unsigned char fix & fix undefined phexdigits[255]
3815,"<desc> this pr adds access log flags when delays are injected as part of fault injection. please note that certain unrelated changes in the pr are merely clang-formatting (from emacs), and it seems to be following the formatting guidelines set forth in the code. </desc> <cmt> add delayinjection flag </cmt> <cmt> log di in access logs and make requests with di traceable </cmt> <cmt> tests for di flag </cmt> <cmt> docs for di flags </cmt>",access log flags for delay injection
3816,"<desc> continuing from pr #4616 to fix #4561, i've added a direct file check to see if a spider with the name provided in scrapy genspider is already present in the directory and not overwrite the existing spider file if present. </desc> <cmt> update genspider.py </cmt> <cmt> issue #4561 enhancement. the bug occurs when genspider is called outside of a startproject. i added a small and simple check to compare the new spider names to the current files in the directory. if there is already a spider with the file name it will return and stop the function. </cmt> <cmt> check if spider already exists </cmt> <iss> `scrapy genspider` should not overwrite existing file </iss>",check if file is already present on running scrapy genspider and terminate if so (#4561)
3817,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this behavior was deprecated for all other index subclasses a few years ago and finally removed in 1.0.  afaict not removing it for categoricalindex was an oversight. xref 8ab6185#r44233424 </desc> <cmt> bug: raise on missing for listlike indexing with categoricalindex </cmt> <cmt> whatsnew </cmt>",obj.loc[listlike] with missing keys and categoricalindex
3818,<desc> opengl for windows is not maintained for years. we need to drop it. do we have any opengl win32-only files to remove? </desc> <cmt> [win32] remove opengl files and configurations from projects vc projects and solution </cmt> <cmt> [win32] remove opengl from buildsetup.bat </cmt>,drop opengl support for win32
3819,<desc> react-native win32 may use non-integer color types. bring in the microsoft/react-native version of animatedinterpolation that knows how to deal with this. upstreaming is tracked by #3984 microsoft reviewers: open in codeflow </desc> <cmt> add win32 override of animatedinterpolation </cmt> <cmt> react-native win32 may use non-integer color types. bring in the </cmt> <cmt> microsoft/react-native version of animatedinterpolation that knows how </cmt> <cmt> to deal with this. upstreaming is tracked by #3984 </cmt> <cmt> change files </cmt>,add overrides for animatedinterpolation and nativeordynamiccolor
3820,<desc> the squared_hinge loss of sgdclassifier (and potentially the squared loss of sgdregressor) tend to trigger numerical overflows even on normalized data for some hyper parameter combinations. this pr fixes that issue by clipping dloss to 1e12. all existing still tests pass. i have also had to prevent strong l2 regularization with large learning rates to trigger negative scales (which are meaningless and can also cause numerical divergence if lower than -1). instead i set the weights to zero in that case. a new non regression tests highlights this case as well. both non regression tests were inspired by #3040. they both fail at epoch #2 and #3 of the iris data with the sgd_fast.pyx implementation from master. </desc> <cmt> fix clip sgd gradient on linear models for stability </cmt> <cmt> the l2 weight decay rescaling is also kept positive (or null) </cmt> <cmt> in case of strong regularization. </cmt> <cmt> tst update numerical overflow (non-regression) tests </cmt>,improve stability of sgdclassifier / sgdregressor with gradient clipping
3821,"<desc> allows a user to add a reconfigure method to their backend class, and then update (all current and future replicas of) their backend by setting the user_config field in the backendconfig, which gets passed to their reconfigure method.  the following example from the doc should make the usage clear: class threshold: def __init__(self): # self.model won't be changed by reconfigure. self.model = random.random()  # imagine this is some heavyweight model. def reconfigure(self, config): # this will be called when the class is created and when # the user_config field of backendconfig is updated. self.threshold = config[""threshold""] def __call__(self, request): return self.model.random() > self.threshold backend_config = backendconfig(user_config={""threshold"": 0.01}) client.create_backend(""threshold"", threshold, config=backend_config) client.create_endpoint(""threshold"", backend=""threshold"", route=""/threshold"") print(requests.get("" backend_config = backendconfig(user_config={""threshold"": 0.99}) client.update_backend_config(""threshold"", backend_config) print(requests.get("" i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add user reconfigure handler </cmt> <cmt> add test </cmt> <cmt> fix function calls so that test passes </cmt>",reconfigure backend class at runtime
3822,"<desc> this pr fixes remark lint warnings for all readme files in the backend directory. related: #5941 component name docs the entire doc was built and tested to see the html output of the changed files, they rendered fine. </desc> <cmt> fix remark warnings for aws kinesis doc </cmt> <cmt> fix remark warnings for mongodb </cmt> <cmt> fix remark warnings on opentsdb doc </cmt> <cmt> fix lint warnings on prometheus docs </cmt> <cmt> format prometheus page </cmt> <cmt> fix main backend readme </cmt> <cmt> fix remark warnings except local links </cmt>",fix remark lint warnings for backends
3823,"<desc> this adds a new api, grpc_recycle_unused_port(), which tests can use to return ports to the portserver. this pr also converts two of the tests which call grpc_pick_unused_port_or_die() a lot to use this api. the portserver we back this api with at google limits the number of ports it will hand out, and the c++ async_end2end_test (which has extra parameterized test cases because we have more credentials types) is now over that limit. </desc> <cmt> add an api to return an unused port to the portserver </cmt> <cmt> fix declarations in port.h to not be ambiguous in c due to k&r. </cmt> <cmt> also actually add the port parameter to grpc_recycle_unused_port. </cmt> <cmt> also remove the downsizing gpr_realloc in the recycle codepath, which is </cmt> <cmt> unnecessary and can free the pointer. </cmt> <cmt> add calls to grpc_recycle_unused_port to two of the tests which call </cmt> <cmt> grpc_pick_unused_port a lot. </cmt>",add a grpc_recycle_unused_port to return pick_unused_port ports to the portserver
3824,"<desc> what do these changes do? added reproducible_seed for trainer config. use this value to seed workers (i.e., actors) in conjunction with worker_index, so that exploration behaviors can be repeated/reproduced. #5194 linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> enable graph-level worker-specific seed </cmt> <cmt> lint checked </cmt>",enable seeding actors for reproducible experiments
3825,"<desc> separated into two commits for simplicity. no behavioral change in either commit, but the first is really just source layout, whereas the second changes naming and documentation. </desc> <cmt> line-wrapping changes only for c# generator code </cmt> <cmt> this should have no behavioral changes at all. </cmt> <cmt> this doesn't strictly enforce an 80-column limit, but removes the most egregious violations. </cmt> <cmt> the indentation in the c# generator code is inconsistent in general, unfortunately - if we have </cmt> <cmt> any good tools that can be trusted to reformat, i'd be happy to apply them. </cmt> <cmt> add more documentation for csharp_options.h </cmt> <cmt> this also renames generate_directories to base_namespace_specified; generating directories is the </cmt> <cmt> immediate *effect* of specifying a base namespace, but with this change the options reflect what has been </cmt> <cmt> specified rather than the effect. (there may be other effects in the future, of course.) </cmt>",tidy up for c# codegen
3826,"<desc> closes #37550 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this fixes the bug, but i am not sure, if the solution is good enough.... </desc> <cmt> fix bug in setitem when indexer was only false changed dtype </cmt> <cmt>  conflicts: </cmt> <cmt> 	pandas/tests/frame/indexing/test_setitem.py </cmt> <iss> bug: loc changes dtype when condition is completly false </iss>",fix bug in loc setitem changing the dtype when condition is false
3827,"<desc> saw it when running tests on linux: objects involved in the operation: sequence ""this"" @ 0x0x7ffce7459758 { } received signal 6 #0 0x7f7cd6955afb base::debug::stacktrace::stacktrace() #1 0x7f7cd695106c base::debug::stacktrace::stacktrace() #2 0x7f7cd695560f <unknown> #3 0x7f7cbfe8bcb0 <unknown> #4 0x7f7cb992a035 gsignal #5 0x7f7cb992d79b abort #6 0x7f7cba2265ad __gnu_debug::_error_formatter::_m_error() #7 0x000000fc6195 std::__debug::vector<>::front() #8 0x000000fc22e8 atom::api::nativeimage::tojpeg() #9 0x000000fcba34 _zn4base8internal13functortraitsimn4atom3api11nativeimageefn2v85localins5_5valueeeepns5_7isolateeieve6invokeips4_jsa_ieees8_sc_ot_dpot0_ #10 0x000000fcb95b _zn4base8internal12invokehelperilb0en2v85localins2_5valueeeee8makeitsoirkmn4atom3api11nativeimageefs5_pns2_7isolateeiejpsa_sc_ieees5_ot_dpot0_ #11 0x000000fcb8d0 _zn4base8internal7invokerins0_9bindstateimn4atom3api11nativeimageefn2v85localins6_5valueeeepns6_7isolateeiejeeefs9_ps5_sb_iee7runimplirksd_rkst5tupleijeejeees9_ot_ot0_ns_13indexsequenceijxspt1_eeeeosf_osb_oi #12 0x000000fcb7d3 _zn4base8internal7invokerins0_9bindstateimn4atom3api11nativeimageefn2v85localins6_5valueeeepns6_7isolateeiejeeefs9_ps5_sb_iee3runepns0_13bindstatebaseeosf_osb_oi #13 0x000000fcb68f base::internal::runmixin<>::run() #14 0x000000fcb4b4 _zn4mate8internal7invokerins0_13indicesholderijlm0elm1elm2eeeejpn4atom3api11nativeimageepn2v87isolateeiee18dispatchtocallbackins8_5localins8_5valueeeeeevn4base8callbackift_s7_sa_ielnsg_8internal8copymodee1elnsk_10repeatmodee1eee #15 0x000000fcb298 mate::internal::dispatcher<>::dispatchtocallback() #16 0x7f7ce4cddf6b <unknown> #17 0x7f7ce4d9e7ff <unknown> #18 0x7f7ce4d9d59c <unknown> #19 0x35634c684204 <unknown> r8: 00007f7ce6f44980  r9: 00007ffce7459258 r10: 0000000000000008 r11: 0000000000000202 r12: 00007ffce74594e0 r13: 0000000000000000 r14: 0000000000000001 r15: 0000000000000000 di: 0000000000005607  si: 0000000000005607  bp: 0000000000000001  bx: 00007ffce74594a8 dx: 0000000000000006  ax: 0000000000000000  cx: ffffffffffffffff  sp: 00007ffce74592a8 ip: 00007f7cb992a035 efl: 0000000000000202 cgf: 0000000000000033 erf: 0000000000000007 trp: 000000000000000e msk: 0000000000000000 cr2: 00007f12f232a700 </desc> <cmt> remove unneeded heap allocation </cmt> <cmt> fix crash when converting invalid image to jpeg </cmt>",fix crashes due to using debug version of libc++
3828,"<desc> this pulls in the fix for rust-random/rand#779, which trips miri when running these test suites. smallrng (formerly used by libcore) is no longer built by default, it needs a feature gate. i opted to switch to stdrng instead. or should i enable the feature gate? </desc> <cmt> bump rand to fix miri failures </cmt> <cmt> bump libcore tests to rand 0.7 </cmt>",bump rand in libcore/liballoc test suites
3829,"<desc> fixes rdar://problem/31000248. </desc> <cmt> sema: fix convenience init delegation to a convenience init in a generic base class </cmt> <cmt> while in the constraint system, the delegation is modeled as </cmt> <cmt> returning an instance of the derived class, in the ast we type </cmt> <cmt> the reference as returning an instance of the base class, and </cmt> <cmt> insert a downcast, because in silgen we're calling the base </cmt> <cmt> class initializer which is typed as returning the base class. </cmt> <cmt> this bit of fixup logic wasn't happening if the base class was </cmt> <cmt> generic, and so we were not inserting the cast, which would </cmt> <cmt> crash in silgen with an assert. </cmt> <cmt> fixes <rdar://problem/31000248>. </cmt> <cmt> ast: fix a comment typo </cmt>",fix generic super convenience init delegation
3830,"<desc> this implementation enable to speed up get_schema operation in bigquery environments which have massively tables (about over 1k tables). in the environment which has about 1k tables , it takes about 10 minutes by current implementation. very slow operation caused the operation timeout at default timeout settings. the cause of the slow operation is calling get table's column list api per table in current implementation. new implementation improve operation time to 10 seconds in same environment by improving to call one api to get all table's column list. bigquery  information schema reference new implementation uses every dataset's information_schema. columns view to get table's column list in dataset. </desc> <cmt> speed up bq get schema </cmt> <cmt> change get schema query to use union all </cmt>",speed up bigquery get schema operation in massively tables environment
3831,<desc> the flyout component is allowed to go bigger than the default largest size in xaml.  it accomplishes this by using a hard-coded maxwidth/maxheight of 5000x5000.  this is causing confusion for xaml's placement logic. the fix is straightforward - push the width/height into the shadow node after layout and use this width/height instead of 5000x5000. microsoft reviewers: open in codeflow </desc> <cmt> fix </cmt> <cmt> change files </cmt>,fix flyout full placement mode
3832,"<desc> tom, here's my attempt at writing an auth-token/login and auth-token/logout views to support scripted logins using tokenauthentication, as you suggested in the forum. the approach i took was to treat the 'login' one as a rest endpoint in itself, accepting post with a createapiview class view and a serializer for validating the input. the logout view is simpler, just a post to a url that deletes the token associated with the authenticated request (otherwise does nothing). i wrote unittests for both logout/login. i had started off with a regular django login() view that created the token using request.post['username'] and request.post['password'] from a form, but i figured why not use the framework itself and support json and form posts, etc.?  however, the logout view is not rest_framework based. is this strange? i'm new to rest_framework, so regardless of this pull request, i'd be interested to know if the view & serializer i wrote is good or could be simplified more.  is it right to re-use the serializer to convert from 'username' + 'password' inputs into a json { 'token' : , 'user' :  } representation?  should we just do regular django login/logout views instead? this is my first pull request ever. appreciate any feedback or comments on what i'm doing right or wrong. sorry the change was accidentally split into 2 commits. </desc> <cmt> added authtoken login/logout urlpatterns and views to support scripted logins and logouts using tokenauthentication. added unittests. </cmt> <cmt> added authtoken login/logout urlpatterns and views </cmt>",added login view for users of tokenauthentication
3833,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr makes the following changes: adds tests for pick and omit. combines pick and omit array and iterator overloads. updates the behavior of the overload that takes a function iterator to yield a partial instead of its current behavior of picking all properties. allows string arrays with unknown string contents to be specified and to yield a partial. updates omit to have similar behavior to pick except that an any object input will always yield an any object output due to issues with _omit<any, string> (including string constants) resulting in pick<any, number | symbol>. i put this together because i was running into a few errors around pick calls with updated type definitions and thought that this would fix them, but as it turns out i didn't look at them closely enough and they're actually just legitimate errors. nevertheless, this seemed like a useful bit of work to submit. update: there were errors around using non-constant string arrays that this fixed, the way that some others moved around and muddied the count just threw me off here. </desc> <cmt> updating type definitions for pick and omit and adding tests. </cmt> <cmt> fixing a few parameter names and summary comments. </cmt> <cmt> updating _pick to not translate any to any since _pick<any, k> is useful and doesn't present the same issues as _omit<any, k>. </cmt> <cmt> removing the object constraint on v for pick and omit since it seems to work with strings as well. </cmt>",object tests - pick and omit
3834,<desc> this patch series modifies some logging statements to add more useful information to the log file. a memory leak is also fixed. </desc> <cmt> change logging statements for pulseaudio plugin </cmt> <cmt> this removes some useless and annoying logging and on the other </cmt> <cmt> hand bumps the prio on more important ones. </cmt> <cmt> fix a memory leak in pulseaudio plugin </cmt> <cmt> add some statistics to pulseaudio plugin </cmt> <cmt> this patch adds counters for packets and frames for debugging purposes. </cmt>,improve logging for pulseaudio plugin
3835,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): implement support for insert-query with kafka tables </desc> <cmt> first attempt to fix build with external libcxx </cmt> <cmt> [wip] </cmt> <cmt> add write-callback on each row for rowoutputstream </cmt> <cmt> [wip] </cmt>,implement support for insertion into kafka tables
3836,"<desc> in order to keep such tests refactor pr more readable, in this pr, i only move those methods which are actually staticmethods out of huge consistency classes to be independent tests, so no code changes! and after this pr, the big consistency classes are broken down to much smaller. this one will pave the way for replacing some other final fixtures & staticmethods out of classes </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 17038 </cmt> <cmt> revert change </cmt> <cmt> revert change </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> move potential staticmethods out of class </cmt>",move static methods out of consistency classes
3837,"<desc> module_utils/lxd.py affected lxd_container module ansible version ansible 2.2.0 when the client certificate is already stored, lxd returns a json error with message ""certificate already in trust store"".  this ""error"" will occur on every task run after the initial run.  the cert should be in the trust store after the first run and this error message should really only be viewed as informational as it does not indicate a real problem.  i certainly don't think an exception should be being thrown?! fixes: ansible/ansible-modules-extras#2750 </desc> <cmt> same change from earlier pull request #17571 which was approved.  commit history got all screwed up so i branched it this time.  resubmitting a new pull request now... </cmt>",resubmitting approved pull request #17571
3838,"<desc> the first two commits are merely cleanup but the third commit fixes the fact that starting a slideshow through builtins current behaves differently than when starting it from the pictures view in the gui because the latter also considers files with video extensions (if enabled in the settings). this moves the general code to start a slideshow without specifying any file extensions in line with that behaviour. </desc> <cmt> cguiviewstatewindowpictures: make getlocktype(), getextensions() and getsources() public like in cguiviewstate </cmt> <cmt> cguiviewstatewindowpictures: cleanup getextensions() </cmt> <cmt> cguiwindowslideshow: use cguiviewstatewindowpictures::getextensions() as a fallback if no file extensions were specified in runslideshow() </cmt>",fix not considering videos when started through builtin
3839,"<desc> the passwordcache logic caches pkcs#11/fido2 passwords that we managed to acquire from their tokens. let's clean things up a bit. </desc> <cmt> homework: make passwordcache const wherever we can </cmt> <cmt> homework: mae sure passwordcache is really optional </cmt> <cmt> it was supposed to be optional (i.e. there's a reason why we never </cmt> <cmt> assert()ed on it), and in many codepaths it is, let's make sure it is </cmt> <cmt> everywhere. </cmt>",minor tweaks to the passwordcache logic
3840,<desc> fix #7959 op's info is not well synchronized on the python side. so i have to use the opdesc info.  input_arg_names() is defined in protobuf.cc as a binding to inputarguments() method in the c++ opdesc class. </desc> <cmt> initial commit </cmt> <cmt> add get_parameters method </cmt> <cmt> add get_parameters method </cmt> <cmt> small fix </cmt> <iss> modify save/load api for the new combined load save operators </iss>,revise python save load api using new load/save op
3841,"<desc> xref #30114 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this is the first step for closing the pr #30114, i will come up with another pr for drop_duplicates </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add ignore index for sort values </cmt>",add ignore_index for df.sort_values and series.sort_values
3842,"<desc> two minor logging fixups </desc> <cmt> log: clarify that failure to write fee_estimates.dat is non-fatal </cmt> <cmt> log: clarify that failure to read fee_estimates.dat is non-fatal </cmt> <cmt> an uppercase ""error"" in the log might indicate a fatal error. though, </cmt> <cmt> all read-failures for fee_estimates.dat are non-fatal, so avoid the </cmt> <cmt> ""error"". </cmt> <cmt> before: </cmt> <cmt> error: cblockpolicyestimator::read(): up-version (149900) fee estimate file </cmt> <cmt> after: </cmt> <cmt> cblockpolicyestimator::read(): unable to read policy estimator data (non-fatal): up-version (149900) fee estimate file </cmt>",clarify that failure to read/write fee_estimates.dat is non-fatal
3843,"<desc> these iterators seem to have been forgotten to be re-exported from std (through alloc) these are stable: core::slice::{splitinclusive, splitinclusivemut} this one is still unstable: core::slice::escapeascii (cc #77174) </desc> <cmt> re-export core::slice::splitinclusive[mut] </cmt> <cmt> re-export core::slice::escapeascii </cmt>",re-export some iterators from core in std
3844,"<desc> i hereby agree to the terms of the cla available at:  converts string-type arguments of function ""if"" and ""transform"" into enum if set optimize_if_transform_strings_to_enum = 1. continuation of #11737 </desc> <cmt> new optimization added </cmt> <cmt> space fixed </cmt> <cmt> codestyle fixed </cmt> <cmt> bug fixed, added check for functions with ""if""-function arguments </cmt> <cmt> transform added </cmt> <cmt> bug fix </cmt> <cmt> bugfix </cmt> <cmt> stderr fixed, tests added </cmt> <cmt> rename setting </cmt> <cmt> rewrite </cmt>",string convertion to enum in if() and transform()
3845,"<desc> stefan krah requested the reversal of these (unreleased) changes, quoting him: the capsule api does not meet my testing standards, since i've focused on the upstream mpdecimal in the last couple of months. additionally, i'd like to refine the api, perhaps together with the arrow community.  automerge-triggered-by: gh:pitrou </desc> <cmt> revert ""bpo-41324 add a minimal decimal capsule api (#21519)"" </cmt> <cmt> add news item </cmt>",revert _decimal c api addition
3846,"<desc> adds the name of the violating plugin to error messages when validating plugin specifications in flutter packages get, etc so it's easier to track down which is the violating plugin. console output from flutter packages get before: invalid plugin specification. after: invalid plugin specification test_plugin_name. i added the following tests: legacy format and multi-platform format together is not allowed and error message contains plugin name in plugin_parsing_test.dart i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> add plugin name to invalid plugin error messages </cmt> <cmt> add test for multi-platform + legacy plugin format error </cmt> <cmt> update authors </cmt>",add violating plugin name to validation errors
3847,"<desc> in this pr: enet now sends fragmented packets unreliably too. enet poll now only service the connection once. 2 out of the 3 changes in #51466 (+ debug warning when sending unreliable fragmented packets). the other change (sendmsg/wsasendto) needs more testing because according to ms docs wsabuf is not available in uwp apps (though wsasendto is?) bugsquad edit: 3.x version of #53129. </desc> <cmt> [net] enet now sends fragmented packets unreliably too. </cmt> <cmt> it used to always send them reliably when transfer mode was unreliable </cmt> <cmt> or ordered if the packet size was more then the enet host mtu (1400 </cmt> <cmt> bytes by default). </cmt> <cmt> this commit also adds a warning when debug is enabled to explain the </cmt> <cmt> effects of sending fragmented packets unreliably. </cmt> <cmt> [net] enet poll now only service the connection once. </cmt> <cmt> it used to call enet_host_service until all events were consumed, but </cmt> <cmt> that also meant constantly polling the connection leading to potentially </cmt> <cmt> unbounded processing time. </cmt> <cmt> it now only service the connection once, and instead consumes all the </cmt> <cmt> retrieved events via enet_host_check_events. </cmt>","enet poll optimizations, fragmented unreliable transfer."
3848,"<desc> this removes references to the pdfviewerui class that was removed a while ago. chromium now uses an extension to show pdfs, and if/when we eventually re-enable pdf support, we'll do it through //extensions. this also lays some preliminary groundwork for allowing the application/x-google-chrome-pdf plugin to be loaded by the extension in future. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> wip: pdf plugin support </cmt> <cmt> disable some junk? probably should be deleted </cmt> <cmt> use our own pepperhelper and black-hole uma </cmt> <cmt> remove references to nonexistent pdf webui </cmt> <cmt> fix patches </cmt>",remove references to non-existent webui
3849,<desc> this patch adds additional addr-fetch peer connection state and timeout coverage as a follow-up to #22096. </desc> <cmt> test: add assert_getpeerinfo method and coverage in p2p_addrfetch.py </cmt> <cmt> test: add addr-fetch timeout connection coverage in p2p_addrfetch.py </cmt>,add addr-fetch peer connection state and timeout coverage
3850,<desc> see #13375 for the first part the slack discussion went on and i added some more information that might be helpful for others as well. i also fixed a formatting bug that i introduced in the first part. </desc> <cmt> improves documentation regarding providers and custom connections </cmt> <cmt> additional documentation on provider packages </cmt> <cmt> additional documentation on provider packages </cmt>,improves documentation regarding providers and custom connections 2
3851,<desc> was looking into adding gradient tests for tf.clip_by_value (#13998 (comment)) and then noticed that there is no gradient tests in math_grad_test.py for tf.maximum and tf.minimum. think it makes sense to add a gradient test to cover tf.maximum and tf.minimum </desc> <cmt> add gradient tests for tf.maximum </cmt> <cmt> was looking into adding gradient tests for tf.clip_by_value </cmt> <cmt> ( </cmt> <cmt> and then noticed that there is no gradient tests in math_grad_test.py </cmt> <cmt> for tf.maximum. i think it makes sense to add a gradient test to cover </cmt> <cmt> tf.maximum. </cmt> <cmt> also add a gradient test for tf.minimum </cmt>,add gradient tests for tf.maximum and tf.minimum
3852,"<desc> this pr changes try_import_tf to return the tuple: tf(v1 compat), tf (1x or 2x), [version int 1 or 2]. this is in preparation of the upcoming full tf2.x support pr. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> fixes. </cmt> <cmt> lint. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt>",tf2x preparation; part 2 (upgrading try_import_tf()).
3853,"<desc> original pull-request #29762 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update minio </cmt> <cmt> update docker_compose_minio.yml </cmt> <cmt> ping tests </cmt> <cmt> may be fix s3 tests </cmt>",cherry pick #29762 to 21.9: may be fix s3 tests
3854,<desc> this change adds a new setting for controlling the developer menu.  tracked by #2987 the change is straightforward - adds a new bool enabledevelopermenu property on reactinstancesettings.  changed cli and other apps to set the flag.  turns the flag on for debug builds. microsoft reviewers: open in codeflow </desc> <cmt> merge </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> beginnings of adding enabledevelopermenu api </cmt>,add api to control developer menu
3855,"<desc> closes #16350 adding an alert that explains 'if you let the description field blank, the role will not be shown </desc> <cmt> addind text to the role description field </cmt> <cmt> adjustments in the alert </cmt> <iss> recent role tags are missing </iss>",role tags missing - description field explanation
3856,"<desc> description: this continues #20457, and reimplements the remaining tests that i first submitted via #20345. i will be rebasing that pr on top of these tests when they are merged. this adds tests for the remaining device types: lock, alarm_control_panel and cover (garage door and window). it also increase the test coverage of light by testing a fake with color_temp support. i added a test helper for creating homekit models to feed into the fakes. this is because upstream doesn't have models for these device types. i've taken care to avoid directly importing homekit, this has made the implementation weird (subclasses inside a function) - but it seems to work. i've also had to add a helper to work out the entity id. some of these implementations set the name to none and then set the name again from the device characteristics on first poll. this means i can't guess their entity ids and hardcode them in the tests. this new set of tests has uncovered 2 bugs: part of the window covering support (for horizontal tilt) was non functional due to a vertical vs horizontal typo color temp support in light was also broken with a typo both of these are fixed in this branch. all the currently supported entities are now at 96% or higher coverage. the __init__.py file is still only at related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> homekit_controller tests: automatically find entity ids in tests </cmt> <cmt> some entities use dynamic ids because of the nature of the test fakes it is </cmt> <cmt> hard to predict the name of the entity that will be created. this inspects the </cmt> <cmt> entitycomponent of the domain to find the freshly created entity. </cmt> <cmt> homekit_controller: tests can now define their own service models. </cmt> <cmt> all existing tests use models as defined upstream. but upstream only defines a </cmt> <cmt> few service models. this adds a generic model helper for creating test </cmt> <cmt> service/characteristic models. </cmt> <cmt> homekit_controller: add cover tests </cmt> <cmt> homekit_controller: add lock tests </cmt> <cmt> homekit_controller: add alarm_control_panel tests </cmt> <cmt> homekit_controller: update light tests for color_temp. </cmt>",add more homekit controller tests
3857,"<desc> first step in making the components of serve resilient to failure. the http proxy is now a reconstructable actor and fetches its configuration from the master actor on initialization. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> move _scale() to master actor </cmt> <cmt> move create_backend </cmt> <cmt> move set_backend_config </cmt> <cmt> move get_backend_config </cmt> <cmt> remove backend_table from global_state </cmt> <cmt> remove global_state, just access master directly </cmt> <cmt> call serve.init() in backends </cmt> <cmt> fault tolerance for http proxy </cmt> <cmt> don't use bare except </cmt>",make http proxy fault tolerant
3858,<desc> backport fixes from #11501 and #11515 into 1.3.x and bump to 1.3.9. </desc> <cmt> upgrade protobuf.js 6 code to work with 6.8 </cmt> <cmt> fix missing return after callback in a function </cmt> <cmt> add another missing return after a callback </cmt> <cmt> bump version to 1.3.9 </cmt>,backport a couple of node bugfixes into 1.3.x and bump patch version
3859,"<desc> this pr fixes #6346 by implementing two changes: the type of a variable declared in a for-in statement is implicitly string (previously it was any). when an object with a numeric index signature of type t (such as an array) is indexed by a for-in variable of a containing for-in statement for an object with a numeric index signature and without a string index signature (again such as an array), the value produced is of type t. an example: var a: myobject[]; for (var x in a) {   // type of x is implicitly string var obj = a[x];  // type of obj is myobject } with this pr, the type of x is now string and the type of obj is myobject because the array is indexed with a for-in variable for an array (and thus the for-in variable is known to contain a numeric string). had the array been indexed with any other string expression, the type of obj would be any because the string could be the name of a property or method (e.g. ""length"" or ""push""). for historical reasons we have used type any for for-in variables even though the iterated values are always strings. the reason we used type any is that when an array is indexed with an expression of type any or number we produce a value of the array element type, and thus the example above produces the correct type for obj. however, with the second new rule above, indexing with an expression of type string can now also produce a value of the array element type if the expression is a for-in variable for an array. the use of type any was never a great solution, in particular because the any is ""silent"" and not caught by the -noimplicitany flag. furthermore, with the introduction of the new for-of statement in es2015 it got worse. consider: var a: myobject[]; for (var x in a) {       // accidentally used for-in instead of for-of x.myobjectmethod();  // reports an error now, but didn't before } this pr is a breaking change for certain (suspicious) constructs. for example: var a: myobject[]; for (var x in a) { if (x == 1) {  // previously ok, now an error // ... } } previously, the static type of x was of type any. thus, even though x contains a string it could be compared to a numeric literal (at run-time this coerces the string operand to a number and then compares that to the numeric operand). this is one of the not so good parts of javascript. mixing of strings and numbers only work for some operators and are a source of many a surprising bug (for example, it doesn't work with the === operator, and + concatenates string values instead of adding the numeric values). </desc> <cmt> change for-in iteration variable type from any to string </cmt> <cmt> updating existing tests </cmt> <cmt> adding new tests </cmt> <cmt> accepting new baselines </cmt> <iss> solve the for-in / indexer mess </iss>",improved checking of for-in statements
3860,"<desc> matrix keymap renamed to layout added layout_ansi and layout_iso matrices keymaps refactored for white space and #include qmk_keyboard_h added info.json readme formatting the uk78.h file has some comments inside about the matrix positions, based on information i found on geekhack and a conversation i had with @rozakiin over reddit pms. further updates and suggestions are welcome, either on this pr or a subsequent one. </desc> <cmt> matrix update </cmt> <cmt> keymap refactor </cmt> <cmt> configurator support </cmt> <cmt> readme cleanup </cmt>",uk78 refactor and configurator support
3861,"<desc> i should have split this up into multiple commits, but.. -- added 'travis.yml' which can be used to integrate travis (done for my fork) -- removed failing test file completely as you suggested -- added a single unit test covering the softmax function (to show the approach) </desc> <cmt> added travis file </cmt> <cmt> try anaconda with travis </cmt> <cmt> updated script name </cmt> <cmt> rename lossweights test </cmt> <cmt> rename test folder </cmt> <cmt> update gitignore </cmt> <cmt> revert loss weighting </cmt> <cmt> decrease memory usage of lstm text gen example </cmt> <cmt> both the training features and labels can be represented as numpy </cmt> <cmt> booleans instead of float32 / float64. this enables standard low ram </cmt> <cmt> machines to scale up to large datasets. especially important if you </cmt> <cmt> either have many characters (ascii), long sequences, or a large dataset. </cmt> <cmt> deleted superfluous test file </cmt> <cmt> added basic softmax activation test </cmt>","added unit test, travis file"
3862,<desc> the page about communication with the ansible community should include details about contributing to and subscribing to the bullhorn. related to the open issue #71924 documentation report docs.ansible.com developers community ansible version 2.10 configuration n/a os / environment n/a </desc> <cmt> added html preview file to gitignore </cmt> <cmt> added bullhorn details to communication.rst </cmt> <cmt> update .gitignore </cmt>,add the bullhorn to the community communication page
3863,"<desc> the text box now has the auto-complete feature. pr checklist cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments the auto-completion text is set as soon as the selection is set to the first item. the auto-completion is removed as soon as there is no more text in the search box. however, as there is a slight delay in the dropdown being produced and the first item to show up, the auto-complete text stays a bit longer when changing from one to another. the following gif explains this scenario. however, that is the earliest point in which we get the event that the list has been modified. we are artificially inducing a 200 ms delay in populating executing and obtaining the results. it seems like a high value and i can notice a visible change in the results showing up between 20 and 200 ms delay (on my system). when there is a 200 ms delay - when there is a 20 ms delay - validation steps performed manually tested its working. </desc> <cmt> added the auto-complete feature </cmt> <cmt> fixed merge conflicts </cmt> <cmt> set only when index is 0 </cmt>",auto completion feature for text box
3864,<desc> objectmeta validation on create and update should be consistent. this is a required precursor to #3789 so we can make name generation in one place. it depends on #3646 and so should not be merged quite yet. </desc> <cmt> tighten validation of name and namespace </cmt> <cmt> structure of badrequest error should have message set </cmt> <cmt> omit empty quotes in message when required value field error type </cmt>,validation of objectmeta is inconsistently applied
3865,"<desc> this is for gcs fault tolerance. ref here for more detail of gcs fault tolerance proposal. objectlocator is used in gcs server. raylets or workers will get object location from gcs server. gcs server will lookup object location from objectlocator. objectlocator is thread-safe. still working on ut. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> add objectlocator </cmt> <cmt> finish impl of objectlocator </cmt> <iss> gcs service </iss>",add objectlocator to gcs server
3866,"<desc> updates the snippet generation tool in /dev/snippets with a new flag, --dartpad. if the flag is present, the html output generated by the tool for use at api.flutter.dev will embed a dartpad iframe to show its application-style sample code. as part of this change, the snippet tool tag for the appbar class has been updated to use the new flag. once it's verified as working, the flag can be added to other widgets' snippets as desired. q.v. dart-lang/dart-pad#1238 (change to dartpad itself that adds the loading of sample code from api.flutter.dev) related issues dart-lang/dart-pad#1222 i added the following tests: two new tests in configuration_test to verify that the right html skeleton file is chosen based on the type parameter and dartpad flag. an additional test in snippet_test to verify that the generate method in snippetgenerator properly generates html output with dartpad. updates to existing tests as necessary to match function signature changes. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read [handling breaking changes]). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> added dartpad snippet option. </cmt> <cmt> including run in query string </cmt> <cmt> help text for flag. </cmt>",adds dartpad option to the dartdoc snippet generator.
3867,"<desc> for our universal terminal for development purposes, we will use telnet to escape the universal application container and empower developers to debug/diagnose issues with their own machine on loopback to the already-elevated telnet context. closes internal development-blocker deliverable i work here manual testing internal tool right now to test the waters on what's possible, no public doc. i'm a core contributor we have two factors at odds here: to develop our modern devices platforms, our developers need the ability to run diagnostics and utilities directly on a device. universal applications tend to be stuck inside a container this provides a development-based way around the issue. the telnet server exists on a device when it is in a development mode and runs in an already elevated context. this is great for performing activities from off-device, but not for the same device. however, if we loopback out of the containered app to the elevated context, we should be able to be on-device but with the same power as off-device. so overall, this adds the following: a telnet connection type, leveraging the mit-licensed telnetpp library for the communication channel telnet profile generators customization of the universal-edition of settings loading so it goes directly into this telnet connection type a bunch of odds and ends cleaning up strings and handling errors and connection things (and icons and whatnot). this enables a developer on a more constrained device that is set to developer mode to launch a special edition of windows terminal straight into a prompt that runs in an elevated context against the same device. todo: expose third-party notices in about box? @dhowett-msft upload telnetpp vcpkg to feed and update references do first pass pr on this myself then set to ""ready"" status from ""draft"" hookup resize make the tab say something telnet server detects this connection type and moves up to xterm256 utf-8 mode. todo after completion: ingest this package into development images of windows connected from local dev box running this application in a containered context to the telnet server running on another device and ran commands. connected in loopback on the device itself to itself and ran commands. </desc> <cmt> add telnet connection type. compensate for gsl conflict. temporarily use azurecloudshell entrypoint to launch telnet conection type. </cmt> <cmt> add telnet generator, create our own settings entry for uwp, pipe everything through, add icons for telnet type. add resources for failure. round out the telnet connection to work more like how we expect. fix applogic to declare uwp status before settings. bring telnetpp license in. </cmt>",create telnet connection type and default loopback profile for universal
3868,"<desc> use hf optimizer and/or scheduler unless specified in deepspeed config if hf is already creating an optimizer and lr scheduler, we should not try to match that config/implementation in a ds_config.json instead we pass it to deepspeed.initialize(..., lr_scheduler=hf_lr_scheduler) this pr checks if ds_config has an optimizer or scheduler, if it does not, calls  create_optimizer or create_cheduler (after splitting it) to create an optimizer or scheduler.  then hf optimizer and scheduler are passed it to deepspeed.initialize(). deepspeed can handle any optimizer and scheduler if these are passed directly to deepspeed.initialize() as an object. due to the chicken-n-egg init problem, the valid combinations are: combos hf scheduler ds scheduler hf optimizer yes yes ds optimizer yes but if cpu_offload is used all bets are off - we can only use ds optim/sched. added by @stas00 below: added: make init_deepspeed support config dict, besides the config file - this makes the testing much easier add tests for this pr using this new feature of passing the dict various small clean ups update the docs check for cpu_offload - add test recode the config overrides to have one true source of values tweak one not working test blocking event: waiting for a new release 0.3.13 from deepspeed. </desc> <cmt> pass hf optimizer and scheduler to deepspeed if not specified in ds config </cmt> <cmt> pass hf optimizer and scheduler to deepspeed if not specified in ds config </cmt>",allow hf optimizer and scheduler to be passed to deepspeed
3869,"<desc> this makes abs, wrapping_abs and overflowing_abs const functions like #58044 makes wrapping_neg and overflowing_neg const functions. abs is made const by returning (self ^ -1) - -1 = !self + 1 = -self for negative numbers and (self ^ 0) - 0 = self for non-negative numbers. the subexpression self >> ($bits - 1) evaluates to -1 for negative numbers and 0 otherwise. the subtraction overflows when self is min_value(), as we would be subtracting max_value() - -1; this is when abs should overflow. wrapping_abs and overflowing_abs make use of wrapping_sub and overflowing_sub instead of the subtraction operator. </desc> <cmt> make abs, wrapping_abs, and overflowing_abs const functions </cmt> <cmt> test const abs, wrapping_abs, and overflowing_abs </cmt>","make abs, wrapping_abs, overflowing_abs const functions"
3870,"<desc> uses the new non_max_suppression op in tf 1.9 with extra score_threshold argument in post processing, so that data flow will not jump between cpu and gpu back and forth. fixes the tensor slicing issue when max_number_of_boxes is less than number of groundtruth boxes. </desc> <cmt> merged commit includes the following changes: </cmt> <cmt> 207771702  by zhichao lu: </cmt> <cmt> refactoring evaluation utilities so that it is easier to introduce new detectionevaluators with eval_metric_ops. </cmt> <cmt> -- </cmt> <cmt> 207758641  by zhichao lu: </cmt> <cmt> require tensorflow version 1.9+ for running object detection api. </cmt> <cmt> -- </cmt> <cmt> 207641470  by zhichao lu: </cmt> <cmt> clip num_groundtruth_boxes in pad_input_data_to_static_shapes() to max_num_boxes. this prevents a scenario where tensors are sliced to an invalid range in model_lib.unstack_batch(). </cmt> <cmt> -- </cmt> <cmt> 207621728  by zhichao lu: </cmt> <cmt> this cl adds a freezablebatchnorm that inherits from the keras batchnormalization layer, but supports freezing the training parameter at construction time instead of having to do it in the call method. </cmt> <cmt> it also adds a method to the keraslayerhyperparams class that will build an appropriate freezablebatchnorm layer according to the hyperparameter configuration. if batch_norm is disabled, this method returns and identity layer. </cmt> <cmt> these will be used to simplify the conversion to keras apis. </cmt> <cmt> -- </cmt> <cmt> 207610524  by zhichao lu: </cmt> <cmt> update anchor generators and box predictors for python3 compatibility. </cmt> <cmt> -- </cmt> <cmt> 207585122  by zhichao lu: </cmt> <cmt> refactoring convolutional box predictor into separate prediction heads. </cmt> <cmt> -- </cmt> <cmt> 207549305  by zhichao lu: </cmt> <cmt> pass all 1s for batch weights if nothing is specified in gt. </cmt> <cmt> -- </cmt> <cmt> 207336575  by zhichao lu: </cmt> <cmt> move the new argument 'target_assigner_instance' to the end of the list of arguments to the ssd_meta_arch constructor for backwards compatibility. </cmt> <cmt> -- </cmt> <cmt> 207327862  by zhichao lu: </cmt> <cmt> enable support for float output in quantized custom op for postprocessing in ssd mobilenet model. </cmt> <cmt> -- </cmt> <cmt> 207323154  by zhichao lu: </cmt> <cmt> bug fix: change dict.iteritems() to dict.items() </cmt> <cmt> -- </cmt> <cmt> 207301109  by zhichao lu: </cmt> <cmt> integrating expected_classification_loss_under_sampling op as an option in the ssd_meta_arch </cmt> <cmt> -- </cmt> <cmt> 207286221  by zhichao lu: </cmt> <cmt> adding an option to weight regression loss with foreground scores from the ground truth labels. </cmt> <cmt> -- </cmt> <cmt> 207231739  by zhichao lu: </cmt> <cmt> explicitly mentioning the argument names when calling the batch target assigner. </cmt> <cmt> -- </cmt> <cmt> 207206356  by zhichao lu: </cmt> <cmt> add include_trainable_variables field to train config to better handle trainable variables. </cmt> <cmt> -- </cmt> <cmt> 207135930  by zhichao lu: </cmt> <cmt> internal change. </cmt> <cmt> -- </cmt> <cmt> 206862541  by zhichao lu: </cmt> <cmt> do not unpad the outputs from batch_non_max_suppression before sampling. </cmt> <cmt> since balancedpositivenegativesampler takes an indicator for valid positions to sample from we can pass the output from nms directly into sampler. </cmt> <cmt> -- </cmt> <cmt> piperorigin-revid: 207771702 </cmt> <cmt> remove unused doc. </cmt>",update object detection post processing and fixes boxes padding/clipping issue.
3871,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. </desc> <cmt> add dt for serialport </cmt> <cmt> eliminate implicit any </cmt> <cmt> change format of the import in the -tests file </cmt>,add new type definition for serialport
3872,"<desc> this pr causes zstd_fast and zstd_dfast in zstd_dictmatchstate mode to actually perfectly mirror the behavior of zstd_extdict (aka copying the dict ctx into the working ctx). previously, in dms mode, these strategies would search the dictionary tables if the working tables didn't have an entry (matchindex < prefixlowestindex) or if the working tables' entry was a mismatch (mem_read32(match) != mem_read32(ip)). this latter situation caused behavior to differ, since in the copied-dict scenario, the existence of the mismatched entry would have overwritten the dictionary match. so this pr changes their behaviors to only search the dictionary tables in the first situation, but not the second. perf results are forthcoming. i expect this to actually be perf-positive for these strategies, since we will do fewer lookups into the dictionary tables. we'll see. </desc> <cmt> zstd_fast: don't search dict context when mismatch was found </cmt> <cmt> zstd_dfast: don't search dict context when mismatch was found </cmt>",don't search dictionary context when working context search resulted in mismatch
3873,"<desc> i got bitten by the not-optimally-documented fact that the return values of before_request callbacks aren't ignored. </desc> <cmt> fix grammar in preprocess_request() docstring </cmt> <cmt> document required signature of before_request functions </cmt> <cmt> unless you happened to also read preprocess_request()'s docstring, </cmt> <cmt> it wasn't not obvious that return values from these functions are treated as </cmt> <cmt> response values. </cmt> <cmt> document that the return values of teardown functions are ignored </cmt> <cmt> document required signature of before_first_request-decorated functions </cmt>",improve docs of signatures of before/after/teardown callback funcs
3874,"<desc> pop a yak off the stack: testing change for preserving serialized sil in merge modules led to... noticing that sil witness table thunks had the wrong linkage, which led to... noticing that referencing thunks and imported synthesized declarations from inlineable functions crashes in the sil verifier, which led to... renaming [fragile] to [serialized] and adding a third [serializable] state i just merged the past part (#8407). this is the second-to-last bit. </desc> <cmt> sil: implement the [serialized] vs [serializable] distinction </cmt> <cmt> this generalizes a hack where re-abstraction thunks become fragile on contact </cmt> <cmt> with fragile functions. </cmt> <cmt> the old policy was: </cmt> <cmt> - [fragile] functions always serialized </cmt> <cmt> - [reabstraction_thunk] transitively referenced from fragile always serialized </cmt> <cmt> the new policy is: </cmt> <cmt> - [serialized] functions always serialized </cmt> <cmt> - [serializable] functions transitively referenced from serialized functions </cmt> <cmt> are always serialized </cmt> <cmt> - most kinds of thunks can now be [serializable], allowing them to be shared </cmt> <cmt> between serialized and non-serialized code without any issues, as long as the </cmt> <cmt> body of the thunk is sufficiently ""simple"" (doesn't reference private </cmt> <cmt> symbols or performs direct access to resilient types) </cmt> <cmt> sil: remove an obsolete verifier check </cmt> <cmt> this code has been commented out for years, doesn't compile, </cmt> <cmt> and when i changed it to compile it blew up building overlays. </cmt> <cmt> i don't feel it adds any value to have it around so i'm </cmt> <cmt> removing it. </cmt>",thunk linkage and fragility cleanup
3875,<desc> started package for ionic framework's cordova plugins added definitions for cordovarduino project </desc> <cmt> add cordovarduino </cmt> <cmt> start ionic-cordova package and add keyboard plugin as a start </cmt> <cmt> run npm test and fix files to pass tests </cmt>,add multiple cordova related things
3876,"<desc> as discussed here #1152, this is a small proposition to update the real-world example with the latest version of react-router-redux feedback welcome ! </desc> <cmt> use react-router-redux and react-router 2.0.0 </cmt> <cmt> configure route & middlewares with react-router-redux </cmt> <cmt> reconcile router configuration on containers </cmt> <cmt> lint and remove unused dependency </cmt>",update real-world example with react-router-redux
3877,"<desc> settings refactored now when the user change the theme, the change is immediate, no more restarting search, videos and channel don't reload on device rotation don't reload the items again, e.g. you go from the search to a video, if you go back to the search it won't reload everything again, same for videos and channel, that provides a quick navigation videodetail ux improved implement toolbar app-wide ditch the searchview, use custom implemented search with autocompletetextview replace old action bar remove toast errors add error messages with a retry button in the layout itself improve workers new workers for search and suggestions add cache functionality now the app will cache the streaminfo's that are already loaded, so if the user decides to come back to that video, it'll open instantaneously the list of related videos had an issue, we were trying to inflate 20+ views, that's just too much (at least in mid-low devices, like mine) and it causes to skip frames, and as result, a jittering and laggy animation. so i limited the related streams to a reasonable amount and added a expand button to load more. closes #420, closes #449 and closes #466 @thescrabi hey, remember to merge the teamnewpipe/newpipeextractor#5 </desc> <cmt> add drawables and improve layouts </cmt> <cmt> add new workers </cmt> <cmt> improve fragments </cmt> <cmt> - they save the state now, that means, no more reloading after rotating the screen or switching between apps </cmt> <cmt> minor improvements </cmt>",implement state saving and improvements
3878,<desc> i had to redo the pull request because i forgot to rename files and test build but is all working now </desc> <cmt> add initial ep40 files </cmt> <cmt> fixed issues </cmt> <cmt> updated keymap </cmt> <cmt> added media control </cmt> <cmt> update keyboards/handwired/ep40/rules.mk </cmt> <cmt> fixed requested changes </cmt> <cmt> fixed more requested changes </cmt> <cmt> added delete key to layor 1 </cmt> <cmt> updated defualt keympap to have a backspace mod del key </cmt> <cmt> removed place holder </cmt> <cmt> removed obsolete code </cmt> <cmt> moved ep40 to ep/40 </cmt> <cmt> fixed file names for moved code </cmt>,moved ep40 to ep/40 for easier adding of next ep keyboard
3879,<desc> effects that are not rendered on a black background can be designed better with this change </desc> <cmt> add parameter to hide the gradient editor of the gradient panel </cmt> <cmt> make background color of the particle renderer configurable </cmt>,make particle editor background color configurable
3880,"<desc> this pr fixes two issues that can happen if the upgrade from http/1 to http/2 fails. </desc> <cmt> http/1 to http/2 upgrade path leak </cmt> <cmt> missing cleanup when the connection upgrade fails </cmt> <cmt> http/1 -> http/2 upgrade path fd leak </cmt> <cmt> on upgrade error, make sure we're closing the http/1 socket before </cmt> <cmt> giving control to the http/2 error handling. </cmt>",http/1 -> http/2 uprade error fixes
3881,"<desc> this restores the trait that was lost in 216e85f. num will eventually be broken up into a more fine-grained trait hierarchy in the future once a design can be agreed upon. to contribute to the discussion about the future of rust's numeric traits, please see issue #4819 and the wiki page. i have also switched to implementing numcast using macros. this removes a significant number of lines of code. </desc> <cmt> clarify purpose of numcast trait </cmt> <cmt> generate numcast impls and tests using macros </cmt> <cmt> add a test to show how numcast can be used in type parameters </cmt> <cmt> remove trailing whitespace </cmt> <cmt> restore num trait </cmt> <cmt> this restores the trait that was lost in 216e85fadf465c25fe7bc4a9f06f8162ec12b552. it will eventually be broken up into a more fine-grained trait hierarchy in the future once a design can be agreed upon. </cmt> <cmt> consolidate tests of numeric operations </cmt>",restore num trait and use macros to implement and test numcast
3882,"<desc> alarm notification urls use the hostname to find the url of the netdata dashboard. this hostname is the [registry].hostname, not the [global].hostname, since the registry is not aware of the global one. before this pr, there were 3 issues: alarm-notify.sh was called with a hostname, but not the registry one. alarm-notify.sh was using ${netdata_registry_hostname}, which of course is wrong if the alarm is for a slave netdata. slaves did not send to master their [registry].hostname. this pr fixes them all. that is: slaves send their [registry].hostname to the master. the master calls alarm notification programs with the registry hostname of the host. </desc> <cmt> minor aesthetic changes to license files </cmt> <cmt> slaves propagate registry_hostname to master, which is now used for alarm notifications, so that clicking an alarm generated by the master can properly show the slave dashboard </cmt>",fix alarm notification urls sent by master for a slave
3883,"<desc> this pull request adds ""ref"" option to svgr loader; so that, the root svg component ref can be accessed. the way it works is that svgr creates a forward ref and passed the ref to svg component using svgref prop. example: import react, { component } from 'react'; import { reactcomponent as logo } from './logo.svg'; // cra default logo file class app extends component { myref = react.createref(); componentdidmount() { console.log(this.myref); } render() { return (<logo svgref={this.myref} />); } } this example will print the svg element. testing i have added unit tests to webpack/svgcomponent.js; however, i was not able to perform the test. yarn e2e:docker -- --test-suite kitchensin kept giving me permission denied error inside the container. </desc> <cmt> add forward ref to svg component </cmt> <cmt> write proper component for the ref test </cmt>",add forward ref to react svg component
3884,<desc> description: add support for stream component to cameras created by doorbird component related issue (if applicable): fixes #22742 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to requirements in the manifest ([example][ex-requir]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> support stream source for doorbird live camera </cmt> <cmt> support stream source for doorbird live camera </cmt> <cmt> support stream component on doorbird camera entities </cmt> <cmt> bump library version </cmt> <cmt> update manifest </cmt> <iss> doorbird event contains wrong rtsp url </iss>,stream support for doorbird component
3885,"<desc> this is so much better than to edit nuklear.h if you need more than 65536 vertices for your ui. also cleaned up some documentation pull requests that made the changes directly on the generated files. </desc> <cmt> fix #718 by moving all the changes to src/nuklear.h </cmt> <cmt> make the size of nk_draw_index an option, also make the documentation a bit more clear. </cmt>",make the size of nk_draw_index an option.
3886,"<desc> this pr moves the context menu entry to the same section as the rotate right/left options and moves the drag and drop menu entry down below the copy here entry. details of the investigations are available in issue #1110. these changes have only been verified for the msi installer. handling the same for msix will be done in a separate pr linked to the same issue. pr checklist applies to #1110 cla signed. if not, go over here and sign the cla tests passed detailed description of the pull request / additional comments details of how the context menu ordering works can be found in #1110 based on the details above, since the shellimagepreview which contains rotate left/right is registered at hkcr/systemfileassociation/.png/shellex/contextmenuhandlers/shellimagepreview, the same has to be done with imageresizer for each of the supported types. thus there are entries for bmp, dib, gif, jfif, jpe, jpeg, jpg, jxr, png, rle, tif, tiff, wdp (all the directly supported types mentioned in the imageresizer code). images like .ico also ""work"" with the imageresizer.exe but it converts it to jpg instead, so it doesn't actually resize a .ico back to .ico. shellimagepreview adds 4 entries: a separator, rot right, rot left and another separator. for a basic check without making the context menu handling more resource intensive, a simple check for a separator at the start index(indexmenu arg) has been added to make sure that if an older version of windows is being used where shellimagepreview isn't available or if it has been disabled the code will still run fine. the drag and drop handler index was simply increased by one because copy here was the initial first value in the context menu. validation steps performed build, install, run on debug/release x64 tests passed checked position of drag/drop and context menu entry for .jpg, .png, .bmp. </desc> <cmt> updated vcxproj file with common project references and cpp version flags </cmt> <cmt> added module template code to dllmain and updated headers for successful build </cmt> <cmt> removed unnecessary include </cmt> <cmt> added dll to runner and add fixes to show up in pt settings </cmt> <cmt> added settings file </cmt> <cmt> added support for enabling/disabling based on powerrename codebase </cmt> <cmt> fixed solution file configurations </cmt> <cmt> removed any cpu from imageresizer csprojs </cmt> <cmt> renamed registry writing and removed build time registry addition </cmt> <cmt> added imageresizer installation details to msi </cmt> <cmt> shifted to mii, todo: fix position </cmt> <cmt> incorporated imageresizer icon in context menu entry </cmt> <cmt> changed registry entries to systemfileassociations and added index changes in insertmenuitem </cmt> <cmt> merged with dev/imageresizer </cmt>",fix imageresizer menu item position (dev/imageresizer)
3887,"<desc> this adds a gradle task called generatecontextdoc in the painless module.  the task will start a cluster, issue commands against the context rest api for painless, and generate documentation for each api per context.  each context has a first page of classes sorted by package first and class name second, along with a page per package with each classes' constructors, methods, and fields.  a link is generated for each constructor, method, and field to a javadoc page when possible. the change itself is small, but the number of lines is large due to the auto-generated changes in documentation. follow up: 1) internal documentation. 2) appropriately link each context to its api docs. 3) add static methods/bindings.  4) add class inheritance hierarchy.  5) links per class/package.  6) improve method links for declaring classes.  7) explore reduction of total classes using hierachy.  8) open-ended exploration of more automation for documentation per context. concern: with all the new links, the docs build process has slowed down some.  i really hope that i don't have to reduce the number because i think the layout is significantly improved for figuring out what's available. </desc> <cmt> added initial gradle files. </cmt> <cmt> use clusterformation instead of testclusters </cmt> <cmt> add gradle dependencies. </cmt> <cmt> remove old api docs. </cmt> <cmt> build table of contexts to apis </cmt> <cmt> add basic page outline for all apis. </cmt> <cmt> checkpoint </cmt> <cmt> checkpoint. </cmt> <cmt> add indices for each context. </cmt> <cmt> checkpoint. </cmt> <cmt> checkpoint. </cmt> <cmt> checkpoint </cmt> <cmt> initial generation of painless apis per context </cmt>",task to generate painless api's per context
3888,<desc> related to #34714 adds an overview page for cluster voting configurations and a reference page for the api that manages the exclusion list. </desc> <cmt> [docs] adds overview and api ref for voting configurations </cmt> <cmt> [docs] removes redundant sections </cmt>,adds overview and api ref for cluster voting configurations
3889,"<desc> added two boolean results in _writebuffer() function, thus utilized update_error_erase. this helps to notice whether esp.flasherasesector or esp.flashwrite was unsuccessful when an error occurs. previously, it would only show update_error_write. with the request of @devyte , added _seterror function to wrap some lines up and tidied the code. </desc> <cmt> added _seterror function in the header file </cmt> <cmt> _seterror function wraps a few lines to eliminate repetitiveness when debugging for errors. </cmt> <cmt> added _seterror function </cmt> <cmt> _seterror function wraps a few lines to eliminate repetitiveness when debugging for errors. </cmt>","utilized update_error_erase, added _seterror function and refactored code"
3890,<desc> fixes #17458. a more detailed analysis of what happens is here: #17458 (comment) </desc> <cmt> add unobservedtaskexceptiontest </cmt> <cmt> fix unobserved task exception problem for non-exhausted response streams </cmt> <iss> unobserved task exception for disposed but not exhausted-by-client server streaming call </iss>,c# fix unobserved task exception problem for cancelled calls with unexhausted response stream.
3891,<desc> extend support for wait_for_completion=false to updatebyquery api by adding submitupdatebyquerytask. similar to prior art #35202. closes: #46350. </desc> <cmt> add submitupdatebyquerytask </cmt> <cmt> move common methods to parent class </cmt> <cmt> add tests </cmt> <cmt> fix checkstyle </cmt> <iss> shouldstoreresult is not set correctly </iss>,updatebyquery api with wait_for_completion being false
3892,<desc> this pr focuses on improving the performance of the tab api by constructing the model on the fly and making the minimum applied changes. </desc> <cmt> enrich the change event </cmt> <cmt> initial tab model building </cmt> <cmt> work in progress model construction </cmt> <cmt> add pauseable emitter </cmt> <cmt> attempt using microtask </cmt> <cmt> make tests pass </cmt> <cmt> update active tab logic </cmt> <cmt> fix layering issue </cmt>,on the fly tab model construction
3893,"<desc> enable int8 concat kernel to improve the performance of mobilenet-ssd, theoretical improvement is 4x for memory bandwidth saving. test=develop </desc> <cmt> enable int8 concat kernel to improve the performance of mobilenet-ssd. </cmt> <cmt> test=develop </cmt> <cmt> optimize ut format. </cmt> <cmt> test=develop </cmt>",enable mkl-dnn int8 concat kernel.
3894,"<desc> 2019-03-08 switched position on alt and alt-shift added tilde character to symbol layer added print screen to keymap 3 added ' (no_apos) to keymap 3 added how to install help in this readme my code follows the code style of this project. i have read the contributing document. </desc> <cmt> small fixes, added tilde, print screen and switched alt keys </cmt> <cmt> comments </cmt> <cmt> .. </cmt>",small improvements to this layout
3895,"<desc> the lowering graph just converts undefs that are encountered into some arbitrary constants. these values should not matter as they will never be used in the calculations. this is a stop gap solution until we get rid of undefs during sese canonicalization pass. this patch also introduces the following: a lowergraph pass to test out the undef lowering. a new configuration in lit.cfg that enables -tf-ensure-single-loop-exit, which will be removed once the sese code stabilizes and the flag is removed. resolves sr-7765. </desc> <cmt> convert undefs to magic constants. </cmt> <cmt> add a tflowergraph pass for testing purposes. </cmt> <cmt> added a test for checking undef lowering. </cmt> <cmt> add a sese_loops configuration to lit </cmt> <cmt> add a runtime test for sese loops. </cmt>",lower undefs introduced by sese loop canonicalization in graph lowering
3896,"<desc> this pr implements an oh-my-zsh standard open function that is cross-platform and easy to use for all plugins and users as well to create their aliases. the function is called open_command and it uses the $ostype value to decide which command to run. this pr also changes those plugins that used old logic so that we have consistent, non-duplicate code throughout the project codebase. plugins changed: fasd, frontend-search, jira, lighthouse, node and web-search. these other plugins also have open commands but are osx specific, so there's no need to use a cross-platform open command: atom, bwana, marked2, osx, textmate and xcode. fixes #1478. fixes #2988. fixes #3920. </desc> <cmt> implement cross-platform open function open_command() </cmt> <cmt> for now this supports: </cmt> <cmt> - mac os x </cmt> <cmt> - linux (presumably works on all versions) </cmt> <cmt> - cygwin (windows) </cmt> <cmt> use standard open command in current plugins </cmt> <cmt> substitutes the current duplicate logic for the standard </cmt> <cmt> and cross-platform function open_command in plugins: </cmt> <cmt> frontend-search, jira, node, web-search </cmt>","implement and use a standard, cross-platform open command"
3897,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. </desc> <cmt> feat(timerpicker): add amtext and pmtext to timerpicker (#1) </cmt> <cmt> * feat(timerpicker): add amtext and pmtext to timerpicker </cmt> <cmt> * fix(notification): fix notification </cmt> <cmt> chore: add deprecatednavigator </cmt>,add some comment and types
3898,"<desc> as prepare is only needed to boot up the hot reloader + exportpathmap routes in development, it's not longer a requirement in the production server. </desc> <cmt> add test for 501 and content-length header </cmt> <cmt> drop prepare requirement in production server </cmt>",drop prepare requirement from production server
3899,<desc> /sig scheduling /priority important-soon cherry pick of #91099 and #91252 on release-1.18. release note: pod finalizers and conditions updates are skipped for re-scheduling attempts </desc> <cmt> skip unnecessary scheduling attempt when pod's finalizers change </cmt> <cmt> add test for finalizers </cmt> <cmt> skip pod conditions from scheduling queue updates </cmt>,skip pod updates from scheduling queue updates
3900,<desc> this pr fixes a few bugs that were found and adds tests checking for these errors. specifically: single byte keys are checked to actually be one byte. unknown global data must be merged when combining two psbts. </desc> <cmt> check that psbt keys are the correct length </cmt> <cmt> checks that all of the one byte type keys are actually one byte and </cmt> <cmt> throw an error if they are not. </cmt> <cmt> add tests for each type to check for this behavior. </cmt> <cmt> fix merging of global unknown data in psbts </cmt> <cmt> actually merge the global unknown key-value pairs. </cmt> <cmt> add a test for merging unknown key-value pairs. </cmt>,bugfixes for bip 174 combining and deserialization
3901,"<desc> adding firmware for two new pcbs. prime_l v2 will be produced. prime_exl plus is a personal project, hence why it's in /handwired. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> correct indicator light states. </cmt> <cmt> function of indicator lights was inverted. these changes correct that. </cmt> <cmt> flesh out keymaps pre production </cmt> <cmt> enable extrakey in rules </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> upstream sync </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> prime_ble initial commit </cmt> <cmt> initial commit for prime_l v2 </cmt> <cmt> update info.json </cmt> <cmt> correct key spacing. </cmt> <cmt> update copyright </cmt> <cmt> update readme.md </cmt> <cmt> inital commit </cmt> <cmt> updates before pr into qmk master </cmt>",add prime_l v2 and prime_exl plus
3902,"<desc> as described in d3/d3#1289 and d3/d3#1322, this produces better drag behavior in iframes. i borrowed the method for supressing text selection from there as well. </desc> <cmt> remove preventdefault and mousedown workaround </cmt> <cmt> as long as the mousedown event does not have preventdefault, </cmt> <cmt> dragging out of an iframe works as expected. </cmt> <cmt> continue to preventdefault on touch </cmt> <cmt> suppress text selection behavior during drag </cmt> <cmt> reference: </cmt> <cmt> add iframe debug html </cmt>",avoid using preventdefault on mousedown
3903,"<desc> my fault is that in recent pr with sklearn compatibility i forgot about pandas support. this pr is expected to bring pandas support back to the sklearn wrapper. fix #901 . since scikit-learn has poor pandas support, i think that the best thing to do is just pass pandas.dataframe to booster as is. </desc> <cmt> added test for sklearn handle categorical features </cmt> <cmt> use raw x, y in sklearn wrapper in case of pandas.dataframe </cmt> <iss> sklearn categorical handling </iss>",bring pandas support to the sklearn wrapper back
3904,"<desc> i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test exempt. i updated/added relevant documentation (doc comments with ///). this pr has same changes as #75148 </desc> <cmt> alert dialog dartpad demo </cmt> <cmt> updated description </cmt>",dartpad demo for alert dialog.
3905,"<desc> this pr implements @avih's the feature-request from issue #10268. what has changed? new configuration setting git.countuntracked, default is false the blue 'change count badge' on the git icon in the main sidebar ignores untracked files if git.countuntracked is true new configuration setting the new setting does not affect the default behaviour of the change count badge as it is off by default, meaning both tracked and untracked files are counted. untracked files are only ignored if git.countuntracked is set to true in the user or workspace preferences. other changes to gitworkbenchcontribution.ts import iconfigurationservice in order to read the countuntracked config in statusupdater: add private member configurationservice in statusupdater.showchangesbadge(): use a different callback for map depending on countuntracked in action </desc> <cmt> ignore untracked in git change count badge </cmt> <cmt> add git setting 'git.countuntracked' </cmt>",ignore untracked files in change count badge
3906,"<desc> this batch should, hopefully, fix the rest of the outstanding coverage-related issues. / </desc> <cmt> test: tweak triggerlimitintervalsec= when built with coverage </cmt> <cmt> collecting coverage causes a significant slowdown in general, but since </cmt> <cmt> this test requires certain timing, we need to tweak the defaults to make </cmt> <cmt> it reliably pass. </cmt> <cmt> test: merge coverage reports from previous test runs </cmt> <cmt> relevant mainly for tests which utilize both qemu and nspawn. </cmt>",last batch of coverage-related tweaks
3907,<desc> i hereby agree to the terms of the cla available at:  fix incorrect query result (and possible crash) which could happen when where or having condition is pushed before group by. fixes #21773 </desc> <cmt> fix filter push down columns order. </cmt> <cmt> add comments. </cmt> <cmt> fix added input. </cmt> <cmt> added test. </cmt> <iss> would use 1.00 eib ... while executing convertingaggregatedtochunkstransform </iss>,fix wrong column order after  filter push down.
3908,"<desc> our unit testing setup is designed for unit tests, and its not really appropriate for integration tests (its not totally realistic). instead i think we should add real integration test setup, with the maven plugins designed to do that, that runs after packaging, unzips elasticsearch, starts up external cluster, runs rest tests against it, and then shuts down the cluster. people already know the rest tests framework and we already have a bunch of tests. i need this kind of thing to fix stuff like jar hell issues for good, and to have more confidence in stuff like security manager and other tricky things. today we kind of have it, but its wierd and run from a python release script. instead i think integ tests should be a regular part of our build. i made a very simple initial impl and it finds bugs already ;) as a followup i would like to extend this to plugins (i will start with delete-by-query, it already has rest tests defined). so please don't worry too much about where the logic currently is, we can refactor as needed after that. </desc> <cmt> add simple integ testing infra </cmt> <cmt> use external test cluster for integration tests </cmt>",add integration test harness to maven build
3909,"<desc> this makes use of c++11 variadic templates to get rid of the conversion between base::listvalue when sending arguments from c++ to javascript. it also makes the c++ code as simple as javascript: base::listvalue args; args.appendinteger(level); args.appendstring(message); args.appendinteger(line_no); args.appendstring(source_id); emit(""console-message"", args); now becomes emit(""console-message"", level, message, line_no, source_id); </desc> <cmt> use c++11 stdlib </cmt> <cmt> convert arguments to v8 directly in eventemitter::emmit </cmt> <cmt> this gets rid of the extra conversion between listvalue. </cmt> <cmt> update native_mate to fix linking error </cmt>",convert arguments to v8 directly in eventemitter::emit
3910,<desc> backports following prs: #96224 #96689 #104410 /sig storage fix detach from non-existant nodes and support dangling volumes </desc> <cmt> add dangling volume check for vsphere </cmt> <cmt> fix unknown dangling volumes </cmt> <cmt> add docs about process of discovering disks from new nodes </cmt> <cmt> address review comments </cmt> <cmt> fix use variables in the loop in vsphere_util </cmt>,fix dangling volume vsphere detaches
3911,"<desc> this is a backport of #31438, plus a bump to beta .3 to build a new beta </desc> <cmt> revert deprecation of ipaddr, stabilizing for 1.7 </cmt> <cmt> after [considerable </cmt> <cmt> pushback]( </cmt> <cmt> that there is a community consensus around providing ipaddr in the </cmt> <cmt> standard library, together with other apis using it. </cmt> <cmt> this commit reverts from deprecated status directly to stable. the </cmt> <cmt> deprecation landed in 1.6, which has already been released, so the </cmt> <cmt> stabilization is marked for 1.7 (currently in beta; will require a backport). </cmt> <cmt> bump beta to .3 </cmt>",backport one last pr for beta 3
3912,"<desc> this pr aims to add logging for the windows 10 gaming features that can negatively affect obs performance.  this is to make it easier for support providers to diagnose possible issues with obs users on windows 10.  tagging @fenrirthviti since this patch is of interest to him. this pr consists of two commits.  the first adds a wrapper function to libobs/util for windows to make it easier to query the windows registry.  the file libobs/util/windows/win-registry.h is based on libobs/util/windows/win-version.h.  the second adds logging for windows 10 gaming features that may negatively impact the performance of game capture, recording, or streaming.  the logging code attempts to log the status of the following features: game bar game dvr game dvr background recording game mode the code only checks the windows registry for these settings.  i didn't implement checks for the relevant group policy settings, partly because i thought that might be too uncommon.  though, i'm open to being more thorough in these checks. i wasn't sure if it would be best to expand the registry functions and structs to include more possibilities (qword, sz, multi_sz, expand_sz, etc.), or if i should keep the additions constrained to the bare necessities for the scope of this pr.  i'm open to opinions on this particular point. i've compiled and tested this on windows 10 pro 64-bit (version 1703, build 15063.674).  i'd be interested in seeing this tested on windows 10 builds prior to 15063 (before the march 2017 creators update).  as always, feedback and reviews are appreciated. if this pr is accepted, it might be helpful to edit pr #1041 to use the registry functions. </desc> <cmt> libobs: add wrapper function to query windows registry </cmt> <cmt> libobs: log windows 10 gaming features </cmt> <cmt> this commit adds logging for windows 10 gaming features that may </cmt> <cmt> negatively impact the performance of game capture, recording, or </cmt> <cmt> streaming. this doesn't check group policy settings. </cmt>",log windows 10 gaming features (game mode)
3913,<desc> i broke this out of #4261 to avoid changing too much at once. this cleans up redundant code by having the app config extend the window config and adding some copy methods to make these easier to maintain without introducing bugs. i also added the ability to change the window size limits of an existing window. @code-disaster i can rebase and squash this after you merge #4261 so it isn't so messy. </desc> <cmt> allow custom window icons in lwjgl3applicationconfiguration and lwjgl3windowconfiguration </cmt> <cmt> merged duplicated code to set window icons in lwjgl3application and lwjgl3window. </cmt> <cmt> window icon docs and convenience method. </cmt> <cmt> cancel glfw bug workaround. </cmt> <cmt> clean up redundancies. can change window limits on existing window. </cmt>,clean up redundant code in lwjgl3 backend
3914,"<desc> context in #28954, we created different processing strategies for errors and transactions post process forwarders. in this pr, we enable post process forwarder to run with one of the following entities (errors, transactions, all) the all option would be used in scenarios where we don't need separate post process forwarders. example devserver, single tenant. there is no production change with this code since the default option for entity is ""all"" which means the current post process forwarder would handle all messages </desc> <cmt> wip: add dataset parameter to post-process-forwarder </cmt> <cmt> add the integration </cmt> <cmt> add option to process all messages </cmt> <cmt> add log message for type of post process forwarder </cmt>",feat(post-process-forwarder) allow different types of post process forwarders
3915,"<desc> this was a simple case of substitutions being applied inconsistently.  i haven't investigated why type parameters are actually showing up in the closure type here, but trans needs to handle them correctly in any case. </desc> <cmt> fix inconsistent use of substs in trans_unboxing_shim </cmt> <cmt> substs were not applied when calling untuple_arguments_if_necessary. </cmt> <cmt> just apply them once at the start of the function, rebinding fty. </cmt> <cmt> also change the function to take them by reference since we don't </cmt> <cmt> need to consume them at all.  closes #18883 </cmt> <cmt> add regression test for #18883 </cmt>",fix unboxed closure ice in trans
3916,<desc> #1620 french translation - initialisation part i have translated the main file readme.md to /fr/readme.md like others. #1620 i have added a french flag in the main readme.md to be used as a link to the translation of it. the french flag is in assets/fr directory. i have translated the file readme.md to french. the rest of patterns will be translated one part after the other i have added cn/kr flags for languages already presents and enabled links to them. thanks in advance </desc> <cmt> :rocket: init fr translation </cmt> <cmt> #1620 evo add french translation - main part </cmt> <cmt> #1620 evo add french translation - main part </cmt> <cmt> #1620 evo french translation - add french flag </cmt> <cmt> #1620 evo french translation - add french flag </cmt> <cmt> issue#1620 </cmt>,#1620 french translation - initialization part
3917,"<desc> add or edit tests to reflect the change. (run with npm test.) i am getting an error from types-publisher about 3.2 not being a valid ts version follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  these methods were missing in the previous version of this definition increase the version number in the header if appropriate.  there is no version number in the header if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add async-ified versions of the adapter methods to iobroker </cmt> <cmt> add two missing parameters </cmt>",add promisified versions of the adapter methods
3918,"<desc> meta: this is the second and final part of the const refactoring series (part one: #20581). i promise: no more refactoring prs from me in a while! :) i'll now go back to focusing on fuzzing/hardening! changes in this pr: don't declare de facto const member functions as non-const don't declare de facto const reference variables as non-const awards for finding candidates for the above changes go to: clang-tidy's readability-make-member-function-const  check (list of clang-tidy checks) cppcheck's constvariable check (list of cppcheck checks) see #18920 for instructions on how to analyse bitcoin core using clang static analysis, clang-tidy and cppcheck. </desc> <cmt> don't declare de facto const member functions as non-const </cmt> <cmt> don't declare de facto const reference variables as non-const </cmt>",declare de facto const reference variables/member functions as const
3919,"<desc> reopening #31163 rdar://62549587 </desc> <cmt> fix the mid-level pass pipeline. </cmt> <cmt> module passes need to be in a separate pipeline, otherwise the </cmt> <cmt> pipeline restart mechanism will be broken. </cmt> <cmt> this makes globalopt and serialization run earlier in the </cmt> <cmt> pipeline. there's no explicit reason for them to be run later, in the </cmt> <cmt> middle of a function pass pipeline. </cmt> <cmt> also, pipeline boundaries, like serialization and module passes should </cmt> <cmt> be explicit at the the top level function that creates the pass </cmt> <cmt> pipelines. </cmt> <cmt> siloptimizer: add enforcement of function-pass pipelines. </cmt> <cmt> don't allow module passes to be inserted within a function pass </cmt> <cmt> pipeline. this silently breaks the function pipeline both interfering </cmt> <cmt> with analysis and the normal pipeline restart mechanism. </cmt> <cmt> add misssing pass in addfunctionpasses </cmt>",fix the mid-level function-pass pipeline
3920,<desc> component name </desc> <cmt> [package amd64 deb][build latest] package build process trigger </cmt> <cmt> [package i386 deb][build latest] package build process trigger </cmt> <cmt> [package amd64 rpm][build latest] package build process trigger </cmt> <cmt> [package i386 rpm][build latest] package build process trigger </cmt> <cmt> netdata/packaging/docs: fix documentation to more clearely define instructions for static64 install </cmt> <cmt> netdata/packaging/docs: format </cmt>,update docs for offline install
3921,"<desc> with min_child_weight and lambda set to 0 it is possible to have a divide by zero in the weight calculation leading to incorrect results. this pr prevents the divide by zero, adds tests for this case and fixes a minor compilation issue with windows. </desc> <cmt> address windows compilation error </cmt> <cmt> do not allow divide by zero in weight calculation </cmt> <cmt> update tests </cmt>","address #2754, accuracy issues with gpu_hist"
3922,"<desc> commit message: fixes minor fuzz bugs that were test issues or config issues matcher api was moved recently, pgv validation wasn't moved to the new directory. this was the previous fix: #12289 mock encoder callbacks never set a definition for addencodedtrailers risk level: low testing: added regression tests fixes: </desc> <cmt> fix 25273 </cmt> <cmt> fix 25163 </cmt>",fix minor fuzz test bugs
3923,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).     increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [ember] remove types for makearray </cmt> <cmt> - fixes </cmt> <cmt> [ember] do not expose private @ember/enumerable package </cmt> <cmt> fixes </cmt> <cmt> [ember] do not expose private @ember/map package </cmt> <cmt> - fixes </cmt> <cmt> [ember] do not expose private @ember/instrumentation package </cmt> <cmt> - fixes </cmt>",remove types for non-public apis
3924,"<desc> add error function operator ( @szha please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> erf </cmt> <cmt> register gpu </cmt> <cmt> add doc </cmt>",add gauss err function operator
3925,"<desc> allows sending platform messages from the plugin side to the framework side. also adds plugineventchannel to support eventchannel in web plugins. related issues fixes #39981 i added the following tests: added plugin_event_channel_test.dart which tests plugineventchannel and added a simple test to plugin_registry_test.dart which tests that basic send events work. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> allow sending messages from the platform to the framework </cmt> <cmt> add ability to send messages from the plugin to the platform. </cmt> <cmt> also adds [plugineventchannel] which is the plugin counterpart to </cmt> <cmt> eventchannel. </cmt> <cmt> fixes </cmt> <cmt> fix analyzer errors </cmt> <iss> [web] add support for sending messages from the plugin back to the framework </iss>",allow sending platform messages from plugins to the framework and implement eventchannel
3926,"<desc> updating the setup instructions for ccr to follow the recent tutorial guidelines. this pr: adds more explanatory content in the introduction, such as ""what you'll learn"" incorporates a gif showing the setup process removes a few external links to focus on the task moves configuring ccr user privileges to a new stack management page closes #59171 closes #61605 backports 7.x #62499 7.9 #62500 7.8 #62502 </desc> <cmt> applying some initial changes. </cmt> <cmt> updating intro and screenshots. </cmt> <cmt> removing unnecessary links, streamlining content, and adding gif. </cmt> <cmt> adding what's next section. </cmt> <iss> [docs] move bi-directional ccr blog to documentation </iss>",updating ccr setup to be more tutorial focused
3927,"<desc> fix #13306. note: if there error happen during property assignment in object literal and there is jsdoc type, we will use jsdoc type as source of truth (see tests cases) </desc> <cmt> get jsdoctype for property assignment </cmt> <cmt> add tests </cmt> <cmt> update tests/baselines </cmt>",fix #13306 recognize @type on property assignment
3928,"<desc> added an overlay div to handle hovering. modified ripple opacity from 0.1 to 0.16 in order to better reflect current style. modified flat-button and raised-button (""buttons"") creation the ""choose an image"" and ""github"" buttons manually created a label element to pass it in as a child of a button. they used button global classnames that have been moved into js. buttons can now be created with both a label prop and children and will be styled appropriately. darkened colors are close but not identical to their less function equivalents. </desc> <cmt> began refractoring for raised buttons. created labelstyle prop and altered some rendering code for flat and raised buttons </cmt> <cmt> finished css refractoring for raised buttons, modified ripple opacity to get closer to original ripple styles. </cmt>",refractored css into js for raised-buttons
3929,"<desc> kifinnsson's colemak angle mod ansi-ish layout keymap for my non-standard dz60 layout. it is an ansi layout on the right and iso on the left (ie 1.25x left shift). this is to implement the angle mod on for colemak which is the base layer. a side effect of this is that i have an extra key on row 4, which sits between the ""b"" and ""k"" keys in colemak. i use this key as a switch to layer 2 which is my macro layer. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> [keymap] kifinnsson's dz60 keymap </cmt> <cmt> kifinnsson's custom keymap for the dz60 </cmt> <cmt> update keyboards/dz60/keymaps/kifinnsson/readme.md </cmt> <cmt> fixed readme.mk </cmt> <cmt> cleaned up my readme.mk </cmt> <cmt> fixed readme.mk </cmt>",kifinnsson's colemak angle mod ansi-ish layout for the dz60
3930,"<desc> before implementing backwards compat for tool lints, the tool case when parsing cmdline lints was unreachable. this changed with #53762. this fix is needed for rls test-pass. (@nrc) r? @manishearth </desc> <cmt> fix of bug introduced by #53762 </cmt> <cmt> add tests for cmdline tool lints </cmt>",fix of bug introduced by #53762 (tool_lints)
3931,"<desc> this pr makes the following changes as a follow up to #11462, finish correcting places where the tuple is mentioned instead of the model object. you must import automodel as well as tfautomodel for the tutorial to run correctly. cleaned up some language for readability. </desc> <cmt> finish quicktour </cmt> <cmt> fix import </cmt>",finish making quick tour respect the model object
3932,"<desc> firmware for the h08, currently only used on the upcoming version of the singa ocelot. also adding my h65, both versions - soldereable and hotswap. currently using different firmware because the split spacebar matrix assignments are different. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add h65 start </cmt> <cmt> add h65 base files </cmt> <cmt> add ocelot base files </cmt> <cmt> add via keymap </cmt>",add h08_ocelot and h65 pcbs
3933,<desc> fix bug where tempo would be dropped if the first tempo was not at time 0 add option to drop events that occur after the last note. this is important for midi synthesis because there are some midi files that are 1 minute long but have 30 minutes of tempo changes. </desc> <cmt> fix </cmt> <cmt> fix </cmt>,sequence proto to midi fixes
3934,"<desc> remove the @actorindependent attribute from nearly everywhere. leave only a narrow parser hack + diagnostic for source compatibility reasons. addresses rdar://78830857. </desc> <cmt> revert ""revert ""remove @actorindependent attribute."""" </cmt> <cmt> this reverts commit 7c0b50e8eadb2873bfa501090247470d8e027127. </cmt> <cmt> temporarily allow @actorindependent as an alias for nonisolated. </cmt> <cmt> addresses rdar://78830857. </cmt>",remove @actorindependent attribute almost completely
3935,<desc> i hereby agree to the terms of the cla available at:  changelog category: fixed bugs: fix parsing create settings profile with writable keyword. fix calculating full names of row policies. fix casting values of settings while reading profiles from users.xml. tests are written in #11670 </desc> <cmt> fix parsing create settings profile with writable keyword. </cmt> <cmt> fix calculating full names of row policies. </cmt> <cmt> fix casting values of settings while reading profiles from users.xml. </cmt>,fix minor bugs in rbac
3936,"<desc> link to github from the contributing page update the current python 3.6 minor version update http links to https, where available fix a couple of typos italicise black </desc> <cmt> link to github, update 3.6 minor version </cmt> <cmt> http -> https </cmt> <cmt> fix typos </cmt>",link to github + https + typos
3937,"<desc> this change updates the painless fields api to use mapped types instead of java types. for this initial release we only support unsigned long field. as we now intend to do conversions solely on the field classes themselves, converters and field values have been removed. instead of using field values potentially as source fallback we will now rely on whatever class is passed into the script to support the field method. in the future, this method will need to check if a field exists on doc and if not, then do source fallback itself once that feature is supported. the path to retrieve a field is also different. instead of using script doc values we now have our own way to retrieve the fields with a getscriptfield method added to leafdoclookup. this allows us less restrictive design space to generate the field type based the type in the leaf doc lookup; however, this will still require additional information that we need to plumb through for certain field types. once we support all the field types this makes it easier to deprecate and remove script doc values. </desc> <cmt> start to change painless fields api from java type to mapped type </cmt> <cmt> ignore bwc tests </cmt> <cmt> add allowed methods for unsigned long field </cmt> <cmt> move and update yaml tests for new field types </cmt>",update painless fields api design to use mapped types
3938,"<desc> both 64 an 32 bits works under latest macos. still didn't tested/ported to arm, though. related to #5705 </desc> <cmt> fix tiny macho-32 creation </cmt> <cmt> - add empty linkedit with empty symtab and dysymtab segments </cmt> <cmt> - text segment should span the whole file </cmt> <cmt> - fix main entry point </cmt> <cmt> - fix load_dylib command format </cmt> <cmt> indent with tabs </cmt> <cmt> fix tiny macho-64 creation </cmt> <cmt> - mostly a port from 32-bit case </cmt> <cmt> - except here we need a writable segment to make dyld happy </cmt> <cmt> - i choose to make the __linkedit segment writable (it's zero-sized after all) </cmt>",fix (not so) tiny macho creation
3939,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): whitelist for dictionary access. currently using the current connected database. detailed description (optional): a bit similar to #4201. with only setting a system of permission for dictionary. list of potential underlined features who is not implemented on this pr. select dictget('dict', 'val', touint64(2)) from bar.table with getcurrentdatabase() == 'foo' we cannot create multiples dictionaries using the same name but with different database permission. only functions dict* are supported, the engine dictionary is not supported. </desc> <cmt> add database right for dictionaries </cmt> <cmt> cosmetic </cmt> <cmt> add documentation </cmt>",whitelist for dictionary from the current connected database
3940,<desc> when the id of my object is a number then i don't want to use id.tostring() so i've added number and any as valid types for the key prop. </desc> <cmt> allowing other types for key </cmt> <cmt> update preact.d.ts </cmt>,allowing other types for key (typescript definitions)
3941,"<desc> currently we create dedicated network threads for both the http and transport implementations. since these these threads should never perform blocking operations, these threads could be shared. this commit modifies the nio-transport to have 0 http workers be default. if the default configs are used, this will cause the http transport to be run on the transport worker threads. the http worker setting will still exist in case the user would like to configure dedicated workers. additionally, this commmit deletes dedicated acceptor threads. we have never had these for the netty transport and they can be added back if a need is determined in the future. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt>",share niogroup between http and transport impls
3942,"<desc> added add_n operator for row sparse ndarrays. added identitycomputeex for dense/sparse ndarrays as fcomputeex, which is required in the backward pass of add_n operator. this work may overlap with @cjolivier01 's, but i need this function to make add_n backward pass work for row sparse inputs. fixed the bug of not filling zeros for the output of square_sum forward fcomputeex function when the input sparse ndarray is not storage_initialized in this pr, #7206 removed test_cast_storage_ex from test_operator_gpu.py since it has not been completely implemented. @piiswrong @eric-haibin-lin @madjam @cjolivier01 @anirudh2290 @stefanhenneking </desc> <cmt> add add_n op for row-sparse ndarrays and identity fcomputeex </cmt> <cmt> fix bug in square_sum </cmt> <cmt> remove test_cast_storage_ex from gpu test since it's not implemented yet </cmt>",operator add_n for row sparse ndarrays
3943,"<desc> introduce pluginmanager.upload_plugin and manage_updatecenter permissions. this change allows these permissions to be isolated, such that acl's can prevent someone with the administer permission from uploading plugins or configuring update sites. existing configurations will work fine since these permissions are impliedby adminsiter. only known impact is that some screens which display all permissions will scroll horizontally more. </desc> <cmt> introduce pluginmanager.upload_plugins permission which allows a user to upload arbitrary plugins. </cmt> <cmt> add pluginmanager.configure_updatecenter permission which allows a user to configure update sites and proxy info. </cmt> <cmt> hide the advanced tab if user doesn't can't upload_plugins or configure_updatecenter </cmt>",new permissions for update center
3944,"<desc> this reverts commit 36a1076, reversing changes made to e1e9319. fixes #89935 r? @estebank </desc> <cmt> revert ""rollup merge of #86011 - tlyu:correct-sized-bound-spans, r=estebank"" </cmt> <cmt> this reverts commit 36a1076d24697621a3bb67ef654b4eb79647aa54, reversing </cmt> <cmt> changes made to e1e9319d93aea755c444c8f8ff863b0936d7a4b6. </cmt> <cmt> add a regression test for #89935 </cmt> <iss> rocket fails to build on latest nightly </iss>",revert #86011 to fix an incorrect bound check
3945,<desc> fixes getcomponentname() for a few cases where it was incorrectly reading the type (a482fb4). we didn't notice because we rarely call it for anything other than user-defined components. changes its signature to require just the type alone rather than the fiber. this might seem like it makes the calling code longer. however we often already have the type destructured anyway when we call it. i also remember from writing some of that code that it was awkward to always have to pass a fiber around when i only needed a type. this lets us remove two ad-hoc forks of getcomponentname() that don't handle all the cases it does. </desc> <cmt> fix getcomponentname() for types with nested $$typeof </cmt> <cmt> temporarily remove profiler id from messages </cmt> <cmt> change getcomponentname() signature to take just type </cmt> <cmt> it doesn't actually need the whole fiber. </cmt> <cmt> remove getcomponentname() forks in isomorphic and ssr </cmt> <cmt> remove unnecessary .type access where we already have a type </cmt>,remove ad-hoc forks of getcomponentname() and fix it
3946,"<desc> fixes #51236 under certain circumstances, autotraitfinder could end up computing a paramenv involving two trait predicates that differed only in the region parameters involved. one of these parameters would be a hrtb, while the other would be a normal region parameter. when this paramenv was later passed to selectioncontext, an ambiguity error would occur, since the erased versions of these predicates would be identical. to solve the issue, we de-duplicate our list of predicates as we build it up. whenever we encounter two predicates that differ only in their assignment of region parameters (a hrtb vs a normal lifetime parameter), we pick the hrtb. this corresponds to selecting a 'stricter' bound to display in the generated documentation: we're requiring that a particular type works for all possible lifetime parameters if it's going to implement a particular auto trait. </desc> <cmt> fix rustdoc crash when 'static bound appears in struct declaration </cmt> <cmt> filter out duplicated trait predicates when generating auto traits </cmt> <cmt> fixes #51236 </cmt> <cmt> a bit of cleanup </cmt>",fix ice when rustdoc encounters certain usages of hrtbs
3947,<desc> new exportsinfo object in modulegraph tracks all info regarding exports. refactoring existing tests yes module argument of getdependencyreference was removed it's possible to get the module of a dependency with modulegraph.getparentmodule so this is not needed. removing it reduces complexity of other code new option optimization.mangleexports allows to enable/disable export mangling by default it's only enabled in production mode. </desc> <cmt> create exportsinfo and move provided exports and mangle info into this new object </cmt> <cmt> remove module argument from getdependencyreference </cmt> <cmt> move usedexports into exportsinfo </cmt> <cmt> fixup: remove module argument </cmt>,refactoring of used and provided exports
3948,"<desc> greetings maintainers! i make this pr to help with this issue regarding inclusion of edge endpoints style option. have a wonderful day! ps. i made a small mistake in pr #44975, so i added a minor fix for it. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> fixed the events style function for nodes & edges </cmt> <cmt> minor fix for #44890 </cmt> <cmt> fixes definitelytyped/definitelytyped/#45090 </cmt> <cmt> why not? </cmt>",added type definitions for edge endpoints
3949,"<desc> partial backport of #17274. the commit that renames a playercorefactory.xml tag has been omitted to avoid deprecating anything for the next point release. unable to test currently. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) </desc> <cmt> fileitem: fix range iterator constness </cmt> <cmt> fix error playing disk image games </cmt> <cmt> game items ending in disk image extensions are currently played using </cmt> <cmt> videoplayer instead of retroplayer. this results in a brief buffering </cmt> <cmt> dialog, and then the player exits to the previous window. </cmt> <cmt> fix launching zip and 7z files from mygames </cmt>",fix launching disk images and zip files
3950,<desc> for #11669. add back standardtransactioncontexts add back governancetransactioncontexts use governancetransactioncontexts on governanceshardingspheredatasource </desc> <cmt> simplify constructor of governanceshardingspheredatasource </cmt> <cmt> simplify constructor of governanceshardingspheredatasource </cmt> <cmt> add back standardtransactioncontexts </cmt> <cmt> add back governancetransactioncontexts </cmt> <cmt> use governancetransactioncontexts on governanceshardingspheredatasource </cmt> <cmt> use governancetransactioncontexts on governanceshardingspheredatasource </cmt> <cmt> resolve conflicts </cmt>,add back standardtransactioncontexts and governancetransactioncontexts
3951,<desc> manual merge of #212 with small reorganization of 1 file/package. </desc> <cmt> add tests to demonstrate bugs </cmt> <cmt> split take and takewhile </cmt> <cmt> implement trustedobservabletester.asserttrustedobservable() </cmt> <cmt> fix violations of the observer contract. </cmt> <cmt> take(0) subscribes to its source </cmt>,manual merge of pull request #212
3952,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. create it with npm run new-package package-name, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> added typings for 'node-powershell' </cmt> <cmt> updated tsconfig.json </cmt> <cmt> changed strictnullcheck to true </cmt>",add type definitions for 'node-powershell'
3953,"<desc> since data/dhtservers loading is currently broken, and the ""unified"" config directory is hardcoded i moved the config dir from .config/toxic to .config/tox using the alredy written functions to get the home dir. </desc> <cmt> use configdir.c instead of hardcoded paths for the list of dht servers. </cmt> <cmt> modified cmakefile to move the serverlist to the proper directory. </cmt> <cmt> tested on gnu/linux. </cmt>",store data and dhtservers in .config/tox
3954,"<desc> the event flow in notebook was not correct previously but integration tests didn't catch any bug because the events are sent between renderer & ext host really fast so most of the time, if you run a command and await for it, the editors/documents mirrors in the ext host are up to date. this is not true when the latency between the renderer and ext host are somewhat high. this explains why we are seeing one flaky test failure with movedown command on ci only, on which the tests might fail if the ci machine is under heavy loads. our web integration tests unveil the root cause of the failure: at least half of the tests failed on web as the events are not sent to ext host from renderer in time. this pr tracks the refactoring of the event syncing of notebook component to fix the bugs. </desc> <cmt> await notebookeditor.setmodel: sends all initialization events to ext host when opening notebook. </cmt> <cmt> support cell text model attach/detach on web. </cmt> <cmt> set visible editors active property correctly. </cmt> <cmt> use updatestate/compute instead of sending delta directly. </cmt> <cmt> diffing editors/documents/visibleeditors/activeeditor. </cmt> <cmt> split editor does not await, notebook events are not sent to ext host in time on web. </cmt> <cmt> disable webview related tests on web. </cmt> <cmt> fix false negative tests </cmt> <cmt> fix windows file name match </cmt>",notebook events between renderer & exthost
3955,"<desc> identical changes to those made for raisedbuttons, see #417 added iconstyle prop, noted in docs site. allows users to override inline-styles for the floatingactionbutton's icon. new prop for ripple components: opacity enhancedbutton also has new opacity props which get passed down the ripple components. </desc> <cmt> refactored css for floating action buttons, modified home page raised buttons to utilize style props. </cmt> <cmt> modified hover and ripple styles to reflect changes to raised button. #417 </cmt> <cmt> removed unused variables. </cmt>",refractored css into js for floating action buttons.
3956,<desc> rework it by adding a remove of that remaining class files before running the build. let's try it! regards </desc> <cmt> isolate the complied java classes into a target folder + log java version. </cmt> <cmt> it is a common practice to put all the compiled classes into a </cmt> <cmt> dedicated folder in order to: </cmt> <cmt> - avoid to mix the code and the complied classes </cmt> <cmt> - to allow a simple way to remove the complied classes </cmt> <cmt> add log of java version in order to make it explicit to the end user. </cmt> <cmt> add remove of remaining class files before running the build </cmt>,isolate the complied java classes into a target folder.
3957,"<desc> this will break everything and make people angry. this is the last thing i'd like to get in before the release. it has no new functionality, but changes the external api to make it consistent. things we are discussing: i wanted to kill git_erevwalkover and git_epassthrough because they are not errors at all. but i also renamed enotfound to notfound. i don't know if this is good or bad. </desc> <cmt> global: change parameter ordering in api </cmt> <cmt> consistency is good. </cmt> <cmt> global: fix unit tests after reordering </cmt> <cmt> errors: remove old comments </cmt> <cmt> refs: git_reference_listall -> git_reference_list </cmt> <cmt> properly tag all enums with a _t </cmt> <cmt> errors: rename the generic return codes </cmt>",break everything before the release
3958,"<desc> this reverts reversion and fixes torrent_info::map_block() call, providing the correct piece size to it. hopefully  now it will not lead to crashes like in issue #4597 </desc> <cmt> revert ""temporarily revert pr #2885 (filename column in peers view)."" </cmt> <cmt> this reverts commit 69d52a06d757ab0ca250da3df31800edc92d69b1. </cmt> <cmt> use correct piece size while calling torrent_info::map_block() </cmt> <cmt> this should fix crashes. issue #4597 </cmt>",show downloading files in peers list. attempt #2
3959,"<desc> hubproxy.on() and hubproxy.off() should accept the same parameters, since you unsubscribe the same method... </desc> <cmt> update signalr.d.ts </cmt> <cmt> hubproxy.on() and hubproxy.off() should accept the same parameters, since you unsubscribe the same method... </cmt> <cmt> update signalr-tests.ts </cmt> <cmt> test for unsubscribing a listener with more than 1 parameter </cmt>","signalr hubproxy.on() and hubproxy.off() should accept the same parameters, since you unsubscribe the same method..."
3960,"<desc> i have followed (at least) the pr section of the contributing guide. resolves #19833. this pr both applies the disabled color to the select element's icon, and apply the same method to autocomplete for consistency. i hope it's okay to combine those two changes together in one pr? one thing i'm not really confident of is re-applying currentcolor to disabled pseudo class, because it looks redundant. any feedback is appreciated. </desc> <cmt> [nativeselect] fix icon color on disabled state </cmt> <cmt> [autocomplete] unify disabled icon color handling with nativeselect </cmt> <iss> [select] - when the select is disabled the dropdown arrow is not greyed out </iss>",apply disabled color to the icon
3961,<desc> this pr moves all code that lives in __init__.py to a new package called core.py. this was causing issues when running home assistant for the first time. </desc> <cmt> extract core into own submodule </cmt> <cmt> finish core extraction </cmt> <cmt> fix mysensors import </cmt>,extract core from __init__ to core package
3962,<desc> thanks @eddyb for pointing me to the right apis! r? @eddyb fixes #70804 </desc> <cmt> miri assignment check: compare types after normalizing all late-bound regions away </cmt> <cmt> add test </cmt> <iss> miri comparison sanity check is wrong </iss>,fix miri assignment sanity check
3963,<desc> this is an enhancement or feature. this is a documentation change. make it easier for theme users to add javascript after the theme's scripts. use a similar method to footer_scripts arrays in _config.yml to reference paths to external or locally hosted javascript files. #2110 </desc> <cmt> add after_footer_scripts logic </cmt> <cmt> document after_footer_scripts </cmt>,allow adding javascript files after those bundled in the theme
3964,"<desc> to avoid data loss, this commit adds a grace period for lagging replicas to catch up the replication offset. done: wait for replicas when shutdown is triggered by sigterm and sigint. wait for replicas when shutdown is triggered by the shutdown command. a new blocked client type blocked_shutdown is introduced, allowing multiple clients to call shutdown in parallel. note that they don't expect a response unless an error happens and shutdown is aborted. log warning for each replica lagging behind when finishing shutdown. client_pause_write while waiting for replicas. configurable grace period 'shutdown-timeout' in seconds (default 10). new flags for the shutdown command: now disables the grace period for lagging replicas. force ignores errors writing the rdb or aof files which would normally prevent a shutdown. abort cancels ongoing shutdown. can't be combined with other flags. new field in the output of the info command: 'shutdown_in_milliseconds'. the value is the remaining maximum time to wait for lagging replicas before finishing the shutdown. this field is present in the server section only during shutdown. not directly related: when shutting down, if there is an aof saving child, it is killed even if aof is disabled. this can happen if bgrewriteaof is used when aof is off. client pause now has end time and type (write or all) per purpose. the different pause purposes are client pause command, failover and shutdown. if clients are unpaused for one purpose, it doesn't affect client pause for other purposes. for example, the client unpause command doesn't affect client pause initiated by the failover or shutdown procedures. a completed failover or a failed shutdown doesn't unpause clients paused by the client pause command. notes: debug restart doesn't wait for replicas. we already have a warning logged when a replica disconnects. this means that if any replica connection is lost during the shutdown, it is either logged as disconnected or as lagging at the time of exit. fixes #9693 </desc> <cmt> add test case for shutdown with slow replica </cmt> <cmt> corrections to test case for shutdown with slow replica </cmt> <cmt> wait for lagging replicas before shutting down on sigterm </cmt> <iss> [bug] data loss when performing a graceful master shutdown under high load </iss>",wait for replicas when shutting down
3965,"<desc> what this pr does / why we need it: this promotes the podprocessnamespacesharing from beta to ga the process namespace sharing kep specifies the following criteria for beta -> ga graduation: 3 articles describing using shareprocessnamespace in a task. the almight pause container blog post by ian lewis; 10 oct 2017 devops with kubernetes by hideto saito, hui-chuan chloe lee, cheng-yang wu; packt publishing; 31 jan 2019 kubernetes tips and tricks by josh reichardt; practical system administration; 18 december 2018 shareprocessnamespace referenced in documentation for a kubernetes cloud provider (as proxy indicator for feature enabled on cloud provider). google cloud: running a cloud mqtt bridge in kubernetes feature spends at least 2 release in beta. no open bug reports for latest release. does this pr introduce a user-facing change?: pod process namespace sharing is now generally available. the podshareprocessnamespace feature gate is now deprecated and will be removed in kubernetes 1.19. </desc> <cmt> promote feature podshareprocessnamespace to ga </cmt> <cmt> generated code for podshareprocessnamespace ga </cmt>",promote podprocessnamespacesharing feature to ga
3966,"<desc> jira is here. in #9139, we added backward iterator on sessionstore. but there is a bug that  when fetch/backwardfetch the key range, if there are multiple records in the same session window, we can't return the data in the correct order. for example: we have a session window inactivity gap with 10 ms, and the records: key: ""a"", value: ""aa"", timestamp: 0 --> with sessionwindow(0, 0) key: ""b"", value: ""bb"", timestamp: 0 --> with sessionwindow(0, 0) key: ""c"", value: ""cc"", timestamp: 0 --> with sessionwindow(0, 0) key: ""d"" value: ""dd"", timestamp: 100 --> with sessionwindow(100, 100) so, when fetch(""a"" /key from/, ""d"" /key to/), we expected to have [a, b, c, d], but we'll have [c, b a, d ] and the reason is that we pass ""false"" in the ""is forward"" parameter for fetch method, and ""true"" for ""backwardfetch"" method, which obviously is wrong. so, why does the tests can't find this issue? it's because the test data we provided doesn't have multiple data in the same session window. in this pr, i fixed the issue, and add tests to improve the test coverage. </desc> <cmt> kafka-13212: add support infinite query for session store </cmt>",fix inmemorysessionstore#fetch/backwardfetch order issue
3967,"<desc> aclk-ng doesn't really need the protobuf and cxx compiler. it is the new cloud protocol/architecture who needs it. this pr allows building aclk-ng without a new cloud. default behavior adds new cloud support if possible. this can be overridden by configuring the flag. this will allow us to remove legacy aclk (not maintained anymore) more quickly and thus simplifying the whole thing (code, build system, installer) as the majority of people will be able to build aclk-ng by default. component name build system + aclk + database/sqlite build with --without-new-cloud-protocol, --with-new-cloud-protocol and without flag. build without any flag and missing protobuf should still make aclk-ng available with old json cloud protocol only. </desc> <cmt> new flag for configure </cmt> <cmt> separate new cloud protocol from aclk-ng </cmt> <cmt> makefile separate new cloud protocol </cmt> <cmt> update cxx_linker condition </cmt> <cmt> update ifdefs in database/sqlite* </cmt> <cmt> aclk_rx_msgs enable_new_cloud_protocol </cmt> <cmt> aclk_query enable_new_cloud_protocol </cmt> <cmt> aclk_tx_msgs enable_new_cloud_protocol </cmt> <cmt> aclk.c enable_new_cloud_protocol </cmt> <cmt> update buildinfo with new cloud proto </cmt> <cmt> add data to api/v1/info </cmt> <cmt> update aclk_state command </cmt>",makes new cloud architecture optional for aclk-ng
3968,"<desc> these commits fix some issues discovered by the coverity scan. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [network/upnp] perform nullptr check before using pointers created with a dynamic cast </cmt> <cmt> [network/upnp] fix formatting of <upnp:lastplaybacktime> </cmt> <cmt> [network/upnp] fix validity check for episode number </cmt>",fix coverity scan issues in upnp code
3969,"<desc> hi i just did some work on zh-cn docs feel free to let me know whether something is not qualified for merge, thanks~ </desc> <cmt> fix node_bindings link in simplified chinese document translation </cmt> <cmt> add simplified chinese translation for source code structure </cmt>",fix a dead link and add a new chinese document translation
3970,<desc> additional fixed merge burger menu components into a single component show a badge with no-read messages in the burger button: remove usesidebarclose hook click in home and directory buttons in sidebar using a mobile browser </desc> <cmt> fix: close sidebar on clicking in home and directory </cmt> <cmt> fix: merging burger menus </cmt> <cmt> fix: remove usesidebarclose hook </cmt>,sidebar not closing when clicking in home or directory on mobile view
3971,<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. </desc> <cmt> fix(client): update current challenge for all challenges </cmt> <cmt> fix(client): update success message for all challenges </cmt>,update current challenge and success message for all challenge types
3972,"<desc> uses the patch from #752 and also fixes #747. it's not the prettiest solution but it seems to work. specifically, it handls python 3 strings when they are lazy. </desc> <cmt> added tests for issue 747 in serializer.py </cmt> <cmt> forcing translations of lazy translatable strings in field to_native method </cmt> <cmt> merge latest changes from master. </cmt> <cmt> clean up test case. </cmt> <cmt> handle python 3 strings and lazy strings. </cmt> <cmt> merge latest changes from master. </cmt> <iss> make sure lazy translatable string get translated by the serializer fields </iss>",issue 747 lazy strings serialized
3973,"<desc> bump go.d.plugin version to v0.26.2 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.26.2 </desc> <cmt> packaging: bump go.d.plugin version to v0.26.2 </cmt> <cmt> packaging: update go.d.plugin checksums </cmt>",update go.d.plugin version to v0.26.2
3974,"<desc> description: this pr adds more parameters to the dsmr sensor component (dutch smart meters), as these are supported by the dsmr_parser library. added: power consumption/production per phase (l1,l2,l3) voltage swells & sags per phase total count of (long) power failures example entry for configuration.yaml (if applicable): sensor: - platform: dsmr dsmr_version: 4 group: meter_readings: name: meter readings entities: - sensor.power_consumption_phase_l1 - sensor.power_consumption_phase_l2 - sensor.power_consumption_phase_l3 - sensor.power_consumption_low - sensor.power_consumption_normal - sensor.power_production_low - sensor.power_production_normal - sensor.long_power_failure_count - sensor.voltage_swells_phase_l1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass (unfortunately i don't have this as a running setup, could someone give it a shot?) </desc> <cmt> add more parameters for dsmr component </cmt> <cmt> add suiting icon for power failure </cmt> <cmt> add suiting icon for swells & sags </cmt>",add more parameters for dsmr sensor
3975,"<desc> in the react-select library (the latest one, 1.0.0-beta12), select.js uses export default. when i tried using import * as select from 'react-select'; react would throw an invariant violation: element type is invalid, saying that the type was object. changing the type definitions to use export default, and changing the import statement above to import select from 'react-select'; fixes the issue. </desc> <cmt> update react-select to export select by default </cmt> <cmt> update react-select tests to match </cmt>",use export default to match library
3976,"<desc> a lot of people (including me!) seemed to miss the installation instruction, especially the protobuf compilation step, when trying out the tutorial or other files for the first time. i hope this would make the tutorial clearer and avoid future confusion. related issues: #1562, #1591, #1595, #1604 </desc> <cmt> add installation link to jupyter notebook tutorial </cmt> <cmt> also use the url link to github because *.md files are not </cmt> <cmt> rendered when using jupyter notebook </cmt> <cmt> move up installation link in obj detection readme </cmt>",make object detection's installation instruction more obvious
3977,"<desc> this pull request improves the runtime representation of protocol conformance records and type metadata records in several ways: move conformance kind into the low bits of the witness table reference, and be explicit about the remaining reserved kind reference objective-c class objects indirectly, so the runtime can fix them up eliminate typemetadatarecordkind::uniquedirectclass, which is no longer necessary use nominal type descriptors whenever we can, reducing the number of typemetadatarecordkind cases to 3 (nominal type descriptor, indirect objective-c class object, and nonuniqued foreign type metadata). pack the kind into the lower bits of type references in protocol conformance records and type metadata records. eliminate the ""flags"" word from protocol conformance records, but leave the word reserved for conditional requirements. </desc> <cmt> [runtime] add ""reserved"" protocol conformance kind and ignore it. </cmt> <cmt> the protocol conformance record has two bits to describe how the </cmt> <cmt> witness table will be produced. there are currently three states </cmt> <cmt> (direct reference to witness table, witness table accessor, and </cmt> <cmt> conditional witness table accessor). add a reserved case for the </cmt> <cmt> fourth state so the swift 5 runtime will (silently) ignore </cmt> <cmt> conformances using that fourth state, when/if some future swift </cmt> <cmt> uses it. </cmt> <cmt> [runtime] rename the segment for protocol conformance records. </cmt> <cmt> the format of protocol conformance records will be changing in swift 5, so </cmt> <cmt> rename the segment (from, e.g., __swift2_proto to __swift5_proto) to allow </cmt> <cmt> swift < 5 and swift 5+ runtimes to coexist. </cmt> <cmt> [runtime] move conformance kind into low bits of witness table reference. </cmt> <cmt> move the 2-bit conformance reference kind from the conformance flags (which </cmt> <cmt> is meant to go away) into the lower two bits of the witness table offset. </cmt> <cmt> [runtime] reference objc class objects indirectly in conformance records. </cmt> <cmt> within conformance records, reference objective-c class objects </cmt> <cmt> indirectly so the runtime can update those references appropriately. </cmt> <cmt> we don't need to do this for classes with swift metadata. </cmt> <cmt> [runtime] eliminate the uniquedirectclass metadata record kind. </cmt> <cmt> now that references to objective-c class objects are indirected </cmt> <cmt> (via uniqueindirectclass), classes with swift type metadata can be </cmt> <cmt> directly referenced (via uniquedirecttype) rather than hopping through </cmt> <cmt> swift_getobjcclassmetadata(). </cmt>",improve representation of protocol conformance records
3978,"<desc> in #3338 , {lightgbm} was rejected from cran for multiple failed submission attempts. as of that submission, the package was failing tests with a version of r instrumented to use valgrind.  this pr attempts to add a ci job that replicates these checks. notes this is a work in progress. i'll add reviewers when i think it's ready. once i confirm that the job fails as it should, i'll try merging in the changes from  if the job takes too long, i'll switch it to an optional job triggered by a comment (like #3402 ) </desc> <cmt> fix int64 write error </cmt> <cmt> attempt </cmt> <cmt> [wip] [ci] [r-package] add ci job that runs valgrind tests </cmt>",fix memory leaks found by valgrind
3979,<desc> -- winrt new audio engine now supports ogg files. -- fixed issue #150 ( -- fixed issue #151 ( </desc> <cmt> added ogg support to audio engine. fixed issues #150 and #151 </cmt> <cmt> added ogg support to audio engine. fixed issues #150 and #151 </cmt> <cmt> added ogg support for windows 10 uwp </cmt> <cmt> updated app guid and disables auto version increment for app cert tests </cmt> <cmt> updated package guid </cmt> <cmt> removed old files. added missing cocos2drenderer.h </cmt> <cmt> removed e option from xcopy of cpp template files </cmt> <cmt> samplers are treated as uniforms </cmt> <cmt> [ci skip][auto]: updating luabinding & jsbinding automatically </cmt>,added ogg support to winrt audio
3980,"<desc> i had to redo how flags were handled for opencl, and in the process i quite likely broke something on the *nix side. i think the template i've set up is more in line with autotools best practices ( unfortunately, with these changes os x/opencl compiles, but the output of the binary is garbage, as opposed to crashing. :( </desc> <cmt> fix missing ""allheaders.h"" when compiling with --enable-opencl on os x </cmt> <cmt> fix various clang compilation errors </cmt> <cmt> also fixed a writable strings warning/error. </cmt> <cmt> warning: iso c++11 does not allow conversion from </cmt> <cmt> string literal to 'char *' [-wwritable-strings] </cmt> <cmt> several were of this form and fixed as the compiler suggested: </cmt> <cmt> openclwrapper.cpp:2411:33: error: non-constant-expression cannot be narrowed </cmt> <cmt> from type 'int' to 'size_t' (aka 'unsigned long') in initializer list </cmt> <cmt> [-wc++11-narrowing] </cmt> <cmt> size_t local_work_size[] = {block_size}; </cmt> <cmt> ^~~~~~~~~~ </cmt> <cmt> openclwrapper.cpp:2411:33: note: insert an explicit cast to silence this issue </cmt> <cmt> size_t local_work_size[] = {block_size}; </cmt> <cmt> ^~~~~~~~~~ </cmt> <cmt> static_cast<size_t>( ) </cmt> <cmt> should have low impact on other platforms/compilers. the change makes </cmt> <cmt> the code more correct. </cmt> <cmt> get opencl to compile on os x </cmt> <cmt> however, the output of the opencl build is garbage.... </cmt>",get --enable-opencl to compile (but not work)
3981,"<desc> i added a new gulpfile sample from gulp 4.0 branch, more simple for new developers, who may not know about sourcemaps or coffee script, in my opinion and a version of it using es2015 with side notes about babel installation requirement. [ issue  #1550 ] split view recommended </desc> <cmt> added new gulpfile sample to readme fiel with es2015 version </cmt> <cmt> .babelrc file mention added </cmt>",added new gulpfile sample to readme file with es2015 version
3982,<desc> this pr adjust some smaller design details so ant components fit well into our app: data-time component: </desc> <cmt> move styling import to main.less and add var overwrites </cmt> <cmt> refine input design </cmt> <cmt> adjust input color </cmt> <cmt> adjust input colors to match </cmt>,update ant variables to fit redash's style
3983,"<desc> closes #11400 this pr makes two changes: first, it fixes the ""permalink"" option to generate valid urls on direct messages, where it was broken. the second change is to make it so that permalinks on dms work for both users on the conversation, regardless of which username is on the url itself. </desc> <cmt> fixed permalink generation on direct messages </cmt> <cmt> permalinks on dms now work for both users regardless of what username is on the url </cmt> <cmt> simplified code </cmt> <iss> permalink to direct message shows 404 error page </iss>",invalid permalink urls for direct messages
3984,"<desc> this pr follows #4658 it provides : 2 examples : typescript & typescript-vuex vue-app typings update : process.server, process.client, process.browser, process.static with current ts state, only documentation should be needed to have the feature ready for release. here is some things that can be done but not mandatory (imo) for feature release : typings for nuxt configuration file, modules, plugins and everything else that should be typed in the nuxt application test improvements regarding typescript fixtures </desc> <cmt> fix(resolver): throw last error for requiremodule </cmt> <cmt> fix(resolver): disable esm for typescript files by default </cmt> <cmt> fix(resolver): disable esm for ts files by default </cmt> <cmt> chore(server): refactor error handling for servermiddleware </cmt> <cmt> wip: add runtime ts tests </cmt> <cmt> feat: add nuxt-ts distribution </cmt> <cmt> chore: update yarn.lock </cmt> <cmt> add tslint & typescript dependencies </cmt> <cmt> add nuxts alias for nuxt-ts binary </cmt> <cmt> use forktschecker by default in a nuxt_ts environment </cmt> <cmt> nuxt.config.ts as default configuraiton file in nuxt_ts environment </cmt> <cmt> update & fix typescript fixture tests </cmt> <cmt> add a .ts module to the typescript fixture + test that it's required </cmt> <cmt> update typescript example with nuxt-ts-edge </cmt> <cmt> rename typescript example to typescript-vuex </cmt> <cmt> simpler typescript example with a helloworld component </cmt> <cmt> extends nodejs.process through vue-app typings </cmt>",typescript examples + improve vue-app typings
3985,"<desc> rollouts were not working for es and ars agents (which do not have a self.workers prop). this pr fixes this issue (#7136 ). issue #7136 closes #7136 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> fix. </cmt> <cmt> fix issue #7136. </cmt> <iss> [rllib] cannot rollout es after training. </iss>",rollout not working for es and ars.
3986,<desc> see #1981 (comment) what about a pull request with the test? makes sense. i'll prep a pr. </desc> <cmt> tests: add test for </cmt> <cmt> build-sys: add test-06-selinux to dist </cmt> <cmt> this is a follow-up to </cmt>,add test for https://github.com/systemd/systemd/issues/1981
3987,"<desc> cherry-pick #31167 to 5.3 because the refactoring that broke this went in before the branch date. </desc> <cmt> lazily associated a silremarkstreamer with an llvmcontext at irgen time </cmt> <cmt> corrects a mistake introduced in #31106 </cmt> <cmt> i was under the impression that the llvmcontext for an instance of </cmt> <cmt> llvm::remarks::remarkstreamer was somehow just scratch-space. it turns </cmt> <cmt> out the asmprinters don't gather remarks data from modules, they gather </cmt> <cmt> it from the remark streamer associated with the module's context. </cmt> <cmt> thus, we cannot have the module's context be distinct from whatever </cmt> <cmt> context the streamer is eventually associated with. </cmt> <cmt> in order to bring these two systems back into harmony, introduce a simple </cmt> <cmt> ownership contract to silremarkstreamer. that is, it starts owned by </cmt> <cmt> a silmodule, in which case the silremarkstreamer holds onto the </cmt> <cmt> underlying llvm object as the optimizer emits remarks. when it comes </cmt> <cmt> time to irgen the module, then and only then do we install the streamer </cmt> <cmt> on the module's context. this tranfers ownership of the underlying llvm </cmt> <cmt> streamer to llvm itself, so it acts as a consuming operation. when we </cmt> <cmt> are about to perform ir generation, the silmodule will be expiring </cmt> <cmt> anyways, so the streamer was already about to be destroyed. </cmt> <cmt> we're just putting it to better use doing its job. </cmt> <cmt> correct the ownership model for sil-opt </cmt> <cmt> destroying the sil remark streamer after transferring ownership to llvm </cmt> <cmt> is frought. for one, the streamer holds the remark file's stream open. </cmt> <cmt> destroying it early doesn't accomodate sil-opt, which transfers control </cmt> <cmt> to llvm before running passes that emit remarks. </cmt> <cmt> instead, just take a reference to the context that the streamer gets </cmt> <cmt> parented onto. if the remarks streamer infrastructure could just hold </cmt> <cmt> the file stream open for us, we wouldn't have to do any of this. </cmt>",lazily associate a silremarkstreamer with an llvmcontext
3988,"<desc> adds a new loader type, ""desconstuctedromloader"", which is used for the typical ""deconstructed"" game dumps we see with several nsos (main, rtld, sdk, etc.) and an .istorage file for the romfs this is now decoupled from the nso loader, which is just that: an nso loader this will make it easier to support such things as a separate nca loader in the future the loader is now a bit ""smarter"", it won't automatically try to load any rtld, sdk, etc. file it sees </desc> <cmt> nso: remove code specific to directory loading. </cmt> <cmt> loader: refactor to also pass filepath into identifytype. </cmt>",separate nso loading from desconstuctedromloader
3989,"<desc> a timeout while waiting for dns resolution can cause on_error to send an error response, and if dns resolution happens to finish right afterwards then on_getaddr will get called and it will try to send another error response. </desc> <cmt> connect: cancel hostinfo_getaddr on error (especially timeout). </cmt> <cmt> a timeout while waiting for dns resolution can cause on_error to send an </cmt> <cmt> error response, and if dns resolution happens to finish right afterwards then </cmt> <cmt> on_getaddr will get called and it will try to send another error response. </cmt> <cmt> merge with master. </cmt>",cancel hostinfo_getaddr on error (especially a timeout).
3990,"<desc> along with fixing #11004, this pr also removes or replaces any mentions of cli/js under the typescript section as that folder no longer appears to exist and afaik any ts has been replaced with js a while back. i could make a javascript section for any js code but i don't believe that is necessary as it'd be mostly repeating the typescript section. </desc> <cmt> update style_guide.md </cmt> <cmt> fmt for style_guide </cmt>",docs(contributing/style_guide) fix #11004 and remove mentions of cli/js
3991,"<desc> fix regression introduced with #6178 setting branches to only: master prevented all tag builds. it's also noted in travis ci documentation that it's expected behavior: note that safelisting also prevents tagged commits from being built. if you consistently tag your builds in the format v1.3 you can safelist them all with regular expressions, for example /^v\d+.\d+(.\d+)?(-\s*)?$/. this patch ensures that release tags are whitelisted, and that deploy job runs with latest node.js version (if not specified travis tries to install project with its default which is v0.10). additionally fix mocha config property name. current setting works, but it was not intended to work -> mochajs/mocha#3936 (comment) for a meantime i've workaround v1.45.0 release with temporary patch in context of a branch ->  is this ready for review?: yes is it a breaking change?: no </desc> <cmt> ensure release tags are build </cmt> <cmt> ensure latest version of node.js </cmt>",fix travis ci deploy config
3992,<desc> fixes #4121 </desc> <cmt> fix content-type for job.stdout.add </cmt> <cmt> docker-dco-1.1-signed-off-by: victor vieux <victor.vieux@docker.com> (github: vieux) </cmt> <cmt> fix content-type for legacy </cmt> <cmt> docker-dco-1.1-signed-off-by: victor vieux <victor.vieux@docker.com> (github: vieux) </cmt> <iss> docker v0.8  remote api (/images/json) reports wrong content-type (text/plain) </iss>,fix header content type api
3993,<desc> two final semantic adjustments for classes with global actors to bring the behavior in line with se-0316: global-actor-qualified classes are implicitly sendable global actor isolation on a class must correspond to its superclass's isolation </desc> <cmt> [se-0316] global actor qualification on a type implies sendable. </cmt> <cmt> [se-0316] check global actor isolation of a class vs. its superclass. </cmt> <cmt> close an actor-isolation hole where we permitted a class to have a </cmt> <cmt> different global actor isolation than its superclass. </cmt>,more semantic adjustments for classes and global actors
3994,"<desc> doc pr sync transform-object-rest-spread's readme with the one on babel.github.io i removed the quote which mentions #4755 because it's already fixed, and i fixed some broken links as well (repl link can't be navigated from github and spec link was gone). </desc> <cmt> update transform-object-rest-spread's readme from its website [skip ci] </cmt> <cmt> sync this readme with </cmt> <cmt>  </cmt> <cmt> i removed the quote which mention babel/babel#4755 because it's </cmt> <cmt> already fixed. </cmt> <cmt> fix broken link [skip ci] </cmt>",update transform-object-rest-spread's readme from babel.github.io [skip ci]
3995,"<desc> update the i2p seeds with the latest ones i can connect to (feedback welcome). update the i2p doc with frequently asked and reported info: ibd speed and running with other networks. </desc> <cmt> contrib, p2p: update i2p hardcoded seeds </cmt> <cmt> doc: add info to i2p.md about ibd time and multiple networks </cmt>",update i2p hardcoded seeds and docs for 22.0
3996,"<desc> i removed the previous reference to lib.d.ts, so hopefully this will pass the tests now. </desc> <cmt> updated for meteor 0.8.3 using new auto-generation script that parses the official meteor api.js documentation file.  updated the test file accordingly. </cmt> <cmt> fixed test file reference to meteor def file. </cmt> <cmt> remove reference to lib.d.ts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> updated for meteor 0.9.1 </cmt> <cmt> minor edits to readme </cmt> <cmt> fixed the comment at the top </cmt>",updated meteor.d.ts and meteor-tests.ts for meteor 0.9.1.
3997,"<desc> allow_no_indices is now true by default and, as before, can be set in the _eql request as a parameter. irrespective of allow_no_indices value, throw verification_exception when there is no index validated from the provided patterns. if allow_no_indices is false and there is a pattern that results in a no index being returned, the elasticsearch's mapping_exception is thrown. fixes #62986. </desc> <cmt> allow all indices options variants </cmt> <cmt> irrespective of allow_no_indices value, throw verificationexception when </cmt> <cmt> there is no index validated </cmt> <iss> eql: `allow_no_indices` behavior </iss>",make allow_no_indices true by default
3998,<desc> closes #1273 </desc> <cmt> prove that to_double() is invoked with illegal input </cmt> <cmt> fix compute_float_64 being called with out of range exponent </cmt> <cmt> rename function after github issue </cmt> <iss> generic/numberparsing.h compute_float_64() invoked with out of range power </iss>,fix segfault in numberparsing #1273
3999,"<desc> this change introduces a new cli tool that allows users to reset the password for the elastic user, setting it to a user defined or an auto-generated value. resolves: #70113 depends on:  #74890 </desc> <cmt> add a tool for creating enrollment tokens </cmt> <cmt> this change introduces a cli tool that can be used to create </cmt> <cmt> enrollment tokens. it doesn't require credentials, but simply </cmt> <cmt> write access to the local filesystem of a node. it uses an </cmt> <cmt> auto-generated user in the file-realm with superuser role. </cmt> <cmt> for this purpose, this change also introduces a base class for a </cmt> <cmt> cli tool that can be used by any cli tool needs to perform actions </cmt> <cmt> against an es node as a superuser without requiring credentials </cmt> <cmt> from the user. it is worth noting that this doesn't change our </cmt> <cmt> existing thread model, because already an actor with write access </cmt> <cmt> to the fs of an es node, can become superuser (again, by </cmt> <cmt> adding a superuser to the file realm, albeit manually). </cmt> <cmt> elastic user password reset cli tool </cmt> <cmt> this change introduces a new cli tool that allows users to reset </cmt> <cmt> the password for the elastic user, setting it to a user defined </cmt> <cmt> or an auto-generated value. </cmt> <cmt> resolves: #70113 </cmt> <cmt> qa test </cmt> <cmt> add docs </cmt> <iss> elastic user password reset cli tool </iss>",reset elastic password cli tool
4000,<desc> disable kvstore for single machine and single gpu add a section on the readme to explain about the performance </desc> <cmt> [python] disable kvstore for single gpu to improve performance </cmt> <cmt> [python] bugfix </cmt> <cmt> [doc] update </cmt>,image-classification performance for multiple gpus
4001,<desc> this pr pushes out updates in the rocm stream executor implementation from the rocm tf fork. most of the changes are cosmetic (clang-format related). the lone functional change is the addition of conv 3d support. please review and merge. thanks. @tatianashp @whchung @chsigg </desc> <cmt> cosmetic / formating changes </cmt> <cmt> sync changes from the rocm repo </cmt> <cmt> sync changes related to adding support for 3d convolutions </cmt>,rocm stream executor implementation updates
4002,"<desc> same as #39996. since ios platform is not buildable at master at the moment, i've managed to test only library selection in editor. for ios platform it is not allowed by appstore to use .dylib directly, so not loading them at this moment makes sense. but since the release of ios 8 developers are allowed to use frameworks, which essentially are dylibs packed with info.plist file and additional install_name value set to them. because of that .dylibs can be replaced with .framework or .xcframework files built with xcode. they can also be turned into .framework automatically. this way the dynamic library loading will be available for ios platform. this repo contains the starter project, allowing the creation of .a, .dylib, .framework or .xcframework, which could be used for gdnative library in project. i've tested this pr with both statically and dynamically linked libraries in different combinations, running on multiple devices that's available to me. i've also tested the way .framework generation works and how appstore handles resulting application. i haven't found any issues, but i could have missed some edge case. </desc> <cmt> gdnative: support dynamic loading of ios frameworks </cmt> <cmt> ios export: turn .dylib into .framework on export </cmt> <cmt> ios export: updated info.plist. framework embedding. fixes for search paths </cmt> <cmt> gdnative editor: support selecting frameworks for ios </cmt>",add support of ios's dynamic libraries to gdnative
4003,<desc> for testing we want to be able to simulate a ray cluster using a number of docker instances running on a single host. this change adds scripts to boot a cluster matching a specific configuration and to run a test script on that cluster. other requirements: test scripts should run from the command line as well as from within the cluster environment one continuous integration host should simultaneously run tests from different ray revisions </desc> <cmt> run test workloads for a docker cluster </cmt> <cmt> better manage docker image versions </cmt>,add multinode tests by simulating multiple nodes using docker.
4004,"<desc> closes #8359 cypress now resolves and loads tsconfig.json for typescript projects starting from the plugins directory ts-node resolves the tsconfig.json starting from the current working directory (cwd) by default. this means using cypress/tsconfig.json won't work to specify typescript config for cypress. in reality, this only affected a couple options in tsconfig.json because only a couple options (e.g. ""esmoduleinterop"", ""downleveliteration"") affect the runtime. any non-runtime options would take affect in a user's ide because it would resolve the tsconfig.json starting from the directory of the opened file. this pr changes it so ts-node will now start looking for the tsconfig.json from the plugins directory. that is cypress/plugins by default or the dirname of the plugins file path if a custom one is provided. for example, if the ""pluginsfile"" is set to <project root>/some/other/path/to/plugins.js, it will start looking in <project root>/some/other/path/to. users will now see runtime options in cypress/tsconfig.json take effect, whereas before they were ignored. has the original issue been tagged with a release in zenhub? </desc> <cmt> fix default esmoduleinterop test </cmt> <cmt> was erroneously passing because it wasn't written correctly </cmt> <cmt> fix: resolve tsconfig.json for plugins process from the plugins directory </cmt> <iss> cypress doesn't evaluate `""esmoduleinterop"": true` in cypress/tsconfig.json? </iss>",resolve tsconfig.json for plugins file from the plugins directory
4005,"<desc> we have an issue where it is possible to an incident snapshot to query outside of retention. this pr fixes this issue by amending the incident start time calculation with a check that will bring the start time to the earliest point in time that we can query in snuba. in addition, if the end time is now before the start time, we just make it the same and this ends up returning no relevant data for the incident. </desc> <cmt> adding retention period check when calculating incident start/end times </cmt> <cmt> adding retention period check when calculating incident start/end times </cmt> <cmt> adding retention period check when calculating incident start/end times </cmt>",respect retention period during incident start/end calculation
4006,"<desc> this pr makes a few changes: print out const param defaults in ""lifetime ordering"" errors rather than discarding them update is_simple_text to account for const params when checking if a type has no generics, this was causing a note to be failed to add to an error message fixes some diagnostic wording that incorrectly said there was ordering restrictions between type/const params despite the const_generics_defaults feature gate is active </desc> <cmt> make lifetime ordering error pretty print const param defaults </cmt> <cmt> fix missing note on type mismatch error diagnostics </cmt>",fix some diagnostic issues with const_generics_defaults feature gate
4007,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). getsource() is called with callback in async mode:  safestring exported on runtime:  webloader extends loader class:  increase the version number in the header if appropriate. bumped to 3.1, although all these changes are likely compatible with many previous versions. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add typings for async getsource and runtime.safestring class </cmt> <cmt> webloader extends loader, set version to 3.1 </cmt>",add missing typings for nunjucks
4008,<desc> eliminate undefs during canonicalization by finding an def-free path from the escaping value to a value defined in the node dominated that dominates the preheader. this is a first in the series of prs to completely eliminate undefs during sese loop canoncialization. partially resolves sr-7765. </desc> <cmt> convert escapingvalues to map that tracks arguments at preheader. </cmt> <cmt> eliminate undefs wherever possible by finding def-free paths. </cmt> <cmt> add a flag to control undef elimination. </cmt> <cmt> fixed the stale comment in def-free path detection. </cmt>,eliminate undefs wherever possible by finding def-free paths through loop.
4009,"<desc> close #20688. according to our docs of cookies api (which is derived from chrome extension's cookies api), the name should be optional. and for expirationdate, it should pass base::time() when the option is omitted:  otherwise it would set a cookie the expires now instead of setting a session cookie, and as result cookies.set api does not work correctly without setting expirationdate. this is a regression since 7.x. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fix cookies.set not working correctly when name or expirationdate is omitted. </desc> <cmt> fix: correctly set cookie date </cmt> <cmt> fix: name is not required for setting cookie </cmt> <cmt> test: clear cookie after each cookie test </cmt> <cmt> test: should test session property </cmt> <iss> session.cookies.set is broken in 7.0 </iss>",name and expirationdate should be optional when setting cookie
4010,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> update index.d.ts </cmt> <cmt> added 'textalign' prop on textinputprops. </cmt> <cmt> added test </cmt> <cmt> ... </cmt>,added 'textalign' prop to textinput definition
4011,"<desc> a small change: when logging the ""node.js integration with remote content"" warning, include the window.location to make it easier for developers to see what content triggered the warning. inspired by #12049.  npm test passes pr title follows semantic [commit guidelines] </desc> <cmt> docs: fix typo </cmt> <cmt> feat: add location url to node+remote warning </cmt>","add location url to ""node.js integration with remote content"" warning"
4012,<desc> part of #28947 the new wip file watcher can be activated using the temporary files.usensfwfilewatcher setting. </desc> <cmt> initial nsfw prototype </cmt> <cmt> get nsfw file watcher sending events back </cmt> <cmt> convert nsfw rename events to delete and create events </cmt> <cmt> improve nsfw types </cmt> <cmt> add throttleddelayer and event normalization </cmt> <cmt> support ignored paths </cmt> <cmt> improve typings </cmt> <cmt> allow nsfw file watcher to work alongside others </cmt> <cmt> start working on multiple root file watcher support </cmt> <cmt> improve nsfw logging </cmt> <cmt> support basic multi root watching </cmt> <cmt> fix test compilation </cmt>,add opt-in multi-root aware file watcher based on axosoft/nsfw
4013,"<desc> fixed #3460 the etcd and nacos plugins didn't set telemetry instance id, that cause telemetry module rises npe. </desc> <cmt> update docker-entrypoint.sh </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> set telemtry instance id in etcd and nacos plugins </cmt> <iss> the application that 'docker-entrypoint.sh' generated make skywalking 6.3 npe </iss>",set telemetry instanced id for etcd and nacos plugin
4014,<desc> merge #6547 from master to 3.1 branch to fix up source compatibility. </desc> <cmt> effectively revert #5778 </cmt> <cmt> this reverts the contents of #5778 and replaces it with a far simpler </cmt> <cmt> implementation of condition resolution along with canimport.  when </cmt> <cmt> combined with the optimizations in #6279 we get the best of both worlds </cmt> <cmt> with a performance win and a simpler implementation. </cmt> <cmt> fix a crasher </cmt> <cmt> restore local type declarations list </cmt>,merge #6547 to 3.1 branch
4015,"<desc> this pr is a second attempt at something i tried to do in #57525. i have revised the process according to guidance from @mbohlool. the purpose of this pr is for me to learn the process of updating the kubernetes api reference documentation, and then to document that process. i'm working on getting the process documented in pr 6366 in the kubernetes/website repository. here's a preview of the new topic. in the docs, i would like to refer to this pr as an example. so i have kept the change simple: fix one typo. related issues: kubernetes/website#921 kubernetes/website#922 in the future, we might want to make the doc generation process a bit more automatic. but for now i think it's important to get the current process documented. release note: </desc> <cmt> fix typo in field description. </cmt> <cmt> generate specs after fixing typo in documentation. </cmt>","fix typo and generate specs, so docs can be regenerated."
4016,"<desc> github does not currently recognize the license text as mit (it currently says ""view license"" instead of ""mit license"") the license parser is very persnickety.  this particular rendition is from vuejs which is an mit-licensed project according to github this also addresses an issue where the package.json files field includes license but not license.md </desc> <cmt> reformat license.md to appease github </cmt> <cmt> rename license file </cmt>",use standard license text for mit license
4017,"<desc> update i18n, json, and sassc to their latest versions. </desc> <cmt> update i18n to the latest version </cmt> <cmt>  </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/i18n-1.6.0/lib/i18n/backend/base.rb:146: warning: the last argument is used as the keyword parameter </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/i18n-1.6.0/lib/i18n/backend/base.rb:84: warning: the last argument is used as the keyword parameter </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/i18n-1.6.0/lib/i18n.rb:179: warning: for t' defined here </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/i18n-1.6.0/lib/i18n.rb:179: warning: for translate' defined here </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/i18n-1.6.0/lib/i18n.rb:205: warning: the last argument is used as the keyword parameter </cmt> <cmt>  </cmt> <cmt> was fixed by ruby-i18n/i18n@2920107fbfbf8778e5e197b7439d24c8a3720762 . </cmt> <cmt> update json to the latest version </cmt> <cmt>  </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/json-2.1.0/lib/json/common.rb:156: warning: the last argument is nil, treating as empty keywords </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/json-2.1.0/lib/json/common.rb:156: warning: the last argument is used as the keyword parameter </cmt> <cmt>  </cmt> <cmt> was fixed in 2.2.0. </cmt> <cmt> update sassc to the latest version </cmt> <cmt>  </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/ffi-1.11.1/lib/ffi/library.rb:275: warning: method redefined; discarding old _context_get_included_files </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/ffi-1.11.1/lib/ffi/library.rb:275: warning: method redefined; discarding old list_get_length </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/ffi-1.11.1/lib/ffi/library.rb:275: warning: method redefined; discarding old list_get_value </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/ffi-1.11.1/lib/ffi/library.rb:275: warning: method redefined; discarding old _make_data_context </cmt> <cmt> /home/u/.rbenv/versions/2.7.0-dev/lib/ruby/gems/2.7.0/gems/ffi-1.11.1/lib/ffi/library.rb:275: warning: method redefined; discarding old version </cmt> <cmt>  </cmt> <cmt> were fixed in sassc 2.2.1. </cmt>",update some gems to avoid warnings in ruby head
4018,"<desc> i have followed (at least) the pr section of the contributing guide. as discussed in #18873 this pr changes the default behaviour of the autocomplete control to prevent focus/open when the clear button is clicked. this could be further customised by providing a boolean option to re-enable the previous behaviour, but that hasn't yet been discussed and is not in this pr. resolves #18873 </desc> <cmt> prevent focusing the input on clear </cmt> <cmt> test case </cmt> <iss> [autocomplete] provide options to control behaviour when cleared </iss>",prevent focusing control / opening dropdown on clear
4019,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add *vendor* property to product </cmt> <cmt> remove duplicated method definition </cmt> <cmt> add myself to ""definitions by"" section </cmt>",add vendor property to product and remove duplicated method definition
4020,<desc> added a getnode function. made little changes to the insert function in order to make it more expresive added comments </desc> <cmt> added getnode function and made changes to insert function </cmt> <cmt> deleted binary_seach_tree </cmt>,rename binary_search_tree and added a getnode function
4021,<desc> fix for bug #3215 by introducing have_qtkit as a separate mode from have_quicktime. changes are pulled in from fixingqtkitpublic branch and discussion </desc> <cmt> fix for bug bug #3215. added have_qtkit as a separate mode from have_quicktime </cmt> <cmt> added have_qtkit to tests </cmt>,bug #3215 fixing qt kit public2.4
4022,"<desc> remove an unnecessary refsetcache.prototype.has() call from globalimagecache.getdata we can simply attempt to get the data directly, and instead check the result, rather than first checking if it exists. extract the actual sending of image data from the partialevaluator.buildpaintimagexobject method after prs #10727 and #11912, the code responsible for sending the decoded image data to the main-thread has now become a fair bit more involved the previously. to reduce the amount of duplication here, the actual code responsible for sending the data is thus extracted into a new helper method instead. </desc> <cmt> remove an unnecessary refsetcache.prototype.has() call from globalimagecache.getdata </cmt> <cmt> we can simply attempt to get the data *directly*, and instead check the result, rather than first checking if it exists. </cmt> <cmt> extract the actual sending of image data from the partialevaluator.buildpaintimagexobject method </cmt> <cmt> after prs 10727 and 11912, the code responsible for sending the decoded image data to the main-thread has now become a fair bit more involved the previously. </cmt> <cmt> to reduce the amount of duplication here, the actual code responsible for sending the data is thus extracted into a new helper method instead. </cmt>",a couple of small image caching/sending improvements
4023,<desc> hello! i would like to contribute this handwired layout. please let me know if it can be included and what revisions need to be made in order to do so. i am fairly new to github and will be more careful about my commits in the future so that you don't get multiple for each distinct change. thank you for your time! </desc> <cmt> add existing file </cmt> <cmt> add new keyboard layout - initial commit </cmt> <cmt> add new keyboard layout - initial commit </cmt> <cmt> revised readme.md </cmt>,additional custom handwired layout - space oddity
4024,"<desc> this pr updates the autoscaler to use the newly added drain node api from #19350. the strategy is to just call the drain api before making the node provider terminate request. closes #19961 closes #14129 i've run scripts/format.sh to lint the changes in this pr. added logic to test_autoscaler::testdynamicscaling to test error handling for the drainnode api. added a new integration test using fakemultinode provider to test the autoscaler's usage of the drainnode api. the test mocks out the node provider's terminate_node logic so that node termination can be handled by the drainnode api. the test also checks that no ""node removed"" message is generated. </desc> <cmt> wip </cmt> <cmt> draft </cmt> <cmt> use bytest for node id </cmt> <iss> terminated idle nodes generate a misleading warning </iss> <iss> [bug] use newly added drain node interface in autoscaler </iss>",use drain node api in autoscaler before terminating nodes
4025,"<desc> introduces udppacketwriter interface that can be used to perform writes in batched/passthrough modes by using quicgsobatchwriter implementation from quiche extension. udp gso (generic segmentation offload) was introduced in linux at version 4.18. it allows batch-writing of multiple messages into a single payload and sending these messages along as a batch in a single sendmsg syscall. currently, envoy performs the sending of messages using simple sendmsg implementation in pass-through mode, i.e. no support for batch writing. with this change, udplistener can use udppacketwriter interface as a defaultwriter or a gsobatchwriter to perform pass-through or batched writes respectively. detailed description of the changes can be found in the design document, here. risk level: low, not in use added udp_listener_impl_batched_writes_test, to verify that multiple packets of varying sizes are batched/flushed as per gso specifications while using udpgsobatchwriter. modified existing tests, to verify that udpdefaultwriter performs writes in pass-through mode. ran all tests. all 677 tests passed successfully. > bazel test //test/... ... executed 677 out of 677 tests: 677 tests pass. info: build completed successfully, 2355 total actions docs changes: none release notes: none fixes: #11925 </desc> <cmt> first batch of changes for udp_gso implementation </cmt> <cmt> designdoc [ </cmt> <cmt> - creates udppacketwriter interface to perform writes in both ""batched or passthrough"" modes </cmt> <cmt> > udppacketwriter provides writetosocket(...), along with other functions similar to that of quic::quicpacketwriter </cmt> <cmt> > udppacketwriterfactory, udppacketwriterconfigfactory interfaces were also introduced to specify factories. </cmt> <cmt> - adds udpdefaultwriter to perform default write behavior using udppacketwriter </cmt> <cmt> > udpdefaultwriter currently uses network::utility::writetosocket(...) implementation to send packets using sendmsg. </cmt> <cmt> > related factories: udpdefaultwriterfactory, udpdefaultwriterconfigfactory </cmt> <cmt> - adds udpgsobatchwriter to perform batched/passthrough write behavior using udppacketwriter and quic::quicgsobatchwriter implementations. </cmt> <cmt> > udpgsobatchwriter currently uses quicgsobatchwriter::writepacket(...) implementation to send packets using sendmsg. </cmt> <cmt> > related factories: udpgsowriterfactory, udpdefaultwriterconfigfactory </cmt> <cmt> - adds quicenvoypacketwriter interface to convert udppacketwriter interface to quicpacketwriter interface </cmt> <cmt> - also, now initializing quic_dispatcher under activequiclistener with udp_packet_writer based quicpacketwriters instead of the envoyquicpacketwriter </cmt> <cmt> - replaced utility::writetosocket(...) implementations under udp_listener_impl and udp_proxy_filter with udppacketwriter implementation. </cmt> <cmt> - other minor changes: </cmt> <cmt> > added udpwriterconfig under listener.proto to config udp_writer_name </cmt> <cmt> > added get function udppacketwriter() under udplistener </cmt> <cmt> > added get function updpacketwriterfactory() under listenerconfig </cmt> <cmt> > minor fixes to tests just to have passing builds. </cmt> <cmt> using network::udppacketwriter instead of network::udppacketwriterptr in quicenvoypacketwriter </cmt> <cmt> fixed failing tests </cmt> <cmt> - added udp_default_writer_config_lib under listener_lib </cmt> <cmt> - added listenerconfig and udppacketwriterfactory mocks under udp_listener_impl_tests </cmt> <cmt> - fixed active_quic_listener_test failures </cmt> <cmt> - nit: fixed code formatting </cmt> <cmt> - fixed udp_proxy_filter_test. </cmt> <cmt> - added mockudppacketwriter to mock udppacketwriter::writetosocket </cmt> <cmt> - fixed all tests to work with udppacketwriter </cmt> <cmt> - added a separate method writepacket() to perform writes at default socket </cmt> <cmt> - changed writetosocket to take iohandle to write to. </cmt> <cmt> - added get method, to return the socket associated with writer. </cmt> <cmt> - todo: maybe try alternate approach of defining the writer under activesession. </cmt> <cmt> - added a separate udppacketwriter under udpproxyfilter::activesession </cmt> <cmt> associated with the io_handle of the session </cmt> <cmt> - added get function udppacketwriterfactory() under udplistener to provide </cmt> <cmt> access to factory while udp_packet_writer creation </cmt> <cmt> - changed udppacketwriter related constructors to take in network::iohandle </cmt> <cmt> of network::socket as parameters. </cmt> <cmt> - added a get function for the writer iohandle under the packetwriters </cmt> <cmt> - added udp_listener_impl_batch_writer_test to test gsobatchwriter behavior </cmt> <cmt> - added udppacketwriter stats to keep track of buffered and sent payloads </cmt> <cmt> - minor nits in envoy_quic_utils functions </cmt> <cmt> added common library udp_listener_impl_test_base to house common code from udp_listener_impl_tests </cmt> <cmt> - reverted changes to have spearate udppacketwriters per activesession </cmt> <cmt> with udpproxy upstreams </cmt> <cmt> - addressed todos in the code </cmt> <cmt> - cleaned function definitions, added comments </cmt> <cmt> - reduced code duplication </cmt> <cmt> - refined function names </cmt> <cmt> - other minor nits </cmt> <cmt> - updated stats to now derive from quicgsobatchwriter params </cmt> <cmt> - modified comments and other minor nits </cmt> <cmt> - added internalbufferwritelocation struct to store quicpacketbuffer returns </cmt> <cmt> - added k_max_outgoing_packet_size under udp_packet_writer </cmt> <cmt> - added external flush test under udp_listener_impl_batch_writer_test </cmt> <cmt> - minor nits and changes to comments. </cmt> <cmt> minor nit, modiefied writepacket comment </cmt> <cmt> resolved merge conflicts with envoyproxy/envoy->master </cmt> <cmt> minor nits, comments added/modified </cmt>",write performance improvement via udp_gso
4026,<desc> fixes #87072 (the second regression). r? @notriddle </desc> <cmt> fix color for <code> which are not in doc blocks </cmt> <cmt> add gui test to check ayu <code> colors </cmt> <iss> rustdoc: styling regressions from stable to beta </iss>,fix ayu theme <code> color
4027,"<desc> after discussing the possibility of using dual antenna options with the propak6, added information about the gnss-502 antenna as an option to the single gps-703-ggg-hv. </desc> <cmt> added option 2 for novatel gnss dual antenna and image </cmt> <cmt> editing wording for gnss-502 </cmt>",addition of gnss-502 antenna option
4028,"<desc> the recent major updates to faiss included a few api changes which made the c api no longer compile. the changes made (small summary below) aim to make things work again, rather than exposing the latest features. the latter can be done in future prs, and i'll be listening to related issues in the event that someone is interested in them. move indexshards (out of metaindexes_c) into a dedicated module indexshards_c remove getter/setters to unreachable fields and non-existing methods in the latest api reimplement faiss_indexivf_imbalance_factor (to retrieve the same output from the inner invlists) remove faissqueryresult, provide faissrangequeryresult instead minor documentation tweaks the c api was relicensed to mit for consistency with the rest of the project. hopefully this change is desirable, do you agree? </desc> <cmt> [c_api] update impl and interface for v1.5 </cmt> <cmt> - move indexshards to dedicated module indexshards_c.{h|cpp} </cmt> <cmt> - remove getter/setters to unreachable fields </cmt> <cmt> - reimplement faiss_indexivf_imbalance_factor (to use invlists) </cmt> <cmt> - minor indexivf documentation tweaks </cmt> <cmt> - remove queryresult, provide rangequeryresult </cmt> <cmt> [c_api] document faisserrorcode </cmt> <cmt> [c_api] update gpu impl and interface for v1.5 </cmt> <cmt> - remove unavailable method settempmemoryfraction </cmt> <cmt> [c_api] relicense to mit </cmt> <cmt> in accordance to the rest of the project </cmt>",update for compatibility with v1.5
4029,"<desc> there was a 404 page when you click ""additional material"" link. i changed it and added my name to contributors list. </desc> <cmt> add mustafa turhan to contributors list </cmt> <cmt> additional material link fix </cmt>","""additional material"" link fix in readme.tr"
4030,"<desc> the ""category"" in context suggester could be string, number or boolean. however with the changes in version 5 this is failing and only accepting string. this will have problem for existing users of elasticsearch if they choose to migrate to higher version; as their existing mapping and query will fail as mentioned in a bug #22358 this pr fixes the above mentioned issue and allows user to migrate seamlessly. note: providing the null value for a category at index and query time will throw an exception. closes #22358 </desc> <cmt> fix for issue #22358 </cmt> <cmt> fix for issue #22358 </cmt> <iss> context suggestion with boolean contexts:illegal_argument_exception </iss>",allow different data types for category in context suggester
4031,"<desc> for 0.13, i'd prefer to keep the requirements the same as before: all platforms require pkg-config except for windows. for now, i believe i've fixed up the current issues and regressions. fixes: #8228, replaces #8242. post-0.13, i believe the consensus is to treat windows like the others and require pkg-config across the board. we can drop all of the non-pkg-config paths, and simply ac_require(pkg_prog_pkg_config) </desc> <cmt> build: fix qt5platformsupport check without pkg-config </cmt> <cmt> the non-pkg-config case can't use pkg-config to check the version. </cmt> <cmt> also, make sure that the check is properly guarded in the case of missing </cmt> <cmt> pkg-config macros. </cmt> <cmt> build: fix windows builds without pkg-config </cmt> <cmt> - guard pkg_prog_pkg_config with an m4_ifdef. if not building for windows, </cmt> <cmt> require it </cmt> <cmt> - add nops as necessary in case the ifdef reduces the if/then to nothing </cmt> <cmt> - ac_subst some missing _libs. these were split out over time, but not all were </cmt> <cmt> properly substituted. they continued to work if pkg-config is installed </cmt> <cmt> because it does the ac_subst itself </cmt> <iss> no error reporting when pkg-config missing in depends build </iss>",fix pkg-config issues for 0.13
4032,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix h.map.layer.objectlayer constructor </cmt> <cmt> fix types for h.service.platformcreatedefaultlayers() </cmt> <cmt> fix lint errors, add test </cmt>",fix types for h.map.layer.objectlayer() and h.service.platform.createdefaultlayers()
4033,"<desc> thanks to @tomuta, we are able to read from harddrives (from devfs device nodes) when booting with ide drives. related to #5793. </desc> <cmt> kernel: when writing to device node, use can_write for checking </cmt> <cmt> instead of can_read which is wrong, use can_write. </cmt> <cmt> kernel: fix race condition completing idechannel async request </cmt> <cmt> kernel: fix race conditions processing async device requests </cmt> <cmt> kernel: return 0 to indicate eof when reading from end-of-file of device </cmt> <cmt> if we happen to read with offset that is after the end of file of a </cmt> <cmt> device, return 0 to indicate eof. if we return a negative value, </cmt> <cmt> userspace will think that something bad happened when it's really not </cmt> <cmt> the case. </cmt>",devfs + block device io fixes
4034,<desc> following #18987 this pr adds a docker-compose based local multi node cluster. the fake multinode docker comprises two parts. the docker_monitor.py script is a watch script calling docker compose up whenever the docker-compose.yaml changes. the node provider creates and updates the docker compose according to the autoscaling requirements. this mode fully supports autoscaling and comes with test utilities to start and connect to docker-compose autoscaling environments. there's also a sample test case showing how this can be used.  i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [ci/wip] fake docker cluster for testing </cmt> <cmt> call docker compose </cmt> <cmt> wip </cmt>,create fake docker-compose cluster environment
4035,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" } summary of this pr: added new event: seeking typed new methods for getting and setting playback rates: getplayed(), getseeking(), getbuffered() and getseeked() </desc> <cmt> update typings to match v2.7.0 </cmt> <cmt> update typings to match v2.8.0 </cmt> <cmt> update version number to v2.9.1 as there is no type changes </cmt>",update typings to match the latest api version 2.9.1
4036,"<desc> this pr fixes problem found during integration tests preparation when parameter 'labels' is empty but 'labels_to_remove' contains values - in such case labels are not removed due to non-matching conditional. docker_node example of such task tested on python3.7 on latestfedora linux - name: try to remove single existing label from swarm node docker_node: hostname: ""{{ nodeid }}"" labels_to_remove: - label1 register: output </desc> <cmt> docker_node: fix for situation where labels parameter is none </cmt> <cmt> docker_node: fix for situation where labels parameter is none and labels are not removed </cmt>",labels operation fails when parameter 'labels' is none
4037,"<desc> closes #15865 closes problem described here: #15865 (comment) fix a bug where mounting element is not always available for npm/vue projects remove conflicting htmlwebpackplugin from user webpack config that prevents compilation userland htmlwebpackplugin clash with the one we provide in our dev server plugin. we should use ours, which is designed specifically for the dev-server we provide in component testing. for some unknown reason i cannot understand the <div id=""__cy_root"" /> clobbered when using html-webpack-plugin@4. i could only reproduce this in specific setups. for some reason using html-webpack-plugin@3 solves this, very bizarre. the easiest solution is just be defensive and create the mounting element if it doesn't exist. has the original issue or this pr been tagged with a release in zenhub? </desc> <cmt> fix: ensure root el exists </cmt> <cmt> fix: remove userland webpack plugins </cmt> <iss> [component-testing] can't have an htmlwebpackplugin in my webpack config </iss>","ensure root el mounting exists, remove userland html webpack plugin"
4038,<desc> i've updated the linux build instructions to add a little more detail. i hope this is satisfactory. thank you! </desc> <cmt> update build instructions for linux </cmt> <cmt> edit linux build instructions based on feedback </cmt> <cmt> add instructions to clean build products </cmt>,linux build instructions issue 1809
4039,"<desc> connectivity check - checking the correctness of the rdma configuration parameters by pinging on each channel. compilation with verbs and without cuda fix (contrib/verbs only works on gpu #13466) code refactoring: call done in case of not ok status fix replace hardcoded 100 with rdma_qp_queue_depth </desc> <cmt> add connectivity check </cmt> <cmt> ping on each channel and count send+recv completions </cmt> <cmt> move postsend and postrecv from mgr to channel, postrecv upon channel creation before connectivity check </cmt> <cmt> call done in case of not ok status fix + light code refactoring </cmt> <cmt> fix compilation error when working without cuda </cmt> <cmt> adding cuda library to build file in order to use google_cuda define </cmt> <cmt> replace hardcoded 100 with rdma_qp_queue_depth </cmt>","adding connectivity check, compilation fix and some code refactoring to verbs"
4040,"<desc> tracking from #23324 this removes all reference comments from our main source files and replaces them with explicit file lists in tsconfigs. this makes the output ordering of our various outputs actually similar, instead of random. total output size in built\local is effectively unchanged so i'm reasonably sure i didn't break anything. the next step is to merge the core references support and replace the long file lists in the tsconfig files with reference directives. </desc> <cmt> remove all reference comments from compiler/ </cmt> <cmt> explicitly list compiler source files in their current emitted order </cmt> <cmt> remove all reference comments from server/ </cmt> <cmt> explicitly list server source files in their current emitted order </cmt> <cmt> remove explicit harness file list from jakefile </cmt> <cmt> fix harness file listing </cmt> <cmt> add explicit file lists to server tsconfig files </cmt> <cmt> remove all reference comments from services </cmt> <cmt> .d.ts changed order </cmt>",project references transitional: remove reference comments
4041,"<desc> this converts all the plugin apis to accept a single object with named keys. some apis are growing, and the number of parameters is getting awkward. that said, we should continue to be conscious of the api we expose to plugins. thanks @jamiebuilds for the suggestion test plan: flow, lint, test </desc> <cmt> convert optimizers </cmt> <cmt> convert packagers </cmt> <cmt> convert runtimes </cmt> <cmt> convert namers </cmt> <cmt> convert bundlers </cmt> <cmt> convert resolvers </cmt>",convert plugin parameters to param objects
4042,"<desc> in some rare cases (e.g. object.create(null)), a prop value doesn't have the tostring() function, and thus cannot be cast to a string, throwing typeerror: cannot convert object to primitive value. this should fix that. </desc> <cmt> fix accessing attributes that don't inherit object </cmt> <cmt> use object's tostring if it exists </cmt> <cmt> fix spacing </cmt> <cmt> fix spacing </cmt>",fix preact/debug accessing attributes that don't have tostring
4043,"<desc> currently ""conv3d"" op with stride > 1 is not supported in eager mode, so we have to disable these test cases for now. </desc> <cmt> currently eager mode doesn't have support of conv3d with stride > 1, so we have to disable these tests in eager mode for now. </cmt> <cmt> fix pylint error. </cmt>","disable ""conv3d with stride > 1"" cases."
4044,<desc> display one more tag when error e067 happened. add an option can display more details when training enhancement i have submitted the spacy contributor agreement. </desc> <cmt> fix off-by-one error </cmt> <cmt> add verbose option </cmt> <cmt> update verbose option </cmt>,display more detail when error e067
4045,"<desc> closes #20975 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> add quick test, found issue, asked on github </cmt> <cmt> fix dtype </cmt> <iss> slicing columns with mixed types <str>,<int> fails with valueerror </iss>","slicing columns with mixed types <str>,<int> fails with valueerror #20975"
4046,"<desc> unbreak the most broken. split #3672 on timo's request. jira issue: core-6473 </desc> <cmt> [tcpip][ip] use an eresource as mutex for address files & connection end points </cmt> <cmt> spinlocks are not reentrant (and this is done a lot), using them forces us to have </cmt> <cmt> an horrible hack in the kernel, which unschedules threads which are at dispatch_level </cmt> <cmt> thus allowing another thread to take ownership of the spinlock while the unscheduled </cmt> <cmt> thread should already hold it. </cmt> <cmt> core-6473 </cmt> <cmt> [ntos:ke] do not allow waiting at irql >= dispatch_level when providing a timeout in kewaitformultipleobjects </cmt> <cmt> core-6473 </cmt>",use as eresource instead of a spinlock as locking mechanism
4047,"<desc> pull request for testing purposes / parking while ci is red. rdar://problem/26305887 before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> fix renaming fix-it when trailing closures are present. </cmt> <cmt> not crashing isn't good enough; we need to actually replace the </cmt> <cmt> right text! </cmt> <cmt> rdar://problem/26305887 </cmt> <cmt> don't try to apply fix-its for renamed operators. </cmt> <cmt> ...or renaming to operators, unless we're sure the original thing was </cmt> <cmt> an operator expression. there are just a lot of ways this can be </cmt> <cmt> screwed up. </cmt> <cmt> (some cases of this can certainly be implemented. i may file a </cmt> <cmt> starterbug later.) </cmt>","correct renaming fix-its for trailing closures, disable them for operators"
4048,"<desc> this pr adds a converterfactory flag to the options of gatsby-transformer-asciidoc, allowing users to declare custom converters and updates the readme with a small guide - further informations are found at </desc> <cmt> add custom converter and update readme </cmt> <cmt> fix linting </cmt> <cmt> revert changes on untouched code </cmt>",feat(gatsby-transformer-asciidoc): add custom template converter
4049,"<desc> in es6, class declaration and class expression are considered strict mode code. typescript compiler has updated parsing for class declaration and class expression as such. one strict mode restriction is that arguments is not allowed as an identifier in parameter declaration. this pull request is to fix using arguments in function's parameter </desc> <cmt> update breaking change from parsing class declaration in strict mode (as specified in es6) </cmt>",class declaration is automatically in strict mode
4050,<desc> and  a couple of other classes. this pr is mostly mechanical code change. </desc> <cmt> remove declarationtypechecker class-specific error reporting functions </cmt> <cmt> remove referencesresolver class-specific error reporting functions </cmt> <cmt> remove docstringanalyzer and docstringparser class-specific error reporting functions </cmt>,add error ids to declarationtypechecker
4051,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. params ...  response ... </desc> <cmt> fix: response.message, params.timeout type </cmt> <cmt> test: set timeout param </cmt>",fix response.message and params.timeout type
4052,"<desc> pr for issue #25802. this pr is similar to #26017 and #25802. however, neither of them were merged. i have attempted to add improvements to the documentation for tf.math.acos as well as tf.math.add. this is my first contribution so please do help me identify and fix any errors i might have made. thank you </desc> <cmt> adding description for 2.0 tf.math.acos </cmt> <cmt> added documentation to 2.0 tf.math.add </cmt> <cmt> minor style changes </cmt>",adding to the documentation of tf.math.acos and tf.math.add functions
4053,"<desc> this pr bundles libressl 2.1.4 (the latest version), and if the os is unix-like (and not cygwin), by default static-links to the library. the feature can be controlled by cmake -duse_bundled_ssl=(on|off). the reasons behind selecting libressl are: libressl would be more secure (or at least as secure) as openssl libressl supports new ciphersuites such as poly1305+chaha20 (the preferred ciphersuite for chrome running on android) libressl is upper-compatible against openssl (boringssl is not) relates to: #85 #131 </desc> <cmt> openssl libraries are mandatory; they can be part of extra_libraries </cmt> <cmt> add make script to build libressl </cmt> <cmt> bundle libressl, and link the standalone server to it by default (libh2o links to openssl) </cmt> <cmt> refrain from using target_include_directories since it was only introduced recently (in cmake 2.8.12) </cmt> <cmt> do not use$(shell); not supported by netbsd </cmt> <cmt> add -lrt for libressl+linux </cmt> <cmt> link using the bundled libressl by default only on unix-like oses </cmt>","bundle libressl, and by default static-link to it on unix-like systems"
4054,"<desc> to avoid getting maxlistenersexceededwarning  on the stat watcher that is shared in node for a filename use it only once and manage callbacks instead. fixes #28690 </desc> <cmt> file move </cmt> <cmt> some refactoring </cmt> <cmt> remove project status, watches etc when project is no longer part of build order </cmt> <cmt> use single stats watcher per filename </cmt> <cmt> fixes #28690 </cmt> <iss> maxlistenersexceededwarning when using tsc -b -w with more than 10 projects </iss>",create only single statfilewatcher through node
4055,<desc> the upstream for react-native for android has made this change with the following summary: this way uiimplementation can hold on to it and use it outside of calls from the uimanagermodule. facebook/react-native@f7cbd56 </desc> <cmt> syncing with upstream </cmt> <cmt> reverting the examples to the previous version </cmt> <cmt> changing uiimplementation to take the eventdispatcher in its constructor </cmt>,pass eventdispatcher to uiimplementation constructor
4056,"<desc> what's in this pull request? resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [update-checkout] rather than manually creating a path, use os.path.join. nfc. </cmt> <cmt> [update-checkout] generate ssh/https urls from a config template rather than hardcoding. </cmt> <cmt> this allows for other configuration files to specify other ssh/https </cmt> <cmt> locations. </cmt>",move the rest of the customization code into the config file
4057,"<desc> variable placement moved higher due to being an essential concept add ""built in functions"" section add ""math expressions"" section (near bottom as it's mostly self explanatory) </desc> <cmt> add built-in functions section to cheat sheet </cmt> <cmt> add math expressions section to cheat sheet </cmt> <cmt> move variable placement to follow 'structs' section </cmt> <cmt> add undocumented built-in functions to cheat sheet </cmt>",update cheat sheet with recent changes
4058,<desc> renamed the following files and folders: sleep_sort folder sleep_sort.c sleep_sort.cs sleep_sort.go sleep_sort.js sleep_sort.php sleep_sort.py sleepsort.java sleepsort.rb sleepsort.sh to sleep_sort.x (x meaning their respective file extensions) to follow the project's naming convention. </desc> <cmt> remove unconventially capitalized folder 'sleep_sort/' </cmt> <cmt> re-add the sleep-sort folder with the right capitalization </cmt>,change the name of sleep_sort folder and its contained files to conventionally capitalized names
4059,"<desc> this pr is to move the existing multi-worker implementation from java to core worker and make the feature available for all worker languages. as described in #2215, the multi-worker feature is important for java to save jvm memory overhead. the issue also discussed the possibility of leveraging coroutine to make workers light-weight. this pr also includes some refactoring to make the lifecycle of core workers more clear, especially on how the core worker is shutdown. previously there are exit, disconnect, shutdown, and ~coreworker in the coreworker class, and most of them are public. it's hard to know what to invoke if we want to shut down a coreworker. now all of them are either private or hidden. worker developers are required to use the documented approach to shutdown a coreworker or the coreworkerprocess. what are included in the pr: introducing the coreworkerprocess. the lifecycle management of core workers will be taken over by it. python adaptation. we will keep using 1 worker for a python worker process. java adaptation. we will delete the raymultiworkernativeruntime (#5505) and re-implement the multi-worker feature based on the new implementation in core worker. todo core worker refactoring for multi-worker support python adaptation java adaptation and removing of multi-worker implementation streaming adaptation review guide i split the touched files into several sections to give you an overall picture of this pr and help you quickly navigate to the parts you may be interested in. core_worker.h|.cc and context.h|.cc in src/ray/core_worker. these are core changes related to multi-worker support. it includes multi-worker management, initialization, and shutdown. please review them first. src/ray/gcs/, src/ray/protobuf/, src/ray/rpc/gcs_server/. these are changed because i moved the worker registration from python/java worker to core worker. the changes are easy to read and understand. but i had to touch a lot of gcs related files to make it fully functional. python/ray/. these changes are required because of the interface changes in core worker. only several files are touched. should be easy to read. also, worker registration is removed from python worker. java/ and src/ray/core_worker/lib/java/. i removed the existing multi-worker implementation from java. so changes are big. review it carefully if you are interested. test files in src/ray/core_worker/. they are touched because of the interface changes and the way of core worker initialization. streaming/. because holding a native pointer of coreworker is no longer suggested (although still possible), there are some java/python/c++ code changes about the way to access the core worker api. luckily the changes are fairly small. #2215 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> temp commit for core_worker.h refactor </cmt> <cmt> pass build of core_worker_lib </cmt> <cmt> fix one tocheck </cmt> <cmt> update and pass core worker test </cmt> <cmt> minor update </cmt> <cmt> lint </cmt> <cmt> pass python build </cmt> <cmt> lint </cmt>",support multiple core workers in one process
4060,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added solution for problem 493 </cmt> <cmt> fixed typo </cmt>,added solution for euler problem 493
4061,"<desc> fix some marko cli issues. also, add some new examples in default. not sure added new example. no </desc> <cmt> fix few issues in marko cli </cmt> <cmt> fix some markocli issues </cmt> <cmt> add support for marko widgets </cmt> <cmt> fix some marko-widgets button </cmt>",few fixed related to marko support
4062,"<desc> closes #18572 attempting to add an existing built-in cypress command using cypress.commands.add() will throw an error, indicating that cypress.commands.overwrite() should be used instead to overwrite the behavior of existing commands. this is a breaking change since errors will now be thrown if users had previously added any new commands which already existed in cypress. previously, cypress would not warn you when you are trying to add a command that already exists in cypress. this could lead to unexpected behavior with the command since it is unclear which would take precedence. now, if a user tries to add a command that already exists (such as cypress.commands.add('get', ...)), cypress will throw an error indicating that overwrite should be used in these situations instead. note: the implementation in this pr will not throw if a user attempts to add a duplicate custom command that they have already defined. this only checks for collisions with core cypress commands. has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? cypress-io/cypress-documentation#4178 </desc> <cmt> throw when adding an existing command </cmt> <cmt> add test </cmt> <iss> cypress.command.add for a command that is a cypress command doesn't warn/error </iss>",adding an existing command with cypress.commands.add() will throw an error
4063,<desc> added support for separate wasm test step in ci. new steps are dynamically generated in .cicd/generate-pipeline.sh for each platform. added scripts/wasm-spec-test.sh to support ci changes and to provide a quick script to run this set of tests. bumped commit of eosio-wasm-spec-tests. see: </desc> <cmt> test new label for wasm spec tests. </cmt> <cmt> update ci to add new step for wasm spec tests. </cmt> <cmt> fix duplicate unit test label. </cmt> <cmt> make script executable. </cmt> <cmt> fix test counter. </cmt> <cmt> bump commit. </cmt>,wasm spec test step in ci
4064,"<desc> just a bit paranoia, a follow-up for #10073. @keszybz @xnox ptal! </desc> <cmt> exec-util: handle putenv() errors </cmt> <cmt> just paranoia, as putenv() can fail and we should catch it, like we </cmt> <cmt> catch all other errors. </cmt> <cmt> follow-up for #10073 </cmt> <cmt> exec-util: add missing logging call </cmt> <cmt> this function logs about all errors, but one case was forgotten. fix </cmt> <cmt> that. </cmt>",add missing putenv() error handling
4065,"<desc> closes #34633 ensure all linting tests pass, see here for how to run them have added clarification to the user guide on the default behaviour of to_timedelta when a string is passed. </desc> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> doc gh34633 warning for default behaviour of to_timedelta </cmt> <iss> bug: to_timedelta() works differently depending on type of arg for the same unit </iss>",to_timedelta docs warning on default behaviour
4066,"<desc> addresses #10961 #11012. this is still a work in progress. i'm posting it here since the api is huge and there may be people interested in starting to review it. other sets of eyes are very welcome, since there may be typos, omissions, or errors in definitions. a lot is still missing, including tests and jsdoc. api  case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. </desc> <cmt> rename leaflet.d.ts to leaflet-0.7.d.ts </cmt> <cmt> defined several important interfaces and the skeleton of some others </cmt>",add type definitions for leaflet 1.0
4067,"<desc> afaict these are artifacts of pre-pytest usage where we needed to manually add info to the traceback. adds a code_check to make sure we aren't catching baseexception anywhere.  baseexception includes keyboardinterrupt, which we shouldn't be catching in general. saving parametrization in test_nanops for a separate pass, as the diff will get big. </desc> <cmt> cln: stop catching baseexception </cmt> <cmt> cln: exception in nanops </cmt>",exception and baseexception in test_nanops
4068,"<desc> the type definition only allowed strings to be used for the toast title and message content, but react-toastr should also allow jsx elements to be used. updated the type definition to allow 'any' type for the toast title and message content to allow for strings or jsx elements. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> updated the typings to allow jsx elements in addition to strings for the toast message content. </cmt> <cmt> refer to </cmt> <cmt> update version number of react-toastr type definition. </cmt>",allow jsx to be used for title and message content.
4069,"<desc> this pr fixes #106316 @joaomoreno add an optional param to the git.api.getremotesources api call to default to a specific provider. you can test it by calling await commands.executecommand('git.api.getremotesources', { providername: 'github' }) this will skip the choose provider and show directly your repos in github </desc> <cmt> add providername option to git.api.getremotesources </cmt> <cmt> formatting </cmt> <iss> provide option to default to github provider git.api.getremotesources and potentially list org repos. </iss>",provide option to default to github provider for git.api.getremotesources
4070,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add options arg to ""find-versions"" </cmt> <cmt> update metadata </cmt>","add optional ""options"" argument to ""find-versions"" default export"
4071,"<desc> re. #41179 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [assert] add notdeepstrictequal </cmt> <cmt> [assert] deprecate non-strict functions </cmt> <cmt> [assert] add asserts _ is _ annotations </cmt>",add support for typescript's assertion functions
4072,"<desc> using chakra, in accessibilityexample we see the dynamic for min represented as a double (0.00000) and crash with a folly typeerror since we enforce the folly::dynamic value is an integer. we're converting to a double anyway, so we instead rely on built-in folly type conversion instead of trying to coerce the value to an int to convert into a double again. (i.e. asdouble will convert an int to a double as well). note that we still see issues with the accessibilityexample page that need to be addressed. will cherry-pick this into 0.63-stable. microsoft reviewers: open in codeflow </desc> <cmt> fix crash using accessibilityvalue without web debugging </cmt> <cmt> existing code will crash with a folly typeerror since we enforce the folly::dynamic value is an integer. using chakra, in accessibilityexample we see the dynamic for min represented as a double (0.00000) and crash. </cmt> <cmt> we're converting to a double anyway, so we instead rely on builtin folly type converstion instead of trying to coerce the value to an int to convert into a double again. </cmt> <cmt> note that we still see issues with the accessibilityexample page. </cmt> <cmt> change files </cmt>",fix crash using accessibilityvalue outside of web debugging
4073,<desc> unify take implementation and api for type variable and disjunction via bindingstep which accepts a producer. and remove typebinding class which is no longer necessary. </desc> <cmt> [csstep] extract common type-var/disjunction functionality into bindingstep </cmt> <cmt> unify take implementation and api for type variable </cmt> <cmt> and disjunction via bindingstep which accepts a producer. </cmt> <cmt> [constraintsystem] nfc: typebinding abstraction is no longer necessary </cmt>,"add bindingstep to unify some logic in typevar, disjunction steps"
4074,<desc> ports #12051 and #12032 </desc> <cmt> use local registry to check if typings package exist (#12014) </cmt> <cmt> use local registry to check if typings package exist </cmt> <cmt> enable sending telemetry events to tsserver client (#12035) </cmt> <cmt> enable sending telemetry events </cmt>,ports #12051 and #12032 into master
4075,"<desc> this pr retires the use_pytorch config setting in favor of a more generic framework=tf|tfe|torch|auto setup, where auto causes torch to be used iff only pytorch is installed (otherwise: tf). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt>","auto-framework, retire use_pytorch in favor of framework=..."
4076,"<desc> when testing locally it now, when it's available, i've realized it was not setup properly, and that it should be setup on aws::lambda::version resource. having that patch in, i've successfully deployed new lambdas with provisioned concurrency setup. however i observed internal error cf stack udpate crashes when trying to update already deployed lambdas with that config (this looks as aws issue, which i discuss with them over email) </desc> <cmt> refactor setup of function versioning </cmt> <cmt> fix handling of provisionedconcurrency handling </cmt>",fix lambda provisioned concurrency setup
4077,"<desc> my aeotech multisensor 6 has a motion sensor and vibration sensor that send command_class_alarm signals. the changes in this pr allow home-assistant to auto-detect these sensors. before this code, only the temperature, humidity, lux, and uv worked. the alarm sensors show up on the main screen and are able to be used to trigger various automation events or anything else. note that for this particular device, you get alarm_level, alarm_type, and sourcenodeid in addition to sensor.aeotec_multisensor_6_burglar. this seems to be a feature of the openzwave library and they can be hidden. the burglar alarm sets to state=8 when motion is sensed and state=3 when vibration is sensed. the command_class_alarm is used in this and similar sensors to give immediate feedback rather than waiting for the normal update interval to report the current state. i eliminated all pylint errors in these sections of code. i recommend following #817 and getting the most recent python-openzwave branch if you're using this particular device. </desc> <cmt> first attempt at adding z-wave command_class_alarm </cmt> <cmt> zwave alarm sensor cleanup (pylint fixes) </cmt>",added z-wave alarm sensors to list of devices that can be auto-detected and used
4078,"<desc> resolve a crasher caused by walktovardecls walking into pretty much anything and everything as long as it could reach a pattern.  if the pattern was an expression pattern, parse would perform lookup into every variable in any inner scope.  because the expression in this pattern is a closure, this meant the user could introduce any number of inner declaration contexts.  here, parse, content to bind a declref, fed the malformed ast to the type checker which balked.  later, the validator took a turn and landed inside a declaration whose parent decl contexts had not yet been validated. </desc> <cmt> fix compiler crash by restricting the walktovardecls walker. </cmt> <cmt> walktovardecls should only walk within the current pattern, not into </cmt> <cmt> any other nodes (especially not nodes that open a scope.) </cmt> <cmt> restricting this fixes the name lookup weirdness that caused the crash. </cmt> <cmt> resolve a crasher </cmt>",restrict walktovardecls to expressions and patterns
4079,"<desc> thanks to the great work by @zvecr in #6424, i can now move rev1 to split_common. this pr does so my code follows the code style of this project. i have read the contributing document. </desc> <cmt> initial work to move to split_common </cmt> <cmt> fixed serial pin </cmt>",move vitamins included rev1 to split_common
4080,"<desc> see the individual commits for details. </desc> <cmt> sema: improve comments based on code review feedback </cmt> <cmt> sema: refactor typechecker::diagnoseinlinabledeclref() </cmt> <cmt> ast: use vardecl::isinitexposedtoclients() from declcontext::getfragilefunctionkind() </cmt> <cmt> getfragilefunctionkind() would report that all initializers in </cmt> <cmt> non-resilient public types were inlinable, including static </cmt> <cmt> properties. </cmt> <cmt> this was later patched by vardecl::isinitexposedtoclients(), </cmt> <cmt> which was checked in diagnoseinlinabledeclrefaccess(). </cmt> <cmt> however, the latter function only looked at the innermost </cmt> <cmt> declcontexts, not all parent contexts, so it would incorrectly </cmt> <cmt> diagnose code with a nested declcontext inside of a static </cmt> <cmt> property initializer. </cmt> <cmt> fix this by changing getfragilefunctionkind() to call </cmt> <cmt> isinitexposedtoclients() and simplifying </cmt> <cmt> diagnoseinlinabledeclrefaccess(). </cmt> <cmt> this commit also introduces a new islayoutexposedtoclients() </cmt> <cmt> method, which is similar to isinitexposedtoclients(), except </cmt> <cmt> it also returns 'true' if the property does not have an </cmt> <cmt> initializer (and in fact the latter is implemented in terms </cmt> <cmt> of the former). </cmt> <cmt> sema: don't check spi violations in diagnoseinlinabledeclrefaccess() </cmt> <cmt> there's no need to check for that here, because we also run </cmt> <cmt> diagnosedeclrefexportability() on declarations referenced </cmt> <cmt> from inlinable code. </cmt> <cmt> this changes some diagnostics; we now produce the same diagnostic </cmt> <cmt> for references to spi types in declaration signatures and for </cmt> <cmt> references to non-type spi declarations in inlinable function bodies. </cmt> <cmt> also note that the old inlinable reference diagnostic no longer has </cmt> <cmt> to handle the 'public' and 'open' access levels, which previously </cmt> <cmt> happened for '@_spi'; so i changed those entries in the %select to </cmt> <cmt> %error. </cmt> <cmt> sema: use vardecl::islayoutexposedtoclients() when checking access in @frozen structs </cmt> <cmt> we require that all stored properties in a @frozen struct have </cmt> <cmt> public or @usablefrominline types, even if the property itself </cmt> <cmt> is not public. this is so that clients can correctly generate </cmt> <cmt> code to manipulate the @frozen struct. </cmt> <cmt> this check was only looking for bona-fide stored properties, </cmt> <cmt> and missing out looking at properties that have backing storage, </cmt> <cmt> namely 'lazy' properties and property wrappers. </cmt> <cmt> sema: use vardecl::islayoutexposedtoclients() when checking if @_spi attribute is allowed </cmt> <cmt> we need to prohibit 'lazy' properties and property wrappers from </cmt> <cmt> being declared @_spi inside of a @frozen struct. making them spi </cmt> <cmt> doesn't make sense, because these properties will be omitted from the </cmt> <cmt> module interface and not taken into account when clients manipulate </cmt> <cmt> values of this type. </cmt> <cmt> sema: enforce that stored properties of @_fixed_layout classes only reference public types </cmt> <cmt> this is the same restriction as with @frozen structs. even though </cmt> <cmt> classes are lowered as a single reference and clients don't usually </cmt> <cmt> manipulate their stored property layout directly, @frozen classes </cmt> <cmt> can have @inlinable designated initializers. </cmt>",another pile of availability checking fixes
4081,"<desc> adding enforcement of group policies for additional required sources and allowed sources. this change includes: reading of source lists from group policy. each source is specified by a json with all its details. a new grouppolicyexception type for reporting errors. enforcement of the policies when adding and removing sources (only allow adding allowed sources and don't allow removing additional required sources). a source export command to produce the json strings used in the policies. unit tests. still pending for group policies: e2e tests use final registry key path, value names, and policy names microsoft reviewers: open in codeflow </desc> <cmt> implement value::getvalue() with trygetvalue() </cmt> <cmt> enforce policies related to sources </cmt> <cmt> add source export command skeleton </cmt> <cmt> fix registry read for source policies </cmt> <cmt> add tests for source policies </cmt> <cmt> check allowed sources' data & id </cmt> <cmt> add source export </cmt> <cmt> move group policy error handling </cmt> <cmt> add some logs, comments, and fix typos </cmt> <cmt> add test for source export </cmt> <cmt> fix group policy error handling </cmt> <cmt> small fixes </cmt> <cmt> spelling </cmt>",group policy for controlling sources
4082,"<desc> closes #3957 when a user attempts to pass {} as an argument to --spec, an error will be thrown indicating the argument could not be parsed since its value was not a string or comma-separated list. previously, cypress would crash badly when {} or any other type of object was passed into the --spec argument. this pr improves the robustness of argument parsing to prevent crashing in these situations. has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? --> n/a have api changes been updated in the type definitions? --> n/a have new configuration options been added to the cypress.schema.json? --> n/a </desc> <cmt> add test </cmt> <cmt> handle empty object args </cmt> <cmt> remove cli test </cmt> <iss> argument parsing crashes badly if passing ""spec: {}"" </iss>","prevent cypress from crashing when argument parsing ""spec: {}"""
4083,<cmt> frexp/ldexp variant </cmt> <cmt> multiply by power of two variant </cmt> <cmt> strengthen assertions </cmt> <cmt> added notes and commented out assertions to reach a stable resting point </cmt> <cmt> two code paths.  all tests pass. </cmt> <cmt> clean-up comments and ranges </cmt> <cmt> remove debugging code </cmt> <cmt> clean-up comments and over-specified tests </cmt> <cmt> add blurb </cmt>,improve speed and accuracy of math.hypot()
4084,"<desc> issue: presets can be used to programmatically modify the preview templates, but information on how to do so is not linked up with the general information about these files. linked information about the preview/manager presets to the general information about preview-head and preview-body files. n/a </desc> <cmt> link to preview/manage templates </cmt> <cmt> link to preset information for preview body/head from general information about preview body and head. </cmt> <cmt> typo </cmt> <cmt> fixing extra to </cmt>",updating preview head/body section to mention presets
4085,"<desc> with a .yarnrc configured for offline mirroring with yarn-offline-mirror-pruning, packages that are resolved in yarn.lock to registry urls, such as: ""@jupyterlab/about-extension@^0.3.1"": version ""0.3.1"" resolved "" ...will indeed be mirrored as @jupyterlab-about-extension-0.3.1.tgz. however, this will be immediately pruned, as the tarball expected on disk  will be about-extension-0.3.1.tgz (derived from the url) which won't match as it is is not suitably mangled. this pr adds an extra expectedtarball for the pre-mangled version. i don't know if this is exactly the right approach, but local testing suggests it works, and since the expected-but-unfound tarballs aren't returned/checked, it didn't seem like it could hurt. this adds a new test case, with a copy of the existing mirror fixture, but with yarn-offline-mirror-pruning and a yarn.lock as i have been seeing in my testing, as opposed to the file-based one. it didn't seem appropriate to add this to the original test case, but i can be easily persuaded otherwise! </desc> <cmt> include scope prefix for mirror tarball name check before pruning </cmt> <cmt> add tests, do as extra check </cmt>",don't always prune mirrored scoped packages resolved by urls
4086,"<desc> for #1097 . format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> re subscribe service when reconnect </cmt> <cmt> change grpc instance maintain by heartbeat </cmt> <cmt> add lifecycle for remoting workers </cmt> <cmt> refactor naming client redo when reconnect </cmt> <cmt> fix checkstyle and pmd </cmt> <cmt> implement forward instance request to responsible server </cmt> <cmt> implement forward heart beat to servers </cmt>",naming support grpc server forward request
4087,<desc> description: remove items from axis.conf that doesnt belong there. checklist: </desc> <cmt> signal callback isnt json serializable so it has to be removed before saving to conf </cmt> <cmt> remove filtered events list which is not a part of component configuration </cmt>,axis discovery fails to save conf
4088,"<desc> dxtn.dll is no official system dll and wined3d is its only user. but latest wined3d prefers the libtxc_dxtn codebase. this is also what mesa uses and fedora legally ships now, so we should stick to the same. surprisingly, the libtxc_dxtn code compiles warning-free in our tree without changing a single line of code! however, i don't understand how the previous dxtn.dll ever worked, because it provided stdcall exports while wined3d imported and called cdecl ones. i have only tested the build as i lack a proper test case and just wanted to supersede #6 the reporters of the related jira issues please test whether our new dxtn.dll fixes their problems. my changes also remove the nswpat option from our buildsystem, because dxtn.dll was its last user. jira issues </desc> <cmt> [dxtn] remove our current dxtn library. </cmt> <cmt> this is no official system dll and wined3d is its only user. </cmt> <cmt> however, latest wined3d prefers the libtxc_dxtn codebase. this is also what mesa uses and fedora ships, so we should stick to the same. </cmt> <cmt> [dxtn] import libtxc_dxtn-1.0.1 from </cmt> <cmt> [dxtn] add a cmakelists.txt and dxtn.spec around libtxc_dxtn. code compiles warning-free in our tree without modifying a single line! </cmt> <cmt> but how did our previous dxtn.dll ever work with stdcall exports when wined3d imported and called them as cdecl? </cmt> <cmt> remove the nswpat option from our buildsystem and compile dxtn by default now. its patents have expired! :) </cmt>",replace our dxtn.dll by a version based on the libtxc_dxtn source code
4089,"<desc> improvements made in this pr: keep track of all currently available work areas (represented by izonewindow interface). avoid deletion / creation of work areas every time that virtual desktop switch occurs. enable getting work area (izonewindow) by providing virtual desktop id and monitor handle. enable getting work area (izonewindow) on which certain window is specified (by providing window handle). remove thread unsafe communication between izonewindow and fancyzones. simplify moving windows into zones by direction and index set. remove active device id concept from jsonhelpers. handle updates of custom zone layout across all desktops (only when layout changes, avoid doing so during desktop switch to avoid flickering). pr checklist applies to #1615 #2725 ... cla signed. if not, go over here and sign the cla </desc> <cmt> initial design for improving handling of different engaged work areas in fancyzones. </cmt> <cmt> remove active device id check in zonewindow. </cmt> <cmt> remove concept of active device identifier in jsonhelpers. </cmt> <cmt> refactor interface description and add new method. </cmt> <cmt> simplify zonewindow initialization. </cmt> <cmt> default value for active zonewindow during move/size. </cmt> <cmt> add newline at the end of file. </cmt>",improve monitor work area handling
4090,<desc> since the old script did a rename of the firmware.bin platformio flash function failed. change script to copy firmware.bin to tasmota <variant> name. so the firmware.bin is still there and flash is still working in plaformio the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.6 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> change rename firmware script to name firmware </cmt> <cmt> since the old script did a rename platformio flash function failed. </cmt> <cmt> change script to copy firmware.bin to tasmota variant name. </cmt> <cmt> so the firmware.bin is still there and flash is working in plaformio </cmt> <cmt> with this change script can be activated and every function will work </cmt> <cmt> delete rename-firmware.py </cmt> <cmt> add files via upload </cmt>,change function rename firmware script to name firmware
4091,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. increase the version number in the header if appropriate. </desc> <cmt> update ncp-tests.ts </cmt> <cmt> update index.d.ts </cmt>,update 'ncp' to version 2.0.0
4092,"<desc> update ansible-test change handling and the cloudstack cloud plugin: use the ansible/ansible:cloudstack-simulator image for cloudstack tests. only run cloud plugin related integration tests for changes to cloud plugins. do not show cloudstack starting notice in explain mode. ansible-test ansible version nsible 2.4.0 (at-cs-ansible a461b68e9c) last updated 2017/05/09 15:26:06 (gmt +800) config file = configured module search path = [u'/users/mclay/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/mclay/code/mattclay/ansible/lib/ansible executable location = /users/mclay/code/mattclay/ansible/bin/ansible python version = 2.7.11 (default, jan 22 2016, 08:29:18) [gcc 4.2.1 compatible apple llvm 7.0.2 (clang-700.1.81)] </desc> <cmt> use cloudstack simulator from ansible repo. </cmt> <cmt> recognize cloud specific ansible-test changes. </cmt> <cmt> hide ansible-test cs notice in explain mode. </cmt>",update ansible-test change handling and cs plugin.
4093,"<desc> fix issue #6861 </desc> <cmt> fix r_str_cmp to follow the documented behaviour </cmt> <cmt> now r_str_cmp behaviour is consistent. </cmt> <cmt> before: </cmt> <cmt> * returns true if both pointers are equal. </cmt> <cmt> * returns false if the strings are equal. </cmt> <cmt> now: </cmt> <cmt> * returns true if both pointers are equal. </cmt> <cmt> * returns true if the strings are equal. </cmt> <cmt> implement ""rabin2 -l [plugin]"" </cmt> <cmt> - display plugin info in a proper structured way for humans with </cmt> <cmt> ""rabin2 -l [plugin]"". </cmt> <cmt> - fix current ""rabin2 -l [-j]"" output. </cmt> <cmt> - allow to specify ""-j"" before or after ""-l"". </cmt> <cmt> fix issue #6861. </cmt> <cmt> implement command il [plugin] </cmt>","implement ""rabin2 -l [plugin]"" and command ""il [plugin]"""
4094,"<desc> this gives us an extra 0.5% - 1.5% examples/second, depending on the environment, and should not in theory change the model architecture itself. final accuracy for imagenet was unchanged at 76.38%, cifar-10 92.5%. </desc> <cmt> try out affine layer instead of dense </cmt> <cmt> use reduce mean instead of avg pooling </cmt> <cmt> remove np </cmt> <cmt> use reduce mean instead of avg pooling </cmt> <cmt> fix axes </cmt> <cmt> cleanup </cmt> <cmt> fixing comment </cmt>",use reduce_mean instead of average pooling in resnet
4095,<desc> ensure per-actor-handle ordering in direct actor calls. sequencing: handled by a sequence number in the push task proto admission control: this is handled on the client side by limiting the number of outstanding bytes in flight per handle (to 16mb by default) closes #5633 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> client half </cmt> <cmt> server impl </cmt> <cmt> add log debug </cmt> <cmt> docs </cmt> <iss> prototype scheduling queue for direct actor calls. </iss>,ordered execution of tasks per actor handle
4096,"<desc> the way we use builtin modules in the main process now becomes: const {app, browserwindow} = require('electron').remote instead of a long require chain: require('electron').remote.require('electron') </desc> <cmt> fix typo, tray => tray </cmt> <cmt> make it easier to use remote </cmt> <cmt> simplify how remote.require('electron') is optimized </cmt> <cmt> send sync message to get list of modules </cmt> <cmt> use the new style remote module in electron </cmt> <cmt> docs: document the new style of remote module </cmt>",make it easier to use browser side modules
4097,"<desc> this change allows a developer to theme the app bar's trailing icons independently from leading if they choose. the existing behavior is preserved, so this will only take effect if a developer explicitly specifies a theme for the actions. additionally, this change updates the documentation for sliverappbar properties that were missed when the appbartheme was added. screenshot showing different themes for the leading/trailing icons: </desc> <cmt> allow app bar actions to be themed independently if needed </cmt> <cmt> update sliverappbar docs that were out of date </cmt> <cmt> clarify fallback behavior in a comment </cmt>",add the ability to theme trailing app bar actions independently from leading
4098,<desc> fixes #3222 </desc> <cmt> test for git corrupt </cmt> <cmt> remove repeate integration cases </cmt> <cmt> remove method and change xml for tableassert </cmt> <iss> remove two method in tableassert and make sure the table number of xml is correct </iss>,remove two methods and change xml for tableassert
4099,"<desc> addresses feature request from issue #10432. continuation of feature implementation--initial changes did not address the case where num_outputs = none, in which case strides and the input channels must be reformulated according to data format. the previous commit is  rmlarsen/tensorflow@d52e15a. i created a previous pr #12120 for a similar issue that @rmlarsen fixed in the above commit, but the strides were still mismatched to data format--i thought it would be cleaner if i just made a new pr. edit--i thought it would be cleaner because my cla would be recognized, but it still hasn't. see the comment below. </desc> <cmt> strides must change form if data format is switched </cmt> <cmt> fixed stride mismatch on channels first data format for separable conv </cmt> <cmt> fixed sepconv2d test and added stride testing </cmt>",fix strides format for data format in contrib.layers.separable convolution2d
4100,"<desc> new features apis initialize gloo by default for distributed training. initialize gloo for low level api. now, we only support to initialize gloo with http server as it is much more common than hdfs store and local files. usage: use with spawn import paddle def train(): paddle.distributed.init_parallel_env() ... if __name__ == ""__main__"": paddle.distributed.spawn(train) use with fleetrun import paddle def train(): paddle.distributed.init_parallel_env() ... if __name__ == ""__main__"": train() start a train with the following command: fleetrun train.py </desc> <cmt> add double grad for expand, test=develop </cmt> <cmt> update, test=develop </cmt> <cmt> add gloo initializer, test=develop </cmt>",initialize gloo for low level collective apis
4101,"<desc> enables the usage of the incremental compiler for web builds, behind the configuration --[no-]enable-web-incremental-compiler. this is available everywhere web is, but not on by default. known issues: plugins don't work init logic is not quite right, we're calling main before fully initialized. frontend_server can't handle package entrypoints. i have a fix pending in the dart sdk i need to land and roll through. fixed by  debugging/vmservice isn't supported. need to work with bat to figure out a strategy here, this was determined to not be a blocker for the initial preview. sourcemaps are not being written as part of the build. will be fixed by  doesn't currently work with builders: key total time is not correct. needs to wait for the next window  frame callback </desc> <cmt> merge devfs changes </cmt> <cmt> merge bootstrap changes </cmt> <cmt> add full incremental compiler support </cmt> <cmt> split experimental path </cmt> <cmt> cleanups of defaults </cmt>",enable usage of experimental incremental compiler for web
4102,<desc> this changes the current script.max_size_in_bytes to be dynamic so it can be set through the cluster settings api.  this setting is also applied to inline scripts in the compile method of scriptservice to prevent excessively long inline scripts from being compiled.  the script length limit is removed from painless as this is no longer necessary with the protection in compile. relates #23209 </desc> <cmt> change max bytes setting to be dynamic. </cmt> <cmt> add tests. </cmt>,make max script length setting dynamic
4103,"<desc> this pull request include two improvements to line series. reduce initial render time(and memory cost) up to 10x in the line series with millions of time series data. improve smooth result in some cases. details about performance improvement. 1. use typedarray. the most important thing did to improve the performance is to use typedarray instead of normal array as much as possible. it will reduce the heap memory and gc cost significantly. in this pr we use typedarray to store the points of polyline and polygons. also no setitemlayout anymore. 2. bake the transform of datatopoint to matrix in cartesian2d it will simplify the transform to a very fast 6x2 multiply and add operations. but it only works for affine transform when axis type is time or value. so it's mainly for boosting the time series data. 3. remove unnecessary date parsing when it's a timestamp. it can avoid creating millions of temporary date object when parsing the time series data. 5. speed up storage access in list component. it's a trick did for modern js engine. i found the access of storage is slow when initializing millions of data in  i profiled it and saw keyedloadic_megamorphic in the profiling result, which means it's not a fast property access. so we simplify the case to the following code. const obj = {}; obj.x = 1; obj.y = 1; function slowobjectaccess() { let sum = 0; for (let i = 0; i < 1e6; i++) { for (let k = 0; k < 2; k++) { const val = obj[k === 0 ? 'x' : 'y']; sum += val; } } return sum; } function fastobjectaccess() { let sum = 0; for (let i = 0; i < 1e6; i++) { for (let k = 0; k < 2; k++) { sum += k === 0 ? obj.x : obj.y; } } return sum; } and the test result shows fastobjectaccesscan be 10x faster than slowobjectaccess. i can't find out why and how to avoid it because my limited knowledge of js engine.  so i add an extra _storagearr array and get from this array in the hotspot code like list#_initdatafromprovider. it works well and the cost of _initdatafromprovider  reduced to half. performance result render time comparison between 4.x and 5.0 heap memory comparison between 4.x and 5.0 details about smooth improvement. the original smooth algorithm will constraint the control points to the global bounding box. which may lead to two issues as shown in the following picture. so in this pr i did two changes. constraint the control points to the bounding box of two points locally. recalculate the previous control point after current control point is changed. and the result after change. #12249 #10200 #4556 </desc> <cmt> line: optimize memory cost and initialize time for the large line. </cmt> <cmt> fix(line): fix poly builder on some case </cmt> <cmt> time: return directly if parsing val is a timestamp. </cmt> <cmt> perf(line): optimize performance of time series data on line. </cmt> <cmt> fix(type): fix some type errors. </cmt> <cmt> perf: optimize storage access in list for large data. </cmt> <cmt> perf: optimize data access in points layout </cmt> <cmt> perf: clean code. fix stacked line </cmt> <cmt> fix(line): optimizing polyline smooth algorithm. </cmt> <cmt> limiting the control points inside the range of two connect points. instead of the global bounding box in the previous implementation </cmt> <cmt> fix(list): fix some null access issues after perf refactor before. </cmt>",improve large line performance. improve line smoothing.
4104,"<desc> breaking change: this change breaks existing service call references to the media_player.blackbird_set_all_zones services by changing the service calls to be blackbird.set_all_zones. my understanding is that because this is not a service provided by the base media_player component, it should live in the domain of the blackbird component instead. if that's the case, then it also makes sense to update the service name. description: update the domain and service name for media_player.blackbird_set_all_zones. see this comment for context: #28890 (comment) related issue (if applicable): related to #27289 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#11299 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. </desc> <cmt> move service constants to const.py, update blackbird custom service domain </cmt> <cmt> readd bluesound services.yaml entries since it should be part of a different branch </cmt>",update service domain for blackbird from 'media_player' to 'blackbird'
4105,"<desc> this pr significantly reduced cuda profiling overhead from 10% to 1%, and provide more detail about cuda runtime api. motivation: recently, i am optimizing multi gpu accelerate efficiency, the bottleneck of multi gpu efficiency is hard to find.  the overhead of paddle's profiler is too big to find the real hot spot, so i decide to optimize this profiler. (overhead of nvprof is acceptable, but it missed the cpu information.) this pr contains: remove unnecessary locks to improve performance(10% overhead -> 4% overhead) using cupti to calculate the kernels elapsed time rather than cuda event(4% overhead -> 2% overhead) change vector to list(2% overhead -> 1% overhead) generate  cuda runtime api timeline like this: </desc> <cmt> refine profiler && add runtime tracer </cmt> <cmt> test=develop </cmt>",profiler refine and add cuda runtime api tracer
4106,"<desc> see issue #553 for discussion. also brings binary support to the hybi parsers, but this feature is still secondary / not connected to anything. </desc> <cmt> added fixes from hybi-07-12 which also apply to 16 </cmt> <cmt> added binary support to hybi-16 parser, refactored hybi tests somewhat </cmt> <cmt> added binary support to the hybi 07-12 parsers as well </cmt> <cmt> fixes #553 - (re)verify origin in websocket transport implementations </cmt> <cmt> corrected origin header name in test </cmt>",origin verification brought into the client
4107,<desc> these two commits are taken from the controller input pr #8807 from @garbear. the first commit introduces an error dialog if the user tries to open the settings dialog for a peripheral device that doesn't have any settings instead of showing an empty dialog with focus problems. the string being used seems to have been in use by confluence at one point but i checked and it isn't used there anymore. the second commit removes a usage of g_peripherals inside cperipherals which doesn't make any sense. </desc> <cmt> [peripherals] show a message if there are no settings available for a peripheral device </cmt> <cmt> cperipherals: don't use g_peripherals for internal method calls </cmt>,don't show the settings dialog if there are no settings available
4108,"<desc> description: this fixes the real issue with hue groups having the same name that was worked around with #5702. checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> revert ""fix hue lightgroups not syncing state (#5702)"" </cmt> <cmt> use light_id in unique_id for hue groups </cmt>",fix hue groups with same names
4109,"<desc> this pr improves the tensorrt binding index query in a way that makes it compatible with optimization profiles. currently profiles are not used in tf-trt, therefore this pr does not change any existing behavior. it is just a preparatory step to implement dynamic shapes with profiles. tensorrt bindings are an array of pointers to input and output buffers for the network. to execute tensorrt inference we have to specify the bindings. to specify the pointers for the bindings, we have to query the binding index for each input and output tensor, and fill the data pointer in the bindings array at the correct location specified by the binding index. since tensorrt 6, an engine can have a optimization profiles, and each profile has it's own set of bindings. this pr make binding index query compatible with multiple optimization profiles. </desc> <cmt> update tensorrt binding index query, so that it works with profiles </cmt>",improve tensorrt binding index query
4110,<desc> we've recently added the batch percentage and average batch size to the disruptor-net performance tests.  we've found that it allows us to quickly see how the effects of batching impact the throughput figures.  i.e. the counter-intuitive effect that a slower consumer can lead to higher throughput as the rate of batching increases. </desc> <cmt> add batch percent and average batch size to performance tests </cmt> <cmt> fix display when batches are not counted </cmt>,add batch size to performance tests
4111,"<desc> when the whole module is spi, as in compiled with -library-level spi, allow the use of spi declarations in api. with the rebranch it should now be safe to print the flag in the module interface. rdar://75335462 </desc> <cmt> [sema] print the library-level in the textual interface </cmt> <cmt> [sema] allow the use of spi in api for spi modules </cmt> <cmt> when the whole module has an spi distribution, spi declarations can be </cmt> <cmt> used in api. </cmt> <cmt> rdar://75335462 </cmt>",allow spi use in api for a module that is completely spi
4112,"<desc> move paper elevation warning to proptypes adjust error counting due to facebook/react#18430 (self-note: would expect(() => {}).toerror() help here?) use fork of enzyme-adapter-react-16 ( </desc> <cmt> temp: use react@next </cmt> <cmt> [paper] move elevation warning to proptypes </cmt> <cmt> [popover] use checkproptypes over .proptypes </cmt> <cmt> test: fix broken test due to strictmode change </cmt> <cmt> test(ci): use dedicated adapter for react@next </cmt> <cmt> revert ""temp: use react@next"" </cmt> <cmt> this reverts commit bf5b3ea49b2e92dd58cfed9b20830dad41a71377. </cmt> <cmt> temp: test with react-dist-tag: next in ci </cmt>",fix broken tests in react@next
4113,<desc> history: this.$nuxt accidentally crept in in the static target pr (#6159). this caused an error which was solved by testing for this.$nuxt rather than using globalname (#7766) as is done elsewhere in the component (see #4743) this pr reverts to using globalname. resolves #8118 </desc> <cmt> fix(vue-app): use nuxt globalname correctly in nuxt-link </cmt> <cmt> closes #8118 </cmt> <cmt> fix: use globals.nuxt in fetch mixin too </cmt> <iss> reference in nuxt-link.client.js to this.$nuxt causes error when custom globalname is set </iss>,use nuxt globalname correctly in nuxt-link and fetch mixin
4114,"<desc> adding in @jsteube's documentation for manual tuning in the hashcat.hctune file for scrypt algorithms after editing and proof-reading. </desc> <cmt> add scrypt manual tuning information </cmt> <cmt> fix typo, spelling </cmt> <cmt> grammar changes, phrasing </cmt>",add edited documentation for scrypt manual tuning
4115,"<desc> when you delete files from the header option, deleted files will not be shown. delete-files-pr.mp4 closes #21627 </desc> <cmt> added toast message after deleting file </cmt> <cmt> fixed delete files issue </cmt> <iss> file item doesn't get removed from the files list on deleting </iss>",files list will not show deleted files.
4116,"<desc> as of #1952, lottie now handles its own bitmaps for software rendering. this was causing an issue for very large compositions. lottie was creating a bitmap at the size of the entire composition which was often far larger than was needed. the most common case for this to happen is when people make 1928x1080 compositions in after effects thinking it's 1:1 with displays. however, lottie treats dimensions in dp which would cause a 1080p composition to have ~6000x4000 pixel bounds. with this pr, lottie will now calculate the largest area that the bitmap can be rendered in given either its bounds, scale, or scaletype and then render a smaller bitmap to a larger area in the original canvas. </desc> <cmt> works with imageview scale types </cmt> <cmt> all scale types work </cmt> <cmt> all scale types work </cmt>",reduce the memory footprint of software rendering
4117,"<desc> cut down on the number of messages sent by not sending a request message when not needed. do not disconnect on unexpected blocks that are valid when syncing. verify last irreversible block notice is not out of date. </desc> <cmt> remove unneeded request_message </cmt> <cmt> sync_master recv_block only called on valid blocks, so don't disconnect if unexpected </cmt> <cmt> check for out of date last irreversible block notice </cmt>",net plugin unexpected block - develop
4118,"<desc> as described here #2210 and #2218, commit for #1841 broke dots handling in ids. this pr replaces dots with underscores when building event handler name. id in container's dom element is set in unescaped version. dots are treated specially in jquery for event handler name - they represent namespace parts. so best would be no dots, as they misleadingly suggest namespaces for jquery. here is jsfiddle with pr select2.js version - first select's id contains dots, [ ] and minus chars: </desc> <cmt> replace dots with underscores in event handler names. dots are processed in special way in jquery on/off. </cmt> <cmt> set id in unescaped version. </cmt>",fix for dots in id
4119,"<desc> ... really this time :) i went for the simpler fix after all since it turned out to become a bit too complicated to extract the current iteration value from its containing option with the different memory layouts it can have. it's also what we already do for match bindings. i also extended the new test case to include the ""simple identifier"" case. fixes #20127, fixes #19732 </desc> <cmt> debuginfo: create debuginfo for for-loop variables again. </cmt> <cmt> debuginfo: clean the debuginfo module up a bit. </cmt> <cmt> debuginfo: add test case for destructured for-loop variable. </cmt> <iss> debuginfo: ""lexical-scope-in-for-loop"" auto-test fails </iss> <iss> internal compiler error: debuginfo::create_for_loop_var_metadata() </iss>",fix regression in for-loop variable debuginfo ...
4120,"<desc> reverts #883 </desc> <cmt> revert ""health check: add tcp ""connect only"" health check (#924)"" </cmt> <cmt> this reverts commit 1a7b0f9977c7b9d99c530f18cddf29adf18725e7. </cmt> <cmt> revert ""docs: pin all python requirements (#929)"" </cmt> <cmt> this reverts commit e91e1f569c1de3ad81cc2b51553deefb5da8b2b8. </cmt> <cmt> revert ""test: add ipv6 testing to integrationtest.echo (#883)"" </cmt> <cmt> this reverts commit a55b88dcd3515a9f57ee7b43cf0f20bd26b21da3. </cmt>","add ipv6 testing to integrationtest.echo"""
4121,<desc> this pr contains two commits. make compiler warnings into errors in travis builds fix for a warning in copy.c that fails the build due to (1) </desc> <cmt> make warnings into errors in travis build </cmt> <cmt> builds will now fail in travis if a warning is </cmt> <cmt> raised. </cmt> <cmt> fix compilation warning in copy code </cmt> <cmt> this change fixes a compilation warning in the </cmt> <cmt> copy code that was introduced with an earlier </cmt> <cmt> refactoring pr. </cmt>,make warnings into errors in travis builds
4122,"<desc> this patch implements the next chunk of flattening out the type checking context. in a series of patches i moved around the necessary state and logic in order to delete the typer and closuretyper traits. my next goal is to clean the interfaces and start to move the normalization code behind them. r? @nrc i hope my pr is coherent, doing this too late at night ;) </desc> <cmt> move fufillmentcontext into infercontext </cmt> <cmt> update all uses of fulfillmentcontext </cmt> <cmt> update all uses of fulfillmentcontext to be ones obtained via </cmt> <cmt> an inferctxt. this is another step of flattening the type </cmt> <cmt> checking context into a single piece of state. </cmt> <cmt> use fresh fulfillmentcontexts in select locations </cmt> <cmt> remove normalizingclosuretyper </cmt> <cmt> remove typer + closuretyper impls for parameterenv </cmt> <cmt> remove typer + closuretyper impls for blocks </cmt> <cmt> remove typer and closuretyper </cmt> <cmt> this commit finalizes the work of the past commits by fully moving the fulfillment context into </cmt> <cmt> the inferctxt, cleaning up related context interfaces, removing the typer and closuretyper </cmt> <cmt> traits and cleaning up related intefaces </cmt> <cmt> clean up patch </cmt>",move fulfillmentcontext into inferctxt and remove typer + closuretyper
4123,"<desc> this closes #4622, by adding 2 basic activation functions: logsigmoid and softshrink logsigmoid is defined as: y = log ( 1 / ( 1 + exp(-x))) however, to make the computation numerically stable for large negative values of x, the well-known ""log-sum-exp"" trick is employed. ( softshrink is defined as follows (for a non-negative lambda): y = x - lambda, if x > lambda x + lambda, if x < -lambda 0, otherwise </desc> <cmt> add numerically-stable logsigmoid activation </cmt> <cmt> add softshrink operator </cmt> <cmt> adjust relative tolerance for grad-check </cmt> <iss> logsigmoid (numerically stable) and softshrink activations </iss>",add logsigmoid (numerically stable) and softshrink
4124,<desc> enable sourcekit's tests if building sourcekit change packaging sourcekit-inproc from sourcekitdinproc.framework to libsourcekitdinproc.so on non darwin platforms this will be required for #8189 resolves sr-1676. </desc> <cmt> enable sourcekit tests if build sourcekit </cmt> <cmt> produce libsourcekitdinproc.so instead of sourcekitdinproc.framework if not darwin </cmt>,enable sourcekit tests if building sourcekit
4125,<desc> from here the plan is to move to passing int64_t* which will allow us to share code between the scalar/vector versions of this function </desc> <cmt> ref: use standard pattern for normalize_i8_timestamps </cmt> <cmt> unused import </cmt>,use standard pattern in normalize_i8_timestamps
4126,"<desc> as the comment in the code suggests, we've had to decrease the too_far_behind timeout before, due to mongo performance improvements, so i've decreased it yet again, from 800ms to 500ms. while i was at it, i also replaced the gotspot polling logic with a promise, after making it possible for testasyncmulti functions to return promises to delay execution of the remaining functions. </desc> <cmt> allow testasyncmulti functions to return promises. </cmt> <cmt> bump test-helpers package version to 1.0.13. </cmt> <cmt> improve ""oplog - entry skipping"" test to prevent intermittent failures. </cmt>","improve ""oplog - entry skipping"" test, which has been failing intermittently."
4127,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. bpampuch/pdfmake#2148 bpampuch/pdfmake#2128 </desc> <cmt> [pdfmake] add image cover </cmt> <cmt> [pdfmake] add superscript and subscript </cmt>,"add image cover, superscript and subscript"
4128,<desc> fixes #8705. supersedes and closes #8725. </desc> <cmt> printing iter and max_iter in online_lda if verbose </cmt> <cmt> fixed typo to print iter and max_iter </cmt> <cmt> tst test verbose feature of latentdirichletallocation </cmt> <iss> latentdirichletallocation verbosity not very helpful by default </iss>,lda verbose should print iteration number in all cases
4129,"<desc> this revives deleted os macros in #6142 while allowing two different behaviors for noderawfs, as suggested in #6142 (comment). </desc> <cmt> revert ""remove unused os macros from test_unistd_unlink"" </cmt> <cmt> allow two different behaviors </cmt>",revive os macros & allow two behaviors on test_unistd_unlink
4130,"<desc> improvements to shell.nix were made in #8910 by @thorstenweber83, but the result was that the nix shell no longer worked on darwin. i have tidied up and improved some of the nix expression, fixing this issue along the way. if someone would be kind enough to test this on linux too, that would be appreciated, though i don't expect issues. removed unnecessary overrides provided a more complete python environment, adequate for actually running/developing bin/qmk unset nix_target_cflags_compile in the nix shell, to avoid incompatible host cc flags getting picked up by avr-gcc. none my code follows the code style of this project. i have read the contributing document. </desc> <cmt> shell.nix: no need to hack supported platforms list </cmt> <cmt> dfu-programmer and teensy-loader-cli are already listed as supported </cmt> <cmt> on darwin in nixpkgs. </cmt> <cmt> shell.nix: provide a python environment suitable for running/developing qmk </cmt> <cmt> shell.nix: fix darwin compilation issues </cmt>","shell.nix improvements, and fix problems on darwin"
4131,"<desc> backport of #36456 - in the case that a variable is missing we should return none otherwise we can break filters - to stable 2.5 branch. aws_ssm lookup plugin ansible version ansible 2.5.0b2 (stable-2.5-aws_ssm_return_none_noexist_fix 1e479b34c7) last updated 2018/02/21 08:34:24 (gmt +100) config file = none configured module search path = [u'/home/mikedlr/dev/ansible/ansible-dev/library'] ansible python module location = /home/mikedlr/dev/ansible/ansible-dev/lib/ansible executable location = /home/mikedlr/dev/ansible/ansible-dev/bin/ansible python version = 2.7.5 (default, aug  4 2017, 00:39:18) [gcc 4.8.5 20150623 (red hat 4.8.5-16)] see also pr #36456 for further description but i might add some further changes there.  this will be the minimal change for easy digestion into stable. </desc> <cmt> aws ssm parameter lookup - change to reutrn nones for missing variables </cmt> <cmt> aws ssm parameter lookup - fix error case message to dump response </cmt> <cmt> aws ssm parameter lookup - fix integration test cases </cmt> <cmt> aws ssm parameter lookup - fix integration test cases </cmt>",bring aws_ssm none fixes into stable (from #36456)
4132,<desc> indices upgrade api (/_upgrade or /{index}/_upgrade) was removed and _reindex is suggested to be used instead. there is no easy way to translate _upgrade request to _reindex requests. the dummy upgrade action will return an exception to a user with a message indicating that _reindex should be used. upgrade api removal #64732 relates #51816 </desc> <cmt> human debug </cmt> <cmt> draft upgrade </cmt>,dummy rest action for indices.upgrade api
4133,"<desc> in our application we give people control of the ""selected"" track on the player for dash streams however there was no way for people to identify the track, unless if you knew the bitrate or width/height properties. this change adds the id property to the mediaformat class which is read from the dash media presentation description. this way it's easier for users to identify tracks on the player. cla should be signed:  feedback is appreciated, feel free to ask questions. thanks. </desc> <cmt> added id property to mediaformat </cmt> <cmt> added the property 'id' to the mediaformat class </cmt> <cmt> which serves as an identifier for the track. </cmt> <cmt> dash representations will have the ""id's"" from their </cmt> <cmt> media presentation description mapped to the id property </cmt> <cmt> in the mediaformat class that will represent the track. </cmt> <cmt> we needed this for an use case where we wanted to read the 'id' </cmt> <cmt> value from the dash representation and present it to the user </cmt> <cmt> in order for the user to select the right track. </cmt> <cmt> deleted unnecessary file used for testing </cmt>",added id property to the mediaformat class
4134,"<desc> added charon keyboard to the charue family my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> initial test firmware </cmt> <cmt> added via keymap (untested) </cmt> <cmt> updated charon via keymap (tested) </cmt> <cmt> update readme.md </cmt> <cmt> update info.json </cmt> <cmt> cleanup </cmt>",adding charon keyboard to charue family
4135,"<desc> taskbar: set chdir to the home directory when opening applications although the chdir was set up for the applications opened from the quick launch, the regular application list hadn't do this. this meant that you could spawn a terminal or hackstudio project in the root directory, which isn't so bad, but it's better to stick to the user home directory. filemanager: set chdir to the current path when opening applications filemanager: use the current directory as one of the initial locations this change makes cd /bin; filemanager open the app in /bin. </desc> <cmt> taskbar: set chdir to the home directory when opening applications </cmt> <cmt> although the chdir was set up for the applications opened from </cmt> <cmt> the quick launch, the regular application list hadn't do this. </cmt> <cmt> this meant that you could open a terminal or hackstudio project </cmt> <cmt> in the root directory, which isn't so bad, but it's better to stick </cmt> <cmt> to the user home directory. </cmt> <cmt> filemanager: set chdir to the current path when opening applications </cmt> <cmt> filemanager: use the current directory as one of the initial locations </cmt> <cmt> this change makes cd /bin; filemanager open the app in /bin. </cmt>",set chdir when opening applications; use the current directory as one of the initial locations
4136,"<desc> remove ""require"" in scripting/javascript/bindings/js/ files, unify to jsb.js add obfuscate.xml into testjavascript, the usage is:  ant -buildfile obfuscate.xml. this step will regenerate testjavascript/game.js add a target called ""testjavascriptobfuscated"" into testjavascript.xcodeproj. ""remove game.js && ant -buildfile obfuscate.xml"" was written into a build phase in this target. as the result, in each time you build and run testjavascriptobfuscated, all js source in cocos2d-js-tests will be obfuscated into game.js, which is the only js file in obfuscated target. i have only modified the ios project. other platforms can do the same. note: to run the target testjavascriptobfuscated correctly, these jobs should be done: merge my pull request in cocos2d-js-tests repo cocos2d/cocos2d-js-tests#140 move the samples/javascript/cocos2d-js-test submodule's ref to the merged reference in step 1. </desc> <cmt> issue #1841, testjavascript-ios is obfuscated successfully </cmt> <cmt> issue #1841, improve tools/closure-compiler/obfuscate.py to general usage, with input params </cmt> <cmt> issue #1841, testjavascript is obfuscated successfully </cmt> <cmt> update submodule samples/javascript/shared to the same ref ptr as master branch </cmt> <cmt> update submodule scripting/javascript/bindings/generated to the same ref ptr as upstream/master branch. </cmt> <cmt> remove jsb_*_.js from compile list </cmt> <cmt> add icons into testjavascript.xcodeproj </cmt> <cmt> fixed #1841, obfuscated js source can run on ios correctly now. </cmt> <cmt> roll back samples/javascript/shared to the ref before. </cmt>",obfuscated js sources can run on jsb correctly now
4137,"<desc> if i'm not wrong this pr addresses the issue #649 </desc> <cmt> add support of codeset a for code 128 </cmt> <cmt> simplification, everything from 0 to 127 is supported by codeset a and b </cmt>",add codeset a support to code 128
4138,"<desc> this fixes our setup.py so that we don't need to pip install with --no-use-pep517 anymore. everything still works with --no-use-pep517 though, so this can be immediately merged. i will follow up with prs to restore pep517-enabled pip everywhere, when i have the time. here's a hopefully correct recap of what went down before i started working on this; some of the stuff i said in getsentry/getsentry#3074 and getsentry/getsentry#3098 isn't accurate, in retrospect. we introduce a pyproject.toml to configure black. for pip 19+, the presence of this file triggers a pep517 build backend. we didn't specify a build-system config section, in which case the build-backend key under this section defaults to the pep517-compliant setuptools.build_meta from setuptools>=40.2.0. (reference:  however, this breaks pip installs, and me failing to completely understand the issue or finding a fix for the root cause in a reasonable amount of time results in discovering and slapping --no-use-pep517 everywhere. disabling pep 517 means we get the legacy behavior of directly executing setup.py, which works. everything is fine, but --no-use-pep517 trips some people up, and also i get bored and think the whole situation isn't ideal, so i try again. okay, so. a sneaky little portion of pep 517 says: if the pyproject.toml file is absent, or the build-backend key is missing, the source tree is not using this specification, and tools should revert to the legacy behaviour of running setup.py (either directly, or by implicitly invoking the setuptools.build_meta:legacy backend). i really thought this was it, because it was added in pypa/setuptools#1642 following extensive discussion from pypa/pip#6163. it's supposed to emulate directly executing setup.py. so i removed --no-use-pep517 and explicitly defined requires = [""setuptools>=40.2.0"", ""wheel""] build-backend = ""setuptools.build_meta:__legacy__"" which got this legacy backend to run, but i ran into the same exact issue. so that implies that the emulation breaks with our setup.py... or does it? perhaps it's got to do with not actually directly executing setup.py? what are the consequences of that? oh, look at how we calculate a part of the path to sentry to inject into sys.path so we can import sentry.utils.distutils: root = os.path.realpath(os.path.join(os.path.dirname(sys.modules[""__main__""].__file__))) the crux of it is sys.modules[""__main__""]. when pip goes on its pep517 code path (triggered by pyproject.toml or --use-pep517), it actually subprocesses out to _vendor/pep517/_in_process.py, which results in that being set to <module '__main__' from '/users/joshua.li/.local/share/virtualenvs/sentry2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py'>. and then the old importerror: no module named sentry.utils.distutils naturally follows. changing it to os.path.dirname(os.path.abspath(__file__)) is more correct and fixes pip installs, whether or not pep517 is disabled, and regardless of setuptools.build_meta or setuptools.build_meta:__legacy__ build backends. </desc> <cmt> lol </cmt> <cmt> remove pep517 disabling </cmt>",sentry now installs via pep517-enabled pip
4139,<desc> submitted as part of an sklearn open source sprint. pair programming with @anilkumarteegala. partially addresses #17417 (for a subset of classes). this pr adds docstring links to the following classes: sklearn.ensemble.stackingregressor sklearn.ensemble.stackingclassifer sklearn.ensemble.adaboostclassifier sklearn.ensemble.adaboostregressor </desc> <cmt> add stackingclassifier docstring links to objects </cmt> <cmt> add stackingregressor docstring links to objects </cmt> <cmt> add adaboostregressor docstring links to objects </cmt> <cmt> add adaboostclassifier docstring links to objects; also add docstring links to file-level docstring </cmt> <cmt> fix flake8 violations </cmt>,enable links to objects in docstrings (sprint issue #17417)
4140,"<desc> sync @tinyallen 's update of ui, the elementui has been removed from dependency, replaced by the lightweight implementation. i will check on the demo env later. </desc> <cmt> sync ui. </cmt> <cmt> remove elementui license </cmt>",ui sync & remove elementui license
4141,"<desc> rx.js inconsistent with official naming, so it was renamed to rx; rx.jquery.d.ts extracted to separate folder/package, due official package separation. reverted changes made by #2537 </desc> <cmt> rx.jquery.d.ts moved to separated folder 'rx-jquery'. </cmt> <cmt> rx.js renamed to rx. </cmt> <cmt> fixed reference path in rx.jquery.d.ts </cmt> <cmt> fixed reference path to rxjs in knockout.rx.d.ts </cmt>",rename to 'rx' and extract 'rx-jquery' module.
4142,<desc> closes #13756 drastically improves the ui of 404 pagenotfound.html initial state final status </desc> <cmt> changes channel description to textarea </cmt> <cmt> solves linting issue </cmt> <cmt> initilizes pagenotfound.js </cmt> <cmt> initilizes stylesheet </cmt> <cmt> some random progress </cmt> <cmt> stylizes 404 pagenotfound.html </cmt> <cmt> changes colors so that they are extracted from theme </cmt> <cmt> fixes linting </cmt> <iss> the text in 404 page is unreadable </iss>,ui of page not found
4143,"<desc> log looks like this now: 2014-03-19 03:56:30+0600 [scrapy] crawled (402) <get  2014-03-19 03:56:30+0600 [scrapy] ignoring response <402  i haven't put a test spider to scrapy.tests.spiders because it is unlikely be useful for other tests. docrawl function was copy-pasted several times so i added it to scrapy.utils.test. in test_crawl crawler is now configured immediately instead of being configured via yield defer.maybedeferred(self.configure) in crawler.start(), but it doesn't seem to affect anything. </desc> <cmt> reduce code duplication in test_spidermiddleware_httperror </cmt> <cmt> scrapy.utils.test.docrawl function </cmt> <cmt> fix for #612 + integration-style tests for httperrormiddleware </cmt> <cmt> tst fix file descriptor leak and a bad variable name in get_testlog </cmt>",fix for #612 + small tests cleanup
4144,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [googlemaps] marker: improve marker events declaration & add jsdoc </cmt> <cmt> [googlemaps] marker: extract tests to separate file </cmt>",marker events jsdoc & separate tests
4145,"<desc> before: after: improvements to the ""event grouping information"" section on event detail page. this section has been available for early adopters for almost a year now (it's collapsed by default). as part of the ga initiative, we made a few improvements: converted to typescript split into multiple smaller files replaced css styles added translations refreshed design it still remains behind the grouping-info feature flag. </desc> <cmt> feat(ui): split groupinfo components into multiple files </cmt> <cmt> wip </cmt> <cmt> feat(ui): refactored index page </cmt> <cmt> ref(ui): refactored groupconfigselect </cmt> <cmt> ref(ui): refactor groupingvariant </cmt> <cmt> ref(ui): refactor groupingcomponent </cmt> <cmt> feat(ui): redesign contribution toggle, variant title, grouping in keyvalue list </cmt> <cmt> wip </cmt> <cmt> colors </cmt>",improve event grouping information section
4146,"<desc> rewrite deno test subcommand - no longer requires to download files from internet add cli/testing.ts - this file is a trimmed down copy of std/testing/mod.ts - has only test() and runtests() method rust test js_unit_test now uses deno.test() to create all test cases instead of relying on std/testing/mod.ts (this is just some dog-fooding) deno test does not support globs expansion and exclusion. one needs to pass a full list of files that should be run - ie. you can still call deno test */*_test.ts but it is shell's job to expand the glob. it's really an mvp to take a step back and look at test module to provide essential things to write test. i expect that third party testing frameworks will arise (or be ported from node). so by no means this pr tries to establish a ""batteries-included""  testing framework. </desc> <cmt> wip new testing framework </cmt> <cmt> merge mod and new_mod </cmt> <cmt> fix runifmain </cmt> <cmt> self host js unit tests </cmt> <cmt> wip2 </cmt>","rewrite deno test, add deno.test()"
4147,"<desc> what do these changes do? for supporting this, we change the fields in gcs.fbs: change [string] to one string that concatenates the array of strings. also, there is a script to support to add a package declarations to auto-generated files. (we should find another approach for this in the future.) this is the related pr. n/a </desc> <cmt> auto gen flatbuffers for java </cmt> <cmt> add auto_gen_tool.py </cmt> <cmt> refine </cmt> <cmt> add a comment </cmt> <cmt> address comments. </cmt> <cmt> address comments. </cmt> <cmt> addressed </cmt> <cmt> refine </cmt> <cmt> address comments </cmt> <cmt> fix typo </cmt> <cmt> add exception </cmt> <cmt> address comments. </cmt> <cmt> refine </cmt>",support to auto-generate java files from flatbuffer
4148,<desc> fixes #65300 fixes #61058 r? @oli-obk </desc> <cmt> report  lint in external macros </cmt> <cmt> add regression test for const_err lints in extern macros </cmt> <iss> external macros don't evaluate panicking consts when crate-local ones do. </iss> <iss> `rustc_data_structures::static_assert!(false)` does not error </iss>,report const_err lint in external macros
4149,"<desc> now javascript-style declarations like this.foo = ""bar"" are handled correctly and errors will be reported on the declaration correctly. previously the code would check the computed property name case and crash because javascript-style declarations have no name property. fixes #15525 </desc> <cmt> add js declaration to index constraint check error reporting </cmt> <cmt> now javascript-style declarations like this.foo = ""bar"" are handled </cmt> <cmt> correctly. </cmt> <cmt> test:index constraint check on js class expression </cmt>",add javascript declarations to index constraint check error reporting
4150,"<desc> added the solution to the problem discussed in the issue #2634. i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> vertical order traversal in a tree added </cmt> <cmt> delete .classpath </cmt> <cmt> delete .project </cmt> <cmt> update verticalordertraversal.java </cmt> <cmt> removed the node class and used the existing binary tree class , also instead of printing the values a sequence in arraylist of ans is returned. </cmt> <cmt> update verticalordertraversal.java </cmt> <cmt> create powsum.java </cmt>",implement a solution to a backtracking problem
4151,"<desc> addresses #15761 default value in sklearn/feature_extraction.text.countvectorizer for the token_pattern parameter cc: (sprint partners) @tijanajovanovic @tahirnadia </desc> <cmt> updated documenation in countvectorizer function for the token_parameter default value </cmt> <cmt> removed the r before the string, error in flake8 </cmt> <cmt> additional change to see if flake8 error solved </cmt>",doc update to text/countvectorizer token_pattern parameter default value
4152,"<desc> fix a missing else if value.isnull() it properly sets align, but then ultimately hits the assert(false); because of a missing else #3465 microsoft reviewers: open in codeflow </desc> <cmt> fix else if for null </cmt> <cmt> change files </cmt>",fix assert/missing else when setting alignself to null
4153,"<desc> check function type parameters for this references. previously, when checking for this references, the compiler did not check type parameters. this caused it to miss some instantiations that were necessary. also some cleanup: rename isindependent* to is*freeofthisreference. 'independent' was a one-off concept that was unique to typescript (and isn't referenced in the spec), so i think the new name is friendlier to new readers. use array.every whenever possible, since typescript added a dependency on es5 since the code was first written. switch to jsdoc so explanations show up nicely in editors. fixes #16930 </desc> <cmt> check function type parameters for this references </cmt> <cmt> previously, when checking for this references, the compiler did not </cmt> <cmt> check type parameters. this caused it to miss some instantiations that </cmt> <cmt> were necessary. </cmt> <cmt> also some cleanup: </cmt> <cmt> 1. rename isindependent* to is*freeofthisreference. 'independent' was a </cmt> <cmt> one-off concept that was unique to typescript (and isn't referenced in </cmt> <cmt> the spec), so i think the new name is friendlier to new readers. </cmt> <cmt> 2. use array.every whenever possible, since typescript added a </cmt> <cmt> dependency on es5 since the code was first written. </cmt> <cmt> 3. switch to jsdoc so that it shows up nicely in editors. </cmt> <cmt> test:this instantiation in type parameters </cmt> <cmt> make sure that this gets instantiated when it's used as a constraint </cmt> <cmt> of a type parameter, and nowhere else in a signature. </cmt>",instantiate this when used only in type parameter constraints
4154,"<desc> currently (especially in jit) we make heavy use of the universal selector (*) to do these sort of ""resets"" for composable utilities, transform for example: *, ::before, ::after { --tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --tw-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; transform: translatex(var(--tw-translate-x)) translatey(var(--tw-translate-y)) rotate(var(--tw-rotate)) skewx(var(--tw-skew-x)) skewy(var(--tw-skew-y)) scalex(var(--tw-scale-x)) scaley(var(--tw-scale-y)) } it turns out reading/writing to css variables can be expensive on site that have a lot of dom nodes (like the tailwind css home page) and that causes things to render more slowly than they really should have to if you only apply those rules when needed. this pr adds a separate optimization step that ensures what used to be the universal selector is replaced with only the selectors needed, so the output looks more like: .rotate-3, .scale-x-150, .hover\:scale-110, .focus:rotate-6, .md\:translate-x-4 { --tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --tw-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; transform: translatex(var(--tw-translate-x)) translatey(var(--tw-translate-y)) rotate(var(--tw-rotate)) skewx(var(--tw-skew-x)) skewy(var(--tw-skew-y)) scalex(var(--tw-scale-x)) scaley(var(--tw-scale-y)) } ...where the selectors included are all of the ones used in your template files that depend on this reset. to make this work, we've added a new @defaults at-rule, which we consider private api for now until we're sure it's the correct abstraction. </desc> <cmt> wip </cmt> <cmt> run prettier </cmt> <cmt> drop new lines in custom matcher </cmt> <cmt> drop all newlines, let prettier handle everything for us. </cmt> <cmt> add cache for the selector parser </cmt> <cmt> add @apply tests for the universal optimizer </cmt> <cmt> drop comments </cmt> <cmt> initial replacements </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> make it work </cmt> <cmt> rename to resolvedefaultsatrules </cmt> <cmt> update tests + defaults identifiers </cmt>",optimize universal selector usage by inlining only the relevant selectors
4155,"<desc> this pr adds the option override_environment_variables=dict() to override environment variables for tasks and actors.  these overrides are inherited by nested tasks and nested actors. this pr builds off of #11040, and the context is the same: context for serve we want to solve the issue of environment isolation. a user should be able to submit two models from to different environments to serve. for example, one model depends on tensorflow 1 and the other depends on tensorflow 2. our original thinking was to use multi-tenancy and job config to capture the driver environment and let the worker to have the same environment. user activate tensorflow 1 environment, runs deploy script in it, the model actor should run in tf1 environment. user activate tensorflow 2 environment, ..., the model actor should run in tf2 environment. issue with current multi-tenancy in serve, our architecture involves a centralized controller actor that manages actor creation and destruction. this is a detached actor is started by a different driver. therefore, when this actor calls modelworkerclass.remote(). the model worker inherits the job environment of the controller. job #1 ---> starts controller job #2 -> driver deploy tf1 -> send to controller -> create tf1 worker (but has the env of job #1!) job #3 -> driver deploy tf2 -> send to controller -> create tf2 worker (but has the env of job #1!) current fix current fix is simply to allow controller override the environment variable for the model workers. the workers created by the controller will still belong to the same job as the controller. if you have any suggestion for better way to doing this, please let us know! i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [wip] add override_worker_env to actor creation option </cmt> <cmt> add dosctring and comments, remove debug log </cmt> <cmt> update src/ray/common/task/task_spec.cc </cmt> <cmt> update src/ray/core_worker/common.h </cmt> <cmt> add docstring </cmt> <cmt> lint </cmt> <cmt> lint </cmt> <cmt> add recursive env overrides for actors and tasks </cmt>",add option to override environment variables for tasks and actors
4156,<desc> see #15761 this pr change how default values are documented in sklearn.metrics.pairwise.py and update docstring according to guideline. </desc> <cmt> update docstring </cmt> <cmt> make reference to shapes of x and y matrices in doc consistent </cmt>,doc fix doc of defaults in sklearn.metrics.pairwise.py
4157,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> add constructors to types i added previously. this removes a warning when trying to use these classes while compiling typescript </cmt> <cmt> add namespace prefix to linkattributes </cmt>",add constructors to classes previously added in joint.shapes namespae
4158,"<desc> test the error for connectivity problems and show the message ""could not reach the marketplace to get apps info"" to better inform the user about the situation. how to test or reproduce take the rocket.chat box offline go to administration -> apps (the messages appear in the red toast) types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> fix error when trying to install apps from zip without internet </cmt> <cmt> move network error testing to handleerror function </cmt>",apps list page on servers without internet connection
4159,<desc> this pull-request contains changes associated with a coding style. related to #20356 </desc> <cmt> clang-format onednn files are adjusted by the formater. </cmt> <cmt> clang-format: ndarray file & duplication are removed </cmt> <cmt> a line contains only semicolon: it was removed </cmt>,auto-formatter to keep the same coding style
4160,"<desc> updated the build.py script to also build otf versions of the cascadia code fonts (in light of the blue zones added!). additionally added a ""build_woff.py"" script that will process the ttf files in the ""build"" folder to produce woff2 files. throws an error if vtt production tables present in the fonts. closes #236 updated build.py to also build otf file added build_woff.py to process ttfs to create woff2 files (if vtt production files have been removed) updated the requirements.txt file to include compression library for woff2 generation </desc> <cmt> minor bug fixes </cmt> <cmt> adding a few missing glyphs, modifying pl characters for better alignment and resolving issue with apple's atsui api. </cmt> <cmt> turning off morx addition </cmt> <cmt> revert ""minor bug fixes"" </cmt> <cmt> this reverts commit ade4ef128bb76171aabfd8d984af68b5ae37b296. </cmt> <cmt> minor update </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> april bug fixes </cmt> <cmt> updating the font to resolve a number of open bugs. also, cleaned up a number of glyphs. </cmt> <cmt> update fontlog.txt </cmt> <cmt> fixing inconsistent hinting offsets </cmt> <cmt> offsets for subscripts and inferior numbers are set inconsistently. these are now corrected. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> adding otf and woff2 generation </cmt> <cmt> modified the build.py script to add in otf generation, and also created a second build script that created woff2 files from the ttf files (if tsi data removed). requirements.txt updated to include woff2 compression library. </cmt> <iss> provide woff for cascadia code </iss>",updating scripts for otf and woff2
4161,"<desc> parallel with #14229. this is partial revert of #12708 which only reverts the breaking api change. </desc> <cmt> replace grpc_compress_message_* with grpc_compress_* </cmt> <cmt> replace message/deflate,gzip with deflate,gzip </cmt> <cmt> regenerate metadata </cmt> <cmt> remove compression_ruby </cmt> <cmt> build projects </cmt>",revert breaking api in #12708
4162,<desc> this is a pr to resolve all of comments left in previous pr: #13765 also provides a readme.md for this example. </desc> <cmt> update code to resolve comments left in previous pr. </cmt> <cmt> add readme.md file for this example. </cmt>,update the example of exporting bart + beamsearch to onnx module to resolve comments.
4163,<desc> python are c#  interop_matrix tests are currently broken for v1.18.0 (test cases files weren't regenerated - see  fix python and c# tests for v1.18.0 release (the interop client is now in a different directory for c# and python) make sure that interop_matrix works fine even if testcase commands don't contain --server_host_override (consequence of #17407). get rid of testcases_version_matrix (it didn't make sense for the data to be separate) matrix and integrate the data into lang_release_matrix unify the logic for handling test case files for csharp and csharpcoreclr runtimes cleanup some older testcase files. </desc> <cmt> interop_matrix: integrate testcases file to release info </cmt> <cmt> generate new testcases for c# </cmt> <cmt> add csharpcoreclr__v1.1.4 </cmt> <cmt> cleanup: get rid of ip literals from node__v1.1.4 testcases </cmt> <cmt> interop_matrix: update python testcases for 1.18.0 </cmt> <cmt> run_interop_matrix_tests.py fixes </cmt>,fix c# and python interop_matrix for v1.18.0 release and other cleanup
4164,"<desc> how to test: bind some key to cycle-values vo null gpu play a remote file so that the demuxer cache is active press the key and observe that: it works the demuxer cache is not dropped when switching use case: mpv-android has to disable video output while the app is in background since the surface disappears. it currently does that by switching vid between no and 1, which drops the demuxer cache every time the app is brought in/out of background, causing noticeable delay. </desc> <cmt> demux: add function to refresh a track without (de-)selecting it </cmt> <cmt> player: allow vo to be switched at runtime </cmt>",allow vo changing at runtime
4165,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. add playsound to channelobject:  add action to notification:  add userinfo to notification: based on observed behavior in the code add it to notneededpackages.json. </desc> <cmt> [react-native-push-notification] renames pushnotification interface to receivednotification to avoid mixing its properties with imported pushnotification from react-native-push-notification module </cmt> <cmt> [react-native-push-notification] adds action to receivednotification </cmt> <cmt> [react-native-push-notification] adds userinfo to receivednotification and changes pushnotificationoptions.onnotification and pushnotificationoptions.onaction argument based on the observed behavior of the package </cmt> <cmt> [react-native-push-notification] adds playsound to the channelobject </cmt>",fixes the name of an interface and adds some missed properties
4166,"<desc> comma should not be a delimiter for non-file form fields. quoting does not apply to content types. </desc> <cmt> cli tool: in -f option arg, comma is a delimiter for files only </cmt> <cmt> also upgrade test 1133 to cover this case and clarify man page about </cmt> <cmt> form data quoting. </cmt> <cmt> bug: </cmt> <cmt> reported-by: omau on github </cmt> <cmt> cli tool: improve "";type="" handling in -f option arguments </cmt>",two cli tool -f option fixes
4167,"<desc> description: a change in the pyhomematic library introduced a separate class for sepcific binary sensors, which lead to the mapping to opening type to break. this slipped by unnoticed and is fixed by this pr. related issue (if applicable): fixes #24080 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> update pyhomematic to 0.1.60 </cmt> <cmt> devicetype for pyhomematic classes, fixes #24080 </cmt> <iss> homematic: window sensor (optical) device_type missing </iss>",fix device types for some homematic ip sensors
4168,"<desc> i've had these changes sitting around in my branch for ages. i figure hacktoberfest is a good time to finally push them over! n/a my code follows the code style of this project: c, python i have read the contributing document. </desc> <cmt> add method to query qmk firmware version </cmt> <cmt> add kc_ver custom macro to all my keymaps </cmt> <cmt> update readmes </cmt> <cmt> remove kc_trns and replace with underscores </cmt> <cmt> fix up 75% keymap </cmt> <cmt> update readme </cmt> <cmt> update changelog </cmt> <cmt> update readme </cmt>",some updates to my personal userspace and keymaps
4169,"<desc> function optimization others </desc> <cmt> [2.0custom op]support new custom op on windows (#31063) </cmt> <cmt> * [2.0.1]support new custom op on windows </cmt> <cmt> * fix ci </cmt> <cmt> * fix code style </cmt> <cmt> * fix ci </cmt> <cmt> * fix ci </cmt> <cmt> * fix coverage </cmt> <cmt> * fix ci </cmt> <cmt> * fix ci </cmt> <cmt> fix unix cmake problem (#31113) </cmt> <cmt> [customop] split test and add inference test (#31078) </cmt> <cmt> * split test & add inference test </cmt> <cmt> * add timeout config </cmt> <cmt> * change to setup install </cmt> <cmt> * change to jit compile </cmt> <cmt> * add verbose for test </cmt> <cmt> * fix load setup name repeat </cmt> <cmt> * polish details </cmt> <cmt> * resolve conflict </cmt> <cmt> * fix code format error </cmt> <cmt> [custom op]fix problem of custom op unitests on windows ci (#31114) </cmt> <cmt> * fix some problem of windows custom op </cmt> <cmt> * fix some problem of windows custom op </cmt> <cmt> * fix some problem of windows custom op </cmt> <cmt> [customop] split build directory for each setup.py (#31124) </cmt> <cmt> * split build directory for each setup.py </cmt> <cmt> * fix template string </cmt> <cmt> [customop] add new paddle custom op so (#31141) </cmt> <cmt> * add new custom op so </cmt> <cmt> * fix use new method error </cmt> <cmt> * fix test failed </cmt> <cmt> [customop] support to specific extra_cflags and exctra_cuda_flags independently (#31059) </cmt> <cmt> * split cxx/nvcc compile flags </cmt> <cmt> * enhance input argument check </cmt> <cmt> * rename extra_cflags into extrac_cxx_flags </cmt> <cmt> * add name checking in setup </cmt> <cmt> * fix test_dispatch failed </cmt> <cmt> * fix word typo and rm usless import statement </cmt> <cmt> * refine import statement </cmt> <cmt> * fix unittest failed </cmt> <cmt> * fix cuda flags error </cmt> <cmt> [customop] support attributes as func input in custom op (#31128) </cmt> <cmt> * add simple attr support and test </cmt> <cmt> * add int, float attr support </cmt> <cmt> * support other attribute </cmt> <cmt> * add custom attrs test in cmake </cmt> <cmt> * polish details </cmt> <cmt> * fix test failed </cmt> <cmt> * add backward test </cmt> <cmt> * update test flags </cmt> <cmt> [customop]add cpp_extension  en doc (#31187) </cmt> <cmt> * add cpp_extension en doc </cmt> <cmt> * remove cuda_cflags and add optional in doc </cmt> <cmt> * refine style </cmt> <cmt> * fix indent problem </cmt> <cmt> * add default none </cmt>",the second part of new custom op extension in 2.0.1
4170,"<desc> following up a discussion from #10591 automated invariance test are currently implemented in test_common.py for scalar ranking functions. it is desirable to have these tests also be available for ranking metrics with potentially non-scalar outputs. for example roc_curve, classification_report or confusion_matrix. scope of this pr is to generalize test_common.py to allow testing of metrics with non-scalar output. this shall be achieved by replacing all assert in such a away that they allow assertion on array-like structures. it should first be discussed if a solution like this is feasible. an alternated route suggested by @jnothman is to aggregate non-scalar metrics using an arbitrary measure and apply the scalar invariance tests. to-do add other metrics to the tests add wrappers for assert_array_greater and assert_array_not_equal check if certain tests become obsolete (if so remove them) </desc> <cmt> support non-scalar output in metrics invariance tests </cmt> <cmt> add curves to invariance tests </cmt>",invariance test for non-scalar metric
4171,"<desc> this is the same pull request as in #41090. i closed it as i messed up the branch and then when i was going to open it, i can't anymore because i have force pushed the branch. adds a flutter sample app based on the material study rally (a hypothetical, personal finance app). it showcases custom tabs, custom painted widgets, and custom animations. related issues n/a n/a before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add rally to examples </cmt> <cmt> follow styleguide </cmt>",add material study app rally as an example app
4172,"<desc> when building event aggregators. event hubs, mediators, and other objects with backbone.events, you need to be able to specify the context in which an event callback is executed. with the standard on and off methods, this works just fine, but the new listento and stoplistening methods lacked a context parameter to handle this. example: an event aggregator to communicate between two parts of an app var vent = _.extend({}, backbone.events); var obj1 = new myobjectwithevents(); var obj2 = new anotherobjectwithevents(); vent.listento(obj1, ""foo"", obj2.dostuff, obj2); obj1.trigger(""foo""); this is a very common pattern in my applications, with the use of marionettejs. up until now, i've been using my backbone.eventbinder to handle this situation. but with the inclusion of listento and stoplistening in backbone.events, i want to deprecate backbone.eventbinder. i need to have this 4th parameter for context available in order to do that without resorting to bind, apply, and call function calls everywhere. this pr adds the 4th parameter to both, with test to show functionality, and minor tweaks to the docs. reference material on event aggregators:   the inability to specify context means that objects must be directly coupled to each other in order to use listento and stoplistening. this direct coupling causes poor system design, tightly coupled application code, and a general spaghetti mess in large scale applications where objects must be able to communication indirectly - without direct knowledge of each other. </desc> <cmt> allow context as 4th parameter to events#listento method </cmt> <cmt> allow context as 4th parameter of stoplistening </cmt> <cmt> updated docs to add context param in listento and stoplistening </cmt>",add context as 4th parameter to listento and stoplistening methods on backbone.events
4173,<desc> these changes enable vreffect and vrcontrols to use the newly recommended webvr best practices when the updated version of the api is detected. also took the opportunity to remove the really old code path because i don't think anyone is actually using it anymore. the browsers that it supported have all been updated to at least the webvr 1.0 spec. </desc> <cmt> updating vreffect and vrcontrols to support webvr 1.1 </cmt> <cmt> stripped out really old webvr code path that's no longer used. </cmt> <cmt> i'd be shocked if anyone was still attempting to use the browser builds </cmt> <cmt> that the old code path was supporting. </cmt> <cmt> ensured that vreffect uses the right eye transforms </cmt> <cmt> since some view matrices may include orientations as well as </cmt> <cmt> translations we need to extract the head-to-eye transforms from the view </cmt> <cmt> matrices to ensure accurate results. this isn't normally necessary but </cmt> <cmt> is required in three.js because the camera is already transformed into </cmt> <cmt> the head position with the vrcontroller. </cmt>,"update with support for webvr ""1.1"""
4174,<desc> related to #19266 this allows us to control github actions through python and not yaml files using other projects. </desc> <cmt> ci usees simple python script to label base on title </cmt> <cmt> ci removes unneeded config </cmt>,ci check only title for regex labeling
4175,"<desc> new settings: reset interval (ms) reset metrics if greater than 0 collect nodejs gc false by default api: track user agent false by default reducing the number of metrics new metrics: rocketchat_metrics_size the calls received from prometheus to pull the data rocketchat_metrics_requests the size of the metrics reported to prometheus rocketchat_info to concentrate the version/url/unique id removed the default labels that were replicating the version, url and unique id among all the records. </desc> <cmt> update prom-client and add setting to reset metrics </cmt> <cmt> # conflicts: </cmt> <cmt> #	app/metrics/server/lib/metrics.js </cmt> <cmt> add gc metrics </cmt> <cmt> fix metrics displaying api query strings </cmt> <cmt> # conflicts: </cmt> <cmt> #	app/api/server/api.js </cmt> <cmt> add setting to disable gc metrics (need restart) </cmt> <cmt> add metrics about metrics :) </cmt> <cmt> remove user_agent label report from apis </cmt> <cmt> prometheus improvements & setting to track user agent </cmt> <cmt> # conflicts: </cmt> <cmt> #	app/metrics/server/lib/metrics.js </cmt> <cmt> reduce statistics frequency </cmt> <cmt> metrics: only get url with params if calling method.call </cmt>","new metrics, performance and size improvements"
4176,"<desc> currently, when collapsedims actually collapses stuff, the inputslices is multiplied by undefined value (which is what was previously in the .sizes array). fix #4490 and #4513 </desc> <cmt> fix grid computation for topk kernel </cmt> <cmt> backslash alignment, no change in code </cmt> <iss> cuda topk dim=0 crash on small tensor in two lines of code </iss>",fix topk work size computation
4177,<desc> dural rotary encoder macro pad dural rotary encoder macro pad my code follows the code style of this project. i have read the contributing document. </desc> <cmt> create readme.md </cmt> <cmt> add files via upload </cmt> <cmt> create glcdfont.c </cmt> <cmt> create config.h </cmt> <cmt> create keymap.c </cmt>,latinpad(dural rotary encoder oled macro pad)
4178,"<desc> when a popup had a subsurface, view_child_init would fail to set the parent link, leading to the subchild not being able to extract the xdg_popup location. includes a fix to check child mapping recursively in order to ensure that we don't try to damage a subsurface before its parent is mapped, as well as an unmapping fix to ensure that we don't try to damage a subsurface after its parent has been unmapped and unlinked (which is neither needed nor possible, as the parent is required for position to be known). closes: #6038 </desc> <cmt> view: recursively check mapped of view_child tree </cmt> <cmt> a subsurface may be set to mapped without its parent. </cmt> <cmt> view: mark subchildren as unmapped in view_child_destroy </cmt> <cmt> the subchildren lose their parent association at this point, so they </cmt> <cmt> will not be able to see that the parent is unmapped. </cmt> <cmt> instead, just set the subchildren to be unmapped directly. </cmt> <cmt> view: set parent for view_child subsurfaces on init </cmt> <cmt> view_child_init was calling view_init_subsurfaces, which did not set the </cmt> <cmt> parent attribute for the subchildren. this lead to the subchildren </cmt> <cmt> acting as standalone children. if the parent was an xdg_popup, this </cmt> <cmt> would make the subchild unaware of the popup position. </cmt> <cmt> introduce view_child_init_subsurfaces for view_child_init to use </cmt> <cmt> instead. </cmt> <cmt> closes: </cmt> <iss> subsurface damage does not account for popup position </iss>",ensure view children have their parent set
4179,"<desc> this pr makes the following contributions: adds a new algorithm tree sort under /sorts (as assigned via this issue) adds a generic type implementation of bst under /datastructures/trees. the existing bst implementations used primitive type int, however, sortalgorithm interface requires sorting for any type that extends the comparable interface. therefore, generic type implementation of bst was required to facilitate tree sort. adds proper package names to /datastructures/trees/bstiterative and /datastructures/trees/bstrecursive classes. modify the class being used in main() function of /datastructures/trees/bstrecursive from bstiterative to bstrecursive. before this change, bstrecursive was testing bstiterative in its main() method which was clearly not correct. issue #2603. i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> add package </cmt> <cmt> add package and use bstrecursive (instead of bstiterative) in main </cmt> <cmt> add generic type implementation of bst (to fix issue #2603) </cmt> <cmt> fixes issue #2603: add tree sort algorithm </cmt>",implementation of tree sort and generic type bst
4180,"<desc> connecthitinsightsis currently declared as taking a react component and returning a react component. however, both the implementation (line 73 - 86) and the official algolia docs (steps 1 and 2) actually takes the insights client and return a functional component that is callable (see line 10 of the screenshot below). add the following types taken from react-instantsearch-core insightsclient insightsclientmethod insightsclientpayload update type: connecthitinsights to reflect the implementation (takes arg insightsclient, return a wrapped function) </desc> <cmt> add search-insights type and fix connecthitinsights </cmt> <cmt> export interface instead of type literal </cmt>",react-instantsearch-core fix insights api types
4181,"<desc> this pr adds the generic mode -m 22300 for sha256 ($salt . $pass . $salt) and the specific hash type -m 22301 = telegram (sha256) as requested in #1534 . the format for -m 22300 is of course just hash:salt, but the format for telegram is similar to the one generated by telegram2john.py (see  an example is like this: $telegram$1*518c001aeb3b4ae96c6173be4cebe60a85f67b1e087b045935849e2f815b5e41*25184098058621950709328221838128 (password for this hash is hashcat) where the first 1 is the (our internal) ""version number"" of the format, 518c00... is the sha256 digest and 25184... is the salt (in hex). thank you very much </desc> <cmt> added -m 22300 = sha256($salt.$pass.$salt) </cmt> <cmt> fixed #1534: added -m 22301 = telegram (sha256) </cmt>",added telegram and sha256($s.$p.$s)
4182,<desc> cont #11097 fix to preserve ellipsis #sync-getsentry </desc> <cmt> ref(interfaces): normalize query strings as pair lists </cmt> <cmt> ref(interfaces): jsonify structured query params </cmt> <cmt> fix: fix rendering of new query type </cmt> <cmt> fix: fix broken test </cmt>,store request query strings as structure
4183,"<desc> issue #2270 add searchdataid in input defaultvalue format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> from original </cmt> <cmt> keep query criteria </cmt>",keep query criteria when config detail return to config list
4184,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> changed type from ""function"" to ""arrow function format"". </cmt> <cmt> added typed ""hexo-bunyan"". </cmt> <cmt> added types hexo-log </cmt> <cmt> typescript version was added to dt-header. </cmt> <cmt> 2 soft tab to 4 soft tab. </cmt> <cmt> delete eslint comment. </cmt>",created types of [hexo-bunyan] and [hexo-log]
4185,"<desc> explanation: allow equatable, hashable, encodable, decodable (and thus codable) and caseiterable to have conformances synthesized in an extension in the same file as the type declaration, e.g. struct foo<t> { var x: t } extension foo: equatable where t: equatable { /* creates an == that compares x */ }. scope: two major features of 4.1 were conditional conformances and synthesis of protocol conformances, but without being able to synthesize in extensions they didn't work together at all: the only way to get a conditional conformance is in an extension. thus, this enables synthesis for many generic types. radar/sr issue:  risk: low: most of the change is mechanical refactoring to enable the actual change to be simple and obvious. there's lots of testing, and a lot of the changes are no-ops for existing code that compiles (for those cases, nominal and conformancedecl are equal, and so changing the references from one to the other don't do anything). additionally, the diff is deceptively large: the non-test diff stat is more like +600,-700. testing: significant additions (1069 additions, 66 deletions) to the test suite both for type checking, code generation and runtime behaviour. reviewer: @douggregor #16439 </desc> <cmt> [sema] create a ""derivedconformance"" class, to store common values. </cmt> <cmt> instead of passing around a typechecker and three decls (the nominal type, the </cmt> <cmt> protocol, and the decl declaring the conformance) everywhere, we can just pass </cmt> <cmt> one object. </cmt> <cmt> this should be [nfc]. </cmt> <cmt> [sema] migrate almost everything to use derivedconformance. </cmt> <cmt> [sema] factor out ""can't derive in extension"" logic. </cmt> <cmt> nfc. </cmt> <cmt> [sema] allow synthesis of protocol conformances in extensions. </cmt> <cmt> this works for all protocols except for decodable on non-final classes, because </cmt> <cmt> the init requirement has to be 'required' and thus in the type's declaration. </cmt> <cmt> fixes most of </cmt> <cmt> [sema] fix synthesis of equatable and hashable conformances in extensions of generic types. </cmt> <cmt>  </cmt> <cmt> [sema] fix synthesis of caseiterable conformances in extensions of generic types. </cmt> <cmt>  </cmt> <cmt> [sema] fix synthesis of *codable conformances in extensions of generic types. </cmt> <cmt> fixes </cmt> <cmt> [sema] disallow synthesis-in-extensions in swift 3. </cmt> <cmt> 'private' properties can't be accessed in extensions in swift 3, so synthesizing </cmt> <cmt> a conformance that reads from such things is going to be incorrect in an </cmt> <cmt> extension. </cmt> <cmt> [test] add more comprehensive tests for synthesis of conformances in extensions. </cmt> <cmt> [sema] use the conformance decl in more diagnostics/validity checks in conformance synthesis. </cmt>",allow synthesis of conformances in same-file extensions
4186,"<desc> add the squishytkl: a gasket o-ring mount tkl keyboard. the squishyfrl is pretty much the same but without an f-row. i can't seem to figure out how to use the stm32f103 bootloaders available so i compiled with generic board files instead and flash via st-link. if there's a way so i don't have to include those board files with my keyboard files, do let me know. thank you. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add squishytkl </cmt> <cmt> add squishytkl-frl </cmt> <cmt> adjust readme.md and info.json </cmt>",add the squishytkl and squishyfrl
4187,<desc> closes #6232 </desc> <cmt> deprecate labelencoder in xgbclassifier; skip labelencoder for cudf/cupy inputs </cmt> <cmt> add unit tests for cudf and cupy inputs with xgbclassifier </cmt> <iss> support gpu input in `xgbclassifier`; deprecate the use of label encoder </iss>,deprecate labelencoder in xgbclassifier; enable cudf/cupy inputs in xgbclassifier
4188,<desc> created a stacked bar sample that shows a waterfall chart. moved the concept of stacking into the axes and changed the line & bar charts so that they don't need to extend the axes as much. scale file diffs are bad due to changes from spaces to tabs. this better matches the contributing guidelines. </desc> <cmt> bar stacked sample </cmt> <cmt> move some functions into the category scale. this cleans up the bar chart interface & allows for waterfall charts by settings stacked to false on the category axis but stacked to true on the y axis </cmt> <cmt> move more data into the linear scale.this simplifies buildscale for line and bar charts </cmt> <cmt> removed unused options from the bar and line charts </cmt>,move stacked options into scales. can be configured independently for each axis
4189,<desc> a couple of other small indentation fixes to the same file are included as well. test is taken directly from the example in the docs. prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. [no version number in the header?] </desc> <cmt> add walk() to fs-extra </cmt> <cmt> fix some indentation in fs-extra </cmt>,add missing walk() method to fs-extra
4190,"<desc> changes: split base85.py into functions rename functions in base16.py to bring about uniformity across the 4 bases rename base64_encoding.py to base_64.py (also for uniformity) i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> update base16.py </cmt> <cmt> rename base64_encoding.py to base64.py </cmt> <cmt> split into functions, add doctests </cmt>","split base85.py into functions, add doctests"
4191,"<desc> fixed sample for signalr stream usage. link to this code sample updated as well, because of 404 error when opening it from aspnetcore/signalr/streaming.md </desc> <cmt> update streamhub.cs </cmt> <cmt> fixed sample. </cmt> <cmt> update streaming.md </cmt> <cmt> fixed link to sample code. </cmt>",signalr stream sample fix. link to sample updated in related article.
4192,"<desc> add japanese translations. docs/ja/breaking_changes.md (based on umi-umi's translation in #7248) docs/ja/breaking_changes_instructions.md my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add japanese translation 'docs/ja/breaking_changes.md' </cmt> <cmt> note: this is cherry-pick from umi-umi's translation in pr #7248 </cmt> <cmt> update ja/breaking_changes.md </cmt> <cmt> update ja/breaking_changes.md, add ja/breaking_changes_instructions.md </cmt> <cmt> translating ja/breaking_changes_instructions.md </cmt>",japanese translation of breaking_changes*.md
4193,"<desc> the typedef provided is wrong on most platforms, so they have chosen to use -d_file_defined. rather than do this, don't provide a fallback definition. standard c promises that file is defined in stdio.h build tested only on a currently unsupported platform (netbsd) - i haven't succeeded in running it yet. </desc> <cmt> don't define file immediately after including stdio.h </cmt> <cmt> it is required by the c standard to be typedef'd in that </cmt> <cmt> header. </cmt> <cmt> gc _file_defined </cmt> <cmt> _file_defined is the include guard for stdio.h on windows. </cmt> <cmt> we no longer provide a fallback of definition of file (which </cmt> <cmt> doesn't match most systems) in the case !_file_defined, so </cmt> <cmt> the definition is now unnecessary. </cmt>",remove fallback definition of file
4194,"<desc> fixes #99905 fixes #99996 fixes #96158 </desc> <cmt> move off deprecated node-pty on api </cmt> <cmt> refactor terminal launch logic to improve error </cmt> <cmt> fixes #99905 </cmt> <cmt> part of #99996 </cmt> <cmt> add troubleshoot link </cmt> <iss> shell tasks are delayed 500 ms when using conpty </iss> <iss> ""exit code: {2}"" in terminal error message when it fails to create process </iss> <iss> provide a help link when terminal failures occur </iss>","refactor terminal launch, improve error handling and add troubleshoot link to notification"
4195,<desc> $  mypy electronics/ success: no issues found in 2 source files related issue: #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> fix mypy errors for scheduling/first_come_first_served </cmt> <cmt> fix mypy errors for scheduling/round_robin.py </cmt> <cmt> fix mypy errors for scheduling/shortest_job_first.py </cmt> <cmt> fix isort errors </cmt> <cmt> fix mypy errors for electronics/ohms_law.py </cmt> <cmt> fix mypy errors for electronics/electric_power.py </cmt>,add/fix type annotations for electronics algorithms
4196,"<desc> two main tricks. one was adding a way to track cascading work e.g. a source plugin adds a node which then transformer plugin takes and creates a new node which then another transformer plugin does more work on and so forth. before there was no way to know when the last bit of work associated with the initial sourcing was finished. to solve this, i added a traceid which is passed in during the original api call and then all subsequent work passes it along. and rather nicely, this is all hidden from the plugins themselves as we inject the traceid into the actions that plugins create. second was moving more internal work into internal plugins. this lets us take advantage of the new tracing capabilities above so that if internal work is triggered by an api call, we're tracking it along with every other plugin. now the bootstrap/index.js file is quite straightforward to read especially with our use of async/await. it's now stepping cleanly through each step of the process. this solves two problems. the biggest is there was occasionally weird graphql errors where some data just wouldn't get processed in time before the debounce timeout. those should be gone now. the other is the debouncing added time overhead to the bootstrap process. removing that means bootstrap is sped up by something like 750-1000 milliseconds. now a barebones gatsby site's bootstrap can be as fast as 2.5-3 seconds (and most of that time is loading javascript so can't wait for prepack.io to get prod ready). i also snuck in a simple jobs system. gatsby-plugin-sharp (image processing plugin) is the only user atm but it let's plugins tell gatsby it has long-running jobs going and block bootstrap from finishing while it's working. it should have all the data necessary for building a nice cli ui @jquense </desc> <cmt> use 'traceid' to track when cascading actions are complete </cmt> <cmt> add jobs system + move query running into internal plugins </cmt> <cmt> fixes, remove logging, disable rebuilding schema in dev </cmt>",make determining when a given stage is finished much more reliable
4197,"<desc> the definitions list setdefaultmuteremotestreams which has been deprecated and removed in trtc sdk web in v.4.8.2. in the changelog, trtc sdk authors recommend using the autosubscribe flag in clientconfig. this flag was not listed in these definitions. version number note: this breaking change was released by tencent in version 4.8.2. the dt-header linting rules do not allow bumping versions to maintenance release numbers. if someone knows what should be done in this case, please let me know. release notes url (with the deprecation notice) provided below. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> removed description of deprecated method client.setdefaultmuteremotestreams, added the clientconfig.autosubscribe flag that is to be used instead of the mentioned method. </cmt> <cmt> added an example of clientconfig.autosubscribe usage to trtc-js-sdk-tests.ts </cmt>","in trtc-js-sdk, removed client.setdefaultmuteremotestreams(), added clientconfig.autosubscribe flag"
4198,"<desc> sorry, tiny commits. i've seen around the database task a few day. i noticed this had some no good codes (consistency, global method ...and more). i've tried to fix these problem before trying #5547, #6648 and some improvements. </desc> <cmt> change an order of methods for readbility. </cmt> <cmt> change the behavior of db:test:clone task when schema_format is sql for consistency. </cmt> <cmt> change the behavior of db:test:prepare task when schema_format is sql for consistency. </cmt> <cmt> add a description about env[""scope""] </cmt> <cmt> remove session_table_name method because this is global and used only once. </cmt> <cmt> move to db:structure namespace, because these methods are global. </cmt>",refactor and improve database tasks.
4199,"<desc> closes #35985 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> doc: add notes about difference to numpy behaviour for ddof. </cmt> <cmt> gh35985. </cmt> <cmt> remove trailing whitespace. </cmt> <iss> doc: make difference between numpy behaviour clearer in dataframe.std() and series.std() </iss>",add notes about difference to numpy behaviour for ddof in std() gh35985
4200,"<desc> introduce browser_control layer </desc> <cmt> add screen_nav layer for copy/pasting within screen </cmt> <cmt> working readreg/paste macros </cmt> <cmt> working read reg / paste macros </cmt> <cmt> write log and tran patterns, and expand </cmt> <cmt> add ls -la shortcut, add tab on combined layer </cmt> <cmt> put delete word on the right pinky key on shell_nav layer </cmt> <cmt> add tab on the right side, add reset key </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added cloud9 macros </cmt> <cmt> add cloud9 shortcuts to atreus layout </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added browser_control layer </cmt> <cmt> finalized browser control layer </cmt> <cmt> adding comment </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add browser control layer to atreus </cmt> <cmt> add flashing command line </cmt> <cmt> remove the tab on combined layer </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",update to ergodox / atreus dvorak 42 key layouts
4201,"<desc> fix issue #8044 tracked at:  solution: bump up atol value from 1e-4 to 1e-2 the following 3 tests related to batchnorm training can all pass  10000 runs: tests/python/unittest/test_operator.py:test_batchnorm_training tests/python/gpu/test_operator_gpu.py:test_batchnorm_training tests/python/mkl/test_mkldnn.py:test_batchnorm finding 1: using fp32 with atol=1e-2 or fp64 with atol=1e-3 both works, chose the former one. tried different numeric_eps=1e-3, didn't work for all cases finding 2: reason of failing due to batchnorm result slightly different than result calculated by numeric gradient. current implementation of batchnorm should be correct. finding 3: verified  the gradient of 3 different batchnorm implementation are close but they are all different than numeric gradient. (cpu, gpu without cudnn, gpu with cudnn) conclusion current batchnorm implementation is correct and result is consistent across all implementations (mkldnn, w/ cudnn, w/o cuddn) the batchnorm gradient is slightly different than numeric gradient calculated using finite differential method. difference is less than rtol=0.16. atol=1e-2, it's large comparing to other operators, but acceptable in this case due to large precision loss in batchnorm. enable this test with larger atol is better than just disable it. (it could caught #11448 if enabled), it serves more like a sanity check to prevent the gradient results are far too off from numeric calculations. batchnorm errors can also be caught in test_batchnorm_with_type where consistency between each implementation is compared. see comments in #8044 for detailed results. please feel free to remove inapplicable items for your pr. the pr title starts with mxnet-620created (except prs with tiny changes) to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> increase atol to 1e-2 </cmt> <cmt> enable test_batchnorm_training </cmt>",[mxnet-620]fix flaky test batchnorm training
4202,<desc> changes: switched to canary branch instead of v2 corrected actions test suite to match new output in canary (changes came with #11015) fixed response checks for posts and tags as they don't include primvary_tag/primary_author by default </desc> <cmt> switched acceptance tests to run agains canary branch </cmt> <cmt> corrected actions specs </cmt> <cmt> corrected authentication spec </cmt> <cmt> moved test suites our of 'old' folder </cmt>,switch to canary endpoints in acceptance tests
4203,"<desc> azure pipelines will report all messages printed to stderr at the end of a pipeline step, leading to output like below. it's convoluted, hard to read and ultimately completely pointless clutter that points to nonexistent errors. so let's fix all instances that caused prints to stderr without any real (or at least with irrelevant) reason. total test time (real) =   0.05 sec cleaning up... stopping git daemon... stopping ssh... done. some tests failed. /home/libgit2/source/azure-pipelines/test.sh: line 317:    26 terminated              git daemon --listen=localhost --export-all --enable=receive-pack --base-path=""${gitdaemon_dir}"" ""${gitdaemon_dir}"" 2> /dev/null ##[error]useradd: warning: the home directory already exists. ##[error]not copying any file from skel directory into it. ##[error]  % total    % received % xferd  average speed   time    time     time  current ##[error]                                 dload  upload   total   spent    left  speed ##[error] 100   609    0   609    0     0   2381      0 --:--:-- --:--:-- --:--:--  2388 ##[error] 100 73489  100 73489    0     0   125k      0 --:--:-- --:--:-- --:--:--  383k ##[error]ceived % xferd  average speed   time    time     time  current ##[error]                                 dload  upload   total   spent    left  speed ##[error] 100   608    0   608    0     0   2491      0 --:--:-- --:--:-- --:--:--  2502 ##[error] 100 71645  100 71645    0     0   184k      0 --:--:-- --:--:-- --:--:--  184k ##[error]errors while running ctest ##[error]errors while running ctest ##[error]errors while running ctest ##[error]/home/libgit2/source/azure-pipelines/test.sh: line 317:    26 terminated              git daemon --listen=localhost --export-all --enable=receive-pack --base-path=""${gitdaemon_dir}"" ""${gitdaemon_dir}"" 2> /dev/null ##[error]/usr/bin/docker failed with return code: 1 finishing: test </desc> <cmt> azure: docker: pipe downloaded archives into tar(1) directly </cmt> <cmt> when building dependencies for our docker images, we first download the </cmt> <cmt> sources to disk first, unpack them and finally remove the archive again. </cmt> <cmt> this can be sped up by piping the downloading archive into tar(1) </cmt> <cmt> directly to parallelize both tasks. furthermore, let's silence curl(1) </cmt> <cmt> to not print to status information to stderr, which tends to be </cmt> <cmt> interpreted as errors by azure pipelines. </cmt> <cmt> azure: test: silence curl to not cause azure to trop </cmt> <cmt> without the ""--silent"" parameter, curl will print a progress meter to </cmt> <cmt> stderr. azure has the nice feature of interpreting any output to stderr </cmt> <cmt> as errors with a big red warning towards the end of the build. let's </cmt> <cmt> thus silence curl to not generate any misleading messages. </cmt> <cmt> azure: docker: avoid re-creating libgit2 home directory </cmt> <cmt> the docker entrypoint currently creates the libgit2 user with ""useradd </cmt> <cmt> --create-home"". as we start the docker container with two volumes </cmt> <cmt> pointing into ""/home/libgit2/"", the home directory will already exist. </cmt> <cmt> while useradd(1) copes with this just fine, it will print error messages </cmt> <cmt> to stderr which end up as failures in our azure pipelines. </cmt> <cmt> fix this by simply removing the ""--create-home"" parameter. </cmt> <cmt> azure: test: silence termination message when killing git-daemon(1) </cmt> <cmt> in order to properly tear down the test environment, we will kill </cmt> <cmt> git-daemon(1) if we've exercised it. as git-daemon(1) is spawned as a </cmt> <cmt> background process, it is still owned by the shell and thus killing it </cmt> <cmt> later on will print a termination message to the shell's stderr, causing </cmt> <cmt> azure to report it as an error. </cmt> <cmt> fix this by disowning the background process. </cmt>",fix misleading messages printed to stderr being
4204,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry spinning off from #38416, xref #38416 (comment) </desc> <cmt> add applyfunctype alias </cmt> <cmt> type func arg of dataframe.apply </cmt> <cmt> type func arg of core.apply.frame_apply </cmt> <cmt> add pythonfunctype alias </cmt> <cmt> type func arg of dataframe.applymap </cmt>","func argument to dataframe.apply, dataframe.applymap, core.apply.frame_apply"
4205,<desc> fixs: #4561 </desc> <cmt> refactor rnn algorithm to share code between forward and backward </cmt> <cmt> commit cc50ca9ea776d545a7412fd5b7b7fb632fe4f8e1 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 11 16:21:36 2017 -0400 </cmt> <cmt> clean code </cmt> <cmt> commit 38503251117335a966d3a1ebdbd65d574afb4215 </cmt> <cmt> merge: 15d54bb b504a23 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 11 16:16:30 2017 -0400 </cmt> <cmt> commit 15d54bb885b088db98940641c60b4601aed5228c </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 11 16:13:48 2017 -0400 </cmt> <cmt> forward run smoothly </cmt> <cmt> commit d8b0f14a31016519e0d5d02d39f73124b1f9ec1a </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 20:39:26 2017 -0400 </cmt> <cmt> using namespace related </cmt> <cmt> commit a8ad874082000a790a2721ea1f752ce3add70d80 </cmt> <cmt> merge: 150acac c193f82 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 20:38:45 2017 -0400 </cmt> <cmt> commit 150acac24b2a682b22c68055df8095d051ca45d5 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 19:40:57 2017 -0400 </cmt> <cmt> add dyseqbatch </cmt> <cmt> commit f2829036b48bbe41aab0b3463b51ea929ba7c552 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 18:23:25 2017 -0400 </cmt> <cmt> create outputs in step scopes </cmt> <cmt> commit 066cbb647f1c7934915352869725cf5ee4ecd36e </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 18:21:57 2017 -0400 </cmt> <cmt> format </cmt> <cmt> commit 50c033b7fdacbc04ab30d20b96327b0055e17926 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 18:19:23 2017 -0400 </cmt> <cmt> init reorder boot </cmt> <cmt> commit b5e8a8ab9904f0d8be070a86827b7fb3180f9578 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   tue oct 10 13:56:31 2017 -0400 </cmt> <cmt> merge dynamic op changes </cmt> <cmt> commit dccf0cc1b5804b498b7bfda168de4d152643139d </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 19:45:24 2017 -0400 </cmt> <cmt> small fix </cmt> <cmt> commit 4a0cc85dcf207d1586e5b2eed106e6fdb775e2ed </cmt> <cmt> merge: 50c364e d30ada2 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 19:44:40 2017 -0400 </cmt> <cmt> commit d30ada2cbbe68d804cd8c94e0a49c42eb6c6d0d5 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 19:01:20 2017 -0400 </cmt> <cmt> fix missing lib </cmt> <cmt> commit 50c364e5594b1a231085db1584eeb90cc48d651b </cmt> <cmt> merge: e99a4ce 383faaf </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 17:44:16 2017 -0400 </cmt> <cmt> commit 3cfaa8b9a20a38c93f114ba4ee94d0846820f8d1 </cmt> <cmt> merge: 58d53f1 d23cd51 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 16:59:02 2017 -0400 </cmt> <cmt> commit 58d53f19be8fd14c0e89c3a34ac75d4d84329690 </cmt> <cmt> merge: e578fc3 e12ec95 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 15:57:32 2017 -0400 </cmt> <cmt> commit e578fc3b9e5d44b071a3403fe91aa28982c79b65 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 15:56:59 2017 -0400 </cmt> <cmt> add definition for with_testing </cmt> <cmt> commit e99a4ce6e41f464e4587a79e50ed59174fd8ac5e </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 15:56:18 2017 -0400 </cmt> <cmt> add pybind </cmt> <cmt> commit df46223ccf29d37f028b7d479592d1889fb0dc8e </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 14:19:05 2017 -0400 </cmt> <cmt> fix maker name </cmt> <cmt> commit 0e40af547b181686208e8aefc395629150275e96 </cmt> <cmt> merge: 0c97e0c 0ff540c </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 14:14:36 2017 -0400 </cmt> <cmt> commit 0c97e0cf03255bf3a910674a518c8a55d626ee87 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 14:14:16 2017 -0400 </cmt> <cmt> fix gtest_prod.h loss error </cmt> <cmt> commit 7245bacd0e3934b0960c6400ecb525a3cda1ca03 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 14:13:37 2017 -0400 </cmt> <cmt> make states a map </cmt> <cmt> commit 72706aefaeff633d96a7df6c6c74cbddef0771b5 </cmt> <cmt> merge: 9b1bfc5 d9585f9 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 13:38:33 2017 -0400 </cmt> <cmt> commit 21b84bde8ecbf7e1a4649471aa86a74972527985 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 9 13:35:24 2017 -0400 </cmt> <cmt> fix cuda error </cmt> <cmt> commit b83ffaee1d7637d9f23b9dd12a637641f62383d3 </cmt> <cmt> merge: cdc6e5d 4c96008 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   fri oct 6 20:06:06 2017 -0400 </cmt> <cmt> commit 9b1bfc59b1707974b49979001cba6f9abd256a14 </cmt> <cmt> merge: 9b4991c 3e82922 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   fri oct 6 18:11:55 2017 -0400 </cmt> <cmt> commit 9b4991ccd6a6b72070595092a452d92d96b12d02 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   thu oct 5 13:59:47 2017 -0400 </cmt> <cmt> fix gtest </cmt> <cmt> commit cdc6e5dbf3e813b8e1cb2cf24cf846424dc44674 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   thu oct 5 13:55:05 2017 -0400 </cmt> <cmt> fix gtest </cmt> <cmt> commit d300ce66f2acb15bfd1bd0cee8d35b30e9747cb6 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   thu oct 5 13:54:27 2017 -0400 </cmt> <cmt> add pybind </cmt> <cmt> commit d5349e13f013d5904a7773c4131b6a404648a276 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:41:56 2017 -0400 </cmt> <cmt> clean code </cmt> <cmt> commit 7d59aeef5eec5bb5d56a8d14e3b109b2893686cb </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:40:11 2017 -0400 </cmt> <cmt> recover op_registry </cmt> <cmt> commit 13c1d6dbe3419b3453ecb33dcde4956888059588 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:38:58 2017 -0400 </cmt> <cmt> recover op_registry </cmt> <cmt> commit 728b4decaf585dca7bff53bca0565fe04a7e03ee </cmt> <cmt> merge: f94f0a8 76169e0 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:06:43 2017 -0400 </cmt> <cmt> commit f94f0a80a552c841bc777521ee28f58ab01855dd </cmt> <cmt> merge: cf87cd6 15b35f9 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:06:36 2017 -0400 </cmt> <cmt> commit cf87cd678b8bbbf6716d5f8ec2b3cfb8c5b646ad </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:06:08 2017 -0400 </cmt> <cmt> finish </cmt> <cmt> commit 76169e02ab52adb0c0b4db59e25cb468a60482bb </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 18:04:54 2017 -0400 </cmt> <cmt> finish debug </cmt> <cmt> commit d432f1702558d1d77f775361aa07b30a99e897c7 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed oct 4 13:16:15 2017 -0400 </cmt> <cmt> finish forward implementation </cmt> <cmt> commit 85dac0fd73f9b05e883ad9436a356baa50c8f52c </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 2 22:52:59 2017 -0400 </cmt> <cmt> add test for dynamic recurrent op </cmt> <cmt> commit fceaad85937a7b2e1fd5ed4ab859b4912f73a4eb </cmt> <cmt> merge: aaaed8b c705f06 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 2 16:34:46 2017 -0400 </cmt> <cmt> commit aaaed8bfee4b6165c23fcafbb2640815787c3568 </cmt> <cmt> merge: cf228a7 a80e010 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 2 13:44:41 2017 -0400 </cmt> <cmt> commit cf228a72b0e34886131b4b7d7dab7dfd4ae77bf9 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   mon oct 2 13:40:51 2017 -0400 </cmt> <cmt> add registry </cmt> <cmt> commit c138e6bdf59bc7b44ee0af56fbfa2097e7fbf15e </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 19:53:59 2017 -0400 </cmt> <cmt> add run </cmt> <cmt> commit b3d28ae4427a5c3894861e065d945fd12287b714 </cmt> <cmt> merge: d77fb89 2719ff6 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 18:44:39 2017 -0400 </cmt> <cmt> commit 2719ff617a093622928d3f9aa0670561949c743c </cmt> <cmt> merge: 956f949 0900aed </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 18:17:15 2017 -0400 </cmt> <cmt> commit 956f949713e77b38a58ffeec81fd42bf71b2dea9 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 15:21:22 2017 -0400 </cmt> <cmt> set type </cmt> <cmt> commit 870be953b66c28e0681587855babfd132c4f11d5 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 15:17:10 2017 -0400 </cmt> <cmt> update </cmt> <cmt> commit d77fb89e299d7b0a31a52b0fba1e1c7d131765ad </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   sat sep 30 15:03:27 2017 -0400 </cmt> <cmt> add implementation </cmt> <cmt> commit 661f30b2f2b7406f8ea845952456dfd2b2f21b53 </cmt> <cmt> author: superjom <superjom@gmail.com> </cmt> <cmt> date:   wed sep 27 22:09:41 2017 -0400 </cmt> <cmt> add tensor array </cmt> <cmt> finish factor for forward and backward </cmt>,feature/dynamic recurrent op forward and backward
4206,"<desc> closes #22116 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry moved pivot from pandas/core/reshape/reshape.py to pandas/core/reshape/pivot.py moved pivot_simple and _slow_pivot from pandas/core/reshape/reshape.py to pandas/core/reshape/pivot.py (only used by one panel test) remapped top level pd.pivot to use pivot instead of pivot_simple added some additional tests for pd.pivot </desc> <cmt> cln: have pd.pivot mirror pivot instead of pivot_simple </cmt> <cmt> remove pivot_simple </cmt> <cmt> fix shared_doc </cmt> <cmt> add more tests and whatsnew </cmt> <cmt> flake8 </cmt> <iss> api: have pd.pivot mirror pivot instead of pivot_simple </iss>",have toplevel pd.pivot mirror pivot instead of pivot_simple
4207,"<desc> this pr breaks out the changes that the fix in #10364 doesn't depend on. one cool change is that the add-on icon is shown in the peripherals dialog. this won't have any effect until x-arcade tankstick and steam controller support is finished, but in the future we can look forward to this: </desc> <cmt> [peripherals] show add-on icon if peripheral is provided by add-on </cmt> <cmt> screenshot: </cmt> <cmt> reset input receiver before destroying object </cmt> <cmt> controllers: remove unused ""overlay"" property </cmt> <cmt> this property was used during development, but didn't make it into the final </cmt> <cmt> pr. </cmt> <cmt> [peripherals] remove controller parameter </cmt> <cmt> this is part of a larger change to refresh button maps for all controllers </cmt> <cmt> belonging to the specified device. this is because modifying one controller </cmt> <cmt> profile can affect another if the other is derived from the button map </cmt> <cmt> being modified. </cmt>",break out joystick improvements from #10364
4208,<desc> xref #30578 #30405 #30402 this follow-up pr is to parametrize and deduplicate inplace cases brought up in the above prs. </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> follow up to clean tests </cmt>,"clean tests for .sort_index, .sort_values and df.drop_duplicates"
4209,"<desc> per request from jeff. also started to build logic to execute service binary and monitor output. </desc> <cmt> refactored crash_gen, extracted logic to create statemachine class </cmt> <cmt> now able to run without parameter, also refactored to run service binary </cmt>","enhanced crash_gen tool, now can execute default test without any parameters"
4210,"<desc> fixes #2252. </desc> <cmt> check style for appendindexplaceholder() </cmt> <cmt> rename to appendselectitemsplaceholder() </cmt> <cmt> rename to appendinsertvaluesplaceholder() </cmt> <cmt> add startindexofgeneratedparameters </cmt> <cmt> add getcurrentparameterindex() </cmt> <cmt> modify getcurrentindex() </cmt> <cmt> rename to startindexofappendedparameters </cmt> <cmt> add final int startindexofappendedparameters </cmt> <cmt> use insertoptimizeresult.addunit() </cmt> <cmt> modify cases for insertoptimizeresult.addunit() </cmt> <cmt> add java doc </cmt> <cmt> modify to use startindexofappendedparameters </cmt> <iss> insert with generated keys,when the last column value is nullcause nullpointerexception </iss>",fix bug for insert sql with null parameters
4211,"<desc> added 3mfloader, amfloader, kmzloader and ktxloader. </desc> <cmt> jsm: added module and ts file for 3mfloader. </cmt> <cmt> ts: clean up </cmt> <cmt> jsm: added module and ts file for amfloader. </cmt> <cmt> jsm: added module and ts file for kmzloader. </cmt> <cmt> ts: clean up </cmt> <cmt> jsm: added module and ts file for ktxloader. </cmt>",more modules and ts files for loaders.
4212,"<desc> does this pr add a new page, or update an existing page? adds the new ""redux fundamentals"" tutorial sequence checklist is there an existing issue for this pr? #3855 have the files been linted and formatted? what docs page is being added or updated? section: ""tutorials"" > ""redux fundamentals"" page: all of them! for adding new content what kind of content category is this page (tutorial, how-to, explanation, reference)? tutorial. who is the intended target audience? beginners who know nothing about redux, yet. what knowledge are we assuming they have? js syntax: es6, async/await, object spreads react: components, hooks other: http / ajax, fetch what are the intended results or takeaways from reading this page? users should understand the fundamental concepts and principles of using redux. what is the most critical info they should learn? key redux concepts and terms (""actions"", ""reducers"", ""state"", ""store"", ""dispatching"") core redux data flow (dispatch -> reducer -> ui) basic usage of redux with react (useselector, usedispatch, <provider>) standard redux usage patterns (action creators, selectors, normalized state) to use redux toolkit instead of writing this code by hand status after having written the ""redux essentials"" tutorial, i'm now moving on to rewriting the existing ""basics/advanced"" tutorial sequence. per #3855 , the goals are: drop all outdated references (""flux"", ""containers"", etc) show simpler patterns (inline action types like {type: ""todos/addtodo""} vs const add_todo = ""add_todo"", single-file redux logic) codesandbox examples show react-redux hooks as the default improve explanation flow and i've written up my plans and intended outline there as well. thus far, i've filled out the first two pages (""overview"", ""concepts and data flow"") with content copy-pasted from the ""essentials"" tutorial.  i've got the first half of page 3 (""state, reducers, and actions"") thrown together, although i haven't worked on the actual example app at all yet.  i'll need to take time to do that shortly. happily, i've got a pretty good picture of how i want to tackle this app and explanation now.  i also will be able to reuse some of the explanations from the existing ""basics"" tutorial, and i intend to keep this shorter than the ""essentials"" tutorial.  so, i'm hoping i'll be able to complete this one somewhat faster than the six months it took me to put the ""essentials"" tutorial together :) </desc> <cmt> add fundamentals overview page </cmt> <cmt> fill out part 1 </cmt> <cmt> add part 2 </cmt> <cmt> stub out parts 3, 8, and 9 </cmt> <cmt> add part 3 skeleton </cmt> <cmt> add ""designing state"" section </cmt>","create the new ""redux fundamentals"" tutorial"
4213,"<desc> hello, this pr adds typings for packages 'electron-packager and electron-builder. they can be used in combination to build electron packages and create installers. thanks. </desc> <cmt> add electron-packager typings </cmt> <cmt> add electron-builder typings </cmt>",add typings for packages 'electron-packager' and 'electron-builder'
4214,"<desc> should finally fix #813 let's assume this proto message: message frame map<int32, string> item = 1; let's assume you want to use the map iterator and the static array.from method to get an array of values from the map. in javascript it works fine: const bytes = ... // get a serialized message somewhere const frame = frame.deserializebinary(bytes) const itemvalues = array.from(frame.getitemmap().values()) but in typescript it fails to compile with @types/google-protobuf 3.15.4 because the map.iterator<t> interface returned by keys(), values() and entries() of the protobuf map does not contain the iterator function: it's available in google-protobuf but missing in the typings package. because of the missing iterator function the typescript compiler tries to handle the argument passed to array.from as an arraylike instead of an iterable. that overload also fails, of course, because of the missing length property. </desc> <cmt> update index.d.ts </cmt> <cmt> fixes [#76]( </cmt> <cmt> update index.d.ts </cmt> <cmt> missing return types added </cmt> <cmt> update index.d.ts </cmt> <cmt> missing type arguments added </cmt> <cmt> update index.d.ts </cmt> <iss> missing interfaces for javascript map type in typescript d.ts file </iss>",add missing symbol.iterator function to interface of map.iterator<t>
4215,"<desc> i have two test boards - based on lpc1768 and on stm32f401. my sd card 2gb works good with lpc, but with stm not - after inserting sd card lcd panel hangs up until i remove sd card. in my case problem located somewhere in low level stm library. i tried find this problem with step-by-step debugging and oscilloscope but i haven't found yet. in any case, problem with init sd card may happen any time. so we don't need enter to cdroot() function after wrong sd init and need inform user about problem with his sd card. this fix excludes panel hang by bypassing cdroot() function after wrong sd init and informs user about problem with sd card on panel in status line. </desc> <cmt> update russian and ukranian languages </cmt> <cmt> dogm is pretty narrow </cmt> <cmt> update language_ru.h </cmt> <cmt> first update </cmt> <cmt> add blackpill board for test stm32f401/asm32f411 </cmt> <cmt> fix text in morpheus board </cmt> <cmt> update panel detect for i2c bus </cmt> <cmt> revert ""merge branch 'tft-glcd-adapter' into bugfix-2.0.x"" </cmt> <cmt> this reverts commit ee3da9eafaa5522a89f91076f1b632d6d5414625, reversing </cmt> <cmt> changes made to 067af016eeb86fbf8fd0bf0b2888939324bd8e96. </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> fix for sd card </cmt> <cmt> fix ru and uk languages </cmt>",fix for mount not initialized sd card
4216,"<desc> this change adds optional functionality to allow blinking an rgb lighting layer on for a specified number of milliseconds. the purpose is to make it easy to use a lighting layer to acknowledge events (e.g. a settings change). to use this new code, it must be enabled using  #define rgblight_layer_blink e.g. in your config.h. kudos to @n8gray for the great rgblight layers implementation. it is my hope that this small addition will make it even more useful! my code follows the code style of this project. i have read the contributing document. </desc> <cmt> implement momentarily blink of lighting layers </cmt> <cmt> refactor spidey3 userspace to use rgb layer blink </cmt>",add ability to blink lighting layer for a specified duration
4217,"<desc> added a few custom macros to my keymap: ""back"" in browser removed since it already exists in qmk ""forward"" in browser removed since it already exists in qmk launch rdp in windows my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add keycodes for new macros to keymaps </cmt> <cmt> add macros for commonly used shortcuts </cmt> <cmt> fix macro code and add comments </cmt> <cmt> replaced with build in qmk keycodes </cmt> <cmt> removed macros that duplicated qmk keycodes </cmt>",add custom macro to launch rdp
4218,"<desc> this is the one pr to rename the series of components in xla, per @cheshire request. the aim of this series is such that all components shared by cuda and rocm have the prefix gpu instead of cudnn. to make the pr easy to review, i make following decisions: each pr only rename one component renaming is done by: $ find . -type f -exec sed -i ""s/foo/bar/g"" {} \ each commit handles the renaming of one symbol. i highly recommend reviewing by commit. 1st commit: file renaming 2nd commit: update include guard and cudnnconvpaddinglegalization symbol all commits verified by convolution_test_gpu this pr is relatively straightforward as its public functions does not include cudnn in it. </desc> <cmt> rename from cudnn_conv_padding_legalization to gpu_conv_padding_legalization </cmt> <cmt> rename from cudnnconvpaddinglegalization to gpuconvpaddinglegalization </cmt>",rename cudnn conv padding legalization to gpu conv padding legalization
4219,"<desc> we now move the comment affordance into the gutter area. </desc> <cmt> comment affordance in line decorations area. </cmt> <cmt> grey color. </cmt> <cmt> put commenting ranges affordance into line decorations area. </cmt> <cmt> commenting range to be marker based. </cmt> <cmt> resolve conflicts for folding, git and comment in glyph </cmt> <cmt> remove unnecessary change. </cmt> <cmt> fix multiple comment zones being toggled on single click </cmt> <cmt> fix microsoft/vscode-pull-request-github#129. diff indicators should not scale with linedecoration width. </cmt> <cmt> fix microsoft/vscode-pull-request-github#129. diff editor should not reset the gutter width everytime. </cmt> <cmt> improve handling for comment creation failure </cmt> <cmt> comment range decorations should have its own color id. </cmt> <cmt> revert monaco.d.ts change </cmt> <cmt> add back changes lost on merge </cmt> <cmt> re microsoft/vscode-pull-request-github#135. do not dipose newcommentwidget when collapsed. </cmt>",move comment affordance into gutter
4220,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. added the missing items field when updating a subscription. this also deprecates the old plan field, which doesn't exist in the docs any longer. updated tests to reflect changes. </desc> <cmt> abstract billing type into a type alias </cmt> <cmt> add items property to subscription interfaces, deprecate plan </cmt> <cmt> add tests </cmt> <cmt> complete tests </cmt> <cmt> correct unit test </cmt>",update stripe package with missing subscription items properties
4221,"<desc> on x86, the default/implicit calling convention is __stdcall. an arm64 application consuming react-native-win32.dll may face linking errors when invoking iwebsocketresource::make (arm64 seems to expect __cdecl by default). microsoft reviewers: open in codeflow </desc> <cmt> export iwebsocketresource::make as __cdecl </cmt> <cmt> change files </cmt>",use explicit calling convention for iwebsocketresource::make
4222,"<desc> conllu2json now checks the 10th column of the first word: if it's a ner tag it will extract ner tags from the whole conllu file and add them to the json file. if not, it creates the json file as before, without ner tags. i have submitted the spacy contributor agreement. </desc> <cmt> changed tag_map, morph_rules, lemmatizer for norwegian </cmt> <cmt> move unicode declaration up </cmt> <cmt> hopefully fixes test failure on python 2 </cmt> <cmt> update contributor_agreement.md </cmt> <cmt> move unicode declarations </cmt> <cmt> hopefully fixes test this time </cmt> <cmt> merge remote-tracking branch 'origin/patch-1' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> revert ""merge remote-tracking branch 'origin/patch-1'"" </cmt> <cmt> this reverts commit f5ccd5dd0df9c4d7efcb2531963506ce64130d0d, reversing </cmt> <cmt> changes made to dd07e180ea76752a80b141dc0bdf1e6f16a7d3d7. </cmt> <cmt> update contributor agreement [ci skip] </cmt> <cmt> extract ner tags from conllu file if available </cmt>",changed conllu2json to be able to extract ner tags
4223,"<desc> this transitions the micro_speech, magic_wand, and person_detection examples for the sparkfun edge board to use the more polished board support package (bsp). led control is standardized to use the ambiq led device interface like the apollo3_evb. it also cleans out a few unused downloads from the apollo3 targets. dependencies update tflu (micro) to use ambiqsuite sdk release 2.2.0 for apollo3 </desc> <cmt> change ambiqsuite sdk references to release 2.2.0 </cmt> <cmt> add am_sdk_dest to handle future sdk releases </cmt> <cmt> remove workaround for 2.0.0 bug </cmt> <cmt> update sparkfun edge bsp repo to support 2.2.0 release </cmt> <cmt> remove unused downloads </cmt> <cmt> update edge bsp to latest </cmt> <cmt> standardize to use of am_devices for led control </cmt> <cmt> rely on bsp for image_provider.cc </cmt> <cmt> go to generic ""platform.h"" </cmt> <cmt> allows future targets to provide their own version </cmt> <cmt> more cleanup </cmt> <cmt> cmsis_ext is not used in apollo3 implementation </cmt>",upgrade edge board support package in tflu (micro)
4224,"<desc> on vxworks, no user home directory at all. so posixpath.expanduser() returns the input path unchanged if user home directory is none. and skip test_expanduser and test_expanduser_pwd on vxworks. </desc> <cmt> * posixpath.expanduser() returns the input path unchanged if </cmt> <cmt> user home directory is none. </cmt> <cmt> * skip test_expanduser and test_expanduser_pwd on vxworks </cmt> <cmt> add news </cmt>",posixpath.expanduser() handles user home of none
4225,"<desc> backports of security fixes in chromium release m90-3  includes backports for the following chromium issues:           notes: security: backported fixes for cve-2021-30518, cve-2021-30516, cve-2021-30515, cve-2021-30513, cve-2021-30512, cve-2021-30510, cve-2021-30508 </desc> <cmt> backports of security fixes in chromium release m90-3 </cmt> <cmt>  </cmt> <cmt> includes backports for the following chromium issues: </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> chore: update patches </cmt>",backport the security fixes from chromium release m90-3
4226,"<desc> this changes the match factory api to return a recursive factory instead of immediately constructing the tree. this allows us to to store the factory function on the hcm, creating a new match tree per stream. this should help ensure that there is no cross-stream pollution, regardless of implementation of the individual components of the match tree. risk level: high testing: existing test coverage docs changes: n/a release notes: n/a platform specific features: n/a </desc> <cmt> matching: do not reuse constructed string value in http inputs </cmt> <cmt> this was incorrectly causing the same values to be reused when the same match input was used between two streams </cmt> <cmt> and the header was present in both streams. </cmt> <cmt> copy a string instead of using a string view </cmt> <cmt> some fixes </cmt> <cmt> wip create tree factory </cmt> <cmt> fix merge build failures </cmt> <cmt> foormat </cmt> <cmt> remove unused file </cmt>",instantiate new matching tree per http stream
4227,"<desc> this pr fixes #2678 and #2681 by adding the following improvements to lgb.convert() functions: lgb.convert(): now fills in missing values in factor and character columns with 0 lgb.convert_with_rules(): rules no longer contains rules where the ""name"" in the rule is a missing value both: now converts logical columns to integer, filling in missing values with -1 now warns if any columns remain which are not numeric or integer moved code for getting column classes into shared internal function to reduce duplication changed from inherits(data, ""data.table"") to data.table::is.data.table() moved error handling up to the beginning of the functions clarified documentation question for reviewers @laurae2 @guolinke could we remove lgb.convert() and just offer lgb.convert_with_rules()? using lgb.convert_with_rules() without passing your own rules (the default), has identical behavior to lgb.convert() and is better because it returns the rules on how columns were changed, which improves reproducibility. since we're considering a 3.0.0 release in #3071 right now, i think this is the right time for such a breaking change. </desc> <cmt> [r-package] improvements to lgb.convert() functions (fixes #2678, #2681) </cmt> <cmt> more stuff </cmt> <iss> [r-package] lgb.convert() functions should convert columns of type 'logical' </iss>","refactor and improvements to lgb.convert() functions (fixes #2678, #2681)"
4228,"<desc> commit message: when the downstream codec encodes response header/body/trailers in the same call stack as upstream decoding, which is the case for http3, a connection could gets closed which will cause the stream to be reset. in such case, filtermanagerimpl shouldn't continue process the rest of the response, especially end_stream. additional description: this contributes to the crash in #19006. this fix stops the crash, but didn't make the test pass. risk level: low testing: new unit tests release notes: guarded by envoy.reloadable_features.handle_stream_reset_during_hcm_encoding </desc> <cmt> fix hcm </cmt> <cmt> add runtime guard </cmt> <cmt> release note </cmt>",handle stream reset during downstream encoding
4229,"<desc> this pr adds more large tensor tests to numpy (extension) operators. to run: pytest tests/nightly/test_np_large_array.py::{test_name} ================================= test session starts ================================== platform linux -- python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 rootdir: /home/ubuntu/incubator-mxnet, inifile: pytest.ini plugins: remotedata-0.3.2, openfiles-0.4.0, astropy-header-0.1.2, hypothesis-5.8.3, arra ydiff-0.3, doctestplus-0.5.0 collected 68 items tests/nightly/test_np_large_array.py ....ss..........ss...s........s..s...sss.s. [ 63%] ....s.....s...ss......sss                                                        [100%] =================================== warnings summary =================================== tests/nightly/test_np_large_array.py:88 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:88: deprecationwarni ng: invalid escape sequence \ ''' tests/nightly/test_np_large_array.py:485 /home/ubuntu/incubator-mxnet/tests/nightly/test_np_large_array.py:485: deprecationwarn ing: invalid escape sequence \ ''' -- docs:  =============== 50 passed, 18 skipped, 2 warnings in 4462.72s (1:14:22) ================ </desc> <cmt> remove asnumpy() </cmt> <cmt> add more tests </cmt> <cmt> add more tests </cmt> <cmt> add more tests </cmt>",numpy ops large tensor tests batch 2
4230,"<desc> it's worked on armv7a platform,the following layer is supported int8 inference without overflow: convolution 3x3s2 int8 packed convolutiondw 3x3s1 int8 convolutiondw 3x3s2 int8 i will try my best to implement the int8 winograd with f[2,3],before the spring festival. </desc> <cmt> add the armv7a conv1x1s1 sgemm int8 implement without overflow : ) </cmt> <cmt> add the armv7a conv3x3s2, convdw3x3s1/s2 int8 implement without overflow </cmt>","add the armv7a conv3x3s2, convdw3x3s1/s2 int8 implement without overflow : )"
4231,<desc> fixes #4291 the right response for a non existent policy should be raise an iamnotfoundexception instead of 500 (not implemented). a little monkey patching solves this. example hitting aws for real: aws --profile localstack iam delete-policy --policy-arn arn:aws:iam::000000000000:policy/non-existent-policy an error occurred (nosuchentity) when calling the deletepolicy operation: policy arn:aws:iam::000000000000:policy/non-existent-policy was not found. </desc> <cmt> fix: adding exception response when calling deletepolicy on non existent iam policy </cmt> <cmt> adding small integration test </cmt> <iss> bug: error while deleting a non existent iam policy. </iss>,adding iam exception response when calling deletepolicy on non existent policy
4232,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add missing params to twixformatoptions </cmt> <cmt> add examples to twix tests </cmt> <cmt> add twix hideyear </cmt>",twix - add missing 'hiding things' properties to twixformatoptions interface
4233,"<desc> description: provide an optional way for the user to securely enter a password/text value. in combination with: home-assistant/frontend#837 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4489 example entry for configuration.yaml (if applicable): input_text: text1: name: text 1 initial: some text mode: password (optional, default is text) checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass documentation added/updated in: home-assistant/home-assistant.io#4489 </desc> <cmt> round values to one decimal </cmt> <cmt> temperature detection range: -20 - 60 deg.c ( + / - 0.3 deg.c ) </cmt> <cmt> humidity detection range: 0 - 100pct rh ( + / - 0.3pct ) </cmt> <cmt> atmospheric pressure detection range: 30 - 110kpa ( + / - 120pa ) </cmt> <cmt> add password mode option </cmt> <cmt> hide the content of the input_text field </cmt>",added password mode to input_text (obscure content of text box)
4234,"<desc> came across some typos while reading source, and fixed other occurrences of same typo. all but one change involve documentation / comments. the only altered source code concerned a method name in dominance.h / dominance.cpp. </desc> <cmt> fix spelling error in documentation / comments while reading source. no code change (shouldn't break anything) </cmt> <cmt> fix method names: 2 occurrences of ""occured"" </cmt> <cmt> merge remote-tracking branch 'apple/master' </cmt> <cmt> oops, missed one. fix build failure </cmt> <cmt> re-commit ones st missed </cmt>",fix typos in docs / comments / method name
4235,"<desc> fastcomp adds all the js library to the asmlibraryarg object which is provided as ""env"" to wasm modules, which lets them access those methods. in the wasm backend we use a more straightforward method of flipping the export_all flag, which provides those methods on module, which is used to look up imports as necessary. export_all is also noticed by metadce (when present, it doesn't try to remove wasm exports) so this likely fixes another bug as well, see the metadce output changes (the additions were metadce'd out before, possibly incorrectly if a side module needs them). fixes #9793 </desc> <cmt> export_all for main_modules in the wasm backend. fixes #9793 </cmt> <cmt> fixes. also fixes metadce here, turns out </cmt> <iss> main_module without export_all does not export js library functions </iss>",enable export_all in main modules with the wasm backend
4236,<desc> fixes #41731 </desc> <cmt> feat: exclude declared variable when object literal completions </cmt> <cmt> feat: check undeclarevariable when completion </cmt> <cmt> feat: add completion test case </cmt> <cmt> feat: code optimization </cmt> <cmt> feat: support shorthand property assignment </cmt> <cmt> feat: add shorthand property assignment test case </cmt> <cmt> feat: update completionpropertyshorthandforobjectliteral test cases </cmt> <cmt> feat: exclude completions of variable initializers </cmt> <cmt> feat: update test cases </cmt> <cmt> feat: add completionlistwithoutvariableinitializer test case </cmt> <iss> object literal completions in declaration initializer include declared variable </iss>,feat/exclude completions of variable initializers
4237,"<desc> this pr is to support higher order gradient in some basic unary operators. thanks to @sxjscience, this pr is a continued work of #12821. this pr adds additional support for relu operator and fixed the issue of negative operator support in #12821. in addition, i added unit tests for to test higher order gradient. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change higher order gradient for a set of unary operators unit test to test higher order gradient </desc> <cmt> try to add support some ops </cmt> <cmt> add unit test for second order grad </cmt> <cmt> implement grad for relu and add unit test </cmt>",second order gradient support for some unary operators
4238,"<desc> right now when a user migrates a database and they need to specify an environment they must do it by specifying rails_env=environment, this also works if you are running console i.e. rails console rails_env=production works. however if you try to use the same syntax with rails server you get an error. the first commit in this pull request fixes that problem. rails server also takes a -e option for setting environment, while rails console does not. the second commit in this pull request adds a -e option to rails console so anyone will be able to set environment across server and console the same way. added tests covering setting the environment in server and console by both -e and rails_env. </desc> <cmt> fix rails server support of rails_env variable </cmt> <cmt> when launching rails server from the command line with a rails environment specified such as rails server rails_env=production an error would occur since rails will try to use rails_env=production as it's server. </cmt> <cmt> when launching rails with a specified server such as thin rails server thin rails_env=production no error will be thrown, but rails will not start up in the specified environment. </cmt> <cmt> this fixes both of those cases </cmt> <cmt> match rails console environment support, to server </cmt> <cmt> rails server takes -e as an argument to specify rails_env, rails console currently does not have the same interface. this commit fixes this disparity so developers can manually specify rails_env or can pass in an environment with a -e. </cmt>","fix environment support for rails server, and match interface of rails console"
4239,"<desc> what did you implement: partially closes #3821 this is specifically to deal with ssm rate exceeded errors. it is a complement to #4294 we are having issues with serverless calling ssm over 50 times because around 10 variables are referenced in a number of places. this issue is currently stopping us from deploying. how did you implement it: i added a cache object to variables class. this is referenced before aws ssm is requested. how can we verify it: i cannot share our config as our ssm variables are secrets. but this change is a pretty simple. the tests verify that the cache is working. todos: write tests write documentation - n/a fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add cache to ssm variables </cmt> <cmt> fix linter </cmt>",add cache to variables class.
4240,<desc> fixes #5482 microsoft reviewers: open in codeflow </desc> <cmt> don't error out on errors from installing dependent framework packages </cmt> <cmt> change files </cmt> <iss> cannot deploy when framework packages of a higher version are already installed </iss>,only install superseding/applicable dependent framework packages
4241,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add support for us geo reverse lookup </cmt> <cmt> update documentation </cmt> <cmt> update documentation </cmt>,"smartystreets javascript sdk - add support for ""us reverse geo"" and documentation"
4242,"<desc> making them more meaning clear and readable. </desc> <cmt> update the chinese index, and clean the dynamic-sql. </cmt> <cmt> improve the chinese translation, with updating half part of the getting-started. </cmt> <cmt> improve the rest part of getting-started. </cmt>",improve chinese docs of index and getting-started.
4243,"<desc> small tut for adding federated users </desc> <cmt> added the option to add a span property to the card.col component, allowing for wider cards </cmt> <cmt> federation card - partially commited, beautifying it </cmt> <cmt> first version of the federation card </cmt> <cmt> added i18n to the card, initial modal implementation </cmt> <cmt> first step of federation modal done </cmt> <cmt> first draft of the dns modal </cmt> <cmt> federation modal - wip </cmt> <cmt> fix: cypress file location </cmt> <cmt> fix some linting errors </cmt> <cmt> step 3 contents </cmt> <cmt> make everything translatable </cmt> <cmt> move invite users modal to a separate file </cmt> <cmt> removed unused banner import </cmt> <cmt> undo: cypress file location </cmt> <cmt> undo: cypress file location </cmt> <cmt> fix i18n string </cmt>",add users from other servers
4244,"<desc> not all pointers to structs start at the beginning, thanks microsoft for your implementation of list entries (list_entry). thus i have tweaked ta so that it can now take an additional argument offset. so for example we can now do the following: ta _ldr_data_table_entry.dllbase 0x10, as we are pointing not at the start of the structure but actually at offset 0x10 (the ininitializationorderlinks field). i have also extended the r_type_get_struct_memb function so that it will now parse inline structs rather than incorrectly bailing out. so below we can see that basedllname (unicode_string) is correctly resolved to the inlined structure. example of new improvements: note: annoyingly cmd_type.c is formatted badly so there are lots of additions due to linting! </desc> <cmt> types: allow an offset to be set for the struct itself </cmt> <cmt> not all pointers to structs start at the beginning, thanks microsoft </cmt> <cmt> with your implementation of list entries. therefore this commit allows </cmt> <cmt> you to tweak the 'entry point' to the struct when using the ta command. </cmt> <cmt> note: annoyingly this file is formatted badly so there are lots of </cmt> <cmt> additions due to linting! </cmt> <cmt> ctype: handle nested structs in get_struct_memb </cmt> <cmt> r_type_get_struct_memb will now parse inline structs rather than </cmt> <cmt> incorrectly bailing out </cmt>",some minor improvements to ta
4245,"<desc> since *.inc uses cpp, i changed the display via .gitattributes. </desc> <cmt> .editorconfig: add utf-8 encoding </cmt> <cmt> .editorconfig: add utf-8 encoding </cmt> <cmt> .gitattributes: customized the *.inc file format </cmt> <cmt> .gitattributes: customized the *.inc file format </cmt>",removed php display in the project
4246,"<desc> prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. run tsc without errors. include the required files and header. base these on the readme, not on an existing project. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. related to issues: #11365 and #11366 changes by module included in this batch: (d3-path) [chore] added complete jsdoc comments (d3-path) [enhancement] validated and activated for use with strictnullchecks (d3-chord) [breaking fix] added additional interfaces ribbon and ribbonsubgroup to reflect the interfaces actually assumed by default by ribbongenerator. while the api documentation refers to passing in a chord object when invoking the ribbongenerator by default, this actually means the default radius accessor returns undefined, which is then coerced to nan. to avoid this ""silent"" fail, ribbon and ribbonsubgroup are now used as the datum types returned by the default ribbon() factory without explicit generics. this is a purposely accepted breaking change, as it means that passing in a chord object will now fail. the correct way, will be to use the generics of the ribbon<...>() factory to cast the datum type to work with chord. this should serve as a mental cue to  ensure the accessors are customized accordingly. e.g. by setting a constant radius. (d3-chord) [chore]: added jsdoc comments (d3-chord) [enhancement]: validated, updated and activated for use with strictnullchecks. note,in particular the updated signatures for invoking the ribbongenerator. these are now overloaded with one returning void (canvas context), and the other returning string | null, where the rendering context is null. note that the api suggests a string is returned in this case, however, it may actually return null as well as per source code. it is at the developers discretion to ensure return value expectations correspond to rendering context. (d3-chord) [chore] updated tests and bumped patch version number to indicate which version was last fully reviewed. </desc> <cmt> d3-path strictnullchecks and jsdoc </cmt> <cmt> * (d3-path) [chore] added complete jsdoc comments </cmt> <cmt> * (d3-path) [enhancement] validated and activated for use with strictnullchecks </cmt> <cmt> d3-chord: enhancement, fixes, chore </cmt> <cmt> * (d3-chord) [breaking fix] added additional interfaces ribbon and ribbonsubgroup to reflect the interfaces actually assumed by default by ribbongenerator. while the api documentation refers to passing in a chord object when invoking the ribbongenerator by default, this actually means the default radius accessor returns undefined, which is then coerced to nan. to avoid this ""silent"" fail, ribbon and ribbonsubgroup are now used as the datum types returned by the default ribbon() factory without explicit generics. this is a purposely accepted breaking change, as it means that passing in a chord object will now fail. the correct way, will be to use the generics of the ribbon<...>() factory to cast the datum type to work with chord. this should serve as a mental cue to  ensure the accessors are customized accordingly. e.g. by setting a constant radius. </cmt> <cmt> * (d3-chords) [chore]: added jsdoc comments </cmt> <cmt> * (d3-chords) [enhancement]: validated, updated and activated for use with strictnullchecks. note,in particular the updated signatures for invoking the ribbongenerator. these are now overloaded with one returning void (canvas context), and the other returning string | null, where the rendering context is null. note that teh api suggests a string is returned in this case, however, it may actually return null as well as per source code. it is at the developers discretion to ensure return value expectations correspond to rendering context. </cmt> <cmt> * (d3-chords) [chore] updated tests and bumped patch version number to indicate which version was last fully reviewed. </cmt>","d3 batch 2 with strictnullchecks, jsdoc and fixes"
4247,"<desc> implementation overview this pull request provides an iterative(non-recursive) implementation of json parsing. it tries to resolve the issue #35 by: saving parser state in an internal stack rather than using function local stack. in this way the complexity of function stack size is constant. providing a stack size limit to the parsing function. implementation details this pull request adds a new flag kparseiterativeflag to parseflag. parsing work with this flag will be directed to genericreader::iterativeparse, which is the entry point of this iterative parser. then the parser will traverse the given token stream and make transitions on a state machine. the state transition table is manually encoded in a static array, which is in function genericreader::predict. and the action code for every transition is in function genericreader::transit. performance report performance tests have been taken among: kparsedefaultflags (recursive parser, without in-situ) kparseiterativeflag (iterative parser, without in-situ) kparseinsituflag (recursive parser, with in-situ) kparseiterativeflag | kparseinsituflag (iterative parser, with in-situ) i expected the parsers with kparseiterativeflag are either slower or quicker than their counterparts. but the iterative parser without in-situ flag runs exceptionally slower than other parsers, while the iterative parser with in-situ being the most quick one. @pah pointed out this may be compiler-specific in #35 (comment). </desc> <cmt> try to resolve issue #35: implement iterative parsing. </cmt> <cmt> rename flags/state names/functions/test cases from 'nonrecursive' to 'iterative'. </cmt> <cmt> bugfix: add missing transition from finish state. </cmt> <cmt> it is sufficient to check finish state in iterative parsing. </cmt> <cmt> wip: refactor iterative parsing. </cmt> <cmt> finish the new implementation of state machine. but not been unittested. </cmt> <cmt> add basic error handling. </cmt> <cmt> handle all unspecific parsing errors. </cmt> <cmt> add unittests for state transition. </cmt> <cmt> add two basic performance tests. </cmt> <cmt> complete unittests for state transition. </cmt> <cmt> revise unittests: reset the handler before the transition which we are going to test. </cmt> <cmt> revise unittests of compound value(array or object)'s initial state transition. </cmt> <cmt> merge upstream/master. </cmt> <cmt> add unittests for kparsererrortermination; fix bugs in last merge. </cmt> <cmt> implement stack size limitation for iterative parsing. </cmt> <cmt> reduce times of stack size check; reduce transition table size. </cmt> <cmt> revise unittests: should not expose implementation details. </cmt>",iterative parsing (for issue #35)
4248,<desc> alias python make.py --single api to api.rst (like is done for the other .rst pages) pass through verbose flag to sphinx </desc> <cmt> enable passing verbosity flag to sphinx </cmt> <cmt> alias api for api.rst </cmt>,small updates to make.py script
4249,<desc> closes #7222 </desc> <cmt> docs: enable redirect link to work for each specific page </cmt> <cmt> docs: add canonical_url for search engines </cmt> <cmt> closes #7222 </cmt> <iss> [docs] [low priority] pytorch docs in google search points to master/unstable </iss>,add canonical_url and fix redirect link
4250,<desc> this pr has a working version of cql for both mujoco envs halfcheetah and hopper from the d4rl dataset. bug fixes such as gpu support and cql will now load the fully loaded dataset into replay buffer while ignoring adding elements into the replay buffer per timestep (as to keep the dataset constant). i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> ok </cmt> <cmt> format fix </cmt> <cmt> cql done </cmt>,cql for halfcheetah-random-v0 + hopper-random-v0 + cql bug fixes
4251,<desc> #73867 added the ability to create data stream aliases but only from aliases defined in the top-level composable template. this amends that to include  aliases defined in any component templates included in the composable template. relates to #66163 </desc> <cmt> include aliases from component templates </cmt> <cmt> add unit test </cmt>,create data stream aliases from component templates
4252,<desc> this pr will add optional header to the utm modules post and put requests as it is needed for some modules. module_utils/utm_utils </desc> <cmt> - removed info declaration from documentation fragment as this is not implemented </cmt> <cmt> - added optional headers for post and put requests </cmt> <cmt> - updated documentation </cmt>,add optional headers to utm modules
4253,"<desc> a couple simple changes to build the docs into the atom.io repo: check if ../atom.io exists skip building guides as they get imported into the db and indexed for search </desc> <cmt> copy docs into atom.io project, don't build guides as they are in the db </cmt> <cmt> check if atom.io directory exists in copy-docs </cmt>",copy docs into atom io
4254,<desc> created lumen gitignore created laravel5 gitignore compatible with the new folder structure. </desc> <cmt> create gitignore for lumen </cmt> <cmt> create gitignore for laravel5 </cmt> <cmt> in laravel 5 the storage folder was moved to the root of the application. the compiled.php has also been moved to the bootstrap/cache directory </cmt> <cmt> this was no longer compatible with the previous laravel.gitignore. </cmt>,gitignore for laravel5 and lumen
4255,"<desc> this pr is the single one in series of #20469 introduce dataprovider adapter: to read data as either file or stream or custom introduce cfg params to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work build configuration force_builders=custom,custom win,custom mac build_gapi_standalone:linux x64=ade-0.1.1f build_gapi_standalone:win64=ade-0.1.1f build_gapi_standalone:mac=ade-0.1.1f build_gapi_standalone:linux x64 debug=ade-0.1.1f xbuild_image:custom=centos:7 xbuildworker:custom=linux-1 build_gapi_standalone:custom=ade-0.1.1f build_image:custom=ubuntu-openvino-2021.3.0:20.04 build_image:custom win=openvino-2021.2.0 build_image:custom mac=openvino-2021.2.0 test_modules:custom=gapi,python2,python3,java test_modules:custom win=gapi,python2,python3,java test_modules:custom mac=gapi,python2,python3,java buildworker:custom=linux-1 test_opencl:custom=off test_bigdata:custom=1 test_filter:custom=* </desc> <cmt> add cfg_param & data_provider </cmt> <cmt> fix compilation after rebase </cmt> <cmt> apply some comments </cmt> <cmt> apply default ctor outside class definition comment </cmt> <cmt> apply cfg param in source </cmt>",onevpl (simplification) add data adapter & cfg params
4256,"<desc> fixes: #4029 inside the blocks environment project, add '/airsim/hudassets' to additional directories to always cook in order to ensure dependencies for the weather menu are included in packaged builds. additionally, a reference to menuactor was added to airsimassets.umap to ensure that blueprint is included in packaged builds as well. the blocks environment was packaged and the weather menu was confirmed to be working in the resulting binary. </desc> <cmt> update defaultgame.ini </cmt> <cmt> add '/airsim/hudassets' to additional directories to always cook in order to ensure dependencies for the weather menu are included in packaged builds </cmt> <cmt> update airsimassets.umap </cmt> <cmt> add reference to menuactor inside airsimassets map </cmt> <iss> weather widget not working when pressing f10 </iss>",fix missing assets in packaged builds
4257,<desc> description: this patch changed sendlocalreply to send grpcmessage in percent-encoded instead of plain string following:  risk level: low testing: unit tests docs changes: n/a release notes: added fixes #6902 </desc> <cmt> sendlocalreply to send percent-encoded grpcmessage </cmt> <cmt> this patch changed sendlocalreply to send grpcmessage in percent-encoded </cmt> <cmt> instead of plain string. </cmt> <cmt> fix </cmt> <iss> using a http based external auth service with grpc proxy entries crashes envoy on 401s </iss>,change sendlocalreply to send percent-encoded grpcmessage
4258,"<desc> all unit-*.cpp files in test/src include catch.hpp and json.hpp. both are header-only libraries, and can benefit from using precompiled headers. use cotire for reducing the compile time using a prefix header (test/src/prefix.hpp). change travis config to use cmake instead of the hand-written makefiles. enable parallel build in travis config (-- -j4) the results - comparing a sample without this change and with: metric without cotire with cotire travis (running time) 32 min 21 sec 28 min 32 sec travis (total time) 2 hrs 3 min 43 sec 1 hr 52 min 36 sec appveyor (total time) 3 min 34 sec 2 min 55 sec the travis build time can be further reduced by using the cmake build system for the slowest pieces (valgrind and sanitizer - these recompile the tests independently now), and the container-infrastructure. </desc> <cmt> :zap: cmake compile time reduce using cotire </cmt> <cmt> - add prefix header </cmt> <cmt> - include catch.hpp </cmt> <cmt> - include json.hpp </cmt> <cmt> - replace private with public for all json_unit files </cmt> <cmt> - move unit.cpp to an object library </cmt> <cmt> - cotire issue: strip whitespace from cmake_include_system_flag_cxx </cmt> <cmt> :construction_worker: add cmake logic to travis config </cmt> <cmt> - get cmake for xcode 8.1 image </cmt>",speedup ci builds using cotire
4259,"<desc> cherry-pick of #31826 and commit bba87cd which is needed for this branch only. explanation: tbdgen validation fails with an error: symbol '<case constructor symbol here>' is in generated ir file, but not in tbd file when we pass the -enable-testing flag, when using enum cases as protocol witnesses. scope: affects use of enum cases constructors to satisfy static protocol requirements (se-0280) sr issue: sr-12821 / rdar://problem/63364542 risk: low. this is a regression since se-0280 landed. testing: added new tbdgen tests. reviewed by: @slavapestov </desc> <cmt> [sil] use limit::ondemand for an enum element in sildeclref::getlinkage </cmt> <cmt> [tbdgen] emit case symbols only if enum is resilient and some other fixes </cmt> <cmt> (1) pass property getter as requirement when the witness is an payload-less enum case (2) remove dead code from visitenumdecl </cmt> <cmt> [test] add some tbdgen test cases for enum case witnesses </cmt> <cmt> [test] update a silgen test </cmt>",fix symbol mismatch for enum case constructors
4260,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> adding preloader and default theme modules </cmt> <cmt> updated version number </cmt>",adding preloader and default theme modules to spectacle
4261,"<desc> i added a couple links to my scala api repository in the documentation pages. i'm not sure if it's in the expected format, but feel free to rephrase if needed. it would be great if we could also add a link in the following page (i could not find it in the documentation sources):  thanks! edit: @asimshankar will take care of adding a link to </desc> <cmt> update from original tf repository </cmt> <cmt> updating the fork </cmt> <cmt> added references to the scala api in the tensorflow documentation pages. </cmt>",third-party scala api links in the documentation
4262,"<desc> fixes #13737. currently sparsefuncs.min_max_axis gives a typeerror whenever the input is a csc matrix (and axis is 0) with int64 indices on a 32-bit machine (due to a cast to intp in _minor_reduce). this does not occur (necessarily) for csr matrices, since the conversion to a csc matrix in _min_or_max_axis will downcast the indices when safe to do so (i.e. when all values fit in an int32). reinitialising the input to _minor_reduce should avoid this (and also the corresponding problem that would occur for csr inputs and axis of 1). a test for min_max_axis has been changed to cover the large matrices this affects. as expected, it now fails on 32-bit windows for the master code base. </desc> <cmt> changed variancethreshold behaviour when threshold is zero. see #13691 </cmt> <cmt> slightly modified change to variancethreshold and added test </cmt> <cmt> removed blank lines from end of file </cmt> <cmt> minor changes to new variancethreshold behaviour </cmt> <cmt> commented test </cmt> <cmt> update sklearn/feature_selection/variance_threshold.py </cmt> <cmt> update sklearn/feature_selection/variance_threshold.py </cmt> <cmt> changed test format </cmt> <cmt> reformatted assertion in test </cmt> <cmt> added test </cmt> <cmt> rolled back changes from other branch </cmt> <iss> utils.sparsefuncs.min_max_axis gives typeerror when input is large csc matrix when os is 32 bit windows </iss>",downcast large matrix indices where possible in sparsefuncs._minor_reduce (fix #13737)
4263,"<desc> i've investigated more why php jwt token creds test behaves differently than in other languages and found the reason. as a side effect, this should fix the problem we're seeing in #19228 (but it's basically a workaround that makes php behave like the other languages so the ""port resolved to 0"" problem is not triggered). </desc> <cmt> php interop client: construct channel target like other languages do </cmt> <cmt> remove port suffix from jwt audience </cmt>",hotfix for php jwt_token_creds interop test
4264,"<desc> as cdp uses the ifdescr in the local port information and lldp uses the ifalias, there is redundant data in ansible_net_neighbors. normalize the ifalias used by lldp to consolidate this. this implies that if there is cdp and lldp neighbor information for a particular interface, one piece of information is overwritten. at the moment, cdp would be preferred over lldp due to the exisiting order of the code. of course, this can be changed. nxos_facts before ""ansible_net_neighbors"": { ""eth1/2"": [ { ""port"": ""gi1"", ""sysname"": ""iosxe1.test.domain"" } ], ""ethernet1/2"": [ { ""port"": ""gigabitethernet1"", ""sysname"": ""iosxe1.test.domain"" } ] }, after ""ansible_net_neighbors"": { ""ethernet1/2"": [ { ""port"": ""gigabitethernet1"", ""sysname"": ""iosxe1.test.domain"" } ] }, </desc> <cmt> nxos_facts: remove dead code </cmt> <cmt> the commit e51964e made this redundant as the structured case is handled </cmt> <cmt> elsewhere. </cmt> <cmt> nxos_facts: do not gather neighbors redundantly </cmt> <cmt> lldp reports the neighbor using the abbreviated interface name, whereas </cmt> <cmt> cdp reports the neighbor using the full interface name. normalize the </cmt> <cmt> local interface name in the lldp case, so there is no redundant </cmt> <cmt> information. due to the order of the gathering, cdp neighbors are saved </cmt> <cmt> in case both lldp and cdp data is available on a certain interface. </cmt>",do not gather redundant neighbor data
4265,"<desc> hi, thanks for the great work. if you're interested, attached are some enhancements i added in my fork: user's gravatar display list of most used programming languages using an html form and native events to process form submission cheers. </desc> <cmt> added gravatar display in the header </cmt> <cmt> now catching exceptions in case a console instance is missing </cmt> <cmt> fixed html entity </cmt> <cmt> fixed indentation </cmt> <cmt> added lang attr to html tag + more consistent indentation </cmt> <cmt> added language statistics (+ indentation and code formatting) </cmt> <cmt> fixed absolute redirect prevents to host resume in webserver subdirectories/urlpaths </cmt> <cmt> using a real form and native event to process the form </cmt>","gravatar display, programming languages statistics, ""form"" submission handling"
4266,"<desc> includes fixes in #11144, #11145 which should land first. we don't run this on any bots yet, but @dschuff suggested we might do it on the test suite bot on chromium ci. </desc> <cmt> test fixes </cmt> <cmt> fix </cmt> <cmt> more [ci skip] </cmt> <cmt> more [ci skip] </cmt> <cmt> more [ci skip] </cmt> <cmt> todo [ci skip] </cmt> <cmt> fix the return value of __stdio_seek </cmt> <cmt> fixes </cmt> <cmt> fixes [ci skip] </cmt> <cmt> handle memory growth in node mmap </cmt> <cmt> more [ci skip] </cmt> <cmt> finish </cmt> <cmt> flake8 [ci skip] </cmt> <cmt> more [ci skip] </cmt>","get ""asan"" test suite passing"
4267,"<desc> the terminalui flag is drilled through all resident runners and devices in many places through the app. nevertheless, this is only used in a single place for an ios codesigning prompt.  remove the drilling and replace with a property on the terminal object. </desc> <cmt> remove drilling of uses terminal ui </cmt> <cmt> update code signing test </cmt> <cmt> revert unrelated changes </cmt>",place terminalui flag on terminal interface
4268,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> react cssproperties position made specific </cmt> <cmt> add test for css position </cmt>",react specific typings for css position
4269,<desc> fixes #37292. </desc> <cmt> properly preserve names of properties with numeric literal strings </cmt> <cmt> accept new baselines </cmt> <iss> storing a keyof to a string quoted number key produces ts2344: invalid constraint in declaration file </iss>,properly preserve numeric string named properties in declaration files
4270,<desc> case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  namespace-ee/react-calendar-timeline#17 it has been reviewed by a definitelytyped member. </desc> <cmt> update react-calendar-timeline.d.ts </cmt> <cmt> by issue: </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update definitions for es6 module system support. </cmt>,update react-calendar-timeline.d.ts for es6 module system support.
4271,"<desc> this resolves #6984 when a request for a snapshot is received, nodeos will now write the snapshot data to a temporary file and create an internal tracking record.  as this block becomes final or finality passes it on a competing fork, nodeos will either rename the temporary file to the expected snapshot name or delete the temporary file and return an error indicating that the snapshot was unusable. temporary files are written to the same directory as final snapshots with a different prefix.  notably this prefix contains a leading . so, on some os's it they will be hidden. this change will hold the rpc request (and its associated http session) open until the temporary snapshot is either finalized or removed.  any subsequent requests for the same snapshot will be attached to the future response and no longer return an error code stating that the snapshot already exists. this should eliminate situations where operators would rarely get snapshots that were invalid due to microforks and also prevent situations where the block.log and the snapshot were not immediately usable once the snapshot was written. notes tracking of temporary snapshots is ephemeral, meaning that if the nodeos process is terminated while snapshots are outstanding it may leave the temporary files on disk and will not clean them up or promote them upon the next invocation.  if this becomes a pain point, in the future we can consider durable ways of maintaining the tracking so that future invocations can resume the management of promoting snapshots produced from earlier invocations. /v1/producer/create_snapshot this endpoint used to return an error code if you made redundant requests for a snapshot before the head block had changed.  now, all requests for a snapshot at that head block will remain open pending the determination of that blocks finality.  at that time, all pending requests for that snapshot's creation will receive the same affirmative or error response. </desc> <cmt> move create_snapshot to an asynchronous call </cmt> <cmt> create the snapshots on demand as before but instead of returning add them to a ephemeral (in process) queue </cmt> <cmt> as the irreversible block passes the height of the snapshot, determine if the snapshot was created on a fork and </cmt> <cmt> prune snapshots outside of the main chain </cmt> <cmt> promote snapshots inside of the main chain </cmt> <cmt> regardless return to the http rpc callers at this time with a success of failure </cmt> <cmt> actually remove temp files for forked away snapshots </cmt>",write snapshots to a temporary file until the block they represent is final
4272,"<desc> in addition to more scenarios added to test_git, this pull-request adds support for specifying a custom inventory file by setting the variable inventory. the pull-request also creates a credentials.template file to guide users on the expected key/value pairs when running integration tests that require credentials (aka cloud). </desc> <cmt> additional test_git scenarios </cmt> <cmt> includes coverage for accept_hostkey and additional scm url formats. </cmt> <cmt> add credentials.template and support custom inventory </cmt> <cmt> testers may override the inventory and vars-file using the environment </cmt> <cmt> variables 'inventory' and 'vars_file'. </cmt>",additional test scenarios in roles/test_git
4273,<desc> fixes an issue that makes the selectcontrol options hidden when overflowing. test plan go to a dashboard inside a filter box open the options of any single-choice dropdown (multi-options dropdowns already worked properly) make sure the options are visible even when overflowing the filter box container has associated issue: #12004 requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix hidden dropdown when overflowing </cmt> <cmt> remove unnecessary space </cmt>,issue #12004 timegrain not visibile
4274,<desc> resolved some namespace issues but haven't fixed everything yet. will start a separate pr later. </desc> <cmt> [r]added basic model test </cmt> <cmt> [r] set up travis tasks for r tests (+1 squashed commit) </cmt> <cmt> squashed commits: </cmt> <cmt> [dc52eb2] t (+12 squashed commits) </cmt> <cmt> squashed commits: </cmt> <cmt> [266218e] test </cmt> <cmt> [2ea3089] fixes </cmt> <cmt> [b53c301] test </cmt> <cmt> [4def042] added rcpp </cmt> <cmt> [974a111] test </cmt> <cmt> [31d674c] test </cmt> <cmt> [c649a59] test </cmt> <cmt> [80950a6] test </cmt> <cmt> [9dd63a1] test </cmt> <cmt> [824100d] test </cmt> <cmt> [f6994d4] test </cmt> <cmt> [264d388] set up r tests on travis </cmt>,set up r travis environment
4275,"<desc> with this pr we support control flow analysis of conditional expressions and discriminant property accesses indirectly referenced through const variables. for example: function f1(x: unknown) { const isstring = typeof x === 'string'; if (isstring) { x.length;  // ok } } function f2(obj: { kind: 'foo', foo: string } | { kind: 'bar', bar: number }) { const isfoo = obj.kind === 'foo'; if (isfoo) { obj.foo;  // ok } else { obj.bar;  // ok } } function f3(obj: { kind: 'foo', foo: string } | { kind: 'bar', bar: number }) { const { kind } = obj; if (kind === 'foo') { obj.foo;  // ok } else { obj.bar;  // ok } } function f4(obj: { kind: 'foo', foo: string } | { kind: 'bar', bar: number }) { const k = obj.kind; if (k === 'foo') { obj.foo;  // ok } else { obj.bar;  // ok } } intuitively, indirect references to conditional expressions or discriminant property accesses behave exactly as if the expressions were written in-line. narrowing through indirect references occurs only when the conditional expression or discriminant property access is declared in a const variable declaration with no type annotation, and the reference being narrowed is a const variable, a readonly property, or a parameter for which there are no assignments in the function body. some examples where narrowing does not occur (but it would had the indirectly referenced conditions been written in-line): function f5(x: unknown) { let isstring = typeof x === 'string'; if (isstring) { x.length;  // error, no narrowing because isstring isn't 'const' } } function f6(obj: { kind: 'foo', foo: string } | { kind: 'bar', bar: number }) { const isfoo = obj.kind === 'foo'; obj = obj; if (isfoo) { obj.foo;  // error, no narrowing because 'obj' is assigned in function body } } up to five levels of indirection are analyzed in conditional expressions. for example, two levels of indirections are analyzed in the following code: function f7(x: string | number | boolean) { const isstring = typeof x === ""string""; const isnumber = typeof x === ""number""; const isstringornumber = isstring || isnumber; if (isstringornumber) { x;  // string | number } else { x;  // boolean } } it is possible to mix indirect conditional expressions and directly specified conditions: function f8(value: number | undefined) : number { const isnumber = typeof value == ""number""; if (isnumber && value > 0) { return value * 10; } return 0; } this pr fixes most of the long list of issues that were closed as duplicates of #12184, but not all. in particular, the pattern of destructuring a discriminant property and a payload property into two local variables and expecting a coupling between the two is not supported as the control flow analyzer doesn't ""see"" the connection. for example: type data = { kind: 'str', payload: string } | { kind: 'num', payload: number }; function foo({ kind, payload }: data) { if (kind === 'str') { payload.length;  // error, payload not narrowed to string } } we may be able to support that pattern later, but likely not in this pr. fixes #12184. fixes #19421. fixes #19943. fixes #24865. fixes #26804. fixes #31037. fixes #31059. fixes #31291. fixes #31344. fixes #31870. fixes #33192. fixes #34535. fixes #35603. fixes #36510. fixes #37638. fixes #37855. fixes #39657. fixes #39996. fixes #40201. fixes #40341. fixes #41266. fixes #41870. fixes #43333. </desc> <cmt> cfa inlining of conditional expressions referenced by const variables </cmt> <cmt> accept new baselines </cmt> <iss> indirect type narrowing via `const` </iss> <iss> feature request: infer types when using variable assignment with if-statements. </iss> <iss> type guard does not work when its value is set to a variable. </iss> <iss> allow storing results of narrowing in booleans for further narrowing </iss> <iss> destructing assignment fail to implicit cast type </iss> <iss> issue narrowing tagged unions with temporary const </iss> <iss> a problem with type checking in `if` statement. </iss> <iss> typescript should respect ""instanceof"" in logical expressions </iss> <iss> bug diagnosing error ""object is possibly 'undefined'"" </iss> <iss> suggestion: discriminate between union types based on extracted property </iss> <iss> wrong type inference when using 3rd variable </iss> <iss> object is possibly undefined even though check is done </iss> <iss> store the result of a type guard into a const but keep its type guard nature. </iss> <iss> typescript can't parse optional object when assigned to a variable </iss> <iss> type inference lost when destructuring </iss> <iss> separate variable type check doesn't guard type </iss> <iss> type is lost when result of type guard is assigned and strictnullchecks is on </iss> <iss> no narrowing on condition captured by const variable </iss> <iss> wrong error ""ts2532: object is possibly 'undefined'"" after assigning to const with optional chaining </iss> <iss> unexpect object is possibly 'undefined' error when checked before. </iss> <iss> compiler fails to infer that a date variable is not null even though it's obvious </iss> <iss> guard variable with conjunctions does not narrow the conjoined operands </iss> <iss> type narrowing does not survive after applying suggested 'extract to constant' refactoring </iss>",control flow analysis of aliased conditional expressions and discriminants
4276,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixed segfault in arrayenumerateuniq, arrayenumeratedense functions in case of some invalid arguments. </desc> <cmt> fix use after free in arrayenumerate [#clickhouse-2] </cmt> <cmt> fix use after free in arrayenumerate [#clickhouse-2] </cmt> <cmt> added performance test #3139 </cmt> <cmt> simplified logic with ""icolumn::converttofullcolumnifconst"" (suggested by amos bird) [#clickhouse-2] </cmt> <cmt> less garbage [#clickhouse-2] </cmt>",fix use after free in arrayenumerateuniq and -dense function.
4277,"<desc> the interface affects dog/cifar competition chapters. the change also affects utils.py, since the new transform function leaves label as an ndarray object, instead of a scalar. please run ci to make sure this is not breaking anything else. </desc> <cmt> add librsvg2-bin in readme </cmt> <cmt> improve kaggle dog tutorial </cmt> <cmt> fix </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> improve </cmt> <cmt> improve </cmt> <cmt> improve </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update data aug </cmt> <cmt> add fix to utils for new transform </cmt> <cmt> fix </cmt> <cmt> improve comments </cmt>",switch to new transform function
4278,<desc> as reported in #961 dynamically generated sections are not correctly reported when using junit reporter. the cause of this is that only the source code line is taken into account when comparing sections in cumulativereporterbase when it should also consider the section's name. closes #961 </desc> <cmt> bysectioninfo should also take into account the section name in addition to the source code line </cmt> <cmt> reverted single header </cmt>,fix for junit reporter when using dynamically generated sections
4279,"<desc> previous versions of solidity would parse octal numbers as octal while the documentation stated that they were interpreted as decimal numbers. since the arcaneness-to-usefulness-ratio of octal numbers is quite high, they are disallowed to avoid confusion. fixes #1724 </desc> <cmt> disallow octal literals. </cmt> <cmt> changelog entry. </cmt>",disallow octal numbers in parser.
4280,<desc> added support of following features: lists and date type for customattributes in-app chat notification primary button actions </desc> <cmt> add lists and date time for customattributes </cmt> <cmt> any changed to object </cmt> <cmt> version of plugin changed </cmt>,"lists and date time for customattributes, in-app chat, notification primary button actions"
4281,<desc> minor cleanup in ansible-test to prepare for updating to a newer pylint version. ansible-test </desc> <cmt> ansible-test - fix use of abstractproperty </cmt> <cmt> ansible-test - use dict.items() where possible. </cmt> <cmt> ansible-test - remove unused code. </cmt> <cmt> ansible-test - cleanup issues reported by pylint. </cmt> <cmt> ansible-test - use dict.items() where possible. </cmt>,ansible-test - cleanup to prepare for pylint update.
4282,"<desc> instead of using dql's describe_all method, we implement it in place and catch exceptions. this makes sure that if we happen to have ability to list tables we don't have describe permission for, the schema load won't fail. </desc> <cmt> safe implementation of describe_all. </cmt> <cmt> autopep8. </cmt>",safe implementation of schema loading
4283,<desc> backport of #14490. reverts gh-14458 and instead fixes the actual incorrect code. this fixes a regression in 1.17 and does not result in a change in behavior of the legacy random code. </desc> <cmt> maint: random: revert gh-14458. </cmt> <cmt> bug: random: fix the mistaken duplicate line. fixes gh-14557. </cmt> <cmt> doc: update randomstate docstring from master. </cmt>,random: revert gh-14458 and refix gh-14557.
4284,"<desc> make a number of changes so that code in the monitoring x-pack plugin is more resilient to automatic formatting. this covers: reformatting multiline json to embed whitespace in the strings move some comments around to they aren't auto-formatted to a strange place. </desc> <cmt> improve x-pack monitoring formatting resiliency </cmt> <cmt> omake a number of changes so that code in the x-pack/plugin/monitoring </cmt> <cmt> directory is more resilient to automatic formatting. this covers: </cmt> <cmt> * format cipher lists vertically, instead of horizontally </cmt> <cmt> * remove string concatenation where json fits on a single line </cmt> <cmt> * move some comments around to they aren't auto-formatted to a strange </cmt> <cmt> place </cmt> <cmt> * disable formatting for some indented and tabluar code in </cmt> <cmt> httpexportbulkresponselistenertests. this also requires a checkstyle </cmt> <cmt> suppression. </cmt> <cmt> exclude sql's datatype.java from being formatted </cmt> <cmt> revert checkstyle changes </cmt> <cmt> checkstyle </cmt>",make x-pack monitoring more robust when formatted
4285,"<desc> to prevent fouc, discussed in #10557 i need to store information about css file dependencies for chunk. right now current implementation just throws away everything but js. can there be more than one css file in chunk? if no - code will be simplified. closes #10557 </desc> <cmt> feature: store css file information for dynamic imports #10557 </cmt> <cmt> feature: store css file information for dynamic imports #10557 </cmt> <iss> fouc with css-modules while using ""next/dynamic"" </iss>",store css file dependencies info for dynamic imports and apply it at ssr
4286,"<desc> the ultimate problem is addressed in faf8f68: servers were not proactively closing incoming connections received after shutdown, leaving clients hanging. along the way, i noticed that pick_first ends up leaving all the subchannels open, even though it'll only use one after selection... and so that got fixed. fixes #3624 </desc> <cmt> tag struct to ease casting in debugger </cmt> <cmt> add a simpler (but slower) path for closures for where it makes sense </cmt> <cmt> discard unnecessary subchannels when they're no longer required </cmt> <cmt> close incoming connections if we are post shutdown </cmt> <cmt> merge github.com:grpc/grpc into smash-it </cmt> <cmt> fix memory leaks </cmt> <iss> channel connectivity test is flaky on windows </iss>",fix connectivity tests under windows
4287,"<desc> towards #14312 this adds the loss function attribute to passiveaggressiveclassifier however, this loss_function_ attribute is inconsistent with the loss parameter set by the user (see #16270) </desc> <cmt> add doc for attribute loss_function_ in passiveaggressiveclassifier </cmt>",ensure all attributes are documented for passiveaggressiveclassifier #14312
4288,"<desc> related issue = #510  #839 when taichi programs are combined with pytorch, the jit evaluation may happen in multiple threads. however, cuda does not allow kernel compiled in one thread to run in another. therefore i have to add std::this_thread::id to jitevaluatorid. i also did some refactoring there since the keys can no longer be uniquely represented using a uint64/uint32... the changeset might seem large since ti format also fixed previously introduced format issues. a few trivial refactorings. </desc> <cmt> . </cmt> <cmt> add thread_id to jitevalutorid </cmt> <cmt> . </cmt> <cmt> fix tests </cmt> <cmt> lock </cmt>",fix constant folding in multithreaded cuda applications
4289,"<desc> original pull-request #19443 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix wrong parts in parts_to_do </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> addition to #15537 </cmt>",cherry pick #19443 to 20.11: addition to #15537
4290,"<desc> several prs were merged onto a feature branch in the sprint while the code freeze on master was in effect. each of these prs has already been tested / reviewed to the same standard as the master branch. component name aclk description of testing that the developer performed each pr contains test information. no retesting should be necessary to merge the branch. </desc> <cmt> aclk connection and protocol improvements (#8139) </cmt> <cmt> * apply clean patch to aclk </cmt> <cmt> * - cleanup the json parsing to remove objects/arrays </cmt> <cmt> - refine comments on functions that require the user's attention for locking structures </cmt> <cmt> - be consistent for the aclk_cmd_onconnect calls </cmt> <cmt> - add more debug messages </cmt> <cmt> - remove todo comments that relate to obsolete specifications </cmt> <cmt> - hide the wss initialization variable inside its function </cmt> <cmt> - cleanup code whitespace (formatting) </cmt> <cmt> * - fixed the timestamp in outgoing messages from string to number </cmt> <cmt> adding aclk retry on connection failure (#8147) </cmt> <cmt> moved the reconnection logic into the main loop and integrated with the lws layer. </cmt> <cmt> fixed reconnect issues on the aclk. (#8163) </cmt> <cmt> not all of the callbacks generated by lws have their return codes checked, so there are callback </cmt> <cmt> kinds that cannot ask for the wsi to be destroyed. connection failures at different phases in the </cmt> <cmt> establishment phase trigger different callback from different points. if the connection fails early </cmt> <cmt> enough then no lws_callback_wsi_destroy is generated and so we did not trigger our own callback to </cmt> <cmt> inform the upper layer. </cmt> <cmt> when the connection is torn down via callback that does not lead to the wsi_destroy the wsi is </cmt> <cmt> internally deallocated after the callback - i.e. the pointer stops being valid at the end of the </cmt> <cmt> callback. we handle this by clearing the pointer and crossing our fingers that there is no memory </cmt> <cmt> leak as lws gives us no visibility into this and if we call lws_close_free_wsi() twice on the same </cmt> <cmt> pointer it can cause a segmentation fault. </cmt> <cmt> ultimately this fix is problematic and we may have to fork libwebsockets to fix this poor aspect of </cmt> <cmt> their api design. </cmt> <cmt> this was tested in docker-compose by taking he broker/agent machines up/down in each combination. </cmt> <cmt> merging with a single review as i need to rebase the feature branch to get valgrind into the </cmt> <cmt> testing environment. </cmt> <cmt> cleaning up aclk - part 1 (#8167) </cmt> <cmt> added a paho inspection point to the test setup and the option to use valgrind on the agent. fixed a build error that occurred due to a glitch in the previous pr. </cmt>",merging the feature branch for the aclk in the previous sprint.
4291,"<desc> the inquiry names were not being updated when the guest name changes, for instance, when the agent changes the guest data and the inquiry is still in the queue. only rooms and subscriptions data were being updated. </desc> <cmt> fix the renaming inquiry name process when the inquiry is in the queue. </cmt> <cmt> fix the && condition stated in the wrong place. </cmt>",omnichannel inquiry names not being updated when the guest name changes
4292,<desc> this pr just moves files and corrects imports. this will minimize noise in the dif for the important pr's that do the real work. see #20434 for details and reasoning. the const bridge in the zha folder itself is to support the quirks library which will be updated post rewrite and this file will be removed. </desc> <cmt> rearrange files </cmt> <cmt> add init to module </cmt> <cmt> update imports </cmt>,zha component rewrite part 1
4293,"<desc> fixes #5599. this pr allows operators and indexing to work with intersection types that include primitive types, making it easier to create and use ""tagged"" primitive types. for example: type guid = string & { $guid };          // tagged string type type serialno = number & { $serialno };  // tagged number type function createguid() { return ""21ec2020-3aea-4069-a2dd-08002b30309d"" as guid; } function createserialno() { return 12345 as serialno; } let map1: { [x: string]: number } = {}; let guid = createguid(); map1[guid] = 123;  // can index with tagged string let map2: { [x: number]: string } = {}; let serialno = createserialno(); map2[serialno] = ""hello"";  // can index with tagged number // operators treat tagged primitives as regular primitives const s1 = ""{"" + guid + ""}""; const s2 = guid.tolowercase(); const s3 = guid + guid; const s4 = guid + serialno; const s5 = serialno.toprecision(0); const n1 = serialno * 3; const n2 = serialno + serialno; const b1 = guid === """"; const b2 = guid === guid; const b3 = serialno === 0; const b4 = serialno === serialno; </desc> <cmt> correct handling of intersection types in allconstituenttypeshavekind </cmt> <cmt> rename allconstituenttypeshavekind/someconstituenttypehaskind to istypeofkind/maybetypeofkind </cmt> <cmt> adding test </cmt> <cmt> accepting new baselines </cmt>",allow operators and indexing with intersections involving primtive types
4294,"<desc> fixes #2073 sometimes, it's possible to have dynamically imported module without an actual physical file (chunk). this is because the same module imported normally and exists in the app's main js bundle. so, we need to make sure to ignore such modules when the page loads with ssr. </desc> <cmt> always check with the fs when gettings chunks. </cmt> <cmt> add a new set of test cases for dynamic imports in dev. </cmt> <cmt> add dynamic import test cases for production. </cmt>",load chunks in ssr mode only if they exists in the filesystem
4295,"<desc> this adds support more for ads rendering settings 861b816 allow setting the ad media bitrate in imaadsloader e.g. adsloader = new imaadsloader.builder(context) .setmediabitratekbps(700) .buildforadtag(uri.parse(adtag)); when vast with multiple bit rates set is returned, if nothing is set, the imasdk selects the highest bit rate. i tried it with the following vast data.  test1: default(not set) -> ad_1080.mp4 test2: sets 700 kbps -> ad_240.mp4 cfcbd21 allow setting the ad ui elements to be rendered in imaadsloader e.g. adsloader = new imaadsloader.builder(context) .setaduielements(collections.emptyset()) .buildforadtag(uri.parse(adtag)); it is useful when you want to create ad ui element in the application. default(not set) empty </desc> <cmt> allow setting the ad media bitrate in imaadsloader </cmt> <cmt> allow setting the ad ui elements to be rendered in imaadsloader </cmt>",customize ads rendering settings more
4296,"<desc> the current description of the input arguments input_dim and mask_zero are a bit confusing: input_dim: int > 0. size of the vocabulary, ie. 1 + maximum integer index occurring in the input data. ... mask_zero: ... if mask_zero is set to true, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal |vocabulary| + 2). the first line seems correct, where i would understand size of the vocabulary as input_dim = len(vocabulary_indices) and 1 + maximum integer index occurring in the input data. as input_dim = max(vocabulary_indices) + 1 however the second line is confusing as you say input_dim should equal |vocabulary| + 2 i would interpret |x| as the cardinality of x, i.e. len(x). so you are effectively saying input_dim = len(vocabulary_indices) + 2 which is not correct. it should be input_dim = len(vocabulary_indices) + 1 or input_dim = max(vocabulary_indices) + 2 the fix this pr fixed that by reformulating the two lines to input_dim: int > 0. size of the vocabulary or maximum integer index + 1. ... mask_zero: ... if mask_zero is set to true, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1). </desc> <cmt> doc: embeddings, fixed indentation </cmt> <cmt> doc: embeddings, clarified input_dim size description </cmt>",slight rewording of description for input_dim in embeddings
4297,"<desc> currently, upsampling1d/2d does tiling on its input ([0, 1] => [0, 1, 0, 1]). this modifies those layers to repeat individual entries instead (so [0, 0, 1, 1] => [0, 0, 1, 1]), as discused in #1226 and #1287 and should fix those issues. this works by adding a new backend operation repeat_elements which has the same behavior as np.repeat. the tensorflow implementation uses a split and a concat. this might not be the most efficient way to do it, but at least it works. i am just starting to learn tensorflow, so if some indexing tricks wizard knows a better way, please let me know :-) </desc> <cmt> add a k.repeat_elements function which works like np.repeat </cmt> <cmt> modify upsampling1d/2d to turn [0, 1] into [0, 0, 1, 1] instead of [0, 1, 0, 1] </cmt>",modifies upsampling1d/2d to repeat entries instead of tiling arrays.
4298,<desc> after powertoy module is disabled we need to make sure that no crash occurs when user tries to change settings of disabled powertoy. pr checklist applies to #1250 validation steps performed disable any of the available powertoys. change settings of disabled powertoy. expected result: nothing happens (no crash occurs). </desc> <cmt> fix for: shortcut guide crashes when saving settings while the module is turned off </cmt> <cmt> add guards checking if certain powertoy is enabled </cmt>,fix crash when saving any module settings while module being disabled
4299,"<desc> based on #16957. right now we are building c++ qps_worker in e2e benchmarks with make, which disables boringssl assembly optimizations. we should see much better numbers for secure channel when building with cmake. </desc> <cmt> too many c++ benchmarks considered ""smoketest"" </cmt> <cmt> more reasonable timeouts scenario timeout </cmt> <cmt> build c++ in benchmarks with cmake </cmt>",build c++ with assembly optimizations
4300,"<desc> the new ndf is a softer distribution proposed by estevez and kulla. we choose it over ashikhmin because of its aesthetic properties and its more intuitive control. we omit the shadowing term proposed by estevez and kulla. and just like with the previous ndf our prefiltered cubemap is wrong (prefiltered with the wrong brdf) but we accept this limitation. </desc> <cmt> add new cloth ndf </cmt> <cmt> based on the work by estevez and kulla, also known as the ""charlie"" sheen. </cmt> <cmt> restore dfg computation to ggx </cmt> <cmt> new proposed approximation for cloth dfg </cmt> <cmt> add ""charlie"" cloth dfg approximation to cmgen </cmt> <cmt> switch to ""charlie"" sheen for cloth shading </cmt> <cmt> document the new cloth ndf and dfg approximation </cmt>","switch cloth model from ashikhmin ndf to ""charlie"" ndf"
4301,"<desc> #16756 </desc> <cmt> merge from cocos2dx v3 </cmt> <cmt> merge from cocos2dx v3 </cmt> <cmt> merge from cocos2d-x </cmt> <cmt> tilegid may overflow when use horizontal flip </cmt> <cmt> ktmxtilehorizontalflag = 0x80000000 </cmt> <cmt> when use horizontal flip, gid will bigger chan 0x7fffffff </cmt>",fix issue#16756 tilegid may overflow when use horizontal flip
4302,<desc> if containing folder is missing we don't do any file lookups in this folder however we still visit this folder to populate the list of failedlookuplocations. with this pr we don't report this files if traceresolution compiler options is specified </desc> <cmt> added missing '.' at the end of message </cmt> <cmt> do not report lookups if containing folder is known to be absent </cmt>,do not report file lookups if containing folder is known to be missing
4303,"<desc> builds on #27441 this target ends up being substantially bigger than i'd like, but i think it represents the minimum part of iomgr that can be split out, and gives me a piece that i can depend on from the promise stuff without dragging in everything, which i like. i've removed the stats and profiling dependencies for now... if it comes time to optimize this particular code again, i'm going to regret that, but i have enough confidence in event engine that i expect that this code will be nuked soon enough and we'll be focusing optimization efforts elsewhere. </desc> <cmt> make error independent </cmt> <cmt> separate grpc_error into its own library </cmt> <cmt> this is forward work to move closure, execctx into their own libraries </cmt> <cmt> in order to make use of them in the activity code for resource quota </cmt> <cmt> wakeups. </cmt> <cmt> automated change: fix sanity tests </cmt> <cmt> automated fix for refs/heads/error </cmt> <cmt> fixes </cmt> <cmt> split out closure lib </cmt> <cmt> exec_ctx </cmt> <cmt> make things compile </cmt>",split execctx into its own target
4304,<desc> fix all flake8 issues uncovered by #8878 except the one in #9200. </desc> <cmt> fix latest flake8 warnings in emcc.py </cmt> <cmt> fix flake8 errors in emscripten.py </cmt> <cmt> fix flake8 in emar and emlink </cmt> <cmt> fix flake8 in emrun.py </cmt> <cmt> fix flake8 errors in test/test_other.py </cmt> <cmt> fix flake8 in test classes </cmt> <cmt> fix flake8 in shared.py </cmt> <cmt> fix flake8 errors in tools </cmt> <cmt> fix flake8 errors in site </cmt> <cmt> fix flake8 in fuzz tests </cmt> <cmt> fix python 3 compatibility problems in gen-unicode-tables.py </cmt>,fix all flake8 issues on python 3
4305,"<desc> command line just specifies the core limit for the client and server the driver then figures out which cores to give to client and server if the client and server are running on the same specified host, the driver will make sure that if only one (client or server) limit is specified, that the other one is automatically determined. </desc> <cmt> make core limitation work for both client and server so that we can run tests on the same </cmt> <cmt> machine if desired. the core_list flags to qps_driver are comma-separated lists of </cmt> <cmt> core numbers. </cmt> <cmt> clang-format </cmt> <cmt> fix copyrights for sanity </cmt> <cmt> sanity fix copyright </cmt> <cmt> change name from coresched to limit_cores </cmt> <cmt> added todo as a reminder to drive core selection automatically </cmt> <cmt> rename coresched --> limit_cores </cmt> <cmt> fix include guard </cmt> <cmt> clean-up core list usage and make it possible to reset the core list </cmt> <cmt> make dynamic sizing of async threads work again </cmt> <cmt> enable properly working core limits on clients and servers, </cmt> <cmt> and determine these dynamically if only one or the other is </cmt> <cmt> specified but both are running on the same host </cmt> <cmt> make sure that client limit is valid </cmt> <cmt> reduce diff </cmt>",enable core limits on performance testing client and server
4306,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> glue - fix to plugins </cmt> <cmt> plugins can now be string arrays rather that just strings </cmt> <cmt> plugins can now be string arrays rather that just strings </cmt> <cmt> glue - fixed compose to return promise </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> glue - updated test </cmt>,glue - fixed compose return type
4307,"<desc> ref #11240 when invoking physicsjoint*::set*(...) before world->updatejoints(), thread abort. to fix this: store value in _writecache apply the change in physicsworld::updatejoints </desc> <cmt> use cache </cmt> <cmt> add unlikely </cmt> <cmt> fix pbxproj file </cmt>",cache physicsjoint* attributes before physicsworld update
4308,"<desc> it would previously segfault on accessing argv[1]. also, mention that dyld shouldn't be normally invoked directly and suggest the ""darling"" command to be used instead. </desc> <cmt> output usage if dyld is launched with no arguments </cmt> <cmt> mention that dyld shouldn't be normally invoked directly </cmt>",output usage if dyld-multilib is launched with no arguments
4309,"<desc> this would be a huge pull request, relating to protocol, agent and backend. 8.x would be an new core without back forward compatibility. after the experiences of removing endpoint_inventory, i found out this strategy is successful. especially, we totally get rid of register, so i want to do more. skywalking 8.0.0 first, it is already unexpected for me, we have to move to 8.0.0 so quickly, but after the discussion with @hanahmily , and thinking about this for several days, i think we have to. the key chances are following remove service, service instance, and network address register. the old register protocols are totally going to be removed. the agent doesn't need to do register anymore. service name and service instance name are generated by the agent itself, but the extra information, such as ip, hostname, language, should report to backend separately. service traffic should be added just like the endpoint traffic but keep the time bucket as we need accurate service name in the given duration service instance traffic should be added too, with external information, such as language, hostname. trace context propagation context should be changed to accept string in service instance name, endpoint name and network address. this could ease the agent logic, but also, requires changes in all language agent and plugin test tool, trace report protocol requires to change too, in order to adopt the string. e2e tests have to ignore php and lua at first, and remove the 6.x compatibility test(doesn't support anymore). the benefits we will get are don't worry about the inventory(s) that has been deleted randomly by end users. (we received a lot of issue reports about this) the upgrade could be easier erasing the whole storage and reboot the new one. (users don't feel comfortable about upgrade) no hot-reboot case in the agent side no cache of network address register information in the agent. no service and service instance cache in the oap no register lock in the oap no file buffer mechanism in the oap too, same as no register happens. in my mind, i think this totally break upgrade is super meaningful and will be good change. even we break many things, they are easy to follow. @mrproliu  i think by following this, we need to change the collaboration header to sw8 :) as no 7.1.0 release will happen. link to mail list, </desc> <cmt> 1. update protocol. 2.finish most changes at the agent side. 3. working on the test case fix. </cmt> <cmt> clean the test issue. agent and plugins are ready. </cmt> <cmt> add idmanager for further refactor. </cmt>",make 8.0.0 core available. new protocol and register removed.
4310,<desc> .set_tooltips and .set_tooltips_class are introduced to 1.3.0. just realised it seems a bit pointless to have two api functions: remove .set_tooltips_class() and ._init_tooltips() include the css_name and props arguments in .set_tooltips for same functionality. no api break since these functions have not yet been released make argument names more consistent with other styler methods. </desc> <cmt> remove set_tooltips_class </cmt> <cmt> whats new docs </cmt> <cmt> tests </cmt>,remove .set_tooltips_class incorpate to .set_tooltips
4311,"<desc> 20e6ff2: fix #24059, fix #25034 fix #22462, fix #22556, fix #21996 (all are duplicates of the same issue). ced9fca: does not fix any particular issue, but it's related to #21461 30f02dd: fix #24022 </desc> <cmt> gdscript: fix type-check of indexed values </cmt> <cmt> gdscript: clarify error message about cycles </cmt> <cmt> they may happen with any cyclic dependency, not only with inheritance. </cmt> <cmt> gdscript compiler: check if subclass exists before comparison </cmt> <cmt> otherwise these checks might trigger the insertion of an empty value, </cmt> <cmt> leading to crashes. </cmt> <iss> gdscript parser has issues with static typing outer class in inner class. </iss> <iss> if a member of an inner class has the same name as a variable in the outer class, the type of the outer variable is used for type-checking </iss> <iss> optional typing conflict if a class and one of its member variables share a common named attribute with different expected types </iss> <iss> crash when downcasting to an inner class type within an inner class </iss> <iss> variable type is overwritten by a local variable </iss> <iss> assignment bug with typed gdscript if class variables has same name as node members </iss>",a bit more of gdscript fixes
4312,"<desc> mappedfieldtype is a combination of two concerns: an extension of lucene's fieldtype, defining how a field should be indexed a set of query factory methods, defining how a field should be searched we want to break these two concerns apart.  this commit is a first step to doing this, breaking the inheritance relationship between mappedfieldtype and fieldtype.  mappedfieldtype instead has a series of boolean flags defining whether or not the field is searchable or aggregatable, and fieldmapper has a separate fieldtype passed to its constructor defining how indexing should be done. relates to #56814 </desc> <cmt> cut 1: /server compiles, mapping tests pass </cmt> <cmt> server/ tests passing </cmt>",mappedfieldtype should not extend fieldtype
4313,"<desc> commit message: after stoplistener(), only close all the listen socket of that listen if the listener is not quic. risk level: low, only quic is affected testing: re-enabled quichttpintegrationtest::admindraindrainslisteners, added unit test fixes #19006 </desc> <cmt> closeallsocket() not close reuse_port sockets </cmt> <cmt> fix admin drain </cmt> <iss> quichttpintegrationtest.admindraindrainslisteners is flaky </iss>",do not close listen socket after stop listening
4314,"<desc> this deletes the autodiffassociatedfunctionwitness from the witness table, and instead puts the autodiff associated functions in normal method witness table entries, using the autodiff sildeclref from #21224. for easier reviewing, i have split it into two commits. the first commit removes most of the autodiffassociatedfunctionwitness stuff, putting everything back mostly like it was in master, and the second commit adds the entries back in, using sildeclref. </desc> <cmt> remove autodiff witness table entries </cmt> <cmt> add autodiff witness table entries using sildeclref </cmt>","autodiff associated functions in witness table, using sildeclref"
4315,"<desc> subject says it all. </desc> <cmt> resolved: when passing rrs across the bus, make sure not to use name compression </cmt> <cmt> we explicitly need to turn off name compression when marshalling or </cmt> <cmt> demarshalling rrs for bus transfer, since they otherwise refer to packet </cmt> <cmt> offsets that reference packets that are not transmitted themselves. </cmt> <cmt> resolve-host: minor wording improvement </cmt>",don't do name compression when passing rrs across the bus
4316,"<desc> per airflow-6515, i executed the following to get a list of potential errors logged with the info or warn level: grep -ie 'log\.(info|warn).*(error|exceptio|fail|unab|couldn|lost|gone|missing|not fou|abort|exit|could not)' -r * in addition to the above, i also ran the following grep -ie 'log\.(info|warn).*(unav)' -r * grep -ie 'log\.(info|warn).*(not p)' -r * grep -ie 'log\.(info|warn).*(invalid)' -r * i changed what i thought were errors to use the error log level. i also changed one or two info entries to warn log level. the above grep commands still return some matches but i believe those are likely false positives. make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> [airflow-6515] change log level from info/warn to error </cmt> <cmt> [airflow-6515] change log level from info/warn to error </cmt> <cmt> [airflow-6515] change log level from info/warn to error </cmt>",change log levels from info/warn to error
4317,"<desc> this allows xgboost to compile with nvcc 11.4 i haven't looked into dh::argsort fully, but if it requires full 64bit support we can't update to cub 1.12+ due to </desc> <cmt> use type aliases for discard iterators </cmt> <cmt> update to include host_vector as thrust 1.12 doesn't bring it in as a side-effect </cmt> <cmt> cub::dispatchradixsort requires signed offset types </cmt>",allow compilation with nvcc 11.4
4318,"<desc> devicelab tasks use taskresult to store the data they need. the runners in the devicelab use a vm service to spawn a separate process to run these tasks. this is some debt where the json has never been converted back into the taskresult, so everything above the task uses map<string, dynamic> with extra checks. this adds extra soundness and should make it easier to work across the devicelab code (task result data is all accessible from task result). related issues #66191 - cocoon logic would be more sound using taskresult instead of json i added the following tests: taskresult tests to verify different json outputs work as expected before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. </desc> <cmt> add cocoon update task status </cmt> <cmt> initial cocoonagent </cmt> <cmt> refactor taskresult to separate file </cmt> <cmt> add imports to the tasks </cmt>",refactor devicelab logic to use taskresult instead of json
4319,"<desc> fix use of apis deprecated in java 9+ </desc> <cmt> set target version to runtime java version </cmt> <cmt> don't bumpt target over 10, 11 is not supported yet </cmt> <cmt> set forbidden apis target compatability to compiler </cmt> <cmt> fix outstanding deprecations </cmt>",set forbidden apis target compatibility to compiler java version
4320,"<desc> this is a bit of an odd one, but it's not too complex. some of the data structures in libgdx have special handling in json, like intmap, objectintmap, and longmap; these output like normal json maps, with only the present keys and present values written. other data structures, like intintmap, intfloatmap, and objectlongmap do not have such special handling, and output json like this for a 14-item intintmap: {size:14,keytable:[0,0,102,0,0,0,0,0,107,0,0,10,0,0,0,2,0,0,0,0,7,0,0,0,0,0,101,0,0,0,4,0,106,0,0,0,0,0,0,1,0,0,103,0,0,6,0,0,0,0,0,0,0,0,3,0,0,105,0,0,8,0,0,0],valuetable:[0,0,14,0,0,0,0,0,1,0,0,2,0,0,0,1,0,0,0,0,3,0,0,0,0,0,63,0,0,0,2,0,4,0,0,0,0,0,0,1,0,0,2,0,0,2,0,0,0,0,0,0,0,0,1,0,0,6,0,0,2,0,0,0]} instead of what the same data in an intmap looks like: {102:14,107:1,10:2,2:1,7:3,101:63,4:2,106:4,1:1,103:2,6:2,3:1,105:6,8:2} these data structures without special handling currently attempt to serialize all fields, because none are marked transient. since this is all of the fields, that includes entries, keys, and values instances, which involve a circular reference to their containing collection. that causes a stack overflow when serializing any of these data structures after a method like iterator(), entries(), keys(), or values(), assuming collections.allocateiterators is false. this fixes the stack overflow by marking the temporary entries, keys, values, and some iterable/iterator objects that get reused by libgdx data structures as transient. it only changes some iterable/iterators because some of those classes already got special treatment, and so marking their iterators as transient isn't required. a better approach would be to repeat the special treatment intmap and objectintmap get for the other data structures in libgdx, but i had written code to do that and it was removed without replacement. even if we do treat intintmap like intmap, this change should still be useful in case someone uses a third-party serialization format that doesn't understand libgdx internals. </desc> <cmt> improve mathutils.asin(), acos() </cmt> <cmt> the average and largest error are significantly better for this version (2-3 orders of magnitude), and it can be slightly faster. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix missing check for index_zero in intintmap, intfloatmap. </cmt> <cmt> this fixes #6347 . thanks @tomcashman , for making this an easy fix! </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> mark key/value/entry/iterator fields as transient. </cmt> <cmt> this stops a bad stackoverflowexception from happening when some map or set types are iterated over and then written with json. that happens in all stable versions i've tried between 1.9.6 and 1.9.13, on at least intintmap but probably also intfloatmap and objectlongmap. </cmt> <cmt> a better alternative would be to add special-case json handling like intmap, objectintmap, and longmap have for the other primitive-backed maps, since that would make the output much cleaner, smaller, and more readable. at one point, the special-case handling i wrote was in my pr that introduced these updated data structrures, but adding that was overruled, and the serialization code was removed without transient being added in its place to fields that cause problems during ""vanilla"" serialization. </cmt>",fix crash during json serialization of intintmap (and probably others) after iteration
4321,<desc> closes #17014 types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> [fix] wrong avatar urls when using providers </cmt> <cmt> fix users not being able to use e2e in dms </cmt> <iss> enabling e2e in direct message channel is possible only to other member </iss>,users not being able to activate/deactivate e2e in dms
4322,<desc> travis ci is not free any more. this pr setup github actions and fix minor build issues please check below build output  current status:  ubuntu-18_04: ok ubuntu-20_04: failed -  windows-2019: ok windows-2022: ok macos-10_15: failed - latest xcode not supported macos-11: failed - latest xcode not supported macos-10_15_ios: failed ?? macos-11_ios: failed ?? windows-2019-android: ok ubuntu-20_04-android: ok </desc> <cmt> create main.yml </cmt> <cmt> add v3 branch </cmt> <cmt> update main.yml </cmt> <cmt> v4 workflow </cmt> <cmt> linux 18.4 </cmt> <cmt> v4 </cmt> <cmt> submodules </cmt> <cmt> fix android </cmt> <cmt> increase cmake version to 3.10 </cmt> <cmt> cmake3.10 </cmt> <cmt> a </cmt> <cmt> greater </cmt> <cmt> remove 3.10.0 </cmt> <cmt> cmake_minimum_required(version 3.6) </cmt> <cmt> new line </cmt>,setup github actions for v4
4323,<desc> sort uses os.walk to find images in a directory. this logic will recursively walk that directory and every sub-directory to find images. this recursive nature is unintended and potentially dangerous. </desc> <cmt> smooth loss </cmt> <cmt> bugfix </cmt>,recursive loading of images all sub-directories in sorter
4324,"<desc> explore page boolean filter was not working for presto db even after the pr #14567. #10098 is_true filter is_true false manual and ci includes db migration (follow approval process in sip-59) </desc> <cmt> front end update - modify operators, to have sql operation and display value </cmt> <cmt> conflict resolution </cmt>",explore page boolean filter is broken for presto db
4325,<desc> i tried to include open recent in this but it makes sense to tackle that separately since history is maintained on the main side right now. perhaps we should have a renderer-side history service with 2 implementations and split that part out from iwindowservice? supersedes #75306 </desc> <cmt> open folders and workspaces in new windows </cmt> <cmt> basic file opening via open file command </cmt> <cmt> respect openfoldersinnewwindow setting for folders/workspaces </cmt> <cmt> make openwindow function resolve at right time </cmt> <cmt> move workspace menu and action to fileactions.contribution </cmt>,"support opening folder, workspace and file via commands in web"
4326,"<desc> on master the global configuration flag would not be passed joblib jobs with a multiprocess backend: from joblib import parallel, delayed from sklearn import get_config, config_context def get_working_memory(): return get_config()['working_memory'] with config_context(working_memory=123): results = parallel(n_jobs=2)( delayed(get_working_memory)() for _ in range(2) results # [1024, 1024] xref: joblib/joblib#1071 </desc> <cmt> wip </cmt> <cmt> bug passes context to joblib jobs </cmt> <cmt> bug fix </cmt> <cmt> bug fix </cmt>",bug passes global configuration when spawning joblib jobs
4327,"<desc> description: fixed all occurrences in the source code comments from ""geo location"" to ""geolocation"", as well as in the default group name of the component; as discussed in home-assistant/architecture#42 (comment) left filenames and source code unchanged. related issue (if applicable): n/a pull request in home-assistant.io with documentation (if applicable): n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> fixed geolocation naming in comments </cmt> <cmt> fixed geolocation naming in default group name </cmt> <cmt> fixed link to documentation (after </cmt>",geo location -> geolocation (comments and default group name)
4328,<desc> this is intended to be a stop-gap measure until we can refactor the flutter tool to fully support fuchsia. </desc> <cmt> add override for frontend server snapshot location for fuchsia reload </cmt> <cmt> fix formatting issues </cmt> <cmt> update artifacts.dart </cmt>,add override frontend_server snapshot for fuchsia_reload command
4329,"<desc> requests to druid for datasource metadata are now issued in parallel some sqla tweaks here and there added an option to scan druid only for new tables, instead of refreshing everything </desc> <cmt> parallelized refresh druid metadata </cmt> <cmt> fixed code style errors </cmt> <cmt> fixed code for python3 </cmt> <cmt> added option to only scan for new druid datasources </cmt> <cmt> increased code coverage </cmt>",druid refresh metadata performance improvements
4330,"<desc> if the cmake option zstd_programs_link_shared is set to true, the zstd programs are linked dynamically instead of statically. resolves #1854 </desc> <cmt> introduce zstd_programs_link_shared </cmt> <cmt> the cmake variable zstd_programs_link_shared indicactes wether or not to link the zstd programs dynamically or statically. </cmt> <cmt> consider zstd_programs_link_shared </cmt> <cmt> actually consider zstd_programs_link_shared in programs cmakelists </cmt> <cmt> fixed check for building programs statically </cmt> <iss> build zstd program against zstd shared lib </iss>",add cmake flag for linking programs dynamically
4331,"<desc> there's still some problem in our gce benchmarks. making this change to isolate things better. this will help in getting perf stats per benchmark also, which will make optimization efforts easier. </desc> <cmt> run qps workers just for the scenario that we want, to avoid interference </cmt> <cmt> missed import </cmt> <cmt> fix typo </cmt> <cmt> fix typo </cmt> <cmt> fix more things </cmt>",shutdown & restart qps workers between benchmark runs
4332,"<desc> mostly a fix for #6543, but some other stuff too. also, some simple sd-bus tweaks i noticed while debugging this (better debug logs + removals of unsued stuff) </desc> <cmt> sd-bus: when showing brief message info show error name in debug out put too </cmt> <cmt> when debug logging is enabled we show brief information about every bus </cmt> <cmt> message we send or receieve. pretty much all information is shown, </cmt> <cmt> except for the error name if a message is an error (interestingly we do </cmt> <cmt> print the error text however). fix that, and add the error name as well. </cmt> <cmt> sd-bus: drop match cookie concept </cmt> <cmt> the match cookie was used by kdbus to identify matches we install </cmt> <cmt> uniquely. but given that kdbus is gone, the cookie serves no process </cmt> <cmt> anymore, let's kill it. </cmt> <cmt> sd-bus: drop bloom fields </cmt> <cmt> these fields are unused since kdbus support has been removed. </cmt> <cmt> resolved: when there is no gateway, make sure _gateway results in nxdomain </cmt> <cmt> let's ensure that ""no gateway"" translates to ""no domain"", instead of an </cmt> <cmt> empty reply. this is in line with what nss-myhostname does in the same </cmt> <cmt> case, hence let's unify behaviour here of nss-myhostname and resolved. </cmt> <cmt> resolved: make sure a non-existing ptr record never gets mangled into nodata </cmt> <cmt> previously, if a ptr query is seen for a non-existing record, we'd </cmt> <cmt> generate an empty response (but not nxdomain or so). fix that. if we </cmt> <cmt> have no data about an ip address, then let's say so, so that the </cmt> <cmt> original error is returned, instead of anything synthesized. </cmt> <cmt> fixes: #6543 </cmt> <cmt> resolved: synthesize records for the full local hostname, too </cmt> <cmt> this was forgotten, let's add it too, so that the llmnr, mdns and full </cmt> <cmt> hostname rrs are all synthesized if needed. </cmt>",some dns rr synthesizing fixes
4333,"<desc> change our fork of hiddenfieldcheck rule to allow it to ignore shadowed variables for methods shorter than a configured minimim line count. while this technically defeats the point of the rule, in practice short methods are easier to verify by eye, compared to longer methods where accidentally referencing the wrong variable is harder to spot. following this, revert some changes in the eql code which were required to pass the hiddenfield check before the minlinecount change. additionally, introduce a mechanism for ignoring shadowed variables when used created a new object. this allowed us to ignore variables in usages of e.g. constructingobjectparser whose purpose, as the name suggests, is to build objects, and object shadows variables in the course of building objects. </desc> <cmt> revert sql shadowed var changes </cmt> <cmt> add minlinecount to hiddenfieldcheck </cmt> <cmt> allow the hiddenfieldcheck rule to ignore shadowed variables for methods </cmt> <cmt> shorter than a configured minimim line count. while this technically </cmt> <cmt> defeats the point of the rule, in practice short methods are easier to </cmt> <cmt> verify by eye, comparing to longer methods where accidentally </cmt> <cmt> referencing the wrong variable will be harder to spot. </cmt> <cmt> additionally, introduce a mechanism for ignoring shadowed variables when </cmt> <cmt> used created a new object. this allowed us to ignored variables in </cmt> <cmt> usages of e.g. constructingobjectparser whose purpose, as the name </cmt> <cmt> suggests, is to build objects, and object shadows variables in the </cmt> <cmt> course of building objects. </cmt>",revert some eql shadowed var changes and improve hiddenfield rule
4334,<desc> addresses #1840. probably best to go through the commits. </desc> <cmt> explicitly specify es6 target in computed property test file names. </cmt> <cmt> added es5 tests for computed properties. </cmt> <cmt> stop erroring on computed properties for es3/es5 emit. </cmt> <cmt> emit computed properties in es3/es5 properly. </cmt> <cmt> add newline before closing paren in multiline object literals. </cmt>,es3/es5 emit support for computed properties
4335,"<desc> following problems i had today with publishing - this should hopefully prevent some of it lerna@3.0.0 added verification if currently logged npm user have publish rights to packages we are about to publish before starting publishing i've also updated add-npm-owner script to lerna 3 and to be a little smarter - it would only add user to packages that user don't have yet publish rights - we have 89 packages so it could take some time running it for all packages. there is room for automation - like running that script in monorepo postpublish, but i figured that's not worth spending time on now after lerna update and verification it provides </desc> <cmt> update to lerna 3 stable </cmt> <cmt> update add-npm-owner script for lerna3 </cmt>",update lerna to v3 stable
4336,<desc> #789 </desc> <cmt> remove tcc chinese comments </cmt> <cmt> maven plugin for release </cmt> <cmt> fix the decode method bug of abstractbranchendresponse </cmt> <cmt> fix the decode method bug of abstractbranchendresponse </cmt> <cmt> # conflicts: </cmt> <cmt> #	core/src/main/java/io/seata/core/protocol/transaction/abstractbranchendresponse.java </cmt> <cmt> #	core/src/test/java/io/seata/core/message/branchcommitresponsetest.java </cmt> <cmt> modify the default nacos config </cmt>,modify the default nacos config file
4337,<desc> reduces checkstyle errors for patterns: facade factory-kit spatial-partition state step-builder changes involved java docs reordering imports indentations line length issues </desc> <cmt> reduces checkstyle errors in facade </cmt> <cmt> reduces checkstyle errors in factory-kit </cmt> <cmt> reduces checkstyle errors in spatial-partition </cmt> <cmt> reduces checkstyle errors in state </cmt> <cmt> reduces checkstyle errors in step-builder </cmt>,resolves checkstyle errors for facade factory-kit spatial-partition state step-builder
4338,"<desc> this change merged the following changes from 1.12 to 1.13: flink-21933 gracefully handle interrupted exceptions in kinesis efo source consumer #15347 flink-21661 kinesis polling consumer does not respect the shard_getrecords_interval_millis configuration. this means consumer will poll kinesis without any delay, resulting in throttle. this bug was introduced with flink-18512 #15157 see related pr descriptions: #15347 #15157 see related pr descriptions: #15347 #15157 dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): yes anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? no </desc> <cmt> [flink-21661][kinesis] fix fetch interval for polling consumer (#15157) </cmt> <cmt> [flink-21933][kinesis] efo consumer treats interrupts as retryable exceptions (#15347) </cmt>",merge kinesis bug fixes from 1.12.
4339,"<desc> more progress on the userspace all the things long term goal. </desc> <cmt> kernel: use userspace<t> for the sendto syscall, and socket implementation </cmt> <cmt> note that the data member is of type immutablebufferargument, which has </cmt> <cmt> no userspace<t> usage. i left it alone for now, to be fixed in a future </cmt> <cmt> change holistically for all usages. </cmt> <cmt> kernel: use userspace<t> for the recvfrom syscall, and socket implementation </cmt> <cmt> this fixes a bunch of unchecked kernel reads and writes, seems like they </cmt> <cmt> would might exploitable :). write of sockaddr_in size to any address you </cmt> <cmt> please... </cmt>",use userspace<t> for the sendto + recvfrom syscalls
4340,"<desc> collection.insertone and insertmany was missed to check with his schema. collection.update on the update field has a new definition. this pr adds missing types definitions and test. </desc> <cmt> schema definition on insertone, insertmany and update definitions. added types as optionaltschema and updatequery. </cmt> <cmt> added user on definitions by </cmt> <cmt> added missing properties and url docs </cmt> <cmt> added missing properties and url docs with test </cmt> <cmt> added missing properties and url docs with test </cmt>",checked tschema on insert and update documents
4341,"<desc> this pr adds a mixin class that f1 and other metrics like precision and recall can leverage in the future. it also provides a new option for the f1 metric called average which defines how the metric will be aggregated across mini batches. passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change approach the ""micro"" vs ""macro"" update strategy is not specific to f1 score. the macro update just takes an average of averages, which can be done for any metric. it may be best to design an abstraction where any metric can have the micro/macro update option, but i couldn't see a good way to do that here that would: be easy to use for end users and maintain backward compatibility and maintain current semantics for now, the behavior for each type of update is hard coded into the update method of the f1 class. we can discuss the approach. please let me know if i have missed or overlooked anything :) </desc> <cmt> add macro/micro f1 and test and binary abstraction </cmt> <cmt> make average an option </cmt> <cmt> use metric.create </cmt>",add micro averaging strategy for f1 metric
4342,"<desc> this is related to #22116. a number of plugins (discovery-azure-classic, discovery-ec2, discovery-gce, repository-azure, repository-gcs, and repository-s3) open socket connections. as socketpermissions are transitioned out of core, these plugins will require connect permission. this pull request wraps operations that require these permissions in doprivileged blocks. </desc> <cmt> add socketaccess files for plugins </cmt> <cmt> add doprivileged blocks to plugins </cmt> <cmt> clean up privilege blocks in gce discovery plugin </cmt>",add doprivilege blocks for socket connect operations in plugins
4343,"<desc> just some small fixes and cleanups udev is required when using gbm, this is because of the libinput input handling. fix for coverity >>>     cid 1477402:  uninitialized members  (uninit_ctor) >>>     non-static class member ""m_abort"" is not initialized in this constructor nor in any functions that it calls. the window system is used through many different methods, let's just make it a member organize the override methods remove the xbmc prefix from the include header. </desc> <cmt> [cmake] gbm: require udev </cmt> <cmt> cvideosyncgbm: use std::atomic<bool> </cmt> <cmt> cvideosyncgbm: get winsystem in the constructor </cmt> <cmt> cvideosyncgbm: organize and label override methods </cmt> <cmt> cvideosyncgbm: fix header include </cmt>",a couple small gbm fixes
4344,"<desc> this cost me many hours of debugging when my network failed to converge when applying build_image_data.py to a new dataset. turns out i didn't read the build_image_data.py comments carefully and missed the part about the background class being labeled 0. the one_hot_encoding in train_image_classifier does not take into account of out-of-range inputs. therefore in my 3 classes dataset, my labels of [3 2 2 1] are converted to these one hot labels: the nn will always classify class 3 as 'wrong'. i fixed this by changing label_index to 0 so my classes will now numerate [0,2]. (alternatively can add tf.subtract(labels, 1)). additionally, i think that the background class is unnecessary since the script is referred to quite often in the readme as a general data converter to tfrecords. the background class seems to be a relic of the imagenet dataset that does not generalize well to other types of data. in any case, i hope this addition will emphasize this nuance to future readme readers. fix shell script to match example. </desc> <cmt> update warning on extra background class added by build_image_data.py </cmt> <cmt> fix script to match example </cmt> <cmt> delete extra line </cmt>",readme.md warning on extra background class added by build_image_data.py
4345,"<desc> the below will replicate the old behavior where methodnotallowed preceded the authentication check: class djangomodelpermissions(permissions.djangomodelpermissions): def has_permission(self, request, view): if request.method not in self.perms_map: raise exceptions.methodnotallowed(request.method) return super().has_permission(request, view) this is an updated version of #5367 that includes a regression test. note: this does slightly change the behavior for when the request has no authentication. previously, if a user made an unauthenticated request, they would receive a 405. with the pr, users would receive the 401 first, then 405 once authenticated. i'd argue that the change is more correct, given the general ordering of authentication, authorization, then method allowed checks. either way, the old behavior can be replicated by moving the 405 check out of get_required_permissions() and into has_permission() before the request.user check. </desc> <cmt> fix authorization few perms tests </cmt> <cmt> add failing test for #5367 </cmt> <cmt> + rejecting anonymous in djangomodelpermissions *before* the .get_queryset call </cmt>",djangomodelpermissions should perform auth check before accessing the view's queryset
4346,"<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. </desc> <cmt> add files </cmt> <cmt> added all types from pkijs-es6 </cmt> <cmt> update </cmt> <cmt> - added pkijs test </cmt> <cmt> - created asn1js </cmt> <cmt> - created pvutils </cmt> <cmt> - fixed type errors </cmt> <cmt> update asn1js typings </cmt> <cmt> update pvutils test </cmt> <cmt> remove pkibase </cmt> <cmt> added common modules x509, cms, ocsp </cmt> <cmt> fix typings errors </cmt> <cmt> add comments </cmt>","add typings for pkijs, asn1js and pvutils"
4347,"<desc> this pr adds two new parameters to the scaleupdatedetails class which track the vertical and horizontal scale of a scale gesture. this is useful if you are creating a widget that should only respond to scales along an axis, i.e. if you are creating a calendar whose days can be made wider by horizontal scaling motions. my ide is set to auto-run dartfmt, so i included those changes. is there a reason the file wasn't already formatted? i can revert those changes if unwanted. </desc> <cmt> dartfmt </cmt> <cmt> added parameters </cmt> <cmt> added parameters </cmt> <cmt> scale computation </cmt> <cmt> added test </cmt> <cmt> added docs </cmt>",adding horizontal and vertical scale parameter to scaleupdatedetails.
4348,"<desc> with this pull request it is now possible to turn debug options on using cmake: $ cd build $ cmake .. -dfoo_debug=on alternatively, debug options can be enabled locally in a single source file by overwriting the macro: #undef foo_debug #define foo_debug 1 that obviously brings the caveat of macros only affecting the current compilation unit, and thus might not work in all cases because some sources rely on debug macros to be defined in other files as well (regexdebug.h is one such example.) there are still a few rough edges, i will address a few of them, others will gradually disappear over time: some macros don't have very meaningful names like spam_debug or lexer_debug. changing if a debug macro is enabled or not requires rebuilding a ton of files, because ak/debug.h is included in so many places. this can ""easily"" be changed by dividing the macros into multiple categories like ak/debug.h, kernel/debug.h and userland/debug.h. </desc> <cmt> everywhere: use cmake to generate ak/debug.h. </cmt> <cmt> this was done with the help of several scripts, i dump them here to </cmt> <cmt> easily find them later: </cmt> <cmt> awk '/#ifdef/ { print ""#cmakedefine01 ""$2 }' ak/debug.h.in </cmt> <cmt> for debug_macro in $(awk '/#ifdef/ { print $2 }' ak/debug.h.in) </cmt> <cmt> do </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec sed -i -e 's/#ifdef '$debug_macro'/#if '$debug_macro'/' {} \; </cmt> <cmt> done </cmt> <cmt> # remember to remove wrapper_gernerator_debug from the list. </cmt> <cmt> awk '/#cmake/ { print ""set(""$2"" on)"" }' ak/debug.h.in </cmt> <cmt> everywhere: remove unnecessary debug comments. </cmt> <cmt> it would be tempting to uncomment these statements, but that won't work </cmt> <cmt> with the new changes. </cmt> <cmt> this was done with the following commands: </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec awk -i inplace '$0 !~ /\/\/#define/ { if (!toggle) { print; } else { toggle = !toggle } } ; $0 ~/\/\/#define/ { toggle = 1 }' {} \; </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec awk -i inplace '$0 !~ /\/\/ #define/ { if (!toggle) { print; } else { toggle = !toggle } } ; $0 ~/\/\/ #define/ { toggle = 1 }' {} \; </cmt> <cmt> everywhere: name debug macros more consistently. </cmt> <cmt> personally, i prefer the naming convention debug_foo over foo_debug, but </cmt> <cmt> the majority of the debug macros are already named in the latter naming </cmt> <cmt> convention, so i just enforce consistency here. </cmt> <cmt> this was done with the following script: </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec sed -i -e 's/debug_path/path_debug/' {} \; </cmt> <cmt> everywhere: debug macros instead of constexpr. </cmt> <cmt> this was done with the following script: </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec sed -i -e 's/dbgln<debug_([a-z_]+)>/dbgln<\u\1_debug>/' {} \; </cmt> <cmt> find . \( -name '*.cpp' -o -name '*.h' -o -name '*.in' \) -not -path './toolchain/*' -not -path './build/*' -exec sed -i -e 's/if constexpr \(debug_([a-z0-9_]+)/if constexpr \(\u\1_debug/' {} \; </cmt> <cmt> meta: make check-debug-flags.sh work with the new changes. </cmt> <cmt> everywhere: hook up remaining debug macros to debug.h. </cmt>",hook up the debug macros with cmake.
4349,"<desc> fixed #1015. @guolinke to be honest, i haven't checked other places where default stratified=true could be used for non-classifying tasks. you could merge it as a hotfix and i later open a new pr if found such places. upd: i haven't found other occurrences. </desc> <cmt> update test_engine.py </cmt> <cmt> update test_engine.py </cmt> <iss> new scikit-learn release breaks tests </iss>",fixed stratifiedkfold for non-classifying tasks
4350,"<desc> this is meant to fail when qmk lint fails. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> properly set the exit_code </cmt> <cmt> handle the case where exit_code is greater than 255 </cmt>",improve the qmk lint workflow
4351,"<desc> collect together two cleanups: eliminate archetypetype::nestedtype, because the distinction between a nested archetype and a nested concrete type is no longer a difference that matters. eliminate one of the ""passes"" in validation of the generic environment, so we're down to 3. </desc> <cmt> [ast] eliminate archetypetype::nestedtype. </cmt> <cmt> now that we no longer distinguish outer archetypes from inner </cmt> <cmt> archetypes, we can replace nestedtype with just type. </cmt> <cmt> [type checker] eliminate one ""pass"" in generic environment validation. </cmt> <cmt> we no longer need a separate ""pass"" that creates an archetype builder </cmt> <cmt> that inherits context archetypes, because we no longer ever inherit </cmt> <cmt> context archetypes. </cmt>",cleanups now that we no longer reuse context archetypes in nested generics
4352,"<desc> npm supports referencing hosted github dependencies in the format github:user/repo#semver:^1.6.0. this is currently not supported by yarn as it resolves the hash into #semver/^1.6.0. note the added / instead of the :. thus, yarn outputs the error: ""couldn't find match for ""semver/^1.6.0"" in ...."" motivation given an empty yarn package: // package.json { ""name"": ""tjosan"", ""version"": ""1.0.0"", ""main"": ""index.js"", ""license"": ""mit"", ""dependencies"": { ""yarn"": ""github:yarnpkg/yarn#semver:^1.6.0"" } } when running yarn: yarn it errors with: error couldn't find match for ""semver/^1.6.0"" in .... whereas npm resolved the dependency without errors. given an empty yarn package: // package.json { ""name"": ""tjosan"", ""version"": ""1.0.0"", ""main"": ""index.js"", ""license"": ""mit"", ""dependencies"": { ""yarn"": ""github:yarnpkg/yarn#semver:^1.6.0"" } } when running yarn: yarn it should resolve the dependencies: yarn install v1.6.0 success saved lockfile. done in x.xxs. </desc> <cmt> support for #semver: in hosted git resolver </cmt> <cmt> fix formatting </cmt>",support for semver hash in hosted git dependency
4353,"<desc> in #5276 tests for the strtobool function were introduced. one test checks the error message on strings that can't be converted unambiguously to a boolean value, in the test case it's ""foo"". the asserted error message is: cannot coerce 'foo' to type bool however, in python 2 the error message is cannot coerce u'foo' to type bool this pr should fix the tests for the python 2.7 configurations i changed the assertion to not raise if there is a u in front of the actual string. because as far as i understood python 2 support is deprecated, i also added a comment as a reminder to replace the line by it's original one when this happens. </desc> <cmt> replace assertion to not raise on a leading u </cmt> <cmt> more specific regex </cmt>",fix strtobool conversion tests on python 2
4354,"<desc> fix a bug in iob_to_biluo function in case of labels with a 'b' character and modify _consume_ent for cli.converter to handle tags already in biluo format. #2385 if tags in biluo format are passed to the cli converter, the l-flag goes unprocessed and n-word tokens are read as (n-1)-word tokens. this is because the cli iob and ner 2json converters both presuppose that ner tags are passed in iob1/2 format and convert them to biluo in gold.iob_to_biluo. this may not always be the case - especially the conll_ner2json converter is not self-evident to accept specifically iob format. what is more, the currently suggested workflow of preparing the dataset for the isolated ner pipeline component is to convert any offset ner tags into biluo using biluo_tags_from_offsets, write a script converting the docs into .iob or .conll format and then use the cli converter on the biluo-tagged docs to obtain the json file accepted by cli train. this shows that a general-purpose writer that will also convert offset tags straight into json would be handy. before it's ready i have modified the iob_to_biluo function to accept both iob and biluo formats. in the process i have also fixed a bug that would corrupt labels with a 'b' character due to the str.replace('b', 'i') method. bug fix </desc> <cmt> issue_2385 add tests for iob_to_biluo converter function </cmt> <cmt> issue_2385 fix and modify iob_to_biluo function to accept either iob or biluo tags in cli.converter </cmt> <cmt> issue_2385 add test to fix b char bug </cmt> <cmt> add contributor agreement </cmt> <cmt> fill contributor agreement </cmt>",fix bug in cli iob and ner converter
4355,"<desc> updates cypress to latest version (5.5.0) due to patched performance issues in 5.2.0. improvements for running cypress locally, including: fix oom crashing of headed chrome test runs (via numtestskeptinmemory) update docs and build script to use chrome as cypress browser correct documentation on manual cypress runs tox: add missing cypress testenv tox: cleanup orphaned background flask processes also reduces the number of retries globally from 2 to 1 to reduce time spent on failed runs. test plan see updated contributing.md documentation. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> reduce numtestskeptinmemory to 0 to prevent chrome oom crash </cmt> <cmt> add cypress-run-chrome script, update docs and cypress_build.sh </cmt> <cmt> upgrade cypress to latest version </cmt> <cmt> tox: add missing 'cypress' env, cleanup flask server </cmt>","update cypress to 5.5.0, improvements for running locally"
4356,<desc> fixes #1301 . -retrieve database names from memory when using show databases -dcl broadcast to database instance -set syntax broadcast to database instance </desc> <cmt> update from origin </cmt> <cmt> update from origin </cmt> <cmt> update from origin </cmt> <cmt> retrieve database names from memory when using show databases </cmt> <cmt> add schema broadcast backend handler </cmt> <cmt> add schema ignore backend handler </cmt> <cmt> add schema unicast backend handler </cmt> <cmt> for checkstyle </cmt> <cmt> remove unused code </cmt>,the enhancement for multiple schema
4357,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> feat: add typings for feflow </cmt> <cmt> feat: update comment </cmt> <cmt> feat: fix new line warn </cmt>",feature/add typings for feflow cli
4358,"<desc> github complained the about section is too long (maximum is 200 characters). related issues #63105 </desc> <cmt> add a infra issue template, especially for the ticket queue. </cmt> <cmt> bug: </cmt> <cmt> mention ci. </cmt> <cmt> limit about sections to <200 chars in the infra issue template. </cmt>",limit about to <200 chars in the infra issue template
4359,"<desc> three weakly related fixes to number handling after the univalue switch. these came to the surface while troubleshooting #6443. make valuefromamount always return 8 decimals this is the format that was always returned to json clients. the difference was not noticed before, because vreal values are post-processed by univalue. by implementing the functionality directly it breaks the dependency of rpcserver on utilmoneystr. formatmoney is now only used for debugging purposes. to test, port over the formatting tests from util_tests.cpp to rpc_tests.cpp. univalue: avoid unnecessary roundtrip through double for numbers json makes no distinction between numbers and reals, and our code doesn't need to do so either. this removes vreal, as well as its specific post-processing in univalue::write. non-monetary amounts do not need to be forcibly formatted with 8 decimals, so the extra roundtrip was unnecessary (and potentially loses precision). util: use locale-independent parsing in parsedouble use locale-indepent c++ based parsing instead of c's strtod, which checks for different input based on the user's locale. fixes #6443. </desc> <cmt> rpc: make valuefromamount always return 8 decimals </cmt> <cmt> this is the format that was always returned to json clients. </cmt> <cmt> the difference was not noticed before, because vreal values </cmt> <cmt> are post-processed by univalue. </cmt> <cmt> by implementing the functionality directly it breaks the dependency </cmt> <cmt> of rpcserver on utilmoneystr. formatmoney is now only used for debugging </cmt> <cmt> purposes. </cmt> <cmt> to test, port over the formatting tests from util_tests.cpp to </cmt> <cmt> rpc_tests.cpp. </cmt> <cmt> univalue: avoid unnecessary roundtrip through double for numbers </cmt> <cmt> json makes no distinction between numbers and reals, and our code </cmt> <cmt> doesn't need to do so either. </cmt> <cmt> this removes vreal, as well as its specific post-processing in </cmt> <cmt> univalue::write. non-monetary amounts do not need to be forcibly </cmt> <cmt> formatted with 8 decimals, so the extra roundtrip was unnecessary </cmt> <cmt> (and potentially loses precision). </cmt> <cmt> util: use locale-independent parsing in parsedouble </cmt> <cmt> use locale-indepent c++ based parsing instead of c's strtod, </cmt> <cmt> which checks for different input based on the user's locale. </cmt> <cmt> fixes #6443. </cmt> <iss> parsedouble() is faulty, depending on locale </iss>","avoid unnecessary parsing roundtrip in number formatting, fix locale issue"
4360,"<desc> explanation: when we create an unstructured task we must copy all task values values to the new task. when a task has a parent task, it's task locals list begins with a pointer to the parent's task locals. when copying values to an unstructured task we did not account for the ""parent pointer"" type of task local item, which leads to attempts to copy null valuetypes which is illegal. in any case, copying a parent pointer even if it worked is specifically against what we should be doing here -- a deep copy. solution: don't copy parent pointers. reviewer: @drexin @douggregor radar/sr issue: rdar://80032684 risk: small. testing: pr testing and ci on main. original pr: #38218 </desc> <cmt> [concurrency] task local must not copy null values </cmt> <cmt> [concurrency] add tasklocal::item:iisparentpointer for cleaner api </cmt>","[5.5][concurrency] unstructured tasks must not attempt to copy ""parent (task local) pointers"""
4361,"<desc> i've made 2 small changes, so that the code reflects the use of the immutable data. the immutable data means we can compare by object identity instead of id. </desc> <cmt> use object identity to compare (immutable data) </cmt> <cmt> compare object identity is sufficient </cmt>",compare through object identity instead of id
4362,"<desc> adding a keymap for the planck keyboard. the layout has a focus around coding, utilising the home row for symbols. there is an additional fn layer and space function layer. n/a my code follows the code style of this project. i have read the contributing document. </desc> <cmt> version 1 of keymappings </cmt> <cmt> adding updated keymappings </cmt> <cmt> adding hash/pound symbol to layer </cmt> <cmt> removing broken macros </cmt> <cmt> adding to readme. amending value of pound sign </cmt> <cmt> changing language in readme </cmt>",custom planck layout for the planck
4363,"<desc> adding a reference guide for working with square to help shore up the e-commerce documentation. i've gone back and forth on this a bit, trying to decide how far to take it. having gone through the square documentation, it seems to me like the existing plugin doesn't correctly place the required reference to square's library. i feel like it's probably worth creating a starter to make this easier for people but also that something like that goes beyond what i set out to do in this pr. i've opened an issue for creating a square starter. in the meantime, the goal of this pr is to give people a starting point. folks should have an idea of the capabilities of square, be able to hook up an app, and get a nonce (token) back when submitting the payment form. i'd love feedback on where screenshots might be most helpful! fixes #20224 addresses #19768 </desc> <cmt> draft square guide </cmt> <cmt> add square guide </cmt> <cmt> tweak square notes </cmt> <iss> [docs][guides] new guide on working with square </iss>",add reference guide for processing payments with square
4364,"<desc> please check if the pr fulfills these requirements the commit message follows our guidelines:  what kind of change does this pr introduce? (check one with ""x"") what is the current behavior? (you can also link to an open issue here) testcomponentbuilder and asynctestcompleter are deprecated. got rid of them. does this pr introduce a breaking change? (check one with ""x"") if this pr contains a breaking change, please describe the impact and migration path for existing applications: ... other information: </desc> <cmt> converted first module. </cmt> <cmt> finish ng_class_spec </cmt> <cmt> working through ng_for_spec. </cmt>",remove uses of deprecated testcomponentbuilder.
4365,"<desc> implement the upcoming third revision of the property wrappers proposal, which includes the following changes: the private backing storage property is always named with a leading underscore, e.g., _foo. wrappervalue is renamed to projectedvalue when projectedvalue is present, the projection property is created (named $foo) at the same access level as the original property declaration. addresses rdar://problem/52140207 </desc> <cmt> [se-0258] rename backing storage property to _foo. </cmt> <cmt> in anticipation of upcoming changes to the property wrapper proposal, </cmt> <cmt> rename the backing storage for a wrapped property to ""foo"", unconditionally. </cmt> <cmt> (cherry picked from commit 446d0b39533aa776df9c4a28cfe45462d9456eb1) </cmt> <cmt> [se-0258] promote projection variables ($foo) to the original property access </cmt> <cmt> when the outermost property wrapper associated with a property has a </cmt> <cmt> wrappervalue, create the projection property (with the $ prefix) </cmt> <cmt> at the same access level as the original property. this puts the </cmt> <cmt> wrapped-value interface and the projection interface at the same level. </cmt> <cmt> the newly-introduced @_projectionvalueproperty attribute is implicitly </cmt> <cmt> created to establish the link between the original property and the </cmt> <cmt> projection value within module interfaces, where both properties will </cmt> <cmt> be explicitly written out. </cmt> <cmt> (cherry picked from commit 7bb01c743ba269ec22ffda855db84e1a7d763fe3) </cmt> <cmt> [se-0258] rename wrappervalue to projectedvalue. </cmt> <cmt> (cherry picked from commit db5440bdefb239d73a9b9199b2353e9e615c5051) </cmt>",implement revision #3 of property wrappers
4366,"<desc> i edited several files to increase compliance with pylint, pep8, etc. </desc> <cmt> improved formatting of basic_maths.py </cmt> <cmt> - added docstrings. </cmt> <cmt> - improved whitespace formatting. </cmt> <cmt> - renamed functions to match snake_case. </cmt> <cmt> improved formatting of factorial_python.py </cmt> <cmt> - added docstrings. </cmt> <cmt> - improved whitespace formatting. </cmt> <cmt> - renamed constants to match upper_case. </cmt> <cmt> improved formatting of factorial_recursive.py </cmt> <cmt> - improved whitespace formatting to meet pylint standards. </cmt> <cmt> improved code to conform to pylint </cmt> <cmt> - renamed max to max_num to avoid redefining built-in 'max' [pylint] </cmt> <cmt> - removed unnecessary parens after 'while' keyword [pylint] </cmt> <cmt> improved formatting of factorial_recursive.py </cmt> <cmt> - added docstrings. </cmt> <cmt> - improved whitespace formatting. </cmt>",improve formatting and code quality
4367,"<desc> while working on #40417, i got frustrated with the behavior of x.py and the bootstrap binary it wraps, so i decided to do something about it.  this pr should improve documentation, make the command-line-parsing more flexible, and clean up some of the internals.  no command that worked before should stop working.  at least that's the theory. :-) this should resolve at least #40920 and #38373. changes: no more manual args manipulation -- getopts used everywhere except the one place it's not possible.  as a result, options can be in any position, now, even before the subcommand. the additional options for test, bench, and dist now appear in the help output. no more single-letter variable bindings used internally for large scopes. don't output the time measurement when just invoking x.py or explicitly passing -h or --help logic is now much more linear.  we build strings up, and then print them. refer to subcommands as subcommands everywhere (some places we were saying ""command"") other minor stuff. @alexcrichton this is my first pr. do i need to do something specific to request reviewers or anything? </desc> <cmt> refer to a subcommand as a subcommand. </cmt> <cmt> for some reason 'command' and 'subcommand' were intermixed to mean the same thing.  lets just call it the one thing that it is. </cmt> <cmt> when dealing with the list of all possible subcommands, deal with them in the same order to ease comparing the sections of code in order.  i chose the order that appears in the help text, because that is most likely to have been ordered with specific reasoning. </cmt> <cmt> don't print build statistics if we explicitly asked for the help message. </cmt>",overhaul bootstrap (x.py) command-line-parsing & help output
4368,"<desc> using the global wait_until makes it impossible to adjust the timeout based on the hardware the test is running on. fix that by using the mininode member function. so for example, ./test/functional/p2p_getdata.py  --timeout-factor=0.04 gives a timeout of 2.4 seconds. </desc> <cmt> test: pep-8 p2p_getdata.py </cmt> <cmt> test: default mininode.wait_until timeout to 60s </cmt>",remove global wait_until from p2p_getdata
4369,"<desc> add some docs. @apeforest @muhyun please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> update perf.md </cmt> <cmt> update readme.md </cmt>",add a few tips for running horovod
4370,<desc> centralize all logging logic in one place. fixed #3805. related #3156. </desc> <cmt> centralize python-package logging in one place </cmt> <cmt> fixed conflicts </cmt> <cmt> continue </cmt> <cmt> fix test name </cmt> <cmt> removed unused import </cmt> <cmt> enhance test </cmt> <iss> logging to python log </iss>,allow to register custom logger in python-package
4371,"<desc> add option to auto_install account_invoice_ocr. add demodata in account with only an attachment to test the ocr module </desc> <cmt> [imp] account: add option to install account_invoice_extract </cmt> <cmt> as account_invoice_extract is now in auto_install=true, we should show a default option in account to install or uninstall the module. </cmt> <cmt> [imp] l10n_generic_coa : adding demodata for ocrempty invoice with an attachment in order to demonstrate ocr feature </cmt>",master account invoice extract fda
4372,"<desc> most of the kernel functions use nearly identical parameter lists. essentially, there are four parameters that vary. this means that the function declarations can be hidden behind a few simple macros with up to two parameters. unify kernel function parameter names add macros for kernel function declarations substitute long parameter lists in ~2900 kernel function declarations with macros. </desc> <cmt> unify kernel function parameter names </cmt> <cmt> in preparation for the abstraction of long repetitive kernel function </cmt> <cmt> declarations, adjust parameter names in a few deviating kernels. </cmt> <cmt> unify esalt_bufs parameter declarations </cmt> <cmt> in preparation for the abstraction of long repetitive kernel function </cmt> <cmt> declarations, rename the salt buffer pointers to *esalt_bufs. also </cmt> <cmt> declare them const where they are not. </cmt>",replace kernel parameter lists with macros
4373,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). v2.3.0 release notes:  primary pull request for v2.3.0:  v2.4.0 release notes:  primary pull request for v2.4.0: paullecam/react-leaflet#593 if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. should be noted that the changes made in v2.3.0 (the useleaflet hook) could be tested better most likely, however i personally cannot figure out how to actually use it, and it's not being covered by any documentation or test code in the library itself. on top of that the fact that as far as i can tell you cannot even really use a functional component because you'd want to extend react-leaflet's type of mapcomponent at the least, which extends mapevented which in turn extends react.component, and not react.functioncomponent. that all said, if the library makes it properly clear how to use the useleaflet hook then by all means we can add it to the typings test but until then alas... unless someone has a genius idea. </desc> <cmt> cover v2.4.0 changes </cmt> <cmt> this adds 2 additional properties to the map component which can be seen </cmt> <cmt> being documented in [this pr]( </cmt> <cmt> the release notes for v2.4.0 can be viewed [here]( </cmt> <cmt> cover v.2.3.0 </cmt> <cmt> v2.3.0 added a react hook. this pr covers the function as well as adding </cmt> <cmt> a test that should test the hook. </cmt> <cmt> - v2.3.0 release notes: </cmt> <cmt> - primary pull request for v2.3.0: </cmt>",upgrade to cover v2.3.0 and v2.4.0
4374,"<desc> breaking change: tesla entity_ids and unique_ids have changed. this is necessary so that multi-vehicle households have a way to distinguish vehicles by basing the name off the name in the app. users should remove old tesla entries from the entity registry after upgrade and update automations where tesla entity_ids are used. description: this pr bumps to teslajsonpy 0.0.26 which will change how entity names are formulated. this also adds an update switch to allow users to disable polling of vehicles to conserve batteries. related issue (if applicable): fixes #25809, fixes #23227 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> bump teslajsonpy to 0.0.26 </cmt> <cmt> breaking change </cmt> <cmt> add update switch to tesla </cmt> <iss> tesla compontent: the ability to schedule or turn on/of polling to reduce battery drain </iss> <iss> tesla component stopped working in v0.96.x (and v0.97.0) </iss>",bump teslajsonpy and add update switch
4375,"<desc> there have been a number of issues and questions regarding the transition from stable_baselines to ray rllib. for newcomers, it can be a bit overwhelming given the wealth of different options that rllib provides. this intentionally simple example is supposed to help with the transition from sb to rllib. sb2rllib_sb_example.py shows how to train, save, load, and test a ppo agent on the cartpole environment with stable_baselines (inspired from the sb documentation). sb2rllib_rllib_example.py shows a functionally equivalent script with rllib. closes #14429 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> added examples for transition from stable baselines to rllib </cmt> <iss> load, play, rollout a trained/saved policy (without cli rollout.py) </iss>","examples for training, saving, loading, testing an agent with sb & rllib"
4376,<desc> for #4520. </desc> <cmt> move where table segment generate to select statement </cmt> <cmt> add class predicateextractor </cmt> <cmt> move get table segments logic from generator to select statement </cmt> <cmt> move get table segments logic from generator to select statement </cmt>,move getalltables' logic from tabletokengenerator to sqlstatement
4377,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance new feature or improvement refactor configinitializer  and enhance setting which field type is map. add some test cases into snifferconfiginitializertest for map field. </desc> <cmt> refactor configinitializer </cmt> <cmt> rename some variable names and add some java docs </cmt>,refactor configinitializer and improve map type config
4378,"<desc> this change will add a user setting that will allow to optout of reporting telemetry. the product will allow a set of predefined events to pass the user optin settings. this way we can calculate the optin rates. the change include: refactor itelemetryconfiguration from maintelemetryservice to telemetry.ts add a configuration option from the electrontelemetryservice. this service will be responsible for caching the events that are reported until the user optin settings are loaded. after that, the service will flush the events. this is to prevent race conditions as some events are reported on load (auto save, workspace stats, workspace load). add a mechanism to allow for a predefined events to pass user optout settings in maintelemetryservice. tests </desc> <cmt> move telemetry service config to telemetry </cmt> <cmt> add optout configuration for telemetry </cmt> <cmt> add optinstatus event </cmt> <cmt> clean up for tslint </cmt>",adding optout option for telemetry
4379,"<desc> attach revision info when registry group by revision when subscription use sequential logic to process to process metadataservice and generalservice this pr will make the service subscription logic more stable and efficient </desc> <cmt> optimize dubbo registry </cmt> <cmt> optimize dubbo registry </cmt> <iss> no provider available from registry http::9090 for service xxx/com.alibaba.cloud.dubbo.service.dubbometadataservice:1.0.0 on consumer 192.168.50.205 use dubbo version 2.7.6, please check status of providers(disabled, not registered or in blacklist). </iss> <iss> no provider available from registry localhost:9090 for service com.xxx.xxxservice on consumer 192.168.1.100 use dubbo version 2.7.8, please check status of providers(disabled, not registered or in blacklist). </iss> <iss> [bug] dubbo spring cloud cause ""o provider available from registry"" </iss>",use revision to optimize dubbo registry
4380,"<desc> essentially, instead of diagnostics referring to the same variable throughout compileprogram, each of the let declarations created a new scoped variable, meaning that the test at the end was not picking up ""global"" and ""semantic"" errors. fixes #4095. </desc> <cmt> fix issue with exit status by ensuring the same 'diagnostics' variable is reused. </cmt> <cmt> double quotes. </cmt>",fix issue where exit code was not being appropriately returned
4381,"<desc> fixes #13875 part 8. remove snowflakekeygeneratealgorithm dependency from jobconfiguration, which is in sharding-core add getactualdatasourceconfig for shardingspherejdbcdatasourceconfiguration, prepare for datasourcepreparer refactoring add jobdatanodeline add tablesfirstdatanodes in job handleconfig, prepare for datasourcepreparer refactoring refactor fields in job handleconfig refactor datasourcepreparer, separate sharding related code from scaling-core refactor jobshardingdatanodes type in handleconfig </desc> <cmt> remove snowflakekeygeneratealgorithm dependency from jobconfiguration </cmt> <cmt> fix pipeline-spi module typo </cmt> <cmt> add comment </cmt> <cmt> remove fillinproperties in jobcontext </cmt> <cmt> add getactualdatasourceconfig </cmt> <cmt> add tablesfirstdatanodes in job handleconfig </cmt> <cmt> refactor fields in job handleconfig </cmt> <cmt> add jobdatanodeline </cmt> <cmt> update tablesfirstdatanodes format </cmt> <cmt> refactor datasourcepreparer, separate sharding related code from scaling-core </cmt> <cmt> refactor jobshardingdatanodes type in handleconfig </cmt> <cmt> unit test </cmt> <cmt> real test </cmt> <cmt> check </cmt> <iss> refactoring: scaling as part of apache shardingsphere 3 layers architecture but not an individual tool </iss>",separate sharding related code from scaling-core module part 3 and refactor job configuration structure
