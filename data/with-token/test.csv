,text,summary
0,"<desc> relative paths in tests can point directly to .d.ts files. however, those references don't reflect what users can actually write. this pr rewrites references like './index' and "".."" to the name of the package. ansi-styles had an unused reference, so i just deleted that one. </desc> <cmt> fix relative paths in tests, attempt 1 </cmt> <cmt> revert athenajs change </cmt>","fix relative paths in tests, part 1"
1,"<desc> changes get_class() to disallow null being a valid parameter, as that behaviour is highly astonishing. the ratio of the number of characters in the rfc to the actual code change, is too darn high. </desc> <cmt> require parameter to be an object if passed. </cmt> <cmt> add test. </cmt> <cmt> fixed ext/standard test that calls get_class() </cmt>",get_class() disallow null parameter rfc
2,<desc> closes #14799 closes #15034 fixes #14774 @amueller i think this is enough? (that doesn't fix the nonsense that the attribute has size 2 (i.e. 2 classes) for oneclass and svr but that's a different issue)  it does now </desc> <cmt> fixed n_support </cmt> <cmt> removed comment </cmt> <cmt> add comment </cmt> <iss> oneclasssvm n_support_ returns incorrect value </iss>,fixed n_support_ attr for oneclasssvm and svr
3,"<desc> refactor typecheckfunctionbodyrequest to return the type-checked body, and remove typecheckabstractfunctionbody in favor of a method on abstractfunctiondecl. in addition, start returning an errorexpr body instead of a partially type-checked body if type-checking fails. then, start using gettypecheckedbody in silgen to allow lazy type-checking when emitting function definitions. </desc> <cmt> [ast] remove newbodykind default </cmt> <cmt> a bunch of callers were accidentally misusing it. </cmt> <cmt> add abstractfunctiondecl::gettypecheckedbody </cmt> <cmt> refactor typecheckfunctionbodyrequest to return </cmt> <cmt> the type-checked body, and remove </cmt> <cmt> typecheckabstractfunctionbody in favor of </cmt> <cmt> a method on abstractfunctiondecl. in addition, </cmt> <cmt> start returning an errorexpr body instead of </cmt> <cmt> a partially type-checked body if type-checking </cmt> <cmt> fails. </cmt> <cmt> add some missing calls to setthrows </cmt> <cmt> we no longer run error checking for already </cmt> <cmt> type-checked synthesized functions, so add a </cmt> <cmt> couple of setthrows calls where they were </cmt> <cmt> previously missing. </cmt> <cmt> [silgen] use gettypecheckedbody </cmt> <cmt> use gettypecheckedbody to allow lazy </cmt> <cmt> type-checking when emitting function definitions. </cmt>",add and use abstractfunctiondecl::gettypecheckedbody
4,"<desc> xref #30539 </desc> <cmt> pandas\core\common.py:273: error: implicit generic ""any"". use ""typing.list"" and specify generic parameters </cmt> <cmt> pandas\core\arrays\categorical.py:514: error: implicit generic ""any"". use ""typing.list"" and specify generic parameters </cmt> <cmt> pandas\core\indexing.py:2227: error: implicit generic ""any"". use ""typing.tuple"" and specify generic parameters </cmt> <cmt> pandas\core\groupby\grouper.py:422: error: implicit generic ""any"". use ""typing.dict"" and specify generic parameters </cmt> <cmt> pandas\tests\frame\methods\test_replace.py:15: error: implicit generic ""any"". use ""typing.list"" and specify generic parameters </cmt> <cmt> pandas\tests\frame\methods\test_replace.py:20: error: implicit generic ""any"". use ""typing.list"" and specify generic parameters </cmt> <cmt> pandas\io\pytables.py:1462: error: implicit generic ""any"". use ""typing.list"" and specify generic parameters </cmt>","implicit generic ""any"" for builtins"
5,<desc> reduces checkstyle errors for patterns: api-gateway lazy-loading leader-election changes involved java docs reordering imports indentations line length issues </desc> <cmt> reduces checkstyle errors in lazy-loading </cmt> <cmt> reduces checkstyle errors in leader-election </cmt> <cmt> reduces checkstyle errors in api-gateway </cmt>,"resolves checkstyle errors for api-gateway, lazy-loading, leader-election"
6,"<desc> issue: #13336 primarily this fixes the handling of the -s (--static-dir) flag for windows users. this flag accepts a string in the shape of <dirname>:<endpoint>. currently it fails to handle absolute paths on windows: for a value like c:\path it would assume c to be the dirname and \path the endpoint. that bug is addressed here. besides fixing the bug at hand, i've extracted this piece of logic into a util, because it previously existed in two separate places. the util is now under unit test and the surrounding code has been cleaned up with some nicer logging. i've also replaced shelljs with copy from fs-extra. one less dependency is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no </desc> <cmt> extract static file handling to utils and make sure we handle windows well. </cmt> <cmt> we no longer need shelljs. </cmt>",fix --static-dir with absolute path on windows
7,"<desc> added some questions and answers in the filehandle and oop perl topics. </desc> <cmt> new questions and spell check (#181) </cmt> <cmt> added new questions related with kvm, libvirt and dnf </cmt> <cmt> new perl questions and answers </cmt> <cmt> added some questions and answers in the filehandle and oop topics. </cmt>",feature/new perl questions and answers
8,"<desc> new features others this pr added basic support for 'return' grammar in dy2stat. it supports the control flow of 'return'. the basics idea is using a return value variable to store the early return statements and boolean state variables with if-else to skip the statements after the return statements. this pr is very basic support. there are some corner cases i didn't develop/test. for example, 'return none', 'return different length of variables', 'return non-tensor and tensor together', 'no return statement'. these corner cases will be done in my next prs. target date is this week. note: for the unit test, i changed test_program_translator.py because the staticcode of dyfunc_with_if_else will change. to guarantee the correctness of dyfunc_with_if_else, i also run it in testrecursivereturn in test_return.py. i commented the early return code in bert_dygraph_model.py because 'return different length of variables' is unsupported now. i also know that there are some other models used early return and we didn't enable it in the unit test. i will add support for it in next prs and then re-enable those tests. </desc> <cmt> add return_transformer, not tested. test=develop </cmt> <cmt> test=develop </cmt> <cmt> add unittest and fix some bugs before testing. test=develop </cmt>",add basic support for grammar 'return'
9,<desc> and some cosmetics related to the fix this also fixes issues with wrong rendering size after dpi changes and/or display switch off/on </desc> <cmt> [xbmc] application: handle resize event even in full screen state on windows. </cmt> <cmt> [windowing] win32: update handling wm_dpichanged event </cmt>,don't react on dpi change event on win10 >= fcu
10,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. (not applicable) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. (already available) </desc> <cmt> updated typings to match vimeo's player.js v2.6.3, updated tests to reflect new methods, properties, and events </cmt> <cmt> cleanup of unused boilerplate lines </cmt> <cmt> setplaybackrate may return rangeerror </cmt> <cmt> options argument in constructor is optional </cmt> <cmt> removed typings for unexposed internals </cmt> <cmt> both playermap and readymap are internal weakmaps in vimeo's player.js and are never exposed, so there is no need to export their types. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",removing typings for unexposed internals
11,"<desc> add debug_* constants in place of the hardcoded values. should help making self-documenting code move endian fixes to clang, previous pr was merged... fast :) i was trying to automatically insert bpf_probe_read in situations like </desc> <cmt> move endian flags to kbuild_helper </cmt> <cmt> add debug constants </cmt>",minor endian and debug enhancement
12,"<desc> i hereby agree to the terms of the cla available at:  fix document for index.md and distinctive-features.md fix document for introduction toc priority detailed description / documentation draft: by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. </desc> <cmt> fix document for index.md and distinctive-features.md </cmt> <cmt> fix document for introduction toc priority </cmt>",fixed a problem with the translation of introduction
13,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add and fix line-styles </cmt> <cmt> fix typo </cmt> <cmt> add text-wrap style </cmt> <cmt> add tests </cmt>",fixed typos and added new style options
14,"<desc> make sure set the target branch to develop #3162 add msgtraceenable config in transaction producer benchmark follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> fix checkstyle fail </cmt> <cmt> add msgtraceenable config in transaction producer benchmark </cmt> <iss> add msgtraceenable config in transaction producer benchmark </iss>",[issue #3162 ]add msgtraceenable config in transaction producer benchmark
15,"<desc> this pr fixes #13767 adding in additional interfaces to correctly define certain easing factories, which allow parameterization (i.e. poly, back and elastic) it is related to #11365 and #11366. thanks for spotting the bug @billdwhite make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> fetch-merge commit from dt master </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> d3-ease: </cmt> <cmt> * [fix]: added interfaces and changed definitions for three classes of easing functions, which can be parameterized. fixes #13767. </cmt> <cmt> * [enhancement]: activated strictnullchecks after validation </cmt> <cmt> * [chore]: added jsdoc comments </cmt> <cmt> * [chore]: added linting config file. </cmt> <iss> [bug] d3-ease omitted easing function parameterizations </iss>","add parameterization, strictnullchecks and  jsdoc comments"
16,<desc> this adds support for setting docker_graphdriver and docker_execdriver to select the graph driver and the execution driver for the cli integration tests. this pr also fixes a race at the end of the test-integration-cli which makes the tests always fail on some systems. </desc> <cmt> cli integration: allow driver selection via vars </cmt> <cmt> this makes it possible to choose the graphdriver and the execdriver </cmt> <cmt> which is going to be used for the cli integration tests. </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> cli integration: fix wait race </cmt> <cmt> the wait at the end of cli integration script could end up failing if </cmt> <cmt> the process had already exited. this was making it look like the tests </cmt> <cmt> have failed. </cmt> <cmt> this change fixes the problem. </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt>,add docker options & fix the wait at the end
17,"<desc> description: when using !include_dir_list in yaml to bring in the contents of multiple yaml files as entries in a list, there is currently no way to control the order of that list.    a typical use is when creating lovelace views: if you use one file per tab then they appear in random order. this one-word patch causes files to be incorporated in alphanumeric order, which makes it predictable and controllable. checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io.  the pr is here. if the code does not interact with devices: </desc> <cmt> make yaml includes such as !include_dir_list incorporate files in alphabetical order </cmt> <cmt> test for !include_dir_list sorting </cmt>",make !include_dir_list use alphanumeric order
18,"<desc> this is an implementation of eap-tls protocol for the ppp stack. yes, now you can authorize via certificates using native windows clients too. i've implemented the eap stack kinda basically for now, but i hope it would be possible to expand it. although i'm not sure what else would be needed to implement. i was thinking implementing eap-ttls with inner eap protocol for secure password-based authentication (plaintext mschapv2 is kinda meh), but we got either ssl of sstp or ipsec of l2tp (noone uses plain l2tp, right?), so i guess this is already ""secure enough"" even with pap... anyway, i've also adjusted the user policy timeouts - now they are propagating correctly in ppp-based protocols too. another important thing. i've added the ability to load ca certificates from the chain_certs folder (and basically making them trusted). before that we had no way of loading our own ca certificates to pass the verification of the client certificate, now we do. but it should be noted, that this is a change which may arise questions about security of such a decision. maybe we should create a configuration setting and making it working only when it is true, and making it false by default. some changes to newsslpipeex were mostly hacks to allow working different clients (once again the android sstp ""vpn client pro"" gave me a headache...), for example for some reason pppd doesn't go well with tlsv1.3. i've tested it on sstp windows 10 native client, sstp ""vpn client pro"" on android, sstp-client on linux (of course all with certificates). as i don't have access to ios and macos devices, tests would be highly appreciated. big thanks for @davidebeatrici who directed me in the direction of newsslpipeex, which was the key to implement this at all. i hope my code is not too horrible. =) </desc> <cmt> adding timeout propagation from user policy in ppp sessions (including l2tp and sstp). </cmt> <cmt> fixing errors as per static analysis </cmt> <cmt> writing skeleton for eap-tls implementation </cmt> <cmt> preliminary (untested) eap-tls implementation </cmt> <cmt> fixing up some errors </cmt> <cmt> added possibility to load ca certificates from chain_certs folder to allow verifying the client certificates against it. </cmt> <cmt> fixing linux... </cmt>",implementation of eap-tls for ppp
19,"<desc> #18324 checks to see if x features are all 0 variance. if so, raises value error and will avoid divide by 0. not sure if this is desired behavior but seems like best way to handle, let me know if the error message is specific enough. </desc> <cmt> added value error for divide by zero caused by zero variance in all features. </cmt> <cmt> formatting fix </cmt>",nearest centroid divide by zero fix
20,"<desc> 1.adjust the related tolua files from external/lua/tolua to cocos/scripting/lua-bindings/manual/tolua, and adjust cocos/scripting/lua-bindings/manual/tolua_fix.cpp/.h to cocos/scripting/lua-bindings/manual/tolua 2.remove the reference of files in the external/lua/quick, and adjust the lua template. 3.adjust cocos_headers in the cocos2dx_studio.ini for lua bindings-generator </desc> <cmt> adjust the related tolua files from external/lua/tolua to cocos/scripting/lua-bindings/manual/tolua and update the project configure </cmt> <cmt> remove the files in the external/lua/quick from project and adjust the related configuration and lua template project </cmt>",adjust the directory structure for libluacocos2d project and update the configuration and the lua template
21,"<desc> part of #21125 fixes #95074 </desc> <cmt> move links files into own folder, start regex link provider </cmt> <cmt> basic regex link detection </cmt> <cmt> pass in validation callback </cmt> <cmt> add first test for regex local link provider </cmt> <cmt> port old link format tests </cmt> <cmt> rename to validated </cmt> <cmt> create word link provider </cmt> <cmt> fix compile </cmt> <iss> emojis before terminal links offset underline position when experimentallinkprovider is turned on </iss>",support validated regex-based link detection and word-based as a fallback that uses quick access
22,"<desc> (click an open the full image if viewing on a non-retina display) this patch adds support for window.devicepixelratio in the canvas renderer. animations using the canvas renderer on screens with a high pixel density > 1 (e.g. apple's retina displays) now look much crisper. to achieve this effect, the canvas size is multiplied by the value in  window.devicepixelratio (e.g. 2), while the size of the wrapper element remains the same. this makes the browser scale down the canvas element, resulting in a much crisper image. the effect is enabled by default if animationitem.wrapper exists and config.dpr is not set to a different value. it is also possible to set config.dpr manually. </desc> <cmt> add support for window.devicepixelratio in canvas renderer </cmt> <cmt> add check for config object </cmt>",add device pixel ratio support
23,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add methods </cmt> <cmt> add examples of method use </cmt>",add instance methods to react native material textfield
24,<desc> fixes #100709 </desc> <cmt> move some ptyprocessready usage inside proc manager </cmt> <cmt> part of #100709 </cmt> <cmt> fix compile </cmt> <cmt> directly expose environmentvariableinfo </cmt> <cmt> it's readonly on the interface </cmt> <cmt> create a new pty ready promise on relaunch </cmt> <iss> improve how process is managed when the terminal is reused </iss>,make terminal relaunch logic more internal to the process manager
25,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). no functional changes, just added new exports for use in module loaders, and removed all but 1 disabled linter rules and fixed the linting issues in the module and the tests.  the remaining listing error for having i in the interface name would be a breaking change so i did not fix that. </desc> <cmt> improve importability of angular-websocket </cmt> <cmt> move tslint, tsconfig closer to defaults, fix all linting issues </cmt>","improve angular-websocket importability, fix linter issues"
26,<desc> make parenthesis optional for named expressions used with while statement. the following used to be a syntaxerror which should be valid according to pep 572. this pr fixes the same. while match := pattern.search(f.read()): pass feel free to rephrase news entry if needed. i couldn't come up with a good test for an actual program for this case without reading a file or iteration. so i have added a test only to test_parser to make sure this is syntactically valid. cc : @gvanrossum @emilyemorehouse </desc> <cmt> add parenthesis optional in named expressions for while statement </cmt> <cmt> add news entry </cmt>,make parenthesis optional for named expression in while statement
27,"<desc> current implementation of 429 handling was totally flawed (many mistakes on promise usage, like resolving+rejection of the same promise, creating promise and throwing it away, 429 retry within 429 retry, etc.). this pr fixes this. </desc> <cmt> bugfixes for aws.request 429 handling </cmt> <cmt> conflicts: </cmt> <cmt> lib/provideraws.js </cmt>",bugfixes for 'too many requests' usage
28,"<desc> fix a bug where you cannot switch between ct/e2e by correctly closing the existing project before opening a new one update global mode to show recent projects instead of hard-coded placeholders open recent project when selecting one from the global mode ""welcome"" component fix a bug where it flashes ""loading"" without styles on the open browser screen - now it shows the browsers immediately demo: demo2.mov </desc> <cmt> allow to switch between ct and e2e seamlessly </cmt> <cmt> show most recent projects </cmt> <cmt> update test </cmt>",fix bugs and update global mode component
29,"<desc> address problem with #12377 by setting threshold my appropriately. ran test with 10000 random seeds and did not produce error. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change set activation to 1e-5 </desc> <cmt> remove disable flag </cmt> <cmt> finite difference should use mean </cmt> <cmt> lower numerical eps </cmt> <cmt> set threshold to 1e-5 </cmt>",fix test_activation by lowering threshold + validate eps for check_numeric_gradient
30,"<desc> this finishes the implementation of --window to also accept a string as the ""name"" of the window. so you can say wt -w foo new-tab wt -w foo split-pane and have both those commands execute in the same window, the one named ""foo"". this is just slightly more ergonomic than manually using the ids of windows. in the future, i'll be working on renaming windows, and displaying these names. --window,-w <window-id> run these commands in the given windows terminal session. this enables opening new tabs, splits, etc. in already running windows terminal windows. if window-id is 0, run the given commands in the current window. if window-id is a negative number, or the reserved name new, run the commands in a new terminal window. if window-id is the id or name of an existing window, then run the commandline in that window. if window-id is not the id or name of an existing window, create a new window. that window will be assigned the id or name provided in the commandline. the provided subcommands will be run in that new window. if window-id is omitted, then obey the value of windowingbehavior when determining which window to run the command in. before this pr, i think we didn't actually properly support assigning the id with wt -w 12345. if 12345 didn't exist, it would make a new window, but just assign it the next id, not assign it 12345. #4472, #8135  ran tests messed with naming windows, working as expected. closes </desc> <cmt> rebase all the changes on main </cmt> <cmt> the history of this had gotten way, way too long. it included everything since i started working on this </cmt> <cmt> fix a bug and fix the tests </cmt> <cmt> fix tests </cmt> <cmt> good ole java </cmt> <cmt> finish that test </cmt>",add support for naming windows with the -w parameter
31,<desc> i have added an algorithm for swap case in string folder i have fixed unexpected expression part from 2 algorithm. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> removed an extra '=' which was creating an error while running a program. </cmt> <cmt> removed the unexpected expression part. </cmt> <cmt> added program for swap cases in string folder </cmt>,added swap case program and removed unexpected expression part
32,"<desc> this pr addresses two aspects of the c++ launcher compilations, and fixes #1729. handling versions with this pr, upon build time the version string is automatically generated by reading the contents of changelog.md and adjusting a resource file. atm, the copyright/company info is hardcoded directly into the template file because i was unsure whether i should've read them from readme.me. added manifest the manifest file handles dpi-awareness (prevents the messagebox becoming blurry) and controls the uac definitions. (more work needs to be done on the subject of dpi-awareness and switching the dialogs to taskdialog as discussed in #1726.) </desc> <cmt> fixed line endings </cmt> <cmt> added version resources and manifest. </cmt> <cmt> add cmder manifest file </cmt> <cmt> added version.rc2.sample </cmt> <cmt> this file controls how the version strings appears in the final compiled .exe file </cmt> <cmt> add functions to get version and generate rc </cmt> <cmt> these functions can be used to a) extract the version from changelog.md and b) create a .rc2 file from the sample template by replacing its content </cmt> <cmt> add automatic version creation </cmt> <cmt> with this commit, the build script extracts the latest version string found in changelog.md, and then creates appropriate resource files for the executable compilation </cmt> <iss> cmder.exe should have a version number </iss>","generate win32 version string based on build no, git tag or fallback to changelog"
33,"<desc> doc only changes, no code changes. </desc> <cmt> convert comments to rustdocs for box, char, comm and cytpes.rs </cmt> <cmt> add spaces before newlines in rustdocs </cmt> <cmt> forgot to add some spaces before backslashes </cmt> <cmt> remove un-needed &lt; </cmt>","rustdocs for box.rs, comm.rs, ctypes.rs, char.rs"
34,"<desc> related issue: #22267 i converted all *utils files in the examples to esmodules to allow for tree-shaking. they now need to be imported like this: import * as nurbsutils from '../curves/nurbsutils.js'; the files i touched are nurbsutils, camerautils, sceneutils, geometrycompressionutils, geometryutils, skeletonutils. i had to move packedphongmaterial out of geometrycompressionutils as well. </desc> <cmt> nurbsutils: convert to esmodules </cmt> <cmt> camerautils: convert to esmodules </cmt> <cmt> sceneutils: convert to esmodules </cmt> <cmt> geometrycompressionutils: convert to esmodules </cmt> <cmt> geometryutils: convert to esmodules </cmt> <cmt> skeletonutils: convert to esmodules </cmt> <cmt> nurbsutils: update imports </cmt> <cmt> camerautils: update imports </cmt> <cmt> geometrycompressionutils: update imports </cmt> <cmt> geometryutils: update imports </cmt> <cmt> skeletonutils: update imports </cmt>",convert utils files to esmodules
35,"<desc> commit message: to prevent long event loop when too many udp packets are in the queue, limit how many packets to read in each event loop. if haven't finished reading, artifacts a read event to continue in the next event loop. add numpacketsexpectedpereventloop() callback to udplistenercallback, so that quic listener can tell how many packets it wants to read in each loop. the actually number of packets read are still bound by max_num_packets_per_event_loop (6000). quic listener returns numpacketsexpectedpereventloop() based on number of connections it has at the moment and the configured envoy::config::listener::quicprotocoloptions.packets_to_read_to_connection_count_ratio. made injectablesingleton really thread safe. risk level: medium, other than quic listener, other udplistenercallbacks return max size_t for numpacketsexpectedpereventloop(). this will cause those callbacks to read 6000 packets per read event. testing: added udp listener unit tests. fixes #16335 #16278 part of #16198 #16493 </desc> <cmt> add read limit </cmt> <cmt> test pass </cmt> <cmt> refine comments </cmt> <iss> flakes in ipversions/http2integrationtest.largeflowcontrolonandgiantbodywithcontentlength/ipv6_http3downstream_httpupstream </iss>",limit number of reads per event loop
36,"<desc> tagging @kiall for review, thanks! with the current chart, if .values.storageclass.create is false, the parameters and mountoptions were still rendered in the template, thus making the chart undeployable (since the manifest is not complete). this pr simply moves the else clause of the .values.storageclass.create to the end of the file, so that the rendered template is completely empty (no-op), and the deployment succeeds. (i did not create an issue for this, as the fix is trivial) dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> when a storage class is not created, mountoptions and parameters are also not included in the file </cmt> <cmt> bump nfs-server-provisioner version </cmt>",fix deployment when not creating storage class
37,"<desc> this pr includes minor edits to the data frame transform apis and the delete anomaly detection job api in the java rest client documentation. for example, it addresses the feedback in #44839 (comment) </desc> <cmt> [docs] minor edits to data frame transform apis </cmt> <cmt> [docs] minor edits in hlrc delete job api </cmt>",minor edits to hlrc ml apis
38,"<desc> description: adding support for other ptz move modes of  onvif integration only supports relativemove where it should also supports absolutemove and continuousmove. for exemple chinese goke gk7102 based ip camera only support continuousmove mode. this pr add those new modes with avaibility to select mode and params in service call. breaking change: the onvif camera service camera.onvif_ptz has been moved from the camera domain to the onvif domain.  onvif_ptz service was also renamed to ptz. so service calls need to be updated to onvif.ptz. changes: add continuousmove mode add continuous_duration delay to stop movement after that delay add absolutemove mode use service.data[key] instead of service.data.get(key) for keys with default schema values lovelace integration sample: - type: entity-button entity: camera.foscam icon: mdi:arrow-left-bold-outline show_name: false tap_action: action: call-service service: onvif.ptz service_data: entity_id: camera.foscam pan: left tilt: zoom: move_mode: continuousmove continuous_duration: 0.8 distance: 1 related issue (if applicable): at least #27744 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io home-assistant/home-assistant.io#11557 breaking change: domain moved from camera to onvif so service calls need to be update to onvif.onvif_ptz the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> adding support for ptz move modes </cmt> <cmt> adding support for other ptz move modes. </cmt> <cmt> onvif intergration used to only support relativemove where it should also supports absolutemove, continuousmove and stop. </cmt> <cmt> for exemple goke gk7102 based ip camera only support continuousmove mode. </cmt> <cmt> this commit add those new modes with avaibility to select mode and params in service call. </cmt> <cmt> adding support for ptz move modes </cmt> <cmt> adding support for other ptz move modes. </cmt> <cmt> onvif intergration used to only support relativemove where it should also supports absolutemove, continuousmove and stop. </cmt> <cmt> for exemple goke gk7102 based ip camera only support continuousmove mode. </cmt> <cmt> update service helper for new avaibility to select mode and params in service call. </cmt>",add more onvif ptz move modes
39,"<desc> previously the serve controller took 1 cpu and each http proxy actor took 1 cpu.  this is unnecessarily constraining in most cases.  for example, on a machine with 2 cpus, serve wouldn't have any available cpus remaining to start new replicas. this pr sets num_cpus=0 for the serve controller actor and the serve http proxy actors by default.  it also adds the option dedicated_cpu: bool = false in  serve.start() for the controller, and an option num_cpus = 0 inhttpoptions for the http proxies, to allow the user to reserve cpus as needed. the controller can thus have either 0 or 1 cpu, the proxies can each have any number of cpus (the same number of cpus for each proxy.) i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> set num_cpus to zero for controller and proxy </cmt> <cmt> add dedicated_cpu parameters </cmt> <cmt> lint </cmt> <cmt> add test </cmt> <cmt> lint </cmt>",set controller and http proxy num_cpus=0 by default
40,"<desc> 'd with @jasonrudolph fixes #19311 in #19244, i included a dependency on @atom/notify to support watching the file system. it spawns an external binary, which worked fine in tests and in dev mode, but broke when the module was packaged in an asar archive. if you want to spawn a process from a node module that is inside an asar archive, that binary must be on the physical file system. electron's file system hacks support require and other file system operations, but they don't support spawn. this pr updates the @atom/notify dependency to support transforming the binary path to account for the module being packaged in a separate location (atom.asar/@atom/notify) than the binary it is trying to spawn (atom.asar.unpacked/@atom/notify/bin). </desc> <cmt> exclude notify binary from asar bundle </cmt> <cmt> fix @atom/notify's binary path when running within atom's asar archive </cmt> <cmt> / </cmt> <cmt> :arrow_up: @atom/notify@1.3.2 to remove unnecessary require.resolve step </cmt> <iss> unable to spawn notify subprocess on windows </iss>",exclude @atom/notify binary from the asar bundle
41,"<desc> added set which does exist ( add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added set to available types </cmt> <cmt> added set which does exist ( </cmt> <cmt> updated tests </cmt> <cmt> - added tests for str </cmt> <cmt> - added tests for pick </cmt> <cmt> bumped version </cmt>",added set method to available types for dot-object package
42,<desc> rationale it is better to compute the auctionend once during contract creation than to compute it every time someone bids. it is also better to not store unnecessary information on the blockchain. i found these issues distracting while learning solidity. change simpleauction does less computing for each bid by retaining the more-relevant auctionend instead of auctionstart. simpleauction drops its now-unused biddingtime variable. blindauction drops its already-unused auctionstart variable. </desc> <cmt> remove auctionstart </cmt> <cmt> also rm biddingtime </cmt>,replace biddingtime with auctionend in auction example
43,"<desc> this pr fixes the logic introduced in #15104 to only check for callback parameters when we aren't in a recursive call to comparesignaturesrelated that resulted from an outer callback check. fixes #18277. </desc> <cmt> don't check for callbacks in recursive call that resulted from callbacks </cmt> <cmt> add regression test </cmt> <cmt> accept new baselines </cmt> <iss> stack overflow while type checking generic, mutually-defined function interfaces </iss>",fix checking of recursive callback types
44,"<desc> update the chinese electron mirror url - this should avoid the ""china mirror does not have a v prepended to the electron version in the url"" problem. the cache directory scheme changed (electron/get#113), so update the example directory structure. remove the remaining references to electron-download. cc: @electron/wg-ecosystem npm lint:docs passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> doc: update chinese electron mirror url </cmt> <cmt> doc: replace remaining references of electron-download with @electron/get </cmt> <cmt> doc: update cache dir example based on recent @electron/get cache changes </cmt>",update installation docs to reflect latest @electron/get changes
45,<desc> i hereby agree to the terms of the cla available at:  fix possible error totals having transform was already added to pipeline in case of a query from delayed replica. </desc> <cmt> update test. </cmt> <cmt> fix totals and extremes for delayed replica. </cmt>,fix totals for delayed replica
46,<desc> added a mnist and an imagenet example to show how to run mxnet with horovod. readme page is also added. readme mxnet_mnist.py mxnet_imagenet.py </desc> <cmt> add examples for mxnet with horovod </cmt> <cmt> update readme </cmt>,add examples of running mxnet with horovod
47,<desc> fix win32 js project crash issue: 445442c </desc> <cmt> fix #24345 </cmt> <cmt> squashed commit of the following: </cmt> <cmt> commit aff4e27200a77db60b13ea30c2457558e5f53059 </cmt> <cmt> author: ricardo quesada <ricardoquesada@gmail.com> </cmt> <cmt> date:   thu dec 10 17:58:41 2015 -0800 </cmt> <cmt> compiles with new gc model </cmt> <cmt> commit 1fa69cd71231d56371cd45a378e50a1888308b42 </cmt> <cmt> author: ricardo quesada <ricardoquesada@gmail.com> </cmt> <cmt> date:   thu dec 10 17:41:15 2015 -0800 </cmt> <cmt> animation3d works ok </cmt> <cmt> commit d439969caf7e6fe83a74e37d078c4361a08cb816 </cmt> <cmt> author: ricardo quesada <ricardoquesada@gmail.com> </cmt> <cmt> date:   thu dec 10 13:39:50 2015 -0800 </cmt> <cmt> sprite3d create: converted to new api </cmt> <cmt> commit aabe449e4a968fad882c44df9be787eb7c3bfcec </cmt> <cmt> author: ricardo quesada <ricardoquesada@gmail.com> </cmt> <cmt> date:   thu dec 10 13:27:33 2015 -0800 </cmt> <cmt> ouch... </cmt> <cmt> commit 688ab610a8cb7607bc3c51b8ca01d800ef3c9794 </cmt> <cmt> author: ricardo quesada <ricardoquesada@gmail.com> </cmt> <cmt> date:   thu dec 10 13:12:25 2015 -0800 </cmt> <cmt> spawn/sequence init* were not bound </cmt> <cmt> fixed. now js scheduler test works ok </cmt> <cmt> adds memorymodeltest </cmt> <cmt> update changelog </cmt> <cmt> mooooores fixes </cmt> <cmt> but gc memory model doesn't work yet... somewhere someone is still </cmt> <cmt> retaining a reference that prevents the whole thing from </cmt> <cmt> releasing </cmt> <cmt> restores autobindings </cmt> <cmt> squashed commit of the following: </cmt> <cmt> [ci skip][auto]: updating luabinding & jsbinding automatically </cmt> <cmt> [ci skip][auto]: updating luabinding & jsbinding automatically </cmt> <cmt> fix deprecation warnings in pu </cmt> <cmt> fix typos in documentation and comments </cmt> <cmt> replace non-ascii characters in comments </cmt> <cmt> fix inconsistent header include guards </cmt> <cmt> fix typos in documentation and comments </cmt> <cmt> fix inconsistent header include guards </cmt> <cmt> fix deprecation warnings in pu </cmt> <cmt> [ci skip][auto]: updating luabinding & jsbinding automatically </cmt> <cmt> [ci skip][auto]: updating luabinding & jsbinding automatically </cmt> <cmt> upgrade spider monkey to solve win32 js project crash issue </cmt>,sync v3 and fix win32 js project crash issue
48,"<desc> this is a concerted effort to actually clean up our yaml files and have yamllint not report any errors. changes made in this pr: the line length limit for warnings in yaml files is bumped from 120 to 150. this is enough to cut out a lot of warnings while still being a reasonable upper limit. the line-length check configuration is updated to explicitly ignore lines that are long due to unsplittable words (such as extremely long urls). explicit ignore directives have been added for submodules and temporary paths that are known to potentially contain yaml files. this makes manually running yamllint on a local checkout a much nicer experience. one new rule (empty-values) has been enabled in the yamllint config. this explicitly forbids use of implicit null values in mappings, which helps protect against structural errors in mappings resulting from implicit null value behavior combined with incorrect indentation. actual usage of null values is relatively uncommon to begin with, and the only files affected by this are a handful of gha workflows. this was prompted by me actually running into such an issue the other day in a personal project and it taking far too long for me to figure out what was going wrong. all errors (but not warnings) reported by yamllint in the repo are fixed. component name area/ci n/a we had originally planned to just fix yamllint stuff as it came up, but i finally got tired of seeing yamllint errors in unrelated files when running it locally. </desc> <cmt> assorted yamllint config updates. </cmt> <cmt> * extended line length limit to 150. this is still a reasonable limit </cmt> <cmt> but cuts down on warnings a bit. </cmt> <cmt> * added explicit ignore directives for external repo paths. this makes </cmt> <cmt> using yamllint locally nicer. </cmt> <cmt> * enabled the rule to require null values to be explicit. this rule </cmt> <cmt> helps prevent accidental bogus mapping problems resulting from </cmt> <cmt> implicit null values combined with incorrect indentation. </cmt> <cmt> this only results in new errors in a couple of gha workflows, which will </cmt> <cmt> be fixed in the next commit. </cmt> <cmt> fix all yamllint warnings in yaml file sin the repo. </cmt> <cmt> most are indentation or spurious empty lines. </cmt>",clean up yaml files in the repository.
49,"<desc> a variant of this camera has an annoying bug surrounding suspend/resume. these two commits fix it. </desc> <cmt> sound/usb: add device quirks for a4tech fhd 1080p webcams </cmt> <cmt> these devices use a type of sonix chipset that produces broken microphone </cmt> <cmt> data if suspended/resumed. </cmt> <cmt> they also don't support readback of the sample rate. </cmt> <cmt> sound/usb: call usb_autopm_get_interface() for devices that should not </cmt> <cmt> be suspended </cmt> <cmt> webcams with microphones are composite devices, and autosuspend is set </cmt> <cmt> at the device level. if uvcvideo is probed after snd-usb-audio, the effect </cmt> <cmt> of the quirk applied by snd-usb-audio is undone by uvcvideo's global </cmt> <cmt> application of autosuspend. </cmt> <cmt> incrementing the interface's pm refcount in such cases prevents runtime pm </cmt> <cmt> from happening, thus the device is left active. </cmt>",prevent a4tech fhd 1080p webcams from being suspended automatically
50,"<desc> some 64-bit (unsigned) integers are not compared correctly (see attached test). </desc> <cmt> valuetest: add test for uint64 comparisons </cmt> <cmt> genericvalue: fix comparison of (ui|i)nt64 numbers </cmt> <cmt> some 64-bit integers cannot be represented losslessly as a double. </cmt> <cmt> due to a typo in the operator==, the comparison has been performed </cmt> <cmt> after a double conversion in too many cases. </cmt>",failing comparisons between certain (ui|i)nt64 numbers
51,"<desc> adds a working failure test for streaming and non-streaming shuffle, without lineage reconstruction. this does a few things. test improvements: modifies autoscalingcluster to allow passing an idle node timeout (the default is very low) some small improvements to the nodekiller actor to hopefully improve flakiness. shuffle fixes: modifies shuffle tracker to wait on futures instead of having tasks signal. during failures, tasks may never signal the tracker, so we can't rely on these to track progress. core fixes: raylet will exit immediately if it receives the shutdown rpc with graceful=false - there was a bug here where it's supposed to exit after replying to the client, but the grpc server goes down for an unknown reason and the client reply is never sent on reference deletion, the owner now publishes an additional message to subscribers that the object has been deleted. previously, this was causing a hang in streaming shuffle because the raylets pulling an object subscribed after the object was already deleted, so they never received the error signal. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix test, shuffle, nodemanager graceful shutdown </cmt> <cmt> error </cmt>",add chaos test for shuffle
52,"<desc> with the following code, model.where(foo: [1, nil]) ar builds an sql like this: where foo in (1) or foo is null here's a tiny patch that makes it like this: where foo = 1 or foo is null </desc> <cmt> no need to compact an already compacted array </cmt> <cmt> where(foo: [1, nil]) becomes ""where foo = 1 or foo is null"" </cmt> <cmt> was ""where foo in (1) or foo is null"" before </cmt>",ar#where with an array of 2 elements including a nil
53,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). bringing the array up to date with the latest library code (v1.5.1): </desc> <cmt> adding investments to the product array </cmt> <cmt> adding investments to the product array in the test as well </cmt>,updating the product list to match the latest library code
54,"<desc> add rss and cache memory stats for containers. docker plugin now returns rss and cache stats for containers. these were commented out due to them not being present in docker 1.11 (maybe due to a bug in docker?) see #848. since these stats are available in newer versions of docker i thought it'd be nice to bring them back. i've also added an additional column for rss in the web ui for containers. bug fix: no fixed tickets: enhacement #1694 </desc> <cmt> bring back 'rss' and 'cache' memory stats in docker plugin </cmt> <cmt> looks like the stats were removed because they where gone in docker 1.11. this change put them back since they've been available again for a while now. </cmt> <cmt> add rss column for containers in web ui </cmt> <cmt> since resident set size is available for containers, an additional column has been added to display this value. </cmt> <iss> enhancement: rss for containers </iss>",add rss metric for containers
55,"<desc> uimanager.js now expects uimanager.getconstantsforviewmanager, but only in production mode.  in dev fallback code exists to read the old constants. fix: add getconstantsforviewmanager synchronous method, uses same function as how we populate all the constants. removed some dead code in populateviewmanagerconstants accidentally left in a year ago. also: add a quick fix in viewpanel, running into -inf width/height sometimes in our app startup add blank line in package.json that gets added after npm install is run microsoft reviewers: open in codeflow </desc> <cmt> add missing blank line </cmt> <cmt> add uimanager.getconstantsforviewmanager as expected by rn 58 </cmt> <cmt> quick fix for uwp </cmt>",fix running with bundle file in 58 - uimanager.getconstantsforviewmanager
56,<desc> bug fixes apis cherrypick from #34156 </desc> <cmt> fix the order of unfold parameters (#34156) </cmt> <cmt> * fix the order of unfold parameters </cmt> <cmt> fix the order of unfold parameters (#34156) </cmt> <cmt> * fix the order of unfold parameters </cmt> <cmt> fix unfold </cmt>,[cherrypick 2.1.2]fix the order of unfold parameters
57,"<desc> moving #4885 over here -- for #4848. as we work on the new ui, let's write our stories in the new format. @ndelangen would you be interested in pairing on improving this importall function? how's your hmr? this works as is but makes use of window and is a bit of a hack. </desc> <cmt> merge 4848-new-example-format into tech/overhaul-ui </cmt> <cmt> fix up parameters examples </cmt> <cmt> change .examples -> .stories </cmt>",use new story format in official storybook
58,"<desc> previously it was not possible to jit hf's modeloutput . by changing dataclass to flax.struct.dataclass this is however possible. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> fix_torch_device_generate_test </cmt> <cmt> remove @ </cmt> <cmt> change dataclasses to flax ones </cmt>",allow dataclasses to be jitted
59,"<desc> model.findoneandupdate supports the overwrite option which is not declared in the queryfindoneandupdateoptions interface.  this option was added to mongoose version 5.9.12 on 2020-05-04.  updated to the latest version of the library, 5.10.9, in the header. also removes trailing spaces in index.d.ts and test/model.ts. add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: here include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [mongoose] add missing overwrite option to interface queryfindoneandupdateoptions </cmt> <cmt> update version </cmt>","add missing option ""overwrite"" to interface queryfindoneandupdateoptions"
60,<desc> description: support is added for lights which are connected to the relays of lcn hardware devices. related issue (if applicable): pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#7977 example entry for configuration.yaml (if applicable): lcn: connections: - name: myhome host: 192.168.2.41 port: 4114 username: !secret lcn_username password: !secret lcn_password lights: - name: living room address: myhome.0.7 output: relay1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> added relay ports to lcn lights platform </cmt> <cmt> exchanged validation for ports with uppercase validator. makes interfacing with pypck enums much more simple. </cmt>,support for relay ports for lcn light platform
61,"<desc> this refactoring doesn't change the api and makes good code reuse improving maintenance. i've tried to make small incremental commits to make your review easier. relevant changes: now all androidapplication* classes implement the androidapplicationbase interface each androidapplication* class uses a lifecycle listener (if needed) specialized for audio management. androidgraphics is now used as-is by activity, fragment and daydream applications. androidlivewallpaper has its own extension of androidgraphics. since the original androidlivewallpaper is a bit nasty, i've preferred to grab and override main methods of the superclass androidgraphics so to minimize the impact and avoid breaking existing stuff. </desc> <cmt> preliminary changes to androidapplicationbase propaedeutic for massive code reuse on graphics classes </cmt> <cmt> made code reuse in methods initialize and initializeforview propaedeutic for upcoming changes </cmt> <cmt> removed isfragment method; let's use a specialized audio lifeclycle listener instead. </cmt> <cmt> unified androidgraphics class for activity, fragment, and daydream; </cmt> <cmt> extended for live wallpaper. </cmt>",androidapplication and androidgraphics classes refactoring
62,"<desc> skywalking provides browser ui, cli and graphql ways to support extensions. but some users may have the idea to query data directly from the storage. such as in elasticsearch case, kibana is a great tool to do this. in default, due to save memory/network and storage space, skywalking saves id(s) only in the entity and metadata saved in the *_inventory entities only. but these tools usually don't support nested query, or don't work conveniently. in this special case, skywalking provide a config to add all necessary name column(s) into the final metrics entities with id as a trade-off. take a look at core/default/activeextramodelcolumns config in the application.yaml, and set it as true to open this feature. this feature wouldn't provide any new feature to the native skywalking scenarios, just for the 3rd party integration. </desc> <cmt> support dynamic column in the source. </cmt> <cmt> support activeextramodelcolumns as a default off option. </cmt>","support name column(s) in the storage for 3rd party integration, like kibana. default off"
63,<desc> if d20382065 successfully rolls out (has some issues still). then we don't need this fork anymore. we should start by at least removing it from modern builds. to do this i needed to fix the unsubscribing stuff mentioned in #18270 (comment). flare is now used by both the fb fork and without it so we should just compile to one or the other. i do that by always returning an unsubscribe listener and always passing that to a removeeventlistener function. the indirections can then be compiled out. </desc> <cmt> move unsubscribe fork to eventlistener </cmt> <cmt> that way we can statically compile out more of these indirections. </cmt> <cmt> don't use the eventlistener fork for modern www builds </cmt>,don't use eventlistener fork in modern www builds
64,"<desc> windows explorer will show when you type explorer.exe. see  #6917 for the interaction. pr checklist applies to  #6917 cla signed. if not, go over here and sign the cla tests added/passed info on pull request created that it also matches on explorer.exe for explorer. matching explorer.exe also for explorer added unit test optimized multiple iterations for iprogram validation steps performed try the plugin explorer.exe and see that it has a result. </desc> <cmt> matching explorer.exe also for explorer </cmt> <cmt> added unit test </cmt> <cmt> optimized multiple iterations for iprogram </cmt> <cmt> fixed linter </cmt>",matching exactname for known win32 programs
65,"<desc> so the problem here was that, when requesting another users profile (not your own), the completedchallenges array was only sent back if showcerts and showtimeline were true - aka public. so i filtered out the cert challenges if showcerts was private and sent it back like that. i came up with a few iterations of this logic before landing on what's in the pr. feel free to suggest something better. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. closes #37855 </desc> <cmt> fix: conditionally send back cert challenges with challenge list </cmt> <cmt> fix: remove empty line </cmt> <iss> timeline does not appear for public portfolio </iss>",timeline not showing when set to public
66,"<desc> the reason for this pull request appears in a conversation for #4844 this is the first of two pull requests. the ultimate goal is to add the mice imputation algorithm to scikit-learn. to do so, we need sklearn's bayesian regression algorithms to be able to return standard deviations as well as predictions. this pull requests adds the option return_std to the predict methods of both bayesianridge and ardregression. once this is accepted, i will make a pull request that implements mice using bayesianridge by default (which seems more robust to small sample sizes than ard in my limited experience). </desc> <cmt> initial commit for return_std </cmt> <cmt> initial commit for return_std </cmt> <cmt> adding tests, examples, ard predict_std </cmt> <cmt> adding tests, examples, ard predict_std </cmt> <cmt> a smidge more documentation </cmt> <cmt> a smidge more documentation </cmt>",adding return_std options for models in linear_model/bayes.py
67,"<desc> several pattern matching needs to be changed when adding a new param now, e.g. #4805 this pr is to refactor xgboost.scala to make code cleaner </desc> <cmt> cleaning checkpoint file after a successful file </cmt> <cmt> address comments </cmt> <cmt> refactor xgboost.scala to avoid multiple changes when adding params </cmt>",refactor xgboost.scala to put all params processing in one place
68,<desc> this pr adapts/utilizes recent enhancements in lucene-7.4: replaces exactnumdocs by the soft-deletes count in segmentcommitinfo. this enhancement allows us to back out changes introduced in #30228. always configure the soft-deletes field in iwc </desc> <cmt> always enable soft-deletes when opening iw </cmt> <cmt> load commit stats directly from segmentinfos </cmt> <cmt> use getsoftdelcount </cmt> <cmt> this reverts commit b12c2f61c5baeb7ba200748834ff69beec5351f5. </cmt> <cmt> configure soft-deletes field </cmt> <cmt> mute matchphraseprefixquerybuildertests </cmt> <cmt> soft-deletes field when restore from snapshot </cmt> <cmt> configure soft-deletes peerrecoverytargetservicetests </cmt> <cmt> when prune commit files </cmt>,replace exact numdocs by soft-del count in segmentcommitinfo
69,<desc> added fingerprint for 2019 acura ilx. dongle id: 42606d78d7bc5712 thanks to discord user simplyken. </desc> <cmt> add fingerprint for eu 2019 civic hatch </cmt> <cmt> remove fw electricbrakebooster </cmt> <cmt> remove extra space </cmt> <cmt> add 2019 acura ilx fingerprint </cmt> <cmt> add 2019 acura ilx to readme.md </cmt>,add fingerprint for 2019 acura ilx
70,"<desc> this is a fix for #836.  to stabilize the formatting, i introduce a function which dedupes adjacent invisible parentheses, so that downstream formatting logic involving breaking up lines depending on line length get the same input regardless of whether ((({atom}))) or ({atom}) is attempting to be formatted. open to feedback on this solution and additional test cases i can throw at it; tried to be conservative w.r.t. how these parens are deduped. as an aside, perhaps in a future pr we can refactor how maybe_make_parens_invisible_in_atom looks.  currently, it's responsible for returning a boolean and causing side-effects, which isn't obvious off the bat.  i added a comment to clarify this for now. </desc> <cmt> fix for unstable formatting involving unwrapping multiple parentheses </cmt> <cmt> more tests </cmt>",fix unstable formatting involving unwrapping multiple parentheses (#836)
71,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> fix sfdc response payload to not be undefined. </cmt> <cmt> add optional scope to sfdc oauth login params. </cmt>,merge fixes for sfdc canvas sdk oauth login scope and response payloads.
72,<desc> check for the packagemanagement capability for caller apps. all medium-il processes have all capabilities so this will pass for powershell callers. i originally tried to add these checks in the activation factories but the calling process in that case was a svchost process. i also updated the telemetry to log the caller. microsoft reviewers: open in codeflow </desc> <cmt> merge microsoft/winget-cli changes. </cmt> <cmt> rest endpoint helper and json object field check - bug fix (#821) </cmt> <cmt> merge latest winget changes. </cmt> <cmt> check caller capabilities </cmt> <cmt> revert line ending change. </cmt>,add capability checks for callers to the packagedapi
73,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. </desc> <cmt> updated to reflect the relationship between label and input elements </cmt> <cmt> updated to reflect the relationship between label and input elements </cmt>",consistency update for label and input elements for last lessons
74,"<desc> the motivation here is to split the one big switch into many more reasonable-sized methods, which makes the file a little easier to read and should give us better backtraces. it also turned out to clean up several kinds of ad hoc local state. no functionality change. i suggest reviewing commit by commit, and skipping the big one (just assume i got it right; i was very careful not to improve anything during that commit). </desc> <cmt> [serialization] pull decl deserialization out to a helper class </cmt> <cmt> in preparation for splitting up one big switch into many small </cmt> <cmt> methods. well, medium-sized methods. </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] move decl attribute deserialization into new helper </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] move one case in getdeclcheckedimpl out of line </cmt> <cmt> ...as a proof of concept. the next commit will move them /all/ out of </cmt> <cmt> line. </cmt> <cmt> (the intent here is to produce better backtraces when not recovering </cmt> <cmt> from errors.) </cmt> <cmt> [serialization] make astdeserializer stateful, and use that state </cmt> <cmt> ...for decl attributes. also, rename to decldeserializer. </cmt> <cmt> [serialization] move various raii-based setup into decldeserializer </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] move helper lambda into decldeserializer </cmt> <cmt> and cache the astcontext pointer for convenience. </cmt> <cmt> [serialization] move all the decl layouts into decldeserializer </cmt> <cmt> now we have a separate function for each serialized declaration kind! </cmt> <cmt> much cleaner, still nfc. </cmt> <cmt> [serialization] collapse one level of helper function i didn't need </cmt> <cmt> no functionality change. </cmt> <cmt> [serialization] collapse prefix/postfix operator deserialization </cmt> <cmt> ...using a template. </cmt>",break up getdeclcheckedimpl into a helper class
75,"<desc> fix check for '.' in names with more efficient implementation better error message when transferring from token account with 0 balance unit tests for registering subdomains and buying short names (tlds) at auction </desc> <cmt> fix #3187 - effecient detection of names with '.' </cmt> <cmt> - also exempt the eosio account from this restriction </cmt> <cmt> implement name auction #3189 </cmt> <cmt> fix bugs and implment tests for name auction, fix #3189 </cmt>",issue3189 - account name auction & tlds
76,"<desc> this pr fixes two issues that have been introduced by #9114. when i switched the metric from rate to tokenbucket in the controllermutationquotamanager, i have mixed up the metrics. that broke the quota update path. when a quota is updated, the clientquotamanager updates the metricconfig of the kafkametric. that update was not reflected into the sensor so the sensor was still using the metricconfig that it has been created with. </desc> <cmt> update the correct metric in the controllerquotamanager when the quota is updated. </cmt> <cmt> wire up the metricconfig differently in the sensor to ensure that updating the metricconfig of the kafkametric is reflected in the sensor. </cmt>",kafka-10458; updating controller quota does not work since token bucket
77,"<desc> there is an option for nodeos that specifies the max flight bytes. however, it did not work fine since the calculation of the bytes in flight was wrong. the bytes in flight was always 0 or 1 so it never exceeds the max flight bytes. it causes an issue that nodeos continues to accept new transactions when there is no new blocks until the process reaches the maximum file descriptors. it causes the nodeos malfunctioning and cannot be recovered. in some environments it causes the whole os malfunctioning. select one </desc> <cmt> fix the issue that nodeos continues to accept transactions after the flight queue size exceeds the maximum flight bytes </cmt> <cmt> make con not a constant parameter for function verify_max_bytes_in_flight </cmt> <cmt> added more debugging messages </cmt> <cmt> testing </cmt> <cmt> remove debugging message </cmt>",fix the bug that the flight bytes are calculated incorrectly
78,"<desc> this should address #806 on linux, but not on mac. to fix the problem on mac, we probably need to patch the arrow cmake module that finds the python libraries. </desc> <cmt> tell cmake which python to use when building arrow. </cmt> <cmt> pass different path into cmake when building arrow so that cmake finds the right python. </cmt> <cmt> add correct python executable to path when running cmake for ray. </cmt>",add correct python executable to path when building arrow.
79,"<desc> some functionality in #623 was actually fairly trivial to implement. the following features are included in the flow list view: press 'm' to toggle an easily visible mark on the current flow. when the flow list is cleared with 'c', marked flows are not deleted. if all flows in the list are marked, marked flows are deleted with 'c' this means that pressing c twice will clear all flows, including marked ones. the mark is made large to stand out while scrolling, but that can be changed by changing symbol_mark in libmproxy/console/common.py. </desc> <cmt> implemented basic marking of flows </cmt> <cmt> - press m to toggle flow mark </cmt> <cmt> - flow mark is set in libmproxy/console/common.py. currently set to ""==="" </cmt> <cmt> marked flows not deleted on clear all </cmt> <cmt> marked flows survive a clear all unless all current flows are marked. </cmt> <cmt> bug: they don't show up until another flow is added </cmt> <cmt> fixed console rendering bug </cmt> <cmt> clearing all flows now works properly </cmt> <cmt> changed symbols and colors </cmt> <cmt> added a better symbol for the mark, and changed the color to red. this helps it </cmt> <cmt> stand out more easily. </cmt>",added flow marking functionality in the console
80,"<desc> this pr adds a handful of server rendering unit tests. with the move to fiber, it's likely that the server rendering path and client rendering path are going to diverge significantly, and i think it'd be useful to have a more robust unit test suite for server rendering as the work on fiber ssr begins. this pr starts to port over tests that i wrote in (since abandoned) pr #6836. this pr only ports over some of the helper functions and 4 of the simplest tests. if this pr is accepted, i plan to submit the rest of the tests in a series of further prs; i only added four tests here because i wanted to keep this pr as digestible as possible. thanks for all your great work! note: i ran tests, linting, and flow, but i could not get ./scripts/fiber/record-tests to work. it first complained about not being able to find jest-cli; when i npm installed jest-cli, it complained about an unresolved promise with the error typeerror: path must be a string. received undefined.  i expect the ci build will fail on this, and i'd appreciate any pointers to getting it to work. </desc> <cmt> added a handful of ssr unit tests, ported from a previous pull request. </cmt> <cmt> fixing linting errors </cmt>",adding some server rendering unit tests.
81,"<desc> this removes ""old"" post-process uniforms and samplers. the new post-process materials don't need them, as they use per_material_instance ones. dithering uses the time uniform, which it now gets from frameuniforms. </desc> <cmt> deprecate post-process uniform buffer </cmt> <cmt> deprecate post-process sampler block </cmt>",remove post-process uniform / sampler blocks
82,<desc> ref this comment in ie calling getboundingclientrect  on an element that is not attached to the dom throw an unspecified error:  saucelabs is failing because some unit test for scrollspy doesn't add the element worked on to the dom. this pr make sure the unit test add the element used in the test to the qunit-fixture as the scrollspy plugin is meant to work on element present on the page. </desc> <cmt> merge commit '6aad73ac6d07082e607986339661a8e9f5dc0c93' into v4-dev </cmt> <cmt> merge commit 'cab6f7d16ca64dfcb0de002940d085c8cfe8b304' into v4-dev </cmt> <cmt> * commit 'cab6f7d16ca64dfcb0de002940d085c8cfe8b304': </cmt> <cmt> more config tweaks. </cmt> <cmt> bump to jquery 3.2.1 </cmt> <cmt> always append element to fixture in scrollspy unit tests </cmt>,fix saucelabs error following merge of #21788
83,"<desc> original pull-request #23261 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> disable hedged requests </cmt> <cmt> disable hedged requests </cmt>",cherry pick #23261 to 21.5: disable hedged requests
84,"<desc> the get_many function in the backends/base.py file previously received ready_states argument, but only considered it, when looking into tasks that are already in cache. the get_many function now also considers the ready_states arg when fetching new results. also added a test case for this behavior. </desc> <cmt> backends base get_many pass ready_states arg </cmt> <cmt> test backends base get_many pass ready_states arg </cmt>",backends base get_many function now passes ready_states
85,"<desc> media keys do not work on milk via keymap my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> update fork branch </cmt> <cmt> allow media keys in milk via </cmt>",fix media keys in via keymap for 2% milk
86,<desc> overwrites some of the other changes already added for babel 6 to flow better and not treat v6 as the anomaly (it's what people will get by default these days). it also does #5360 more completely. </desc> <cmt> [docs] update getting started for babel 6 </cmt> <cmt> [docs] update tooling integration for more babel 6 </cmt>,update docs for babel 6
87,"<desc> built on #8579 </desc> <cmt> provide a mechanism to create a secure client channel </cmt> <cmt> initial test fix </cmt> <cmt> expand corpus, add call creds </cmt> <cmt> expand corpus, fix crash </cmt> <cmt> expand corpus, fix crash </cmt> <cmt> expand corpus </cmt>",add credentials creation to api_fuzzer
88,"<desc> fixes rdar://problem/46571799. </desc> <cmt> silgen: drop generic signature from witness thunk if all parameters are concrete </cmt> <cmt> sil functions for ast declarations do this, and the sil verifier enforces </cmt> <cmt> this, so let's do it for witness thunks too, fixing a devirtualizer </cmt> <cmt> crash. </cmt> <cmt> fixes <rdar://problem/46571799>. </cmt> <cmt> sil: silfunctiontypes don't allow generic signatures where all parameters are concrete </cmt>",fix devirtualization of conditional conformance where all generic parameters are concrete [5.0]
89,<desc> this is to add a plugin for fakerjs as requested in #1199 the name of the plugin is gatsby-source-faker usage of the plugin is described in the readme of the plugin itself and there is an example site with the usage shown. question - i want to make a netlify deploy of this. can you point me to how you are deploying your current examples? i would follow the same. </desc> <cmt> added plugin </cmt> <cmt> added example usage </cmt> <cmt> add readme </cmt>,plugin in gatsby to use faker
90,"<desc> what do these changes do? fix ddpg optimizers add twin delayed ddpg (td3) the original implementation compute gradients with actor optimizer and critic optimizer respectively but apply gradients with the fake optimizer defined by base class tf policy graph. actually, tensorflow optimizers compute the gradients in the same way, while the momentum adjustments function in applying the gradients. thus, the original implementation failed to use the two optimizers created by the ddpg agent itself. td3 mainly add 3 tricks to ddpg and this pr tries to add td3 upon ddpg. the comparison is showed as follow: td3 seems more stable w.r.t. ddpg and solves the pendulum-v0 quickly in the sense of sample efficiency. </desc> <cmt> fix ddpg optimizer and add td3 </cmt> <cmt> supplement missed argument </cmt> <cmt> formated by yapf </cmt>",enable twin delayed ddpg for rllib ddpg agent
91,"<desc> this pr adds open method to the deserializationschema and serializationschema. it gives users access to metrics. moreover it adds a well defined step in the lifecycle to perform initialization. it also updates kafka, kinesis, pubsub and gcp connectors to call the method. check tests in corresponding connectors. the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (yes / no / don't know) </desc> <cmt> [flink-17306] added open to deserializationschema </cmt> <cmt> [flink-17306] add open to kafkadeserializationschema </cmt> <cmt> [flink-17306] add open to kinesisdeserializationschema </cmt> <cmt> [flink-17306] add open to pubsubdeserializationschema </cmt> <cmt> [flink-17306] call open of deserializationschema in rmq </cmt> <cmt> [flink-17306] add open to serializationschema </cmt> <cmt> [flink-17306] add open to kafkaserializationschema </cmt> <cmt> [flink-17306] add open to kinesisserializationschema </cmt> <cmt> [flink-17306] call open of serializationschema in pubsub sink </cmt> <cmt> [flink-17306] call open of serializationschema in rmq sink </cmt>",add open method to (de)serializationschema
92,"<desc> fixes #19074 this change disables image lazy-loading when both of the following are true: a image is being rendered following a client-side page transition the image has been previously loaded during this session. before this change, all images with lazy-loading enabled have a visible flicker during client-side page transitions, even though they're already loaded. with this change, there's are two performance risks: there's a chance that some offscreen images will have lazy-loading disabled unnecessarily because they were previously loaded. i think the performance hit here is pretty negligible and the situation is unlikely to come up very often. there's a chance a different-sized version of the image will be selected by the browser, but lazy-loading will be disabled anyway. this seems even more unlikely to me, and anyway the performance hit from a stray un-lazy-loaded image (on a client-side transition) is very minor. in both cases, i think the performance risk is outweighed by the ux improvement of getting rid of the image flicker on page transition. </desc> <cmt> don't lazy-load already-loaded image in csr </cmt> <cmt> fixes 19074 </cmt> <cmt> scope change to client-side only </cmt> <iss> [next/image] repeated images rerender on every page switch. </iss>",don't lazy-load already-loaded image in client-side transition
93,"<desc> closes #38053 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry i think if we are at this place and len(values) is 1, we want to return a scalar instead of a series. this happens only because loc is a slice (0,1) with one multiindex level instead of a scalar. should i create a file to move all multiindex at tests to the multiindex folder? </desc> <cmt> fix at bug </cmt> <cmt> add test and whatsnew </cmt> <iss> bug: calling at[] on a series with a single-level multiindex returns a series, not a scalar </iss>",series.at returning series with one element instead of scalar
94,"<desc> when storing renderer process callbacks in the main process, there are two keys for one remote object: 1) the webcontents id and 2) the object id. this pr extends the idweakmap to accept arbitrary key type so it is possible to use two ids as key, instead of relying on hacks to merge two ids into one id. close #5476. </desc> <cmt> remove unused methods of idweakmap </cmt> <cmt> add keyweakmap without add method </cmt> <cmt> fix leak when keyweakmap::remove is called directly </cmt> <cmt> usually the keyobject would be destroyed when gc happens, but then </cmt> <cmt> remove is called before gc happens, the keyobject would be leaked </cmt> <cmt> forever. this fixes it by keeping keyobject as a member of map. </cmt> <cmt> make keyweakmap a template class </cmt> <cmt> remove idweakmap </cmt> <cmt> use create function instead of idweakmap constructor </cmt> <cmt> turn api::idweakmap into api::keyweakmap<t> </cmt> <cmt> move createidweakmap to v8util </cmt> <cmt> use doubleidweakmap for |rendererfunctions| </cmt>",extend the idweakmap to accept arbitrary key type
95,"<desc> bug fixes apis make paddle.to_tensor() copy if data is varbase, so the computation graph is splited from which of data. make the  stop_gradient of input(data) not changed </desc> <cmt> fix stop_gradient in paddle.to_tensor </cmt> <cmt> make to_tensor copy if data is varbase </cmt>",make paddle.to_tensor() copy if data is tensor
96,"<desc> this pr adds a new pipeline to ci for testing builds under cuda 11.0. the new pipeline (""unix-gpu-cu110"") is triggered by the full-build when the sanity build completes. </desc> <cmt> add new docker containers for cuda 11.0 and libcudnn8. </cmt> <cmt> add new functions for running gpu builds and tests in new cuda11 containers. </cmt> <cmt> add runtime functions for cuda 11.0 related builds/tests. </cmt> <cmt> add new pipeline for testing cuda 11.0 builds. </cmt>",add new ci pipeline for building and testing with cuda 11.0.
97,"<desc> the typedefs for pushcontainer and unshiftcontainer were missing. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add typedef for container modification methods </cmt> <cmt> add typedef for unshiftcontainer() and pushcontainer(). these methods </cmt> <cmt> are used to insert nodes into a list of nodes (container) owned by the </cmt> <cmt> current node. </cmt> <cmt> add tests for typdefs of push/unshift container </cmt> <cmt> add ""dean l"" to definitions author list </cmt>",add typedef for push/unshift container
98,"<desc> refactoring no if relevant, link to documentation update: n/a summary getexports was returning 2 types of shape which could force its caller to deopt. this also was the case for identtoloaderrequest no </desc> <cmt> prevent identtoloaderrequest to return 2 objects with different shapes </cmt> <cmt> unify dependency#getexports result </cmt> <cmt> ensure the type of the binding don't change </cmt>",use a single object shape for dependency exports
99,"<desc> as discussed in #6, the following pr adds a cli for mermaid which is exposed as a mermaid command when installed globally, via npm install -g mermaid. mermaid will look for the phantomjs command in your path and give helpful errors if it's not found, or is too old. additionally, you can specify the path to phantomjs with the -e switch. otherwise, functionality is identical to my mermaid-cli package, which will be deprecated once this pr is accepted and a new version including the cli is published. then, we can focus on improvements here! </desc> <cmt> adds cli for rendering mermaid files </cmt> <cmt> adds cli tests </cmt> <cmt> adds cli information to the readme. </cmt> <cmt> better information around cli's phantomjs requirement </cmt> <cmt> make obvious that readme known issues section is for the cli </cmt>",adds command line interface for generating pngs from mermaid description files
100,"<desc> related to #20822 previously, in pr #20822, i edited a small typo in the phrase ""where n_samples in the number"" by updating it to ""where n_samples is the number"". this pr: edits new instances of the same typo caught by grep-searching for a version of the phrase where the parameter, n_samples, is enclosed in backticks: git grep 'where n_samples in' . adds backticks to cases of n_samples (also n_features, n_components) in a docstring that don't have them: n_samples -> n_samples . i believe this catches all last cases of the typo. please let me know if anything can be added or changed. </desc> <cmt> add backticks to mentions of ""n_sample"" (and other nearby parameters) inside of a docstring. </cmt> <cmt> edit instances captured by git grep with the typo: 'where n_samples in' rather than 'where n_samples is'. </cmt>","doc replace the phrase ""where n_samples in the number"" with ""where n_samples is the number"""
101,"<desc> fixes #20699 adds a feature to 'passthrough' to pass the features without a transformation and added test and documentation for it. changes made in featureunion._validate_transformers() to allow 'passthrough' changes made in featureunion._iter() to use functiontransformer(none) in place of passthrough to represent the identity transformer. added featureunion._passthrough_function() which returns a functiontransformer(none) with get_feature_names set. this separate function is needed as the functiontransformer class does not have a get_feature_names function which is needed by featureunion. wrote a test function test_set_feature_union_passthrough() to test the functionality. it may be better to check if more than one transformers are not set to passthrough as having a repetition of  the same features is redundant. </desc> <cmt> add support for passthrough in featureunion </cmt> <cmt> add tests for passthrough </cmt> <cmt> add documentation for passthrough </cmt> <iss> support ""passthrough"" in featureunion </iss>",enh add support for 'passthrough' in featureunion
102,"<desc> reading the pagination page, i came across a couple of typos and grammar changes. changed ""loosing"" to ""losing"" changed ""usecases"" to ""use cases"" </desc> <cmt> fix minor typo on pagination documentation </cmt> <cmt> also fix usecases to use cases </cmt>",some minor typos and grammar changes.
103,"<desc> description: use previously stored brightness when turning on light. this is mostly useful with homekit, since it calls turn_on and brightness changes as two separate calls. removed manually handled states because newer library can return states reliably when update() is called. checklist: local tests pass with tox. your pr cannot be merged unless tests pass new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> remember last brightness value and use it on turn_on() </cmt> <cmt> pyfnip-0.2 now returns state reliably, no manual changes needed. </cmt> <cmt> split too long line of code </cmt> <cmt> updated pyfnip library version </cmt>",make futurenow light remember last brightness when turning on
104,"<desc> continuation of #4167. had to merge that one because the changes to the data files made github unable to handle the diff. this pr builds on top of @polm's work and adds the basic scaffolding for a lookups class (available via vocab.lookups). see #3971 for more details. for consistency, i've also converted all lemmatizer data to json. the json resources can be provided as relative paths in the language defaults, and the lookups takes care of the rest. this lets us avoid a lot of code duplication in the language classes. it will also make it much easier going forward to implement serialization methods and later move the large data files out of the core library and only include them with the model packages. of course, the ultimate goal is to replace the current dict-based lookups with a more efficient implementation (see #3971). having the basic scaffolding in place should make this easier. also, some package size stats (installation on disk from sdist): without compression: 262 mb with compression: 18.1 mb enhancement todo serialization methods docstrings fix serialization issue that seems to cause vocab bytes mismatch on python <= 3.5 (see failing tests) more tests test building a wheel and make sure compression happens i have submitted the spacy contributor agreement. </desc> <cmt> improve load_language_data helper </cmt> <cmt> wip: add lookups implementation </cmt> <cmt> start moving lemma data over to json </cmt> <cmt> wip: move data over for more languages </cmt> <cmt> convert more languages </cmt> <cmt> fix lemmatizer fixtures in tests </cmt> <cmt> finish conversion </cmt> <cmt> auto-format json files </cmt> <cmt> fix test for now </cmt> <cmt> make sure tables are stored on instance </cmt> <cmt> update docstrings </cmt>",basic lookup class scaffolding and json for all lemmatizer data
105,<desc> replace dedicated method with typecheckchildindependently always setting the closest possible declaration context for type-check call. this fixes a problem where sub-expression comes from multiple levels or nested closures but csdiag didn't re-typecheck parent closure. resolves: rdar://problem/50869732 </desc> <cmt> [csdiag] always find and set correct declaration context for sub-expression type-check </cmt> <cmt> replace dedicated method with typecheckchildindependently always </cmt> <cmt> setting the closest possible declaration context for type-check call. </cmt> <cmt> this fixes a problem where sub-expression comes from multiple levels </cmt> <cmt> or nested closures but csdiag didn't re-typecheck parent closure. </cmt> <cmt> resolves: rdar://problem/50869732 </cmt> <cmt> (cherry picked from commit a5df7862636a303828cee724c6b779bc77280f65) </cmt> <cmt> [typechecker] nfc: add a test-case for rdar://problem/50869732 </cmt> <cmt> (cherry picked from commit 4fdc9fffe8552a1f7c6d5b76031511d8de988c80) </cmt>,always find and set correct declaration context for sub-expr type-check
106,"<desc> this pr fixes issue #1816 . qstring::number doesn't support displaying -0.0, so i converted all usages on the gui to tofloatstring/todoublestring. this fixes the floating point display in the mmx/xmm/ymm editor, in the registers view in simd float/double mode, and in the watch window for floating point type watchpoints. to support this all void* buffer based stringutil functions are now const correct, and tofloatstring/todoublestring got an optional precision parameter, which is set to the previously used value by default. one noteable change is that todoublestring has 15 digits of precision by default, while qstring::number only had 6 (the same as tofloatstring has). with the new precision parameter we can set it back to 6 if necessary, but i think the more precision the better the only place where the added precision could cause problems is the newly added simd mode of the registersview, @torusrxxx could you also take a look to see if it matches your design for displaying the fpu registers? </desc> <cmt> gui: make stringutil void* buffer functions const-correct </cmt> <cmt> gui: add precision support to tofloatstring and todoublestring </cmt> <cmt> gui: fix -0.0 float display by converting with stl instead of qstring::number </cmt>",fix negative zero floating point display
107,"<desc> this is a slightly premature first cut of the rama u80-a implementation. doing a pr now so @jackhumbert and @yiancar can see the is31fl3736 driver implementation and discuss ideas about merging with the is32fl3733 driver. </desc> <cmt> initial commit of rama u80-a </cmt> <cmt> initial commit of rama u80-a </cmt> <cmt> moved is31fl3736 driver, minor cleanups </cmt> <cmt> superficial stuff </cmt>","rama u80-a, wilba.tech wt60-a, wt65-a, wt80-a, is31fl3736 driver"
108,"<desc> this simplifies check_is_fitted to error if no fitted attribute is found. this clearly is less strict than what we had before, but i did not need to change any tests, so according to our tests (i.e. the guaranteed functionality), this implementation is as good as the previous one. the main motivation for this change is to allow us to reduce boiler-plate in the future. if we introduce a validation method as in #13603, we could now include the check_is_fitted there. </desc> <cmt> make check_is_fitted not take attributes </cmt> <cmt> cleanup, remove any_or_all </cmt> <cmt> fix lof, birch, mixtures </cmt>",simplify check_is_fitted to use any fitted attributes
109,"<desc> before this patch, a fling of a scrollable will end up recommending deferred loading, but not a similarly large (or larger) jumpto. this adds an _impliedvelocity field to scrollposition that tracks how many pixels were forced in a single frame, and adds that to the activity's velocity when asking the scrollphysics whether we should defer. related issues fixes #64124 i added the following tests: test that this works as expected when using jumpto with large values. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> deferred loading for jumpto/forcepixels </cmt> <cmt> doc and test </cmt> <iss> scrollcontroller.jumpto() at top causes a surge in memory </iss>",make large jumpto recommend deferred loading
110,<desc> handwired/arrow_pad: layout macro and keymap refactor layout macros moved from the keymaps to arrow_pad.h. layout_pad21 refactored to only accept keys that are physical present (no kc_no entries required in keymap) keymaps now use #include qmk_keyboard_h keymaps refactored to use process_record_user function (from action_get_macro) handwired/arrow_pad: readme cleanup fixed the make commands and updated the layout macro. handwired/arrow_pad: configurator support </desc> <cmt> handwired/arrow_pad: layout macro and keymap refactor </cmt> <cmt> - layout macros moved from the keymaps to arrow_pad.h. </cmt> <cmt> - layout_pad21 refactored to only accept keys that are physical present (no kc_no entries required in keymap) </cmt> <cmt> - keymaps now use #include qmk_keyboard_h </cmt> <cmt> - keymaps refactored to use process_record_user function (from action_get_macro) </cmt> <cmt> handwired/arrow_pad: readme cleanup </cmt> <cmt> fixed the make commands and updated the layout macro. </cmt> <cmt> handwired/arrow_pad: configurator support </cmt>,handwired/arrow_pad refactor and configurator support
111,<desc> they are either tst_<name> with: def test_ip_<name>(): for t in [types]: tst_<name>(t) or test_<name> + test_<name>_<other thing>. </desc> <cmt> tst: use pytest for some already-parametrized tests. </cmt> <cmt> tst: parametrize print tests. </cmt>,use pytest for some already-parametrized core tests
112,"<desc> this fixes tooltips for scatter and bubble charts. also made the scatter chart a first class chart type so that you can create one (with the correct default) by doing var mychart = new chart(ctx, { type: 'scatter', data: [], options: {} }); </desc> <cmt> update default tooltip callbacks for bubble charts </cmt> <cmt> update default tooltip configs for scatter charts. made scatter charts a first class chart type. </cmt> <cmt> remove commented code </cmt>",fixes scatter and bubble chart tooltips
113,"<desc> for #6331. as discussed. </desc> <cmt> pass test metadata in via an environment variable. </cmt> <cmt> [only works on the server right now, fairly uselessly] </cmt> <cmt> for #6331 </cmt> <cmt> pass test metadata through to the client via meteorenv </cmt> <cmt> for #6331 </cmt>",fix meteor istest for packages 6331
114,"<desc> changed _url_pattern in language/tokenizer_exceptions.py, using url regex validation pattern from:  this change will screen out a number of patterns that are not urls as well as picking up some patterns that were missed. test cases were added to test_urls to expose the issue and validate the fix. types of changes new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. </desc> <cmt> issue #840 - url pattenr too broad </cmt> <cmt> fix error in test case parameterization </cmt>",fix for issue #840 - url pattern too broad
115,"<desc> epe-1551 add test cases for cleos new option --abi-file that was added in pr#10821 to specify one or more local abi files for cleos for serialzation/deserialization offline, which doesn't require nodeos rpc endpoint. select one: select any that apply: </desc> <cmt> trigger build </cmt> <cmt> fix flaky test </cmt> <cmt> fix flaky test </cmt> <cmt> test malicious abi </cmt>",add a test for cleos new option --abi-file
116,"<desc> this pr aims to add more cnn models to benchmark scripts like squeezenet and mobilenet and make it more user-friendly. also add a cnn benchmark script for gluon. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change add 'inception-v4', 'inception-resnet-v2', 'mobilenet', 'densenet121', 'squeezenet1.1' to benchmark_score.py add '--network' to script for specific and run all models by default to keep same with before. add '--batch-size' to script for specific and run [1, 2, 4, 8, 16, 32] by default to keep same with before. add script for gluon to benchmark more cnn models. 'densenet121', 'squeezenet1.1' in benchmark_score are converted from gluon in order to cover more cases. these models are benefit a lot from #12530 @pengzhao-intel @juliusshufan </desc> <cmt> add models to cnn benchmark </cmt> <cmt> improve benchmark score </cmt> <cmt> add benchmark_gluon </cmt> <cmt> improve lint </cmt> <cmt> improve lint </cmt>",add more models to benchmark_score
117,"<desc> prevents logic bugs where kscopedschedulerlock{kernel}; is written instead of: kscopedschedulerlock lock{kernel}; from slipping through silently. now the compiler is obliged to warn about cases like that. </desc> <cmt> k_scheduler: mark kscopedschedulerlock as [[nodiscard]] </cmt> <cmt> prevents logic bugs like: </cmt> <cmt> kscopedschedulerlock{kernel}; </cmt> <cmt> instead of: </cmt> <cmt> kscopedschedulerlock lk{kernel}; </cmt> <cmt> from slipping through. </cmt> <cmt> k_scoped_lock: mark class as [[nodiscard]] </cmt> <cmt> prevents logic bugs of the kind described in the previous commit from </cmt> <cmt> slipping through. </cmt> <cmt> k_scoped_lock: delete copy and move assignment operators </cmt> <cmt> if we delete the copy and move constructor, we should also be deleting </cmt> <cmt> the copy and move assignment operators (and even if this were intended, </cmt> <cmt> it would be pretty odd to not document why it's done this way). </cmt>",mark lock helper classes as [[nodiscard]]
118,"<desc> when queue.get is called on an empty queue, previously we would block until something was put into the queue, and similarly when calling queue.put on a full queue we would block until space was created.  this pr provides async get and put methods so that other computations can be done during this blocking situation. when putting or getting large numbers of small items into the queue, serialization overhead becomes significant.  previously, there would be a remote call for each item.  this pr provides batched put and get methods, so there is only one remote call for each batch. this pr also cleans up and adds more details to the documentation. the batched put and get methods are sync and don't support blocking as described above.  this seems appropriate for the use case of, say, quickly grabbing or dumping 10000 strings from the queue.  a future pr could provide async versions of the batched put and get, and an option for blocking for batched put and get. closes #11162. closes #11443. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> expand docstring </cmt> <cmt> add batch put and get, and async put and get </cmt> <cmt> add tests </cmt> <cmt> lint </cmt> <iss> [util] queue should support batching </iss> <iss> [doc] add documentation for ray.util.queue.queue </iss>",add queue async and batch methods
119,<desc> this pr fixes #101834 // </desc> <cmt> enable sandbox for issue reporter and process explorer (fix #101834) </cmt> <cmt> sandbox - enable vscode-file protocol for sandboxed renderers </cmt> <cmt> issues - stop setting nodecacheddatadir </cmt> <iss> enable sandbox for issue reporter and process explorer </iss>,"enable sandbox, contextisolation and vscode-file for process explorer and issue reporter"
120,"<desc> this is a rebased branch based on development per #971 conditional integration is an adaptive limit on the integral term that prevents accumulation when the proportional or other terms would saturate the heater output.  this helps avoid overshoot by not winding up the integral when starting pid control far from the setpoint. see the discussion under the #971 issue for more information. </desc> <cmt> getting even with v1 </cmt> <cmt> update readme.md </cmt> <cmt> heater.c: limit pid i term with conditional integration. </cmt> <cmt> temperature.cpp:add pid conditional integration on heated bed. </cmt> <cmt> configuration.m: set pid_integral_drive_max from pid_max from bang_max. </cmt> <cmt> current defaults are all 255.  if it makes sense to reduce them, they should come down together, and </cmt> <cmt> be in a  pid_integral_drive_max <= pid_max <- bang_max relationship. </cmt>",add conditional integration to prevent excessive integral windup
121,"<desc> i hereby agree to the terms of the cla available at:  documentation for #7974 changelog category: changelog entry: deleted descriptions for settings allow_experimental_data_skipping_indices, allow_experimental_cross_to_join_conversion and allow_experimental_multiple_joins_emulation. removed duplicated description for join_any_take_last_row. </desc> <cmt> clickhousedocs-511: removed obsolete settings. </cmt> <cmt> clickhousedocs-511: removed duplication for ## join_use_nulls {#join_use_nulls}. </cmt>",deleted some experimental settings. removed duplicated description for join_any_take_last_row.
122,<cmt> sqlite.connection type now implements gc protocol </cmt> <cmt> sqlite.cursor type now implements gc protocol </cmt> <cmt> sqlite.row type now implements gc protocol </cmt> <cmt> sqlite.prepareprotocol type now implements gc protocol </cmt> <cmt> sqlite.statement type now implements gc protocol </cmt> <cmt> sqlite3.cache and sqlite3.node types now implements gc protocol </cmt>,fully implement gc protocol for sqlite3 heap types
123,"<desc> hello friends ran into this bug on our production site, prerendermanifest stores revalidation info for the index as ""/"": { .. }, but the code tries to access this information as ""/index"". this leads to our index page always having s-max-age: 1 </desc> <cmt> use route for prerender manifest path </cmt> <cmt> delete test artifact </cmt>",wrong index path revalidation timer
124,"<desc> adds a new long running multi-node release test for distributed training and testing. will be useful for identifying issues with raysgd and tune fault tolerance before each release. addresses #2877 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> adding long running distributed tests </cmt> <cmt> adding documentation </cmt> <cmt> formatting </cmt> <cmt> updating documentation </cmt> <cmt> updating documentation </cmt> <cmt> more documentation fixes </cmt>",multi-node training+tune long running test
125,"<desc> @martijnvg @talevy i've made some edits to the ingest node doc (sorry to get these in rather late, but elasticon and the all-hands got in the way). can you take a quick look and confirm that the changes are ok? summary of changes: added some explanatory text around concepts (mostly in the intro) that i thought needed a bit more context. tried to remove passive voice where it made the sentence harder to read added some headings to break up long bits of text added ids to sections (otherwise, the generated html pages get renamed whenever we change the heading text). fixed sentences that were ambiguous </desc> <cmt> ingest node edits </cmt> <cmt> edits to ingest plugin docs </cmt>",add edits to the ingest doc
126,"<desc> reintroduces #21527 (which was reverted in #21723). extra fixes on top of the old pr: update third_party/boringssl-with-bazel to the freshest master-with-bazel to bring fix for #21733 avoid async_end2end_test failures under msan (the issue has been investigated in #21722 and it turned out the only problem is that the test is too slow for 4mb messages when msan is enabled) fixes #21733 </desc> <cmt> revert ""revert ""unify boringssl submodules and use non-developer boringssl cmake build"""" </cmt> <cmt> this reverts commit fe2242e603c341833a67f33e49fe7189ab5f9fd6. </cmt> <cmt> update third_party/boringssl-with-bazel, check_submodules.sh and grpc_deps.bzl </cmt> <cmt> run tools/distrib/generate_grpc_shadow_boringssl_symbol_list.sh </cmt> <cmt> regenerate projects </cmt> <cmt> avoid async_end2end_test timeout on msan </cmt> <iss> boringssl-with-bazel cannot compile shared lib </iss>",reintroduce #21527 (boringssl submodule unification)
127,"<desc> checklist for the pandas documentation sprint (ignore this if you are doing an unrelated pr): pr title is ""doc: update the  docstring"" the validation script passes: scripts/validate_docstrings.py <your-function-or-method> the pep8 style check passes: git diff upstream/master -u -- ""*.py"" | flake8 --diff the html version looks good: python doc/make.py --single <your-function-or-method> it has been proofread on language by another sprint participant please include the output of the validation script below between the """" ticks: ################################################################################ ####################### docstring (pandas.dataframe.mod) ####################### ################################################################################ modulo of dataframe and other, element-wise (binary operator mod). equivalent to dataframe % other, but with support to substitute a fill_value for missing data in one of the inputs. parameters ---------- other : series, dataframe, or constant axis : {0, 1, 'index', 'columns'} for series input, axis to match series index on level : int or name broadcast across a level, matching index values on the passed multiindex level fill_value : none or float value, default none fill existing missing (nan) values, and any new element needed for successful dataframe alignment, with this value before computation. if data in both corresponding dataframe locations is missing the result will be missing notes ----- mismatched indices will be unioned together returns ------- result : dataframe examples -------- >>> a = pd.dataframe([2, 4, np.nan, 6.2], index=[""a"",""b"",""c"",""d""], ...                  columns=['one']) >>> a one a   2.0 b   4.0 c   nan d   6.2 >>> a.mod(3, fill_value=-1) one a   2.0 b   1.0 c   2.0 d   0.2 >>> b = pd.dataframe(dict(one=[np.nan, 2, 3, 14], two=[np.nan, 1, 1, 3]), ...                  index=['a', 'b', 'c', 'd']) >>> b one   two a   nan   nan b   2.0   1.0 c   3.0   1.0 d   14.0  3.0 >>> c = pd.dataframe(dict(one=[np.nan, np.nan, 6, np.nan], ...                       three=[np.nan, 10, np.nan, -7]), ...                  index=['a', 'b', 'd', 'e']) >>> c one three a   nan nan b   nan 10.0 d   6.0 nan e   nan -7.0 >>> b.mod(c, fill_value=3) one   three two a   nan   nan   nan b   2.0   3.0   1.0 c   0.0   nan   1.0 d   2.0   nan   0.0 e   nan  -4.0   nan see also -------- dataframe.rmod ################################################################################ ################################## validation ################################## ################################################################################ errors found: use only one blank line to separate sections or paragraphs errors in parameters section parameter ""other"" has no description parameter ""axis"" description should finish with ""."" parameter ""level"" description should finish with ""."" parameter ""fill_value"" description should finish with ""."" missing description for see also ""dataframe.rmod"" reference if the validation script still gives errors, but you think there is a good reason to deviate in this case (and there are certainly such cases), please state this explicitly. i only added  the examples. these errors were present before i added the examples. </desc> <cmt> doc: update the index.isin docstring (#20249) </cmt> <cmt> doc: added examples to dataframe.mod docstring </cmt> <cmt> removed trailing whitespace </cmt>",update the examples to dataframe.mod docstring
128,<desc> this pr extracts common logic from codepushcore and moves it to codepushbasecore that could be used as parent class for all codepush platforms implementations. also contains minor improvements and fixes. </desc> <cmt> extract several methods to codepushbasecore </cmt> <cmt> extract more methods from codepushcore </cmt> <cmt> add more methods for basecodepushcore </cmt> <cmt> change field visibility </cmt> <cmt> minor fixes </cmt> <cmt> fix visibility </cmt> <cmt> minor improvements </cmt> <cmt> minor improvements </cmt>,transit common logic from codepushcore to codepushbasecore
129,<desc> run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  closes #32900 </desc> <cmt> fix engineversion result type </cmt> <cmt> closes #28133 </cmt> <cmt> closes #27984 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add missing qstatename ro objectlayout </cmt> <cmt> closes #32900 </cmt> <cmt> update nxlibrarydimensiondef </cmt> <cmt> fix missing qlabelexpression </cmt> <iss> [@types/qlik-engineapi] extend definition of interface igenericobjectlayout </iss>,fix engine api missing fields
130,<desc> reduces checkstyle errors for patterns: dao data-bus data-locality data-mapper data-transfer-object decorator changes involved java docs reordering imports indentations line length issues </desc> <cmt> reduces checkstyle errors in dao </cmt> <cmt> reduces checkstyle errors in data-bus </cmt> <cmt> reduces checkstyle errors in data-locality </cmt> <cmt> reduces checkstyle errors in data-mapper </cmt> <cmt> reduces checkstyle errors in data-transfer-object </cmt> <cmt> reduces checkstyle errors in decorator </cmt>,resolves checkstyle errors for dao data-bus data-locality data-mapper data-transfer-object decorator
131,"<desc> force curly braces for one-line control elements (eg. if (true) return ""a"" => if(true) { return ""a"" } prohibit single if/else in else branch f.ex.: if(true){} else{ if(false){} else{} } unignored lib/app/store.js </desc> <cmt> lint: add curly and no-lonely-if </cmt> <cmt> lint: add lib/app/store.js to eslint config </cmt>","force if braces, no lonely ifs and add store.js"
132,"<desc> add some bitmap images to our zipfldr shell extenson. ms version of this has them, but our one currently hasn't. and i think without bitmaps the wizard dialogs look a bit incompleted. i made them similar to ms bitmaps. they have exactly the same size (height x width), but looks differently, in reactos tango style. jira issue: core-17092 add the resource bitmaps into res directory; add accodring definitions into resource.h; enable the bitmaps in zipfldr.rc using the definitions numbers; enable the first bitmap (zipfldr1.bmp) in the idd_proppagedestination and idd_proppagecomplete wizard dialogs for all localizations; fix controls posision of those dialogs after adding the bitmaps same for all localizarions. enable the 2nd bitmap (zipfldr2.bmp) at the right top of the wizard dialogs, same as it done in ms implemetation. (where i need to properly enable it if it should be outside those dialogs, probably near the caption instead of the begin...end section?) also i haven't used the 3rd bitmap (zipfldr3.bmp) anywhere, since the dialog which uses it is not currently implemented in our zipfldr, compared to ms version. so i only added it as a resource file. result before: after: win2k3 zipfldr (for comparison): </desc> <cmt> [zipfldr] add some bitmap resources </cmt> <cmt> [zipfldr] enable zipfldr1.bmp in some wizard pages </cmt> <cmt> update all localizations accordingly </cmt> <cmt> [zipfldr] fix controls position for all localizations </cmt>",add some bitmap resources core-17092
133,"<desc> original pull requests: #3497, #3695, #3698, #3699, #3704, #3723, #3735. </desc> <cmt> fix memory leaks appearing when cvopenfilestorage throws </cmt> <cmt> (cherry picked from commit 16ce114e0cad6c85efead4a0ebb07724d691407a) </cmt> <cmt> cvopenfilestorage: reduce the scope of xml_buf and make sure it's freed... </cmt> <cmt> ... before any exceptions occur. </cmt> <cmt> (cherry picked from commit 08da247a871ed40b868119a999af538da6526c6d) </cmt> <cmt> don't install documentation if it isn't built </cmt> <cmt> the have_doc_generator variable was always true. </cmt> <cmt> (cherry picked from commit 3d46c1f9602bea7e6c6a49db8b6f2421166ef65d) </cmt> <cmt> conflicts: </cmt> <cmt> doc/cmakelists.txt </cmt> <cmt> fix a memory leak in cvcapture_ffmpeg::close </cmt> <cmt> ffmpeg now requires that frames allocated with avcodec_alloc_frame are </cmt> <cmt> freed with avcodec_free_frame. </cmt> <cmt> (cherry picked from commit 77578d415f4d2b22a4ee1989ef0afda73c9d649b) </cmt> <cmt> conflicts: </cmt> <cmt> modules/highgui/src/cap_ffmpeg_impl.hpp </cmt> <cmt> remove useless cpack_*_component_install variables </cmt> <cmt> they don't actually do anything. and even if they did, all components are </cmt> <cmt> enabled by default, anyway. </cmt> <cmt> (cherry picked from commit 49fe496914cca93f19dd61aa7b1c120037d65282) </cmt> <cmt> conflicts: </cmt> <cmt> cmake/opencvpackaging.cmake </cmt> <cmt> install data on windows </cmt> <cmt> because why not? </cmt> <cmt> (cherry picked from commit e8a73940099b9823879e156a896e42a1854ca1bb) </cmt> <cmt> conflicts: </cmt> <cmt> data/cmakelists.txt </cmt> <cmt> add a script to run all tests on windows </cmt> <cmt> it's pretty much a simplified copy of the linux script, lacking fancy colors. </cmt> <cmt> also, i had to drop python testing, because it's not easy to pass the python </cmt> <cmt> module location to the script, and i have no pressing need to run the python </cmt> <cmt> tests at the moment. </cmt> <cmt> (cherry picked from commit c1e3ca170e6acd983fc010bffd6bc10f12a738c5) </cmt> <cmt> conflicts: </cmt> <cmt> cmakelists.txt </cmt> <cmt> update the cpack variables to match the changes in asmorkalov/cmake#1 </cmt> <cmt> which also happens to align the non-debian specific variables </cmt> <cmt> with the ones used by upstream cmake. </cmt> <cmt> (cherry picked from commit b8c60234c3fa94c31a3e2a72275fefa811c75d5c) </cmt> <cmt> conflicts: </cmt> <cmt> cmake/opencvpackaging.cmake </cmt> <cmt> add component display names </cmt> <cmt> (cherry picked from commit 6d52ea898442d2458a40f8b06b75320c9ab4a5cc) </cmt> <cmt> mark the libs component required </cmt> <cmt> everything else depends on it, after all. </cmt> <cmt> (cherry picked from commit cf54e3b97ea13c0aeef5e94b5330a4b26a601d81) </cmt> <cmt> conflicts: </cmt> <cmt> cmake/opencvpackaging.cmake </cmt>",forward-port a bunch of my changes from 2.4
134,"<desc> see #32515 (comment). had to limit typescript version to 2.1+, because magic-strinc use partial: add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> improve(buble): prefer use ""sourcemap"" type from official package, instead of manually defining it </cmt> <cmt> fix(buble): ""tourl()"" is a method, not a property </cmt>",use sourcemap type from magic-string package
135,"<desc> what do these changes do? this is a re-implementation of the functionrunner which enforces some synchronicity between the thread running the training function and the thread running the trainable which logs results. the main purpose is to make logging consistent across apis in anticipation of a new function api which will be generator based (through yield statements). without these changes, it will be impossible for the (possibly soon to be) deprecated reporter based api to behave the same as the generator based api. this new implementation provides additional guarantees to prevent results from being dropped. this makes the logging behavior more intuitive and consistent with how results are handled in custom subclasses of trainable. new guarantees for the tune function api: every reported result, i.e., reporter(**kwargs) calls, is forwarded to the appropriate loggers instead of being dropped if not enough time has elapsed since the last results. the wrapped function only runs if the functionrunner expects a result, i.e., when functionrunner._train() has been called. this removes the possibility that a result will be generated by the function but never logged. the wrapped function is not called until the first _train() call. currently, the wrapped function is started during the setup phase which could result in dropped results if the trial is cancelled between _setup() and the first _train() call. exceptions raised by the wrapped function won't be propagated until all results are logged to prevent dropped results. the thread running the wrapped function is explicitly stopped when the functionrunner is stopped with _stop(). if the wrapped function terminates without reporting done=true, a duplicate result with {""done"": true}, is reported to explicitly terminate the trial, but will not be logged. #3956 #3949 #3834 </desc> <cmt> rewrote the function runner to make the logging behavior consistent across both the trainable class apu and the function api. </cmt> <cmt> fixed missing keyword </cmt> <cmt> bug fixes </cmt> <cmt> fixed wrong order in timing calculation </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changed wrapped function to always report done=true before terminating </cmt> <cmt> fixed typo in new function wrapper, fixed some formatting and unused imports </cmt> <cmt> fixed race condition when reporting results in _train and simplified how functions are wrapped </cmt>",make the logging of the function api consistent and predictable
136,"<desc> adds links to flax colabs did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> fix_torch_device_generate_test </cmt> <cmt> remove @ </cmt> <cmt> add colab links </cmt>",add links to google colabs
137,"<desc> fixes #13811 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> tmp. </cmt> <cmt> fixing bc for question answering with long context. </cmt> <iss> attributeerror when running question answering models for result </iss>",fixing question-answering with long contexts
138,"<desc> change due to security concerns, this change disables local manifest files by default. user can still turn on local manifest files through group policy, or through running 'winget settings --enable localmanifestfiles' as administrator. validation added tests. also tested manually. microsoft reviewers: open in codeflow </desc> <cmt> code </cmt> <cmt> tests </cmt>",disable local manifest by default
139,"<desc> currently, the build_type variable of .travis.yml was ignored up to now by travis.sh and the build process. also, while cmake does not complain on build type debug (as listed in .travis.yml currently), the cmake documentation always spells it debug, so take this. using the variable in travis.sh to call cmake -dcmake_build_type=debug leads to the problem reported in issue #1175, i.e. some python driven tests won't find their test executable. the travis build triggered by the first commits here will probably fail; then a fix can be tested and discussed. this pull request fixes #1175 and #1070. </desc> <cmt> use build type set in .travis.yml </cmt> <cmt> the build_type variable of .travis.yml was ignored up to now. </cmt> <cmt> use upper-case build type </cmt> <cmt> while cmake does not complain on build type 'debug', the cmake </cmt> <cmt> documentation always spells it 'debug', so take this. </cmt> <iss> some tests are failing when using the debug configuration (-dcmake_build_type=debug) on debian </iss>",use cmake build type defined in .travis.yml for travis builds
140,<desc> description: quick version push of lupupy to 0.0.17. this will now correctly transmit the state alarm_triggered which can be used in automations etc. </desc> <cmt> added state_alarm_triggered transmission; pushed lupupy version </cmt> <cmt> added state_alarm_triggered transmission; pushed lupupy version </cmt> <cmt> added state_alarm_triggered transmission; pushed lupupy version </cmt> <cmt> added state_alarm_triggered transmission; pushed lupupy version </cmt>,lupupy version push to 0.0.17 - will now transmitted state_alarm_triggered
141,"<desc> the vendored libmpdec has been partially updated in 9b9f158, this completes the update to upstream version 2.5.1. patch provided by stefan krah. </desc> <cmt> complete the update to libmpdec-2.5.1. </cmt> <cmt> add news item </cmt>",finish updating the vendored libmpdec to version 2.5.1
142,<desc> this addresses cleanups asked for in the comments of #9560. @drybjed has tested the code with the examples in his readme and everything passes.  jimi-c and bcoca took a quick look as well.  we're good to merge code-wise. @drybjed will work up a separate pr to document the new filters. </desc> <cmt> add ipaddr() filter plugin </cmt> <cmt> first try at only failing if the filter is actually used. </cmt> <cmt> replace large if-elif-else blocks with a dict-dispatcher </cmt> <cmt> use pass instead of bare none value </cmt> <cmt> better error message </cmt>,modified version of pr 9560
143,<desc> left/right trim/ltrim/rtrim timestampadd/timestampsub other interval-relarted improvements additional case insensitive functions #3712 #3714 #3704 #3705 </desc> <cmt> rewrite left and right functions to corresponding substring calls #3712 </cmt> <cmt> introduce trim/ltrim/rtrim functions #3714 </cmt> <cmt> introduce regexpquotemeta function to properly handle regexp special chars in trim #3714 </cmt>,additional functions for sql compatibility
144,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. @raisedadead per our discussion, i have removed all but the spanish translations in the /docs/i18n folder.  we can download the other languages as they become approved on crowdin. </desc> <cmt> fix: update translations.md </cmt> <cmt> chore: remove chinese, hinit, and italian </cmt>",chore(docs) - remove all but spanish translations
145,"<desc> similar to what was done in #17827, this pr caches the source directory based on the deps file and saves it to a file store that is attached to our windows vms. pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> ci: speed up src retrieval </cmt> <cmt> don't save zip on ia32 </cmt>",speed up windows source retrieval
146,"<desc> updated dark mode colors. text editing menu color is still not correct: #41507. the color of the clear button seems to have changed  in ios 13.1 so might be different from what you see on ios 13.0 devices/simulators. dark light related issues #35541 i added the following tests: dark mode background color updated goldens: flutter/goldens#47 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. </desc> <cmt> remove cupertinosystemcolors </cmt> <cmt> wrong color </cmt> <cmt> update docs </cmt> <cmt> comments </cmt> <cmt> update comments </cmt> <cmt> update tests </cmt> <cmt> s/gray/grey/ </cmt> <cmt> tab scaffold </cmt> <cmt> text selection </cmt> <cmt> text field </cmt> <cmt> update tests </cmt> <cmt> update colors </cmt> <cmt> update </cmt> <cmt> update tests </cmt>","cupertino { tabscafold, textselection, textfield } dark mode & minor fidelity update"
147,"<desc> _convert_scalar_indexer is called with kind=""iloc"" from only one place, and in that case the base class method is equivalent to just the 1-liner self._validate_indexer(""positional"", key, ""iloc"") all subclasses just call the base class method so by inlining that 1-liner, we can take the ""iloc"" case out of _convert_scalar_indexer altogether. kind=none is never passed, so we can rip that right out. ultimately i want to disentable/de-duplicate/disambiguate _convert_scalar_indexer vs _maybe_cast_indexer partial overlap with #31625. </desc> <cmt> inline indexing 1liners </cmt> <cmt> dont pass iloc to convert_scalar_indexer </cmt> <cmt> cln: _convert_scalar_indexer handle only loc and getitem </cmt>","_convert_scalar_indexer only handle ""loc"" and ""getitem"""
148,"<desc> this ensures that we write a short log message to the journal whenever we forcibly kill processes remaining in a scope or service after execstop= or the clean signal sending completed. most importantly, log about all services we kill due to logind's killuserprocess= setting on logout. as suggested on the fedora ml. </desc> <cmt> logind: minor coding style improvements </cmt> <cmt> util: don't send sigcont following a sigcont or sigkill in kill_and_sigcont() </cmt> <cmt> core: when forcibly killing/aborting left-over unit processes log about it </cmt> <cmt> let's lot at log_notice about any processes that we are going to </cmt> <cmt> sigkill/sigabrt because clean termination of them didn't work. </cmt> <cmt> this turns the various boolean flag parameters to cg_kill(), cg_migrate() and </cmt> <cmt> related calls into a single binary flags parameter, simply because the function </cmt> <cmt> now gained even more parameters and the parameter listed shouldn't get too </cmt> <cmt> long. </cmt> <cmt> logging for killing processes is done either when the kill signal is sigabrt or </cmt> <cmt> sigkill, or on explicit request if kill_terminate_and_log instead of log_terminate </cmt> <cmt> is passed. this isn't used yet in this patch, but is made use of in a later </cmt> <cmt> patch. </cmt> <cmt> cgroup: suppress sending follow-up sigcont after sending sigcont/sigkill anyway </cmt> <cmt> core: make sure requeststop signal is send directed </cmt> <cmt> this was accidentally left commented out for debugging purposes, let's fix that </cmt> <cmt> and make the signal directed again. </cmt> <cmt> core: when a scope was abandoned, always log about processes we kill </cmt> <cmt> after all, if a unit is abandoned, all processes inside of it may be considered </cmt> <cmt> ""left over"" and are something we should better log about. </cmt> <cmt> logind: always abandon session scopes before killing them </cmt> <cmt> this way systemd is informed that we consider everything inside the scope as </cmt> <cmt> ""left-over"", and systemd can log about killing it. </cmt> <cmt> with this change systemd will log about all processes killed due to the session </cmt> <cmt> clean-up on killuserprocesses=yes. </cmt>",log about all processes we forcibly kill
149,"<desc> as i mentioned the issue #1503 ,i translated index.md to japanese. </desc> <cmt> add ja and translate key feature </cmt> <cmt> translate opinions </cmt> <cmt> translate by document upgrade </cmt> <cmt> translate to end </cmt> <cmt> fix text </cmt> <cmt> translate spoiler alert </cmt>",add japanese translation for index.md
150,"<desc> this provides the ability to specify s3 timeouts via environment variables, as requested in #15868. </desc> <cmt> syncing personal fork to master 20170812 </cmt> <cmt> catching up to master 20170822_1652 </cmt> <cmt> sublime text index-ignore file (a copy of .gitignore) </cmt> <cmt> pull from master-master </cmt> <cmt> syncing to master-master </cmt> <cmt> picking up asim's multidimensional string tensors </cmt> <cmt> catch-up to master-master </cmt> <cmt> merging down master-master </cmt> <cmt> picking up master-master including am's merge-in </cmt> <cmt> merging back from master 20171028 </cmt> <cmt> catch up 20171210 </cmt> <cmt> catchup 20171212 </cmt> <cmt> sync up 20180104 </cmt> <cmt> additions to the s3 filesystem code to allow testing of whether twiddling timeouts will address connectivity issues discussed in #15868 </cmt> <cmt> removing .ignore file from the repository. </cmt>",addresses s3 timeout configurability discussed in #15868
151,"<desc> r? @eddyb @nikomatsakis or whoever else.  the strategy employed here was to essentially change code we generate from %s = alloca %s ; potentially smaller than argument, but never larger %1 = bitcast %s* %s to { i64, i64 }* store { i64, i64 } %0, { i64, i64 }* %1, align 4 to %1 = alloca { i64, i64 } ; the copy of argument itself store { i64, i64 } %0, { i64, i64 }* %1, align 4 %s = bitcast { i64, i64 }* %1 to %s* ; potentially truncate by casting to a pointer of smaller type. </desc> <cmt> fix handling of c arguments </cmt> <cmt> fixes #33868 </cmt> <cmt> add a regression test </cmt>",fix handling of ffi arguments
152,"<desc> includes fixes from #487 and other fixes to try to get the tests to run cleanly.  they still do not. :( fix unclaimed user name for ""insanejournal"". remove ""kiwifarms"".  you now have to be logged in to see any profile. update claimed user name for ""gitee"". do not use api call for ""brew"".  it probably needs to be authenticated now. fix claimed username for ""lor"". update user url for ""zomato"".  site did work before, but it is better to use preferred location. update claimed username for ""toster"". remove ""codementor"".  all usernames come back as unclaimed. fix ""opennet"" claimed username. remove ""easyen"".  as of 2019-12-31, usernames appear to redirect to an internal index. remove ""yandexmarket"".  as of 2019-12-31, all usernames are reported as existing. remove ""ramblerdating"".  as of 2019-12-31, site always times out. fix ""football"" claimed username. </desc> <cmt> fix unclaimed user name for ""insanejournal"". </cmt> <cmt> remove ""kiwifarms"".  you now have to be logged in to see any profile. </cmt> <cmt> update claimed user name for ""gitee"". </cmt> <cmt> do not use api call for ""brew"".  it probably needs to be authenticated now. </cmt> <cmt> fix claimed username for ""lor"". </cmt> <cmt> update user url for ""zomato"".  site did work before, but it is better to use preferred location. </cmt> <cmt> update claimed username for ""toster"". </cmt> <cmt> remove ""codementor"".  all usernames come back as unclaimed. </cmt> <cmt> fix ""opennet"" claimed username. </cmt> <cmt> remove ""easyen"".  as of 2019-12-31, usernames appear to redirect to an internal index. </cmt> <cmt> remove ""yandexmarket"".  as of 2019-12-31, all usernames are reported as existing. </cmt> <cmt> remove ""ramblerdating"".  as of 2019-12-31, site always times out. </cmt> <cmt> fix ""football"" claimed username. </cmt> <cmt> update version and site list. </cmt>",more fixes to site coverage
153,"<desc> description: the current generation of homekit accessories do not show the dash in the pin code on the label that is in the box. so the pairing ui should accept the pin code with and without dashes. it should only pass pin codes with dashes to the underlying library, where they are used to seed homekit crypto primitives. the underlying library can also raise homekit.exceptions.malformedpinerror which we should handle and map to an error in strings.json as well. related issue (if applicable): fixes #25933 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> handle malformedpinerror from homekit_python </cmt> <cmt> handle both formats of pin codes </cmt> <iss> homekit_controller: accept both dashed and non-dashed pin codes </iss>",accept homekit_controller pairing codes both with and without dashes
154,"<desc> with the ability for json-rpc to set art for items, there's the possibility of art such as ""tvshow.poster"" to be set at the episode level.  we don't want this, as otherwise that particular episode will always have that tvshow poster, even after the user changes the tvshow poster.  this will pollute the database with entries that then need to be manually changed one by one via choose art. to fix this, we store all parent art using the . pattern.  e.g. fanart for tvshows is tvshow.fanart.  this still allows season-specific fanart to be used (they can just specify fanart at the season level) and, indeed, even episode-specific if that's appropriate. to pull this off, we need the normal generic listitem.art(fanart) to drop back to the appropriate art.  thus, we generalise the fallback already available for listitem.art(thumb) to allow other fallbacks.  it happens at fetch time, as otherwise the art map is populated with these items that can't be eliminated. tested with old skins and all fallbacks working.  tested with new skins and all fallbacks working. @montellese, @martijnkaijser the change is subtle, but it will mean that you'll no longer retrieve ""fanart"" and ""thumb"" at the episode or season level, unless they're set at that level.  you'll instead retrieve ""tvshow.fanart"".  same with songs/albums - you'll get artist.fanart and probably also album.thumb rather than thumb at the song level. </desc> <cmt> [art] adds clearart to cguilistitem </cmt> <cmt> [art] use a fallback map for art to generalise the fallback for the 'thumb' type, and set outside of cguilistitem </cmt> <cmt> [art] adds a param to appendart to specify the prefix, and utilise for setting art for children of tvshows, seasons + albums </cmt>","art fallback fixes, and don't save show/album/season art for seasons/songs/episodes"
155,"<desc> added loggers registry require training.logger entry in the config current console logging is defined as default: @loggers = ""spacy.consolelogger.v1"" (additional) logging to weights & biases is supported for those who'd want it (and have wandb installed): @loggers = ""spacy.wandblogger.v1"" project_name = ""my_cool_project"" i added a finalize callback to the logger, which currently isn't doing anything, but i could imagine some (yet to be implemented) other loggers could perhaps require one? so i figured it would be best to already take it into account for the logger api. open questions wandblogger calls into consolelogger so you get both. is there a better way? like providing a list of loggers in the config? i felt like that might overcomplicate the config, while the logger implementations could just take care of this themselves. do we want this wandblogger as part of the core lib, or as part of an example project? (can move it if we prefer) comments about weights & biases w&b is really nice. by uploading the full config (not just the training bit), you can basically filter your runs on whatever training/model parameter you like. this all works pretty much out of the box (graphs are on toy data): w&b also automatically analyses your system, including memory utilization, network traffic, disk io, cpu & gpu, ... i think this will be very useful for looking at the results of our training runs, inspecting gpu usage for the transformer models, etc etc... i have submitted the spacy contributor agreement. </desc> <cmt> quick test as part of train script </cmt> <cmt> train_logger in config, default consolelogger in loggers catalogue </cmt> <cmt> entitiy typo </cmt> <cmt> add wandb_logger </cmt> <cmt> cleanup </cmt>",weights & biases logger for train cli
156,"<desc> converted the guidelines/logo page to theme-ui. fixed the responsive layout. local url:  production url:  screenshot(s) before after </desc> <cmt> converted guidelines containers from styled-system to theme-ui </cmt> <cmt> guidelines logo page made responsive </cmt> <cmt> copycolumn sticky styling fixed for responsive </cmt> <cmt> converted list, listitem & dontlistitem to theme-ui </cmt> <cmt> converted css to sx in possible places of guidelines logo page </cmt> <cmt> fixed the linting issue by converting double quotes to backtick </cmt> <cmt> contentcolumn width changed for mobile </cmt> <cmt> updated box and flex to theme-ui </cmt> <cmt> used the box component from theme-ui inside layout </cmt> <cmt> updated the breakpoints </cmt> <cmt> breakpoints updated </cmt>",mobile layout for /guidelines/logo + converted to theme-ui
157,"<desc> transportreplicationaction is a rather complex beast, and some of its concrete implementations do not need all of its features. more specifically, it (a) chases a primary around the cluster until it manages to pin it down and then (b) executes an action on that primary and all its replicas. there are some actions that are coordinated by the primary itself, meaning that there is no need for the chase-the-primary phases, and in the case of peer recovery retention leases and primary/replica resync it is important to bypass these first phases. this commit is a step towards separating the transportreplicationaction into these two parts. it is a mostly mechanical sequence of steps to remove some abstractions that are no longer in use. </desc> <cmt> use channelactionlistener in operationtransporthandler </cmt> <cmt> generic primaryresult </cmt> <cmt> no need for shardreference superclass </cmt> <cmt> use actionlistener instead of channel for primary response handler </cmt> <cmt> use actionlistener instead of channel for replica response handler </cmt> <cmt> use concreteshardrequest throughout asyncprimaryaction </cmt> <cmt> use concretereplicarequest throughout abstractreplicaaction </cmt> <cmt> replace operationtransporthandler with lambda </cmt> <cmt> replace primaryoperationtransporthandler with lambda </cmt> <cmt> replace replicaoperationtransporthandler with lambda </cmt> <cmt> allow subclasses to control whether primary action is forced </cmt> <cmt> today this requires overriding and reimplementing registerrequesthandlers() but </cmt> <cmt> it's clearer to highlight the difference like this </cmt>",remove some abstractions from transportreplicationaction
158,<desc> this pr fixes remark lint warnings for the readme files in the contrib directory. related: #5941 component name docs ~/netdata$ was removed to avoid it being copied to clipboard. </desc> <cmt> fix lint error for debian contrib </cmt> <cmt> remove directory name to avoid direct copy </cmt>,fix remark lint for contrib
159,<desc> detect and diagnose invalid uses of trailing closures - either passed to a parameter which doesn't support that or extraneous e.g. func foo(x: int) {} foo { _ in } // can't pass trailing closure to int foo(x: 42) { _ in } // extraneous trailing closure. resolves: rdar://problem/55102498 </desc> <cmt> [constraintsystem] allow to check presence of fix by kind and locator </cmt> <cmt> [constraintsystem] intoduce a fix for incorrect use of trailing closures </cmt> <cmt> [diagnostics] add a diagnostic for incorrect use of trailing closures </cmt> <cmt> [constraintsystem] use new trailing closure fix in matchcallarguments </cmt> <cmt> [csdiag] nfc: remove obsolete trailing closure diagnostics </cmt>,port invalid trailing closure use diagnostics
160,"<desc> adding descriptions for dozens of apis that did not previously have them. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> testerrorchange </cmt> <cmt> mainly the bindings apis </cmt> <cmt> adding missing documentation for many apis </cmt> <cmt> typo and fixing dialogoptions info </cmt>",adding missing descriptions to many apis in office.js
161,<desc> #2922 cause helix:led_test build break. this pullrequest fix build break. copy new quantum/rgblight.[ch] into keyboards/helix/rev2/keymaps/led_test/ add new rgblight mode 35 (rgb cyclic) into local rgblight.[ch] </desc> <cmt> copy new rgblight.[ch] from quantum/ into keyboards/helix/rev2/keymaps/led_test/ and add mode 35 rgb cyclic mode </cmt> <cmt> force rgb light mode 25 </cmt>,fix helix:led_test build break
162,"<desc> you can now send websocket status codes and reasons when closing. you can now detect which status code and reason was given by a disconnecting peer, and detect if the connection was shutdown cleanly. websocketserver.disconnect_peer, websocketclient.disconnect_from_host, and websocketpeer.close will no longer immediately close the connection (at least in native platforms). please refer to the updated documentation. closes #21617 . </desc> <cmt> implement websocket close notify. </cmt> <cmt> implement websocket clean close detection. </cmt> <cmt> update websocket documentation </cmt> <iss> godot doesn't send close frames upon disconnecting, and doesn't allow reading of close frames </iss>",implement websocket close frame handling
163,"<desc> related: #19891 fixes the following mypy errors. airflow/providers/amazon/aws/sensors/s3.py:27: error: module ""functools"" has no attribute ""cached_property"" from functools import cached_property airflow/providers/amazon/aws/sensors/s3.py:194: error: need type annotation for ""keys"" (hint: ""keys: list[] = ..."") keys = [] airflow/providers/amazon/aws/sensors/emr.py:22: error: module ""functools"" has no attribute ""cached_property"" from functools import cached_property read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> [16185] added localkubernetesexecutor to breeze supported executors </cmt> <cmt> revert ""[16185] added localkubernetesexecutor to breeze supported executors"" </cmt> <cmt> this reverts commit a1c532eacfeddcbefaa3e565a0522e25315286c4. </cmt> <cmt> fixed mypy errors in aws/sensors </cmt>",fix mypy errors in aws/sensors
164,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. original module uses babel-add-module-exports plugin which adds module.exports = exports['default'] line at the end of each transpiled file and thus breaks default import in typescript because module is converted into common js module. this addresses that and makes definitions of files inside lib be generated in common js style. </desc> <cmt> fix exports for react-icons lib to comply with commonjs </cmt> <cmt> regenrate lib definitions files </cmt> <cmt> change lib file template, regenrate files </cmt>",fix exports for files in lib
165,"<desc> according to  the performance status of crf decoding, just implemented the intrinsic function's optimization to accelerate the data processing. platform:  intel(r) xeon(r) gold 6140 cpu @ 2.30ghz /  intel(r) xeon(r) cpu e5-2699 v3 @ 2.30ghz model path: models/fluid/chinese_ner batch size: 6, 1, 12 command: python infer.py --device cpu --profile data source: use original date provided in the model chinese_ner in the github. the following is the comparison with the different scenarios. </desc> <cmt> optimize crf decoding with avx/avx2 instruction </cmt> <cmt> enable the avx2 flags for compiling </cmt> <cmt> clean the code and decrease the count of multiply calculation </cmt> <cmt> add the support of avx512 instruction to optimize crf decoding </cmt> <cmt> clean the code </cmt> <cmt> enable the avx512f flags for compiling </cmt> <cmt> clean the code for the invaluable switch </cmt>",optimize crf decoding with avx/avx2/avx512f instruction
166,<desc> description this pr migrates the doc's app bar page to hooks. relates to #15032. i have followed (at least) the pr section of the contributing guide. </desc> <cmt> [docs] migrate bottomappbar to hooks </cmt> <cmt> [docs] migrate buttonappbar to hooks </cmt> <cmt> [docs] migrate denseappbar to hooks </cmt> <cmt> [docs] migrate searchappbar to hooks </cmt> <cmt> [docs] migrate bottomappbar js to hooks from docs:typescript:formatted </cmt> <cmt> [docs] migrate buttonappbar js to hooks from docs:typescript:formatted </cmt> <cmt> [docs] migrate denseappbar js to hooks from docs:typescript:formatted </cmt> <cmt> [docs] migrate searchappbar js to hooks from docs:typescript:formatted </cmt>,migrate docs' app bar page to hooks
167,<desc> fixing workflow badge to point to the master branch and not forks with pr. looking into how to do the same for codecov </desc> <cmt> catching exceptions in the dependancy call - eg for pydantic validation error to return a 422 </cmt> <cmt> update fastapi/dependencies/utils.py </cmt> <cmt> changed to only focus on value and type errors which arise from pydantic validation </cmt> <cmt> fixing test workflow badge </cmt> <cmt> reseting master fork changes </cmt>,fix badges in readme and main page
168,"<desc> this transitions liballoc to rust 2018 edition and applies relevant idiom lints. i also did a small bit of drive-by cleanup along the way. r? @oli-obk i started with liballoc since it seemed easiest. in particular, adding edition = ""2018"" to libcore gave me way too many errors due to stdsimd. ideally we should be able to continue this crate-by-crate until all crates use 2018. </desc> <cmt> liballoc => edition = 2018. </cmt> <cmt> liballoc: cargo check passes on 2018 </cmt> <cmt> liballoc: refactor & fix some imports. </cmt> <cmt> liballoc: adjust abolute imports + more import fixes. </cmt> <cmt> liballoc: prefer imports of borrow from libcore. </cmt> <cmt> liballoc: apply uniform_paths. </cmt> <cmt> liballoc: elide some lifetimes. </cmt> <cmt> liballoc: elide &'static. </cmt> <cmt> liballoc: fix some idiom lints. </cmt> <cmt> liballoc: remove redundant extern crate. </cmt>",transition liballoc to rust 2018
169,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test reach__router. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add generic type for useparams </cmt> <cmt> update tparam with some extra type saftey </cmt> <cmt> a param might be undefined </cmt> <cmt> use 'in keyof' for useparam generics </cmt> <cmt> add a test for useparams </cmt>,update the types of useparams
170,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance </desc> <cmt> update submodule skywalking-ui </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> fix k8s api bugs </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> fix api connection leak </cmt>,fix k8s api connection leak
171,<desc> this pr adds tests for the dashboard graph backend code and several improvements (like correct edges between bucket notifications) </desc> <cmt> modulraize pytest fixtures </cmt> <cmt> fix infra graph for s3 notifications and add test </cmt> <cmt> add dynamodbnode graph test </cmt>,improve infra graph code and add tests
172,"<desc> looks like on windows (and possibly linux), a web content's render widget host view can report as focused even when in a hidden window. this pull request adds a check to prevent hidden window's from having focused web contents. this mirrors the key window check already in the mac implementation. closes #6811 </desc> <cmt> add failing webcontents.isfocused spec </cmt> <cmt> ensure hidden windows don't have focused webcontents </cmt>",prevent web contents in hidden windows from reporting as focused
173,"<desc> closes #14885 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> 'bug14885' </cmt> <cmt> added keyerror exception for multiindexes </cmt> <iss> wrong ""too many indexers"" error message when indexing a series with multiindex </iss>",raise keyerror when indexing a series with multiindex
174,<desc> fixes #33197 </desc> <cmt> removing duplicate text-decoration style for abbr[title] #33197 </cmt> <cmt> removing duplicate text-decoration style for abbr[title] #33197 </cmt> <cmt> fix: removing duplicate text-decoration style for abbr[title] #33197 </cmt> <iss> bootstrap reboot 4.x css contains duplicate text-decoration style for abbr[title] </iss>,remove duplicate text-decoration style for abbr[title]
175,"<desc> closes #30904 (fixed between nightly-2019-07-14 and nightly-2019-07-31) closes #40231 (example 1 is fixed in 1.32.0, example 2 is fixed in 1.38.0) closes #52432 (fixed in rustc 1.40.0-beta.1 (76b4053 2019-11-05)) closes #63279 (fixed in rustc 1.40.0-nightly (246be7e 2019-10-25)) r? @centril </desc> <cmt> add test for issue-30904 </cmt> <cmt> add test for issue-40231 </cmt> <cmt> add test for issue-52432 </cmt> <cmt> add test for issue-63279 </cmt> <iss> struct and variant constructors are not generic over lifetimes like regular functions. </iss> <iss> ice: unexpected tail in unsized_info_ty with generics + traits </iss> <iss> ice casting a reference to a static closure as usize, inside array length </iss> <iss> ice: instantiated twice </iss>",add some tests for fixed ices
176,<desc> the initial bottom panel size on small screens was too big changed the initial value of the bottom panel size to be dynamic to the screen. </desc> <cmt> the initial panel size when the position is at the bottom will now be dynamic to the screen size </cmt> <cmt> updated snapshot </cmt>,fix initial bottom panel size
177,"<desc> change adds the id to the manifest fields telemetry event, and logs a detailed search request event. as a side effect/to enable this, getarg now returns a string_view, which will be empty if the value is not present. testing no new tests are added. </desc> <cmt> everything but search request callout added </cmt> <cmt> move to using string_view for args and log search request </cmt> <cmt> proper line endings </cmt>",add telemetry for more scenarios
178,"<desc> updates the colors for the docs code snippets when using a dark color scheme. here's a before and after: current docs link, pr docs link </desc> <cmt> update code snippet colors for dark theme </cmt> <cmt> use media queries </cmt>",use a dark color theme for code snippets in dark mode
179,"<desc> test passed for pb 2.6.0, 3.0.0, 3.6.0, 3.7.0, 3.8.0 </desc> <cmt> make redisrequest derived from redisrequestbase </cmt> <cmt> make redisrequestbase be member of redisrequest </cmt> <cmt> make rpcdumpmeta be member of sampledrequest </cmt> <cmt> make the descriptor and reflection of esp_message, memcache, </cmt> <cmt> nshead_message, serialized_request, thrift_message be independent </cmt> <cmt> of protobuf. </cmt> <cmt> change controller::rpc_dump_meta to controller::sampled_request </cmt> <cmt> compatible with pb 3.8.0 </cmt> <cmt> remove headers of test proto when 'make clean' </cmt> <cmt> adapt callback.h after pb3.7 & remove unnecessary files </cmt>",adapt to protobuf 3.7 & 3.8
180,"<desc> there is a bug in current watermark accounting that headers and trailers are not counted. it is suboptimal in gquic, but an accounting bug in iquic. in iquic, if we don't count headers bytes as total bytes buffered, but subtract from it the bytes written in stream oncanwrite(), we would subtract more than we counted into total bytes buffered. this is because iquic stream writes headers/trailers on data stream. the fix is counting headers/trailers into total bytes buffered. in gquic these bytes are counted against connection level watermark, but not stream watermark. because it's hard to determine which byte belongs to which stream when header stream writes them out. in iquic these bytes are counted against both connection level and stream level watermarks. this also fix a concern of unlimited buffer in headers stream where headers-only responses are buffered in headers stream. risk level: low testing: added new test in quic stream and session part of: #8826, #2557 </desc> <cmt> count headers bytes </cmt> <cmt> new test fail </cmt> <cmt> test pass </cmt> <cmt> adjust stream tests </cmt>",fix headers/trailers bytes accounting against watermark
181,"<desc> related to  when command error message and ping ""dummy"" result json is published from cmndping(), and there is a rule on ping result, json gets broken as per the example below. this pr makes the result response asynchronous by inserting a done ping_t element in the list and move publishing the result json to the polling loop. tagging @sfromis @s-hadinger exemple of broken results: 2:43:12.446 cmd: ping bad.domain 12:43:12.474 mqt: xxxxxxxx/tele/ping = {""ping"":{""bad.domain"":{""reachable"":false,""ip"":"""",""success"":false}}} 12:43:12.485 rul: ping#bad.domain#reachable performs ""var1 false"" 12:43:12.494 mqt: xxxxxxxx/stat/var = {""var1"":""false""} 12:43:12.499 mqt: xxxxxxxx/stat/ping = {"" 16:12:00.890 cmd: ping bad.domain 16:12:00.931 mqt: tele/nodemcu/ping = {""ping"":{""bad.domain"":{""reachable"":false,""ip"":"""",""success"":false}}} 16:12:00.944 rul: ping#bad.domain#reachable performs ""var1 false"" 16:12:00.956 mqt: stat/nodemcu/var = {""var1"":""false""} 16:12:00.961 mqt: stat/nodemcu/ping = {""s 0"":""unable to resolve ip address""} the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> move response for unresolved ip into poll </cmt> <cmt> cleanup </cmt>",fix ping race condition breaks json
182,"<desc> fixes vercel/next.js#4994 componentdidupdate is called for both props + state changes, oneditorchange only has to be called when the state is changed, so i added a shallow equals check to make sure it's only updated when the state really has been changed. this solves the back button issue by removing the custom history api being used. next.js needs to control the history as it puts some state into the history entry for when you're using the back button. hence why you saw the error. </desc> <cmt> add shallowequals check for onupdate </cmt> <cmt> using next.js router instead of custom history api </cmt> <cmt> fixes </cmt>",don't use custom history api
183,"<desc> this pull request adds basic documentation for the searchable snapshots rest apis. the main motivations are to not break downstream projects (see #53871) and to provide a simple example of how to mount a snapshot. it adds a new ""searchable snapshots apis"" sub section in the rest apis section. the ""mount snapshot api"" is the more complete documentation and provides an example of how to create a new index backed by a snapshot. those api are experimental and marked as such. i've not seen any mention of the license, except the [testenv=""basic""]  tags that i copied from other doc. </desc> <cmt> add basic docs for searchable snapshots rest apis </cmt> <cmt> update links </cmt>",add basic documentation for searchable snapshots rest apis
184,"<desc> fixes #1236 build the development environment as a docker image with the pr, we can build the development docker image by: git clone --recursive  cd paddle docker build -t paddle:dev -f paddle/scripts/docker/dockerfile . note that by default docker build wouldn't import source tree into the image and build it.  if we want to do that, we need to set a build arg: docker build -t paddle:dev -f paddle/scripts/docker/dockerfile --build-arg build_and_install=on . run the development environment once we got the image paddle:dev, we can use it to develop paddle by mounting the local source code tree into a container that runs the image: docker run -d -p 2202:22 -v $pwd:/paddle paddle:dev this runs a container of the development environment docker image with the local source tree mounted to /paddle of the container. note that the default entry-point of paddle:dev is sshd, and above docker run commands actually starts an sshd server listening on port 2202.  this allows us to log into this container with: ssh root@localhost -p 2202 usually, i run above commands on my mac.  i can also run them on a gpu server xxx.yyy.zzz.www and ssh from my mac to it: my-mac$ ssh root@xxx.yyy.zzz.www -p 2202 build and install using the development environment once i am in the container, i can use paddle/scripts/docker/build.sh to build, install, and test paddle: /paddle/paddle/scripts/docker/build.sh this builds everything about paddle in /paddle/build.  and we can run unit tests there: cd /paddle/build ctest </desc> <cmt> add dockerfile.dev for building a standard develop environment </cmt> <cmt> update dockerfile.dev </cmt>",paddle standard development environment as a docker image
185,"<desc> gradually improving the windows build experience, so far: clean deletes all specified folders (doesn't stop on first missing one) build removes any path entry containing a msbuild.exe (avoids node-gyp errors) </desc> <cmt> fix clean command to actually work when paths missing </cmt> <cmt> exclude path entries with msbuild.exe to fix node-gyp on windows </cmt>",improve the windows build process
186,"<desc> develop merge master develop merge master format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:chexck findbugs:findbugs to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> naming model refactor </cmt> <cmt> revert ""naming model refactor"" </cmt> <cmt> revert ""naming model refactor"" </cmt>",develop merge master ready 0.5 version
187,"<desc> adds features and method with docstrings update user guide whats new add tests this pr adds the method format_index so that the typical format routines can also be applied to display the index labels and columns headers of a styler. with all the recent functionality here is a complete example: notes also had to move _refactor_levels function from style.py to style_render.py for use here. </desc> <cmt> build format_index mechanics </cmt> <cmt> test index formatter display_value, and clearing </cmt> <cmt> prelim doc string </cmt> <cmt> format_index docs </cmt>",styler.format_index() to display index values similarly to data-values with format()
188,<desc> #161 (comment) </desc> <cmt> exclude /proc/ and /sys/ from the monitored filesystems </cmt> <cmt> read netfilter count of sockets and max sockets on systems without /proc/net/stat/nf_conntrack </cmt> <cmt> added alarm for monitoring the percentage used of connection tracker table </cmt> <cmt> updated configs.signatures </cmt> <cmt> prevent the delay to charge the netfilter alarm </cmt>,netfilter sockets chart when netfilter stats are not available and netfilter alarm
189,"<desc> there are some random failures of apiv3 tests during ci on github (github actions). this is probably caused by clashes of computed identifier of test documents. these clashes probably arise in very fast (or parallel) test execution, when test documents get the same timestamp. this pr tries to solve this by isolating test documents, which is achieved by using different device name in different test file. </desc> <cmt> apiv3: isolating documents from tests (not allowing clashes of calculated identifiers) </cmt> <cmt> removing unused async keyword </cmt>",trying to fix random fail of apiv3 tests
190,"<desc> hi mike, i've added batchsize and batchstartsat parameters to handle the buffer size problem and to cope with the senario where your buffer is larger than you want to submit at any one time. i.e. your incoming buffer is 10 elements and your ring only has 8 slots. (a problem a tripped over in one of our test scenarios). </desc> <cmt> expose the publication batches on the ring buffer </cmt> <cmt> expose the publication batches on the disruptor </cmt> <cmt> fix up compiler warnings in ringbuffertest </cmt> <cmt> configure snapshot versioning for publication to local nexus. </cmt> <cmt> expose batchsize on batch event publication. </cmt> <cmt> tidy up idea warnings </cmt> <cmt> add batchsize and offset to batch publication </cmt> <cmt> trypublish will now return false if the batch size is bigger than the ring buffer </cmt>",batch publication on ring buffer (take2)
191,"<desc> this came about as a requirement for converting dataframe.to_html into styler.to_html, citing @jorisvandenbossche in favour of the functionality. note that the dataframe.to_html render_links argument is rather limited to just detecting only a url in a cell. the function added for styler here is a more general pattern search, and it allows the result to be viewed in jupyter notebook directly, which the precursor does not. </desc> <cmt> render links </cmt> <cmt> tests </cmt>",add render_links for styler.to_html formatting
192,"<desc> rgb mapping is unique between iso and ansi gmmk pro pcbs, split each version into a separate revision for proper support. @hatbuster @giesd @tipok i don't actually have an iso model to test, on so if you could please confirm this actually works. fixes #13524 my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> gmmk/pro: split ansi and iso pcbs into different revisions, properly support rgb </cmt> <cmt> on iso </cmt> <cmt> fix formatting </cmt>","split gmmk pro pcbs into separate revisions, fix rgb mapping on iso"
193,"<desc> open-mmlab/mmcv#1330 supported more interfaces in fileclient. now we can load all ground truth files including json files and images from ceph. at the same time, this pr wraps panopticapi so that the evaluation of panoptic segmentation can also be run on ceph. you need to set file_client_args in the dataset. file_client_args = dict( backend='petrel', path_mapping=dict({ '.data/coco/': 's3://openmmlab/datasets/detection/coco/', 'data/coco/': 's3://openmmlab/datasets/detection/coco/' }) data = dict( samples_per_gpu=2, workers_per_gpu=2, train=dict( type=dataset_type, ann_file=data_root + 'annotations/panoptic_train2017.json', img_prefix=data_root + 'train2017/', seg_prefix=data_root + 'annotations/panoptic_train2017/', pipeline=train_pipeline, file_client_args=file_client_args, ), ...) </desc> <cmt> first version </cmt> <cmt> replace with our api </cmt> <cmt> add copyright </cmt> <cmt> move the runtime error to multi_core interface </cmt>",support file_client in datasets and evaluating panoptic results on ceph
194,"<desc> see title the caching font data mechanics allows have vertices with negative x coordinate. here is an example of real vertices data for the same character: char is not blurry: #float3(x,y,z),float4(r,g,b,a),float2(tu,tv) ""{+72, +124, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13085938, +0.30000001}"" ""{+77, +124, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13574219, +0.30000001}"" ""{+77, +138, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13574219, +0.76666671}"" ""{+72, +138, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13085938, +0.76666671}"" char is blurry: #float3(x,y,z),float4(r,g,b,a),float2(tu,tv) ""{-159, +124, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13085938, +0.30000001}"" ""{-153, +124, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13574219, +0.30000001}"" ""{-153, +138, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13574219, +0.76666671}"" ""{-159, +138, +0}"",""{+0.89803928, +0.89803928, +0.89803928, +1}"",""{+0.13085938, +0.76666671}"" as can you see if vertex data has negative value of x coordinate the dimension of char is greater at 1 pixel - 6x14 instead of 5x14. it would be helpful if some one can test this on linux </desc> <cmt> [guifontttf] fixed rounding x coordinate of a char if it has negative value. </cmt> <cmt> now caching font data algorithm allows negative coordinates of vertices. rounding x coord does not consider negative values and it causes a font blurry in some cases. </cmt> <cmt> [guifontttfdx] optimized: don't change rendering state if there is nothing to render. </cmt>",fixed a blurry font  which is happening sometimes in some cases.
195,"<desc> this fixes and updates support for the nook hd (hummingbird) and hd+ (ovation), and adds support for the nook tablet (acclaim). </desc> <cmt> set nook_pre_header_sz from 0xfffff to 0x100000 </cmt> <cmt> all applicable nook hd/hd+ roms are using this offset </cmt> <cmt> add support for the new nook_magic </cmt> <cmt> the new cmdline value that's been in use since marshmallow </cmt> <cmt> add support for the nook tablet, acclaim </cmt> <cmt> also changed occurences of nook with nookhd </cmt>","fixup support for nook hd, add support for acclaim"
196,"<desc> use inherited value, 'false', from its base class object3d. </desc> <cmt> removed override this.receiveshadow = undefined </cmt> <cmt> inherited value is false (from its based class, object3d) </cmt> <cmt> removed checking undefined against receiveshadow </cmt> <cmt> receiveshadow is always boolean. skip redundant check object.receiveshadow !== undefined &&. </cmt>",removed override of .receiveshadow from light.js
197,"<desc> hi guys, here is a new pr for the plugin approach. it is still rough, but should already be as good as the previous version. it features: a plugin folder where we can put different versions of algorithm new plugins with the align extraction and the masked merge (which are the latest afaik) there is still room for improvments: general syntax may be improved, but please provide me specific feedback if you see something (or even do a pr on my own repo if you prefer) we can add easily the plugin choice through arguments, but its out of my scope for now we should add arguments parsing for plugins, but this part is not clear for me i want to add a specific support for model plugins as well as a cleaner model loading, but i'm not sure of the consequences yet, so i let that for later </desc> <cmt> adding plugins </cmt> <cmt> adding new plugins (extract_align & convert_masked) </cmt> <cmt> adding pluginloader </cmt>",adding plugins + integration of face alignment & masked script
198,"<desc> issue: - this supercedes #13458 avoid bundling all supported syntax highlighter languages for addon-docs, but rather just the ones we need. this shaves off close to 2 mb from the preview vendor bundle. is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no </desc> <cmt> fix dist/ts path </cmt> <cmt> avoid loading entire react-syntax-highlighter library by importing it direction instead of through @storybook/components. </cmt> <cmt> import languages from esm build. </cmt> <cmt> use ts-expect-error instead of ts-ignore. </cmt>",bundle only required syntax highlighter languages
199,"<desc> why needed? regression due to #20160 which did not consider the consequential behavior change on non-probe systems. this addition of manual_probe_start_z being defined in conditionals_post.h messes up manual mesh bed levelling. when you perform mesh bed levelling, after the home, the nozzle moves to the first point. the height of that point should be ""zero"" - at the last home position. after levelling, the nozzle should move up, to the safe travel height, then move to the next xy point 2, and then move down to the previous z height, same as point 1. walkthrough of problem in code: for mesh bed levelling: if mesh_bed_leveling enabled, sets probe_selected 1 (line 795 in conditionals_lcd.h) [**] for probe_selected, z_clearance_between_probes falls back to z_homing_height. (line 2613 in conditionals_post.h) if z_clearance_between_probes is defined, then manual_probe_start_z is defined (line 2629 on conditionals_post.h) then if manual_probe_start_z is defined, then lines 224-230 in bedlevel.cpp will not run and thus manual_probe_start_z will be used for all bed leveling points as the start z height. the result is, that after moving to each new xy point during manual mesh bed levelling, the nozzle starts from z = manual_probe_start_z rather than z = zprevious. (lines 224-230 in bedlevel.cpp) simple solution, until someone has time to refactor the absolutely abysmally coded bed levelling code. the marlin policy of code devoid of useful comments really comes back to bite here! change line 216 in bedlevel.cpp: #ifdef manual_probe_start_z becomes #if defined(manual_probe_start_z) && !defined(mesh_bed_leveling) for non-probe systems. fixes manual mesh bed leveling process; each point will start from z-height of previous points. this was the previous behavior prior to this regression. fixes #21239 </desc> <cmt> bugfix 2.0.x </cmt> <cmt> fix manual mesh bed levelling </cmt> <cmt> crude fix for manual mesh bed leveling operation, for non-probe systems. </cmt>",fix usage and commentary of manual_probe_start_z and z_after_probing
200,"<desc> this pr updates the interactive link styles for the management link options on the /manage page. it brings the styles in line with the new look & feel theme. screenshots hover focus active entry 1: updated the styles for the links on the management page changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @timja @daniel-beck before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue must exist, be a bug or improvement, and be labeled as lts-candidate to be considered (see query). </desc> <cmt> extracts styles from the /manage page </cmt> <cmt> - finalizes extracting the /manage page styles to the the proper less file </cmt> <cmt> update link styles for /manage page </cmt>",update /manage interactive link styles
201,"<desc> the out-of-source build is officially recommended, and it makes us avoid some kinds of build errors like #2093 by removing the build directory easily. also, i've explained h2o_root in the doc to run h2o on the project directory without installing it. </desc> <cmt> doc: recommend out-of-source build </cmt> <cmt> doc: explain h2o_root for h2o developers </cmt>","recommend out-of-source build, explain h2o_root"
202,"<desc> negatesignatures is called with a signature which has not yet had the hashtype appended to it, yet the function assumed a hashtype was there and was incorrectly saving and then appending the last byte of its input (ie the last byte of the original s instead of a hashtype). only one pair of the test scripts was triggering this bug (""p2pk with high s""), which was actually causing the invalid version of the test to fail in the wrong place -- it was failing in the isvalidsignatureencoding function rather than further down in islowdersignature where the s value is checked.  fixing negatesignatures causes this test to change so that islowdersignature is now being tested as i believe was intended. fixing that test resulted in there no longer being code coverage for the check in isvalidsignatureencoding relating to extra bytes after the s, so the second commit here adds a pair of tests to exercise that check. </desc> <cmt> fix negatesignatures to not duplicate last byte of s </cmt> <cmt> negatesignatures is called with a signature without a hashtype, so </cmt> <cmt> do not save the last byte and append it after s negation. </cmt> <cmt> updates the two tests which were affected by this bug. </cmt> <cmt> add test for der-encoding edge case </cmt> <cmt> the fix to negatesignatures caused a test which had been failing </cmt> <cmt> in isvalidsignatureencoding to then fail in islowdersignature. </cmt> <cmt> add new test so the original check remains exercised. </cmt>",fix usage of negatesignatures in script_tests
203,"<desc> some new release tests newly started to fail with the same commit check assertion failure as seen before in #21096, e.g. impala:  this pr applies the fix from #21119 to all app configs used in all release tests that install specific commits from from env[""ray_wheels""].  this pr also adds it as an instruction to e2e.py to help people creating new app configs for new release tests. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> uninstall old ray in all release test app configs </cmt> <cmt> add instruction to e2e.py dosctring </cmt>",uninstall old ray in all release test app configs to fix commit mismatch error
204,"<desc> this introduces a new option setoption22 which is related to setoption20. it can essentially be described as ""apply setoption20 setting to commands from the faceplate"" see #469 for more info. </desc> <cmt> tuya: fix setoption20 for oittm/moes </cmt> <cmt> tuya: add setoption22 to select if brightness-commands from faceplate should be ignored while powered off </cmt>",fix setoption20 behavior for oittm/moes
205,"<desc> when you do: spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat']) there is a high risk of throwing an exception if the user did not install the model before. te easiest way to use the spacy tokenizer is the one i propose here. this way there is no need for the user to download any spacy model. more info here: </desc> <cmt> update tokenization_xlm.py </cmt> <cmt> update tokenization_openai.py </cmt> <cmt> update tokenization_openai.py </cmt>",better use of spacy tokenizer in open ai and xlm tokenizers
206,"<desc> move additional code/methods into baseviewer and have the extending classes override/extend methods as necessary this attempts to provide more ""default"" methods in the base class, in order to reduce unnecessary duplication and to improve self-documentation of the baseviewer class slightly. the following changes are made (in no particular order): have baseviewer implement the _scrollintoview method, and extend it as necessary in pdfviewer/pdfsinglepageviewer. simply inline the baseviewer._resizebuffer method, in baseviewer.update, since there's only one call-site at this point. provide a default implementation of _isscrollmodehorizontal in baseviewer, and have pdfsinglepageviewer override it. provide a default implementation of _getvisiblepages, and have pdfviewer extend it and pdfsinglepageviewer override it. try to simplify the pdfsinglepageviewer._scrollintoview method slightly, by unconditionally ensuring that rendering always occurs </desc> <cmt> move additional code/methods into baseviewer and have the extending classes override/extend methods as necessary </cmt> <cmt> this attempts to provide more ""default"" methods in the base class, in order to reduce unnecessary duplication and to improve self-documentation of the baseviewer class slightly. </cmt> <cmt> the following changes are made (in no particular order): </cmt> <cmt> - have baseviewer implement the _scrollintoview method, and *extend* it as necessary in pdfviewer/pdfsinglepageviewer. </cmt> <cmt> - simply inline the baseviewer._resizebuffer method, in baseviewer.update, since there's only one call-site at this point. </cmt> <cmt> - provide a default implementation of _isscrollmodehorizontal in baseviewer, and have pdfsinglepageviewer override it. </cmt> <cmt> - provide a default implementation of _getvisiblepages, and have pdfviewer extend it and pdfsinglepageviewer override it. </cmt> <cmt> try to simplify the pdfsinglepageviewer._scrollintoview method slightly, by unconditionally ensuring that rendering always occurs </cmt>","move more code/methods into baseviewer, and simplify the pdfsinglepageviewer._scrollintoview method slightly"
207,<desc> fixes #20675 the memoized state of effect hooks is only invalidated when deps change. deps are compared between the previous effect and the current effect. this can be problematic if one commit consists of an update that has changed deps followed by an update that has equal deps. that commit will lead to memoizedstate containing the changed deps even though we committed with unchanged deps. the n+1 update will therefore run an effect because we compare the updated deps with the deps with which we never actually committed. to prevent this we now invalidate memoizedstate on every updateeffectimpl call so that memoizedstat.deps always points to the latest deps. test plan ci green codesandbox of #20675 has expected behavior all codesandboxes in #20676 (comment) have the expected behavior (no effects are logged after clicking) </desc> <cmt> current behavior of effect dependencies on render phase updates </cmt> <cmt> fix: don't schedule effects when render phase updates aren't committed </cmt> <iss> bug: functioncomponent re-render phase cause a bug </iss>,don't run effects if a render phase update results in unchanged deps
208,"<desc> we only really care about the glibc api, but we probably should only use the official parts, wherever possible. </desc> <cmt> signal-util: don't introduce symbols with double underscores </cmt> <cmt> ansi c reserves identifiers beginning with an underscore for compiler </cmt> <cmt> internal stuff. we already invade that namespace plenty and probably </cmt> <cmt> should not. but even going for the doubly underscore prefixed namespace </cmt> <cmt> is a bit too much. let's just rename the offending table as </cmt> <cmt> ""static_signal_table[]"", since it lists the static defined signals </cmt> <cmt> rather than the ""dynamic"" rtsigmin/rtsigmax signals. </cmt> <cmt> sort-util: use comparison_fn_t instead of __compar_fn_t </cmt> <cmt> let's avoid using the internal type of glibc, and rather use the one </cmt> <cmt> they officially export. </cmt> <cmt>  </cmt> <cmt> stub: also move magic string in stub into .sdmagic pe section </cmt> <cmt> we already did that for sd-boot, hence do it for sd-stub the same way. </cmt> <cmt> also, move the __attribute__ stuff to the beginning of the statement, </cmt> <cmt> rather than the middle. mostly just because we usually put it first for </cmt> <cmt> implementations for identifiers (for prototypes we put it last). </cmt> <cmt> macro: also use trailing __ for alignof use in attributes </cmt> <cmt> while the underscore is optional, the docs say we should suffix and we </cmt> <cmt> do that everywher else. do so here too. </cmt> <cmt> network: use official bswap_32() rather than inofficial __bswap_32() </cmt> <cmt> the former is a macro for the latter, but let's use the official api </cmt> <cmt> (the one that has an api). </cmt> <cmt> tree-wide: use c99 __func__ rather than obsolete __function__ </cmt> <cmt> we use __func__ almost everywhere, but there are some holdouts. fix </cmt> <cmt> that. </cmt> <cmt> ethtool-util: let's use userspace types in userspace code </cmt> <cmt> using kernel types __u32 is fine for headers shared by the kernel, but </cmt> <cmt> if we define something in userspace and only use it in userspace, in our </cmt> <cmt> own .c files, let's stick to userspace fixed-length types. </cmt> <cmt> localed: use project_file rather than __file__ for logging </cmt> <cmt> all our log.h code uses project_file for this, let's hence use it here </cmt> <cmt> too. </cmt>","use less glibc internal symbols, modernize some other stuff"
209,"<desc> description: this pr breaks out one of the concepts from #6161 -- an efficient mechanism for remembering a set of statnames to reject, to use for caching the results of the stats-matcher. risk level: low -- not used yet. testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> adds sharedstatnamestorageset. </cmt> <cmt> stop using shared_ptr for the rejected-stats set; the way it's structured, this is not necessary. </cmt>",add/test heterogenous set of statnamestorage objects.
210,"<desc> add new feature: can create public namespace in different formats, include json, xml, yml, yaml, txt, just like creating a private namespace. public namespace in these formats can be associated correctly. discussion fixes #2602 remove verify formats of creating public namespace in portal api and front-end add front-end elements to create public namespace in formats add front-end text box to show associated namespace when parent namespace are different with child namespace. read the contributing guide before making this pull request. run mvn clean test to make sure this pull request doesn't break anything. update the changes log. </desc> <cmt> feature: allow create public namespace in many formats </cmt> <cmt> - change front-end and portal service to allow create new namespace in format json/yaml/xml/txt </cmt> <cmt> - can not associating namespace of these formats now </cmt> <cmt> - todo: change some documents on front-end page </cmt> <cmt> feature: portal front-end can request associate namespace info </cmt> <cmt> feature: public namespace in many formats </cmt>",public namespace support different formats
211,"<desc> changing it from a generic ""bad request"" to 431 (request header fields too large) moving the existing h2 integration test to integration.cc and adding http/1.1 coverage. </desc> <cmt> changing error code on overly long headers to 431, moving h2 test to cover http as well </cmt>","tweaks to the ""headers too long"" path"
212,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). region opacity:  point sensitivity:  increase the version number in the header if appropriate. </desc> <cmt> add missing fields and run autoformatter </cmt> <cmt> update version and add my name to author list </cmt> <cmt> fix failing test </cmt>,"c3 - add missing fields, run autoformatter, fix failing test"
213,"<desc> fixing the led code in my keymap to use both leds on the pro micro. before, it was incorrectly using pin b5 instead of d5. edited the led driving code to accurately use the leds on pins b0 and d5 instead of b0 and b5 as my previous code was doing. fixing use of incorrect pins for leds in my keymap. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fixing led pins to accurately use the pro micro leds </cmt> <cmt> fixing trailing whitespace </cmt>",mf68 keymap led pins fixed
214,"<desc> this updates statusbaritem.hostbackground and statusbaritem.hostforeground to use their own colors, as previously discussed. this also polishes the extension-remote-badge to make it centered. </desc> <cmt> update statusbaritem.host colors </cmt> <cmt> center remote icon in badge </cmt> <cmt> center remote icon in extension editor </cmt>",polish host colors and badge
215,<desc> this is a follow up to #24305 which ended up breaking getsentry tests. i made a small change so that getsentry doesn't break on top of that pr. commit to fix tests: 9dd9e29 </desc> <cmt> have a ready to go buffer of demo orgs </cmt> <cmt> move to different file </cmt> <cmt> adds migration </cmt> <cmt> adds django app for demo </cmt> <cmt> fix times </cmt> <cmt> makes tests </cmt> <cmt> merge from master </cmt> <cmt> update </cmt> <cmt> small fix </cmt> <cmt> update </cmt> <cmt> move import statement </cmt> <cmt> merge from master </cmt>,feat(demo) premake orgs v2
216,"<desc> pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: ""[component] fix leaky abstraction"". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( a few days ago lorempixel.com was down for a couple days. the cards with images on the card page didn't have images for both the avatar and card during that time. this pr replaces the image links with images hosted in the repo. closes #4731 </desc> <cmt> changed images used for card page to hosted image; added nature image from lorempixel </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",replaces images on card page with hosted images
217,"<desc> resolves #21676. fixes failing test added in #21677 when adding the new suspense/offscreen effects semantics, we intentionally left out the subtreeflags checks since these values aren't 100% reliable and the check is just an optimization. (refer to the // todo (offscreen) comments in the source code.) it looks like #21386 (re)added one though, which was causing a failure case originally reported here: reactwg/react-18#31 for now, this pr just removes that check and adds a follow up todo comment. this is just a bandaid fix to allow us to resume rolling out the new suspense layout semantics. a proper long-term fix would be to identify why the subtreeflags are incorrect in this case. </desc> <cmt> add failing test for suspense layout semantics </cmt> <cmt> removed subtreeflags check from commitlayouteffects_begin() </cmt> <cmt> this was preventing layout effects from being recreated within offscreen subtrees in some conditions. </cmt> <iss> bug: layout effects don't re-fire in 18 on suspense re-showing </iss>",fix for failed suspense layout semantics
218,"<desc> plus some more stuff, read the commit comments / changes. </desc> <cmt> alias --verbose to --log-level=info </cmt> <cmt> print_verbose is now simply logger.info() and is always displayed if </cmt> <cmt> log level allows it. this affects only the prune and mount </cmt> <cmt> commands which were the only users of the --verbose option. the </cmt> <cmt> additional display is which archives are kept and pruned and a single </cmt> <cmt> message when the fileystem is mounted. </cmt> <cmt> files iteration in create and extract is now printed through a </cmt> <cmt> separate function which will be later controled through a topical </cmt> <cmt> flag. </cmt> <cmt> silence file listing unless --changed is present </cmt> <cmt> silence borg by default </cmt> <cmt> this also prints file status on stderr directly, bypassing the logger </cmt> <cmt> as we do with other topical flags (like progress and status) </cmt> <cmt> update documentation to follow changes </cmt> <cmt> move changed with other topical flags </cmt> <cmt> we need to have a sane default there otherwise the option may not be defined in some sub-commands and will crash </cmt> <cmt> do not display unchanged files by default </cmt> <cmt> add a --unchanged topical file to display those files </cmt> <cmt> change file status test and cleanup last ref to --verbose </cmt> <cmt> this ports the changes here to #445 </cmt> <cmt> add a --filter option replacing --changed/--unchanged </cmt> <cmt> the problem here was that we do not just have changed and unchanged items, </cmt> <cmt> but also a lot of items besides regular files which we just back up ""as is"" without </cmt> <cmt> determining whether they are changed or not. thus, we can't support changed/unchanged </cmt> <cmt> in a way users would expect them to work. </cmt> <cmt> the a/m/u status only applies to the data content of regular files (compared to the index). </cmt> <cmt> for all items, we always save the metadata, there is no changed / not changed detection there. </cmt> <cmt> thus, i replaced this with a --filter option where you can just specify which </cmt> <cmt> status chars you want to see listed in the output. </cmt> <cmt> e.g. --filter am will only show regular files with a(dded) or m(odified) state, but nothing else. </cmt> <cmt> not giving --filter defaults to showing all items no matter what status they have. </cmt> <cmt> output is emitted via logger at info level, so it won't show up except if the logger is at that level. </cmt> <cmt> archive checker: remove report_progress, fix log levels </cmt> <cmt> remove --log-level, add --debug and --info option, update docs </cmt> <cmt> removed --log-level due to overlap with how --verbose works now. </cmt> <cmt> for consistency, added --info as alias to --verbose (as the effect is </cmt> <cmt> setting info log level). </cmt> <cmt> also added --debug which sets debug log level. </cmt> <cmt> note: there are no messages emitted at debug level yet. </cmt> <cmt> warning is the default (because we want mostly silent behaviour, </cmt> <cmt> except if something serious happens), so we don't need --warning </cmt> <cmt> as an option. </cmt> <cmt> add developer docs about output and logging </cmt>",refactor --verbose and silence borg by default (supercedes pr 444)
219,"<desc> as discussed in dotnet/aspnetcore#15351, the behavior of the ""defaults"" methods could be clarified a bit. i had a few minutes so i took a stab at it. internal render: kestrel web server implementation in asp.net core configure certificate authentication in asp.net core </desc> <cmt> update kestrel.md </cmt> <cmt> update certauth.md </cmt> <cmt> update kestrel.md </cmt> <cmt> update kestrel.md </cmt> <cmt> update certauth.md </cmt>",add a clarifying note about kestrel's configureendpointdefaults and configurehttpdefaults methods
220,"<desc> the current kubectl can't proxy anything that's not under the /api path. this removes that restriction while still allowing old tooling work the same. this is required for kubectl to be a drop-in replacement for the ro port; prometheus example is updated to show this. </desc> <cmt> fix 'kubectl proxy' to allow the /metrics page to be proxied, without breaking the previous proxy behavior </cmt> <cmt> fix prometheus usage of kubectl proxy </cmt> <cmt> gendocs </cmt>",allow kubectl proxy to proxy everything
221,"<desc> corrects the first iconbutton sample, adds a raisedbutton sample. fixes #27168 fixes #12382 </desc> <cmt> add sample for raisedbutton </cmt> <cmt> updated iconbutton sample </cmt> <iss> add example in flatbutton, raisedbutton, etc that shows setting the text of the button </iss> <iss> iconbutton sample fails to run. </iss>","update an iconbutton sample, add raisedbutton sample"
222,"<desc> openers and editors were still being stored in project. this moves the specs and the variables themselves over to workspace. moving buffers over is something else we could do, but i'm not sure how that fits with our multi-project plans. </desc> <cmt> move openers to workspace </cmt> <cmt> update workspace::getopeners </cmt> <cmt> move project::eacheditor to workspace::eacheditor </cmt> <cmt> use existing remove method </cmt> <cmt> fix problem with workspace::eacheditor </cmt> <cmt> move editor tracking to workspace </cmt> <cmt> fix bug in project::geteditors </cmt> <cmt> set atom.workspace in workspace spec </cmt> <cmt> move editor removal specs to workspace </cmt> <cmt> move editor-created event to workspace </cmt> <cmt> move editor-created specs to workspace </cmt>",move functionality from project to workspace
223,"<desc> here are the proposed changes to improve seo. additionally, i changed the rest of the h1 titles in the landing page to h2. </desc> <cmt> feat: change element hierarcy </cmt> <cmt> feat: update meta </cmt>",update seo on landing page
224,"<desc> dealing with issues: #2728 - separate directories for geometry primitives and scene primitives instead of mixing them in src/core? #2729 - ray3 geometry primitive (first part of splitting current ray into separate classes) #2736 - ray - sphere intersection testing. #2738 - bad bounding box calculation in buffergeometry.js if there is only a single point ray has full unit test coverage and all unit tests pass. </desc> <cmt> initial implementation of ray3. </cmt> <cmt> add recastself and document that i am unsure of the best way to handle failure cases. </cmt> <cmt> fixed #2728, moved geometry primitives out of src/core into src/math.  src/core is now exclusive scene primitives. </cmt> <cmt> rename ray -> raycaster, ray3 -> ray per @mrdoob (see #2729) </cmt> <cmt> ray unit tests. </cmt> <cmt> finished scope of ray unit tests, now i just need to make them work. </cmt> <cmt> all ray unit tests pass. </cmt>","new ray geometric primitive, ray->raycaster rename, move of geometric primitives to src/math"
225,"<desc> hey, i have updated the type definitions for the touchripple classes to match what is implemented in the buttonbase component.  fixes #11803. thanks! </desc> <cmt> fixed typings on touch ripple classes </cmt> <cmt> added semicolon to end of class key </cmt>",corrected the type definitions for the touchripple classes
226,"<desc> update windows openssl to ver 1.1.1 (library files and include files). move visual studio 2008 static link libs from src/buildfiles/library to src/buildfiles/library/vs2008. also .sln and .vcproj files are updated. add visual studio 2017 static link libs of openssl and zlib to src/buildfiles/library/vs2017. improve .gitignore. your great patch is much appreciated. we are considering to apply your patch into the softether vpn main tree. softether vpn patch acceptance policy:  you have two options which are described on the above policy. could you please choose either option 1 or 2, and specify it clearly on the reply? -1 preliminary declaration for future switch to a non-gpl license i hereby agree in advance that my work will be licensed automatically under the apache license or a similar bsd/mit-like open-source license in case the softether vpn project adopts such a license in future. </desc> <cmt> win32 openssl header file: ver 1.0.2j -> ver 1.1.1 </cmt> <cmt> added openssl 1.1.1 .lib files for visual studio 2008. </cmt> <cmt> add automatically generated files to .gitignore </cmt> <cmt> add visual studio automatically generated files to .gitignore </cmt> <cmt> improve .gitignore </cmt> <cmt> added openssl 1.1.1 and zlib's .lib files for visual studio 2017. </cmt>","upgrade windows openssl to 1.1.1, and also visual studio 2017 static link libraries support."
227,"<desc> new features apis paddle new apis: put_along_axis. xu huang is on holiday so we created this pr to work on it. it is based on his pr: #37921 api screenshot: </desc> <cmt> init commit </cmt> <cmt> init commit </cmt> <cmt> add put_along_axis_op and unitest </cmt> <cmt> fix a lot of bug </cmt> <cmt> for ci </cmt> <cmt> fix cmake depency problem in ci </cmt> <cmt> modified as review suggestion and fix rocm ci problem. </cmt> <cmt> split this pr into two parts, this is the put_along_axis_op part </cmt> <cmt> fix a bug in broadcast in python level </cmt> <cmt> fix a bug in caculate gradient of value </cmt> <cmt> using tensorcopy instead directly assign </cmt> <cmt> add inplace api for put_along_axis and unittest. </cmt> <cmt> used pre-commit for manipulation.py </cmt>",put_along_axis (based on pr #37921 by xu huang)
228,"<desc> this pull request is just a small documentation change that i think will be helpful to others. i spent a while trying to figure out how to get material-ui to play well with other styling libs and noticed i needed to specify the default style injection point in my html head to ensure the right order of styles. </desc> <cmt> add default injection comment to help for overriding </cmt> <cmt> thought it might be useful for others to clarify what comment is used by material-ui by default, to inject styles after. this can greatly help integration with other styling libs. </cmt> <cmt> note that currently the injection comment is  <!-- jss-theme-reactor --> but as mentioned by @oliviertassinari here </cmt> <cmt> update override help injection comment </cmt> <cmt> as per </cmt> <cmt> note current implementation still uses <!-- jss-theme-reactor --> for now. </cmt>",update help for 'overriding' to specify injection point
229,"<desc> ref #205 </desc> <cmt> remove native contract actions types from built-in types </cmt> <cmt> add from_variant/to_variant specialization for uint{64,32,16,8} to prevent the catch all </cmt> <cmt> template<typename t> void from_variant( const variant& v, boost::multiprecision::number<t>& n ) function </cmt> <cmt> that forces the variant to be in string format (v.get_string()) </cmt>",fix surrounding quotes for uint64 in json
230,"<desc> resolves #5701 </desc> <cmt> dev </cmt> <cmt> dev upgrade to 0.10.3 for latest reports pgs distribution </cmt> <cmt> dev create pr for activity document </cmt> <cmt> ice cream dev update </cmt> <cmt> dev update for loop overrides </cmt> <cmt> dev </cmt> <cmt> dev </cmt> <cmt> add carb foodtype, absorptiontime to reports </cmt> <cmt> add carb foodtype, absorptiontime to reports </cmt> <cmt> add carb foodtype, absorptiontime to reports </cmt>","add loop carbs foodtype, absorptiontime to reports for issue #5701"
231,<desc> i hereby agree to the terms of the cla available at:  changelog category: documentation for #7572 detailed description: translated to russian topic that was added in #8161. </desc> <cmt> [clickhousedocs] translate custom http handlers with prepared queries (#126) </cmt> <cmt> * literacy checking </cmt> <cmt> * ru translation </cmt> <cmt> * update docs/ru/interfaces/http.md </cmt> <cmt> * update docs/ru/interfaces/http.md </cmt> <cmt> * update docs/ru/interfaces/http.md </cmt> <cmt> * update docs/ru/interfaces/http.md </cmt> <cmt> * update http.md </cmt> <cmt> * update http.md </cmt>,the predefined http handlers topic translated to russian
232,<desc> changed method range to rangeclosed to include end. </desc> <cmt> string to char array and char array to string. </cmt> <cmt> method change </cmt> <cmt> custom threadpool in java 8 parallel streams </cmt> <cmt> implemented suggested edits from editor. </cmt> <cmt> broke long method signature </cmt> <cmt> changed primitive type int to long and formula. </cmt> <cmt> update wrapper type to long </cmt> <cmt> conflicts: </cmt> <cmt> core-java/src/test/java/org/baeldung/java/streams/threadpoolinparallelstream.java </cmt>,custom thread pools in java 8 parallel streams
233,<desc> i think it may be good to fix this because cmd-line help is more likely to be forgotten in testing and so a program may be distributed to users with one of these two bugs that break cmd line help and so make it unusable. </desc> <cmt> fix an error when help for an option is blank </cmt> <cmt> update news </cmt>,fix an error in argparse help when help for an option is blank
234,<desc> this fixes build issues with the 32-bit risc-v port. </desc> <cmt> library/panic_unwind: add unwind_data_reg for risc-v 32-bit </cmt> <cmt> library/std: linux: add support for risc-v 32-bit </cmt> <cmt> library/std: raw: add support for risc-v 32-bit </cmt> <cmt> library/std: sys_common: add support for risc-v 32-bit </cmt> <cmt> library/unwind: add support for risc-v 32-bit </cmt> <cmt> tools/build-manifest: add support for risc-v 32-bit </cmt>,build fixes for risc-v 32-bit linux support
235,"<desc> for : #5092 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> add unit test for embeddedpermissionpersistserviceimpl </cmt>",add unit tests for class embeddedpermissionpersistserviceimpl in nacos 2.0
236,"<desc> added maven package setup instructions as an alternative to intellij. also removed a duplicate java setup/install markdown file. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) @lanking520 @andrewfayres </desc> <cmt> added command line alternative to intellij </cmt> <cmt> removed the duplicate file </cmt>",added command line alternative to intellij in install instructions
237,"<desc> some further fix for #12779 will refine all dist deps in next pr. add op_role_var (the op attributes record corresponding parameter and gradient) when transpile to distributed program, in multi_device_graph_pass try to let one gradient's send op and it's recv op for the parameter locate on the same place. tested for cpu/gpu and sync/async mode </desc> <cmt> dist transpiler add control dependency var between send and recv </cmt> <cmt> fix async deps </cmt>",resovle multi gpu async deps
238,<desc> closes #23360 </desc> <cmt> feat(gatsby-recipes): use theme-ui preset as default index.js </cmt> <cmt> feat(gatsby-recipes): show elapsed timer when apply steps after 10 seconds </cmt> <iss> update the ui when the apply step has taken longer than 10 seconds </iss>,"while apply a step, show the time elapsed after 10 seconds"
239,"<desc> visiting a wildcard variable declaration (e.g. let _ = 4) with sourceentitywalker::walktodeclpre(decl *, charsourcerange) currently yields a range of length zero, whereas e.g. let x = 4 yields a range of length 1. the motivating use case for having a length-1-range here instead is to provide an accurate inlay type hint after the variable identifier, see apple/sourcekit-lsp#408 (comment) for details this pr therefore fixes the issue by defaulting to length 1 if the declaration doesn't have a name and an underscore occurs at the corresponding location in the source file. </desc> <cmt> add wildcard parameter case to variabletype test </cmt> <cmt> fix name range of wildcard names in walktodeclpre </cmt>",fix name range of wildcard declarations
240,<desc> fixes bug #71 (new installs fail because /var/lib/docker doesn't exist) and also makes a minor improvement to the download progress bar </desc> <cmt> minor formatting changes to progressreader. newlines when complete </cmt> <cmt> create docker directories *before* allocating a layerstore </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>,create /var/lib/docker so new installs don't fail
241,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> update-repo </cmt> <cmt> update-repo </cmt> <cmt> added access manager v3 types </cmt>",added pubnub access v3 api types
242,"<desc> contributes to #3283. right now maintainer has to type /gha run build-r-artifacts to prepare r-package for submission to cran. this pr moves cran package building from github actions to azure pipelines where we create all other artifacts. new job takes about 1 minute, so it doesn't significantly impact overall ci time. but with this job it is possible to attach cran artifact to releases automatically (refer to #3872 (comment)). @jameslamb could you please help to summarize what else should be done to close issue #3283? </desc> <cmt> build cran r-package on azure with every commit and attach to releases </cmt> <cmt> test ci </cmt> <cmt> fix path </cmt> <cmt> revert ci test </cmt>",build cran r-package on azure with every commit and attach it to releases
243,"<desc> in my work on the cdt pipeline, i discovered that the docker plugin for buildkite follows docker's philosophy of requiring you to explicitly import environmental variables into your container. this contradicts with the expected behavior of buildkite environmental variables, which are a set of variables available in all buildkite agents providing context about the current build. we write a lot of scripts which rely upon these buildkite environmental variables. this pull request adds the propagate-environment flag to explicitly tell the docker plugin for buildkite to import all the variables you see on the ""environment"" tab of any buildkite job into the running container so we can rely on them when writing automation scripts. i also did some refactoring of these yaml files for pull request 7148, so this pull request reflects that refactoring on develop. long-running tests tested in build 2560 and build 2562. update in pull request 7148 against the release/1.7.x branch, i also added error handling code to ctest in the test scripts. this addresses the case where ctest runs some tests and then throws a non-zero exit code, preventing artifacts from being uploaded. this code disables exit-on-error for the script, saves the ctest exit status, uploads artifacts (failing only when artifacts are not present and ctest exit status is zero), and then rethrows the ctest exit status at the end. update 2 removed the long-running tests as this pipeline has been centralized. see pull request 7159 for more information. none. none. none. </desc> <cmt> buildkite docker plugin now adds variables on ""environment"" tab to container </cmt> <cmt> updated buildkite yaml to match release/1.7.x branch </cmt>",buildkite docker plugin propagate-environment and ctest error handling
244,"<desc> firstly, the indicators in cpusidebar aren't shown for loopxx instructions. also, back in the days when you selected loopxx instruction, you could spot the hint like ""jump is taken"" or ""jump is not taken"" in the cpuinfobox. i believe this was deleted by this commit 6348cb5 after changes in cpuinfobox::disasmselectionchanged because it is still present in my april snapshot. however, it was working incorrectly. this is, because the loop instruction firstly decrements the ecx, then checks if it's != 0. i will try to explain it using images. ecx = 0, ""jump is not taken"" in the info box however... the jump is in fact taken, ecx = 0xffffffff now when the ecx = 1, ""jump is taken"" in the info box however... the jump is not taken, ecx = 0 x64dbg needs to check whether the ecx = 1 to check if the branch is going to execute, that is because both decrementation and comparison is done inside the cpu loop instruction handler </desc> <cmt> gui: make loop conditional instruction, fixes #2366 </cmt> <cmt> zydis: fixed isbranchgoingtoexecute for loopxx instructions </cmt>",changes connected to loopxx instructions
245,"<desc> description: allow -l warn to configure log level, and sanity check arg value. risk level: low testing: unit test docs changes: n/a release notes: n/a fixes #9560 </desc> <cmt> allow -l warn to configure log level on startup, and protect against invalid values for log level. </cmt> <cmt> update allowed log levels in usage </cmt> <iss> envoy_log(warn, ...) vs -l warning inconsistency </iss>","allow ""-l warn"" and protect against invalid arg values"
246,"<desc> add error info when fc bias shape is not 1d issue 15032 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change @patriczhao @taolv @anirudh2290 </desc> <cmt> add fail info for mkldnn fc </cmt> <cmt> fix lint </cmt>",add error info when mkldnn fc bias dimension is wrong
247,"<desc> followup #3306 </desc> <cmt> remove util methods from cli/resources.rs </cmt> <cmt> try resource table on state </cmt> <cmt> remove global resource table </cmt> <cmt> cliresource -> streamresource, remove cli/resources.rs </cmt> <cmt> fix stdio resources </cmt> <cmt> fix stdout </cmt> <cmt> add hack not to drop worker </cmt>","per-worker resource table, take 2"
248,"<desc> even after tokuhirom/test-tcp#59 went in, we have been seeing occasional ci errors (for an example, see  this might be (at least partly) due to us calling empty_port with no argument (thus looking for an empty port on 127.0.0.1) and then trying to use that port on 0.0.0.0. this pr fixes the issue in either of the two ways depending on the tests being run: look for an empty port on 0.0.0.0 (by calling empty_port({ host => '0.0.0.0' })) bind using the loopback address (i.e. 127.0.0.1) to the empty port being found </desc> <cmt> call empty_port for 0.0.0.0 since that is the address we listen to </cmt> <cmt> remove unused import </cmt> <cmt> redis-server binds to 0.0.0.0 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> remove unused import </cmt> <cmt> remove unused import </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> plack::server::standalone binds to 0.0.0.0 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> remove unused import </cmt> <cmt> bind to 127.0.0.1 </cmt> <cmt> remove unused import </cmt>",check avialability of correct address
249,<desc> small typo correction to text in two i18n.json files how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> [fix]: corrects typo in english i18n.json file </cmt> <cmt> [fix]: corrects typo in belarusian i18n.json file </cmt> <cmt> this will need to be re-translated in belarusian </cmt>,corrects typo in analytics section of the admin page
250,<desc> this pr enables debugging with vscode's ptvsd on a local docker setup. update readme with instructions on how to start debugging - getredash/website#192 bring back --reload by creating a dedicated debug docker entry point (@arikfr wdyt?) </desc> <cmt> open port 3000 for remote debugging </cmt> <cmt> add ptvsd </cmt> <cmt> use port 5678 to avoid changes in vscode's default config </cmt> <cmt> attach to ptvsd </cmt>,enable remote debugging with ptvsd
251,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> remove unused is_command() instances from keyboard-level config.h, 0-9 </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, a-b </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, c-d </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, e-g </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, handwired </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, h-m </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, n-r </cmt> <cmt> remove unused is_command() instances from keyboard-level config.h, s-z </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, 0-9 </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, a </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, b </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, c </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, d-e </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, f-h </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, handwired </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, i-k </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, l-m </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, n-r </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, s-v </cmt> <cmt> remove unused magic key definitions from keyboard-level config.h, w-z </cmt>",remove unused is_command() instances and magic key definitions
252,"<desc> while here, respect the host default compiler of cc. if that fails, then try gcc and finally clang. now i can do ./configure make and there are zero warnings when cc is clang on netbsd. </desc> <cmt> toupper(3) says the argument should be of type int </cmt> <cmt> move the format string into the {l,r}print_col() functions. </cmt> <cmt> this avoids a more invasive change to avoid warnings about </cmt> <cmt> passing an unchecked string as a format argument. </cmt> <cmt> prefer the host default compiler </cmt> <cmt> if that fails, fall back to gcc and then clang. </cmt>",fix build when clang is the compiler
253,"<desc> this consistently improves dev performance in chrome. before this change: create 10k rows: 7861 update 1k rows: 1405 update 1k rows: 1337 update 1k rows: 1373 update 1k rows: 1340 update 1k rows: 1381 clear 10k rows: 1603 create 10k rows: 7799 update 1k rows: 1391 update 1k rows: 1339 update 1k rows: 1324 update 1k rows: 1338 clear 10k rows: 1567 after this change: create 10k rows: 6460 update 1k rows: 1312 update 1k rows: 1237 update 1k rows: 1231 update 1k rows: 1263 update 1k rows: 1248 clear 10k rows: 1083 create 10k rows: 6326 update 1k rows: 1298 update 1k rows: 1233 update 1k rows: 1245 update 1k rows: 536 update 1k rows: 1058 update 1k rows: 1299 clear 10k rows: 1104 this only seems to help dev in chrome. i did not observe any significant difference in prod in chrome, or in either build in firefox or safari. normally it would be too much dogscience but i feel the wins for chrome dev (most common use case) are significant, they are consistently reproducible, and it kinda makes sense to use numbers anyway. </desc> <cmt> ensure this._domid is always a number </cmt> <cmt> ensure this._rootnodeid is always a number </cmt>",improve dev performance in chrome
254,"<desc> this adds support for a virtual serial usb device. it appears along side the other hid devices when enabled. it is useful for being able to send over usb serial instead of as a hid device, in case you ever need such a thing., in my case, i wanted to use a serial device to emulate a stenograph machine to be used in plover. this is implemented for the ergodox, but can easily be adapted for others. macro functions can be used to send whatever you need over serial. </desc> <cmt> added usb virtual serial support </cmt> <cmt> txbolt (steno) serial protocol for ergodox ez </cmt>",virtual serial port - and a layout that uses that virtual serial port for plover
255,<desc> added top level 'tutorial' section added a 2 images to help illustrate tutorial ran through the tutorial and made small edits for clarity </desc> <cmt> tutorial ported from @spicyj's internal wiki to top-level navigation option </cmt> <cmt> fix the conflict </cmt> <cmt> fixed coloring for tutorial </cmt> <cmt> additional tutorial cleanup </cmt>,"new top level menu item tutorial, tutorial ported from @spicyj's internal course"
256,<desc> checked out the new release tag if found and do makes docs on it. rest of the logic stays same. added readable comments in many places so reader can follow the logic in the code. </desc> <cmt> temporary fix to update the verionsioning of 1.1.0 that is skipped during build process </cmt> <cmt> updated build_doc.sh </cmt> <cmt> testing new updates of build_doc.sh </cmt> <cmt> fixed comments and syntax </cmt> <cmt> removed test data and comments </cmt>,updated build_doc.sh to build on the new release tag found
257,<desc> this change moves all test files from the ./tests folder to ./tests/testdata and makes the cwd ./tests/testsdata for all these tests. </desc> <cmt> create new testdata folder. </cmt> <cmt> more fixes. </cmt> <cmt> fix remaining integration tests. </cmt> <cmt> fix module graph tests. </cmt> <cmt> fix remaining tests </cmt> <cmt> format. fix linting errors. </cmt>,move test files to testdata directory
258,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> updating the office-js with addin api and office-js-preview with the acoffice.actions.associate api. </cmt>,adding definition for sharedruntime api in office-js and adding office.actions.associate in office-js-preview
259,<desc> i ran clang scan-build on code derived from src/buffer.c and am upstreaming a couple of fixes. fix a resource leak in git_buf_try_grow when realloc returns null. minor fix to bounds on an assert in git_buf_join. assert in git_buf_join to keep static analyzers happy. don't pass null str_a to memmove.  it's undefined. add unit tests for calls to git_buf_join where buf->ptr and str_a overlap. </desc> <cmt> fix corner cases and an undefined behavior </cmt> <cmt> add unit tests for git_buf_join corner cases </cmt>,fix a couple of corner cases and an undefined behavior
260,"<desc> the readme file for the ergodox ez section suggested creating a pull-request to add our custom firmware, so i thought i'd give it a go. motivation essentially, i wanted to switch to a layout that was less jarring than the default ergodox ez layout, and did not require finger gymnastics to perform common os x shortcuts (most of which involve the cmd (lgui) key). how is it different from the default ergodox ez layout? this layout more closely resembles that of the mac keyboard, and has some other goodness baked in. here is a rundown of what that means: mac-like changes the key to the left of ""1"" is ""~"" instead of ""="". the key to the right of ""0"" is backspace instead of ""-"" (misleadingly labeled ""delete"" on the mac's keyboard). there was no room to fit in ""-"" and ""="" between ""0"" and backspace, unfortunately. the key to the left of ""q"" is tab instead of delete. the rightmost big key on the left thumb is cmd (lgui) instead of backspace. other changes the button to the left of ""a"" is ctrl/esc instead of backspace. this is actually how i have the keyboard on my macbook set up to be, since it's loads more convenient than a  caps lock key. this is the ctrl key i find myself using most. the key to the right of ""5"" and the key to left of ""6"" are ""["" and ""]"", respectively, instead of left and right. there is a more convenient set of left and right already present. truth be told, i don't really use these keys, as they are a stretch to reach. the toggle l1 keys have been replaced by the otherwise displaced ""-"" and ""="". they are laid out, left-to-right, in the same order as on the mac keyboard. honestly, they are not terribly conveniently placed, and their placement might change in a later version. i found that i did not toggle l1 frequently at all, and found using the momentary keys to access l1 to fit my workflow better. the ""~""/l1 key in the bottom-left is now just momentary l1. the ""~"" key was moved to the top-left as mentioned before, and i like to keep my multi-use keys to a minimum due to the latency for them to switch from ""press"" to ""hold."" the home and end buttons have been shifted up on the left thumb, and shift inserted below them. this makes doing shift-5 and other such combinations less painful. the page up and page down buttons have been shifted up on the right thumb, and alt was moved from above them to below them. i use alt more than page up or page down (mostly in terminal applications), and thought that it deserved a more accessible location. i'm always open to feedback and/or suggestions! </desc> <cmt> version 1.0.0 </cmt> <cmt> change lower-left control to momentary l1 </cmt> <cmt> there's so many control keys in this keymap, one needed to go. so, i changed </cmt> <cmt> the lower-left control key to be a momentary l1, just like the same key on the </cmt> <cmt> right side. </cmt>",add j3rn's mac-centric ergodox ez keymap
261,<desc> fixes #7058 allows classes to access private and protected member of parent (enclosed) classes. </desc> <cmt> allow private and protected class members to be accessible in nested classes </cmt> <cmt> added tests </cmt> <cmt> accept baselines </cmt> <iss> private/protected class members not accessible in nested classes </iss>,nested private and protected class members
262,"<desc> let's not release stuff with known java incompatiblities, e.g. we know will break in java 9, and could technically even break going forwards in java 8, e.g. calling  this is a backport of all bugfixes so that 2.1 won't have compatibility issues. </desc> <cmt> add java 9 support for bootclasspath to jvminfo (it throws uoe otherwise which is not properly handled) </cmt> <cmt> update to forbidden-apis 2.0 </cmt> <cmt> disable mockfilesystems in 2.1, as they do broken reflection incompatible with java 9 </cmt> <cmt> fix mvn verify under jigsaw </cmt> <cmt> get our stats back by reflecting mxbeans correctly </cmt> <cmt> backport removal of illegal test </cmt> <cmt> remove unnecessary permissions that are not possible in java 9 </cmt> <cmt> make logger final so its not detected as a static leak </cmt> <cmt> suppressfilesystems in this straggler </cmt>",fix mvn verify on jigsaw with 2.1
263,"<desc> this pr allows one to build the user documentation with python 3 and sphinx>= 2.4.0. it also removes several warnings. remove autogenerated js doc (backport from master) forward-port-of: #47027 forward-port-of: #46069 </desc> <cmt> [fix] doc: cherry pick of e4b75149f7c </cmt> <cmt> remove js apidoc </cmt> <cmt> breaks doc-building all the time, more advanced es6 features are not </cmt> <cmt> supported by the js parsing library </cmt> <cmt> x-original-commit: 9ac8ac990ebac41a45dee804e86fbfe56fccd02d </cmt> <cmt> [fix] doc: remove warning block quote ends without a blank line </cmt> <cmt> before this commit, the following warnings were displayed: </cmt> <cmt> odoo/doc/reference/orm.rst:714: warning: block quote ends without a blank line; unexpected unindent. </cmt> <cmt> odoo/doc/reference/orm.rst:721: warning: block quote ends without a blank line; unexpected unindent. </cmt> <cmt> odoo/doc/reference/orm.rst:728: warning: block quote ends without a blank line; unexpected unindent. </cmt> <cmt> odoo/doc/reference/orm.rst:735: warning: block quote ends without a blank line; unexpected unindent. </cmt> <cmt> x-original-commit: 3aa41a5131bbc08d7390f207ca84d7a6994d29cd </cmt>",compatible python 3 and sphinx 2.4
264,"<desc> currently, using st.empty() (or st.cache/st.spinner, which use st.empty internally) will break static sharing because of recent changes to the frontend. specifically, the frontend now requires that delta ids start from 0 and increment by 1 for each new delta in each container. because we remove st.empty deltas from serialized reports, we break the implicit ""sequential delta id"" rule, and the frontend crashes when trying to view a shared report that used st.empty. this example app will demonstrate the breakage: run the app, share it, and try to view the shared report: import streamlit as st st.empty() st.write(""i'm not shareable!"") this pr does a few things. the most basic and important thing is: st.emptys are no longer stripped from shared reports. (fixes #827, which is the original motivation here.) to facilitate that, it also does a few other things: global.sharingmode=""file"" is now a supported config option. if you use this sharing mode, your protobufs will be serialized to frontend/public/reports, which allows them to be served by the dev server. this is obviously not intended for users; while it's not harmful if they use it, config.py now emits a warning upon config loading if this option is set and global.developmentmode is not. (this means that testing changes to static sharing no longer requires the ""make build -> run app -> share to s3 -> try to debug minified javascript"" routine; you can do it all from the devserver.) the frontend staticconnection code has been refactored and simplified a bit to account for the new sharing mode. there's now a test for reportsession.handle_save_request that ensures the serialized data is what we expect. i've not added frontend/public/reports to the .gitignore, which means that if you use global.sharingmode=""file"", you'll end up with a bunch of uncommitted serialized report data in your frontend folder. you should remove these before doing a make build so that they don't end up in a pypi wheel file or anything. (make clean will remove them.) next steps the ""strip st.empty deltas out of shared reports"" functionality was in streamlit to prevent serialization of the st.empty's that get auto-created by st.cache. since we'd still like to prevent cache-induced serialization spam, the next step is to change st.spinner (which st.cache uses, and which is what actually creates the additional empties) to be more clever, and probably not involve delta-creation at all. </desc> <cmt> remove unused variable </cmt> <cmt> remove unused import </cmt> <cmt> re-enable global.sharingmode = ""file"" </cmt> <cmt> save local report files to frontend/public, so we can fetch them at the expected location </cmt> <cmt> unify s3 report object fetching </cmt> <cmt> simplify s3 object fetching </cmt> <cmt> config: show a warning if the user has ""sharingmode=file"" and they aren't in developmentmode </cmt> <cmt> do *not* strip out empty delta messages when serializing a report </cmt> <cmt> this breaks report sharing, because the frontend expects delta ids to be sequential </cmt> <cmt> don't calculate num_deltas; it's not used anywhere </cmt> <cmt> remove unused imports </cmt> <cmt> fix report_test.py </cmt> <cmt> reprotsession serialization test </cmt> <iss> snapshot crashes when using @st.cache </iss>",fix st.empty breakage inside shared reports
265,"<desc> fix #5155 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> wip: add nacosnamingmaintainservicetest </cmt> <cmt> wip </cmt> <cmt> add  nacosnamingservicetest </cmt>",add unit tests for package com.alibaba.nacos.client.naming.remote in nacos 2.0
266,"<desc> unchanged backport of #17188. </desc> <cmt> [flink-23864][docs] add flink-connector-pulsar module to flink-docs, auto generate the config document. </cmt> <cmt> [flink-23864][connector/pulsar] release pulsar message if user enable poolmessage option. </cmt> <cmt> [flink-23864][connector/pulsar] remove pulsar_auto_update_partitions option. </cmt> <cmt> [flink-23864][docs] add pulsar connector document (chinese & english). </cmt>",add pulsar connector document [1.14]
267,<desc> follow up of  #455 pull request. </desc> <cmt> alow to disable a downloader handler just like any other component. </cmt> <cmt> tests for loading download handlers </cmt> <cmt> fix minor typo in downloaderhandlers comment </cmt> <cmt> doc for disabling download handler </cmt> <cmt> minor fixes in loadtestcase in test_downloader_handlers </cmt> <cmt> * same __init__ parameters in both download handlers's mocks </cmt> <cmt> * additional assertion in test_disabled_handler </cmt>,allow to disable a downloader handler just like any other component
268,"<desc> d3.geo.stream incorrectly treated geometrycollection as a higher-level object type, rather than a geometry type as specified in the geojson spec. this caused bounds calculations to be incorrect on feature/featurecollection objects that contained geometrycollection geometries. patch adds a test for this case and corrects the handling of geometrycollection in d3.geo.stream (and therefore d3.geo.bounds). </desc> <cmt> test for problematic nesting case </cmt> <cmt> geometrycollection is a *geometry*, not objecttype (c.f. </cmt>","in d3v3, geo.bounds stopped working for geometrycollection within feature"
269,"<desc> conflicts: luck of read error handling in 5.0 branch. </desc> <cmt> implement module api for aux data in rdb </cmt> <cmt> other changes: </cmt> <cmt> * fix memory leak in error handling of rdb loading of type obj_module </cmt> <cmt> (cherry picked from commit 3b6aeea44cf8bdc64214a5f145da55453722a9a2) </cmt> <cmt> fix to module aux data rdb format for backwards compatibility with old check-rdb </cmt> <cmt> when implementing the code that saves and loads these aux fields we used rdb </cmt> <cmt> format that was added for that in redis 5.0, but then we added the 'when' field </cmt> <cmt> which meant that the old redis-check-rdb won't be able to skip these. </cmt> <cmt> this fix adds an opcode as if that 'when' is part of the module data. </cmt> <cmt> (cherry picked from commit 3bfcae247a1c51788940bd4d2f32751ead451e42) </cmt>",backport module rdb aux data into 5.0
270,"<desc> addresses #20308 this pr ensures radiusneighborsclassifier is compatible with numpydoc. remove radiusneighborsclassifier from docstring_ignore_list. remove deprecate unused parameter kwargs from radiusneighborsclassifier. verify that all tests are passing. add test to check that the futurewarning is correctly raised. just to reiterate, note that the parameter kwargs was removed deprecated from the __init__ method of radiusneighborsclassifier since it was not used. </desc> <cmt> remove radiusneighborsclassifier from docstring_ignore_list. </cmt> <cmt> fix numpydocs from radiusneighborsclassifier. </cmt> <cmt> remove unused parameter  from radiusneighborsclassifier. </cmt>",doc ensures that radiusneighborsclassifier passes numpydoc validation
271,<desc> this fixes golint failures under test/e2e/upgrades/.... ref: #68026 does this pr introduce a user-facing change?: </desc> <cmt> fix golint failures for test/e2e/upgrades/apps </cmt> <cmt> fix golint failures for test/e2e/upgrades/storage </cmt> <cmt> fix golint failures for test/e2e/upgrades </cmt>,fix golint failures for e2e/upgrades/...
272,"<desc> at the moment, the --use-preload-cache option stores everything under one entry in indexeddb which causes issues for preloads >133169152 bytes(?), this pr adds support for chunking the cache into separate entries. (sidenote: i'm not entirely sure i made these commits correctly, let me know if i messed it up) </desc> <cmt> add support for chunked persistence </cmt> <cmt> consistent use of .md for markdown files (#7300) </cmt> <cmt> cleanup rst files. nfc. (#7301) </cmt> <cmt> - convert tabs to spaces. </cmt> <cmt> - remove trailing whitespace </cmt> <cmt> cleanup create_runtime_funcs. nfc. (#7272) </cmt> <cmt> webidl binder: define properties with js accessors (#7298) </cmt> <cmt> currently c++ class and struct properties are defined in javascript bindings with get_foo and set_foo accessor methods. this pr adds support for directly accessing the properties using native js accessors. for example: </cmt> <cmt> // current way </cmt> <cmt> myobject.set_foo(1); </cmt> <cmt> console.log(myobject.get_foo()); </cmt> <cmt> // after this pr: </cmt> <cmt> myobject.foo = 1; </cmt> <cmt> console.log(myobject.foo); </cmt> <cmt> this is more idiomatic javascript, and means that the bindings match the idl correctly. i have left the existing getters and setters in place, so this is be backward-compatible. </cmt> <cmt> explain what happens if error_on_undefined_symbols is set to 0 (#7287) [ci skip] </cmt> <cmt> comment on memory growth [ci skip] (#7297) </cmt> <cmt> add number of wasm funcs to other.test_metadce (#7307) </cmt> <cmt> * but ignore # of functions in main module, it changes a lot </cmt> <cmt> support input from the global module object in modularize_instance (#7293) </cmt> <cmt> fixes #7101 </cmt> <cmt> background: normally, if you define module and properties on it, like prerun, then we notice that and use them. in modularize, however, the user creates the instances of the module, and can pass module or something else as desired (if we passed module there it might be surprising). however, in modularize_instance mode we are more like the normal mode in that there is a single instance, started automatically, and defining things on module is how the user can influence it. </cmt> <cmt> add docs for upgrading bundled libs [ci skip] (#7286) </cmt> <cmt> fix export_all with wasm backend (#7310) </cmt> <cmt> the semantics of export_all are not that we should avoid doing </cmt> <cmt> any gc but rather that any symbols that survive gc should be </cmt> <cmt> exported. </cmt> <cmt> report missing exported_functions by default (#7311) </cmt> <cmt> cleaner handling of clusure compiler errors (#7313) </cmt> <cmt> previously you would see an emscripten internal backtrace </cmt> <cmt> if closure compiler failed. </cmt> <cmt> sadly we have a lot of existing warnings so we don't display </cmt> <cmt> the process stderr unless we the subprcess returns non-zero. </cmt> <cmt> i guess we should try to address the closure warnings, at least </cmt> <cmt> the ones in emscripten proper. </cmt> <cmt> clean up file_packager </cmt>",add support for caching large preloads
273,"<desc> please answer these questions before submitting a pull request why submit this pull request? bug fix new feature provided improve performance related issues bug fix bug description. how to fix? new feature or improvement describe the details and related test reports. hi~ now we use spring @scheduled to execute scheduled tasks, but it seems to be not supported. so i add the client side support.  please see if it makes sense. </desc> <cmt> pull request </cmt> <cmt> support spring @scheduled annotation </cmt>",add support for spring @scheduled
274,<desc> cherry pick e37dfda 2d891d9 247899a </desc> <cmt> [v1.x] update armpl version (#20332) </cmt> <cmt> * update armpl version </cmt> <cmt> * enable apl </cmt> <cmt> * downgrade openblas to 3.13 </cmt> <cmt> * update dockerfile </cmt> <cmt> [v1.x] use armpl as blas for mxnet aarch64 wheels (#20342) </cmt> <cmt> * use armpl as blas for mxnet </cmt> <cmt> * link libgfortran </cmt> <cmt> * fix cpath </cmt> <cmt> * rectify if condition </cmt> <cmt> * update armpl macro </cmt> <cmt> * remove lapacke.h as duplicate of cblas.h </cmt> <cmt> specify arm cd armpl include path (#20364) </cmt> <cmt> workaround </cmt>,cherry-pick armpl changes from v1.x
275,<desc> i added the right row export to display the discussions list 2021-04-14.18-02-36.mp4 fixes #21547 </desc> <cmt> updating the code </cmt> <cmt> updating the code </cmt> <cmt> updating the fork </cmt> <cmt> update main branch </cmt> <cmt> updating the branch </cmt> <cmt> update fork </cmt> <cmt> upating the fork </cmt> <cmt> correcting the discussions problem </cmt> <iss> the application crashes when you try to open the discussions list </iss>,fix the bugs opening discussions
276,"<desc> made some small adjustements that make the nel functionality resemble the code for the other pipes more closely. this will be followed by another pr which has the (updated) documentation for all this functionality. goldparse gold.links is now a dictionary with (ent.start_char, ent.end_char) keys and the values being dicts with kb_id:value entries, representing the kb ids mapped to either 1.0 or 0.0, indicating positive and negative examples respectively. this is similar to the gold.cats field for text classification. for training, all the kb_id: value combinations are used, including the negative cases for testing (accuracy measurement), only the positive cases are checked entitylinker gold.links now corresponds 1-to-1 to doc.ents which allows a more proper chaining of entity_linker.predict() and entity_linker.get_loss() functions etc (just like for the other pipes) entitylinker also now returns tensors as part of its predict() output default context_width set to 128 kb new methods in kb: get_vector and get_prior_prob to easily access information about entities & aliases, + unit tests in kb.pyx, renamed entity prob to freq (entity frequency in a corpus) to avoid confusion with prior_prob (which refers to the probability of an alias being linked to an entity) errors.e144 when entity_width or context_width could not be found when building the nel model created kb directory if it didn't exist to address issue #4000 misc black processing caused a lot of edits in the files small fix in tokenizer.pyx documentation enhancement i have submitted the spacy contributor agreement. </desc> <cmt> tokenizer doc fix </cmt> <cmt> proper error for missing cfg arguments </cmt> <cmt> set default context width </cmt> <cmt> small fix </cmt> <cmt> code cleanup </cmt> <cmt> get vector functionality + unit test </cmt> <cmt> fixes in kb and gold </cmt> <cmt> filter training data beforehand (+black formatting) </cmt> <cmt> use original gold object in get_loss function </cmt> <cmt> have gold.links correspond exactly to doc.ents </cmt> <cmt> output tensors as part of predict </cmt> <cmt> formatting </cmt> <cmt> rename entity frequency </cmt> <cmt> fix for issue #4000 </cmt> <cmt> test corner cases </cmt>",api changes for entity linking functionality
277,"<desc> fixes a typeerror when deleting a task result with s3 backend. this links to #5721, which already solved this problem for .get() and .set(), but not for .delete() </desc> <cmt> convert key from bytes to str </cmt> <cmt> add unit test for s3 delete of key with type bytes </cmt>",fix type error in s3 backend
278,"<desc> currently, selectabletext always stays alive, which can create two problems observed in #91509: performance can suffer in long lists of selectabletexts. selectabletext can cause a primaryscrollcontroller to stay connected unexpectedly. i've changed selectabletext's wantkeepalive to match editabletext, so it only stays alive if it's focused: flutter/packages/flutter/lib/src/widgets/editable_text.dart line 1567 b5e1ebd bool get wantkeepalive => widget.focusnode.hasfocus; @chunhtai do you know of any reason we shouldn't do that? i've also added some docs to try to warn developers about the second problem a bit.  @piinks is there anywhere else i should document that? fixes #91509 </desc> <cmt> selectabletext will only keepalive when it has selection, and docs improvement </cmt> <cmt> test that selection is preserved </cmt> <cmt> actually, let's do this based on focus like editabletext </cmt> <iss> nestedscrollview + tabbar + selectabletext: unexpected behaviour when scrolling </iss>",selectabletext keep alive only when it has selection
279,<desc> this pr fixes a number of alerts reported by lgtm.com (@lgtmhq). there is a good number of other alerts well worth looking at here:  you can set up automated pull request reviews on lgtm.com as well! </desc> <cmt> fix lgtm.com alert: can't compare bool to string (operator precedence) </cmt> <cmt> details: </cmt> <cmt>  </cmt> <cmt> fix lgtm.com alerts: nullness check using !== operator </cmt> <cmt> details: </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt>,fix lgtm.com alerts: equality tests
280,"<desc> button ""enable auto-completion in data filter text"" in preferences/dbeaver/editors/dataeditor/presentation adding org.jkiss.dbeaver.ui.editors.data in german, russian localized </desc> <cmt> #8461 new button in preferences/dbeaver/editors/dataeditor/presentation adding with auto-complition in data filter text </cmt> <cmt> #8461 resultsetmessages localized in org.jkiss.dbeaver.ui.editors.data </cmt>",#8461 button enable auto-complete in preferences/data editor adding
281,<desc> revert 8302b5a and a temporary fix for runtime env blocking and that also prevent workers from starting up too fast (before #17154 can be solved). closes #16226 closes #16537 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> re-revert </cmt> <cmt> surgical fix </cmt> <iss> [runtime_env] installing a second environment seems to make workers in a first environment unschedulable </iss> <iss> unit & integration tests for runtime_env scheduler blocking </iss>,fix runtime env and dispatch queue take 2
282,<desc> see commits comments for details :) </desc> <cmt> fix and improvements to the backend documentation </cmt> <cmt> improved preamble of the backend.md template: </cmt> <cmt> - fixed a typo </cmt> <cmt> - added few notes that makes the documentation more self explanatory </cmt> <cmt> - made all code examples running by copy&paste </cmt> <cmt> aligned the format of the  backend() function </cmt> <cmt> fixed docstring of set_image_dim_ordering() function </cmt> <cmt> fixed a typo in %userprofile% env name for window users </cmt>,improvements in the documentation of backend
283,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo: coverage service link (codecov, coveralls, gocover etc.) very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> fix typo in readme.md </cmt> <cmt> fixes #3204 </cmt> <cmt> fix typo in readme.md </cmt> <cmt> test </cmt> <cmt> delete main.yml </cmt> <cmt> modify workflow </cmt>",fix test stale repositories workflow
284,<desc> no-issue this means that we no longer make requests to the stripe api for every request </desc> <cmt> installed @tryghost/members-ssr@0.4.0 </cmt> <cmt> no-issue </cmt> <cmt> this now supports caching of the data returned by the members-api </cmt> <cmt> renamed cookies set by members-ssr </cmt> <cmt> no-issue </cmt> <cmt> as discussed with @erisds i have prefixed these cookies with ghost </cmt>,cached members-api data in members-ssr cookie
285,"<desc> since envoy uses a time system that allows injecting mock timestamps, there is no need to support timestamp parsing in the production code. in the test code, this is cleanly abstracted out as a test-only utility function. risk level: low testing: ran affected tests docs changes: n/a release notes: n/a </desc> <cmt> use test utility to parse timestamps </cmt> <cmt> forbid the use of std::get_time </cmt> <cmt> there is an existing test utility for parsing timestamps according to a </cmt> <cmt> format string, and non-test code should be using the injectable time </cmt> <cmt> system support instead of parsing real timestamps. </cmt>",remove timestamp parsing with std::get_time
286,"<desc> this continues the port of the java comparison tool to python. changes to the blockstore and a small change in main.cpp are in separate commits. this includes and runs both the ""inexpensive"" and ""barely expensive"" tests. the ""barely expensive"" test (which consists of a few re-orgs) take a minute or two on my machine. java test is here: </desc> <cmt> tests: rework blockstore to avoid re-serialization. </cmt> <cmt> continuing port of java comptool </cmt> <cmt> catch exceptions from non-canonical encoding and print only to log </cmt>",continuing port of java comparison tool
287,"<desc> fixes #2340 in the future, we should use chunkhash of each file for better caching. for now, we can't do this with our webpack/babel setup. (specially with ssr) we can do that for all assets in the future. </desc> <cmt> add buildid to the path of dynamic chunks. </cmt> <cmt> add buildid to the webpack devserver's path. </cmt> <cmt> add static export support. </cmt> <cmt> update with-dynamic-import example. </cmt> <cmt> remove async-reactor since it's buggy. </cmt> <cmt> add static export support. </cmt>",use buildid in chunk urls as well
288,<desc> linear_assignment can now be imported from scipy #13464 removed the use of sklearn.utils.linear_assignment_ and _hungarian and replaced it with scipy.optimize.linear_sum_assignment tweaked test case for _hungarian so that it works with scipy.optimize.linear_sum_assignment more info can be found here #13464 </desc> <cmt> merge fork </cmt> <cmt> merge fork </cmt> <cmt> merge fork </cmt> <cmt> importing linear assignment from scipy </cmt>,mnt import linear assignment from scipy
289,"<desc> fixes #29337. mksnapshot.zip for macos arm64 (apple silicon) was missing two needed files: mksnapshot_args and clang_x64_v8_arm64/gen/v8/embedded.s.  this pr adds those files to mksnapshot.zip for macos arm64 pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed using custom v8 snapshots on apple silicon. </desc> <cmt> build: include mksnapshot args in arm64 mksnapshot.zip </cmt> <cmt> get gen/v8/embedded.s from proper location </cmt> <iss> [bug]: using custom v8 snapshots on apple silicon does not work </iss>",ensure that mksnapshot for apple silicon has all of the needed files for snapshot generation
290,"<desc> this should finally finish addressing #381. note i haven't actually tested the example applications yet, so i may have introduced bugs. </desc> <cmt> test examples for pep8 compliance. </cmt> <cmt> make rl_pong example pep8 compliant. </cmt> <cmt> make policy gradient example pep8 compliant. </cmt> <cmt> make lbfgs example pep8 compliant. </cmt> <cmt> make hyperopt example pep8 compliant. </cmt> <cmt> make a3c example pep8 compliant. </cmt> <cmt> make evolution strategies example pep8 compliant. </cmt> <cmt> make resnet example pep8 compliant. </cmt>",make example applications pep8 compliant.
291,"<desc> loaders are applied in the wrong order when using inline match resource, as shown in #9053. the resulting behaviour does not match the expected behaviour as described by the documentation. i'm attempting to write a loader which depends on matchresource working as documented, and the bug has been open for a while with no progress. a bugfix. yes. unsure. all tests were run and passing locally, but not sure if fix as written is appropriate, so opening a pr for review/guidance. hopefully none, as this makes matchresource behave as documented, however see above. </desc> <cmt> add test case for #9053 </cmt> <cmt> fix loader ordering </cmt>",wrong loaders order when using inline match resource
292,"<desc> requested in #5242. for example i use bestvideo[height<=?1080][width<=?1920][ext!=?webm]/best[height<=?1080][width<=?1920],bestaudio, which can be written now as (bestvideo[ext!=?webm]/best)[height<=?1080][width<=?1920],bestaudio. since i thought that using regexes would be hard, i decided to use tokenize.tokenize to split the spec in strings and operators (it also checks if there are missing brackets or parenthesis). i admit that the implementation is a bit ugly, so we may want to rethink it or clean it (maybe moving it to utils.py), but it works. the filters (everything inside []) is still processed with the same regexes, because it's simpler and i haven't thought of an alternative implementation. @haasn your string (bestvideo[tbr<13000][height>720]/bestvideo[tbr<13000][fps>30])+(bestaudio[ext=webm]/bestaudio) seems to be parsed correctly, but i'd like to verify it works as expected. </desc> <cmt> [youtubedl] rework how the format spec is processed </cmt> <cmt> the spec string is processed using 'tokenize.tokenize' to split it in words and operators, the filters are still processed using regular expressions. </cmt> <cmt> this should make easier to allow grouping operators with parens. </cmt> <cmt> [youtubedl] format spec: treat 'all' like a normal specifier </cmt> <cmt> so you can use filters with it, for example 'all[width>=400][width<=600]'. </cmt> <cmt> [youtubedl] format spec: allow grouping specifiers with parentheses </cmt>",allow grouping specifiers in -f
293,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues #3777 bug fix bug description. how to fix? new feature or improvement describe the details and related test reports. </desc> <cmt> shardingsphere 4.x rc3 test </cmt> <cmt> shardingsphere 4.x rc3 test </cmt> <cmt> shardingsphere 4.x rc3 test </cmt> <cmt> shardingsphere 4.x rc3 plugin </cmt> <cmt> shardingsphere 4.x rc3 plugin </cmt> <cmt> # conflicts: </cmt> <cmt> #	.github/workflows/plugins-test.yaml </cmt> <cmt> shardingsphere 4.x rc3 plugin </cmt>,provide plugin for shardingsphere 4.0.0-rc3
294,"<desc> will need to open a pr for getsentry but starting in sentry for discussion the default we're currently using. browsers like baidu, op_mini, kaios are telling babel preset to bring in all kinds of core-js functions we don't need. npx browserslist --env=""production"" and_chr 89 and_ff 86 and_qq 10.4 and_uc 12.12 android 89 baidu 7.12 chrome 89 chrome 88 chrome 87 edge 89 edge 88 firefox 86 firefox 85 firefox 78 ie 11 ios_saf 14.0-14.5 ios_saf 13.4-13.7 kaios 2.5 op_mini all op_mob 62 opera 73 opera 72 safari 14 safari 13.1 samsung 13.0 samsung 12.0 this pr chrome 91 chrome 90 chrome 89 chrome 88 chrome 87 chrome 86 chrome 85 chrome 84 chrome 83 chrome 81 edge 91 edge 90 firefox 90 firefox 89 firefox 88 firefox 87 firefox 86 firefox 85 firefox 84 firefox 83 firefox 82 firefox 81 firefox 78 ios_saf 14.5-14.7 ios_saf 14.0-14.4 ios_saf 13.4-13.7 ios_saf 13.3 ios_saf 13.2 ios_saf 13.0-13.1 ios_saf 12.2-12.4 ios_saf 12.0-12.1 op_mob 62 safari 14.1 safari 14 safari 13.1 safari 13 from looking at what bundle analyzer says, this change would take us from 215 kb to 91 kb gzipped of core-js </desc> <cmt> feat(ui): add browserslist </cmt> <cmt> declare supported versions instead </cmt>","setup browserslist, reduce core-js use"
295,"<desc> this is in the same spirit as #2352. it inserts the engine as an indirection for creating and starting a container, with minimal disruption on the implementation and code structure. </desc> <cmt> separate a) initialization of the http api and b) actually serving the api into 2 distinct jobs </cmt> <cmt> engine: 'start' starts the specified container </cmt> <cmt> httpapi: don't create a pidfile if it isn't set in the configuration </cmt> <cmt> engine: fix a bug which caused handlers to be shared between multiple engine instances </cmt> <cmt> engine: don't export private testing utilities </cmt> <cmt> engine: improved logging and identification of jobs </cmt> <cmt> engine: optional environment variable 'logging' in 'serveapi' </cmt> <cmt> hack: simplify the creation of test directories </cmt> <cmt> engine: fix a bug when encoding a job environment to json </cmt> <cmt> better error reporting in engine logs and unit tests </cmt> <cmt> fix main() </cmt> <cmt> engine: 'create' creates a container and prints its id on stdout </cmt> <cmt> remove debug messages </cmt> <cmt> conflicts: </cmt> <cmt> engine/engine.go </cmt> <cmt> engine/job.go </cmt> <cmt> server.go </cmt> <cmt> utils_test.go </cmt>",expand the engine api with 'create' and 'start' jobs edit
296,<desc> my take on ben's pr. does this look more reasonable? / </desc> <cmt> propose unified rev-parse api </cmt> <cmt> implement unified git_revparse </cmt> <cmt> deprecate git_revparse_single and _rangelike </cmt> <cmt> add rev-list example to makefiles </cmt> <cmt> reintroduce git_revparse_single. </cmt> <cmt> redeploy git_revparse_single. </cmt> <cmt> change git_revparse to output git_object pointers </cmt> <cmt> this will probably prevent many lookup/free </cmt> <cmt> operations in calling code. </cmt> <cmt> clean up example code. </cmt> <cmt> clean up minor details </cmt> <cmt> is this crazy? </cmt>,"unified rev-parse, with a revision object"
297,<desc> fixes #454 fixes #701 </desc> <cmt> add webdialoghelper </cmt> <cmt> implement enumeratedirectory </cmt> <cmt> override => override in atom_browser_client.h </cmt> <cmt> implement runfilechooser </cmt> <cmt> upgrade brightray to handle localized string </cmt> <cmt> mac: add color chooser dialog </cmt> <cmt> aura: add color chooser dialog </cmt> <cmt> win: add color chooser dialog </cmt> <iss> clicking on file input elements doesn't show file dialog </iss> <iss> support for input type color </iss>,implement file dialog and color chooser for <input> tag
298,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. provide a url to documentation or source code which provides context for the suggested changes: release v.1.1.7 and release v1.1.8 increase the version number in the header if appropriate. i looked through the releases since 1.1.0 and it now seems to cover the new api. </desc> <cmt> new methods </cmt> <cmt> angular-google-analytics: fix typo in extended interface </cmt>,update api since release 1.1.0
299,"<desc> this work does the following: removes the banner add for typeform-based font awesome survey reinstates all other fonticons/black tie banner ads changes references in code and content from ""fonticons"" to ""fort awesome"" updates color combinations for fort awesome (using fa's off-black) and black tie banner ads note: the survey page ( reviewers ui, fed, and content - @davegandy </desc> <cmt> removing survey promotion to homepage </cmt> <cmt> updating banner ads visually and name-wise to reference fort awesome </cmt> <cmt> adjusting color settings for black tie banner ad </cmt>",remove font awesome feedback survey
300,"<desc> we've split docs.ansible.com/ansible/ and docs.ansible.com/ansible-core, but they still look identical. change the css for the core documentation to make it obvious which site you are looking at. fixes #73202. note: while the pr is wip, the .css file will remain maxified, in case we need to change it more. so far, this pr replaces the ansible ""lake"" (teal) color with ansible black. we'll minify the css before merging. docs.ansible.com/ansible-core for local builds: make coredocs builds the new /ansible-core/ colors make webdocs builds the familiar /ansible/ colors </desc> <cmt> updates core conf to use separate ccs file </cmt> <cmt> adds unminified core ccs file </cmt> <cmt> replaces lake color with ansible black </cmt> <iss> differentiate ansible vs ansible-core docsites via theme/color changes </iss>",change look and feel of the ansible-core docs
301,"<desc> addresses #16965 by showing eeprom errors on the lcd at startup if auto init is not enabled to automatically handle them. some handling for service messages to still function. i have not validated this and tested it here, ill leave that to the requester. </desc> <cmt> lcd alert eeprom error </cmt> <cmt> add flag to reset status so it only triggers if there is a service state to show </cmt>",set lcd status for eeprom errors
302,"<desc> fixes: #3656 (comment) component name /collectors/python.d.plugin/python_modules i tested, with the changes httpcheck module works with </desc> <cmt> python.d urlservice: ignore decode errors during decoding bytes (py3) </cmt> <cmt> python.d logger: ignore encoding errors in unicode </cmt> <iss> httpcheck do not accept urls that do not end with com </iss>","urlservice bytes decode, logger unicode encoding fix"
303,<desc> floating point from/to string conversion is a very complex topic. i just added the most basic implementation i could think of which is slightly different from the stuff in <ak/printfimplementation.h>. </desc> <cmt> ak: remove out() and warn(). </cmt> <cmt> ak: rename new_out to out and new_warn to warn. </cmt> <cmt> ak: add formatters for floating point numbers. </cmt>,rename new_out/new_warn to out/warn; add formatter for floating point numbers.
304,"<desc> this code is my proposal for closing #469. magic numbers are removed from both mnist and cifar10. cifar10 also features a reasonably intuitive approach to handling multiple layers with various pooling / filter sizes. i've tried following the general convention for variables and comments as set forth by other examples. note: it'd be a good idea to add a subsample / stride example in the near future as there are no tests / examples of that within keras and it's non-trivial but that's likely a separate issue. i've still not gotten subsampling to work in my code for the right whale recognition kaggle competition, where the high image resolution almost demands it. </desc> <cmt> remove magic numbers from mnist_cnn.py (re: #469) </cmt> <cmt> remove magic numbers from cifar10_cnn.py (fixes #469) </cmt>",removing magic numbers from mnist and cifar10
305,<desc> bpo-30320: test_eintr now uses pthread_sigmask() (#1523) test_eintr: fix resourcewarning warnings test_eintr: remove unused import bpo-25277: add a watchdog to test_eintr </desc> <cmt> bpo-30320: test_eintr now uses pthread_sigmask() (#1523) </cmt> <cmt> rewrite sigwaitinfo() and sigtimedwait() unit tests for eintr using </cmt> <cmt> pthread_sigmask() to fix a race condition between the child and the </cmt> <cmt> parent process. </cmt> <cmt> remove the pipe which was used as a weak workaround against the race </cmt> <cmt> condition. </cmt> <cmt> sigtimedwait() is now tested with a child process sending a signal </cmt> <cmt> instead of testing the timeout feature which is more unstable </cmt> <cmt> (especially regarding to clock resolution depending on the platform). </cmt> <cmt> (cherry picked from commit 211a392cc15f9a7b1b8ce65d8f6c9f8237d1b77f) </cmt> <cmt> test_eintr: fix resourcewarning warnings </cmt> <cmt> (cherry picked from commit c50cccfcc3b3a9ef3fe7a78b7e7271930dc24aee) </cmt> <cmt> test_eintr: remove unused import </cmt> <cmt> bpo-25277: add a watchdog to test_eintr </cmt> <cmt> set a timeout of 10 minutes in test_eintr using faulthandler. </cmt>,backport test_eintr enhancements from master to 3.5
306,"<desc> fix some assertions, hack out some others (they need more atl work). core-17505 </desc> <cmt> [explorer][shell32] add workaround for buggy window creation </cmt> <cmt> [netshell] release a pointer instead of leaking it </cmt> <cmt> [shellmenu] only clear a toolbar when it is created </cmt> <cmt> [shellmenu] properly delegate to ccontainedwindow </cmt>",fix some assertions now that they are enabled
307,"<desc> what this pr does / why we need it: builds equivalents of the various kubernetes release tarballs, solely using bazel. for example, you can now do $ make bazel-release $ hack/e2e.go -v -up -test -down special notes for your reviewer: this is currently dependent on ixdy/bazel@3b29803, which i have yet to turn into a pull request, since i'm still trying to figure out if this is the best approach. basically, the issue comes up with the way we generate the various server docker image tarfiles and load them on nodes: we md5sum the binary being encapsulated (e.g. kube-proxy) and save that to $binary.docker_tag in the server tarball we then build the docker image and tag using that md5sum (e.g. gcr.io/google_containers/kube-proxy:$md5sum) we docker save this image, which embeds the full tag in the $binary.tar file. on cluster startup, we docker load these tarballs, which are loaded with the tag that we'd created at build time. the nodes then use the $binary.docker_tag file to find the right image. with the current bazel docker_build rule, the tag isn't saved in the docker image tar, so the node is unable to find the image after docker loading it. my changes to the rule save the tag in the docker image tar, though i don't know if there are subtle issues with it. (maybe we want to only tag when --stamp is given?) also, the docker images produced by bazel have the timestamp set to the unix epoch, which is not great for debugging. might be another thing to change with a --stamp. long story short, we probably need to follow up with bazel folks on the best way to solve this problem. release note: </desc> <cmt> use custom io_bazel repo for docker_build changes </cmt> <cmt> reorder package_kube_manifests_tarball a bit to make it more readable </cmt> <cmt> refactor docker bazel rules and tag docker images </cmt> <cmt> add genrule to produce e2e_node.test binary artifact </cmt>",build release tars using bazel
308,"<desc> fix #10735 this pr did the following things: add lod_tensor.py utility module providing functions for ease of creating lodtensor in book examples. add test code for lod_tensor.py as an example, modify test_word2vec.py to show how to use the lod_tensor.py module in book examples. </desc> <cmt> add lod_tensor utility python module </cmt> <cmt> add lod_tensor test code </cmt> <cmt> add more lod tensor tests </cmt> <cmt> modify word2vec example code using new api </cmt> <iss> make the creation of lodtensor more user friendly in book examples </iss>",add lod_tensor.py for ease of creating lod tensor in book examples
309,"<desc> texture copies with ""incompatible"" formats (i.e. color <-> depth) were left unimplemented on opengl after tcr. this pr aims to implement format conversions by repurposing the existing method used for bgr <-> rgb texture format conversion. this is expected to fix a number of issues. for example: luigi's mansion 3 shadow trail lm3_bug.mp4 lm3_fix.mp4 bayonetta 2 cutscene dof bayo_bug.mp4 bayo_fix.mp4 closes #6845 closes #4220 </desc> <cmt> gl_texture_cache: rename bgrcopypass to formatconversionpass </cmt> <cmt> gl_texture_cache: make formatconversionpass more generic </cmt> <cmt> this allows the usage of the formatconversionpass to be applied to more than the previously used bgr conversion scenarios. </cmt> <cmt> texture_cache: use pixel format conversion when supported by the runtime </cmt> <iss> broken cutscene rendering in bayonetta 2 </iss> <iss> luigi's mansion, shadow stretching on open gl glsl, glasm </iss>",implement pixel format conversions for copies
310,<desc> ios_command not failing in case of receiving 'command authorization failed' in tacacs environments. adding that regex to terminal plugin makes the task to fail correctly. fixes #31575 terminal/ios </desc> <cmt> add 'command authorization failed' to stderr regex list </cmt> <cmt> add missing comma </cmt> <cmt> remove superfluous comma </cmt> <iss> ios_config incorrectly claims success when commands fail </iss>,command authorization failed ios regex
311,"<desc> instead of specialized locking and sleeping blocking strategies, allow using any waitstrategy as a fallback blocking strategy. make sleepingwaitstrategy configurable to allow for sleeping immediately without any retries, as wanted by phasedbackoffwaitstrategy. small typo fix </desc> <cmt> remove misplaced millis suffix </cmt> <cmt> arbitrary phasedbackoffwait fallback strategy </cmt> <cmt> * instead of specialized locking and sleeping </cmt> <cmt> blocking strategies, allow using any waitstrategy </cmt> <cmt> as a fallback blocking strategy. </cmt> <cmt> * make sleepingwaitstrategy configurable to allow </cmt> <cmt> for sleeping immediately without any retries, as </cmt> <cmt> wanted by phasedbackoffwaitstrategy. </cmt>",arbitrary phased backoff wait fallback + typo fix
312,"<desc> map height changed from 100vh to 100% in #5772, but now map doesn't appear at all. so i set body and html height to 100% in tutorial_frame.html layout. so map with height 100% should look good now. </desc> <cmt> fix map height in extending example </cmt> <cmt> add html and body styles to tutorial_frame </cmt> <cmt> move js styles to css </cmt> <cmt> remove unnecessary styles from mobile/example.md </cmt>","fix map styles in ""extending leaflet"" example"
313,<desc> can we add me in the owners file? the chart-pr from me was just approved (see #10922 ) but i missed creating an owners file directly. dco signed </desc> <cmt> add nextcloud chart </cmt> <cmt> insert suggestions from reviews in #5180 </cmt> <cmt> disable ingress per default </cmt> <cmt> fix nextcloud e2e tests </cmt> <cmt> [nextcloud] add owners file for further contribution </cmt>,nextcloud chart add owners for further contribution
314,"<desc> this add support for the emulated dogm through spi: spi_graphical_tft. add xpt2046 hw spi version too. recent mks boards have only spi for the tft. currently, the users can just use their lvgl ui. but the lvgl ui isn't complete. mks robin nano v2 and mks gen l 2.0 this pr add an option any other users that have only spi tft. may work with any spi tft. the default marlin default text menu is by far the most complete ui. a lot of users do prefer it. supports 180 screen rotation. text ui will never die!! </desc> <cmt> hw spi for touch buttons </cmt> <cmt> spi_graphical_tft emulated dogm using spi </cmt> <cmt> config spi_graphical_tft </cmt> <cmt> either </cmt>","spi emulated dogm (like fsmc_graphical_tft, but spi)"
315,"<desc> fixes #53612 do not gate the value setting behind the repeat check. this was causing samsung keyboards to freeze/crash when it was re-shown after dismissal. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> change repeat filter logic </cmt> <cmt> fix logic for tests </cmt> <cmt> test </cmt> <cmt> comments + cleanup </cmt> <iss> samsung keyboard crash/freeze when dismissing and reopening keyboard </iss>",un-gate value setting in formatter repeat check logic
316,"<desc> this backports #29190 and #29156. there are slight changes due to the integration tests because of incompatibilities in the test framework between 1.13 and master (see #29210 (comment)). @vieux @diogomonica @cyli @tiborvass </desc> <cmt> registry: remove reference.go </cmt> <cmt> this removes some very old vestigial code that really should have been </cmt> <cmt> removed during the content addressability transition. it implements </cmt> <cmt> something called ""reference"" but it behaves differently from the actual </cmt> <cmt> reference package. this was only used by client-side content trust code, </cmt> <cmt> and is relatively easy to extricate. </cmt> <cmt> (cherry picked from commit d91ed88365317cd86555e2f54bffa30ec6590dfe) </cmt> <cmt> cli: split out getnotaryrepository and associated functions </cmt> <cmt> split these into cli/trust so that other commands can make use of them. </cmt> <cmt> (cherry picked from commit 4b8c79f25ee00ca5dfe22271c166938009bda976) </cmt> <cmt> cli: pin image to digest using content trust </cmt> <cmt> implement notary-based digest lookup in the client when </cmt> <cmt> docker_content_trust=1. </cmt> <cmt> (cherry picked from commit d4d6f8c0d0c6cd0ba6dc96ab7a9ed07e1e766074) </cmt>","backport ""content trust for swarm services"""
317,<desc> follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> init </cmt> <cmt> semver bump </cmt> <cmt> fix lint problems </cmt> <cmt> fix history </cmt> <cmt> remove unneded util </cmt> <cmt> remove unused exports </cmt> <cmt> fix missing optionals on background image tag </cmt> <cmt> inlined all definitions </cmt> <cmt> correct mistypings </cmt> <cmt> resolve error on obj copy and narrow obj search types </cmt> <cmt> delete temp file </cmt> <cmt> made linktag props optional </cmt> <cmt> linktag extends htmlanchorelement props </cmt> <cmt> fix link attributes </cmt> <cmt> update to scrivito 1.17 </cmt> <cmt> update scrivito to 1.18 </cmt> <cmt> update scrivito to 1.19 </cmt> <cmt> linting </cmt>,update scrivito.js typings to scrivito 1.19
318,"<desc> backport of #63713 and #53286 yum </desc> <cmt> yum - only instantiate yumbase once (#63713) </cmt> <cmt> * yum - only instantiate yumbase once </cmt> <cmt> previously, this code was re-instantiating the yumbase object </cmt> <cmt> many times which is unnecessary and slow. however, we must do it </cmt> <cmt> twice in the state: absent case because the yumsack and </cmt> <cmt> rpmsack data of the previously instantiated object becomes </cmt> <cmt> invalid and is no longer useful post transaction when we verify </cmt> <cmt> that the package removal did in fact take place. also, this patch </cmt> <cmt> removes the repetitive re-processing of enable/disable of repos in </cmt> <cmt> various places. </cmt> <cmt> here's a display of the speed increase against a rhel7 host: </cmt> <cmt> yaml </cmt> <cmt> - hosts: rhel7 </cmt> <cmt> remote_user: root </cmt> <cmt> tasks: </cmt> <cmt> - name: install generic packages </cmt> <cmt> yum: </cmt> <cmt> state: present </cmt> <cmt> name: </cmt> <cmt> - iptraf-ng </cmt> <cmt> - screen </cmt> <cmt> - erlang </cmt> <cmt> - name: remove generic packages </cmt> <cmt> yum: </cmt> <cmt> state: absent </cmt> <cmt> name: </cmt> <cmt> - iptraf-ng </cmt> <cmt> - screen </cmt> <cmt> - erlang </cmt> <cmt>  </cmt> <cmt> before this patch: </cmt> <cmt>  </cmt> <cmt> real    0m52.728s </cmt> <cmt> user    0m5.645s </cmt> <cmt> sys     0m0.482s </cmt> <cmt>  </cmt> <cmt> after this patch: </cmt> <cmt>  </cmt> <cmt> real    0m17.139s </cmt> <cmt> user    0m3.238s </cmt> <cmt> sys     0m0.277s </cmt> <cmt>  </cmt> <cmt> fixes #63588 </cmt> <cmt> fixes #63551 </cmt> <cmt> * add changelog </cmt> <cmt> yum - handle enable of non-existent repo (#53286) </cmt>",backport/2.8/63713 yum single yum base instantiation 53286 non existent repos
319,"<desc> what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where ""xxx"" is the issue number) if adding a new feature, the pr's description includes: when working directly with render functions in typescript / tsx, currently the following code is unsafe and unchecked by the ts compiler: this.$sopedslots.default() // default can be undefined the change in this pr makes typescript complain about the unsafe access accordingly and the code has to be expressed in a way that prevents calling an undefined function, e.g.: ( this.$scopedslots.default || ( () => 'default value' ) )( props ) </desc> <cmt> fix(types): declare $scopedslots as potentially undefined to enable stricter ts checks </cmt> <cmt> fix(types): fix tests </cmt>",improve $slots and $scopedslots type to prevent unchecked access to undefined
320,"<desc> for changelog. remove if this is non-significant change. short description (up to few sentences): fixed ""no message received"" error when interacting with postgresql odbc driver through tls connection. this fixes #3360. fixed segfault when using mysql odbc driver. </desc> <cmt> always build odbc bridge as a separate binary #3360 </cmt> <cmt> strip clickhouse-odbc-bridge to avoid symbol clash with odbc drivers #3360 </cmt> <iss> external dictionary, psql: no message received </iss>",build odbc-bridge as a separate binary. do not export symbols from it.
321,<desc> i'm a still pretty much a git noob so please be gentle </desc> <cmt> added setviewoffset to camera for multi-monitor displays. </cmt> <cmt> examples in another commit </cmt> <cmt> compile with camera.setviewoffset </cmt> <cmt> 2 examples for using setviewoffet. </cmt> <cmt> i think setviewoffset is mostly useful for multiple monitors </cmt> <cmt> synced across multiple machines but that's a hard demo to setup </cmt> <cmt> so these demos show doing it locally with muliple canvases </cmt>,added setviewoffset to camera so three.js can be used for multiple monitor demos
322,"<desc> previously, we created one cache per minor version. this changes allows us to invalidate the ata cache by releasing a new patch version of typescript. invaliding the ata cache may be necessary to work around performance bugs in a version of typescript, like those in 3.4. also, bump the version to 3.4.3. </desc> <cmt> create an ata cache per patch version of ts </cmt> <cmt> previously, we created one cache per minor version. this changes allows </cmt> <cmt> us to invalidate the ata cache by releasing a new patch version of </cmt> <cmt> typescript. </cmt> <cmt> bump version to 3.4.3 </cmt>",cache ata per patch version
323,"<desc> following this code sample copied & pasted from the yeoman documentation, we should be able to call the generator.option method without a config argument: module.exports = class extends generator { // note: arguments and options should be defined in the constructor. constructor(args, opts) { super(args, opts); // this method adds support for a --coffee flag this.option(""coffee""); // and you can then access it later; e.g. this.scriptsuffix = this.options.coffee ? "".coffee"" : "".js""; }; add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. (n/a) </desc> <cmt> made option.config argument optional as per yeoman documentation </cmt> <cmt> removed generated dependencies </cmt>",make the config argument of the generator.option method optional
324,<desc> refactoring and implementing one code style for imports in react-reconciler package </desc> <cmt> simplify imports in reactchildfiber </cmt> <cmt> import type first in reactcurrentfiber </cmt> <cmt> simplify imports in reactfiberbeginwork </cmt> <cmt> simplify imports in reactfiberscheduler </cmt> <cmt> simplify import in reactfibertreereflection </cmt> <cmt> simplify import in reactfiberunwindwork </cmt>,simplify imports in react reconciler
325,"<desc> this also includes the changes from #25011 for bpo-43612. these make more sense in the context of these changes. currently gzip.compress and gzip.decompress are implemented with gzipfile. this is a lot of overhead when a simple in memory compression is needed. as shown in the benchmarks below, the overhead is considerable for datasizes below 4096 bytes (which are probably very common targets for in memory compression and decompression). this pr changes the implementations to compress and decompress in memory. i compiled python before and after this change with --enable-optimizations to ensure a fair comparison. i used this script to benchmark: import gzip import pathlib import statistics import sys import timeit data=pathlib.path(sys.argv[1]).read_bytes() sizes = [0, 128, 512, 1024, 4096, 8192, 16384] def benchmark(bench_string, number=1000, repetitions=10): for size in sizes: data = data[:size] compressed_data = gzip.compress(data) timeit_kwargs=dict(globals=dict(**locals(), **globals()), number=number) results = [timeit.timeit(bench_string, **timeit_kwargs) for _ in range(repetitions)] average = statistics.mean(results) print(f""data size {size}: {round(average * (1_000_000 / number),2)} microseconds average"") if __name__ == ""__main__"": print(""gzip compression"") benchmark(""gzip.compress(compressed_data)"") print() print(""gzip decompression"") benchmark(""gzip.decompress(compressed_data)"") before: gzip compression data size 0: 7.92 microseconds average data size 128: 12.1 microseconds average data size 512: 18.45 microseconds average data size 1024: 22.41 microseconds average data size 4096: 32.51 microseconds average data size 8192: 41.03 microseconds average data size 16384: 57.99 microseconds average gzip decompression data size 0: 8.99 microseconds average data size 128: 10.26 microseconds average data size 512: 12.62 microseconds average data size 1024: 13.55 microseconds average data size 4096: 21.12 microseconds average data size 8192: 30.59 microseconds average data size 16384: 61.24 microseconds average after: gzip compression data size 0: 3.68 microseconds average data size 128: 7.64 microseconds average data size 512: 14.06 microseconds average data size 1024: 17.42 microseconds average data size 4096: 27.25 microseconds average data size 8192: 37.09 microseconds average data size 16384: 53.48 microseconds average gzip decompression data size 0: 1.98 microseconds average data size 128: 3.74 microseconds average data size 512: 5.36 microseconds average data size 1024: 6.72 microseconds average data size 4096: 14.1 microseconds average data size 8192: 23.57 microseconds average data size 16384: 52.72 microseconds average </desc> <cmt> add test for zlib.compress wbits </cmt> <cmt> add wbits argument to zlib.compress </cmt> <cmt> use clinic to generate input </cmt> <cmt> update documentation for zlib </cmt> <cmt> add blurb news entry for zlib.compress wbits parameter </cmt> <cmt> fix doc typo </cmt> <cmt> remove unnecessary whitespace, add punctionation and complete sentences. </cmt> <cmt> break line to comply with pep-7 </cmt> <cmt> update blurb to include :func: reference </cmt> <cmt> remove erroneous double backticks </cmt> <cmt> faster gzip.compress implementation </cmt> <cmt> more efficiently decompress gzip files in memory </cmt> <cmt> ensure correct endianness </cmt> <cmt> remove redundant line </cmt> <cmt> fix typos and test errors </cmt> <cmt> revert changing default on compress for backwards compatibility </cmt> <cmt> update documentation with gzip speed improvements </cmt> <cmt> add a blurb for gzip speed improvements </cmt> <cmt> use + instead of bytes.join() method </cmt>",faster implementation of gzip.compress and gzip.decompress
326,"<desc> using an incorrect count of unpacked values in the for template tag raises an exception rather than failing silently. so 6461b25 was an easy fix, but the last one was a bit more involved. after some more digging around, i found that cramer forgot to do the changes i made in bc722ab in a93ed9c. this lets us keep the existing 3 arg unpacking in context's interfaces in the templates (see for example a7e7711), and even fixes text rendering of the alert email. </desc> <cmt> django 1.10 is strict about using an incorrect count of unpacked values in the for template tag </cmt> <cmt> (cherry picked from commit 8f5a118513eced0a40c67efddc07e8f4d09cd724) </cmt> <cmt> fix rendering for /debug/mail/alert in tests/acceptance/test_emails.py </cmt> <cmt> you might be thinking this interfaces is the same one in </cmt> <cmt> src/sentry/templates/sentry/emails/error.txt </cmt> <cmt> 30:{% if interfaces %}{% for label, _, text in interfaces %} </cmt> <cmt> but it actually comes from src/sentry/web/frontend/debug/mail.py. </cmt> <cmt> that one comes from src/sentry/plugins/sentry_mail/models.py, so no changes to interfaces in src/sentry/templates/sentry/emails/error.txt are required. </cmt> <cmt> never mind, i was wrong. cramer forgot to mirror changes he made in a93ed9c24dc over to here </cmt> <cmt> revert ""fix rendering for /debug/mail/alert in tests/acceptance/test_emails.py"" </cmt> <cmt> this reverts commit 0d838e36ff10cf223cdfe4b488a93f4a40b0d796. </cmt> <cmt> fill in tests/fixtures/emails/alert.txt with test output </cmt> <cmt> cleanup </cmt>",fix unpacking values to for during templating
327,"<desc> i think we're good moving this chapter into copy-editing. </desc> <cmt> * add version numbers </cmt> <cmt> * update to latest react & livescript </cmt> <cmt> * freeze traceur at 0.0.58 </cmt> <cmt> * upgrade traceur to 0.66 </cmt> <cmt> * array comprehension is gone from es6; adjust accordingly. </cmt> <cmt> * reflect the readjusted es6 syntax in chapter writeup </cmt> <cmt> * livescript 1.3.0 </cmt> <cmt> * s/continue/return/ </cmt> <cmt> * beginning to incorporate review ideas from john </cmt> <cmt> * refactor block scope constants </cmt> <cmt> * explicitly mention angularjs as per john </cmt> <cmt> * add a ""why"" section to main.js as per john morrissey </cmt> <cmt> * add calc() flowchart as per @jwm's review. </cmt> <cmt> that's all, folks! </cmt>",incorporate reviews from the two reviewers
328,"<desc> as of now, bad word ids are not checked when added to the configuration/passed as inputs to the generate method. this is an issue when an invalid bad word id is defined: if the vocab size is 30k, then defining a bad word id for 30001 crashes the generation function with the following error: torch.sparse.longtensor(banned_mask.t(), indices, scores.size()).to(scores.device).to_dense().bool() runtimeerror: size is inconsistent with indices: for dim 1, size is 30000 but found index 30001 please let me know if you think this should raise a better error instead, rather than a warning. </desc> <cmt> removes overflowing bad word ids </cmt> <cmt> raise warning </cmt>",fix overflowing bad word ids
329,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. see react redux | custom hooks and the source code (each file contains a createsomething function which is typed in this package. the current typing for the createetc functions reflect basic return and argument types, but does not reflect the relation between the argument and return type. this is especially important (in fact, without the relation, the type is useless) because the return type cannot be used, in general, when the argument is non-trivial (i.e. the argument is not {}). the depreciation of the typeduseselectorhook is because the new types will obsolete that type. include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. add it to notneededpackages.json. </desc> <cmt> update index.d.ts </cmt> <cmt> update react-redux-tests.tsx </cmt> <cmt> update index.d.ts </cmt>",improved factory function types and deprecated typeduseselectorhook.
330,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: postmanlabs/newman#2392 include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> added request agents introduced in newman 5.1.0. </cmt> <cmt> bump newman version </cmt>",add request agents to newman run options
331,<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. </desc> <cmt> fix: handle no user request </cmt> <cmt> fix: make the current challenge button do something </cmt>,current challenge link on /welcome
332,"<desc> cherry-pick #23587 to swift-5.1-branch-04-24-2019 reviewed by @rintaro extend the support for single-expression closures to handle single-expression functions of all kinds. this allows, e.g. func foo() -> myenum { . } to complete members of myenum. rdar://problem/48938531 </desc> <cmt> [code-completion] add type context for single-expression functions </cmt> <cmt> extend the support for single-expression closures to handle </cmt> <cmt> single-expression functions of all kinds. this allows, e.g. </cmt> <cmt> func foo() -> myenum { .<here> } </cmt> <cmt> to complete members of myenum. </cmt> <cmt> [code-completion] fix type context for single-expression implicit getter </cmt> <cmt> this adds an implicit body so that we can dig out the return type </cmt> <cmt> context the same way as a normal function. for now, we are also treating </cmt> <cmt> the first expression in a multi-statement implicit getter body the same </cmt> <cmt> way; we'll need to refactor how we complete in accessors to </cmt> <cmt> differentiate those cases. </cmt> <cmt> add top-level and init/deinit tests </cmt>",add type context for single-expression function bodies
333,<desc> the test cases contained in this pr were automatically generated by diffblue's deeptest software please feel free to merge them into your repository. the tests for fastjson can be viewed in more detail (with a trace view & step-through execution) at  we would be delighted with any feedback you have on these tests. </desc> <cmt> add unit tests from diffblue deeptest for fastjson.jsonpath </cmt> <cmt> add unit tests from diffblue deeptest for fastjson.parser.jsonscanner </cmt>,add diffblue deeptest unit tests for com.alibaba.fastjson
334,<desc> make importmeta.url compatible w/ whatwg spec and @types/node typedef references: withastro/snowpack#1869  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: withastro/snowpack#1869 </desc> <cmt> [@types/snowpack-env] remove readonly flag </cmt> <cmt> make importmeta.url compatible w/ whatwg spec and @types/node typedef </cmt> <cmt> references: </cmt> <cmt> - </cmt> <cmt> - </cmt> <cmt> [@types/snowpack-env] update test stub </cmt>,remove readonly flag for importmeta.url
335,"<desc> uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespaces from that line: /kind design this pr updates the cpumanager and the topologymanager to error out if an invalid policy is specified for either of them. previously, these components would simply fall back to their respective none() policies if an invalid policy was specified. this pr updates these components to return an error when an invalid policy is passed to them, forcing the kubelet to fail fast when this occurs. these semantics should be preferable because an invalid policy likely indicates operator error in setting the policy flag on the kubelet correctly (e.g. misspelling 'static' as 'statiic' or 'strict' as 'striict'). in this case it is better to fail fast so the operator can detect this and correct the mistake, than to mask the error and essentially disable the cpumanager or the topologymanager unexpectedly. does this pr introduce a user-facing change?: passing an invalid policy name in the --cpu-manager-policy flag will now cause the kubelet to fail instead of simply ignoring the flag and running the cpumanagers default policy instead. </desc> <cmt> update the cpumanager to error out if an invalid policy is given </cmt> <cmt> previously, the cpumanager would simply fall back to the none() policy </cmt> <cmt> if an invalid policy was specified. this patch updates this to return an </cmt> <cmt> error when an invalid policy is passed, forcing the kubelet to fail </cmt> <cmt> fast when this occurs. </cmt> <cmt> these semantics should be preferable because an invalid policy likely </cmt> <cmt> indicates operator error in setting the policy flag on the kubelet </cmt> <cmt> correctly (e.g. misspelling 'static' as 'statiic'). in this case it is </cmt> <cmt> better to fail fast so the operator can detect this and correct the </cmt> <cmt> mistake, than to mask the error and essentially disable the cpumanager </cmt> <cmt> unexpectedly. </cmt> <cmt> update the topologymanager to error out if an invalid policy is given </cmt> <cmt> previously, the topologymanager would simply fall back to the none() policy </cmt> <cmt> if an invalid policy was specified. this patch updates this to return an </cmt> <cmt> error when an invalid policy is passed, forcing the kubelet to fail </cmt> <cmt> fast when this occurs. </cmt> <cmt> these semantics should be preferable because an invalid policy likely </cmt> <cmt> indicates operator error in setting the policy flag on the kubelet </cmt> <cmt> correctly (e.g. misspelling 'strict' as 'striict'). in this case it is </cmt> <cmt> better to fail fast so the operator can detect this and correct the </cmt> <cmt> mistake, than to mask the error and essentially disable the </cmt> <cmt> topologymanager unexpectedly. </cmt>",update the cpumanager and topologymanager to error out if an invalid policy is given
336,"<desc> @jibec please check if this is doing what is needed. </desc> <cmt> revert ""gitignore .pot file"" </cmt> <cmt> this reverts commit ee4e9a1090941797d7ed64e23a49ceeba762577c. </cmt> <cmt> it seems we need the .pot file in the repo to allow weblate to import it. </cmt> <cmt> po: import the .pot file into version control </cmt> <cmt> fixes #14531. </cmt>",import the .pot file into version control for weblate
337,"<desc> in handbrake 1.2, every resx locale file had windows line-break type. downloading from transifex to my mac resulted in unix line-break type. so, the first commit will change all current resx files back to windows line-break type. (all resx files are then utf-8 + bom and windows line-break type) the second commit updates the locales to latest strings. </desc> <cmt> change all resx files to windows line-break type </cmt> <cmt> update locales </cmt>",switch locale files to windows line-break type and update to latest strings
338,"<desc> i'm doing a lot of agging over a codebase with single line packed js files scattered through it. i do want to know if there were matches, and on which line, but some of those files with one massive line can play havoc with the output when i'm trying to navigate a couple of dozen matches. things can get a bit tricky when most of the matches are nice 100 column lines, then one 15,000 column monster comes along! lines that long don't exactly play nice with a terminal or a text editor (it crashes the current master of neovim using the ag.vim plugin). i've solved my problem by adding a -w num / --width num option which truncates matched lines to the length specified. -w was chosen as it didn't seem to clash with anything else, including in grep and ack. i thought i might clean it up, write some tests and see if you might find it a useful or worthy addition to ag. make test runs without errors, but i think my own test case might be missing a few scenarios, like the truncation when print_path is set to path_print_each_line. there are a couple of warts with my implementation - the newline handling on line 205 of print.c is problematic when you redirect the output to a file. it seems to clash with the ""file without newline"" detection. i didn't want to start digging too deeply into the newline handling logic without first starting a discussion. i figured it's also one of those things where someone who knew the codebase more intimately might be able to say ""oh yeah, that's easy: you're doing that bit wrong, just move it over here and pow!"", or even just ""no, this whole thing isn't a good idea, you can already do that using x"" ;) </desc> <cmt> added line width truncation option -w </cmt> <cmt> added missing --width longopt handling </cmt>",added an option to truncate long lines with -w num
339,"<desc> original pull-request #19218 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update dragonbox </cmt> <cmt> update dragonbox </cmt>",cherry pick #19218 to 21.1: update dragonbox
340,<desc> optionally run spp over rasm2 assembly input with -p(reprocessor) argument adds a new function to ease the addition of the optional bool to the massemble function. removes spp integration from rasm2 </desc> <cmt> add spp to asm.c </cmt> <cmt> move spp integration to libr.asm.c </cmt> <cmt> also remove the spp parts from rasm2.c </cmt> <cmt> fix #6356 </cmt> <cmt> make spp parsing optional </cmt> <cmt> add -p arg to rasm2 </cmt>,move ssp integration to libr/asm.c [fix #6356]
341,"<desc> this pr begins the work on cuda deivce api. the pr only implements memory allocation and deallocation, and makes use of those methods in llvmprogram and memorypool. this would be very useful for unifying the memcpy logic used in ggui, which would facilitate implementing ggui on other backends. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> remove virtual </cmt> <cmt> auto format </cmt> <cmt> remove macro </cmt> <cmt> fix </cmt> <cmt> format </cmt> <cmt> resolve some convo </cmt> <cmt> comment </cmt>",cuda device api 1/n: memory allocation
342,"<desc> way back in #2904, we removed some input styling code from the temp basal change percentage field, because it was forcing a numeric keypad to pop up on mobile browsers, and most of those keypads don't have a - key for entering negative amounts. all browsers tested at that time popped full keyboards after this change. getting reports now though that some browsers (samsung phones, kindle fire) are still popping the numeric keypad, since the field has type=""number"". removing that input type designation to allow for negative values on all devices. (this means a small regression in ux, as all users will now need to switch to the number display on their standard mobile keyboards before entering a value each time, but i think it's better than excluding devices from entering anything at all.) </desc> <cmt> dev </cmt> <cmt> dev update </cmt> <cmt> dev sync </cmt> <cmt> dev update </cmt> <cmt> dev sync </cmt> <cmt> sync dev </cmt> <cmt> remove type=number </cmt>","temp basal input fix for browsers that don't follow standards (samsung phones, kindle fire)"
343,<desc> i'm new to typescript and most of this stack so apologies if i've missed anything..... this allows you to access the events properties. e.g the example for selecting events at </desc> <cmt> update definitions to support react-big-calendar event object properties </cmt> <cmt> update version number </cmt>,update definitions to support react-big-calendar event object properties for onselectevent (version 0.15.0)
344,"<desc> on certain os x filesystems mtime is rounded to 1sec, to make sure the test also passes on these machines i changed the sleep to 1 sec, i've also done this in #881, but that's a rather big change, with this one i hope it gets merged faster as some people might get issues with this (in my case this test always fails) </desc> <cmt> fix fs test for mac </cmt>",fix cache test for os x
345,"<desc> closes #10202 </desc> <cmt> show 'enable/disable' system messages on edit room </cmt> <cmt> fix double switch enable/disable </cmt> <cmt> undo autoformat </cmt> <iss> suppress system generated messages in rooms [""user"" set moderator by ""user"", room topic changed to] </iss>",missing option to disable/enable system messages
346,"<desc> closes #42076 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry seems to work. let's try this again. </desc> <cmt> update posix.yml </cmt> <cmt> update python-dev.yml </cmt> <cmt> update ci.yml </cmt> <cmt> update database.yml </cmt> <cmt> update sdist.yml </cmt> <cmt> update pre-commit.yml </cmt> <cmt> update posix.yml </cmt> <cmt> update pre-commit.yml </cmt> <cmt> update python-dev.yml </cmt> <cmt> update sdist.yml </cmt> <cmt> update database.yml </cmt> <cmt> update ci.yml </cmt> <iss> ci: disable auto-cancel for master branch </iss>",try to not auto-cancel on master
347,"<desc> consolidating some bug fixes and improvements to the world api. work in progress. handle the corner case when ue deletes an actor visually and from the actor list but reference still exists in memory, causing fatal errors when another object of the same name is spawned. queue up garbage collection when an actor is destroyed. use a tmap for name<->asset mapping, instead of iterating through all assets in the database in getmeshfromregistry at every spawn. use a tmap for name<->actor mapping, instead of iterating through all actors in scene at every object api call. </desc> <cmt> use a tmap for asset registry </cmt> <cmt> handle ue's garbage collection delays when spawning. don't force particular names </cmt> <cmt> print message when asset registry is ready </cmt>",fixes and improvements to world api
348,"<desc> this should fix #932 - if binding_mode colours are not defined, use urgent_workspace colours as a fallback. three missing settings were also implemented: focused_(workspace|statusline|separator) they provide different colours for swaybar on the focused output. </desc> <cmt> use urgent_ws color in swaybar if binding_mode is undefined </cmt> <cmt> add bar colours for focused_(workspace|statusline|separator) </cmt> <cmt> if these aren't defined in config, color settings without 'focused_' </cmt> <cmt> prefix are used as a fallback. </cmt> <iss> resize indicator looks different from i3 </iss>",fix some colour settings in swaybar
349,"<desc> prefer to make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. run tsc without errors. include the required files and header. base these on the readme, not on an existing project. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. </desc> <cmt> add definitions for redux-persist </cmt> <cmt> add missin generic types </cmt> <cmt> add definitions for filter transformer </cmt> <cmt> add definitions for encrypt transformer </cmt> <cmt> fix header </cmt> <cmt> add definitions for compress transformer </cmt> <cmt> delete unnecessary linter configs </cmt>",add redux-persist and basic transformers
350,"<desc> currently the set sorting does default to year, but this is then overriden by the default sort by sorttitle of the main movie title node. this changes things so that the sort mode always defaults to sort by year, and if changed by the user, this is no longer saved into the default sort modes for title nodes.  it is still saved for the actual set that's changed. the alternative to this would be to have a set-specific default sorting/view structure, so that if the user changes the view/sort mode/direction in one set it's automatically changed in all other sets (not previously changed by the user).  not sure if that's better or not - typically sort by year would be correct in almost all cases, but there may be cases where the user wants a default view type for listings inside sets that is different than movie title listings??  personally i don't see the use case. </desc> <cmt> ensure rating sort modes are available inside sets </cmt> <cmt> change sorting inside sets to sort by year, and don't save to the general movie titles default sort when user changes (i.e. save only for the current set) </cmt>",sorting inside sets should default to year
351,"<desc> hi there, in this pr, the code of roialign is adapted from detectron2 roialign. it supports sampling ratio and aligned roialign. roialign with sampling_ratio=0 and aligned=false is consistent with the eldder version. besides, it pre-calculates the sampling weight to accelerate this operator. benchmark on unittest: before after 1.90s 1.45s </desc> <cmt> update roialign </cmt> <cmt> update tool for roialign </cmt>","improve roialign (accelerate roialign, support sampling ratio and aligned roialign)"
352,<desc> backports #8598 to v1.0.x and add objective-c tests cc: @makdharma @hsaliak </desc> <cmt> update messages.proto and add a new test </cmt> <cmt> tests hacks </cmt> <cmt> send reset from the client when server closes stream unexpectedly </cmt> <cmt> ensure something executes the new rst_stream code </cmt> <cmt> missed file </cmt> <cmt> undo test hack </cmt>,send rst_stream from client when it receives trailing metadata without the corresponding rst_stream
353,"<desc> this pr improves batched inference for wav2vec2 models by: adding an attention_mask adding zero-mean unit-variance normalization to the tokenizer correctly setting returning attention_mask and doing normalization depending on which architecture is used background some of fairseq's wav2vec2 models apply group normalization over the time axis in the feature extractor. this means that the convolutional layers in the feature extractor can not 100% correctly treat padded input resulting in those models giving different results depending on whether the input is padded or not. see pytorch/fairseq#3227 . those models should never make use of attention_mask which is made sure by setting return_attention_mask=false in their corresponding tokenizer configs:  for the ""newer"" models however that have the improved layer norm architecture in the feature extraction:  performance evaluation i've evaluated both wav2vec2-large-960h-lv60-self and wav2vec2-large-960h-lv60 on the test set of librispeech and got some nice improvements: wav2vec2-large-960h-lv60-self: 2.2 wer -> 1.8 wer wav2vec2-large-960h-lv60: 3.4 wer -> 2.2 wer so that the results now seem to match the paper's results very nicely. also, i checked that wav2vec2-base-960h should not use an attention_mask as the performance on librispeech test then drop heavily from ~4 wer to ~20 wer. todo once this pr is merged, i can fully focus on adding the fine-tuning functionality and will also update the model cards with the new evaluation code & results. </desc> <cmt> save intermediate </cmt> <cmt> finish batch the same as fairseq </cmt>",improve tokenizer & model for batched inference
354,"<desc> rebased against 2.4, replaces pr #1334. fix for #1330 </desc> <cmt> regression test for #1330 (coerce none to '') </cmt> <cmt> possible fix for #1330 </cmt> <cmt> coerce none to '' in charfield.to_native() </cmt> <cmt> charfield - add allow_null argument </cmt> <cmt> set allow_none = true for charfields with null=true </cmt> <cmt> test for setting allow_none=true for nullable charfields </cmt>",coerce none to empty string
355,"<desc> replace #include ""tinyxml2/tinyxml2.h"" with #include ""tinyxml2.h"" in new cocostudio code. this change fix build with cmake when system installed libraries are used (-duse_prebuilt_libs=no). some systems may install tinyxml2 includes without special prefix directory, so findtinyxml2.cmake was written to find include directory that directly contains tinyxml2.h header (without prefix dir). moreover, official install script in tinyxml2 project install header to <prefix>/include/tinyxml2.h also fix some warnings in code. and remove unneeded inclusion of tinyxml2.h from user visible header file (cocos/editor-support/cocostudio/flatbuffersserialize.h), as a result usage of tinyxml in cocos may be ""private"" for user project. </desc> <cmt> replace #include ""tinyxml2/tinyxml2.h"" to #include ""tinyxml2.h"" in new cocostudio code. this should fix build with cmake when use_prebuilt_libs=no. because findtinyxml2.cmake find tinyxml2.h header (without prefix dir). and some systems install tinyxml2 includes without special directory. </cmt> <cmt> also this inclusion style match other existing files such as cocos/platform/ccfileutils.cpp </cmt> <cmt> hide tinyxml2 from user visible header. </cmt> <cmt> fix couple of warnings. make forward declarations to match to real declarations. </cmt>",fix usage of tinyxml2 in cocostudio code
356,"<desc> description: there are several differnent foscam libraries, all pretty similar.  it seems that an old, un-maintained version is currently being used.  just redirecting this to one that is more actively maintained and has some newer bug fixes that i have already tested and confirmed work on my local installation.  should not break any existing installations. related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. if the code does not interact with devices: </desc> <cmt> change foscam python library to pyfoscam, which is more up to date and has several critical bug fixes. </cmt> <cmt> update requirements_all.txt to match. </cmt>",use more up-to-date version of pyfoscam library
357,"<desc> also see #2581. closes #3036. previous behaviour when using mutable values like dictionaries or lists as the default argument, keep in mind that they behave just like mutable default arguments in python functions. this can easily cause unintended results, like the same value being set on all objects instead of only one particular instance. in most cases, it's better to use getters and setters, and only set the default for boolean or string values. the following now works doc.set_extension('mutable', default=[]) doc1 = nlp(""hello world"") doc2 = nlp(""what's up?"") doc1._.mutable.append(""foo"") print(doc1._.mutable)  # ['foo'] print(doc2._.mutable)  # [] enhancement i have submitted the spacy contributor agreement. </desc> <cmt> support mutable default values in extensions </cmt> <cmt> update documentation </cmt>",support mutable default values for extension attributes
358,"<desc> we can back the note out after the phantomjs issue is fixed, but i think for the time being we need this note. </desc> <cmt> added a note to advise users to stick with an earlier version of node.js until the known issue with phantomjs is fixed. </cmt> <cmt> fixes #477 </cmt> <cmt> added a note about the known issue between phantomjs and node 0.10.x </cmt>",fix for #411 - change to contributing.md about phantomjs and node 0.10.x
359,"<desc> i recently purchased the gulf coast 3-point bed leveling kit, and realized that marlin didn't have a way to take advtantage of it. the problem was that marlin defaults to front left, front right, rear right, rear left. the adjustment knobs for this kit are in the front left, rear left, and the center right. this update will allow users to define the probing order, and will also allow enabling 3-point leveling if they want it. if they enable 3-point leveling, then the corner_bed_leveling will only perform the first 2 corners, then it determines the opposite edge and moves there. this edge will respect whatever offsets would normally be used for the standard 4-corner probe. (so right edge will use rb.x + y_center) configuration.h edits: enable   #define level_bed_corners enable #define level_corners_3_points if you want to try out the 3-point leveling mess with level_corners_leveling_order if you want to change the order. a description comment explaining it is provided. note that i didn't currently error check, so if they put a number less than 0 or greater than 4 into the array, it will likely ignore that corner altogether. picture! as you can see, some additional text has been added to the 'probing' screen so that there is feedback to the user as to the last probe measurement, as well as the # of points probed within tolerance. </desc> <cmt> add 3-point leveling to corner bed leveling </cmt> <cmt> this added 3-point leveling to the corner bed leveling lcd menu option. this also adds the ability to customize the probing order if you want to change that up as well. </cmt> <cmt> corrected default leveling order </cmt>",corner bed leveling 3 point leveling
360,"<desc> timedelta comparison already handled this correctly but i didn't see a test for it, so added one. closes #15183 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> timestamp comparisons for object arrays, closes #15183 </cmt> <cmt> whitespace fixup, add whatsnew </cmt> <iss> bug: timestamp array comparison may raise recursionerror </iss>",prevent recursionerror on timestamp comparison against object array
361,"<desc> fixes issue spotted here  the classes are being blocked for root, but forwarded on other slot. however, on this component the docked slot is used as root, so we need to block them. </desc> <cmt> use shouldforwardprop for docked root </cmt> <cmt> prettier </cmt>",fix classes forwarded to dom node for docked drawer
362,<desc> a new batch of fixes to be able to build some c++ tests on windows. </desc> <cmt> make factop build on windows. </cmt> <cmt> make memmapped_file_system build on windows. </cmt> <cmt> make port_test work on windows </cmt> <cmt> enable c++ control_flow_ops_test on windows. </cmt> <cmt> enable more c++ tests on windows. </cmt>,some more c++ test fixes
363,"<desc> since many users on the forum complained that the example was not running due to the fact that delay(10) wasn't enough for some slow servers, i'm proposing this change. </desc> <cmt> replace delay with while loop in wificlient.ino </cmt> <cmt> oupps ! i forgot to set the timout value </cmt>",replace delay() with a while loop in wificlient.ino
364,<desc> update doc for v1.1.6 update spring boot version to 1.5.9 add  spring boot actuator endpoints support </desc> <cmt> add > spring boot actuator endpoints </cmt> <cmt> update > v1.1.6 </cmt> <cmt> add > spring boot actuator endpoints </cmt> <cmt> fix > config </cmt>,druid spring boot starter > update doc for 1.1.6 & add spring boot actuator endpoints support
365,"<desc> description: the coinmarketcap sensor can now only display values in dollars. the coinmarketcap api also supports other currencies like euro, pound and more. this pr adds support to use the sensor with other display currencies. this pr also adds the first test for the coinmarkercap sensor. there is one possible breaking change. the name of the sensor attribute '24h_volume_usd' is changed to '24h_volume'. pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3779 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add support for different display currencies in coinmarkercap sensor. </cmt> <cmt> add test for coinmarketcap sensor. </cmt> <cmt> add test dependency to gen_requirements_all. </cmt>",add display currency setting to coinmarketcap sensor
366,"<desc> translates content-tracing-ko.md remove outdated comments about remote buffer in browser-window.md fix typos and improve grammer in tutorials at ko translations </desc> <cmt> remove remain sentences </cmt> <cmt> remove remain sentences </cmt> <cmt> remove comments about remote buffer </cmt> <cmt> remove comments about remote buffer in browser-window.md, because remote </cmt> <cmt> buffer now supports in remote module. </cmt> <cmt> fix typos and improve grammer, translate more files </cmt> <cmt> translate content-tracing-ko.md file. </cmt> <cmt> fix typos, improve grammer in tutorials and update as upstream. </cmt>","add more translations and fixes, remove outdated comments"
367,<desc> handle outdir and declrationdir correctly to generate output file names for the tsbuild exclude json files from project reference redirects from files to be emitted list fixes #30382 </desc> <cmt> handle outdir and declrationdir correctly to generate output file names for the tsbuild </cmt> <cmt> exclude json files from project reference redirects from files to be emitted list </cmt> <cmt> fixes #30382 </cmt>,handle json files included in the project from project reference redirect
368,"<desc> this pull request contains simple lossless and simple lossy webp file support with the help of libwebp. for now this means aseprite can open and save static (not animated) lossless and lossy webp files as long as they do not use the extended format. we still lack support for animation, color profile, exif and xmp. but probably only animation is going to be of interest for aseprite for now. animation will be implemented in a second step along with support for the  extended format, exposing the missing features so aseprite could use them if any need arises. also a rudimentary save options dialog was implemented so user can save webp in lossless or lossy format. it was made quick and probably still needs some optimization for better ux. </desc> <cmt> add submodule libwebp for #273 </cmt> <cmt> implement simple non animation webp for #273 </cmt> <cmt> this includes lossless and lossy webp file format. for this reason a </cmt> <cmt> save option dialog was added giving rudimentary options for saving to </cmt> <cmt> the user. </cmt> <cmt> add libwebp info to credits </cmt>",support for the simple lossless and lossy (non animated) webp format for #273
369,"<desc> (maybe) breaking change: not currently a breaking change, but could be. it is possible to expose both the alexa.percentagecontroller and alexa.powerlevelcontroller for variable fan entities. existing entities will use the alexa.percentagecontroller and newly discovered fan entities will expose both. during testing entities that expose both would receive setpowerlevel directives vs. setpercentage indicating alexa prefers powerlevel and powerleveldelta directives when both are exposed. existing alexa.percentagecontroller handlers for fan entities were left in to maintain backwards compatibility. however, if you want to remove the bloat. just remove any references to fan entities from the alexa.percentagecontrollers. but will likely break existing fan entities already connected to alexa, and they will need to be removed and re-discovered. description: implements powerlevelcontroller for variable fan entities. while attempting to maintain percentagecontoller for existing entities already discovered by alexa. this also provides a ""bandaid"" to speed percentage mapping when integrations override the default attr_speed_list. e.g. lutron_caseta_pro maps speed_medium_high to 75, and would be reported as 0 in change reports. related issue (if applicable): checks off #24579 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> implement alexapowerlevelcontroller </cmt> <cmt> implement alexapowerlevelcontroller tests </cmt>",add powerlevelcontroller for fan to alexa
370,"<desc> based on the new github issue template, i have separated them on specific areas to make it easier if someone wants to contribute to the project. </desc> <cmt> basic template for new issues </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> updated issue template </cmt> <cmt> updated issue template </cmt> <cmt> update issue_template.md </cmt> <cmt> update issue_template.md </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changed bug report to the new github issue template </cmt> <cmt> add feature request template </cmt> <cmt> question template </cmt> <cmt> fixed title of question and added emojis </cmt>","new issue, feature and question template"
371,"<desc> this replaces some of the pyint* macros in npy_3kcompat with their definitions. because of type conflicts, it isn't always a simple substitution. the f2py/cfuncs.py case is complicated and most fixes are left to a separate pr. </desc> <cmt> maint: replace pyint_fromlong by pylong_fromlong. </cmt> <cmt> replace the npy_3kcompat macro pyint_fromlong by its definition. </cmt> <cmt> maint: replace pyint_aslong in some places. </cmt> <cmt> replace the npy_compat macro pyint_aslong in some functions. </cmt> <cmt> this is not a straight forward substitution because of type conflicts. </cmt> <cmt> the fixes for numpy/f2py/cfuncs.py are postponed to another pr because </cmt> <cmt> they are more complicated. </cmt> <cmt> maint: replace pyint_asssize_t by pylong_asssize_t. </cmt> <cmt> replace the npy_3kcompat macro by its definition. </cmt>",replace some  pyint_*  macros defined in npy_3kcompat.
372,"<desc> working on fixing:  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> convert tabs to spaces </cmt> <cmt> use grid alignment for keycodes and macro arguments </cmt> <cmt> rework layout macro </cmt> <cmt> update layout macro to resemble the assembled layout. </cmt> <cmt> use human-friendly formatting in info.json </cmt> <cmt> update readme </cmt> <cmt> update maintainer's account name, and add bootloader and flashing instructions. </cmt>",misonoworks karina layout macro rework
373,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> weixin-app: use covariant event type </cmt> <cmt> add jimexist </cmt> <cmt> add jimexist </cmt>",update weixin app event type
374,<desc> this pr adds unit tests for wire and xcontent serialization of remaining intervalssourceprovider implementations. closes #50150 </desc> <cmt> add test for intervalssourceprovider.intervalfilter </cmt> <cmt> add test for intervalssourceprovider.match </cmt> <cmt> add test for intervalssourceprovider.combine </cmt> <cmt> add test for intervalssourceprovider.disjunction </cmt> <cmt> add license headers </cmt> <iss> add tests for intervalssourceprovider implementations </iss>,add tests for remaining intervalssourceprovider implementations
375,"<desc> c++ worker will generate a template project, we need to ignore the generated files by c++ worker. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> linkopts shared </cmt> <cmt> ignore generated files </cmt>",[c++ worker]ignore genrated files
376,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: < if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> added chatpermissions interface </cmt> <cmt> - the field all_members_are_administrators has been removed from the documentation for the chat object. the field is still returned in the object for backward compatibility, but new bots should use the permissions field instead. </cmt> <cmt> - modified chat interface. added : permissions, can_set_sticker_set, and sticker_set_name </cmt> <cmt> updated message interface & added new interfaces - poll & polloption </cmt> <cmt> - forward_sender_name </cmt> <cmt> - media_group_id </cmt> <cmt> - caption_entities </cmt> <cmt> - poll </cmt> <cmt> - connected_website </cmt> <cmt> modified exisiting interfaces - audio, animation </cmt> <cmt> - removed redundancy by extending filebase on animation </cmt> <cmt> - added new properties to animation : width, height, and duration </cmt> <cmt> - added new property to audio : thumb </cmt> <cmt> modified contact and venue interfaces </cmt> <cmt> - added foursquare_type to venue </cmt> <cmt> - added vcard to contact </cmt> <cmt> added new interface loginurl </cmt> <cmt> rearranged interface ordering so that it matches telegram documentation </cmt> <cmt> updated chatmember interface </cmt> <cmt> - rearranged ordering to match telegram documentation </cmt> <cmt> - added new property : is_member </cmt> <cmt> fixed linting errors and made login_url as optional param in inlinekeyboardbutton </cmt>",added new interfaces and updated existing ones
377,"<desc> index-time analyzers are currently specified on the mappedfieldtype.  this has a number of unfortunate consequences; for example, field mappers that index data into implementation sub-fields, such as prefix or phrase accelerators on text fields, need to expose these sub-fields as mappedfieldtypes, which means that they then appear in field caps, are externally searchable, etc.  it also adds index-time logic to a class that should only be concerned with search-time behaviour. this commit removes references to the index analyzer from mappedfieldtype, and instead adds a 'registerindexanalyzer' method to fieldmapper; all index-time analysis is mediated through the delegating analyzer wrapper on mapperservice.  in a follow-up, this will make it possible to register multiple field analyzers from a single fieldmapper, removing the need for 'hidden' mapper implementations on text field, parent joins, and elsewhere. </desc> <cmt> centralize index analyzer management </cmt>",move index analyzer management to fieldmapper/mapperservice
378,"<desc> in the spirit of jmac & laravelshift i've extracted 2 session variables to the environment file. not 'just because' but that one is able to set session_driver to redis, but unable to set a connection without touching the core session config file. </desc> <cmt> extract core 2 session configurations to environment </cmt> <cmt> in the spirit of jmac & laravelshift i've extracted 2 session variables to the environment file. not 'just because' but rather that one is able to set session_driver to redis, but unable to set a connection without touching the core session config file. </cmt> <cmt> corrected bad copy paste </cmt>",extract 2 core configurations for sessions to environment
379,"<desc> description: adds try/except to prevent failure if a zone has an invalid schedule, preventing issue #27768 bumps evohome-async client to v0.3.4b1 - this is a version # change only, to match an upstream repo. see: zxdavb/evohome-async@0.3.3b5...0.3.4b1 related issue (if applicable): prevents #27768 pull request with documentation for home-assistant.io (if applicable): n/a **example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. </desc> <cmt> refactor entity_ids, and consolidate classes </cmt> <cmt> complete refactor </cmt> <cmt> change back boiler name </cmt> <cmt> de-lint </cmt> <cmt> delinting tweaks </cmt> <cmt> bump client to 0.3.4b1 </cmt> <cmt> handle bad schedules that cause issue #27768 </cmt> <cmt> correct rebase error </cmt>",bugfix evohome and bump client
380,<desc> resolves devrel-1350 - private access: create explainer doc in nodeos/concepts select one: select any that apply: </desc> <cmt> add first draft of privacy feature explainer :doc </cmt> <cmt> add lead dev edits to privacy feature explainer :doc </cmt>,add privacy access feature explainer
381,"<desc> the immutable mode assumes that the output of react is a persistent tree, not mutations on a mutable dom tree. useful for targeting frameworks that accept immutable data structures as input. also adding another experimental rn renderer (cs) to try this out. </desc> <cmt> cs renderer </cmt> <cmt> because we didn't have enough rn experiments. i want to add one more. </cmt> <cmt> split out hydration from the host config object </cmt> <cmt> this makes it easier to do feature detection on the configuration. </cmt> <cmt> move mutation host config to separate optional object </cmt> <cmt> refs and life-cycles should happen even in immutable mode </cmt> <cmt> unmount components even in non-mutation mode </cmt> <cmt> this is the same as committing deletions but instead of finding host </cmt> <cmt> components to delete, it only invokes componentwillunmount and detaching </cmt> <cmt> of refs. </cmt> <cmt> add persistent updates api </cmt> <cmt> this mode will use a clone based api instead of mutating host instances. </cmt> <cmt> needs implementation still. </cmt> <cmt> it's awkward that there can be more than one child inserted into the root. </cmt> <cmt> so we need a new api to create a ""root"" instance so that we can update it </cmt> <cmt> atomically. alternatively we could keep the mutable api for containers </cmt> <cmt> and assume that most use cases would only have a single root. </cmt> <cmt> package up cs renderer </cmt>",split host config out into a mutable or immutable mode
382,"<desc> fixup abort handling of dvdplayer when it's using internal input streams </desc> <cmt> dvdplayer: complete the update of ffmpeg interrupt interface </cmt> <cmt> the old interface could not handle being called from another thread </cmt> <cmt> udp: fix sign of error codes. </cmt> <cmt> udp: fix non-blocking and interrupt handling. </cmt> <cmt> in non-blocking mode, lowest-level read protocols are </cmt> <cmt> supposed block only for a short amount of time to let </cmt> <cmt> retry_transfer_wrapper() check for interrupts. </cmt> <cmt> also, checking the interrupt_callback in the receiving thread is </cmt> <cmt> wrong, as interrupt_callback is not guaranteed to be thread-safe </cmt> <cmt> and the job is already done by retry_transfer_wrapper(). the error </cmt> <cmt> code was also incorrect. </cmt> <cmt> bug reported by andrey utkin. </cmt> <cmt> dvdplayer: make sure member variables are inited in constructor </cmt> <cmt> dvdplayer: make sure we can also abort the open of a ffmpeg input stream </cmt>",fix abort of ffmpeg streams
383,"<desc> causes memory usage regressions </desc> <cmt> revert ""disable a text field test that fails on some macs with libtxt (#14895)"" </cmt> <cmt> this reverts commit aa04a056f39cc9db23878509dc61e0dae7cd7b05. </cmt> <cmt> revert ""roll engine to 33b88173f3820690169348859bbdc29133179e0b (#14832)"" </cmt> <cmt> this reverts commit 44592238bbf28fe2038bb51ed86e0038ab09a8c7. </cmt>",revert engine back to 33b881
384,"<desc> original pull-request #22102 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update entrypoint.sh </cmt> <cmt> fix for #22100 </cmt> <cmt> update entrypoint.sh </cmt> <cmt> docker: avoid chown of . </cmt>",cherry pick #22102 to 21.1: docker: avoid chown of .
385,"<desc> note the lnks here are being pulled from the search plugin, not the program plugin </desc> <cmt> removing description from title </cmt> <cmt> adjusting subtitle </cmt> <cmt> removing accidently paste </cmt> <cmt> removing desc for uwp apps </cmt> <cmt> getting dups removed from list if lnk exists </cmt> <cmt> adjusting subtitle </cmt> <cmt> removing accidently paste </cmt> <cmt> getting dups removed from list if lnk exists </cmt>",deduping results for program plugin
386,"<desc> closes #19950 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry very simple implementation at the moment. the thought here is to introduce this method and perhaps subsequently extend to allow for string concatenation of the elements. longer term there could also be a keyword added to .agg of groupby which will dispatch to this instead of simply returning a multiindex column, which could alleviate some of the pain users are experience when trying to rename columns after an aggregation. @tomaugspurger and @jorisvandenbossche from the dev chat today </desc> <cmt> added initial test </cmt> <cmt> method implementation </cmt> <iss> add method to flatten all multi-index levels </iss>",add to_flat_index method to multiindex
387,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. adeled/react-paginate#334 adeled/react-paginate@aef9d19 </desc> <cmt> add page label builder </cmt> <cmt> update tests </cmt> <cmt> update package version </cmt>,update reactpaginateprops to match v7.1.2
388,<desc> fixed corner case for failures and added debug logging. and increase time allowed to shutdown. </desc> <cmt> fixed corner case for failures and added debug logging. </cmt> <cmt> increased time to wait for shutdown. </cmt> <cmt> cleaned up log statements. </cmt>,extend shutdown allowed time in under min available resources test - 2.0
389,"<desc> please don't merge this pr until cocos2d/cocos2d-js-tests#201 is merged. </desc> <cmt> issue #2521: updating comments where searchs full path. </cmt> <cmt> issue #2521: capture event of controlbutton in ccb for jsb. </cmt> <cmt> issue #2521: fixing a logical error in ccbreader::addowneroutletnode. 'null  != node' --> 'null == node'. </cmt> <cmt> issue #2521: removing an unused method controlstepper::setvalue(double value, bool send); since it's not implemented and there is an similar method 'setvaluewithsendingevent' could replace it. </cmt> <cmt> issue #2521: testjavascript needs ccbreader support. </cmt> <cmt> issue #2521: adding 'cc.convertcolor3btohexstring' in jsb_cocos2d.js. </cmt> <cmt> issue #2521: updating tojs/cocos2dx_extension.ini, bind more cccontrols. </cmt> <cmt> issue #2521: reporting an error when the callback function is undefined in 'js_cocos2dx_setcallback'. </cmt> <cmt> closed #2521: updating jsb_cocosbuilder.js, it supports cccontrol now. </cmt> <cmt> issue #2521: updating js-test. </cmt>",adding more extensiontest like cocosbuildertest and controlbuttontest and bug fix in ccbreader.
390,"<desc> setting a default initial hidden state of zeros if the hidden state is not provided by the user. doing this in the rnnbase class, so it works for all three - rnn, gru and lstm. </desc> <cmt> fixed issue #434 : default initial hidden state for recurrent layers </cmt> <cmt> fixed a whitespace </cmt> <cmt> fixed whitespace issue again </cmt>",default initial hidden states for recurrent layers : issue#434
391,"<desc> detailed description / documentation draft: this update adds a new page, /careers/, to the website with an embedded greenhouse iframe. this new page is linked to from the ""apply now"" button on the company page. </desc> <cmt> migrate changes in compiled css to sass source </cmt> <cmt> add greenhouse careers page </cmt>",add greenhouse careers page to website
392,"<desc> #11121 inadvertently broke the constructor for the testnode() object in p2p-segwit.py, silently breaking at least one of the tests. although the python code was raising exceptions due to a testnode() object not existing (or having the right type), mininode was masking these from anyone running the test through the test_runner (like travis), because it catches all exceptions during message delivery and just prints a log message and continues.  such ""graceful"" handling of errors is almost certainly something we don't want in our test suite, so the first commit here attempts to prevent that type of failure from ever being masked. the second commit fixes the particular bug in p2p-segwit.py. </desc> <cmt> qa: treat mininode p2p exceptions as fatal </cmt> <cmt> qa: fix bug introduced in p2p-segwit.py </cmt> <cmt> changing __init__() -> set_test_params() in the tests should not have </cmt> <cmt> applied to nodeconncb-derived objects. </cmt>","fix error introduced into p2p-segwit.py, and prevent future similar errors"
393,"<desc> what do these changes do? add common preprocessing for each request in node manager three parts are included in preprocessing, logging, checking heartbeat and checking being killed. change submit task request to an asynchronous request. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add preprocess </cmt> <cmt> finish preprocess </cmt> <cmt> chang log level </cmt> <cmt> fix </cmt>",add common preprocessing for each request in node manager.
394,"<desc> i generate java model for api from swagger.yaml. as the swagger spec uses a lot's of inline schema, i end up with various inlineresponse200xx types generated. as swagger do support title as model name, i added this metadata for better generated model. swagger-codegen-plugin for maven  run code generator define titles for swagger inline schema objects so generated code use understandable names </desc> <cmt> schema is missing canremove & detachkeys </cmt> <cmt> example demonstrates they are expected </cmt> <cmt> duplicate definitions for api response with just an id </cmt>",improve swagger schema for code generation
395,"<desc> also, ensure that privatenetwork=/joinsnamespaceof=/networknamespacepath= have an effect on socket units. </desc> <cmt> execute: use structured initialization </cmt> <cmt> execute: make things a tiny bit shorter </cmt> <cmt> execute: (void)ify more </cmt> <cmt> execute: no need to check for null when function right after does anyway </cmt> <cmt> core: add open_netns_path() helper </cmt> <cmt> the new call allows us to open a netns from the file system, and store </cmt> <cmt> it in a ""storage fd pair"". it's supposed to work with setup_netns() and </cmt> <cmt> allows pre-population of the netns used with one opened from the file </cmt> <cmt> system. </cmt> <cmt> core: add new setting networknamespacepath= for configuring a netns by path for a service </cmt> <cmt> fixes: #2741 </cmt> <cmt> core: support netns joining also for sockets created by .socket unit </cmt> <cmt> similar to the cgroup magic we nowadays do when listening to sockets, to </cmt> <cmt> assign them the right bpf programs, let's also do the same and join the </cmt> <cmt> specified netns in the child process. </cmt> <cmt> this allows people to listen in sockets in specific namespaces, or join </cmt> <cmt> multiple services and socket units together to live in the same </cmt> <cmt> namespace. </cmt> <cmt> run: make sure networknamespacepath= can be used on the systemd-run cmdline </cmt> <cmt> man: document networknamespacepath= </cmt>",add networknamespacepath= to unit files
396,"<desc> i hereby agree to the terms of the cla available at:  do not allow to apply parametric aggregate function with -merge combinator to aggregate function state if state was produced by aggregate function with different parameters. for example, state of foostate(42)(x) cannot be finalized with foomerge(s) or foomerge(123)(s), parameters must be specified explicitly like foomerge(42)(s) and must be equal. it does not affect some special aggregate functions like quantile and sequence* that use parameters for finalization only. detailed description / documentation draft:   -resample combinator determines number of intervals (and size of nested aggregate function states array) based on parameters. quantileresamplemerge(0.5, 257, 65536, 1)(s) expects array of size 65279 and tries to read it, however, quantileresamplestate(0.50, 1, 2, 42)(x) produces array of size 1. probably there are more complicated cases and the simplest solution is just to forbid mismatching parameters. also mismatching parameters of -state and -merge aggregate functions do not make any sense in general case. </desc> <cmt> fix another bug </cmt> <cmt> fix_tests </cmt>",check aggregate function parameters in -merge combinator
397,"<desc> this change re-enables travis for branches other than 'v2'. the nacl broken nacl build was actually fixed by a new release of native client but this change is still useful for those of use who want to use travis on our own repos and branchs. </desc> <cmt> fix generate-jsbindings.sh so it can on forked repos. </cmt> <cmt> cleanup .travis.yml, and enable travis on all branchs </cmt>",cleanup travis.yml and re-enable on all branches.
398,<desc> implement various traits (iterbytes and extra's encodable and decodable) for rc when t alreay implements the trait. </desc> <cmt> add an implementation of encodable and decodable for rc. this will be needed to use rc in place of @ in libsyntax. </cmt> <cmt> implement iterbytes for rc<t>. </cmt>,implement various traits for rc<t>
399,<desc> this pr migrates the changes in #4534 and rebases them onto master branch. </desc> <cmt> adds string-to-int and int-to-string methods to enums </cmt> <cmt> remove check for valuetoname property in enumtrait </cmt> <cmt> remove unused imports </cmt>,add enum methods for converting to/from strings
400,"<desc> original pull-request #29925 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update cctz </cmt> <cmt> update cctz </cmt>",cherry pick #29925 to 21.10: update cctz
401,<desc> references #21088 update :arxiv: update docstrings to use consistent naming of :arxiv: links. together with @aufarkari we updated the :arxiv: links only (so :doi: still need to be updated in a separate pr). </desc> <cmt> update decomposition.rst </cmt> <cmt> updating the arxiv formatting </cmt> <cmt> updating arxiv formatting </cmt> <cmt> update plot_partial_dependence.py </cmt> <cmt> updating reference formatting </cmt>,doc use the arxiv directive in the docstrings
402,"<desc> the graph extent mechanism is not good. i have some ideas for a better replacement, but this pr simply removes it. it also stops recursing on statement scopes and processes them using an ""on the heap"" stack, which fixes #29466. r? @dotdash </desc> <cmt> add some comments to mir struct. </cmt> <cmt> remove the graphextents, the design of which seems bogus. they carried </cmt> <cmt> the right information, but it's hard to maintain in the face of </cmt> <cmt> optimizations, and in the form that the analyses probably actually want. </cmt> <iss> stack overflow when compiling lots of macros </iss>",remove graph extents and inline statements
403,"<desc> move a handful of tests from renderer to main runner. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> test: tsify more webcontents specs </cmt> <cmt> getfocusedwebcontents </cmt> <cmt> setdevtoolswebcontents, isfocused, iscurrentlyaudible </cmt> <cmt> getwebpreferences, opendevtools </cmt> <cmt> before-input-event </cmt> <cmt> zoom-changed </cmt> <cmt> sendinputevent </cmt> <cmt> insertcss </cmt> <cmt> startdrag </cmt> <cmt> focus, getosprocessid </cmt> <cmt> zoom api </cmt>",tsify more web contents specs
404,"<desc> currently, if a new commit on master comes between the different stages, the cd pipeline will break. the reason is, the libxmet binary will be posted against one commit id, but the release pipeline (e.g. for pypi packages), will be kicked off with the latest commit id. this pr proposes to fix this issue by introducing a commit_id parameter to the release job definition. this solves the issue. this means we can use the commit id as the branch specifier in the 'pipeline' section of the job configuration and ensure that the specified commit_id will be used for the build. this comes with some drawbacks, namely that release job will assume the state of the last job it ran. this can change the pipeline definition and lead to hard to track errors. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> removes unnecessary parameter </cmt> <cmt> adds revision parameter to release job </cmt>",add commit_id param to release job
405,"<desc> this pr adds links to my article about using antd-scss-theme-plugin to the chinese and english versions of customize-theme. antd-scss-theme-plugin is a webpack plugin for customizing ant design with an scss theme file, using ant design's compiled variables in scss files throughout your project, and hot-reloading the customized ant design styles. connect #9815 (and this comment by @afc163 in particular). please makes sure that these checkboxes are checked before submitting your pr, thank you! make sure that you propose pr to right branch: bugfix for master, feature for latest active branch feature-x.x. make sure that you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. </desc> <cmt> update customize-theme.en-us.md with link to antd-scss-theme-plugin article </cmt> <cmt> this article describes how to install the use the antd-scss-theme-plugin for webpack, and how doing so allows you to: 1) customize ant design's variables from an scss theme file, 2) use compiled ant design variables in other scss theme files in your project, and 3) enable hot-reloading of ant design styles. </cmt> <cmt> update customize-theme.zh-cn.md with link to antd-scss-theme-plugin article </cmt> <cmt> this article describes how to install the use the antd-scss-theme-plugin for webpack, and how doing so allows you to: 1) customize ant design's variables from an scss theme file, 2) use compiled ant design variables in other scss theme files in your project, and 3) enable hot-reloading of ant design styles. </cmt>",add links to antd-scss-theme-plugin article to the customize-theme doc file
406,"<desc> and some cleanup. additionally, attempted machine translation of french docs. may attempt chinese later? </desc> <cmt> update newbs flashing guide </cmt> <cmt> for the newbs that want to start flashing </cmt> <cmt> update flashing docs </cmt> <cmt> misc flashing </cmt> <cmt> attempt at flashing in french </cmt> <cmt> lets hope i didn't butcher this too badly with machine transations </cmt>",update flashing information to include :flash target
407,"<desc> closes #16028 closes #16045 this pr provides a way to make predictions with categoricalnb with data that contains categories that were not observed in the training data. e.g., data for a problem can possibly have 2 categories, but training data only contains samples with one category observed: >>> import numpy as np >>> from sklearn.naive_bayes import categoricalnb >>> x_train = np.array([[0], [0], [0]]) >>> y_train = np.array([0, 1, 0]) >>> clf = categoricalnb(min_categories=2) >>> clf.fit(x_train, y_train) >>> x_test = np.array([[1]]) >>> clf.predict(x_test) array([0]) >>> clf.n_categories_ array([2]) this adds the additional parameters/attributes to __init__ of categoricalnb: parameters ---------- min_categories : int or array-like or none, (default=none) minimum number of categories per feature: - int : sets the minimum number of categories per feature to n_categories for each features. - array-like : n_categories[i] holds the minimum number of categories for the ith column of the input. - none : determines the number of categories automatically from the training data. attributes ---------- n_categories_ : ndarray (n_features,) number of categories for each feature. this value is provided inferred from the data or set by the minimum number of categories. this feature has uses in instances where a given category may be rare, and then by random chance is observed in a test/application set, but not in the training set. in the current version, such an instance will raise an error (as detailed in #16028). this differs slightly from the solution i proposed in #16028 . implementation in this way allows a minimum number of categories to be specified, but be overridden if the data has more categories, which i thought may be user-side. this fix will still result in the same unhelpful error message mentioned #16028 if category i has a greater value in a non-training set than the value of n_categories[i] - 1. is #16045 considered stalled at this point?  would it be worth wrapping a helpful error message for that case into this pr? </desc> <cmt> tst: expose indexerror for unseen feature category </cmt> <cmt> enh: allow unseen categories with n_categories in categoricalnb </cmt> <cmt> tst: test n_categories works and gives appropriate errors </cmt> <cmt> maint: refactor so n_categories_ is kept as attribute in categoricalnb </cmt> <cmt> maint: fix pep8 violation </cmt> <cmt> tst: add test for min_categories < n_categories_ and refactor </cmt> <cmt> fix: remove addition to feature max </cmt> <cmt> doc: remove unique values from docstring </cmt> <iss> categoricalnb bug with categories present in test but absent in train </iss>",enh add min_categories parameter for each feature to categoricalnb
408,"<desc> original pull-request #26707 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix set role. </cmt> <cmt> fix set role </cmt>",cherry pick #26707 to 20.8: fix set role
409,<desc> adds fuchsiasdk a wrapper/shim which provides access to the set of command line tools necessary to work with a fuchsia device. internal tool will inject a different implementation that knows where to look in google3. adds fuchsiaworkflow which defines that fuchsia development is supported wherever an fx command can be found. this is somewhat hacky... adds fuchsiadevices which adds basic support for device discovery using netaddr and netls commands. this should work as-is internally when the tool commands are swapped out with a different fuchsiasdk location. </desc> <cmt> fuchsia devices </cmt> <cmt> add tests and refactor sdk to fx wrapper </cmt> <cmt> add missing newlines </cmt>,"support for fuchsia device discovery, workflow, and sdk wrapper"
410,<desc> added my personal hhkb-based layout for the dz60. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> created personal keymap for dz60 hhkb layout. </cmt>,add hhkb-based keymap for dz60
411,"<desc> fixes #4260. evaluates the output iterable right after the spider callback, as it's currently being done in the process_spider_output chain. (plus some minor styling adjustments) </desc> <cmt> [test] spider middleware: catch exceptions right after the spider callback </cmt> <cmt> spider middleware: catch exceptions right after the spider callback </cmt> <iss> first spider middleware does not process exception for generator callback </iss>",catch spider callback exceptions early
412,"<desc> when the upstream responds a payload whose length is smaller than content-length header value, the current implementation of fastcgi handler and mruby's http_request don't send rst_stream frame. this pr makes those handlers send rst_stream. note1: this pr depends on #1489 to make some tests pass note2: desirable h2o behaviours upstream payload h2o payload rst_stream (h2) chunked (h1) smaller than c-l send all received body yes - bigger than c-l send body upto c-l no - te:chunked ending in mid-of-chunk send all received body yes append a broken chunk (1\r\n) te:chunked ending on chunk boundary but no eos send all received body no append an eos (0\r\n) see also: #1031 </desc> <cmt> fix keepalive problem which happens when mruby's http_request shortcut is used </cmt> <cmt> send rst_stream when received smaller payload than content-length header </cmt>",forward the error to the client when upstream closes the connection abruptly
413,<desc> this pr updates some return types to include undefined. that helps documenting the api and prevents bugs when using strictnullchecks fixes #15841 </desc> <cmt> update types.ts </cmt> <cmt> update types in parser.ts and scanner.ts </cmt>,update return types of apis
414,"<desc> 3.2 version of #42178 : this pr has most of the things in #41097 (excluding the virtual keyboard support): refactor event handlers, moving add/remove logic to native/utils.js window event handlers no longer usecapture (fixes #33020) canvas resize option now available on export (fixes #37205). plus, a rework of the initialization process to better handle file system synchronization (last commit, fixes #39643): the engine now expects to emscripten fs to be setup and sync-ed before main is called. this is exposed via module[""initfs""] which also allows to setup multiple persistence paths (internal use only for now). additionally, fs syncing is done once for every loop if at least one file in a persistent path was open for writing and closed, and if the fs is not syncing already. this should potentially fix issues reported by users where ""autosave"" would not work on the web (never calling syncfs because of too many writes). </desc> <cmt> move request_quit to javascript_main. </cmt> <cmt> small refactor to javascript handlers. </cmt> <cmt> crated helper class in native/utils.js. </cmt> <cmt> simplify code in os/displayserver. </cmt> <cmt> window event listener do not use capture. </cmt> <cmt> better hidpi support in html5. </cmt> <cmt> make canvas resize optional in html5. </cmt> <cmt> js synchronous start, better persistent fs sync. </cmt> <cmt> the engine now expects to emscripten fs to be setup and sync-ed before </cmt> <cmt> main is called. this is exposed via module[""initfs""] which also allows </cmt> <cmt> to setup multiple persistence paths (internal use only for now). </cmt> <cmt> additionally, fs syncing is done **once** for every loop if at least one </cmt> <cmt> file in a persistent path was open for writing and closed, and if the fs </cmt> <cmt> is not syncing already. </cmt> <cmt> this should potentially fix issues reported by users where ""autosave"" </cmt> <cmt> would not work on the web (never calling syncfs because of too many </cmt> <cmt> writes). </cmt>","synchronous main, better persistence, handlers fixes, optional full screen."
415,"<desc> i found various things i wanted to adjust while working with this helm chart, so i made this bigger pr for some initial discussion and local development. i can split it  up into reasonable chunks to get it merged later if it makes sense to you. while reviewing, i recommend doing it one commit at the time. change overview some refactoring for readability, these changes are in alignment with common modern practices. see for example: helm/helm#4562 added ability to add more configuration files switched to using a k8s secret over the k8s configmap to save .values.configfile content as sensitive passwords were suggested to be stored in the file. added checksum annotations to restart pods on configuration changes bumped superset version to 0.28.1 </desc> <cmt> refactor template to include function </cmt> <cmt> refactor to utilize default function </cmt> <cmt> refactor away blank container.env </cmt> <cmt> refactor systematic left whitechomping </cmt> <cmt> refactor indentation for readability </cmt> <cmt> allow for additional config files </cmt> <cmt> restart pods on changed config </cmt> <cmt> secure secrets in config </cmt> <cmt> refactor away unused code </cmt> <cmt> bump superset version </cmt> <cmt> bump chart version </cmt>","refactoring, additional configs, secure secrets, versionbump"
416,<desc> closes #25104 added type set_option docstring in config.py -added type to boxplot_frame_groupby docstring in plotting/_core.py -indented versionadded in excelwriter docstring io/excel.py -updated code_check.sh to take into account pr10 type errors </desc> <cmt> added type set_option docstring in config.py </cmt> <cmt> added type to boxplot_frame_groupby docstring in plotting/_corew.py </cmt> <cmt> indented versionadded in excelwriter docstring io/excel.py </cmt> <cmt> updated code_check.sh to take into account pr10 type errors </cmt>,fixes to docstrings and add pr10 (space before colon) to validation
417,"<desc> added via support to doodboard/duckboard_r2 as a copy of the default keymap with via enabled. tested on my own duckboard r2.  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> update r1 keymap and config </cmt> <cmt> add duckboard r2 </cmt> <cmt> add via support for duckboard r2 </cmt>",add via support to doodboard/duckboard_r2
418,"<desc> the regex's used to find img tags in html fields were changed to match eslint rules but that change broke the matches for certain situations (but not the ones in our tests ). this pr reverts those changes, matches any special character in url's (instead of just url-safe characters), and adds a unit test for 2 of our html regex's. </desc> <cmt> revert regex's to earlier state before eslint changes and match any character in urls </cmt> <cmt> test wp html image regexs </cmt>",fix(gatsby-source-wordpress): html image regex's
419,<desc> flutter stable 2.5.0 framework scheduled cherrypicks cherrypick devtools version issues: #89320 commit: 870f5e8 roll engine cherrypicks from: flutter/engine#28496 </desc> <cmt> update devtools version to latest release 2.6.0 (#89318) </cmt> <cmt> this will need to be cherry picked into the stable release. </cmt> <cmt> 'update engine revision to f0826da7ef2d301eb8f4ead91aaf026aa2b52881 for stable release 2.5.0' </cmt>,flutter stable 2.5.0 framework cherrypicks
420,"<desc> as of v140, there were duplicate onpress events firing for keyboard/controller presses on touchable*s. #2968 removed the native onpress, but unfortunately #3042 and #3049 removed the js ones (not realizing that the native ones had already been removed.) this pr brings back the js onpress calls. verified using the playground app and rntester. microsoft reviewers: open in codeflow </desc> <cmt> add handlepress back to touchable* onkeyup </cmt> <cmt> change files </cmt>",fix onpress not firing for touchable* keyboard events
421,"<desc> removes tmparch/tmpbits from command syntax because we have @a and @b now. moreover, it improves @a/@b usages, because it also correctly sets/restores anal hints. </desc> <cmt> core/cmd_print: remove redundant code from ""pd"" command </cmt> <cmt> no need to have tmp arch and tmp bits in the syntax, we can use @a and </cmt> <cmt> @b. also, fix @a and @b to temporarily overwrite anal hints. </cmt> <cmt> core: remove useless code in ""pa"" and ""aex"" commands </cmt> <cmt> no need to have arch and bits in the command syntax, just use @a and @b. </cmt>",fix pd syntax (also aex and pa)
422,"<desc> code example for article ""introduction to quartz"" </desc> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merged branch master into master </cmt> <cmt> merge remote-tracking branch 'eugenp/master' </cmt> <cmt> quartz example for article: introduction to quartz </cmt> <cmt> adding new module for java quartz </cmt> <cmt> removing quartz code from jee7 module </cmt> <cmt> fixing folder structure </cmt>",code example for article bael-818
423,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fixed tests/series/methods/test_asof.py </cmt> <cmt> fixed tests/series/methods/test_droplevel.py </cmt> <cmt> fixed tests/series/methods/test_tz_localize.py </cmt> <cmt> fixed tests/series/test_apply.py </cmt> <cmt> fixed tests/series/test_arithmetic.py </cmt> <cmt> fixed tests/series/test_datetime_values.py </cmt> <cmt> fixed test/series/test_operators.py </cmt> <cmt> fixed tests/tools/test_to_time.py </cmt> <cmt> final commit before style checks </cmt> <cmt> tst: final commit fixing bare pytest raises </cmt> <cmt> tst: fixed bare pytest raises </cmt>",30999 fix bare pytest raises
424,"<desc> there're a few problems with current version of type definitions that this pull request addresses: type checking is not performed in many places using any rather than a generic type. no property name type-check. for example, we ideally shouldn't allow to do this: state.set('foo', 1) // state type doesn't have the property foo types are sometimes wrong. for example, methods shouldn't return solely the mixin part immutableobject<any>, but rather the type plus the mixin part t & immutableobjectmixin<t>. checklist: follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> enforce strong typing for partial objects and property names </cmt> <cmt> enforce strong typing in update, updatein, without </cmt> <cmt> final polishing </cmt> <cmt> add fallback definition to solve dynamic scenarios and when the number of arguments is more than 5 </cmt> <cmt> set/update fallbacks, tests, tslint coverage </cmt> <cmt> fix common mistakes </cmt> <cmt> add function-like constructor; fix lint errors </cmt>","replace any with meaningful types, enforce string property typing, fix bugs"
425,<desc> this prodives a https endpoint with a self-signed ca certificate. the main motivation is to provide infrastructure for integration tests for #71979. ansible-test for more information and an example use case see #71979. </desc> <cmt> introduce self-signed.ansible.http.tests </cmt> <cmt> forwarding of port 444 </cmt> <cmt> forward port 8444 to port 444 on http test container </cmt> <cmt> fix port forwarding for windows under docker </cmt>,add self-signed https endpoint for ansible-test
426,<desc> i hereby agree to the terms of the cla available at:  now partition id in queries like alter table ... partition id xxx validates for correctness. fixes #25718. </desc> <cmt> add test </cmt> <cmt> simple validation for partition id before drop partition </cmt> <iss> validate partition id before drop partition </iss>,add simple validation for partition id before drop partition
427,"<desc> this enables running the built-in js component tests for list. we need to make source copies of these since they are not published in the npm package, but we can keep them synchronized via override tooling. need to add for react-native-win32 in a later change microsoft reviewers: open in codeflow </desc> <cmt> run rn list jest tests </cmt> <cmt> this enables running the built-in js component tests for list. we need to make source copies of these since they are not published in the npm package, but we can keep them syncrhonized via override tooling. </cmt> <cmt> still need to register these in overrides.json, add for react-native-win32 as well. </cmt> <cmt> change files </cmt>",run rn list component jest uts
428,<desc> just breaking up the logic so i can reuse it for defer. </desc> <cmt> [move-function] convert movekillscopyableaddressesobjectchecker.visitor to be a local variable instead of a field. </cmt> <cmt> nfc. </cmt> <cmt> [move-function] move addressestocheck out of movekillscopyableaddressesobjectchecker and into the users of said checker. </cmt> <cmt> this ensures that movekillscopyableaddressesobjectchecker is only ever </cmt> <cmt> processing a single address rather than maintaining this worklist. this will </cmt> <cmt> enable me to reuse parts of it in a simpler way for defer checking. </cmt> <cmt> [gardening] move a utility function into the utility section of the file before more re-organization. </cmt> <cmt> [move-function] refactor out the main dataflow computation into a helper struct. </cmt> <cmt> [move-function] move the single basic block dataflow also onto that helper struct. </cmt>,some refactorings in preparation for defer
429,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldnt have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> added typings for datadog-winston </cmt> <cmt> updated comments </cmt> <cmt> fixing comments which will also kick the git checks </cmt> <cmt> apparently i can't have a patch in my version. i thought this was supposed to be the version of the js package my types target </cmt> <cmt> ahh i see now, it is the version of the js package, just with patch omitted </cmt> <cmt> updated library to use commonjs style imports </cmt> <cmt> formatting </cmt>","adding typescript support for ""datadog-winston"""
430,<desc> finish testcases  for opentstb-telnet-protocol with taosadapter renew testcases  for opentstb-telnet-protocol with taosc opentsdbtelnettaosadapterinsert.py no ci temporarily because develop branch doesn't build taosadapter. </desc> <cmt> [td-10908]<test>: add testcases for influxdb-line-protocol with blmv3 </cmt> <cmt> modify util/common.py </cmt> <cmt> modify functions </cmt> <cmt> save </cmt> <cmt> finish insert/opentsdbtelnetblm3insert.py </cmt> <cmt> [td-10952]<test>: finish insert/opentsdbtelnetblm3insert.py </cmt> <cmt> [td-10952]<test>: finish testcases  for opentstb-telnet-protocol with taosadapter </cmt> <cmt> rm insert/influxdbblm3insert.py in this branch </cmt> <cmt> [td-10952]<test>: renew testcases  for opentstb-telnet-protocol with taosc </cmt>,renew testcases  for opentstb-telnet-protocol with taosc and finish testcases  for opentstb-telnet-protocol with taosadapter
431,"<desc> change variable name for nettytransporter actually, these are handler not listener follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> fix typo ,the method not only for get port </cmt> <cmt> change variable name listener to handler </cmt>",fix variable name  in nettytransporter
432,"<desc> i hereby agree to the terms of the cla available at:  documentation for #3210 files from en docs are copied to ru docs. don't review them, they will be overwritten with russian translation. </desc> <cmt> docapi-6206: odbc engine and table function. </cmt> <cmt> docapi-6206: fix. </cmt> <cmt> docapi-6206: odbc table engine description. </cmt>",docapi-6206 odbc table engine and odbc table functions descriptions
433,"<desc> closes #23490 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry fix issue described in #23490, and add tests to catch this case. </desc> <cmt> bug - account for names when concating series on axis 1 </cmt> <cmt> tst - add test to make sure names argument is accounted for when concating series and axis=1 </cmt> <iss> bug: pd.concat with all series on axis=1 ignores the `names` argument. </iss>",bug - pd.concat with all series on axis=1 ignores the names argument (issue: 23490)
434,"<desc> adds mapper functions allows css.core for style/css add new round shapes add extra params to handler connecting unused interfaces (i.e. they are now being used) for the styles add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> allows css.core for the style/css </cmt> <cmt> adds new round shapes </cmt> <cmt> - allow mapper functions when defining style properties </cmt> <cmt> - adds ""ghost"" </cmt> <cmt> - plugs some interfaces to css.node/edge </cmt> <cmt> - add extra params to handler </cmt> <cmt> - fixes the originalevent type </cmt> <cmt> - adds other events methods </cmt> <cmt> fix linting </cmt>",add mapper functions and more
435,"<desc> this is a large refactor of our string methods. the goal is to have the series.str accessor dispatch the actual compute down to the extensionarray. the motivation is to allow a series backed by arrow memory to use the arrow string kernel (e.g. series.str.lower() on an arrow-backed stringarray should eventually call pyarrow.compute.utf8_lower().) to facilitate this, i made the following changes split core/strings.py into a sub package: core/strings/accessor.py: implements the series.str accessor, which (mostly) just delegates to the ea and wraps core/strings/object_array.py: implements the string methods for object-type ndarray. core/strings/categorical.py, core/strings/string_array.py, implements categorical & stringarray-specific methods defines a new extensionarray._str extension point. this is where eas get to take over and use their compute note that there are a few methods like cat, extract, and extractall that don't yet dispatch. i need to look into them a bit more, there implementation is a bit confusing. closes #36216 </desc> <cmt> implement basedtypetests for arrowstringdtype </cmt> <cmt> refactor to use parametrized stringdtype </cmt> <cmt> wip </cmt> <cmt> annoyed </cmt> <cmt> wip </cmt> <iss> refactor stringmethods for extension arrays </iss>",dispatch string methods to extensionarray
436,"<desc> isolate multi-thread support from 'multiplereader', making it an independent decorated reader(threadedreader). add docstring for some python interfaces. combine 'open_files', 'multi_pass_reader' and 'threaded_reader' together to make a new python open_files() interface. simplify python interface 'create_xxx_reader' names, e.g, rename 'create_double_buffer_reader' to 'double_buffer'. remove readers' hasnext(), for it is unsafe in multi-thread environment. </desc> <cmt> add 'buffer_size' api for open_files op </cmt> <cmt> add docstring </cmt> <cmt> a draft of threadedreader </cmt> <cmt> complete threaded reader </cmt> <cmt> fix compile errors </cmt> <cmt> modify multiplereader </cmt> <cmt> 1. removes multiplereader's multi-thread support, for we have got </cmt> <cmt> threadedreader. </cmt> <cmt> 2. rename multiplereader to multifilereader </cmt> <cmt> update readers python api </cmt> <cmt> 1. combine 'open_files', 'multi_pass_reader' and 'threaded_reader' </cmt> <cmt> together to make the new 'open_files' interface. </cmt> <cmt> 2. add some docstring. </cmt> <cmt> 3. simplify interface names of 'create_xxx_reader', e.g, rename </cmt> <cmt> 'create_double_buffer_reader' to 'double_buffer'. </cmt> <cmt> fix errors </cmt>",modify readers to fit the parallel executor
437,<desc> migration for the pivot table visualization render updated pivot table make editor settings work clean up old code add tests review changes and manual test -- </desc> <cmt> npm install react-pivottable </cmt> <cmt> initiate pivot table migration </cmt>,migrate pivot table visualization to react
438,"<desc> closes #8961 related to rocketchat/rocket.chat.livechat#399 the users and managers want to know the website url from where the livechat offline message comes from. now, the livechat widget will send this information among the other fields passed through the endpoint. ps: i'm going to add the new field(host) of the endpoint on the related rest doc page. </desc> <cmt> add web site url from where the message has been sent. </cmt> <cmt> turn the host field mandatory. </cmt> <iss> livechat: include website url in email sent when agents are offline </iss>",add livechat website url to the offline message e-mail
439,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! add courses from kaggle and a few screencasts in brazilian portuguese it has some good skills to be developed within the channels/platforms that are being submitted. both kaggle and youtube are free platforms. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> check_urls=free-courses-en.md </cmt> <cmt> check_urls=free-podcasts-screencasts-pt_br.md </cmt> <cmt> check_urls=free-courses-en.md </cmt> <cmt> check_urls=free-podcasts-screencasts-pt_br.md </cmt> <cmt> check_urls=free-courses-en.md </cmt>",adding courses from kaggle and screencasts
440,"<desc> since the release version is a calculated based on the previous git tag for beta releases, this calculated version will be wrong if there was not a previous dev release. this adds a validating that the calculated version matches the candidate branch numbers. </desc> <cmt> wip </cmt> <cmt> validate git parsed version and rc branch match </cmt>",validate git parsed version and release branch match
441,<desc> hello this pr will fix the shown zoffset value in tune and prepare menu. actual behavior value wrong scaled and only one digit after the point like 0.0 screen: </desc> <cmt> zoffset </cmt> <cmt> update dwin.cpp </cmt>,fix e3v2 (crealityui) zoffset in tune & prepare menu
442,"<desc> this pr contains the changes from #306 by jwisniewski plus some fixes to make it work with latest libgdx code. </desc> <cmt> what i did (philosophy): </cmt> <cmt> libgdx is based on singletons (gdx.app etc), moreover user can implement </cmt> <cmt> his own singletons and it just works when libgdx is used to make desktop </cmt> <cmt> applications, android activities etc. live wallpaper backend was </cmt> <cmt> designed in wrong way (from libgdx point of view), this design tried to </cmt> <cmt> force libgdx to work in environment it was not designed to. there should </cmt> <cmt> be only one instance of libgdx singletons in application, but libgdx </cmt> <cmt> wallpapers work on many engines with many surfaceholders.. </cmt> <cmt> i just moved things to (in my opinion) right direction: i forced live </cmt> <cmt> wallpapers api to create environment libgdx is designed to. redesigned </cmt> <cmt> androidlivewallpaperservice stops all this madness linked with switching </cmt> <cmt> wallpaper 'engines' by itself. rest of user application, libgdx </cmt> <cmt> internals etc. works normally and exactly the same as in other types of </cmt> <cmt> applications (there is only one instantion of applicationlistener, </cmt> <cmt> androidgraphicslivewallpaper, glsurfaceview etc). it should be possible </cmt> <cmt> to run any of existing libgdx apps as wallpaper now (perhaps after </cmt> <cmt> solving few little issues - i'm new in libgdx:)). </cmt> <cmt> all lifecycle issues was resolved. with this lw backend user can switch </cmt> <cmt> wallpapers as fast as he want, can sleep phone in live wallpaper </cmt> <cmt> preview, it now runs without problems on devices on which it crashed </cmt> <cmt> before. no null gl contexts inside render() method. </cmt> <cmt> much faster wallpaper loading (ex in preview) </cmt> <cmt> much faster resuming after phone was in sleep mode. </cmt> <cmt> most of code duplicated for lw backend is no longer used and can be </cmt> <cmt> deleted. </cmt> <cmt> if end developer want to implement custom application behavior in </cmt> <cmt> wallpaper preview, there is additional interface called </cmt> <cmt> androidwallpaperlistener, he should implement it in his application </cmt> <cmt> listener and respond for event called when preview is opened/closed (see </cmt> <cmt> modified livewallpaper test). </cmt> <cmt> what i did (technically): </cmt> <cmt> + completely new implementation of androidlivewallpaperservice. there </cmt> <cmt> can be many engines in runtime, and any of them is linked with own </cmt> <cmt> surfaceholder on wallpaper should draw. but.. only one engine is active </cmt> <cmt> at specific time. wallpaper service switches smartly between them and </cmt> <cmt> update glsurfaceview to use currently active surfaceholder and render on </cmt> <cmt> it. this is transparent for rest of application, and for glsurfaceview </cmt> <cmt> itself too! i just simulates events called when surface holder is lost </cmt> <cmt> or restored. glsurfaceview 'think' its surface was lost and restored, </cmt> <cmt> but really it was just switched to another surface holder (linked with </cmt> <cmt> active wallpaper engine). </cmt> <cmt> + androidgraphicslivewallpaper now uses glsurfaceview and </cmt> <cmt> glsurfaceviewcapcake as original androidgraphics (with slight </cmt> <cmt> modifications). gl..surfaceviewlw classes are deprecated, not used, and </cmt> <cmt> can be removed completely. </cmt> <cmt> + androidgraphislivewallpaper synchronized with current androidgraphics </cmt> <cmt> and androidgraphicsdaydream (now it is near mirror copy of original </cmt> <cmt> androidgraphics, i think you should merge this three classes in near </cmt> <cmt> feature before they will be resynchronized again, it shouldn't be hard </cmt> <cmt> to do) </cmt> <cmt> + androidwallpaperlistener, interface that can be implemented in </cmt> <cmt> addition to applicationlistener in libgdx application to autimatically </cmt> <cmt> add support for live wallpaper specific events </cmt> <cmt> + updated livewallpaper test </cmt> <cmt> + added synchronization to androidgraphicslivewallpaper.resume (as in </cmt> <cmt> pause, destroy etc) </cmt> <cmt> + synchronization in androidgraphicslivewallpaper.resume </cmt> <cmt> + fixed synchronization of lifecycle methods in </cmt> <cmt> androidgraphicslivewallpaper (waiting threads was notified too early and </cmt> <cmt> on some devices it caused errors while rotating device in lwp </cmt> <cmt> preview: </cmt> <cmt> a/libc(1274): fatal signal 11 (sigsegv) at 0x0000003c (code=1), thread </cmt> <cmt> 1291 (thread-153) </cmt> <cmt> + more logging </cmt> <cmt> + wallpaperservice ondispose improved: glthread is killed now and audio </cmt> <cmt> is disposed </cmt> <cmt> - disabled logging </cmt> <cmt> + optimized number of calls to logger (less logging! when pausing / </cmt> <cmt> restoring live wallpaper - which can occur very often in contrast to </cmt> <cmt> regular applications) </cmt> <cmt> + some cleaning of commented code etc </cmt> <cmt> ~ input created without help of androidinputfactory - it causes errors </cmt> <cmt> when obfuscated because of reflection relying on plain class names </cmt> <cmt> + more fixes for lifecycle - pausing of lwp was broken </cmt> <cmt> crashing again.. </cmt> <cmt> + bugfix: ""fatal signal 11"" on some devices when rotating lwp in preview </cmt> <cmt> application listener pause will not be called anymore! </cmt> <cmt> + fix for surfacechanged event </cmt> <cmt> disabled logging </cmt> <cmt> + mesh constructor with optimizations for dynamic meshes </cmt> <cmt> vertexbufferobjestsubdata restored to original </cmt> <cmt> android backend classpath restored to original from libgdx repo </cmt> <cmt> fixed support for glsurfaceviewcupcake </cmt> <cmt> note: </cmt> <cmt> i added slight modification to lifecycle of surface view in general. </cmt> <cmt> i have tested it on galaxy s and galaxy s3, but it is not yet as heavy </cmt> <cmt> tested as last implementation (by thousands of my clients on google </cmt> <cmt> play and samsung apps). so this update can repair support for opengl </cmt> <cmt> 1.x, but can also destroy it on opengl 2.0. </cmt> <cmt> conflicts: </cmt> <cmt> backends/gdx-backend-android/src/com/badlogic/gdx/backends/android/androidgraphicslivewallpaper.java </cmt> <cmt> backends/gdx-backend-android/src/com/badlogic/gdx/backends/android/androidlivewallpaper.java </cmt> <cmt> merged latest changes of lwpredesign from jwisniewski with latest libgdx, fixed some glu stuff </cmt>",redesigned android live wallpaper backend by jwisniewski
443,"<desc> execute monodevelop from the right appdomain. closes #15454 sometimes stackframe.getmethod() returns null (e.g.: latest frame of a missingmethodexception). still not sure what to do with that frame (maybe skip it), but at least it no longer fails. skip csharplanguage::debug_get_current_stack_info() if an error is printed from gdmonoutils::update_corlib_cache(). fix crash when calling gdmonoutils::print_unhandled_exception(exc) if there is no scriptdebugger attached. </desc> <cmt> mono: fix starting monodevelop process from the wrong appdomain </cmt> <cmt> mono: some stacktrace to stackinfo[] fixes </cmt> <cmt> - sometimes stackframe.getmethod() returns null (e.g.: latest frame of a missingmethodexception). still not sure what to do with that frame (maybe skip it), but at least it no longer fails. </cmt> <cmt> - skip csharplanguage::debug_get_current_stack_info() if an error is printed from gdmonoutils::update_corlib_cache(). </cmt> <cmt> - fix crash when calling gdmonoutils::print_unhandled_exception(exc) if there is no scriptdebugger attached. </cmt>",stackframe and monodevelop crash fixes
444,"<desc> i figured out the problem i was having: it was a problem with the test code and not with the submission. anyway, i cleaned it up a bit (changed floats to real_t). </desc> <cmt> added rot/pos constructor for matrix32 variant. </cmt> <cmt> implemented interpolation for affine transformations (matrix32::interpolate_with) </cmt> <cmt> changed 'scale' to 'scale_basis' in 'interpolate_with'. </cmt> <cmt> changed floats to 'real_t'. </cmt>",interpolation for affine transformations/bound rot/pos matrix32 constructor
445,"<desc> see #5493 implemented all suggestions, except the extended detection of puya like flash operations. current detection is only to match the vendor id from the flash chip id. </desc> <cmt> [puya] applied espeasy puya_v3.patch </cmt> <cmt> applied the patch to get the starting point as described in </cmt> <cmt> [puya] only allocate memory when puya detected </cmt> <cmt> core 2.5.0 puya patch, no puya: </cmt> <cmt> description	function	#calls	call/sec	min (ms)	avg (ms)	max (ms) </cmt> <cmt> save file		4	0.25	34.755	45.264	67.620 </cmt> <cmt> free mem:	16168 </cmt> <cmt> core 2.5.0 puya patch, faked puya detect: </cmt> <cmt> description	function	#calls	call/sec	min (ms)	avg (ms)	max (ms) </cmt> <cmt> save file		2	0.04	41.332	57.544	73.756 </cmt> <cmt> free mem:	11560 </cmt> <cmt> [puya] check for puya chip as soon as possible at boot </cmt> <cmt> check for puya chip in call for getflashchipid() </cmt> <cmt> this will only be done once and the result of the get function is also cached. </cmt> <cmt> [puya] use limited buffer (512 byte) allocated at first write </cmt> <cmt> no need to allocate a buffer when not writing to flash. </cmt> <cmt> the default buffer size is 512 bytes, which is 2 pages in the flash chip. </cmt> <cmt> [puya] lower puya flash buffer to 1 page (256 b) </cmt> <cmt> as discussed here: </cmt>",rewrite puya patch to be more universal and mem friendly.
446,<desc> i made the change you proposed on  i also added a test to ensure the string are being converted into unicode. do you think we need a test to ensure they are correctly translated? force_text should be already tested. </desc> <cmt> added tests for issue 747 in serializer.py </cmt> <cmt> forcing translations of lazy translatable strings in field to_native method </cmt>,issue 747 lazy strings serialized
447,"<desc> i removed all extension checking code to gl-subsystem.c as it needs to be called on all platforms and does not change given a platform. i added a function and tables to handle opengl debug and error messages via the arb_debug_output extension or via the gl 4.0 api if available. i removed the hardcoded request for a 3.2 context on linux and windows. it will now give the latest context given it fits our requirements (which is just a core profile and debug context if _debug is set currently). snuck in was a change to autoconf that allows autoconf to correctly find wxwidgets 2.9 (or greater) with wx-config (not just wx-config-2.9) without user interaction. </desc> <cmt> added opengl debug callback support and context changes. </cmt> <cmt> 1. we no longer hardcode a 3.2 profile. it chooses the latest profile that fits out description. </cmt> <cmt> 2. i added three tables and macros to help with the offsets compared to the variables to help reading. read comments for more info. </cmt> <cmt> 3. i added glewexperimental being set. what a dumb ""feature"". it doesn't help anything... </cmt> <cmt> remove enable statements. this should be done in platform-independent code using glew. </cmt> <cmt> added gl_update (does nothing for now). </cmt> <cmt> fix previous commit.. </cmt> <cmt> added glx version check and assures context is set to none on failure. </cmt> <cmt> fixed the location glewexperimental was being set to just before glewinit() (where it should be). </cmt> <cmt> minor style fixup </cmt> <cmt> change _debug coverage a bit </cmt> <cmt> i removed gl-specific extension checking to a platform independent file. </cmt> <cmt> i also fixed autoconf to find wxwidgets 2.9 without user intervention </cmt> <cmt> removed unused code and added more organization </cmt>",various changes to opengl intialization
448,"<desc> several plugins were using the stat command to determine modified time in order to determine if cached targets needed to be updated.  this command needed to be different on os/x than on other os's.  using the [ builtin's -nt comparison does this and should be more portable. the phing task also had some regex's that would remove legitimate targets from completion. </desc> <cmt> use [ -nt ] instead of stat -f%m to check cache files. </cmt> <cmt> allow "":"" and ""-"" characters in phing tasks. </cmt> <cmt> tasks that included hyphens or colons were being excluded from </cmt> <cmt> completion.  this improves the usage for this. </cmt>",improve portability of cache file detection for command targets
449,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add definitions for dropbox chooser </cmt> <cmt> update typedefs </cmt> <cmt> merge from base repo </cmt> <cmt> remove newline </cmt>",update names and cleanup for dropbox chooser definitions
450,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see issues referenced in commit messages increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix: allow ember.typeof zero-argument case </cmt> <cmt> fixes: </cmt> <cmt> fix: remove outdated ember.string.fmt </cmt> <cmt> fixes: </cmt> <cmt> fix: allow zero-argument usage of ember.isblank, .isempty, .ispresent and .isnone </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt> <cmt> fixes </cmt>","fix several ""empty check"" function zero-argument cases"
451,"<desc> looks like there's an issue setting up the middleman server on windows (""connection actively refused"") on tests that are run after test_valid_actor_state, mark as flaky for now i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> skip test_wrapped_actor_creation on windows </cmt> <cmt> rerun windows ci </cmt> <cmt> mark test_valid_actor_state_2 as flaky </cmt> <cmt> mark test_valid_actor_state </cmt>",skip test_valid_actor_state tests on windows
452,<desc> fix a few of the javadoc compiler warnings in jenkins core. </desc> <cmt> fix javadoc warnings for unknown tags </cmt> <cmt> @sine -> @since </cmt> <cmt> @lnk -> @link </cmt> <cmt> @author: -> @author </cmt> <cmt> make embedded @ sign literal in one case where it is literal </cmt> <cmt> remove trailing extra curly brace from javadoc @see reference </cmt> <cmt> use javadoc @see external url syntax for these external urls </cmt> <cmt> remove empty @see javadoc comment in updatecenter </cmt> <cmt> terminate javadoc @link tags with curly brace instead of right paren </cmt>,javadoc fixes for jenkins core
453,"<desc> function safe_eval ansible version $ ansible --version ansible 2.3.0 config file = configured module search path = default w/o overrides i met this issue when i tried to run test_uri under python 3. in this test, there are some json files downloaded through http (with uri module) and some local json files and at the end of test this two groups of files are compared to each other to check if downloaded files are the same. the problem isn't in the task where the result of uri module is registered as a variable but in the task, where this registered variable with results is used to check. when this registered variable is used in the task for final check, function safe_eval is not capable of evaluating it from yaml template. problem is that under python 2 safe_eval returns dictionary, but under python 3 it returns a string because there is invalid expression exception inside the function. this simple change fixes this problem under python 3. however, this change is in the core part of the code so it should be reviewed. related pr with discussion and more details: #18060 </desc> <cmt> enable tests on python 3 for uri </cmt> <cmt> added one more node type to safe_nodes into safe_eval module. </cmt> <cmt> ast.usub represents unary operators. this is necessary for </cmt> <cmt> parsing some unusual but still valid json files during testing </cmt> <cmt> with python 3. </cmt>",fix ast nodes for python 3 and enable dependent test_uri
454,"<desc> implemented as in </desc> <cmt> added test for the html5 progressbar element. </cmt> <cmt> tested in opera [9,10,11], firefox [3.6,4], safari 5, ie[7,8] and chrome [9,10,11] </cmt> <cmt> added test for the html5 meter element. </cmt> <cmt> tested in opera [9,10,11], safari 5, chrome 11, firefox [3.6, 4, 5] and msie 8. </cmt>",added tests for progressbar and meter-element.
455,"<desc> supports displaying filament sensor data on either a character 20x4 or graphical lcd.  because nearly all the lcd real-estate is taken the code uses the status area to display the data.  the status will display for 5 seconds, and then be replaced by the data display.  to see the status again, press the knob to select the menu again.  also, if the status message is updated, it will display for 5 sec.  a #define in the config file is used to enable the display. i also added some background explanation to the readme about the filament sensor input. </desc> <cmt> sync up from my marlin_v1 to filament-sensor </cmt> <cmt> display filament sensor data on 20x4 lcd </cmt> <cmt> changes to support displaying the real-time filament width and the </cmt> <cmt> volume factor on a 20x4 lcd.  the data is displayed on the 4th line. </cmt> <cmt> first the status message is displayed for 5 seconds, and then the </cmt> <cmt> filament data is displayed.  the status message can be seen by </cmt> <cmt> re-selecting the info screen in the menu. </cmt> <cmt> display filament sensor data on graphic lcd </cmt> <cmt> added support to show the filament width on the status line of the </cmt> <cmt> graphic lcd.  the status will show for 5 sec and then switch over to </cmt> <cmt> data.  status can be seen by clicking the button. </cmt> <cmt> added filament sensor to the readme </cmt> <cmt> added some background on the filament sensor to explain it better. </cmt>",display filament sensor data on a 20x4 lcd or graphical lcd
456,"<desc> fixes #74633 this was the indirect cause of  #74633. see that issue for an explaination of why it was problematic.  in summary, updating diagnostics can retrigger code actions even if the user facing diagnostics have not actually changed </desc> <cmt> don't update js/ts diagnostics if they have not changed </cmt> <cmt> fixes #74633 </cmt> <cmt> this was the indirect cause of  #74633. see that issue for an explaination of why it was problematic.  in summary, updating diagnostics can retrigger code actions even if the user facing diagnostics have not actually changed </cmt> <cmt> use every for equals </cmt> <cmt> use array prototype instead of creating instance </cmt> <iss> blinky lightbulb </iss>",don't update js ts diagnostics if they have not changed
457,"<desc> this pr changes nothing, it's a bug fix fixed debug draw of scaled circle body in arcade physics </desc> <cmt> fix debug draw of scaled arcade body </cmt> <cmt> forgot to devide width by 2 </cmt>",fix arcade circle debug draw
458,"<desc> similar to #65353 (which this pr should've been a part of), however in this case we didn't previously nest the tables when processing trait paths in impl block declarations. closes #65411 </desc> <cmt> save-analysis: nest tables when processing impl items </cmt> <cmt> save-analysis: add a relevant test case </cmt> <iss> -z save-analysis ice when processing impl under an fn item </iss>",nest tables when processing impl block definitions
459,"<desc> typo you, your </desc> <cmt> new page an title </cmt> <cmt> add in outline </cmt> <cmt> build tools </cmt> <cmt> node-install </cmt> <cmt> links and preamble </cmt> <cmt> debian too </cmt> <cmt> update gatsby-on-linux.md </cmt> <cmt> copy edits </cmt> <cmt> copy edits </cmt> <cmt> update gatsby-on-linux.md </cmt> <cmt> typo you, your </cmt> <cmt> update from upstream </cmt> <cmt> update from upstream </cmt> <cmt> typo you, your </cmt>",fix typo on linux docs page
460,"<desc> this pr fixes a pretty interesting bug with the ot internal state i observed twice. the boiler may perform a restart. this might happen because of the power blip, internal watchdog reset, or software bug/feature. ot integration sees this as a timeout, and transitions to the otc_disconnected state and reconnect. on reconnect, ot integration does not send all parameters, such as boiler setpoint or dhw temperature. in my case, this leads to the default dhw temperature and a condition when the boiler is unable to start by the ot_ch 1 or by the heat request signal from the mechanical thermostat. this pr adds a reset logic of the internal state before the handshake. that way all the parameters will be queued for sending after the boiler reset. the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> reset ot protocol internal state on handshake </cmt> <cmt> reset current command pointer </cmt>",reset internal state on handshake
461,"<desc> stubs notifymountaddoncontent, notifyunmountaddoncontent and checkaddoncontentmountstatus used by animal crossing: new horizons v2.0.0 dlc </desc> <cmt> service: aoc: stub notifymountaddoncontent and notifymountaddoncontent </cmt> <cmt> used by animal crossing: new horizons v2.0.0 dlc </cmt> <cmt> service: aoc: stub notifyunmountaddoncontent </cmt> <cmt> used by animal crossing: new horizons v2.0.0 dlc </cmt>",aoc: stub more 13.x functions used by animal crossing
462,"<desc> nio exposed an issue in the new availability walkers where an implicit check was not being performed. they were able to get this to crash by using a defer statement - the body of which contains implicit declarations that got run through the walker. this exposed a wider hole in availability checking of defer statements. namely, that it wasn't happening. this is a narrow fix (as opposed to the broader fix in #36102) that is safer to take for swift 5.4. rdar://74484150 </desc> <cmt> revert ""fix a family of crashers in availability checking"" </cmt> <cmt> this reverts commit ae711a7e7628f0309ca1eeb7f4be1655c3f2ad9f. </cmt> <cmt> fix a crash in availability checking of defer bodies </cmt> <cmt> nio exposed an issue in the new availability walkers where an implicit </cmt> <cmt> check was not being performed. they were able to get this to crash by </cmt> <cmt> using a defer statement - the body of which contains implicit </cmt> <cmt> declarations that got run through the walker. this exposed a wider hole </cmt> <cmt> in availability checking of defer statements. namely, that it wasn't </cmt> <cmt> happening. </cmt> <cmt> this is a narrow fix (as opposed to the broader fix in </cmt> <cmt>  </cmt> <cmt> swift 5.4. </cmt> <cmt> rdar://74484150 </cmt>",narrowly fix a crash in availability checking of defer bodies
463,"<desc> this error is similar to eacces, and is thrown when the tool tries to delete a directory that it does not have permissions for. reuse the existing errror message with minor modifications. </desc> <cmt> add eperm to list of immediate exit error codes </cmt> <cmt> remvove extra mocks </cmt>",add eperm to set of immediate exit errors
464,"<desc> adds option for prometheus compatible metric exports in all pods under the mongodb-replicaset chart fixes some broken tls chart functionality and allows the metrics exporter to use tls options which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # first pr into kubernetes/charts </desc> <cmt> replicaset prometheus metrics export </cmt> <cmt> bugfix: fix tls issues </cmt> <cmt> 1. moves context of ssl configuration script into /work-dir </cmt> <cmt> where certain files are expected to be created. </cmt> <cmt> 2. specifies the --sslmode=requiressl flag on the container command when using tls </cmt> <cmt> as specified by mongo docs. </cmt> <cmt>  </cmt> <cmt> documentation on metrics options </cmt>",add prometheus exports to mongodb replicaset
465,"<desc> cherrypick the change( #53604) to add no-negcache flag to dnsmasq which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): release note: add --no-negcache flag to kube-dns to prevent caching of nxdomain responses. </desc> <cmt> add no-negcache flag to kube-dns in kubeadm </cmt> <cmt> add no-negcache flag to kube-dns </cmt>",cherrypick pr#53604 to 1.8
466,"<desc> issued #82 caused me to rethink how atom defines words. the config option editor.nonwordcharacters now determines words. i found it easier to understand and describe what is not a word rather than what is a word. this also changes atom's word movement behavior to match vim's instead of textmates, because i think vim has a better mechanic. </desc> <cmt> editor.wordregex is now a config option. </cmt> <cmt> cursor.getbeginningofcurrentwordbufferposition behaves like vim </cmt> <cmt> make cursor.movecursortobeginningofword behave like vim </cmt> <cmt> selection.selectword will consider whitespace a word </cmt> <cmt> make editsession specs match vim style word behavior </cmt> <cmt> rename wordseparators to nonwordcharacters </cmt> <cmt> :lipstick: </cmt> <cmt> _ and - both considered non word characters. fixes #82 </cmt> <cmt> maybe @defunkt wanted the reverse though (consider _ and - word characters)? either way, it's a config option you can change now. </cmt>",change how atom defines a 'word'
467,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the first argument of the callback function might be an htmlimageelement. see:  there might be a second argument of the callback function providing the image metadata. see:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> extended loadimagecallback with metadata argument. </cmt> <cmt> lint. </cmt> <cmt> extended unit test. </cmt> <cmt> cleanup test. </cmt>",enhanced load image callback with metadata argument
468,"<desc> in attempting to use the fakeclient, it seemed that the api group and version was not correct everywhere.  these changes made it so that the generated code for the fake client was usable for flowcontrol. </desc> <cmt> update api/flowcontrol/v1alpha1 to have correct group and version </cmt> <cmt> update generated code </cmt>",update flowcontrol to have correct group and version everywhere
469,"<desc> this is an aggregate table who's function is to provide a simple place to query all of the known auto-executing programs on a system. it's kept very simple: just name, path and the source table. the goal here is to allow system administrators to get a list of all auto-executing executables on a system with one query, and then use that data to e.g. join with file hashes to check for known malicious files, or to run analysis on to detect outliers or large changes across a fleet. any time a new table is added to osquery for windows that contains auto-executing items, the kautoexectablemappings can be updated to include entries from that table in this one. the goal is for this table to keep growing as we add more windows tables, for example browser extensions. </desc> <cmt> adding autoexec table </cmt> <cmt> adding impl </cmt>",adding autoexec table for windows
470,<cmt> cube/char_bigrams: fix some memory leaks </cmt> <cmt> coverity report: </cmt> <cmt> cid 1164717 (#1 of 1): resource leak (resource_leak) </cmt> <cmt> 10. leaked_storage: variable upper_32 going out of scope leaks </cmt> <cmt> the storage it points to. </cmt> <cmt> cid 1164718 (#1 of 1): resource leak (resource_leak) </cmt> <cmt> 10. leaked_storage: variable lower_32 going out of scope leaks </cmt> <cmt> the storage it points to. </cmt> <cmt> cube/char_samp: fix some memory leaks </cmt> <cmt> coverity report: </cmt> <cmt> cid 1164722 (#9 of 9): resource leak (resource_leak) </cmt> <cmt> 20. leaked_storage: variable label32 going out of scope leaks the storage </cmt> <cmt> it points to. </cmt>,fix issues reported by coverity scan
471,"<desc> a bunch  of small code optimizations and trying to reduce header dependencies by using forward declarations. some important includes were missing, which was found by other changes not part of this pr (those will be submitted soon as well). why is this change required? -> not required, but nice to have. kodi has been running with these commits for two days (using gbm on intel nuc). bug fix (non-breaking change which fixes an issue) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document (i couldn't yet figure out how to run the tests. all tests fail, even without my commits and i have no idea why.) </desc> <cmt> guilib/guimessage: make the class ""final"" </cmt> <cmt> nobody derives from this class.  this removes some overhead and </cmt> <cmt> clarifies the role of this class. </cmt> <cmt> guilib/guimessage: don't override copy constructor/operator </cmt> <cmt> the implementations auto-generated by the c++ compiler are better than </cmt> <cmt> that and less fragile. </cmt> <cmt> guilib/guibasecontainer: use std::list for cguilistitemlayout </cmt> <cmt> this reduces the overhead, because resizing the std::vector will </cmt> <cmt> create lots of temporary cguilistitemlayout copies.  a std::list never </cmt> <cmt> needs to move its items. </cmt> <cmt> these lists are very small, so the overhead for iterating it is </cmt> <cmt> negligible, but copying a cguilistitemlayout (which is not movable) is </cmt> <cmt> very expensive because a rather large tree of objects needs to be </cmt> <cmt> copied. </cmt> <cmt> guilib/guibasecontainer: forward-declare class cguilistitemlayout </cmt> <cmt> reduce header dependencies and speed up the build. </cmt> <cmt> guilib/guilistitemlayout: make ""final"" </cmt> <cmt> nobody derives from this class, and most instances are managed in a </cmt> <cmt> stl container, where polymorphism is impossible.  this removes some </cmt> <cmt> overhead and clarifies the role of this class. </cmt> <cmt> guilib/guilistgroup: make class ""final"" </cmt> <cmt> eliminate some overhead because this is a leaf class. </cmt> <cmt> guilib/guicontrol: use forward declarations </cmt> <cmt> reduce header dependencies and speed up the build. </cmt> <cmt> guilib/guicontrol: use emplace_back() instead of push_back() </cmt> <cmt> eliminate temporary instance. </cmt> <cmt> guilib/guivisualisationcontrol: add missing includes </cmt>",various guilib optimizations and include cleanup
472,"<desc> this commit adds some clean up logic to esresttestcase so that searchable snapshots indices are deleted after test case executions, before the snapshot and repositories are wipe out. backport of #73555 </desc> <cmt> [7.x] delete mounted indices after in searchable snapshots yaml tests </cmt> <cmt> revert ""[7.x] delete mounted indices after in searchable snapshots yaml tests"" </cmt> <cmt> this reverts commit 885b187685ee39da9aae0d22619f51792aee8467. </cmt> <cmt> add wipesearchablesnapshotsindices </cmt> <cmt> adjust version </cmt> <cmt> of course </cmt> <cmt> found the culprit </cmt> <cmt> ifs </cmt>",delete mounted indices after test case in esresttestcase
473,"<desc> empty .gitignore files have been added for no reason, and we lost some empty but useful directories (read: ""that will be used later on"") during the git migration. </desc> <cmt> remove unwanted .gitignore files. </cmt> <cmt> add .keep guard files in order to restore lost but empty directories we had with svn. </cmt> <cmt> note that when you start populating these directories, you can remove the associated .keep guard file(s)! </cmt>",fix svn to git migration
474,"<desc> closes #23865 closes #27075 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff new tests addeded #23865 #27075 both reported that when df.groupby was called and by was set to more than one pd.categorical column, that any missing categories were not returned, even when observed=false. this issue was fixed in #29690. this pull request adds tests to make sure that this correct behaviour is enforced by tests. new bug found testing did reveal one further issue: dataframegroupby.count() returns nan for missing categories, when it should return a count of 0.  seriesgroupby.count() does return 0, which is the expected behaviour. i have raised an issue for this bug (#35028 ) and marked the test with an xfail. when the bug is fixed, the xfail will cause the tests to fail, and the xfail can be removed. existing test changed as it had the wrong expected result a similar issue was reported for .sum() in #31422: missing categories return a sum of nan when they should return a sum of 0. there was a mistake on the existing test for seriesgroupby.sum(), as it said the expected output was nan (see below) when it should have been 0. pandas/pandas/tests/groupby/test_categorical.py line 1315 0159cba (""sum"", np.nan), i have changed this so that the expected output is 0 (this is inline with the comment here: #31422 (comment) ) and marked the tests for .sum() with xfail. when the bug is addressed, the xfail will cause the tests to fail, and the xfails can be removed. </desc> <cmt> tests for dataframe.groupby with 2 categoricals </cmt> <cmt> black </cmt> <iss> inconsistant behaviour of empty groups when grouping with one vs. many </iss> <iss> groupby ignores unobserved combinations when passing more than one categorical column even if observed=true </iss>",add test to ensure that df.groupby() returns the missing categories when grouping on 2 pd.categoricals
475,"<desc> refactor renaming leftovers: ""data frame transform"" to ""transforms"", touch only internals (variable names, non-public api's, doc strings, ...) and apply code-formatting (spotless). no logical changes. </desc> <cmt> rename leftovers from data frame transforms to transforms </cmt> <cmt> apply code formatting </cmt>",refactor naming leftovers and apply code formating
476,"<desc> reapply 5b35750, which was reviewed in #12700 artificially pin the linter package at 0.1.35 due to dart-lang/linter#824 (see yjbanov@50a4cf5) </desc> <cmt> revert ""revert ""fix --force-upgrade script; upgrade to the latest package versions (#12700)"" (#12729)"" </cmt> <cmt> this reverts commit 7f0d4f4caae30d20670a8f3272fa1c70170ace8a. </cmt> <cmt> keep linter pinned at 0.1.35 </cmt>",reapply #12700 but keep linter pinned at 0.1.35
477,"<desc> # app ### event: 'certificate-error' returns: * event event * webcontents [webcontents](web-contents.md) * url url * error string - the error code * certificate object * data buffer - pem encoded data * issuername string * callback function emitted when failed to verify the certificate for url, to trust the certificate you should prevent the default behavior with event.preventdefault() and call callback(true). # session ### session.setcertificateverifyproc(proc) * proc function sets the certificate verify proc for session, the proc will be called with proc(hostname, certificate, callback) whenever a server certificate verification is requested. calling callback(true) accepts the certificate, calling callback(false) rejects it. calling setcertificateverifyproc(null) will revert back to default certificate verify proc. close #3330. </desc> <cmt> add delegate for atombrowserclient </cmt> <cmt> rename select-certificate to select-client-certificate </cmt> <cmt> add certificate-error event </cmt> <cmt> add session.setcertificateverifyproc </cmt> <cmt> docs: update the certificate apis </cmt>",rework of the certificate api
478,<desc> this pull request will fix #5785. add a file_identifier that i forgot to include use t.finishtbuffer() for each class instead of flatbuffersbuilder.finish(). and add a test to ensure that the file_identifier exists. </desc> <cmt> use finish***buffer instead. </cmt> <cmt> add file_identifier test. </cmt>,add file identifier to objectapi serialization utility.
479,"<desc> since we're adding another target that i believe will require more customization in the future and i think our strategy of just using sed was getting too messy, i've added a new preprocessor which tries to follow the ff preprocessor( also, i added a new build target generic which builds the generic production version of pdf.js.  this is basically the contents of our old web build target.  i mainly did this because now the file build/pdf.js is not preprocessed since it needs to be preprocessed differently by each main build target. for testing, i built all the targets and compared them to the current build output.  everything still needs verification though. </desc> <cmt> initial build for b2g. </cmt> <cmt> add the new preprocessor. </cmt> <cmt> update the readme to reflect build changes. </cmt> <cmt> remove trailing whitespace. </cmt> <cmt> fix mozcentral build. </cmt>",add b2g build and new preprocessor.
480,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation this is pretty minor, but just something i noticed while looking around. since superset uses fontawesome, we can replace a custom component with custom svg by using a simple fontawesome image. we should probably upgrade to fontawesome 5 at some point... many more toys in that toybox! before: after: reviewers @graceguo-supercat / @mistercrunch note: this doesn't change any functionality, but as far as i can tell, that button doesn't have functionality in the first place, or at least nothing happens when i click it. is it for future use, or am i missing something? </desc> <cmt> replaced! </cmt> <cmt> added role to the fa image/button </cmt>",filter edit icon component replaced with font awesome
481,"<desc> the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. add it to notneededpackages.json. </desc> <cmt> fixed ""text"" type in iinstruction </cmt> <cmt> i don't believe that the text property should be a number, and when i changed it to a string in a personal project it worked perfectly. </cmt> <cmt> [@types/leaflet-routing-machine] fixed ""text"" type in iinstruction interface. </cmt> <cmt> merge </cmt> <cmt> added 3.2.12 version compatibility </cmt> <cmt> fixed typing bugs </cmt> <cmt> lint errors are fixed </cmt> <cmt> typescript support version is upgraded </cmt>",brings the type definition up to date with its js library version 3.2.12
482,"<desc> original pull-request #25045 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix </cmt> <cmt> better way </cmt> <cmt> odbc fix </cmt>",cherry pick #25045 to 21.5: odbc fix
483,"<desc> #75570 identified that %#v can be expensive, and more specific formatters can be easier to debug in some cases. adjust some relatively core errors to use %t or %s instead. </desc> <cmt> avoid using %#v for errors when using only a portion of the object </cmt> <cmt> %#v may have significant performance costs in frequently invoked code. </cmt> <cmt> avoid using %#v for errors when %t is clearer </cmt> <cmt> %#v may have significant performance costs in frequently invoked code. </cmt> <cmt> avoid using %#v for errors when %t or %s would be more accurate </cmt> <cmt> %#v may have significant performance costs in frequently invoked code. </cmt> <cmt> avoid using %#v for errors when %t is more informative </cmt> <cmt> %#v may have significant performance costs in frequently invoked code. </cmt>",remove use of %#v in frequently accessed code
484,<desc> this pr fixes the long-running tests by making the bootstrapping process in the python test scripts use eosio rather than eosio.token as the issuer in order to avoid an inline transfer during issue which would fail when the restrict_action_to_self protocol feature is activated. also the bios contract has been updated to reflect the latest changes in the eosio/eosio.contracts#220 pr which rename the action to pre-activate a protocol feature from preactivate to activate. the rename required changes to unit test and python test frameworks as well as the protocol_feature_tests/double_preactivation unit test. </desc> <cmt> fix long-running tests given restrict_action_to_self protocol feature changes </cmt> <cmt> use updated bios contract that renames preactivate action to activate; adjust tests and testing utilities accordingly </cmt>,fix tests in forced-replay branch; use updated bios contract
485,"<desc> this pr sets up a common project for preview pane powertoy. the common project would include interface and com object required to write a preview pane handlers. pr checklist applies to #914 cla signed. if not, go over here and sign the cla additional comments added stylecop.json from /src/codeanalysis/stylecop.jsonto common project </desc> <cmt> added project template for common library </cmt> <cmt> added reference to stylecop.json </cmt> <cmt> fixed xml documetation file path for common project </cmt> <cmt> added reference to stylecop.json </cmt>",setup common project preview pane
486,<desc> issue: #542 #549 #739 description: implement use_container_width in charts and deprecate height and width properties with a warning </desc> <cmt> first implementation for vega_lite charts </cmt> <cmt> implement use_container_width to other charts </cmt> <cmt> implement use_container_width in all charts </cmt> <cmt> fix tests </cmt> <cmt> restore examples </cmt>,improve sizes handling for charts
487,"<desc> pr intends to add support for higher order gradient for logp1, expm1, square. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira-978 issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change higher order gradient for a logp1, expm1, square. unit test for the same. </desc> <cmt> support logp1, expm1, square for higher order grad </cmt> <cmt> add relevant tests </cmt>","higher order gradient support logp1, expm1, square."
488,"<desc> currently, if a postgres table contains a record with a binary field and this record is fetched from the db, an exception is raised if the binary data is nil. this bug is due to the fact that the unescaping of the column value is passed directly to pgconn without checking for nil. pgconn#unescape_bytea does a check on the value type and raise an exception if the value isn't a string. this pr adds tests around the binary type (currently no tests exist), and a fix for the mentioned bug. </desc> <cmt> added a test suite for the postgres binary type </cmt> <cmt> this shows a problem with nil values </cmt> <cmt> fix for the bytea/binary nil value bug </cmt>",ar postgres binary bug fix
489,"<desc> when i first read the output, i spent a lot of time to understand these numbers to match them. now, words along with the ids clearly show what's going on in the sample data and prediction pairs. sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] 3084 originated -> 12 as 3084 originated -> 5239 anarchism 12 as -> 6 a 12 as -> 3084 originated 6 a -> 12 as 6 a -> 195 term 195 term -> 6 a 195 term -> 2 of sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] 3084 -> 5239 originated -> anarchism 3084 -> 12 originated -> as 12 -> 3084 as -> originated 12 -> 6 as -> a 6 -> 195 a -> term 6 -> 12 a -> as 195 -> 6 term -> a 195 -> 2 term -> of </desc> <cmt> added words to clearly show word ids and corresponding words together. </cmt> <cmt> now, they clearly show  what's going on in the sample data and prediction pairs. </cmt> <cmt> [new output]: clearly shows the word ids and corresponding words </cmt> <cmt> sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] </cmt> <cmt> 3084 originated -> 12 as </cmt> <cmt> 3084 originated -> 5239 anarchism </cmt> <cmt> 12 as -> 6 a </cmt> <cmt> 12 as -> 3084 originated </cmt> <cmt> 6 a -> 12 as </cmt> <cmt> 6 a -> 195 term </cmt> <cmt> 195 term -> 6 a </cmt> <cmt> 195 term -> 2 of </cmt> <cmt> [old output]: no words for sample data. word ids and words are mixed, so it's very hard to read </cmt> <cmt> sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] </cmt> <cmt> 3084 -> 5239 </cmt> <cmt> originated -> anarchism </cmt> <cmt> 3084 -> 12 </cmt> <cmt> originated -> as </cmt> <cmt> 12 -> 3084 </cmt> <cmt> as -> originated </cmt> <cmt> 12 -> 6 </cmt> <cmt> as -> a </cmt> <cmt> 6 -> 195 </cmt> <cmt> a -> term </cmt> <cmt> 6 -> 12 </cmt> <cmt> a -> as </cmt> <cmt> 195 -> 6 </cmt> <cmt> term -> a </cmt> <cmt> 195 -> 2 </cmt> <cmt> term -> of </cmt> <cmt> changed it to two space </cmt>",word2vec basic show id and word together
490,"<desc> fixes #8688. see also #8700 (should be closed). in feature_extraction (.text) module there's no validation of ngram_range property for the following vectorizers : class hashingvectorizer(baseestimator, vectorizermixin, transformermixin) class countvectorizer(baseestimator, vectorizermixin) class tfidfvectorizer(countvectorizer) for example we can init a vectorizer that extracts n-grams in this range: 2 >= n >= 1, which doesn't make sense. following @jnothman guidelines on #8688 i added a private function in vectorizermixin and called it on relevant fit/transform functions of hashingvectorizer and countvectorizer (tfidf implements same fit/transform), tested all of the three. the function vectorizermixin.build_analyzer() is the one relying on ngram_range. call to it can be found in hashingvectorizer.transform() and on countvectorizer.fit_transform()/transform() which also uses vectorizermixin.build_analyzer()  through countvectorizer._count_vocab() </desc> <cmt> added test for vectorizers invalid ngram_range </cmt> <cmt> added ngram_range validation for countvectorizer and hashingvectorizer fit/transform funcs </cmt> <cmt> moved validation call on countvectorizer.transform to be earlier </cmt> <cmt> fixed pep8 warnings </cmt> <iss> no error on countvectorizer(ngram_range=(2, 1)) </iss>",fix validation of ngram_range property in vectorizers
491,<desc> some key codes were forgotten. most of this happened in firefox browser. they included some alphabet letters in persian and arabic. the key codes are as follow: semicolon_firefox: 59 colon: 58 comma_firefox_windows: 60 comma_firefox: 62 bracket_right_firefox: 174 bracket_left_firefox: 175 </desc> <cmt> + forgotten keycode (firefox) </cmt> <cmt> + add forgotten keycode (firefox in windows) </cmt>,add forgotten keycode and letters
492,<desc> games that use the depth test will most likely draw a black screen until depth clearing is implemented. see #609 </desc> <cmt> gpu: implemented the z24s8 depth format and load the depth framebuffer. </cmt> <cmt> gpu: added registers for depth test and cull mode. </cmt> <cmt> maxwelltogl: added conversion functions for depth test and cull mode. </cmt> <cmt> gpu: set up the depth test state on every draw. </cmt>,implemented the depth buffer and depth test + culling
493,<desc> we currently put all tooltips in a textblock which is unnecessary and moreover breaks word wrapping logic fixes #5625 microsoft reviewers: open in codeflow </desc> <cmt> use string object for tooltips instead of textblocks since that breaks wordwrap etc </cmt> <cmt> change files </cmt> <iss> rnw implementation of tooltips causes text truncation </iss>,fix word-wrapping behavior of tooltips
494,<desc> adds support for cv_32fc1 and cv_32fc4 to cuda morphology filter. this mostly extends exiting cv_8u implementation. thanks. </desc> <cmt> implement 32f support for morphology operation </cmt> <cmt> update docs for 32f support in morphology operation </cmt>,cv_32fc1 and cv_32fc4 support for cuda morphology filter
495,<desc> i hereby agree to the terms of the cla available at:  changelog category: </desc> <cmt> print correct error message in log for unknown settings in users.xml </cmt> <cmt> add test for custom settings in users.xml </cmt>,correct error message if setting not found in users.xml
496,"<desc> closes #13865 menulist now supports the use of home and end keys, changing focus to the first and last listitem. i have followed (at least) the pr section of the contributing guide. </desc> <cmt> add home and end keys to be handled in meathod handlekeydown </cmt> <cmt> added support for home and end keys in menulist </cmt> <cmt> added two tests for menulist home and end key functionality </cmt>",add home and end key support
497,"<desc> stash application should stage new files, even when we're not updating the index. c:\temp\stash_apply_sucks>git status on branch master changes to be committed: (use ""git reset head <file>..."" to unstage) new file:   bar modified:   foo c:\temp\stash_apply_sucks>git stash saved working directory and index state wip on master: 4a6df6d foo head is now at 4a6df6d foo c:\temp\stash_apply_sucks>git status on branch master nothing to commit, working directory clean c:\temp\stash_apply_sucks>git stash apply on branch master changes to be committed: (use ""git reset head <file>..."" to unstage) new file:   bar changes not staged for commit: (use ""git add <file>..."" to update what will be committed) (use ""git checkout -- <file>..."" to discard changes in working directory) modified:   foo what a sensible architecture this is.  so we need to do the same thing.  we break the actual iterator walking code out of merge to create a new index that has just the new files, which we will set as the new repo's index (unless the user actually specified that they wanted to restore the index). </desc> <cmt> stash apply: add a newly staged file to tests </cmt> <cmt> stash: don't allow apply with staged changes </cmt> <cmt> iterator: provide git_iterator_walk </cmt> <cmt> provide git_iterator_walk to walk each iterator in lockstep, </cmt> <cmt> returning each iterator's idea of the contents of the next path. </cmt> <cmt> stash: stage new files when unstashing them </cmt> <cmt> files that were new (staged additions) in the stash tree should </cmt> <cmt> be staged when unstashing, even when not applying the index. </cmt>",stage new files even when not updating the index
498,<desc> fixes #1640 you can now change the entire data object of the chart and then call update and the chart will work. the line sample has been update to test this behaviour. note to whomever reviews this: please test all chart types before merging. </desc> <cmt> reference data from the main controller wherever possible. updated tests to account for this. </cmt> <cmt> update line sample to change the entire data object </cmt>,can now replace entire chart data object on the fly
499,"<desc> bug fixes apis added type and value checks for parameter ""shape"" in static graph, when passing ""shape"" to function ""fill_constant()"". bugs are described as below: </desc> <cmt> fixed bugs </cmt> <cmt> fixed bugs </cmt> <cmt> some modifications have been made in branch junhui_dev, now i have to update from upstream develop before push </cmt>",fixed bugs for 2.0 api
500,"<desc> this moves the rollup cleanup code for http tests from the high level rest client into the test framework and then entirely removes the rollup cleanup code for http tests that lived in x-pack. this is nice because it consolidates the cleanup into one spot, automatically invokes the cleanup without the test having to know that it is ""about rollup"", and should allow us to run the rollup docs tests. part of #34530 </desc> <cmt> wip </cmt> <cmt> fix position </cmt> <cmt> rework </cmt> <cmt> preserve rollup jobs more places </cmt> <cmt> fixup </cmt>",consolidate rollup cleanup for http tests
501,<desc> this change refactors the goroutine filter parsing from the terminal package into service/api so it can be shared by the terminal client and the dap server. this supports setting goroutine filters using the launch configuration. </desc> <cmt> service/dap: filter goroutines </cmt> <cmt> adjust defaults </cmt> <cmt> add tests </cmt> <cmt> remove label change </cmt>,support goroutine filters in dap
502,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #38772 upon first doing this challenge the test messages did not indicate the specified string was not matching. this small modification is to redirect the user to carefully compare their string with those indicated in the instructions. </desc> <cmt> changed tests messages to indicate string </cmt> <cmt> minor tweak with wording of message </cmt> <iss> test error message does not indicate wrong string </iss>",fix/curriculum en es6 complete a promise - modified test messages to be more clearer
503,<desc> since the multi-root workspace file contains settings/launch configs we need to factor it in workspace trust: factor in the directory storing the workspace file into calculating workspace trust set workspace trust when saving the workspace file if the folders are trusted </desc> <cmt> do not check untitled workspace files </cmt> <cmt> trust folder when saving workspace file </cmt> <cmt> trust folder when saving workspace file </cmt> <cmt> fix merge conflict </cmt>,workspace trust - multi-root workspace file
504,"<desc> this applies similar fixes to those in #5133 to the rest of the ui forms after #5133 and this pr are merged, all ui forms in the project should now open in qt creator/designer and resave without any entries being shuffled around or clobbered before this change, the changed qwidgets in the form files are not properly shown in qt creator, only their associated layouts are displayed and their qwidget properties are not accessible or shown. these widgets will also get completely removed upon saving. after these changes, the items are properly listed in the qt creator hierarchy. qt creator/designer is the primary method for building ui forms and all our form files should open and save without creating unnecessary history changes all forms have been compared against v27.0.1 to ensure they still get laid out the same at various sizes code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> ui: clean up settings form markup </cmt> <cmt> this continues work from #5133 to correct ui file markup and save correctly in qt creator </cmt> <cmt> defining alignment as an attribute in the <item> tag seems to be old behaviour that current versions of qt creator do not respect and will clobber these entries on save. </cmt> <cmt> the correct approach is to have alignment as a property element in the widget. </cmt> <cmt> as well, qwidgets that contain property definitions as well as a layout child item do not properly show up in the qt creator hierarchy. </cmt> <cmt> these properties are still invisibly applied but the qwidgets are not shown in qt creator and will get removed from the file after saving. </cmt> <cmt> ui: clean up toolbar form markup </cmt> <cmt> ui: clean up autoconfig form markup </cmt> <cmt> ui: clean up about form markup </cmt> <cmt> ui: clean up filters form markup </cmt> <cmt> fixes some qwidgets that qt creator tries to clobber. as a result, there are a couple spacers added now for the toolbars to align properly and a stretch policy on the main layout. </cmt> <cmt> this re-adds the native attribute for the obsqtdisplay that was removed in #3782. i believe this particular removal was an error, and there is no way around this entry being native since obsqtdisplay extends qwidget </cmt> <cmt> ui: clean up interact form markup </cmt> <cmt> this re-adds the native attribute for the obsqtdisplay that was removed in #3782. i believe this particular removal was an error, and there is no way around this entry being native since obsqtdisplay extends qwidget </cmt> <cmt> ui: clean up transform form markup </cmt> <cmt> fixes some qwidgets that qt creator tries to clobber. as a result, there is a new spacer added now to ensure the controls remain grouped at the top of the window. </cmt> <cmt> ui: clean up custom browser docks form markup </cmt> <cmt> minor alphabetical rearrange by qt creator </cmt> <cmt> ui: clean up importer form markup </cmt> <cmt> minor alphabetical rearrange by qt creator </cmt> <cmt> ui: clean up missing files form markup </cmt> <cmt> minor alphabetical rearrange by qt creator </cmt> <cmt> ui: clean up remux form markup </cmt> <cmt> minor alphabetical rearrange by qt creator </cmt> <cmt> ui: clean up update form markup </cmt> <cmt> small whitespace fix </cmt>",clean up other ui form file markup
505,<desc> when i was reading the online readme i missed this syntax cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc due to it being preceded by the note. i've rearranged the instructions for clarity. thanks for all that you do! </desc> <cmt> improve formatting of step 2 for clarity </cmt> <cmt> make the note an optional for improved instructions </cmt>,modify readme to clarify the manual way
506,"<desc> add comments documenting set_axis_is_at_home and homeaxis output ""a"" and ""b"" for scara axes in stepper::report_positions improve probe position output in log_machine_info use const args in set_current_from_steppers_for_axis and probe_pt specify 8-bit integers for extrapolate_one_point args other minor comment/spacing adjustments </desc> <cmt> document set_axis_is_at_home </cmt> <cmt> document homeaxis </cmt> <cmt> patch sync_plan_position comment </cmt> <cmt> stepper::report_positions patch </cmt> <cmt> set_current_from_steppers_for_axis const arg </cmt> <cmt> fix nozzle position description </cmt> <cmt> tweak extrapolate_one_point </cmt> <cmt> adjust comments, spacing </cmt> <cmt> use const ref args in probe_pt </cmt>","some comments, const args, debug output tweaks"
507,<desc> references #14216. this finalizes the work on pr #19375 replaces the use of assert_raises* with pytest.raises in model_selection/tests/test_split.py #dataumbrella cc: (pair programming partner) @cycks </desc> <cmt> replace assert_raises* by pytest.raise in model_selection/tests/test_split </cmt> <cmt> ensure line 1391 and 1399 in the previous commit are not longer than 79 characters </cmt> <cmt> tst use correct indenting style in test_split.py </cmt>,tst replaces assert_raises* by pytest.raises in model_selection/tests/test_split.py
508,"<desc> link to jira issue:  description above provides context of the change commit message starts with [airflow-6430], where airflow-nnnn = jira id* unit tests coverage for changes (not needed for documentation changes) commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. (*) for document-only changes, no jira issue is needed. commit message starts [airflow-xxxx]. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> [airflow-6430] - add tests for patch_table method </cmt> <cmt> [airflow-6430] - add tests for run_extract method </cmt> <cmt> [airflow-6430] - add tests for get_tabledata method </cmt> <cmt> [airflow-6430] - add tests for run_table_delete method </cmt> <cmt> [airflow-6430] - add tests for run_table_upsert method </cmt> <cmt> [airflow-6430] - add tests for run_grant_dataset_view_access method </cmt> <cmt> [airflow-6430] - add tests for get_dataset_tables_list method </cmt>",bigquery hook - add tests for bigquerybasecursor
509,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> update index.d.ts </cmt> <cmt> add missing functions to definition </cmt> <cmt> add missing validation functions to definition and tests. </cmt> <cmt> update json-schema-tests.ts </cmt> <cmt> fix spaces </cmt>,add missing functions to json-schema definition
510,"<desc> the current code mix two different naming convention to define the name of the interface and class, which looks strange. this pr proposes to use ""taskassigner"" as the interface name and ""taskassignerimpl"" as the implementation class name. all relevant variable names have been renamed appropriately. </desc> <cmt> merge ray master </cmt> <cmt> rename interface and class for task assigner based on suitable pattern. </cmt>",rename the interface and class for task assigner based on suitable naming convention
511,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> finished accessibilityfeatures </cmt> <cmt> removed old declaration for extensions only according to the docs </cmt> <cmt> updated definitions of chrome.runtime </cmt> <cmt> updated chrome.app.window typings </cmt> <cmt> added missing docs to chrome.bluetooth </cmt> <cmt> chrome.bluetoothlowenergy wip </cmt> <cmt> added missing typings in chrome.filesystem </cmt> <cmt> relocate webview methods </cmt> <cmt> webview typings fixed and doc updates. tests updated. </cmt> <cmt> set added types under window to optional </cmt> <cmt> updated typings on some objects </cmt>",refined and more proper webview element types
512,"<desc> extension of #228. clarifies some of the language. allows for """"""\ as opening delimiter for multi-line basic strings. renames ""raw string"" to ""literal string"". </desc> <cmt> add multiline and raw strings to toml. </cmt> <cmt> refine spec for the four string variants. </cmt>",add mult-line and literal strings
513,"<desc> @rafaelks here are a few additions for the mobile apps. once you find out more information regarding the oauth items i will start working on getting them added. closes #7775 4f3c9d4 closes #7765 fb04102 closes #7764 fb04102 closes #7763 ae87222 /api/v1/channels.messages?roomid=general&query={ ""pinned"": true } closes #7762 ae87222 /api/v1/channels.messages?roomid=general&query={ ""starred._id"": { ""$in"": [""${userid}""] } } closes #7761 1914d7a closes #7760 25792e6 closes #7770 ae3f821 closes #7241 ae3f821 closes #7262 ae87222 in addition to the items above, direct message endpoints no longer require a user to know the room's id. instead you can now pass the query parameter username to the endpoints and it will assume you mean a direct message conversation between the authenticated user and the username provided. </desc> <cmt> add the channels/groups/im.files endpoint </cmt> <cmt> add a messages endpoint which supports pagination like the other endpoints. rework the direct messages endpoints to support username instead of room id </cmt> <cmt> allow pinning, unpinning, starring, and unstarring via the rest api </cmt> <cmt> fix #7775, return the unread properties </cmt> <cmt> add rest api endpoints to list members in a channel </cmt> <cmt> fix a few issues related to the integrations. </cmt> <cmt> 1. process_incoming_request can now return falsey (null, undefined, 0, false, etc) and nothing will be sent to the channel </cmt> <cmt> 2. integrations can post messages to channels without the user being in them (direct messages, etc) </cmt> <cmt> 3. users can't brute force check if a room exists by successfully sending a message there </cmt> <iss> [bug] posting messages via api as non member to private rooms or read only channels </iss> <iss> cannot create direct message room via api </iss> <iss> [rest api] members list </iss> <iss> [rest api] files list </iss> <iss> [rest api] starred messages list </iss> <iss> [rest api] pinned messages list </iss> <iss> [rest api] star a message </iss> <iss> [rest api] pin a message </iss> <iss> webhook: process_incoming_request: unable to skip/ignore requests without error (400) (#7374 re-open) </iss> <iss> get unread message via rest api for rocket.chat </iss>",additions to the rest api
514,<desc> continues work on #3283 </desc> <cmt> adjusts inline text state presentation for a11y </cmt> <cmt> adjusts specificity of main content links </cmt> <cmt> adjusts blockquote color scheme </cmt> <cmt> temporarily unhides catastrophic css overrides </cmt> <cmt> reverts text-decoration add </cmt> <cmt> makes hash-link always visible </cmt> <cmt> adds underline for topnav hover/focus/active </cmt>,docs rebuild - improves accessibility of topnav links and hash links
515,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> removing prompt verbage from selection binding options </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> adding a link to the search options article </cmt>",adding a link to the word search options details page
516,"<desc> this commit series essentially brings back dvb channel switching. basically, the commit messages contain everything, and i tried to be mostly atomic in my commits, but here a short summary (which sadly got almost as long as the summary of the commit messages): some refactoring to allow checking options for updates as suggested by @wm4 in #6781 . this also cleaned up the option mess in stream_dvb by finally keeping them cleanly in a separate struct. more refactoring, since stream_dvb accepts some configuration via the stream-uri and also via config parameters. now, the logic is in one place, and config parameters (if set) always win (e.g. you can finally set a program by name via dvbin-prog as expected!). polling the options for changes. done in streaming_read for lack of a better place, with a throttling since there's no need to react too fast. adding dvbin-channel-switch-offset. since the channel list is dynamically chosen depending on connected and selected adapters, and there is no communication backchannel, we now have a property to select the offset from the initially chosen channel. documentation updates! a user can now for example put this: h cycle dvbin-channel-switch-offset up k cycle dvbin-channel-switch-offset down q set dvbin-prog ""zdf hd"" in input.conf, and switch channels by pressing h and k, or tune to zdf hd explicitly by pressing q. channel switching also got a bit faster again due to some cleanups. comments, suggestions and a review very welcome. i am especially unsure if the throttling is really needed, or if there is a better place to poll. </desc> <cmt> stream_dvb: use separated out options struct. </cmt> <cmt> this also allows the use of m_config_cache_alloc </cmt> <cmt> which allows to watch config updates. </cmt> <cmt> stream_dvb: factor out logic to determine program and card. </cmt> <cmt> this is now treated in dvb_parse_path consistently </cmt> <cmt> instead of logic scattered over various functions. </cmt> <cmt> this is a requirement to sensibly re-evaluate config </cmt> <cmt> after options have been changed, since we have two ways </cmt> <cmt> to configure the stream (decorated uri and config parameters). </cmt> <cmt> stream_dvb: move stream->is_on initialization to state preparation. </cmt> <cmt> notably, this allows to call dvb_streaming_start more than once, </cmt> <cmt> simplifying e.g. channel switching. </cmt> <cmt> also, get rid of unused timeout variable. </cmt>",bring back dvb channel switching
517,<desc> unify @iycheng and @architkulkarni 's prs to use common code for parsing runtime_env. this is an incremental step towards the full runtime_env spec in  followups: replace working_dir / working_dir_uri with files. unify env vars vs job_config for specifying runtime config </desc> <cmt> fix </cmt> <cmt> wip </cmt>,incremental refactor of runtime_env for consistency
518,"<desc> this cl will add the ability to add a bottom to the search bar. related issues working example: cl/338056388 associated to b/170283545 i added a check for existence in search_test.dart before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. yes, this is a breaking change. if not, delete the remainder of this section. i got input from the developer relations team, specifically from: rami-a </desc> <cmt> added bottom to search app bar </cmt> <cmt> add test for bottom in search appbar </cmt>",add bottom to search bar
519,"<desc> description: this pr adds basic support for hue lightgroups. currently, storing lights in a group in hass causes hass to send multiple api calls when turning on or turning off, therefore, the lights don't turn on/off simultaneous. when sending the request to a group, the lights will turn on/off simultaneous. the new hue app doesn't provide a ui to create groups, but the old one does. also, some light fixtures (like philips hue beyond) have multiple light sources that are combined in a group automatically. there are still a few things worth mentioning: the api to get a group returns a any_on and all_on. i've used the any_on, since that mimics the current behaviour of a group in hass. the group api provides a state of a (random) single light in the group (in the action dict). by using this, you can control a group in the interface ui as if it would be one light. also, there is still a issue that i don't know how to solve: turning on/off a group doesn't update the state of the individual lights of that group in the ui, however, the update_lights() is executed and lights and lightgroups arrays are modified. i don't know how i can tell hass to update the state of the entities. related issue (if applicable):  pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add support for hue lightgroup entity </cmt> <cmt> don't filter on lightgroup and add properties for a group </cmt>",add support for hue lightgroups
520,"<desc> fixes #81314 this pretty much just changes the span highlighted in the lint from pat_sp to ident.span. there's however an exception, which is in patterns with shorthands like point { y, ref mut x }, where a suggestion to change just x would be invalid; in those cases i had to keep the pattern span. another option would be suggesting something like point { y, x: ref mut _x }. i also added a new test since there weren't any test that checked the unused lint with optional patterns. </desc> <cmt> use identifier's span in unused lint </cmt> <cmt> bless some tests </cmt> <cmt> add regression test </cmt> <iss> span is too large for unused `rest @ ..` pattern warning </iss>",highlight identifier span instead of whole pattern span in unused lint
521,"<desc> super minor tweaks to some icons (removing shadow outside of the colored areas, according to icon guidelines) adding the missing files for mouse highlighter and find my mouse to installer file linked issue: #14702 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> updated docs images </cmt> <cmt> updated docs images </cmt> <cmt> updated icon files </cmt> <cmt> update product.wxs </cmt>",minor icon fixes and adding missing files to installer file
522,"<desc> updated tests with flag introduced in #6959 printing git info to deterministically identify commit the tests are run on. </desc> <cmt> [hotfix] printing remote, branch, commit hash that is being tested </cmt> <cmt> [flink-10678] disabled log checking in tests that fail jobs on purpose </cmt>",disabled log checking in tests that fail jobs on purpose 1.5-e2e
523,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. this pr adds some cypress tests for the /lean page. related to #38611 </desc> <cmt> add tests for quotes on /learn </cmt> <cmt> add tests for superblocks and blocks </cmt>",add e2e tests for /learn
524,"<desc> fixes #44153 (from 1.23.0) fixes #47486 (from 1.36.0) fixes #48010 (from 1.38.0) fixes #48027 (from nightly) fixes #48638 (from nightly) </desc> <cmt> add test for issue-44153 </cmt> <cmt> add test for issue-47486 </cmt> <cmt> add test for issue-48010 </cmt> <cmt> add test for issue-48027 </cmt> <iss> rustc panic (reprise) </iss> <iss> trait with associated function with ""where self:sized"" cannot be made into an object and results in compiler bug. </iss> <iss> ice: unknown layout </iss> <iss> ice: encountered ambiguity selecting `binder(<[type error] as bar>)` during trans, presuming due to overflow </iss> <iss> `repr(packed)` triggers internal compiler error </iss>",add some tests for fixed ices
525,"<desc> original pull-request #24870 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> add a test for materialized(distributed()) with join and group by </cmt> <cmt> removejoin: remove joined columns </cmt> <cmt> do not try convert columns that does not exists in materialized view </cmt> <cmt> do not try convert columns that does not exists in the result block </cmt> <cmt> convert 01890_materialized_distributed_join to .sh for explicit database for join </cmt> <cmt> minor style changes in storagematerializedview::read, storagemerge::createsources </cmt>","fix ""missing columns"" exception when joining distributed materialized view"
526,"<desc> this pr fixes a few of the issues with the latest update to the sandbox. first, it lowers the number of users in each aggregate session so there is no longer a warning from relay. second, it reduces the number of individual sessions that are sent which should help with the time it takes to create a demo org. finally, it makes the crash free rate better reflect the thresholds that are set. this pr also allows for the quick demo generation parameters to be an override instead of a copy of the ""normal"" generation parameters. grw-176 and grw-175 </desc> <cmt> changed thresholds for crashing </cmt> <cmt> sandbox fixes </cmt> <cmt> tech changes </cmt> <cmt> sandbox fixes </cmt>",fixes crash free rates and relay warning in sandbox
527,<desc> actually fixing a quic stream limit issue.  also fixing an unrelated bug with clean stream shutdown occasionally causing spurious stream-close writes to a closed connection. risk level: high (changing connection pool limits) testing: new integration test docs changes: n/a release notes: n/a platform specific features: n/a fixes #18160 </desc> <cmt> wip </cmt> <cmt> quic: (mostly) fixing stream limit bug </cmt> <cmt> quic: fixing stream limits bug </cmt> <iss> envoy crash when test http3 upgrade </iss>,fixing the disconnect between quiche stream count and envoy
528,"<desc> noticed while working on #14400 that the optional catch-all handling was missing in namedregex. this whole file also seemed quite regex heavy so i took a look at the overall logic and changed a few things. it worked by regex escaping the whole route then unescape the dynamic parts. i changed it to only regex escape the static parts, this eliminates unnecessary back and forth escaping. it also makes the dynamic parts handling more readable. the whole logic is less reliant on regexes and just uses simple string manipulation to translate the route into a regex, i didn't measure anything but as an effect this should make it more performant. </desc> <cmt> decode param before parse </cmt> <cmt> wip </cmt> <cmt> don't mutate in map </cmt>",update route regex for optional catch-all parameters in named regexes
529,"<desc> added network response checks to all curl http calls and all git clone calls. </desc> <cmt> amazon: added status checks on all http and git requests, on error notified user and exit </cmt> <cmt> amazon: minor changes to errors messages on git clone </cmt>",eosio build amazon network response checks
530,"<desc> during gsoc i extended smartplaylist rules to support implicit oring within a single rule and field. for that i added the possibility to select multiple values from the list of possible values for a browsable field. out of caution i removed the possibility to manually type into the value control of a browsable field because the user needs to follow a certain syntax to be able to specify multiple values which result in implicit oring. while this makes sense for operators like ""is"" and ""is not"" it doesn't make any senses for ""starts with"", ""ends with"", ""contains"" and ""does not contain"" where the user usually doesn't provide a fully matching value. therefore we need to allow manual typing in the value control. these changes add that functionality back. the syntax to define multiple values for implicit oring is to seperate the values by "" / "" (the spaces are mandatory because some scrapers e.g. provide genres like ""thriller/suspense""). if the user has manually typed a value which does not match any actual value and then uses the ""browse"" button to view a list of available values, none of the values is pre-selected and selecting a value from the list results in the loss of the previously entered value. </desc> <cmt> csmartplaylistrule: remove unneeded parameters in getlocalizedrule() and getparameter() </cmt> <cmt> csmartplaylistrule: add setparameter() methods </cmt> <cmt> cguidialogsmartplaylistrule: allow manual typing of the value of a browsable field </cmt>",restore possibility to type in the value field of a smartplaylist rule for browsable fields
531,"<desc> the example didn't wait for the runtime to be ready - i guess it was from back when synchronous startup was the default? i rewrote the example to use modularize. also it was missing an export of ccall. also rename extra_exported_runtime_methods to exported_runtime_methods as the ""extra_"" is no longer needed. </desc> <cmt> fix node example. fixes #11314 </cmt> <cmt> nicer </cmt> <cmt> fix </cmt>",fix node example in docs. fixes #11314
532,"<desc> fixed technical typo in plot_weighted_samples.py fixed a typo that said ""class weights"" when it meant ""sample weights"" which is an important technical difference. </desc> <cmt> update plot_weighted_samples.py </cmt> <cmt> fixed a typo that said ""class weights"" when it meant ""sample weights"" which is an important technical difference </cmt> <cmt> fixed technical typo in  plot_weighted_samples.py </cmt>",doc fixed technical typo in plot_weighted_samples.py
533,"<desc> added phantom solder pcb variant and upcoming kbd8x hs pcb variants. for phantom solder, did not include multiple layout options as via is the expected use case. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added config for phantom solder all layout via only </cmt> <cmt> fixed matrix def </cmt> <cmt> added kbd8x </cmt> <cmt> changed info name </cmt>",added phantom solder pcb and kbd8x hs pcb variants
534,"<desc> do not mutate alpha in the render target (useful for transparent render targets). make non-lit behavior consistent with lit. </desc> <cmt> masked mode now leaves destination alpha intact. </cmt> <cmt> this prevents strange behavior with semi-transparent render targets, </cmt> <cmt> which the model viewer team discovered when testing against the khronos </cmt> <cmt> alpha test conformance model. </cmt> <cmt> add mask smoothing to the unlit path. </cmt>",two fixes for masked blending mode.
535,"<desc> steps towards getting rid of _silgen_name altogether, which is generally unsafe and not something we're interested in supporting in its current form. i left out dispatch and foundation for now because those have code owners active in the swift project. the ""platform"" overlay (darwin/glibc) has also been exempted for now because i didn't want to poke at any low-level import dependencies. there are a few downsides to all this: these headers get installed along with the shims even though they're only used to build the overlays, and only on apple platforms. i or someone else should go back later and split these new shim headers into their own folders with their own module maps. add separate cmake targets for each one, for better dependencies. don't install the headers on irrelevant platforms. overall, though, i think this is a safety and simplicity win. </desc> <cmt> [sdk] use swiftprivate to remove _silgen_name from the appkit overlay. </cmt> <cmt> [sdk] use an extra shim header to remove _silgen_name from xctest. </cmt> <cmt> [sdk] use an extra shims header to remove _silgen_name from the os overlay. </cmt> <cmt> [sdk] use perform(_:with:) to remove _silgen_name from gameplaykit. </cmt> <cmt> this does require a dummy protocol for now; hopefully we can take it out </cmt> <cmt> later. </cmt> <cmt> [sdk] use existing ns_refined_for_swift to remove _silgen_name from scenekit. </cmt> <cmt> [sdk] use an extra shim header to eliminate _silgen_name from objectivec. </cmt> <cmt> [sdk] use an extra shim header to remove _silgen_name from safariservices. </cmt> <cmt> [sdk] use an extra shims header to remove _silgen_name from the xpc overlay. </cmt> <cmt> [sdk] fix circularity issues with overlay shim headers. </cmt> <cmt> loading a clang module eagerly brings in overlays for anything it re-exports, </cmt> <cmt> but this is a problem for these new ""shim header"" modules, which generally </cmt> <cmt> import the underlying module for an overlay and are in turn imported by the </cmt> <cmt> overlay. that means that when we try to import an overlay, we'll end up with </cmt> <cmt> a circular reference before it's done loading all its dependencies. break the </cmt> <cmt> cycle by not exporting anything from these modules, which are mostly just an </cmt> <cmt> implementation detail anyway. </cmt>",remove _silgen_name from all apple overlays except dispatch and foundation
536,<desc> the download-dashboards container has no option to set environment variables. this change allows variables to be set for proxies. dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/grafana] add env values for download dashboard images </cmt> <cmt> [stable/grafana] update docs </cmt>,add env vars for download dashboard container
537,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. new pr, the original is here #34797 </desc> <cmt> fix(challenges): update challenge text and assertion test </cmt> <cmt> fix(challenges): update assert test regex </cmt> <cmt> fix(challenges): update regex, fix inline comment in code example </cmt>",fix/remove property references and update tests
538,"<desc> closes #12689 closes #9232 closes #6051 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> tst: test for 6051 read_csv with multiindex columns </cmt> <cmt> tst: test for #9232 </cmt> <cmt> tst: tests for needs-test issues #12857, #12689 </cmt> <iss> bug: read multi-index column csv with index_col=false borks </iss> <iss> bug: dataframe constructor incorrect with series input depending on name </iss> <iss> err: invalid error reporting when comparing vs. none </iss>",tests for needs-test issues #12857 #12689
539,"<desc> this pr addresses these github issues: #2709 - box3 class specification (axis aligned bounding box) #2708 - sphere class specifications #2706 - plane class specifications #2715 - vector3.minself, maxself - simplifies bounding box calculations in various places. the new classes work and i integrated them into both frustum.js and geometry.js. in integrating box3 and sphere into geometry for boundingbox and boundingsphere respectively, i did so in a way that didn't change the javascript data structures used -- there is still a radius on boundingsphere and there is still min/max on boundingbox.  it is just that these two member properties (boundingbox and boundingsphere) are now proper classes. i have made an effort to copy the existing style in threejs with naming conventions as well as code organization.  i believe these classes look like they belong in threejs. code reviewed by @chandlerprall (via irc) and @wvl (off list) </desc> <cmt> implement box3.js and add to common.js - issue #2709 </cmt> <cmt> implement plane.js, add to common.js and update frustum.js to use it instead of vector4 - issue #2706 </cmt> <cmt> implement sphere.js class, add to common.js - issue #2708 </cmt> <cmt> improvements as a result of code review by @chandlerp </cmt> <cmt> simplify sphere.js via use of vector3.distanceto*(), minimize code in plane.js </cmt> <cmt> proposed vector3.minself, maxself - issue #2715 </cmt> <cmt> plane,box3,sphere improvements: static constructors, code simplficiation, optimizations.  box3 made more robust via true empty (+max_value,-min_value). </cmt> <cmt> minor cleanup of box3 class + no longer modifying input parameter in clamppoint. </cmt> <cmt> adopt sphere.js and box3.js in geometry.js. </cmt> <cmt> polishing box3, plane and sphere. </cmt> <cmt> change box3, plane and sphere declarations from frustum.js-style to vector3.js-style. </cmt> <cmt> move away from static fromxxx-style constructors to setxxx style member functions widely used in threejs. </cmt> <cmt> nickname consistency. </cmt> <cmt> bug fixes.  all examples now run while using box3, sphere and plane. </cmt>","polished box3, sphere and plane classes for threejs/core"
540,"<desc> some tests in windows may randomly take up to 5s, increasing to 10s. better name test results with its source job. @arcanis can you integrate this in your pr? let me know if you see any other blocker. we're also looking into fastening up these tests, </desc> <cmt> increase timeout in windows, we're seeing tests failing randomly and others close to default 5 sec. </cmt> <cmt> distinguish tests published from each job. </cmt> <cmt> pass name as vmimage is not available </cmt> <cmt> remove unnecessary detect unfinished tests. </cmt> <cmt> using strategy var instead of parameter </cmt> <cmt> use variables instead of strategy </cmt>",increase windows timeouts and better name test results
541,"<desc> this is a pretty obvious typo in retrospect. never hit it before, because in all non-defterm windows, the _startupactions always has one action. closes #11463 </desc> <cmt> oh you gotta be </cmt> <cmt> great cool these weren't needed </cmt> <iss> defterm window will not accept command palette *commandline mode* commands </iss>",fix the wt action in defterm windows
542,"<desc> the older algorithm was pretty inefficient for big matches. fixes #29227. (on my computer, mir construction on this test case goes from 9.9s to 0.025s.) whereas before we had a loop like: for all outcomes of the test we are performing for all candidates check whether candidate is relevant to outcome we now do: for all candidates determine which outcomes the candidate is relevant to since the number of outcomes in this case is proportional to the number of candidates, the original algorithm turned out to be o(n^2), and the newer one is just o(n). this pr also does some minor speedups by eagerly mirroring all patterns, so that we can just pass around &pattern<'tcx>, which makes cloning cheaper. we could probably go a bit further in this direction. r? @aatch </desc> <cmt> remove the mirroring for patterns and just convert them eagerly; then, </cmt> <cmt> pass around references instead of boxed values to save on clone costs. </cmt> <cmt> clone the candidates and match-pairs lazilly, instead of eagerly. </cmt> <cmt> reorganize match construction to be o(n) instead of o(n^2). whereas </cmt> <cmt> before we iterated over the test and each outcome thereof, and then </cmt> <cmt> checked processed every candidate against this outcome, we now organize </cmt> <cmt> the walk differently. instead, we visit each candidate and say ""here is </cmt> <cmt> the test being performed. figure out the resulting candidates for each </cmt> <cmt> possible outcome and add yourself into the appropriate places."" </cmt> <cmt> add regression test for #29227. </cmt>",change match desugaring in mir to be o(n) instead of o(n^2)
543,"<desc> two small improvements of compiler/rustc_lint/src/types.rs </desc> <cmt> rustc_lint: remove unused to_string </cmt> <cmt> in this instance, we can just pass a &str slice </cmt> <cmt> and save an allocation. </cmt> <cmt> make {u,}int_range functions a bit nicer </cmt> <cmt> .into() guarantees safety of the conversion. </cmt> <cmt> furthermore, the minimum value of all uints is known to be 0. </cmt>",fix two small issues in compiler/rustc_lint/src/types.rs
544,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add a command to format json files </cmt> <cmt> change to work after rebase </cmt>",add a qmk format-json command that will format json files
545,"<desc> this one takes care of all the remaining methods that made use of the @_with_element decorator. primarily widgets, but also some miscellaneous remaining elements. one possible thing we could do differently is to namespace widgets somehow so it's more clear which of these return values and which do not, e.g. perhaps placing them in the streamlit.widgets.foo module  instead of streamlit.elements.foo i think we'll wait until a future part 4 to rename delta_generator to something that makes sense. but taking suggestions in the meantime! fixes #1765 </desc> <cmt> extract _iframe and _html </cmt> <cmt> extract audio and video </cmt> <cmt> _pb2 to proto, part trois </cmt> <cmt> fix typo while extracting video </cmt> <cmt> extract checkbox, multiselect, select, radio </cmt> <cmt> extract time_input, date_input, text_input, and text_area </cmt> <cmt> extract empty and progress </cmt> <cmt> extract number_input </cmt> <iss> documentation - api should not list element as a parameter. </iss>","splitting up delta_generator, part 3!"
546,<desc> we merged the symbol and gen_sym argument as one now. i think we can delay bucketing support for predict as it seems the applications that need bucketing typically have their own customized predicting implementation. both char-rnn and neural translation do sampling at prediction time. </desc> <cmt> refactoring: merge symbol argument with sym_gen in feedforward </cmt> <cmt> update doc on gen_sym </cmt>,merge gen_sym with symbol argument in feedforward
547,"<desc> fixes #6731 -add test case for ruleschemametadata </desc> <cmt> add more test case for hintmanager (apache#6712) </cmt> <cmt> add more test case for hintmanager (apache#6712) </cmt> <cmt> fixed the grammar errors </cmt> <cmt> fix the test bug </cmt> <cmt> delete hintmanager.close </cmt> <cmt> add test case for ruleschemametadata(apache#6731) </cmt> <cmt> revert ""delete hintmanager.close"" </cmt> <cmt> this reverts commit c42e5303 </cmt> <iss> add test case for ruleschemametadata </iss>",add test case for ruleschemametadata(#6731)
548,<desc> adds shared module support for writing modules that work with cisco nexus devices over nxapi </desc> <cmt> add initial support for cisco nxapi </cmt> <cmt> this commit adds the shared module support for cisco nxapi.  the shared </cmt> <cmt> module builds on top of the urls shared module.  the urls module provides </cmt> <cmt> the http/s transport.  this module only supports the json request message </cmt> <cmt> format. </cmt> <cmt> fixes conditional statement for py24 compatibility </cmt> <cmt> changes the nxapi argument spec to require url_password </cmt>,initial shared module support for nxapi
549,"<desc> returns a struct of libfeature and reduces to a single api call querying of compile-time features. followup on api comments on #13549 @szha please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> prototype for runtime feature detection </cmt> <cmt> includes from diamond to quotes </cmt> <cmt> add cpu feature and blas flavour flags </cmt> <cmt> add blas flavour and cpu sse and avx flags </cmt> <cmt> mxnet_use_lapack </cmt> <cmt> fix c++ linting errors </cmt> <cmt> expose runtime feature detection in the public c api and in the python api </cmt> <cmt> refactor storage -> featureset </cmt> <cmt> refine documentation </cmt> <cmt> add failure case </cmt> <cmt> fix pylint </cmt> <cmt> address cr comments </cmt> <cmt> address cr comments </cmt>",addresses comments in runtime feature discovery api
550,"<desc> this adds support for several features of chromium's logging system that were previously not exposed in electron. in particular: it's now possible to send chromium logs to a file. this can be done either by passing --log-file=.../path/to/file.log along with --enable-logging. passing --enable-logging=file without --log-file will send logs to a default path, electron_debug.log in the user-data directory. this is particularly relevant on windows, on which os it is not possible to collect log messages from child processes when logging to stderr. electron_enable_logging=[1|file] is equivalent to passing --enable-logging / --enable-logging=file electron_log_file=.../path/to/file.log is equivalent to passing --log-file=.../path/to/file.log we now support --log-level=n to set the minimum level of log messages printed. it's now possible to enable logging from javascript, if done in the first tick. logging switches added by app.commandline.appendswitch() will be read immediately after the first run of js. cc'ing @electron/wg-api npm test passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: added support for directing chromium logging to a file with --log-file=.../path/to/file.log. also, it's now possible to enable logging from javascript by appending command-line switches during the first js tick. </desc> <cmt> feat: support electron_log_file environment vars. </cmt> <cmt> adds support for two new environment variables, electron_log_file and </cmt> <cmt> electron_log_level. if either of these is used, electron_enable_logging </cmt> <cmt> is implied. </cmt> <cmt> docs: document electron_log_file envvar </cmt>",bring --enable-logging functionality in line with chromium
551,"<desc> because v1/v0 message formats do not expect a header, ignore their presence when down-converting v2 messages that contain headers. added a test-case to verify down-conversion sanity in presence of headers. </desc> <cmt> kafka-6739: when down-converting from v2 to v0/v1, broker must ignore any header present in the record. </cmt> <cmt> added a test case to verify sanity when down-converting records containing headers. </cmt> <cmt> add comment. </cmt>",ignore the presence of headers when down-converting from v2 to v1/v0
552,"<desc> split from #24768 retry-after is broken for post/put, and a very common retry behavior for service account api tokens not yet being available exposed that we don't tell clients to retry when a retry error is sent. @wojtek-t re: load failures </desc> <cmt> allow statuserrors to be modified after creation </cmt> <cmt> have the service account controller force retry </cmt> <cmt> service account controller, when api token not found, now sends 500 with </cmt> <cmt> retry-after: 1s. also change the apiserver to actually write the error. </cmt> <cmt> print more data about an error for debugging </cmt> <cmt> sometimes clients send unintelligible data to the server, provide a bit </cmt> <cmt> more debugging in the returned error to make it easier to pin down where </cmt> <cmt> the problem is from the user side. </cmt> <cmt> reset input buffer on retry </cmt> <cmt> retries were previously sending empty bodies to the server. </cmt>","fix the retry-after code path to work for clients, and send correct bodies"
553,"<desc> with this pr we improve typing of the single-parameter bind method in --strictbindcallapply mode such that generic functions and overloaded functions are more accurately typed (i.e. we improve typing of calls to bind that bind just this and none of the function's parameters). previously, bind always erased type parameters and propagated only the last overload signature. now, when calling the single-parameter bind method on a function that has no explicitly declared this parameter (which turns out to be >99% of all observed uses of bind), we simply propagate the function type itself, thus preserving generics and overloads. the pr introduces two new conditional types in lib.d.ts: thisparametertype<t>: extracts the type of the this parameter of t, or 'unknown' if t has no 'this' parameter. omitthisparameter<t>: removes the 'this' parameter from t. if t has no explicitly declared this parameter, the result is simply t. otherwise, a new function type with no this parameter is created from t. generics are erased and only the last overload signature is propagated in this new function type. fixes #28582. fixes #28900. </desc> <cmt> improve typing of 'bind' method on function types </cmt> <cmt> accept new baselines </cmt> <cmt> fix findallreferences for 'this' parameter declarations </cmt> <cmt> update fourslash list of global types </cmt>",improve 'bind' typing in --strictbindcallapply mode
554,"<desc> extend s3 unit tests and fix regex that distinguishes between host and path based bucket references #4254 </desc> <cmt> extend s3 unit tests to test whether uris are correctly distinguished between host and path style reference </cmt> <cmt> fix the following issues with the regex to distinguish between path and host style s3 bucket references: 1) any host style reference with a key did ot match, 2) {expr}*.localhost always a match, 3) {expr}*.s3.{region} did not match </cmt> <cmt> make edge.py use the existing util method instead of re-implementing the regex match itself </cmt> <cmt> extend s3 unit tests with tests that distinguish between host and path style references </cmt> <cmt> make edge.py use the existing util method instead of re-implementing the regex match itself </cmt> <cmt> fix the following issues with the regex to distinguish between path and host style s3 bucket references: 1) any host style reference with a key did ot match, 2) {expr}*.localhost always a match, 3) {expr}*.s3.{region} did not match </cmt> <cmt> extend s3 unit tests to test whether uris are correctly distinguished between host and path style reference </cmt>",s3 reference style detection fixes
555,<desc> quick @cptspiff - before someone changes the projects :d tested on osx/ios/linux </desc> <cmt> [cosmetic] - fix identation </cmt> <cmt> [paplayer] - use dvdplayercodec for airtunes streams - now that we have the demuxer (thx gimli!!) - so we can get rid of bxacodec.cpp/.h </cmt> <cmt> [bxacodec] - get rid of the now obsolete bxacodec </cmt>,remove bxacodec and use dvdplayercodec instead
556,"<desc> why invert colors? when using flameshot in dark environments on a regular basis it would be very useful to invert the colors in the capture, making the screenshot white(ish) background and dark text. thus, enhancing the usability of those screenshots in reports and prints without having to use additional tools or workarounds. also, it's been a feature request for quite a while (#689). how does it work? basically, i copied the savetool and made an inverttool, that inverses all pixels before saving the screenshot. the actual consists of four lines: qpixmap inverted = context.selectedscreenshotarea(); qimage img = inverted.toimage(); img.invertpixels(); inverted.convertfromimage(img); however, it turned out that flameshot requires to update quite a few places in order to add a tool. without much of a documentation i tried to stay close to how the savetool is setup. before merging i'd advise that someone with a way better understanding of this project looks at my modifications in order to spot potentially missing or even unnecessary code for this new tool to be integrated. example see the above mentioned issue for a video demo. here's a screenshot of the newly added button. usage after choosing the area and drawing markers, text, arrows etc. - use ctrl+i or the invert button to save the screenshot with inverted colors. notes this isn't a perfect solution. people might want to invert colors while still drawing stuff or see a review of the inversion before saving the capture. additionally, more filters could be added maybe (comment by @mmahmoudian). however, my qt knowledge isn't by far good enough to be able to help with those things. from my point of view, this invert tool is a good solution for the time being and could still be extended at a later point. alright, that's it - let me know if i missed something or should update anything. </desc> <cmt> add invert tool to build commands </cmt> <cmt> add icons for invert tool </cmt> <cmt> integrate invert tool </cmt> <cmt> add shortcut for invert tool </cmt> <cmt> add invert tool </cmt> <cmt> add translation for invert tool </cmt> <cmt> run clang-format </cmt>",add a tool to take an inverted screenshot
557,"<desc> this pr expands the additional check in #37195 to also cover intersections with generic constituents. fixes #36637. </desc> <cmt> consolidated extra property check with intersections </cmt> <cmt> fix comment </cmt> <cmt> add tests </cmt> <iss> when merging a generic object type with new optional properties, these properties are not type checked </iss>",extra check in assignment of intersections with generic constituents
558,"<desc> the proposed pull request updates the definitions to conform to jquery.cookie version 1.4.1. since this library is deprecated and moved here, this should be one of the last pull requests for jquery.cookie. even though jquery.cookie was deprecated in favour of a jquery-less version, it's still beneficial for definitelytyped to have the most up to date definitions of it, since it is still heavily used. the only required addition was for the defaults property, which allows users to set defaults for cookie options.  jsdoc documentation was also added for all properties and methods.  this enables intellisense for editors that support. the jsdoc documentation uses snippets of documentation from the official jquery.cookie github repo as much as possible. the test file was also updated to test the defaults property. </desc> <cmt> updated for version 1.4.1, jsdoc documentaiton </cmt> <cmt> updated jquery.cookie.d.ts to conform to the latest version of jquery.cookie (1.4.1). this meant adding a defaults property to the jquerycookiestatic interface.  also added missing jsdoc documentation for better intellisense for editors that support it. the documentation uses the github repo documentation where possible. </cmt> <cmt> updated to test new defaults property </cmt>","updated for version jq cookie v1.4.1, added jsdoc documentation"
559,"<desc> this pr contains multiple commits; please look at the commit messages. make test-cmd what=kubeadm executes into a /hack rule that sources a /test/cmd script function that executes code in /cluster and then the result of the /cluster call is passed as a flag to an ""integration"" test in cmd/kubeadm/test . tempted to pull some git blame on this one, but let's leave it a mystery. fascinating... this is now simplified to make test-cmd executes a /hack/ rule that sets an environment variable and runs the same integration tests. unwanted scripts are deleted. also kubernetes/kubeadm#1383 is fixed by using another environment variable. open to alternative ideas on this one, but i don't see what else is possible...and this is for dry-run so... apply other minor cleanups to the tests too. fixes kubernetes/kubeadm#1383 does this pr introduce a user-facing change?: </desc> <cmt> remove /cluster/kubeadm.sh and /test/cmd/kubeadm.sh </cmt> <cmt> /cluster/kubeadm.sh is used to find the kubeadm binary. </cmt> <cmt> this file is legacy and is removed. </cmt> <cmt> remove /test/cmd/kubeadm.sh. this file contains a function that is used </cmt> <cmt> to build kubeadm and invoke ""make test"". move the function contents </cmt> <cmt> to hack/make-rules/test-cmd.cmd. </cmt> <cmt> stop sourcing /test/cmd/kubeadm.sh in /test/cmd/legacy-script.sh. </cmt> <cmt> also remove the --kubeadm-path invocation as this can be handled </cmt> <cmt> with an env. variable directly. </cmt> <cmt> cmd/kubeadm/test/cmd: refactor _test.go files </cmt> <cmt> make getkubeadmpath() fetch the kubeadm_path env. variable. </cmt> <cmt> panic if it's missing. don't handle the ""--kubeadm-path"" </cmt> <cmt> flag. remove the same flag from the build bazel test rule. </cmt> <cmt> don't handle ""--kubeadm-cmd-skip"" usage of this flag is missing </cmt> <cmt> from the code base. </cmt> <cmt> remove usage of ""kubeadmcmdskip"" as the flag ""--kubeadm-cmd-skip"" </cmt> <cmt> is never passed. </cmt> <cmt> kubeadm-init: allow overriding the dry-run temp directory </cmt> <cmt> allow overriding the dry-run temporary directory with </cmt> <cmt> an env. variable (kubeadm_init_dryrun_dir). </cmt> <cmt> use the same variable in test/cmd/init_test.go. </cmt> <cmt> this allows running integration tests as non-root. </cmt> <iss> tests are not passing with unprivileged user </iss>",cleanup the kubeadm integration tests and related scripts
560,<desc> allow calc() to specify a distance in the rasi format. for example: width:  calc(100%-10px); width: calc((100%-10em)/2); supports +-/*%. fixes: #1088 </desc> <cmt> initial test to allow math in distances. </cmt> <cmt> support + and - </cmt> <cmt> needs spaces around + and -. </cmt> <cmt> [theme] fix printing theme with math in distance. </cmt> <cmt> [theme] use calc() syntax. </cmt> <cmt> [theme] add * and /  to calc(). </cmt> <cmt> [theme] fix the precedense ordering in parsing. also avoid making copies. </cmt> <cmt> [theme] don't print unneeded (). </cmt> <cmt> [theme] add modulo to calc. </cmt> <iss> ability to combine distances in rofi theme files [request] </iss>,add calc() support to distance in theme format.
561,<desc> description: update sound mode list and current sound mode only on main_zone to avoid xml parse errors related issue (if applicable): fixes #16724 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> add support for sound_mode for yamaha rxv media_player </cmt> <cmt> catch parseerror exeption on surround_program for unsupported models </cmt> <cmt> catch all exeptions from rxv </cmt> <cmt> only get sound mode list / current sound mode on main_zone </cmt> <iss> yamaha rxv zone_2 not working anymore after update to 0.78.0 </iss>,yamaha avr update and change sound mode only on main_zone
562,"<desc> description: as is, an error gets thrown when turn_on is called without an hs value. by adding an if statement, we only try to set rgb if an hs value is applied. related issue (if applicable): fixes #13519 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> handle turn_on situation when no color is set </cmt> <cmt> as is, an error gets thrown when turn_on is called without an hs value. by adding an if statement, we only try to set rgb if an hs value is applied. </cmt> <cmt> handle turn_on situation when no color is set </cmt> <iss> flux led/magiclight - unable to change brightness </iss>",fix flux_led error when no color is set
563,"<desc> the keyboard manager editor allowed setting ""alt (left)"" -> ""alt"" and ""alt (right)"" -> ""alt"". this would make it so that when these were combined when opening the editor, they would be combined to ""alt"" -> ""alt"" and the editor would crash trying to present the error flyout. what is include in the pr: three changes related to this crash: 1 - don't combine the modifier keys to the combined key. 2 - catch the exception when trying to show an unavailable flyout when loading the window. 3 - don't allow the user to make mappings such as ""alt (left)"" -> ""alt"" or ""alt"" -> ""alt (left)"". verify that before you could set up ""alt (left)"" -> ""alt"" and ""alt (right)"" -> ""alt"" and it would crash the kbm editor if you saved and then try to reopen. after having that configuration saved, verify that the window no longer crashes when you try to open kbm editor. linked issue: #12978 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries </desc> <cmt> [kbm editor] don't combine keys to same key </cmt> <cmt> avoid crashes when flyouts can't be shown yet </cmt> <cmt> disallow mapping of left or right key to combined </cmt>",fix crash when mapping left and right modifier to the combined key.
564,"<desc> what do these changes do? a worker that is assigned a task and blocked in a ray.get should release its resources to allow another task to run. without this, with the following task, you cannot have a recursion deeper than the number of cores available: def recurse(i): if i == 0: return i return ray.get(recurse.remote(i - 1)) this is similar to #286, but for the raylet. </desc> <cmt> [xray] throttle task dispatch by required resources </cmt> <cmt> pass in number of initial workers into raylet command </cmt> <cmt> workers blocked in a ray.get release resources </cmt>",workers blocked in a ray.get release their resources
565,"<desc> description: update upstream library to 0.10.7 adds hmip-miob the two main switches can be controlled (implemented) the two digital input channels cannot be read due to missing value in upstream lib the analog output can not be controlled (range of 0-10v) (not implemented, could be implemented in a follow up pr) pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#9190 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly (example). new dependencies have been added to requirements in the manifest (example). new or updated dependencies have been added to requirements_all.txt by running </desc> <cmt> update upstream dependency </cmt> <cmt> add two switches </cmt>",add device hmip-miob to homematic ip cloud
566,"<desc> adding integration test class for stored procedures. providing a sql file to add stored procedure to mysql database. </desc> <cmt> added sql file to insert stored procedures in the mysql database </cmt> <cmt> added sql file to insert stored procedures in the mysql database </cmt> <cmt> removed sql file, to move to resources folder </cmt> <cmt> added named queries to foo model </cmt> <cmt> added foo stored procedures tests </cmt> <cmt> update readme.md - added link to stored procedure article </cmt>",bael-63 - add stored procedures with hibernate tests
567,"<desc> this is a spinoff of #48130 that generalizes the proposal to allow early termination with the composite aggregation when leading sources match a prefix or the entire index sort specification. in such case the composite aggregation can use the index sort natural order to early terminate the collection when it reaches a composite key that is greater than the bottom of the queue. the optimization is also applicable when a query other than match_all is provided. however the optimization is deactivated for sources that match the index sort in the following cases: multi-valued source, in such case early termination is not possible. missing_bucket is set to true i retained the commit from #48130 and merged the original idea that @howardhuanghua described in the pr to early terminate even when the sort is reversed in the leading source. </desc> <cmt> optimize composite aggregation by index sorting </cmt> <cmt> fix long ling issue </cmt> <cmt> enhance comment </cmt> <cmt> fix a reset issue </cmt> <cmt> enhance test case </cmt> <cmt> add reverse order test case </cmt> <cmt> remove extra test case </cmt> <cmt> adapt optimization to handle more than one leading source when index sort is applicable. </cmt> <cmt> add index sort uts. </cmt>",optimize composite aggregation based on index sorting
568,"<desc> failure to create the suspend.target transaction probably doesn't happen in practice.  however it can be triggered simply by masking suspend.target.  i would aspire to not lock the user out of the system if they try to test suspend failure this way.  also fix the error case to handle cleanup for scheduled shutdown.  and scheduled shutdown needs to send preparetoshutdown in the first place, so we fix that first (in the previous commit). similarly, logind normally blocks suspend during shutdown, and vice versa.  but scheduled shutdowns failed to block suspend.  fix that first. (scheduled shutdown is a bit of mess.  i'm sure systemd-shutdown was simpler.  i don't see why it had to be replaced, but i don't want to drop the api at this point either). </desc> <cmt> logind: remember to remove '/run/systemd/shutdown/scheduled' </cmt> <cmt> logind: method_schedule_shutdown() already rejects empty type </cmt> <cmt> don't test for an empty type afterwards.  this is not how you cancel </cmt> <cmt> scheduled shutdowns - there's a separate method for that. </cmt> <cmt> logind: add missing check for conflicting operation v.s. scheduled shutdown </cmt> <cmt> > we don't want to shutdown while a suspend is running, and vice versa. </cmt> <cmt> > this would be confusing and could lead to data loss in the worst case. </cmt> <cmt>  </cmt> <cmt> according to the above comment, if the conflicting operation is hung, </cmt> <cmt> we don't want to force things when the admin has not passed a force option. </cmt> <cmt> similarly if you're not an admin, you probably shouldn't get to sneak </cmt> <cmt> around this check by using a scheduled shutdown instead of an unscheduled </cmt> <cmt> one.  (and no-one so far thought it necessary to add such a permission in </cmt> <cmt> polkit). </cmt> <cmt> note that if the conflicting operation was _not_ hung, and we lost the </cmt> <cmt> race with suspend, the system might not have shut down at the scheduled </cmt> <cmt> time anyway.  which is no good if you were scheduling a power outage. </cmt> <cmt> and scheduling a shutdown for an arbitrary time when the system is resumed, </cmt> <cmt> does not seem a very useful semantic.  more likely, scheduled shutdowns are </cmt> <cmt> useful on systems which do not use suspend, such as multi-user servers. </cmt> <cmt> (in which case even polkit defaults likely don't let the users trigger </cmt> <cmt> suspend). </cmt> <cmt> logind: respect ""delay"" inhibitors in scheduled shutdowns </cmt> <cmt> there is no justification not to wait an extra (default) 5 seconds, for </cmt> <cmt> a more graceful shutdown of user programs.  again, you don't get to ignore </cmt> <cmt> delay inhibitors for unscheduled shutdowns, short of </cmt> <cmt> systemctl poweroff -f. </cmt> <cmt> it is simplest if we move the test for m->shutdown_dry_run into </cmt> <cmt> manager_scheduled_shutdown_handler(). </cmt> <cmt> however we need to not add such delays during a ""dry run"".  otherwise, we </cmt> <cmt> would still have to be considered ""in progress"" for some seconds after our </cmt> <cmt> admin has seen the final wall message.  if they go to poweroff, we would </cmt> <cmt> have blocked them with a misleading error message.  note this poweroff </cmt> <cmt> will still process delay inhibitors as needed.  if the admin planned to </cmt> <cmt> use a more forceful method... eh.  it's their responsibility to assess </cmt> <cmt> whether that's safe. </cmt> <cmt> there is an argument that the alternative behaviour could be used (racily!) </cmt> <cmt> to kludge around them not being able to shutdown to ""single user mode"".  if </cmt> <cmt> we cared about that case, we would have easily preserved non-racy support </cmt> <cmt> for it in shutdown. </cmt> <cmt> additionally, though i think this code does read more easily by reducing </cmt> <cmt> inconsistencies, we didn't come up with any use case for delay inhibitors </cmt> <cmt> v.s. shutdown.[1]  the sigterm v.s. sigkill delay is more general, and we </cmt> <cmt> allow a whole 90 seconds for it, not just 5.  so i don't think keeping this </cmt> <cmt> approach bears a risk of significant damage. </cmt> <cmt> [1] </cmt> <cmt> logind: add missing resume signal when we fail to initiate sleep/shutdown </cmt> <cmt> this fixed </cmt> <cmt> as much as i was able to reproduce it in a vm, at least. </cmt> <cmt> e.g. this signal might wake the screen back up, providing a more visible </cmt> <cmt> indicator of suspend failure.  in my vm testing, it was also required in </cmt> <cmt> order to unblock keyboard input in gnome-shell after the failed suspend. </cmt> <cmt> at the same time, fix the error handling for scheduled shutdowns.  this now </cmt> <cmt> mirrors the behaviour of when you use shutdown -k - it sends all the </cmt> <cmt> scary messages about shutting down, ""but you'll have to do it [shut down </cmt> <cmt> the system] yourself"".  it also avoids the risk of locking out the admin </cmt> <cmt> (nologin file), in case they logged out for some reason (and they use </cmt> <cmt> sudo instead of root). </cmt> <cmt> not that i have any idea why you'd want to use shutdown -k, but the code </cmt> <cmt> is easier to analyze if it rolls back on error (in the absence of any code </cmt> <cmt> comment as to why that's not wanted). </cmt>",add missing resume signal when we fail to initiate sleep (and shutdown)
569,"<desc> fixes #267 the calculator currently only accepts exponential numbers like 2323e+12 and 23241e-12. the calculator should also accept 2323e12 or 334.232e12 in the scientific mode. modify the regex used to check exponentials modify onpaste(string^ pastedstring, viewmode mode) to accept exponentials without signs. add unit tests unit tests + manual testing in english, french and spanish. before/after </desc> <cmt> add exponential without sign support </cmt> <cmt> add unit tests </cmt> <cmt> fix formatting </cmt> <cmt> remove extra spaces </cmt> <iss> the calculator should accept exponential numbers without sign in scientific mode </iss>",accept exponential numbers without -/+ sign.
570,"<desc> these tests cover corner cases that were without test coverage on tornado/httputil.py there are just 2 lines in this file without test coverate yet: import doctest doctest.testmod() when __name__ == '__main__' is this feature still needed? considering now that tornado has unit tests and 'tornado.httputil.doctests' function is covered on runtests.py? </desc> <cmt> add test to parse_multipart_form_data() on httputil when ""boundary"" parameter has quotes </cmt> <cmt> add test to parse_multipart_form_data() when missing headers </cmt> <cmt> add test to parse_multipart_form_data() when invalid content-disposition </cmt> <cmt> add test to parse_multipart_form_data() when line does not end with the correct line break (\r\n) </cmt> <cmt> add test to parse_multipart_form_data() when no ""name"" parameter is found </cmt>",add more tests to httputil.py
571,"<desc> correctly incref an intance's type. currently, if a heap-allocated type creates an instance through pyobject_{,gc}_new{var}, the type won't incref. this adds a change to pull the incref to the core pyobject_init{init} function to correctly incref heap-allocated types. this now means that heap-allocated types that add a custom tp_dealloc, should decref the instance types - just like the default tp_dealloc does. currently there are 10 heap-allocated types in cpython: pycursespanel_type in _curses_panel.c sslerror_type in _ssl.c example_type in _testmultiphase.c str_type in _testmultiphase.c tkapp_type in _tkinter.c tktt_type in _tkinter.c pytclobject_type in _tkinter.c xxo_type in xxlimited.c str_type in xxlimited.c null_type in xxlimited.c struct sequences in structseq.c out of those only the following 5 types allocate instances through pyobject_{gc}_new{var}: pycursespanel_type. action: added a decref in its tp_dealloc tkapp_type. action: removed the manual incref after allocation. tktt_type. action: removed the manual incref after allocation. pytclobject_type. action: removed the manual incref after allocation. xxo_type. no action: it inherits the default tp_dealloc which already decrefs the type. struct sequences. action: removed decref the type in the deallocation function. </desc> <cmt> add incref to heap-allocated type objects </cmt> <cmt> added news </cmt>",incref heap-allocated types in pyobject_init
572,"<desc> this is useful when it's possible to end iteration before scanning all headers, such as searching for a the first of a particular header. reverse iteration is useful for searching for the last of a particular header, and is used to reduce the number of headers processed when parsing out a cookie value. </desc> <cmt> make headermap::iterate exit early </cmt> <cmt> this is useful for things like searching for cookies, where it is </cmt> <cmt> reasonable to break early. </cmt> <cmt> support reverse iteration over a header map </cmt> <cmt> should be helpful for cases where the last header sent overrides </cmt> <cmt> previous ones. </cmt> <cmt> use headermap reverse iteration to find cookies </cmt>",make headermap iteration exit early and add reverse iteration
573,"<desc> #39105 removed the normal unit testing from ci in favor of bazel, but the staging repos don't have build files in them because bazel choked on it.  this meant that unit tests weren't being run in ci (even though make test did it).  this restores the staging tests. @ixdy @spxtr since you were on the initial issue @liggitt @kubernetes/rh-cluster-infra thanks to @cheftako for finding it. </desc> <cmt> fix up broken tests </cmt> <cmt> restore unit testing for the staging repos </cmt>",restore unit testing for staging repos
574,"<desc> @rocketchat/core @twizzydizzy see #6144 comment by twizzydizzy we do not want passwords to be saved in mongodb when ldap is enabled (this might be made into an option in the backend, if not, they should not be saved by default) unless fallback-login is activated this means the passwords need to be erased (for ldap-flagged accounts) on disabling fallback login and stored on next login, when this feature is enabled this pr changes the password storage behaviour if ldap_login_fallback is enabled. the password will not be saved in mongodb. </desc> <cmt> do not store password if ldap_login_fallback is off </cmt> <cmt> restore whitespace </cmt>",do only store password if ldap_login_fallback is on
575,"<desc> i've been reading the book and noticed a few small grammatical and stylistic issues which i've rolled into this pull request. i'm not sure if i should do so many small, unrelated edits in a single pull request but it seems like a lot of overhead for each small edit. maybe one commit per edit but one pull request per file/section? feedback is very much appreciated as this is my first pull request ever! r? @steveklabnik rollup </desc> <cmt> fixed backquotes and awkward borrowing clause </cmt> <cmt> ""errors with"" is idiomatic in english </cmt> <cmt> ""also ... as well"" is redundant </cmt> <cmt> also ""to access"" is cleaner than ""for accessing"" </cmt> <cmt> many small grammatical and stylistic changes </cmt> <cmt> grammatical: ""here's"" should be ""here are"", ""rules"" is plural. </cmt> <cmt> stylistic: ""rules for"" is more idiomatic than ""rules about"". </cmt> <cmt> grammatical: no verb in ""one or the other""; changed to ""it's one or the other"". </cmt> <cmt> code: added implied fn main() { ... } because it is referenced in ""note: previous borrow ends here"" </cmt> <cmt> semantic: ""but"" seems like the wrong word here, there is now, contrast, only further explanation. ""so"", ""thus"" or ""therefor"" is clearer. </cmt> <cmt> grammatical: another misuse of ""here's"", should be ""here are"" (or possibly ""here're""). </cmt> <cmt> grammatical: ""use"" should be capitalized. all other subheadings capitalize the first word. </cmt> <cmt> fixed typo: term should be terms </cmt> <cmt> two terms (input lifetime and output lifetime) so ""term"" needs to be plural. </cmt> <cmt> took comment out of code block </cmt> <cmt> no reason for a long comment in a code block when we could take it out, especially since it looks like it's using markdown (struct, & and lvl). </cmt> <cmt> merging my book edits recent commits. </cmt>",small grammatical and stylistic edits to book
576,<desc> previously some images were using jpg.js that could actually be decoded by the browser. they're now decoded using the browser then sent back to apply the needed color conversions. </desc> <cmt> decode more jpegs using the browser if possible. </cmt> <cmt> move comments. </cmt>,decode jpegs using browser when possible
577,<desc> i hereby agree to the terms of the cla available at:  non-significant (changelog entry is not needed) detailed description (optional): part of #7512 it's needed to remove database and table name from path to data </desc> <cmt> make data path relative </cmt> <cmt> use arbitrary relative path in *mergetree </cmt> <cmt> refactor storagefile construction </cmt> <cmt> use relative paths in istorage::rename(...) </cmt> <cmt> fixes </cmt>,use relative paths in storages
578,"<desc> clarifies plattform specific behaviour of preferences: on android, prior to flushing, changes to the preferences are not available to the user on ios changes are not synchronized between different preferences instances fixes #5558. </desc> <cmt> clarify how preferences work on android. </cmt> <cmt> add a note about preferences behaviour on ios. </cmt> <iss> preferences behaviour differs on android </iss>",clarify plattform specific behaviour of preferences
579,"<desc> since #9319 proposed by gregory maxwell and released in v0.14, peers manually added through the -addnode config option or using the addnode rpc have their own separate limit of 8 connections that does not compete with other inbound or outbound connection usage and is not subject to the limitation imposed by the -maxconnections option. this pr updates the -addnode and -maxconnections config options and the addnode rpc help docs with this information. -addnode config option help $ bitcoind -h | grep -a5 addnode= -addnode=<ip> add a node to connect to and attempt to keep the connection open (see the addnode rpc help for more info). this option can be specified multiple times to add multiple nodes; connections are limited to 8 at a time and are counted separately from the -maxconnections limit. $ bitcoind -h | grep -a3 maxconnections= -maxconnections=<n> maintain at most <n> connections to peers (default: 125). this limit does not apply to connections manually added via -addnode or the addnode rpc, which have a separate limit of 8. addnode rpc help $ bitcoin-cli help addnode addnode ""node"" ""command"" attempts to add or remove a node from the addnode list. or try a connection to a node once. nodes added using addnode (or -connect) are protected from dos disconnection and are not required to be full nodes/support segwit as other outbound peers are (though such peers will not be synced from). addnode connections are limited to 8 at a time and are counted separately from the -maxconnections limit. </desc> <cmt> doc: update addnode rpc help </cmt> <cmt> doc: update -addnode config option help </cmt>",update helps for addnode rpc and -addnode/-maxconnections config options
580,<desc> added it to gatsbyjs.org and it removed 20kb from our commons bundle! easy win for any website using lodash. </desc> <cmt> add gatsby-plugin-lodash </cmt> <cmt> make new packages default to 1.0.0 </cmt> <cmt> publish </cmt> <cmt> - gatsby-plugin-lodash@1.0.1 </cmt>,add new gatsby plugin for lodash which adds their webpack & babel plugins to builds.
581,"<desc> used shell_notifyicongetrect function to get the bounds of the application's tray icon. note that this only works with windows 7 or windows server 2008 r2 and later. i did not test this on windows xp. since even microsoft stopped supporting windows xp, i think decent support on modern os's is more important than supporting legacy systems. it would be nice if someone could check if no things got broken to badly though (is there an error when clicking the tray icon on windows xp?)... if so, could this be handled gracefully? fixes #1159 and related to #1500. </desc> <cmt> added bounds payload to tray clicked event </cmt> <cmt> used [shell_notifyicongetrect function]( </cmt> <cmt> note: only works with windows 7 and later. </cmt> <cmt> related to #1159, #1500. </cmt> <cmt> updated tray api docs to reflect changes in ce8aa07 </cmt> <iss> window position </iss>",added bounds payload to tray clicked event on windows
582,"<desc> remove duplicate code in abstractconfig.java to make brief and clean remove code classutils.isprimitive(method1.getreturntype()) in abstractconfig.java at line 653 classutils.isprimitive(method1.getreturntype()) is already judge in method methodutils.isgetter follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> merge from dubbo master </cmt> <cmt> merge from dubbo master </cmt> <cmt> remove duplicate code </cmt>",[dubbo-4491]remove duplicate code in abstractconfig.java
583,<desc> clean up various integration tests that referenced the integration_config.yml vars file. integration tests </desc> <cmt> fix var_blending test temp dir usage. </cmt> <cmt> fix filters integration test: </cmt> <cmt> - fix use of output_dir. </cmt> <cmt> - use localhost instead of testhost since we're only testing filters. </cmt> <cmt> - fix fileglob test to actually test a directory that exists. </cmt> <cmt> fix lookups integration test: </cmt> <cmt> - fix use of output_dir. </cmt> <cmt> - use localhost instead of testhost since we're only testing lookups. </cmt> <cmt> fix ansible-runner test temp dir usage. </cmt> <cmt> fix template and template_jinja2_latest test. </cmt> <cmt> use the output_dir env var to get the output directory for the tests. </cmt>,clean up various integration tests.
584,"<desc> add mbedtls lib support support custom openssl, sodium and mbedtls crypto lib path update libsodium to 1.0.12 in tests add libopenssl 1.1 to tests add mbedtls to tests add more ciphers to jenkins update config.json.example </desc> <cmt> add mbedtls crypto wrapper. </cmt> <cmt> add tests files for new aead ciphers </cmt> <cmt> add custom lib path support </cmt> <cmt> fix some typo </cmt> <cmt> fix forbidden ip list </cmt> <cmt> rm crypto lib build files </cmt> <cmt> remove crypto source </cmt> <cmt> add xchacha20 test config </cmt>","add mbedtls wrapper, custom crypto lib path, test files"
585,"<desc> with these magic symbols, programs that link against the _concurrency module with a deployment target prior to ios 15 / macos 12 / watchos 8 will reference libswift_concurrency.dylib via rpath. fixes rdar://81187835. </desc> <cmt> add magic symbols for concurrency. </cmt> <cmt> extend and test install_name symbols for back-deployed concurrency. </cmt> <cmt> with these magic symbols, programs that link against the _concurrency </cmt> <cmt> module with a deployment target prior to ios 15 / macos 12 / watchos 8 </cmt> <cmt> will reference libswift_concurrency.dylib via rpath. </cmt> <cmt> fixes rdar://81187835. </cmt>",add install_name symbols for back-deployed concurrency.
586,"<desc> breaking changes rename circle to circular and rect to rectangular for consistency. the possible values should be adjectives, not nouns: -<skeleton variant=""circle""> -<skeleton variant=""rect""> +<skeleton variant=""circular""> +<skeleton variant=""rectangular""> last item of #21964. closes #21964 </desc> <cmt> [skelton] rename variant circle -> circular </cmt> <cmt> [skelton] rename variant rect -> rectangular </cmt> <cmt> add skeleton section </cmt> <cmt> update docs </cmt> <iss> [rfc] renaming api for consistency </iss>",rename variant circle -> circular and rect -> rectangular for consistency
587,"<desc> description: when the target sonarr service is not available during setup, set the sensors to unavailable. since sonarr is a self-hosted solution, it makes sense that the user would know about the availability of the service, and that it would return. when the service becomes available again, the sensors will pick up the data. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add exception handling to request call to prevent </cmt> <cmt> failure in setup_platform if host is down </cmt>",add exception handling to sonarr
588,<desc> refactoring of ramping code to make it as separate from the rest of the locust code at possible. added tooltips for the ramping form in the ui. </desc> <cmt> added tooltips to ramping form </cmt> <cmt> refactoring of ramping functionality to make it as separate at possible </cmt>,refactoring (separation) of ramping code; added tooltips for ramping form in ui
589,<desc> thank you for contributing to kubernetes/charts. before you submit this pr we'd like to </desc> <cmt> return ingressclass in notes </cmt> <cmt> fix broken controller-hpa </cmt> <cmt> bump chart version </cmt> <cmt> expose volumename for chartmuseum </cmt> <cmt> bump chartmuseum version </cmt> <cmt> spelling </cmt>,fix a couple spelling errors
590,"<desc> from auto-308. the ci system has been running all tests for the serial test steps on eos:develop-boxed. the serial tests rely on container-level parallelization, so each step should only be running one test. this pull request fixes the develop-boxed bug, simplifies some of the ci code, makes the pipeline easier to debug, and folds some log segments in order to focus on the parts of the build process that the customer cares most about. the working directory was also changed from /workdir to /eos to support using the same container for multiple ci systems. see also pull request 9653 -- eos:develop-boxed pull request 9655 -- eos:blockvault pull request 9656 -- eos:develop pull request 9657 -- eos:release/2.0.x pull request 9658 -- eos:release/1.8.x none. none. none. </desc> <cmt> remove dead code </cmt> <cmt> evaluate $(pwd) at runtime so that it is easier to copy-pasta docker commands to a local machine </cmt> <cmt> support paths with spaces and passing through multiple arguments </cmt> <cmt> don't source ~/.bash_profile outside of the ci system </cmt> <cmt> print even more commands before running them to make this bash spaghetti easier to debug </cmt> <cmt> print test logs in realtime; organize following steps </cmt> <cmt> fix shell string quoting issues </cmt> <cmt> de-duplicate npm command </cmt>",fix serial test bug + simplification + ux
591,"<desc> languagecodeexpander can try to load language when trying to resolve language code. without this patch, every language load (even in local langinfo object) cause reset global locale. </desc> <cmt> langinfo: fix: remove global object usage from non-static function </cmt> <cmt> [win32] langinfo: undef function names on win32 </cmt>",langinfo - fix overriding default language when checking for language presence
592,<desc> backports #26111 #26223 #26187 #26219 #26221 </desc> <cmt> enable traffic director time tracer (#26111) </cmt> <cmt> just update the timeout (#26223) </cmt> <cmt> increase xds job timeouts (#26187) </cmt> <cmt> revert grpc_xds_k8s job timeouts back to 120 mins (#26219) </cmt> <cmt> revert grpc_xds_k8s_python timeout to 120mins (#26221) </cmt> <cmt> seems to have been inadvertently increased in #26187 </cmt>,backport config update timeout change to v1.37.x
593,"<desc> --no-heap-copy is irrelevant to us since we don't use the packager tool, instead i fixed the createdatafile call. also included a patch that makes sure we always use out() and err() (implementing stdout and stderr) instead of console.log/warn. these functions are now always available since we bumped the minimum emscripten version. </desc> <cmt> fix file preloading warning in html5 platform </cmt> <cmt> use stdout/-err for all messages in html5 platform </cmt>","properly preload files, always use stdout/-err in html5 platform"
594,"<desc> we do not presently stash files correctly when a file is added in the index and then modified in the working directory.  we are examining only the working directory with regard to the head, and without examining the index as well (with that file staged) we treat that file as untracked and thus do not include it in the workdir tree. correct that by using a diff that includes the index similar to git_diff_tree_to_workdir_with_index but with different special cases.  (git_diff_tree_to_workdir_with_index is aimed at producing something like git diff and so collapses some cases - we differ in that we want to ensure that we still pay attention to the workdir side when the index side is deleted.) </desc> <cmt> diff_tform: remove reversed copy of delta merger </cmt> <cmt> drop git_diff__merge_like_cgit_reversed, since it's a copy and </cmt> <cmt> paste mess of slightly incompatible changes. </cmt> <cmt> git_diff__merge: allow pluggable diff merges </cmt> <cmt> stash tests: ensure we save the workdir file </cmt> <cmt> ensure that when a file is added in the index and subsequently </cmt> <cmt> modified in the working directory, the stashed working directory </cmt> <cmt> tree contains the actual working directory contents. </cmt>","stash workdir correctly when added in the index, modified in the workdir"
595,"<desc> longer-term, do we want to use numpy's new behavior?  update a little more background: consider two ndarrays in np<1.18 arr1 = np.array([1, 2, np.nan, 3, 4]) arr2 = np.array([1, 2, np.datetime64(""nat""), 3, 4], dtype=""datetime64[ns]"") >>> np.sort(arr1) array([ 1.,  2.,  3.,  4., nan]) >>> np.sort(arr2) array([                          'nat', '1970-01-01t00:00:00.000000001', '1970-01-01t00:00:00.000000002', '1970-01-01t00:00:00.000000003', '1970-01-01t00:00:00.000000004'], dtype='datetime64[ns]') in numpy 1.18, the behavior of np.sort(arr2) is changing to put the nat at the end instead of at the beginning, to behave more like nan.  this breaks a few tests, which this pr fixes. side-note: as of now, 1.18 changes the behavior for datetime64, but not timedelta64. </desc> <cmt> tst: fix test broken by np 1.18 sort change </cmt> <cmt> nicer fix </cmt>",fix tests broken by np 1.18 sorting change
596,"<desc> layername buttons will grow/shrink to fill layer panel width. grows to a maximum of the draw width of the widest set layer name. also fixes #47 </desc> <cmt> fix stbte_create_map declaration </cmt> <cmt> stbte: layername button grows/shrinks </cmt> <cmt> layer name buttons grow to fill box </cmt> <cmt> stbte: update documentation/version 0.31 </cmt> <cmt> changed revision history, todo, credits, and readme </cmt> <iss> stbte_create or stbte_create_map </iss>",layer name buttons grow with layer panel
597,"<desc> validate-modules sanity test now validates removal version numbers (similar to version_added validation), checks that removal collection versions are major releases, and not minor or patch releases, and checks that version_added collection versions are not patch releases: error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-deprecated-version: argument 'read_only' in argument_spec found in mounts has deprecated aliases 'ever' with invalid removal version '1.2.3.4': invalid semantic version '1.2.3.4' error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-deprecated-version: argument 'tmpfs' in argument_spec has an invalid removed_in_version number '1.2.3.4': invalid semantic version '1.2.3.4' error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-removal-version: ansiblemodule.argument_spec.mounts.options.read_only.deprecated_aliases.1: version ('1.2.3.4') is not a valid collection version (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: removal-version-must-be-major: ansiblemodule.argument_spec.mounts.options.read_only.deprecated_aliases.0: version ('1.3.0') must be a major release, not a minor or patch release (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: removal-version-must-be-major: ansiblemodule.argument_spec.published_ports.deprecated_aliases.0: version ('1.2.0') must be a major release, not a minor or patch release (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: version-added-must-be-major-or-minor: documentation.options.device_read_bps.suboptions.rate: version_added ('1.0.1') must be a major or minor release, not a patch release (see specification at  error: plugins/modules/cloud/misc/helm.py:0:0: removal-version-must-be-major: documentation.deprecated: removed_in ('3.1.0') must be a major release, not a minor or patch release (see specification at  (also removes some error codes from docs/docsite/rst/dev_guide/testing_validate-modules.rst which have been forgotten, or which haven't been reported anymore.) the pylint sanity test now checks that removal collection versions are major releases, and not minor or patch releases: error: plugins/modules/cloud/docker/docker_container.py:3445:8: removal-version-must-be-major: removal version ('3.1.0') must be a major release, not a minor or patch release (see specification at  the runtime-metadata code-smell sanity test now has stricter date validation (f.ex. yyyy-m-d no longer accepted), checks removal version numbers (semver version numbers for collections, strictversion for ansible-base), and checks that removal collection versions are major releases, and not minor or patch releases: error: meta/runtime.yml:0:0: expected iso 8601 date string (yyyy-mm-dd), or yaml date for dictionary value @ data['plugin_routing']['modules']['gcspanner']['deprecation']['removal_date']. got '2020-1-4' error: meta/runtime.yml:0:0: removal version must be a semantic version ( error: meta/runtime.yml:0:0: extra keys not allowed @ data['plugin_routing']['modules']['gcp_url_map']['deprecation']['extra_key']. got 'whatever' error: meta/runtime.yml:0:0: removal_version ('3.1.0') must be a major release, not a minor or patch release (see specification at  validate-modules sanity test pylint sanity test runtime-metadata code-smell sanity test </desc> <cmt> validate removal versions. </cmt> <cmt> should not be here anymore. </cmt> <cmt> validate that removal collection versions and version_added collection versions conform to semver spec. </cmt> <cmt> validate removal version numbers in meta/runtime.yml. </cmt> <cmt> stricter validation for isodates (f.ex. yyyy-m-d is not allowed). </cmt> <cmt> improve error reporting. </cmt> <cmt> validate removal collection versions. </cmt>","improve version number validation, validate some semantic versioning properties"
598,<desc> commit log pegasus hoof: layout macro refactor (7c2da6c) renamed keymap to layout added layout_tkl_ansi macro white space changes (changed tabs for 2 spaces) pegasus hoof: keymap refactor (08d6f43) updated layout macro names changed to #include qmk_keyboard_h removed redundant kc_trns definitions white space changes (changed tabs to spaces) removed deprecated build script instructions from rules.mk files updated config.h to #pragma once pegasus hoof: configurator support (10fc65a) pegasus hoof: readme cleanup (6e4e932) reformat header and description paragraph fix hardware availability link (was 404) renamed filename to lowercase pegasus hoof: add layouts = tkl_ansi to rules.mk (ed1b987) </desc> <cmt> pegasus hoof: layout macro refactor </cmt> <cmt> - renamed keymap to layout </cmt> <cmt> - added layout_tkl_ansi macro </cmt> <cmt> - white space changes (changed tabs for 2 spaces) </cmt> <cmt> pegasus hoof: keymap refactor </cmt> <cmt> - updated layout macro names </cmt> <cmt> - changed to #include qmk_keyboard_h </cmt> <cmt> - removed redundant kc_trns definitions </cmt> <cmt> - white space changes (changed tabs to spaces) </cmt> <cmt> - removed deprecated build script instructions from rules.mk files </cmt> <cmt> - updated config.h to #pragma once </cmt> <cmt> pegasus hoof: configurator support </cmt> <cmt> pegasus hoof: readme cleanup </cmt> <cmt> - reformat header and description paragraph </cmt> <cmt> - fix hardware availability link (was 404) </cmt> <cmt> - renamed filename to lowercase </cmt> <cmt> pegasus hoof: add layouts = tkl_ansi to rules.mk </cmt>,"bpiphany pegasus hoof refactor, configurator support and readme cleanup"
599,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: cure53/dompurify#367 if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. cure53/dompurify#367 </desc> <cmt> [dompurify] publicly expose dompurify's interfaces and event names via the dompurify namespace. </cmt> <cmt> [dompurify] update dompurify's sanitize method return types to reflect version 2.0.1 (support for trustedhtml types) </cmt>",expose dompurify typings on namespace and update types to better reflect version 2.0.1
600,<desc> what do these changes do? adds support for running eager tf policies. blocking issues #5434 #5435 #4921 linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> attempt at eager + builder </cmt> <cmt> tweaks </cmt> <cmt> finished eager pg </cmt>,adds eager support with a generic tfeagerpolicy class
601,"<desc> the following code would throw exception before this fix because the value was not broadcast to the right shape . data = mx.nd.ones((2, 2))  # data.shape = (2, 2) value = mx.nd.array([3])  # value.shape = (1,) data[:] = value  # the value should be broadcast to shape (2, 2) first and then call copyto(data) </desc> <cmt> fix ndarray assignment issue with basic index </cmt> <cmt> uncomment useful code </cmt>",fix ndarray assignment issue with basic indexing
602,"<desc> i am reviewing our demo env carefully, fixed the following. service traffic should serialize and deserialize the time bucket, otherwise, there is a chance service_traffic-0 generated. service traffic should serialize and deserialize the time bucket, otherwise, there is a chance service_traffic-0 generated. make top n results more clear about the owner. previously, the same endpoint names of different services look the same. sync ui. fix service traffic equal and hashcode method. the time bucket is not a part of the entity attribute. </desc> <cmt> make top n result more clear of owner. </cmt> <cmt> remove virtual node service and service instance source generation. </cmt> <cmt> sync ui. </cmt>","polish metrics logic, fix service traffic bug"
603,"<desc> fix #5322 1.add port attribute in configcenterconfig 2.when using zookeeper and configcenterconfig is null, set port attribute. 3.when setting address attribute, set the relevant properties like registryconfig if (address != null) { try { url url = url.valueof(address); setusername(url.getusername()); setpassword(url.getpassword()); updateidifabsent(url.getprotocol()); updateprotocolifabsent(url.getprotocol()); updateportifabsent(url.getport()); updateparameters(url.getparameters()); } catch (exception ignored) { } } follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> fix #5322 </cmt> <iss> 2.7.4.1registryconfigsetport() </iss>","[dubbo-5322]when using zookeeper and configcenterconfig is null,don't set port attribute."
604,"<desc> from react-native 0.64, react-native-codegen allows defining aliases for object literal types. this change reflect it on the codegen. i don't know why microsoft.reactnative.sln still compiles as these new structs are used in the spec but implementations are not changed. it is interesting that no module implementations are using react_struct except alert and deviceinfo. alert doesn't check the spec class when registering. deviceinfo doesn't contain constants in the spec. i will fix them in separate commits. microsoft reviewers: open in codeflow </desc> <cmt> split files </cmt> <cmt> generate struct fields </cmt> <cmt> update generated code </cmt> <cmt> emit react_struct and react_field </cmt> <cmt> make a new macro since react_struct cannot be used for nested struct </cmt> <cmt> change files </cmt>",generate aliased struct for turbo module
605,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> update select.md </cmt> <cmt> from final can be used not only with collapsingmergetree </cmt> <cmt> update select.md </cmt> <cmt> from final can be used not only with collapsingmergetree </cmt>,doc change. from final can be used not only with collapsingmergetree
606,"<desc> lb policies hold an arbitrary number of subchannels, with their corresponding fds. for performance reasons, not all of these fds can be linked to the call's pollset_set. however, they still need to be polled for the lb policies to be notified of changes in the subchannels's connectivity state. this pr leverages the background poller introduced in #12732 to poll the client_channel's interested parties very frequently in order to minimize delays in detecting subchannel activity. fixes #13081 #13080 #13128 #13159 reverts #13127 (re-enables tests) </desc> <cmt> bg-poll very frequently to pick up subchannels's updates in lb tests </cmt> <cmt> re-enabled all polling engines for lb tests </cmt>",make the bg poller poll very frequently in lb tests
607,<desc> fixes #14771 @guardrex please check it out :) </desc> <cmt> change endpoint from todo to todoitems </cmt> <cmt> update all references to the previous endpoint </cmt> <iss> blazor webassembly sample references a previous version of the api tutorial </iss>,update blazor webassembly sample to go at pair with the new webapi sample
608,"<desc> relands #26944 (was reverted in #27191) multicast_dns has landed internally, so this should no longer be an internal roll blocker. / fixes #23164 </desc> <cmt> discover port over mdns - needs tests </cmt> <cmt> appid parameter </cmt> <cmt> case insensitive parameter comparison </cmt> <cmt> cleanup printing </cmt> <cmt> merge </cmt> <cmt> update pub location to git for now </cmt> <cmt> unintentional change </cmt> <cmt> move vars, report error, remove requirespubspecyaml </cmt> <cmt> stray blank lines </cmt> <cmt> document class and move parameter </cmt> <cmt> tests for discovery, roll back user interaction </cmt> <cmt> remove unused import </cmt> <cmt> use published package </cmt> <cmt> newline </cmt> <cmt> merge </cmt> <cmt> fix checksum </cmt> <cmt> opt in, only for ios for now </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> pubspec </cmt> <iss> teach flutter_tools how to use mdns to find the ios observatory port </iss>",reland automatic discovery of observatory port for ios
609,"<desc> instead, generate them on demand. i'm not sure why we started to hard-code it, but i think it may have been just trickier to write? fixes #9605 </desc> <cmt> automatically generate cxa_find_matching_catch handlers, avoid hardcoding a limit. </cmt> <cmt> fix </cmt> <iss> error: undefined symbol: __cxa_find_matching_catch_24 </iss>",avoid hardcoding a limit to the number of args to cxa_find_matching_catch
610,<desc> the await for syntax seems to trick the command runner into thinking the task hasn't finished yet fixes #24261 </desc> <cmt> remove await for </cmt> <iss> fuchsia attach can hang due to await for </iss>,remove await for syntax from fuchsia log scanner
611,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> update outputinfo </cmt> <cmt> update outputinfo </cmt>,update of the outputinfo interface for the sharp module
612,<desc> avoid building swiftremotemirror for all targets by default. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> build-script: reduce the amount of debug output </cmt> <cmt> cmake: rename an obscure is_host flag to host_library </cmt> <cmt> cmake: pass down the host_library flag to _add_swift_library_single() </cmt> <cmt> cmake: build target libraries together with the stdlib </cmt> <cmt> this avoids building swiftremotemirror for all targets by default. </cmt>,build target libraries with stdlib
613,"<desc> amazingly, if you get the very latest visual studio 2015, it seems to work. (the initial visual studio 2015 does not work.) fixes #999 </desc> <cmt> starting work on antique support </cmt> <cmt> silencing some warnings (visual studio 2015) </cmt> <cmt> continuing </cmt> <cmt> cleaned one issue. </cmt> <cmt> updating the singleheader </cmt> <cmt> let us see what appveyor says. </cmt> <iss> vs2015, patch 3 (vs14.*) support. </iss>",this might enable building the core library under visual studio 2015
614,<desc> this pass consists of the following passes inside:: extract bright pass mip map blur pass combine pass </desc> <cmt> bloom pass inspired from unreal </cmt> <cmt> * extract bright pass </cmt> <cmt> * mip map blur pass </cmt> <cmt> * combine pass </cmt> <cmt> resize function in bloom </cmt> <cmt> resize function in bloom </cmt>,bloom pass - inspired from unreal engine
615,"<desc> improve clarity of the local option to formhelper#form_with and the configuration option that controls its implicit default. i brought this up in #41245. to summarize: the existing documentation is confusing because: the first line states the default behavior but that's misleading. the default behavior actually depends on a configuration option which might be different from the default in the project one is working in, and depends on the version of rails the project was generated by, and whether the default config has been changed during a subsequent upgrade, and whether the default config is overridden in the application config. the configuration option is named ""form_with_generates_remote_forms"" ""generates"" seems to indicate that it has something to do with the rails generator #form_with doesn't take a ""remote"" argument (like #form_for does) but the word ""remote"" is in the configuration option name it's inconsistent with its use of the terms ""remote"" and ""local"" and understanding it requires processing at least one double-negative my goal is to: document the option itself as a boolean, defining the behavior when two possible values are specified. reference the rails configuration option as a way to control behavior of this method when the local option is not provided to the method. document the default value of the configuration option to make it clear that the default value dependent on the version of rails. (this is most important because developers working in older applications may end up reading this documentation without realizing that the documentation is incorrect for their version of rails. also keep in mind that since the ""6.0 defaults"" are actually still part of the rails codebase, this documentation is referring to code/default values that are in the codebase, not code/default values that have been removed or changed completely.) closes #41245 </desc> <cmt> clarify #form_with local option documentation </cmt> <cmt> reword #form_with local option documentation </cmt> <iss> confusing documentation of formhelper#form_with and `form_with_generates_remote_forms` config </iss>",improve documentation of formhelper#form_with local option [ci skip]
616,"<desc> the methods are always present, and not ""maybe undefined"" as currently declared in the declaration file. documentation:  the methods were declared as optional in order to fix the tests, where the mocks did not include the parse method. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> platform: the parse and tostring methods are not maybe present, they are definitely present. </cmt> <cmt> platform: fixed the tests </cmt>",the parse and tostring methods are not maybe undef
617,<desc> i have followed (at least) the pr section of the contributing guide. closes #17215 closes #16631 </desc> <cmt> [docs] add margin between vertical slider examples (17215) </cmt> <cmt> [slider] add track prop (#17215) </cmt> <iss> [slider] hide the track </iss> <iss> [slider] reverse slider </iss>,add support for removed and inverted track
618,"<desc> this fixes #980. this makes each component report user activity. the mediatechcontroller and player need to disable this. mediatechcontroller reports user activity manually as it also handles hiding and showing of the control bar. the tap test should only focus on taps. </desc> <cmt> fix touch events. </cmt> <cmt> make components listen to touch events themselves. </cmt> <cmt> components can have a ""listentotouchmove"" property that would report </cmt> <cmt> user activity on touch moves. </cmt> <cmt> currently, the only problem left is that the mediatechcontroller emits </cmt> <cmt> tap events to show/hide the controlbar but that causes the control bar </cmt> <cmt> to not be hidden via a tap. </cmt> <cmt> remove unused var </cmt> <cmt> stop immediate propagation on tap events </cmt> <cmt> make media tech controller only hide control bar. </cmt> <cmt> enableuseractivity on component </cmt> <cmt> disableuseractivity on mediatechcontroller and player. </cmt> <cmt> mediatechcontroller does it manually. </cmt> <cmt> remove listentotouchmove. </cmt> <cmt> test is for tap events and not user activity </cmt> <iss> cant listen to touch events over the video element. </iss>",enable listening for touch events above the player
619,"<desc> backport #13603 to 3-0-x. </desc> <cmt> add api to return an unique id for page </cmt> <cmt> fix double-freeing remote references </cmt> <cmt> after the page does navigations, garbage collection can still happen in </cmt> <cmt> the old context. this commit changes to store references to remote objects </cmt> <cmt> by _pages_, instead of by _webcontents_. </cmt>",guard against double-freeing remote references (3-0-x)
620,"<desc> create react app is setting some default build infrastructure for react apps. we had an issue of deciding what's the default config is. now we support, create-react-app's settings as the defaults. that means, we could use react-storybook with create-react-app based projects without doing any webpack configurations. this comes with following core changes: add postcss based css loader. add file-loader for images and common types. add url-loader for shorter media files. do not pre-build manager(storybook ui) bundle. continue support for babel's stage-0 preset and add es2016 preset. </desc> <cmt> match default setup same as create-react-app. </cmt> <cmt> stop pre-building the manager </cmt> <cmt> this allow us to customize the manager dynamically. </cmt> <cmt> update manager for the production build. </cmt> <cmt> remove building source-maps. </cmt> <cmt> fix lint issues. </cmt> <cmt> improve static file handling. </cmt> <cmt> update dev docs. </cmt> <cmt> use dist directory for the manager's source. </cmt>",update defaults to match create-react-app
621,<desc> they are relative to the pixel density of the image. </desc> <cmt> thresholding: change the window and tile size parameters to relative numbers </cmt> <cmt> they are relative to the pixel density of the image. </cmt> <cmt> fix a mismatch between tprintf format string and args </cmt>,change the window & tile size params to relative numbers
622,<desc> this pr fixes #132651 </desc> <cmt> editors - first cut base editor with view state </cmt> <cmt> editors - make more view state management reusable </cmt> <cmt> editors - more code alignments </cmt> <cmt> editors - first cut view state support for side by side editors </cmt> <iss> allow to split an editor into two without creating separate tabs </iss>,refactor editor view state to be reusable and adopt for side by side editor
623,"<desc> this change introduces the correct storage_spec parameters when calling recommenddatastores() method from the pyvmomi plugin. this fixes incorrect datastore cluster placement recommendations during an ""add disk"" scenario for the vmware_guest_disk module. fixes #67100 see related issue for full conversation. vmware_guest_disk </desc> <cmt> fix sdrs recommendations </cmt> <cmt> fixes storage drs recommendation call for add disk scenario </cmt> <cmt> undo changes to whitespacing </cmt> <cmt> undo changes to whitespacing (pt. 2) </cmt> <iss> vmware_guest and vmware_guest_disk modules fail to return storage drs recommendations when using datastore clusters </iss>",vmware_guest_disk storage drs bugfix for get_recommended_datastore
624,"<desc> atm there are exactly two places where blockmanager.eval is called: dataframe._combine_match_columns and dataframe._combine_const.  this replaces the usage in _combine_match_columns with a dispatch-to-series implementation.  some output dtypes get changed (see edits in test_axis_select_reindex, test_pivot), and some errors get changed from valueerror to typeerror (see test_operators). the other usage of _data.eval will be removed separately; that turns out to be a lot more trouble because a bunch of dataframe behavior is currently incorrect (see #22017). this pr also: simplifies some of the special-casing in sparsedataframe; trying to move towards not having separate implementations for these methods dispatches _combine_match_index to avoid calling self.values when doing so would require coercing to object-dtype. </desc> <cmt> avoid casting to object dtype in mixed-type frames </cmt> <cmt> dispatch to series ops in _combine_match_columns </cmt> <cmt> comment </cmt> <cmt> docstring </cmt>","dispatch (some) frame ops to series, avoiding _data.eval"
625,<desc> just some updates to badges: uses the flat style for all badges that use shields.io adds lgtm.com badges (following all the alert fixes in recent prs that have now been merged. this should make it easier to track number of alerts.) </desc> <cmt> :memo: use flat badges where possible </cmt> <cmt> :memo: add lgtm.com badge in readme </cmt>,improvements to badges in readme
626,"<desc> bump go.d.plugin version to v0.29.0 component name packaging install this branch, ensure there are no errors, and go.d.plugin version is 0.29.0 </desc> <cmt> packaging: update go.d.plugin checksums </cmt> <cmt> packaging: bump go.d.plugin version to v0.29.0 </cmt>",update go.d.plugin version to v0.29.0
627,<desc> remove both the active cluster and warming cluster if cds response told so. fixed both sotw and delta. risk level: mid since the bad behavior exist for long time. testing: fixed unit tests and integration test. added new integration test. fixes #13994 </desc> <cmt> clean up </cmt> <iss> warming cluster is not removed at new cds response </iss>,remove warming cluster if cds response desired
628,"<desc> i added the missing swift sections from the xcode release notes to changelog.md and formatted them for display on github. preview here they're not as granular by date as the previous sections, but at least the history is filled in. no code changes. / </desc> <cmt> minor formatting tweaks to changelog.md </cmt> <cmt> add missing xcode 6.1 and swift 1.1 release notes </cmt> <cmt> add missing xcode 6.1.1 release notes </cmt> <cmt> add missing xcode 6.3 and swift 1.2 release notes </cmt> <cmt> add missing xcode 7.0 and swift 2 release notes </cmt> <cmt> add missing xcode 7.1 and swift 2.1 release notes </cmt> <cmt> update changelog.md formatting </cmt>",update changelog.md with missing content
629,"<desc> headers unneeded usings files need blank line at bottom fixed double returns returns after braces stylecop is commented out but still in the csproj's pr checklist applies to #5295 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? validation steps performed how does someone test & validate? </desc> <cmt> headers </cmt> <cmt> unneeded usings </cmt> <cmt> files need blank line at bottom </cmt> <cmt> fixed double returns </cmt> <cmt> returns after braces </cmt> <cmt> commenting out stylecop </cmt>",smaller stylecop fixes in wox.core and wox.infra
630,"<desc> restore ""jump to chart"" functionality from the alarms modal, that was lost when we prevented page scrolling when a modal is open. all chart names can now be searched with browser control-f (searching statsd metrics is now working) updated to fontawesome free 5.0.1 </desc> <cmt> restore jump to start from the alarms modal </cmt> <cmt> allow charts to be searched with browser control-f </cmt> <cmt> updated to fontawesome-free-5.0.1 </cmt>","restore ""jump to chart"" from alarms modal"
631,"<desc> make the cli arguments optional add early check for files count (bail when len(filenames == 0) add --dict argument (when set, this will use the first half of the file as a dictionary for the second half) example: benchmark using the first half of silesia files as the dict for the second half and compare the current hash to facebook:dev python automated_benchmarking.py --mode current --dict true --dir ~/silesia </desc> <cmt> make arugments optional and add --dict argument </cmt> <cmt> removing accidental print statement </cmt>",make arguments optional and add --dict argument
632,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): added support startswith, endswith, multisearchany, notlike for mergetreeindexfulltext. added support startswith, endswith, multisearchany for mergetreeindexset. added support empty, notempty, notlike for primary key. </desc> <cmt> primary key and mergetreeindexfulltext support for string functions </cmt> <cmt> minor style changes </cmt>","primary key, mergetreeindexfulltext and mergetreeindexset support for string functions"
633,"<desc> this pr implements support for threads and cluster into redis-benchmark. multi-thread support by default, redis-benchmark will be launched in single-thread mode as usual. in order to launch it in multi-thread mode, you can use the --threads option, ie: redis-benchmark --threads 6 the command above will launch redis-benchmark with six threads. cluster support redis benchmark can now work with clusters. this can be done by using the --cluster option. the redis instance which redis-benchmark will connect to will be used as the cluster entry point. examples: redis-benchmark --cluster -p 7000 the line above will launch redis-benchmark in cluster mode and will use the instance with port 7000 as the cluster entry point. when launched in cluster mode, redis-benchmark will implicitly start in multi-threading mode too. by default, it will use one thread for each master node found in the cluster. anyway, you're free to change this default configuration by explicitly pass the --threads option, ie: redis-benchmark -p 7000 --threads 6 --cluster # if the cluster has three masters, use two threads per master node when launched in cluster mode, you can use the special {tag} placeholder inside the key names in order to let redis-benchmark use slot hash tags, in a similar fashion of the __rand_int__ placeholder. in this case, redis-benchmark will automatically replace the {tag} placeholder with the proper slot hash tag depending on which master node is querying. example: redis-benchmark -p 7000 --cluster get mykey:{tag} default redis-benchmark's tests already have the {tag} placeholder in their key name(s). you're free to mix the {tag} placeholder and the __rand_int__ placeholder in order to be sure that every thread uses random and different keys (remember to use the -r option to enable the key name randomization). example: redis-benchmark -r -p 7000 --cluster get mykey:{tag}:__rand_int__ when working in cluster mode, redis-benchmark will always fetch the cluster configuration before starting the test(s). anyway, if some slot is moved during the tests (ie. because of a resharding), after receiving an ""ask/moved"" reply error, redis-benchmark will fetch the cluster configuration again in order to update it. the configuration update will be atomically handled by threads. </desc> <cmt> thread support for redis-benchmark. </cmt> <cmt> added basic support for clusters to redis-benchmark. </cmt> <cmt> redis benchmark: table-based slot hashtag placeholder replacement in cluster mode. </cmt> <cmt> various changes to redis-benchmark thread and cluster support </cmt> <cmt> - moved or ask replies are now handled in cluster mode. </cmt> <cmt> - only the first slot per node is used in cluster mode. </cmt> <cmt> - mutlithreading: reduced usage of mutexes in favor of atomic vars. </cmt> <cmt> redis benchmark: configurable thread count in cluster mode and fixes </cmt> <cmt> redis benchmark: fixed issued with config.hostip and code cleanup </cmt> <cmt> redis benchmark: add {tag} to all default tests </cmt> <cmt> redis benchmark: display 'save' and 'appendonly' configuration </cmt> <cmt> redis benchmark: use atomic var for liveclients in 'createclient' </cmt> <cmt> redis benchmark: update slots configuration after moved/ask reply </cmt> <cmt> redis benchmark: fix default hset test key </cmt> <cmt> redis benchmark: update help with threads/cluster options </cmt>",multithread support and cluster support
634,"<desc> introduces a new series of node settings xpack.security.authc.domains.<domain_name>.realms: <realm_name_list>. the setting sets the domain property on realm and realmconfig instances. the domain property ought be subsequently used in order to determine if two identical usernames are the same personas, and hence can share ownership (of profiles, keys, tokens, scrolls), even though they authenticated via different realms (but which are associated under the same domain). </desc> <cmt> domain to realm </cmt> <cmt> maybe </cmt> <cmt> spotless </cmt> <cmt> main </cmt> <cmt> javadoc </cmt> <cmt> nit </cmt>",introduce domain setting to associate realms
635,"<desc> the original author of #2522 hasn't returned to github in more than 2 months, so i'll take the courtesy of completing that pr. basically what's been proposed in the original pr, plus my own review suggestions applied. side change rewritten _include/video to use a case-when clause for the iframe src attribute, so other html attributes need not repeat for each video provider. #2522 </desc> <cmt> enhance support for bilibili videos in responsive video helper, and add corresponding doc </cmt> <cmt> apply @ibug's review in mmistakes/minimal-mistakes#2522 </cmt>",enhance bilibili video support (redo of #2522)
636,"<desc> for pyston some tests fail due to implementation details pyston/pyston#62 (no recursion limit and ""immortal"" objects), these are marked as skip. </desc> <cmt> skip test for recursionerror on pyston, since it disables recursion checking </cmt> <cmt> for pyston the refcount of ""immortal"" objects is set to ~infinity </cmt>",skip finite recursion and refcounting tests for pyston
637,"<desc> this also adds mathutils to the desktop jni bindings, which was missing (unless this was done on purpose?) </desc> <cmt> add javadoc for colors </cmt> <cmt> add javadoc for box </cmt> <cmt> ad javadoc to mathutils </cmt> <cmt> add mathutils to desktop jni bindings </cmt>","add javadoc for colors, box, and mathutils"
638,<desc> commit 9934a0a has changes that affect the global salt configs. everything else is azure specific. fixes #1731 #1485 </desc> <cmt> deploy update </cmt> <cmt> updates and formatting to azure scripts. </cmt> <cmt> update cert generation for azure. </cmt> <cmt> remove azure from icebox. </cmt> <cmt> update readme.md </cmt> <cmt> update azure. </cmt> <cmt> bring azure guide up to date. </cmt> <cmt> rearrange cluster sanity checks for azure. </cmt> <cmt> merge readme changes. </cmt> <iss> azure deployment is broken with binary-deploy </iss>,bring azure deploy scripts up to date
639,<desc> the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> add variant zigbee </cmt> <cmt> add variant zigbee </cmt> <cmt> add variant zigbee (#196) </cmt>,add variant zigbee to github actions (ci and build)
640,"<desc> follow the advice from the readme. increase the version number in the header if appropriate.  this is still valid for the current version. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix optional types </cmt> <cmt> fix optionals </cmt> <cmt> fix optionals </cmt>",tabulator-tables  - minor fixes to optional types
641,"<desc> fix for the issue described in #2785. when serializing an dict or object, now the default value is used if the key or attribute is missing from the dict or object. previously a keyerror or attributeerror was raised. two tests failed after implementing the change, which was to be expected as they specifically targeted the behaviour of key or attribute being required even if default is set for the field (serializers.py, testnotrequiredoutput). they have been replaced by tests targeting the use of defaults when key or attribute is not present in the instance. deserialization seems unaffected. what isn't clear to me is what the rationale was of explicitly requiring the instance key/attribute to be present, even if a default is provided, so i'm wondering if there's a scenario i'm overlooking. </desc> <cmt> default value will now be used when serializing if key or attribute is missing. </cmt> <cmt> removed no longer needed tests. </cmt> <cmt> added tests for using default when default is callable. </cmt> <cmt> fixed field get_attribute(), now uses get_default() instead of default. </cmt> <cmt> documentation update. </cmt>",allow required false and default
642,"<desc> rewritten nginx, phpfpm and apache modules to use wrappers on chart creation (methods: chart,  dimension, begin, set, end). created intermediate class simpleservice which is now a base for urlservice. as requested in #628, new logservice prototype was created which is also a child of simpleservice wrote new apache_cache module to parse apache mod_cache log file. i have done some basic test, but not on apache_cache. probably needs some more testing, which i will do when i find some time. </desc> <cmt> rewrite apache, nginx and phpfpm plugins to use wrappers on chart creation </cmt> <cmt> create simpleservice </cmt> <cmt> move all url variables from simpleservice to urlservice </cmt> <cmt> add check() method in simpleservice </cmt> <cmt> logservice prototype </cmt> <cmt> apache_cache python module </cmt> <cmt> fix default apache url </cmt> <cmt> error messages </cmt>",wrappers around charts creation + logservice
643,"<desc> a suggestion for improving docs. i spent a while trying to figure out where additional configmaps are uploaded to the halyard pod on a k8s spinnaker deployment so they could be used in config scripts, and this one line would've helped. i realize spinnaker is deployed on multiple kinds of infra, not just k8s, which is why i didn't mention a halyard pod, but maybe there's a better way to make this note generic. dco signed </desc> <cmt> move the api_host variable to deck.yml, where it belongs </cmt> <cmt> bump chart version for gate fix </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> noting where additional config maps are written to disk may be helpful to beginners </cmt>",add note to spinnaker doc about destination path for additionalconfigmaps
644,<desc> this is a port of #5605 for the 11.3 branch passing system test on branch builder </desc> <cmt> minor:updates for new versions </cmt> <cmt> minor:missing import for kafkaexception </cmt> <cmt> minor:fixed parameter in test - result from bad cherry pick? </cmt> <cmt> minor:update url to match new kafka packages location </cmt>,update streams upgrade system tests 0.11.0.3
645,"<desc> the onnx page is currently broken due to some name changes. the api reference is blank:  i fixed the overview table to link to things and now have the api reference appearing. i also updated the description text. sphinx won't render any shortcut references to the functions, so i'm calling them out the long way. when the python config for these onnx modules are updated we can try out the shorthand references and see if sphinx likes it or not. there are lint issues showing up in the docs build logs from these onnx files as well as many other files. i'll create a separate issues for these comments. </desc> <cmt> update onnx api references </cmt> <cmt> update descriptions </cmt>",update onnx api docs references
646,"<desc> fixes #12416 this pr detects a mismatch between cls and a checkpoint a user intends to load. however, it can't find a mismatch when a config doesn't contain the tokenizer's information. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> detect mismatch by analyzing config </cmt> <cmt> fix comment </cmt> <iss> berttokenizer with bertjapanesetokenizer pretrained model generates unintended tokenization. </iss>",add tokenizers class mismatch detection between cls and checkpoint
647,<desc> i hereby agree to the terms of the cla available at:  i've translated half of the clickhouse documents into persian. they are: introduction getting started interfaces data types remaining pages: sql reference operations f.a.q the rest of these will be translated for the next few days. one thing is some sentences are very difficult to translate. i'm trying to improve the translation. thanks. </desc> <cmt> initial translate fa. translate index.md </cmt> <cmt> complete what is clickhouse? translate </cmt> <cmt> translate distinctive_features to farsi </cmt> <cmt> fix align </cmt> <cmt> translate features_considered_disadvantages to farsi </cmt> <cmt> translate performance page to farsi </cmt> <cmt> translate ya_metrika_task page to farsi </cmt> <cmt> translate getting_started.index.md to farsi </cmt> <cmt> fix align </cmt> <cmt> translate getting_started.example_dataset.ontime to farsi </cmt> <cmt> translate getting_startet.example_dataset to farsi </cmt> <cmt> translate command-line client interface to farsi </cmt> <cmt> translate entire interfaces to persian </cmt> <cmt> 90% of data types category to persian </cmt> <cmt> complete translate data type to persian </cmt>,translate clickhouse documents into persian
648,"<desc> description: scan_interval and interval_seconds (on device_tracker) will now work for any interval between 1 second and 1 day whereas without this they only work between 1 and 60 seconds. intervals are not always respected perfectly. for instance, if you want a 25 second interval it is rounded up to a 30 second interval. related issue (if applicable): fixes #5080 pull request in home-assistant.github.io with documentation (if applicable): example entry for configuration.yaml (if applicable): device_tracker: - platform: nmap_tracker hosts: 192.168.1.1/24 interval_seconds: 240 home_interval: 15 checklist: documentation added/updated in home-assistant.github.io if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> update scan_interval and interval_seconds max to 1 day vs. 60 seconds </cmt> <cmt> format fixes </cmt> <iss> scan_interval doesn't allow intervals greater then 60 seconds. </iss>",support longer-than-60-second scan_interval and interval_seconds
649,<desc> not exactly my favorite fix. but everything else would lead to redoing the whole method. might break if there are different cores with different specifications? @koying @martijnkaijser @a4840639 </desc> <cmt> fix debug bar not showing all cpus on android </cmt> <cmt> code modernization </cmt>,show all cpus in debug overlay
650,"<desc> closes #242 removed redundant checks for null, when it will already be handled by calling 'delete' </desc> <cmt> removal of null check </cmt> <cmt> removed the redundant check for null which is already correctly handled </cmt> <cmt> by used the delete </cmt> <cmt> removal of null check </cmt> <cmt> removed the redundant check for null which is already handled by using </cmt> <cmt> delete </cmt>",removes redundant null pointer checks checks
651,"<desc> cleanup of ppo, appo, and dd-ppo code (equivalent to previous pg one): add type annotations. get rid of loss class. add comments and explanations to everything we do in ppo. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip </cmt> <cmt> merge </cmt> <cmt>  conflicts: </cmt> <cmt> 	rllib/evaluation/rollout_worker.py </cmt> <cmt> wip. </cmt>","ppo, appo, and dd-ppo code cleanup."
652,<desc> this pr fixes the problem that in some server-side sdks no user data is attached to session data and so no users adoption metric information it solves this by calculating adoption based on sessions in addition to users adoption calculations </desc> <cmt> added tests for calculating release adoption in sessions mode </cmt> <cmt> added logic that allows adoption to be calculated either based on sessions or users </cmt> <cmt> modified adoption calculation to return both users and sessions adoptoin </cmt> <cmt> added sessions adoption to adoption calculation tests </cmt>,add session adoption to release-health
653,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. not adding any substantial changes </desc> <cmt> addcustomattribute takes a string or a number </cmt> <cmt> added brooks patton to contributors for new relic </cmt> <cmt> bumped minor version </cmt>",newrelic functions addcustomattribute and addcustomattributes takes strings and numbers
654,"<desc> this should tidy up the javadoc generation and the hystrix-contrib project. </desc> <cmt> use classpath, which is being changed by provided, instead of default </cmt> <cmt> nebula-30 fixing javadoc arguments. using proper delegate in javadoc closure, add custom string option </cmt> <cmt> nebula-28 preventing contrib project from being uploaded </cmt> <cmt> nebula-31 ignore output from gradle maven ant tasks </cmt>","fixes for nebula-28, nebula-30, nebula-31"
655,"<desc> this memoize shadowcreatepagepath in actions.createpage to avoid rerunning it for same inputs. this is not ideal, because we could have memoized potentially stale output, but webpack part of shadowing doesn't invalidate when there are changes in shadowing chain right now, so it's acceptable. this will need memo cache busting when webpack part will be looked at </desc> <cmt> perf: memoize shadowcreatepagepath </cmt> <cmt> more info </cmt>",memoize shadowcreatepagepath to fix performance regression
656,<desc> this change adds infrastructure for geoshape making it accessible via the new scripting fields api. this does not add any methods outside of get at this point in time since it needs additional thought/discussion on what makes sense similar to geopoints. note that because geoshape does not support xcontent this is just a skeleton that currently supports getscriptdocvalues. </desc> <cmt> add a geoshape field to the scripting fields api </cmt> <cmt> add skeleton for painless allow list </cmt> <cmt> add tests </cmt>,add support for geoshape to the scripting fields api
657,<desc> add test to run 500 nodes 10k actors. we can bump this up later. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add tests to nightly test </cmt> <cmt> up; </cmt> <cmt> up </cmt> <cmt> up </cmt>,add x nodes y actors test to nightly tests
658,"<cmt> msa-757: smart gas-lock work with z-wave </cmt> <cmt> msa-786: description from the app : ""with visible realtime energy usage status, have good energy habits and enrich your life"" </cmt> <cmt> this app is specialized to show energy data which was grabbed from encored technologies' device that user installed at their home. </cmt> <cmt> modifying 'timevalve smart' </cmt> <cmt> added gentle wake up controller, updated smartapp </cmt> <cmt> added gentle wake up controller, updated smartapp </cmt> <cmt> update timevalve-smart.groovy </cmt> <cmt> commenting out fingerprint temporarily to avoid potential conflicts with other devices as this devices is specifically for a korean deployment in ap01 - see dvcsmp-1425 </cmt> <cmt> msa-786: encored technologies : smart energy service </cmt> <cmt> msa-757: timevalve smart </cmt> <cmt> merging changes into stage </cmt>",merging changes into prod from staging
659,"<desc> the shortcut cmd + u or  ctrl + u is used to delete the content of current cursor back to the start of line, not always delete the whole line </desc> <cmt> the shortcut cmd + u or the ctrl + u is used to delete the content of current cursor back to the start of line, not always delete the whole line </cmt> <cmt> fixed </cmt>",fixed the description of ctrl + u
660,<desc> added a couple mixdown utility methods. also added ability to start an encode via json string rather than the model. this is handy for a debug feature where you can copy a json job from the log and tweak it quickly to see what happens. added the .vs folder to .gitignore. </desc> <cmt> some additions for mixdowns and ability encode from json string. </cmt> <cmt> excluded .vs folder via gitignore. </cmt>,mixdown additions and direct json jobs
661,"<desc> this pr does the following: the list of predefined mime types to a dedicated file (so that it could be handled more easily) generate the list from the mime.types file of nginx fixes #254 </desc> <cmt> move the list of default mime-types to a dedicated file (so that it coould be generated automatically) </cmt> <cmt> build the default list of mime-types from that of nginx, using </cmt> <iss> even more mime types ? </iss>",yet more mime-types by default
662,"<desc> re-enables dynamic bitrate that was disabled in #5165 and fixes a long-standing issue with the dynamic bitrate feature. as dynamic bitrate is calculated and applied when a packet is sent, it runs in the context of whatever thread is outputting a packet such as the audio output thread. that thread would then try to reconfigure the video encoder while the encoder thread could be in the middle of encoding. x264 handles this situation correctly, but nvenc (and possibly others) deadlock with no error visible to the user. this pr introduces a new encoder field, reconfigure_requested, which when set to true by an obs_encoder_update call, will cause the appropriate encoder thread (both regular and gpu) to call encoder->info.update before the next encode call. obs_encoder_update no longer calls encoder->info.update directly but still applies the settings. freezing output with no explanation is bad. disabling dynamic bitrate entirely is also bad. i changed dbr update interval to 1 second and limited my wan upload rate to between 1000-5000kbps. the current code, when run with nvenc, deadlocked after three minutes / 247 bitrate changes. the new code did not experience any issues after four hours / 20,162 bitrate changes. i also disabled jim-nvenc and tested ffmpeg nvenc dynamic bitrate still worked correctly. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> revert ""obs-ffmpeg, obs-qsv11: disable dynamic bitrate support"" </cmt> <cmt> this reverts commit 1b29bfc88419515fa423804fac4411794c4df745. </cmt> <cmt> libobs: defer reconfiguring encoders to the encode threads </cmt> <cmt> fixes a long-standing issue with dynamic bitrate where the rtmp output </cmt> <cmt> thread could try to reconfigure an encoder while the encoder is in the </cmt> <cmt> middle of encoding. x264 seems to handle multithreaded calls well, but </cmt> <cmt> nvenc would deadlock in this situation with no error visible to the </cmt> <cmt> user. </cmt>",defer encoder reconfiguration to encode threads (fixes dynamic bitrate freeze)
663,"<desc> what do these changes do? added a documentation tutorial (with graphics) on profiling the performance of a basic ray example using python time, python cprofile, line_profiler (a third-party profiler), and the ray timeline web ui. there is an existing documentation page profiling.rst for ray developers, so i put mine's as a separate page user-profiling.rst under the same help section. no issue number. requested by @pcmoritz </desc> <cmt> ray documentation - created new section 'profiling for ray users', opposed to current profiling section for ray developers. completed three sections 'a basic profiling example', 'timing performance using python's timestamps', and 'profiling using an external profiler (line_profiler).' left to-do two sections on cprofile and ray timeline visualization.' </cmt> <cmt> ray documentation - fixed rst codeblock linebreaks in 'user profiling' </cmt> <cmt> ray documentation - for user profiling, added section on cprofile </cmt> <cmt> ray documentation - for user profiling, completed ray timeline visualization section, including graphical images </cmt> <cmt> ray documentation - made user profiling timeline image larger, minor wording edits </cmt> <cmt> ray documentation - minor wording edits to user profiling </cmt> <cmt> ray documentation - user profiling- fixed broken link </cmt>",documentation- basic profiling for ray users
664,"<desc> fixes .app bundle crash (regression from #23244). add additional context updates (sdl fix linked in #23100 comment), main window content should always update correctly, splash screen is not fully fixed. fixes #23307, fixes #23496, related #22689 </desc> <cmt> fix .app bundle crash on macos </cmt> <cmt> fix initial blank screen on macos mojave (except splash). </cmt> <iss> osx 3.1 latest build crashes </iss> <iss> current godot alpha crashes on mac osx(mojave) </iss>",fix .app bundle crash and blank initial window
665,"<desc> currently, plasma running as thread actually has been enabled by default (because java launches ray using python scripts).  some critical functions like object spilling are also assuming that plasma store is running as a thread. so the outdated code path is no longer used and it is not functioning correctly. however, some c++ tests are using plasma store running as a process for testing, this is not good because they are not testing what we are currently using. this pr removes the outdated plasma store executable and migrates those tests. this also reduces the size of our wheel build. this pr may be required to pass some tests in #14924 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> remove plasma store executable & never used tests </cmt> <cmt> lint </cmt>",remove code paths that contains plasma store executable
666,"<desc> this pull request introduces a new, temporary and experimental flag '-enable-astscope-lookup' that reimplements unqualified name lookup in terms of the new astscope data structure. there are some outright bugs in this new name lookup implementation, as well as a number of places where the implementation needs to perform more semantic analysis because we were relying on (weird, indefensible, but convenient) name lookup behavior to diagnose problems. </desc> <cmt> [scope map] query the declarations introduced by a given ast scope. </cmt> <cmt> introduce an operation that produces the set of local declarations </cmt> <cmt> that are newly introduced by a given ast scope. this is a building </cmt> <cmt> block of unqualified name lookup, which walks upward in the tree </cmt> <cmt> (e.g., from children to parents) looking for declarations that have </cmt> <cmt> been made visible at each step. </cmt> <cmt> [name lookup] add a staging flag for astscope-based name lookup. </cmt>",introduce unqualified name lookup based on astscopes
667,<desc> example project dependency upgrade. for  #11188 project dependency upgrade details springframework 4.3.20.release upgrade to 5.0.13.release springboot 1.5.17.release upgrade to 2.0.9.release mybatis 3.4.2 upgrade to 3.5.1 mybatis-spring 1.3.0 upgrade to 2.0.1 hibernate 4.3.11.final upgrade to 5.2.18.final project upgrade details example-core governance-spring-boot-example other-feature-example sharding-example/sharding-spring-boot-jpa-example sharding-example/sharding-spring-boot-mybatis-example transaction-example </desc> <cmt> upgrade pom dependency management </cmt> <cmt> upgrade governance-spring-boot-example </cmt> <cmt> upgrade other-feature-example </cmt> <cmt> upgrade sharding-example/sharding-spring-boot-jpa-example </cmt> <cmt> upgrade sharding-example/sharding-spring-boot-mybatis-example </cmt> <cmt> upgrade transaction-example </cmt> <cmt> upgrade example-core </cmt>,example project dependency upgrade. (#11188)
668,"<desc> part of #643, covers test case for #565 </desc> <cmt> add test </cmt> <cmt> drop host header as well, so that header copying can be as simple as the prev. commit </cmt> <cmt> drop transfer-encoding header passed from downstream (since the content is already decoded, and also not to require the header copying logic in rack apps to specifically drop the header when calling http_request) </cmt>","adjust request header handling, add tests"
669,<desc> this allows the configuration of the plugin to have multiple collections. also adapted the mapping feature to use a collection and then his mapping. it is also backwards compatible. </desc> <cmt> bring my fork up to date </cmt> <cmt> merge from master </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add multi collection functionality </cmt> <cmt> change config in using site </cmt> <cmt> adapt readme to the new functionality </cmt>,add multiple collections to the config
670,"<desc> allow dashboard sending cookies on all requests, fixes #477 allow netdata respect donottrack, according to #416 (comment) and instructions given at efforg/privacybadger#850 and efforg/privacybadger#781 this feature is disabled by default. to enable it set [global].respect web browser do not track policy = yes. when enabled the following will happen: for browsers sending the http header dnt: 1, the registry will refuse to serve them. all responses will have the http header tk: t (tracking), or tk: n (not tracking) depending on whether a cookie is used by netdata or not. allow netdata generate svg badges. a demonstration wiki page will be added once this is merged. </desc> <cmt> allow cookies on all requests to support running netdata behind an authentication web server </cmt> <cmt> added option and code to respect </cmt> <cmt> added support for generating svg badges with chart data </cmt> <iss> dashboard.js - cross-domain authentication problems </iss>",allow cookies on all requests; respect donottrack; generate svg badges
671,"<desc> adds operator sum(csr, axis=0) = dense and sum(csr, axis=1) tried 128*100m shape csr matrix and was able to perform sum along axis 0 and 1. density is 0.1% allocation fails for 128*100m for dense ndarray, for 1m and 10m the speedup for sparse operator is 300x for 1m and 1200x for 10m for density of 0.1%(uniform distribution) completes one todo in #8168 @eric-haibin-lin @reminisce @cjolivier01 @piiswrong </desc> <cmt> add infer storage for sparse slice operator </cmt> <cmt> remove unused files </cmt> <cmt> indentation fix and add gpu test for fallback </cmt> <cmt> change sum builtin to py_sum </cmt> <cmt> add sum_axis(csr,axis=0)=dense and sum(csr,axis=1)=dense operator </cmt> <cmt> documentation changes for sparse </cmt> <cmt> add fallback unittest for keepdims and exclude </cmt>","operators for sum(csr, axis=0) and sum(csr, axis=1)"
672,<desc> i spotted a race condition on my previous pr #8104. the problem affects only the case of finite generators and has no effect on the infinite ones. this pr fixes the bug and updates the test to capture similar problems. please check the github comments on the code where i explain where the problem was and how i fixed it. feedback is always welcome! :) </desc> <cmt> fixing race condition </cmt> <cmt> check again for empty queue after detecting that all threads have finished. </cmt> <cmt> updating the test to check for all set items </cmt>,fixing finite generator race condition
673,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. i am trying to follow all the steps but this is my first contribution to definitelytyped. </desc> <cmt> update react-boostrap-table-next </cmt> <cmt> update selectrowprops interface bgcolor property and some comas to semicolons. </cmt> <cmt> updated bgcolor to have all possible types. </cmt>",update selectrowprops interface small change to bgcolor
674,"<desc> issue: #2537 implemented support in a11y-addon for delayed rendering of components by adding a ""re-run tests"" button within the panel. i also corrected the contrast of the addon's tabs (to 7:1) and added the number of violations and passes to each tab (because if you re-run, the number may change, but you wouldn't know until you navigated to the tab). there's a story called ""accessibility"" in cra-kitchen-sink that demonstrates a11y-addon with a regular button and with a button that doesn't render until 1s after the preview loads. in order to verify that it works, click the ""re-run tests"" button. (ideally, we would be able to verify that results are displayed in the tab.) </desc> <cmt> implement pr #2537 </cmt>",handle a11y for components with delayed rendering
675,"<desc> this pr implements native filter and cross filter api simplification efforts introduced in apache-superset/superset-ui#1040 and apache-superset/superset-ui#1053 . the following changes are done: setdatamask hook now has new structure: { filterstate: { value: any, ...otherprops: any } ownstate: { ...otherprops: any } extraformdata: extraformdata } nested append_form_data and override_form_data fields in extraformdata type are moved up one level into the main filter object currentvalue removed from formdata now it passed in props.filterstate.value in superchart injected ownstate and filterstate fixed bug when remove cross filter from dashboard it's wasn't from dashboard metadata fixed bug that filter_select was attached to filterboxes fixed bug that when user just added cross filter without setting, it's scoping filter not appeared in filter badge migrate old filter set metadata to new format upgrade python code for legacy charts that depend on viz.py affected areas: native filters cross filters own state of charts filter sets test plan all frontend + backend unit tests have been updated, and a test for the migration has been added to ensure that both up and down migrations produce expected results. includes db migration (follow approval process in sip-59) runtime estimates and downtime expectations provided: only affects dashboards with filter sets. will only affect environments running the dashboard_native_filters_set feature flag </desc> <cmt> refactor: updates usage of ownfilters to ownstate </cmt>",update datamask and extraformdata schema
676,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: v4.7.0 v4.7.1 v4.7.2 yaireo/tagify@7d7f683 yaireo/tagify@cd611a9 </desc> <cmt> customize invalid tags messages </cmt> <cmt> userinput setting </cmt> <cmt> dropdown.toggle() method </cmt> <cmt> test tagify.texts </cmt> <cmt> bump version 4.7 </cmt>,"update settings, bump version 4.7"
677,"<desc> changelog: statefulset instead of deployment for slave component. separate pvc for each role (master, slave) related with these issues && pr: #2527 #2543 #2539 #2386 </desc> <cmt> update redis image </cmt> <cmt> delete blank lines </cmt> <cmt> fix chart version </cmt> <cmt> delete tailing spaces </cmt> <cmt> new line </cmt> <cmt> new line character in the end </cmt> <cmt> fix persistance volume claim | pvc was pointing to a wrong claim </cmt> <cmt> add image repos in chart's sources </cmt> <cmt> create 2 pvc for master and slave components and update slave deployment to statefulset </cmt> <cmt> bump to version 0.3.0 </cmt>",replace slave deployment to statefulset + create separate pvc for masters and slaves
678,"<desc> added to readme, releases, cars test route added to test_routes.py route with openpilot: bf43d9df2b660eb0|2021-09-23--14-16-37 thanks to community santa fe owner er3#3623 (discord id). </desc> <cmt> add fingerprint: hyundai santa fe 2022 </cmt> <cmt> update lfahda_mfc: add 2022 hyundai santa fe </cmt> <cmt> add car port: hyundai santa fe 2022 </cmt> <cmt> add test route: hyundai santa fe 2022 </cmt> <cmt> update releases.md </cmt> <cmt> update cars.md </cmt>",add car port for 2022 hyundai santa fe
679,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: negomi/react-burger-menu@d174cd5 negomi/react-burger-menu@156e932 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update types to match version 2.6.8 </cmt> <cmt> add myself to definitions by </cmt>",add missing types to match v2.6.8
680,"<desc> this pr backports the following prs to 1.28: xds: fix duplicate lds update detection gracefully switch xds policy instances when cluster name changes. after this pr, to the best of my knowledge, #22400 is the only blocker for the 1.28 release. </desc> <cmt> xds: fix duplicate lds update detection </cmt> <cmt> gracefully switch xds policy instances when cluster name changes. </cmt>",backport #22388 and #22371 to 1.28
681,"<desc> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. update ses options typings to match this version add version of createtransport to nodemailer which accepts ses transport as options remove templatesender from transport type since this doesn't seem to exist any more query: there seem to be two versions of nodemailer-ses-transport around, one merged in with nodemailer and one separately. the separate one seems to be what the typings are based on, but the combined one seems to have been updated more recently. first pr - typescript wasn't working for me with these packages so i thought i would try to fix it for everybody - any advice appreciated. </desc> <cmt> update ses transport types to match current nodemailer </cmt> <cmt> updated tests </cmt> <cmt> updated version number </cmt>",update ses nodemailer typings to match current implementation
682,"<desc> in case of a new cheat sheet, you have used the cheat sheet template. all the markdown files do not raise any validation policy violation, see the policy. all the markdown files follow these format rules. all your assets are stored in the assets folder. all the images used are in the png format. any references to websites have been formatted as text the ci build of your pr pass, see the build status here. </desc> <cmt> add note about imdsv2 </cmt> <cmt> add toc </cmt>",add toc and note about aws imdsv2
683,"<desc> renamed matrix keymap to layout_numpad_4x4 keymaps refactored: #include qmk_keyboard_h matrix renames readability updates added info.json file added layouts = numpad_4x4 to rules.mk </desc> <cmt> matrix refactor: rename keymap to layout_numpad_4x4 </cmt> <cmt> keymap refactor: qmk_keyboard_h, matrix renames, readability </cmt> <cmt> configurator support </cmt> <cmt> add numpad_4x4 layout to rules.mk </cmt>",roadkit refactor and configurator support
684,"<desc> related to #59255 this pr would begin to issue a deprecation warning when running a date range, date histogram, or auto date histogram over a boolean field.  this is currently permitted, but is unlikely to be what the user intended to do, as a histogram over the values [0, 1] is not terribly useful.  one possible way users could encounter this situation would be an index pattern that includes indexes with different mappings. </desc> <cmt> deprecate running date histogram on booleans </cmt> <cmt> deprecate running histogram on booleans </cmt>",deprecate date aggregations on boolean fields
685,"<desc> hi, this pr adds a note about the default weight initializer to the tf.layers.dense and tf.layers.dense docstrings to clarify how the default weights are initialized as discussed in #9744 . </desc> <cmt> add docstring note about dense weight initializer </cmt> <cmt> add docstring note aboutthe dense class weight initializer </cmt>",add a note about how weights are initialized in dense/dense to the docstrings
686,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> updated google-libphonenumber utils function with formatoutofcountrycallingnumber that was missing </cmt> <cmt> updated spaces </cmt>",added missing formatoutofcountrycallingnumber function to definitions of google-libphonenumber
687,"<desc> seems like i was too optimistic in assuming connections would always come in the same order! also consistently named conns to relationships throughout the file, added myself as an author and clarified a couple of comments. @mrdoob i also came up against an issue where a single skeleton is shared between two meshes - is this something that is supported in three.js? </desc> <cmt> minor fixes </cmt> <cmt> added author </cmt>",fbxloader minor animation fix and refactor
688,"<desc> after discussion, i added falling back to fetch based pinging when the websocket fails to connect. i also added an example of how to proxy the ondemandentries websocket when using a custom server. fixes: #6296 </desc> <cmt> add falling back to fetch based pinging when failing to connect </cmt> <cmt> to ondemandentries websocket </cmt> <cmt> add warning letting user know why we are falling back to fetch </cmt> <cmt> add example of proxying ondemandentries websocket </cmt> <cmt> using custom server </cmt> <iss> hmr reloading page every 10 seconds </iss>",add falling back to fetch based pinging for ondemandentries
689,"<desc> this change fixes 2 symptoms: ""can't find view with tag x"" that sometimes is thrown when closing a secondary window. this is due to a race between a spurious root view size change notification and the removerootview command coming from js. leak of the ui elements/related structures of a secondary dispatcher thread when a view is closed (by means of a window.current.close()) just after the ""await rootview.stopreactapplicationasync()"". this is due to a 1-0-1 pattern that confuses the os into detecting ""secondary thread not used anymore, so it can be killed"", when subsequent cleanup phase in the native hierarchy does need that thread again. in the new code the root view cleanup is carefully choreographed: detaching the root view has to complete before calling unmountapplication, so removerootview is guaranteed to follow rather than to race. stopreactapplicationasync now waits for the cleanup of the whole chain, up to nativehierarchymanager. </desc> <cmt> fix race condition during close window by making sure ""unmountapplicationcomponentatroottag"" is called after detaching the root view. </cmt> <cmt> this should fix ""can't find element with tag x"" exceptions during window closing. </cmt> <cmt> fixed a close window issue that may trigger a leak if the hosting view is closed too fast.. </cmt>","fix some race conditions/leaks in some ""close window"" multi-window scenarios"
690,"<desc> when using native, we should use the old menu for this release while we sort out electron issues </desc> <cmt> add the old menu back for native menus </cmt> <cmt> make menu labels match </cmt>",bring back the old menu due to electron 2.0 issues
691,"<desc> then flowed it throughout the compiler, finding and fixing a handful of bugs relating to underscore-prefixed identifiers in the process. includes a test for two (new) cases noticed - diagnostics from conflicting symbols from export *'s, and enums with underscore prefixed member emit. i mentioned this while talking among the team last week. this can be done in place of/alongside #16868. additionally, this fixes #15334, #14268, #11902, and #3268. (each should also now exist as a test case in this pr, too) the shape of this brand is also rather unique compared to others we've used. instead of just an intersection of a string and an object, it is that union-ed with an intersection of void and an object. this makes it wholly incompatible with a normal string (which is good, it cannot be misused on assignment or on usage), while still being comparable with a normal string via === (also good) and castable from a string. summary: __string is used to represent a string whose leading underscore have been escaped (if present) or a string representing an internal compiler symbol name, such as ""__call"". to escape a string in this way, call escapeleadingunderscores. to unescape such a string, call unescapeleadingunderscores. strings of this kind are used to represent symbol names and identifier text, to allow for internal symbol names to cohabitate the same symbol table as normal members without being in conflict. the brand on this type is structured such that it is castable and comparable with normal strings, but a normal string cannot be used in its place and it can not be used in place of a normal string (to prevent escaped text from leaking out via diagnostic messages and the like). the union member enabling this is the member intersected with void, which makes it incompatible with anything asking for a string. </desc> <cmt> created a branded type for escaped strings </cmt> <cmt> then flowed it throughout the compiler, finding and fixing a handful of </cmt> <cmt> bugs relating to underscore-prefixed identifiers in the process. </cmt> <cmt> includes a test for two cases noticed - diagnostics from conflicting </cmt> <cmt> symbols from export *'s, and enum with underscore prefixed member emit. </cmt> <cmt> correctly double underscores wrt mapped types </cmt> <cmt> add fourslash tests for other fixed issues </cmt> <iss> properties prefixed with double-underscore cannot be accessed in mapped type mappings </iss>",created a branded type for identifier-escaped strings
692,"<desc> given a schema like this, flatc now outputs a warning about the duplicate attribute: warning: duplicate.fbs(5, 36): warning: attribute already found: priority namespace mygame; attribute ""priority""; table monster (priority:1, priority:2) { } root_type monster; </desc> <cmt> added missing endtable() call to verifyobject() </cmt> <cmt> verifyobject called verifytablestart() but not endtable(). this made verifier::verifycomplexity() increase depth_ with each table, not with the depth of tables. </cmt> <cmt>  </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added check to verifyalignment </cmt> <cmt>  </cmt> <cmt> add getstringview (convenience function to get string_view from a string returning an empty string_view on null pointer) like getstring, getcstring </cmt> <cmt> merge remote-tracking branch 'remotes/upstream/master' </cmt> <cmt> # conflicts: </cmt> <cmt> #	include/flatbuffers/flatbuffers.h </cmt> <cmt> merge remote-tracking branch 'remotes/upstream/master' </cmt> <cmt> flatc should warn, when an attribute is attached more than once. </cmt> <cmt> flatc.exe -b duplicate.fbs </cmt> <cmt> warning: duplicate.fbs(5, 36): warning: attribute already found: priority </cmt> <cmt> duplicate.fbs: </cmt> <cmt> namespace mygame; </cmt> <cmt> attribute ""priority""; </cmt> <cmt> table monster (priority:1, priority:2) { </cmt> <cmt> } </cmt> <cmt> root_type monster; </cmt>","flatc should output a warning, when an attribute is attached more than once"
693,"<desc> this makes sure both the systemd services are enabled by default in the install instructions because the rpm packages do not do this, unlike the deb packages. if docker is not enabled then it will not restart on system boot allowing containers with restart policies to be started.  again, this is not an issue for deb based systems because they do this in the install scripts but it is a general expectation that rpm based systems require the user to manually enable these services. </desc> <cmt> enable docker socket and service on fedora </cmt> <cmt> make sure that the users enable both the socket and service for docker </cmt> <cmt> as part of the default install instructions.  if both are not enabled </cmt> <cmt> docker will not start at boot and restart containers. </cmt> <cmt> state that docker supports fedora 24 </cmt>",enable docker.socket and docker.service in fedora install docs
694,"<desc> removed duplication of faces, vertices, and normals; meshcollider works directly on source mesh (was this very loose coupling there for a reason?) face4 intersection is done through 2 raytriangle calls -> todo: make rayquad function? in addition to distance, raycastnearest returns index of the face the ray collides with (handy to use as uniform in fragmentshaders to e.g. color the ""hit"" face differently) </desc> <cmt> removed duplication of vertices, faces, and normals from meshcolliderwbox, and pass mesh directly to meshcollider constructor </cmt> <cmt> meshcollider takes original mesh as argument. meshcollider's raymesh extended to support face4 faces (implemented as two raytriangle calls) </cmt> <cmt> fix for face4 raymesh (raytriangle typo). raycastnearest resturns index of face in addition to distance. </cmt> <cmt> raytriangle for face4 type now really fixed ;) </cmt>",expanded collision for meshes to include face4 faces
695,"<desc> this option is stable, since it was added in kubernetes v1.12.0 (sep 2018). the previous $(kubectl config current-context) command may cause bugs after switching contexts. </desc> <cmt> use --current flag for kubectl kcn alias </cmt> <cmt> this option is stable, since it was added in kubernetes v1.12.0 (sep 2018). the previous $(kubectl config current-context) command will cause bugs after switching contexts. </cmt> <cmt> fully document kcn alias </cmt>",use --current flag in kcn alias
696,"<desc> fixes #3667. i tried to come up with examples that are somewhat real-world, not too complicated and that showcases some of prettier's strengths. </desc> <cmt> playground: add graphql example </cmt> <cmt> playground: add markdown example </cmt> <cmt> playground: add flow example </cmt> <cmt> playground: add less example </cmt> <cmt> playground: add vue example </cmt>",add playground examples for all languages
697,"<desc> update english grammatical_error_correction.md correct task description. add new best-published results. improve dataset descriptions. fix incorrect links. split results into restricted and unrestricted settings for fairer comparisons. use acl anthology or official proceedings links instead of arxiv links. </desc> <cmt> update grammatical_error_correction.md </cmt> <cmt> corrected the task description, added two settings for fairer comparison of state-of-the-art </cmt> <cmt> update grammatical_error_correction.md, new sota </cmt> <cmt> new sota added </cmt> <cmt> update links in grammatical_error_correction.md </cmt> <cmt> update grammatical_error_correction.md </cmt>","fixing links and descriptions, and adding new results for grammatical error correction (gec)"
698,"<desc> addresses #2711 enables the hc-dark theme on all platforms. improves color contrast to aaa standard on many elements that weren't previously meeting it. resolves visual bugs, such as synthetic-focus misplacement and action bar duplicate icons differentiates the selection of text from current line and find/word matching works well in mac osx even when os-level accessibility features are enabled, such as increasing contrast. note: a css rule used (mix-blend-mode: difference;) currently works in all browsers but opera, ie and edge, so it will not be ideal for the online monaco editor without suitable shims.  let me know if we need to address this; we can do that now or in the future. </desc> <cmt> enable high-contrast theme on all platforms.  removed unused variable per hygiene.js </cmt> <cmt> inverting selection, for higher contrast.  wip </cmt> <cmt> fixed inversion selection bug from z-index </cmt> <cmt> removed gitter on tree hover high-contrast </cmt> <cmt> moved high contrast inverted effect to its own stylesheet </cmt> <cmt> improved selection hilights for hc-dark theme </cmt> <cmt> changed hc-dark orange color to be aaa compliant with high contrast </cmt> <cmt> aaa compliance with comment token </cmt> <cmt> fixed focus on search input hc-dark theme </cmt> <cmt> removed ghosting bug on activity bar hc-dark theme </cmt> <cmt> aaa compliant scrollbars hc-dark </cmt> <cmt> aaa compliance for current line </cmt>",enabling high contrast dark theme on all platforms + hc-dark improvements
699,"<desc> this adds platform dependent checks to lower the buffer sizes on android to use less memory. it also reduces the normal defaults as perf testing showed we didn't need to be as high. this adds system properties for overriding the defaults, rx.ring-buffer.size and rx.indexed-ring-buffer.size fixes #1820 </desc> <cmt> rxringbuffersize (128 default, 16 on android) </cmt> <cmt> - changing from 1024 to 128 based on perf tests </cmt> <cmt> - platform dependent check for android to set to 16 to reduce memory usage </cmt> <cmt> indexedringbuffersize (256 default, 8 on android) </cmt> <cmt> - changing from 512 to 256 based on perf tests </cmt> <cmt> - platform dependent check for android to set to 8 to reduce memory usage (use cases on android should rarely if ever hit the use case with merge that requires the higher buffer sizes for performance) </cmt>",reduce ring buffer default sizes (and lower for android)
700,"<desc> correct negative sampling for wav2vec2forpretraining. previously padded feature vectors could be sampled which would give the model bad signals during pretraining. this pr makes sure that a padded feature vector cannot be sampled as a ""negative"" vector. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> fix_torch_device_generate_test </cmt> <cmt> remove @ </cmt> <cmt> finish </cmt> <cmt> correct script </cmt> <cmt> correct script </cmt>",padded vectors should not allowed to be sampled
701,<desc> allow apps to create direct messages; implements getmembers; allow apps to search for direct message rooms based on usernames; </desc> <cmt> allow apps to create direct messages </cmt> <cmt> implement getmembers; </cmt> <cmt> adds ability to search direct rooms by usernames </cmt>,add more methods to deal with rooms via rocket.chat.apps
702,"<desc> makes the bootstrap timeout configurable increase the bootstrap timeout to 15 minutes. for replica sets with a lot of data, 5 was too low. fixes the error replsetreconfig got badvalue: found two member configurations with same host field when initial join fails part way through. adds publishnotreadyaddresses: true to service since the tolerate-unready-endpoints annotation is deprecated. adds a new service for use by clients that only returns ready endpoints. this resolves clients connecting to pods that are crashing or in the process of joining. users will need to update their applications to the new service to take advantage of this functionality, but they can continue to use the old service and it won't break anything. note that i could not add a discovery service and keep the existing service for clients since servicename in statefulset is not an editable field. fixes #9459 fixes #9266 i tested a new install and upgrade from the previous chart version dco signed </desc> <cmt> [stable/mongodb-replicaset] fix failure to join replica set </cmt> <cmt> [stable/mongodb-replicaset] fix clients accessing unready endpoints </cmt> <iss> [stable/mongodb-replicaset] make init timeout configureable </iss> <iss> [stable/mongodb-replicaset] unable to join replica set after failure </iss>",fix joining replica set after failure
703,"<desc> what did you implement: the docs link to cognito user pool triggers aws documentation is only a guide on the incoming events and doesn't contain the actual trigger names. i added a link to the cloudformation documentation that does contain those triggers. how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> changing event link </cmt> <cmt> added words </cmt>",adding cognito user pool trigger documentation link
704,"<desc> pep 8 compliance cleanups for python.d modules with names starting with d, e, f, g, and h. relevant: #4167 </desc> <cmt> python.d/dnsdist.chart.py pep 8 cleanup </cmt> <cmt> * converted tabs in indentation to spaces (this is why the diff looks </cmt> <cmt> huge). </cmt> <cmt> * fixed container literal formatting. </cmt> <cmt> * general cleanup regarding blank lines. </cmt> <cmt> python.d/dns_query_time.chart.py pep 8 cleanup </cmt> <cmt> fixed container literal formatting. </cmt> <cmt> python.d/dockerd.chart.py pep 8 cleanup </cmt> <cmt> fixed overly long lines and trailing empty line. </cmt> <cmt> python.d/dovecot.chart.py pep 8 cleanup </cmt> <cmt> made string literals use consistent quoting and fixed container literal </cmt> <cmt> formatting. </cmt> <cmt> python.d/elasticsearch.chart.py pep 8 cleanup </cmt> <cmt> fixed container literal formatting. </cmt> <cmt> python.d/exim.chart.py pep 8 cleanup </cmt> <cmt> fixed string quoting and container literal formatting. </cmt> <cmt> python.d/fail2ban.chart.py pep 8 cleanup </cmt> <cmt> fixed string quoting and container literal formatting. </cmt> <cmt> python.d/freeradius.chart.py pep 8 cleanup </cmt> <cmt> fixed quoting of strings and formatting of container literals. </cmt> <cmt> python.d/go_expvar.chart.py pep 8 cleanup </cmt> <cmt> fixed formatting of conainer literals. </cmt> <cmt> python.d/haproxy.chart.py pep 8 cleanup </cmt> <cmt> make string quoting consistent and fix formatting of container literals. </cmt> <cmt> python.d/httpcheck.chart.py pep 8 cleanup </cmt> <cmt> fixed quoting of strings and formatting of container literals. </cmt>","python.d pep 8 cleanup, modules d-h"
705,"<desc> this pr adds tests with the sanitizers run by cran on package submissions. see this blog post for a lot more background. the tests take 22 minutes to run, so in this pr i'm proposing that we add them as a manual test that can be triggered by a comment (copying @strikerrus 's great work on #3424 ). this can be triggered by commenting /gha run r-sanitizers-check on a pr. how this makes lightgbm better catches issues like memory violations in lib_lightgbm allows us to catch issues in ci to improve the likelihood of cran accepting submissions of the r package </desc> <cmt> [ci] add r ci job with ubsan </cmt> <cmt> stuff </cmt> <cmt> fix command </cmt> <cmt> stuff </cmt> <cmt> update template </cmt> <cmt> fail on errors </cmt> <cmt> spaces </cmt> <cmt> trigger by comment </cmt>",add test on r package with sanitizers
706,"<desc> adds support for ssm parameter resolution for cloudformation. there are still some issues with the flow for parameter initialization which will need a bit more refactoring in the future but for now it adds the ssm string parameter support without rewriting too much of the core cfn logic. some other changes: started adding new tests in a new cloudformation test subdir for integration tests since we'll have to add more cfn tests here in the near future. the exiting unittest tests will be moved there in the near future as well and split up where necessary. added new fixtures for cleanup (might make sense to encapsulate them in a utils fixture to avoid too many parameters in the unit tests) minor type hint additions support for change set types (""create""/""update"") and corresponding errors. ""import"" is not yet supported, but a corresponding todo was added. </desc> <cmt> add cloudformation test for create changeset </cmt> <cmt> change set stack state should be review_in_progress initially </cmt> <cmt> refactor create_change_set and related utils and add tests </cmt> <cmt> add logs client and fix timeout in tests </cmt> <cmt> add helper fixtures for checking and cleaning stacks </cmt> <cmt> implement ssm string parameter resolving for cloudformation </cmt>",support resovling ssm parameter values in cloudformation
707,"<desc> with this commit, three won't crash anymore when calling fromgeometry with an empty geometry as argument. </desc> <cmt> mrdoob/three.js dev into lowfab/three.js dev </cmt> <cmt> check whether geometry has any faces before accessing faces[0] </cmt>",handle empty geometry in buffergeometry.fromgeometry
708,"<desc> dp= lets you properly attach to child processes now. fixed issues around it. ref rizinorg/cutter#1894 </desc> <cmt> add process selection to linux native debug ##debug </cmt> <cmt> previously, dp= wouldn't fully switch to the given process since it was </cmt> <cmt> treated like dpt thread switching, leaving the debugger in an undefined state. </cmt> <cmt> fix linux_set_options error ##debug </cmt> <cmt> previously, setting options would fail sometimes since pt_attach's attach </cmt> <cmt> sigstop wasn't hit before reaching linux_set_options. </cmt> <cmt> allow debug plugins to modify pid/tid on select ##debug </cmt> <cmt> previously, when using dp=, the debug plugin would set a new tid based </cmt> <cmt> on the requested pid, but r_debug_select would set the old tid as dbg->tid, </cmt> <cmt> resulting in issues interacting with the current thread. this could also </cmt> <cmt> be an issue when the requested pid/tid is invalid and the plugin selects </cmt> <cmt> something else. </cmt>",linux native debug process selection fixes
709,<desc> summary added the op batch_normalization in the numpy backend. related issues pr overview added the function in the numpy backend added the numpy implementation in the docs added tests. this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> finished the functions. </cmt> <cmt> started doing the test function. </cmt> <cmt> added the batch_normalization operation to the numpy backend. </cmt>,added batch_normalization in the numpy backend.
710,"<desc> fixes #21947 i replaced the sentence descriptions for possible choices of parameter include_boundaries in the documentation of function check_scalar with interval notations. the members are discussing which interval notation to use. i went ahead and made changes as per the english notation. will make changes, if members decide to go ahead with other notation. </desc> <cmt> add interval notation in check_scalar doc </cmt> <iss> add interval notation for include_boundaries parameter for the function check_scalar </iss>",doc add interval notation for include_boundaries in documentation check_scalar
711,"<desc> this bumps gnutls to last stable v 3.3.10 and enables gnutls support in ffmpeg on android (again). i can't remember the exact reason why it was disabled for gotham - some unresolved symbols or the locking callbacks maybe - but it should be fixed with moving ffmpeg to depends. i've been running this on adt-1 for a while and didn't notice issues related to it. it also got some user testing, see </desc> <cmt> [android] re-enable gnutls in ffmpeg </cmt> <cmt> [depends] bump gnutls to last stable version 3.3.10 </cmt> <cmt> [depends] fix nettle dylib target </cmt> <cmt> [depends] fix gmp makefile </cmt>",enable gnutls support in ffmpeg
712,"<desc> remove compatibility module from actioncontroller, either by cleaning up code that is going to be deprecated in 3.2, or by moving code to their right places inside actioncontroller modules. i'm sending a second pull request for 3-2-stable branch deprecating most of the methods inside this module. please let me know if something should be improved. thanks. </desc> <cmt> remove old compatibility methods not being used </cmt> <cmt> remove constant already defined in exceptions module </cmt> <cmt> remove other old compatibility constants </cmt> <cmt> remove rescue_action from compatibility module and tests </cmt> <cmt> remove relative url root setting from env var </cmt> <cmt> this is already being set by rails configuration. </cmt> <cmt> remove deprecated logic to render templates starting with / </cmt> <cmt> render :template => ""/foo/bar"" </cmt> <cmt> rename test class and fix tests to keep consistency </cmt> <cmt> based on 50d23bc2bd3653b3c66e480c22ae97c5f7fd7f62. </cmt> <cmt> move render :nothing and :text => nil options to ac::rendering </cmt> <cmt> refactor render nothing/text => nil logic, and move to right place </cmt> <cmt> options :nothing and :text => nil should be handled by </cmt> <cmt> actioncontroller::rendering instead. </cmt> <cmt> remove method missing handling when action is not found, use action missing instead </cmt> <cmt> do not create a method_missing method to handle not found actions, use </cmt> <cmt> the action_missing method provided by rails instead. </cmt> <cmt> move render_to_body logic to return a spaced string to ac::rendering </cmt> <cmt> this seems to be required only when calling render :partial with an </cmt> <cmt> empty collection from a controller. this call happens to return no </cmt> <cmt> content, letting the response body empty, which means to rails that it </cmt> <cmt> should go on and try to find a template to render based on the current </cmt> <cmt> action name, thus failing hard. </cmt> <cmt> although tests keep all green, we need to check a better way to fix </cmt> <cmt> this. </cmt> <cmt> remove deprecated default_charset= from ac::base </cmt> <cmt> this should be set globally as a configuration, using </cmt> <cmt> config.action_dispatch.default_charset instead </cmt> <cmt> move protected instance variables definition, kill compatibility module </cmt> <cmt> bring back rendering templates that start with / in nested structures </cmt> <cmt> update changelog </cmt>",action controller refactor - remove compatibility module
713,"<desc> in the scenario that we have multiple ray clusters with processes running on the same node, we want to make sure that each cluster's dashboard only contains metrics from the processes in its cluster. the ray reporter process collects node-level metrics about ray workers, but some of the ray worker processes running on a given node could belong to other ray clusters (the way workers are currently identified is through a process name-prefix, and we will eventually want to make more structured). we could have, in theory, gotten a list of relevant worker process ids via an rpc call; however this would have have added strain to the core system. for the time being at least, i have placed the relevant changes on the front end. there is a concept now of clusterworkers, which is a subset of the workers in a given node's stats. this clusterworkers subset is calculated by looking at the process ids of the workers in the raylet stats that the reporter fetches for the dashboard. the data is then used to filter the worker values that are being passed into various parts of the ui, such as node details table data and data aggregation rows. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> add an idea of cluster workers versus all workers on a node. we do not want to show workers on the dashboard that are on a node belonging to our cluster, but that do not themselves belong to the cluster because the node hosts more than one ray cluster. </cmt>",dashboard only shows workers in its cluster
714,"<desc> when using flow-offloading with [luci-app-pptp-server] installed, [luci-app-pptp-server] rules will forward all the traffic which the protocol name includes ppp, which means pppoe traffic also will be forwarded. to solve this problem, iptables need to add return rules when matching pppoe. thanks to @lga1150 </desc> <cmt> update pptpd.include </cmt> <cmt> if not return pppoe traffic, it will make flow-offload rules has no effect. </cmt>",fixed conflict with flow-offloading rules
715,<desc> new keyboard tgr 910 ce (note this is different than the 910) with via keymap added in. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> initial commit for tgr 910 ce </cmt> <cmt> got firmware working on the 910 ce </cmt> <cmt> add via support </cmt> <cmt> add iso and all layouts </cmt> <cmt> update information about resetting the board </cmt> <cmt> fixup default keymap to have a second layer </cmt> <cmt> fixup default keymap </cmt> <cmt> add via enabled keymap </cmt> <cmt> cleanups and adding community layout support </cmt> <cmt> add caps lock led support and backlight </cmt> <cmt> add qmk configurator support </cmt>,new keyboard: tgr 910 ce
716,"<desc> system indices should be hidden from users. since they are already restricted indices, a users that can't view restricted indices already can't see or access them, but they should also be hidden for superusers or users that are otherwise granted advanced privileges. to the greatest degree possible, we apply hidden settings in the transport layer, so that the system can create an index or alias that is set to visible, for example, when operating in a mixed cluster mode. however, in the case of aliases created by templates, we hide the alias in the service layer. this change has broken a number of tests that were relaying unnecessarily on wildcard searches. in general, the fix for these issues was to apply expand_wildcards=open,hidden to the request. </desc> <cmt> force system indices to be hidden in indexmetadata </cmt> <cmt> hide system data streams </cmt>",all system indices are hidden indices
717,"<desc> the patch fixed the errors when using bash and cmder is installed under a directory with spaces in the path, e.g. c:\users\foo bar\cmder . please review. thanks. the first commit fixed errors i encountered (in v1.3.0), while the second commit fixed similar issues. note: the development branch (the base) is behind master, in fact, pre v1.3.0.  should i stick with merging to it? </desc> <cmt> fix bash login when ${cmder_root} has spaces. </cmt> <cmt> e.g., if ${cmder_root} is /c/users/foo bar/cmder, </cmt> <cmt> the following errors will occur: </cmt> <cmt> bash: pushd: /c/users/foo: no such file or directory </cmt> <cmt> bash: [: /c/users/foo: binary operator expected </cmt> <cmt> bash: /c/users/foo: no such file or directory </cmt> <cmt> further fix bash login when ${cmder_root} has spaces. </cmt> <cmt> inspecting the script uncovers similar problems elsewhere </cmt> <cmt> not encountered in my initial testing. they are fixed accordingly. </cmt>",fix bash login when $cmder_root has spaces
718,"<desc> this reinstates the use of direct adjacency information when gathering constraints, effectively reverting 54bdd7b. one-way constraints get added but aren't traversed. fixes the regression tracked by rdar://problem/54274245. </desc> <cmt> [constraint graph] reinstate the adjacencies of constraint graph nodes. </cmt> <cmt> reinstate the list of adjacencies in each constraint graph node, </cmt> <cmt> effectively reverting </cmt> <cmt> dfdd352d3d236851a0e5b7fb93d1286966032089. exclude one-way constraints </cmt> <cmt> from this computation; we'll handle them separately. </cmt> <cmt> [constraint graph] use adjacency info for constraint gathering. </cmt> <cmt> this reinstates the use of direct adjacency information when gathering </cmt> <cmt> constraints, effectively reverting </cmt> <cmt> 54bdd7b840721523f363e343d7b25997a8a332fe. </cmt> <cmt> fixes the regression that commit caused, which is tracked by </cmt> <cmt> rdar://problem/54274245. </cmt>",reinstate the use of adjacency information for constraint gathering
719,<desc> this pr finishes to clean up some old references to sphinx in the setup or makefile and updates the contributing guide/docs readme to explain to users how to build the docs with our new tool or how to write them. fixes #14762 </desc> <cmt> clean up sphinx </cmt> <cmt> update contributing guide </cmt> <cmt> update docs readme </cmt> <iss> make docs failing </iss>,post sphinx-clean up and contributing guide updates
720,"<desc> fixes two small bugs: fix platform import on linux using python3 $ mitmproxy -t --host mitmproxy: transparent mode not supported on this platform. using python3 sys.platform returns linux instead of linux2 (python2). this causes the platform import to fail on python3. substitute tilde with user's home. delivering the cert ~/.mitmproxy/mitmproxy-ca-cert.pem using mitm.it fails because the tilde is not replaced with the user's home directory. </desc> <cmt> fix platform import on linux using python3 </cmt> <cmt> using python3, sys.platform returns ""linux"" instead of ""linux2"" using </cmt> <cmt> python2. this patch accepts ""linux"" as well as ""linux2"". </cmt> <cmt> substitute tilde with user's home. </cmt> <cmt> when downloding the mitmproxy certificate using mitm.it, '~' currently </cmt> <cmt> is not expanded causing a filenotfoundexception. this patch uses </cmt> <cmt> expanduser() to replace the initial tilde with the user's home. </cmt>","fix platform import, substitute ""~"" with user's home"
721,"<desc> for #2927. </desc> <cmt> [docs] flatbutton - revert linkbutton example, and document linkbutton & href props </cmt> <cmt> [docs] floatingactionbutton - flatten example code, document linkbutton & href props </cmt> <cmt> [docs] raisedbutton - add title & description to examples, document linkbutton & href props </cmt> <cmt> [docs] radiobutton - add description to example, document 'checked' prop as internal </cmt>","flatbutton, fab - document linkbutton & href, raisedbutton, radiobutton - add title & description to examples"
722,"<desc> earlier changes to the stm32f1 serial isr has eliminated hanging due to serial overflows when using serial 1-5 for marlin or dgus communication. these changes missed the following two usages of serial, which could still hang: malyan lcd, which hard-coded serial1 in its cpp file. tmc hardware serial to resolve this, several changes were made: add malyan_lcd_serial_port to configuration.h. update stm32f1 hal.h to handle this new port like it does for other ports which may control the printer. always instantiate all mserial ports (1-3 or 1-5, depending on board) to allow them to be easily used from pins files. make emergency parser optional in mserial class, so it won't be enabled for malyan_lcd or tmc. update all stm32f1 pins files to use mserial instead of serial. add static asserts that detect anything using serial classes, since they can cause the board to hang. avoid potentially unsafe hangs when using hardware serial for a malyan lcd or tmc uart communication. these configurations are for an skr e3 dip with tmc 2209 drivers and a malyan lcd attached to the tft port. using this i was able to reproduce hangs while printing prior to this change, even though this is using softwareserial for the tmc drivers. configurations_malyan.zip #18358 </desc> <cmt> update malyan lcd to use mserial on stm32f1, and try to prevent use of non-mserial ports. </cmt> <cmt> add configuration.h option. </cmt>",fix more stm32f1 serial hangs due to overflows
723,"<desc> when i pulled in the default starter to build my website, one of the first things i changed was to add more html landmarks. so that everyone can benefit from this accessibility improvement, i added main and header elements to the default and blog starters. that way, screen reader users can navigate gatsby sites by landmarks. more information: </desc> <cmt> add header and main landmarks to blog starter </cmt> <cmt> these improve accessibility for screen reader users, along with the existing html footer element. </cmt> <cmt> add header and main landmarks to default starter </cmt>",add landmarks to default & blog starters
724,"<desc> you probably don't want to look at the changes, it's huge, instead look at the individual commits. this pr updates the bullet wrapper to version 2.82 rev 2704, but doesn't add the new functionality (like featherstone and mlcp). it only updates the existing functionality of the wrapper with the bug fixes of 2.82. it also includes some additional changes i had pending, closes #826 closes #836 and closes #837. tested on win64 and android. this pr is mostly to check the others builds on jenkins, therefor will merge myself. i will try to create the swig interface for the new functionality tomorrow. </desc> <cmt> update bullet source to 2.82 rev2704 </cmt> <cmt> more bullet source updates (rev2704) </cmt> <cmt> fix build + add callbacks + add btsimplexsolverinterface </cmt> <cmt> swig generated files </cmt> <cmt> include original files to reference custom patch </cmt> <cmt> re-apply: fixed btscalar to not use sse on ios simulator </cmt> <cmt> update vs project </cmt> <iss> contactlistener generates a lot of garbage, pool btcollisionobjectwrappers! </iss> <iss> filtering collisions using a broadphase filter callback </iss> <iss> convex hull distance </iss>",update to 2.82 rev 2704
725,<desc> this incorporates the ideas of #2434 </desc> <cmt> dvdplayer: move canseek/canpause to seekable interface </cmt> <cmt> dvdplayer: disable seeking and pause for udp/rtp and seek for tcp </cmt> <cmt> dvdplayer: move navigator state into imenus </cmt> <cmt> this allow bluray navigator to make use of it eventually </cmt>,disallow seeking for udp and some interface improvements in dvdplayer
726,<desc> gdb catches sigint and by default doesn't pass it to process. but it passes sigterm </desc> <cmt> dbms: fix build </cmt> <cmt> basedaemon: change terminate signal to sigterm. </cmt> <cmt> gdb catches sigint and by default don't pass it to daemon </cmt>,terminate sends sigterm instead of sigint
727,"<desc> handles #7158 </desc> <cmt> completion list for a class extending another class should contain members from base class </cmt> <cmt> handles #7158 </cmt> <cmt> give the class element completion on typing keywords like public, private, readonly </cmt> <cmt> also when name of the function is location, make sure we are actually looking at the same symbol before using the declaration to get signature to display </cmt> <cmt> tune the completion list for static and private modifiers </cmt> <cmt> do not show inherited members in completion for when writing private member </cmt> <cmt> show only static inherited members when writing static member </cmt>",when writing class elements show completion with allowed keywords and inheritted properties
728,"<desc> as per  this is the initial machinery to setup the l10n infrastructure for markdown documentation. a new ""docs-l10n"" target will take care of generating, updating and then building .pot and .po files, and later on the final .md. this commit includes the .pot for all current .md docs; they can be feed directly to mozilla verbatim if wanted. please note that po4a only provides the orig.md -> .pot -> l10n.po -> l10n.md flow. the l10n.md -> l10n.html generation is not currently built in the makefile, as no language has been enabled. </desc> <cmt> use po4a to provide translatable documentation </cmt> <cmt> this commit add a new ""docs-l10n"" make target which uses po4a to: </cmt> <cmt> * create .pot (po templates) from markdown doc </cmt> <cmt> * update templates and po for enabled languages </cmt> <cmt> * generate translated markdown for completed (> 80%) translations </cmt> <cmt> currently, no language has been activated. </cmt> <cmt> generate initial translatable templates for documentation </cmt> <cmt> these files are automatically genereated by make docs-l10n (via po4a), </cmt> <cmt> which will also take of updating them if the original .md changes. </cmt>",initial po4a setup for translatable markdown documentation
729,"<desc> our eventual goal is to completely remove unboundgenerictype. one of the places where we return an unboundgenerictype is from getdeclaredtype(). this pr begins the preparations for removing getdeclaredtype() by replacing calls with getdeclaredinterfacetype() when the declaration is known to be non-generic, in which case it returns the same thing. </desc> <cmt> ast: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> sema: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> sil: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> clangimporter: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> ide: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> irgen: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt> <cmt> frontend: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() </cmt>",replace trivial calls to getdeclaredtype() with getdeclaredinterfacetype()
730,"<desc> this is a series of updates to the tokenizer and tokenizer docs in order to sync the docs and the current tokenizer implementation. a new tokenizer function makes debugging the tokenizer a bit easier by implementing a slow debugging version that returns labels for each token about the pattern or rule matched, based on the pseudo-code in the docs. there are some minor changes to tokenizer to bring it in sync with the intended behavior based on the docs. while updating the pseudo-code in the docs, it made sense to make a working version to check the details, so i expanded that just a bit to add some better debugging functionality. i think keeping this in sync with the actual tokenizer will be a similar amount of effort to keeping the pseudo-code in the docs in sync. instead of being in the tokenizer itself, it could also be an example/demo script that takes nlp.tokenizer as an argument, but i liked being able to implement unit tests that compared its behavior to the actual tokenizer. i wish that it were easier to add tests for more of the tricky cases, since i haven't formally tested that the behavior is identical for all of the unusual test cases. it's also kind of unsatisfying that it doesn't handle whitespace tokenization, but this isn't usually a source of confusion for users and i think adding it would make the pseudo-code harder to read, and it's already a bit too long. i wouldn't be opposed to adding it, though. fixes #4573, fixes #4645. edited: implements explain() method that returns a list of (pattern_string, token_string) tuples to avoid the hacky displacy usage. easy displacy integration is postponed to a future pr. outdated description of displacy integration: in the initial version, the information is stored in a doc with the debugging information saved on the tags. this is a bit hacky since there's no way to mark the doc as not-for-actual-use, but it makes for easy visualization. alternatively, the labels could also be stored on a custom attribute and the visualization would require a few extra steps. i also tried visualizing the labels as entity spans, but the default entity visualization was pretty hard to read with labels on every token. with custom templates, it could be made a bit more readable and having the information as spans might be better than as hacky tags. (or there could be a ""tag"" visualization where you can specify which attribute to display?) docs, enhancement. i have submitted the spacy contributor agreement. </desc> <cmt> expose tokenizer rules as a property </cmt> <cmt> expose the tokenizer rules property in the same way as the other core </cmt> <cmt> properties. (the cache resetting is overkill, but consistent with </cmt> <cmt> from_bytes for now.) </cmt> <cmt> add tests and update tokenizer api docs. </cmt> <cmt> update hungarian punctuation to remove empty string </cmt> <cmt> update hungarian punctuation definitions so that _units does not match </cmt> <cmt> an empty string. </cmt> <cmt> use _load_special_tokenization consistently </cmt> <cmt> use _load_special_tokenization() and have it to handle none checks. </cmt> <cmt> fix precedence of token_match vs. special cases </cmt> <cmt> remove token_match check from _split_affixes() so that special cases </cmt> <cmt> have precedence over token_match. token_match is checked only before </cmt> <cmt> infixes are split. </cmt> <cmt> add make_debug_doc() to the tokenizer </cmt> <cmt> add make_debug_doc() to the tokenizer as a working implementation of </cmt> <cmt> the pseudo-code in the docs. </cmt> <cmt> add a test (marked as slow) that checks that nlp.tokenizer() and </cmt> <cmt> nlp.tokenizer.make_debug_doc() return the same non-whitespace tokens </cmt> <cmt> for all languages that have examples.sentences that can be imported. </cmt> <cmt> update tokenization usage docs </cmt> <cmt> update pseudo-code and algorithm description to correspond to </cmt> <cmt> nlp.tokenizer.make_debug_doc() with example debugging usage. </cmt> <cmt> add more examples for customizing tokenizers while preserving the </cmt> <cmt> existing defaults. </cmt> <cmt> minor edits / clarifications. </cmt> <iss> prefix_search overriding token_match in tokenizer </iss> <iss> custom tokenizer token_match doesn't seem to take proper precedence </iss>",add tokenizer explain() debugging method
731,"<desc> i hereby agree to the terms of the cla available at:  changelog category: detailed description / documentation draft: by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. </desc> <cmt> add files in ru docs </cmt> <cmt> add ru translation </cmt> <cmt> edit en text </cmt>",edit and translate to russian
732,<desc> travis use latest platformio v.4.2. changes neede in platformio.ini backward compatible the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.6.1 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> update .gitpod.yml </cmt> <cmt> update </cmt> <cmt> update platformio.ini </cmt> <cmt> update platformio.ini </cmt>,fix platformio.ini syntax for v.4.2 (and travis compile fail)
733,"<desc> corrects errors in the qmk configurator implementation, and enables community layout support. current layout_tkl_ansi shown; layout_tkl_iso similar:  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> correct layout_tkl_ansi data </cmt> <cmt> number row was positioned 0.25u too low. </cmt> <cmt> correct layout_tkl_ansi macro </cmt> <cmt> - remove position k027 (right half of split backspace) </cmt> <cmt> - remove position k096 (right portion of split right shift) </cmt> <cmt> correct layout_tkl_iso macro </cmt> <cmt> - remove position k027 (right half of split backspace) </cmt> <cmt> - remove position k096 (right portion of split right shift) </cmt> <cmt> enable community layout support </cmt> <cmt> add layout_tkl_ansi_split_bs_rshift and layout_tkl_iso_split_bs_rshift </cmt>",linworks fave87 layout macro refactor
734,"<desc> extract interaction constraints from split evaluator. the reason for doing so is mostly for model io, where num_feature and interaction_constraints are copied in split evaluator.  also interaction constraint by itself is a feature selector, acting like column sampler and it's inefficient to bury it deep in the evaluator chain.  lastly removing one another copied parameter is a win. enable inc for approx tree method. as now the implementation is spited up from evaluator class, it's also enabled for approx method. removing obsoleted code in colmaker. they are never documented nor actually used in real world.  also there isn't a single test for those code blocks. unifying the types used for row and column. as the size of input dataset is marching to billion, incorrect use of int is subject to overflow, also singed integer overflow is undefined behaviour.  this pr starts the procedure for unifying used index type to unsigned integers.  there's optimization that can utilize this undefined behaviour, but after some testings i don't see the optimization is beneficial to xgboost. related to #4732 . </desc> <cmt> extract interaction constraints, enable it for approx. </cmt> <cmt> * extract interaction constraints from split evaluator. </cmt> <cmt> the primary reason for doing so is that it copies the num_feature parameter, </cmt> <cmt> which makes serialization and parameter validation difficult.  also, as it </cmt> <cmt> should be used for selecting feature, like column sampler, instead of computing </cmt> <cmt> weight. </cmt> <cmt> * clean up for colmaker. </cmt> <cmt> remove support for parallel_option and cache_opt.  now we use whatever </cmt> <cmt> settings that are default before this pr.  as these parameters are never </cmt> <cmt> documented nor actually maintained. </cmt> <cmt> * enable for approx. </cmt> <cmt> remove the implementation in split evaluator. </cmt> <cmt> mention in doc. </cmt>",extract interaction constraint from split evaluator.
735,<desc> with #18777 it's no longer necessary to update the shadow camera bounds every frame because the the xy dimensions are always based on the longest edge of the frustum. this pr moves the shadow bounds update into updatefrustums which only gets called when the camera frustum changes in order to reduce the work needed to update every frame. it also removes the need to pass matrixworld into update and instead just uses the member cameras matrixworld. temporary live link:  @vhawk </desc> <cmt> separate shadow bounds update from update </cmt> <cmt> remove need to pass camera matrix world to update </cmt> <cmt> remove unnecessary shadow camera updates </cmt>,"remove unnecessary logic in ""update"""
736,"<desc> when image is not specified, but the container needs to be re-created for some reason (restart, configuration changed, etc.), currently simply nothing happens (without any user feedback). this is a consequence of #41678, which simply does not run the configuration check when image is not specified. this pr replaces the change in #41678 with slightly more sophisticated code: if the container doesn't exist yet, a (useful) error is returned because image is really needed in this place. if the container already exists, the container's image id is used for recreation. fixes #21188, fixes #27960. docker_container ansible version 2.8.0 </desc> <cmt> don't simply ignore container in present() if image is not specified. </cmt> <cmt> use image from existing container for recreation if not specified. </cmt> <iss> restarting container with non-default log driver fails with ""no command specified"" </iss> <iss> docker_container state: stopped is broken (fails and removes container) </iss>",fix behavior when image is not specified
737,"<desc> the main difference is level 19 using btultra strategy (which is now badly named, since it's no longer reserved for --ultra levels anymore) so that we can make level 19 a ""strongest compression level at window size <= 8 mb"". several other levels have been updated, to reflect improvements in intermediate strategies, and smooth the speed/compression curve on a slightly larger scale, due to level 1 being faster, and level 19 being stronger. </desc> <cmt> update compression levels for large inputs </cmt> <cmt> update table for 128 kb blocks </cmt> <cmt> update table levels for blocks <= 16k </cmt> <cmt> also : allow hlog to be slighly larger than windowlog, </cmt> <cmt> as it's apparently good for both speed and compression ratio. </cmt> <cmt> updated compression levels for blocks of 256kb </cmt>",update table of compression levels
738,"<desc> refactoring no if relevant, link to documentation update: n/a summary rename variables from async to future proof names no other information based on review feedback from #3166 </desc> <cmt> fix lint issues </cmt> <cmt> rename variable for future compatibility </cmt> <cmt> fix lint issues </cmt> <cmt> rename variable for future compatibility </cmt> <cmt> fixup eslint issues </cmt> <cmt> rename variable for future compatibility </cmt>",rename async for future compatibility
739,<desc> commit message: log xds control plane server identifier on change this is already exported as a stat but it's useful for post-hoc debugging if it shows up in the logs. risk level: low testing: ran affected tests docs changes: n/a release notes: n/a platform specific features: none </desc> <cmt> add logging of control plane identifier </cmt> <cmt> this only affects grpc_mux_impl. the corresponding change to </cmt> <cmt> new_grpc_mxu_impl will be made in a future commit. </cmt> <cmt> add remote identity logging for new_grpc_mux_impl </cmt> <cmt> this will help diagnose issues when envoy connects to a load-balanced </cmt> <cmt> xds endpoint with multiple serving backends. </cmt>,log control plane identifier on change
740,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  regarding the last checkbox above: there are additional types added in the newer version of nunjucks which i haven't added here, so i suppose this change doesn't bring it up to date with the newest version? but further than this i have a bigger concern about the versioning here. there are also the previously defined extend types which are incorrect:   ^ these are definitions for an instance method which does not exist (its static, as my new types show). as such if you try to call extend on an instance of the loader class as the existing type definition defines it, you will just get a runtime error because extend is not defined. i think it would be best to remove those incorrect types, but i'm not quite sure what the procedure would be in terms of versioning. removing those would technically be a breaking change, but the code that it breaks would just be failing at runtime currently. i hope someone can advise what i should do if i am to remove the incorrect type. the definetelytyped documentation on versioning is mum on the issue of a breaking change that doesn't correspond to a new major version for the typed package. for now i haven't removed the incorrect type from the loader class, i've only added the correct type for the static version of the method that actually does exist. </desc> <cmt> fix incorrect extend type </cmt> <cmt> add test for documented loader extension approach </cmt>",fix incorrect loader extend type in type definition
741,"<desc> closes #40951 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> times in ewm groupby: sort times in according to grouping; add missing support for times in numba implementation; fix bug in cython implementation </cmt> <cmt> add gh issue id to tests </cmt> <iss> bug: issues with groupby ewm and times </iss>",various groupby ewm times issues
742,"<desc> description: #17415 was merged to dev but not master.  since then the init.py has been updated to reflect other changes.  this pr brings the previous pr and current together.  previous #17415 was being tested and i can confirm is valid.  @awarecan sorry about the delay and misunderstanding.  i have also updated the services.yaml to reflect the correct id to use.  i will submit another pr to update documentation. also, the request sync timeout was set to 5s.  routinely the service would sync but throw an error indicating that  ""could not contact google for request_sync"".  this was not the case.  the service did sync and new devices would show up.  however google was not responding within the 5s timeout threshold.  i tested up to 10s and sometimes the same thing would happen.  a safe value ended up being 15s.  i have a very large amount of devices sync'd to ga (200+) and this is likely the reason for googles response taking longer than 5s. related issue (if applicable): fixes #17380 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): request_sync: description: send a request_sync command to google. fields: agent_user_id: description: ""optional. only needed for automations. specific home assistant user id (not username, id in configuration > users > under username) to sync with google assistant. do not need when you call this service through home assistant front end or api. used in automation script or other place where context.user_id is missing."" checklist: </desc> <cmt> fix google assistant request sync service call </cmt> <cmt> more descriptive services.yaml </cmt> <cmt> update services.yaml </cmt> <iss> google_assistant.request_sync at homeassistant start </iss>",update google assistant services description and request sync timeout
743,"<desc> this pr replaces the shardrouting argument in abstractsearchasyncaction#onfirstphaseresult with the more contained string nodeid argument, as that is the only info retrieved from it. the shardid can also be read directly from the sharditerator that's already provided as an argument, plus there is no need to create new instances of shardid by providing the index and the int shard_id separately, the whole shardid should be passed around when possible. the searchshardtarget constructor that takes shard_id and index separately stays only for testing purposes. </desc> <cmt> replace shardrouting argument in abstractsearchasyncaction#onfirstphaseresult with more contained string nodeid </cmt> <cmt> there is no need to pass in shardrouting if the only info read from it is the current node id, the shard id can be read directly from the sharditerator that's already provided as an argument. </cmt> <cmt> avoid creating a new shardid when creating a searchshardtarget in snapshotsservice </cmt>",don't carry shardrouting around when not needed in abstractsearchasyncaction
744,"<desc> add more information in trace-api-plugin responses for better usage. add transaction_mroot, action_mroot and schedule_version in block trace; add status, cpu_usage_us, net_usage_words, signatures and transaction_header in transaction trace. see #9005 for release/2.0.x version </desc> <cmt> add more info in block trace & transaction trace. </cmt> <cmt> remove unused include; remove unnecessary copy when caching traces. </cmt> <cmt> add receipt check; remove unnecessary constructors </cmt> <cmt> fix wrong index </cmt>",[develop]add more info in trace-api-plugin
745,"<desc> new server session monitor for sau (simultaneously active users), which will provide important informations for dau (active daily users) and mau (monthly active users). the monitor is based on meteor server sessions and will store the data in a new collection: rocketchat_sessions. the approach of this implementation will deal with connection events, such as onconnection and onclose, as well as dealing with account events, such as onlogin and onlogout. the sau monitor will use the meteor server sessions to update the session activities in db. the monitor will ping the active sessions every minute, updating the lastactivityat field on session documents. the session lifecycle is stored per day, so when the server date is changed, the current sessions will be created on the new day. this behaviour is designed to facilitate the collector process, which will aggregate the session life cycle and store it in another collection of statistics. the regular(non-mobile) session documents will look like the doc below: { ""_id"" : ""xsm2orqtspwgyoqt2"", ""year"" : 2018, ""month"" : 7, ""day"" : 20, ""instanceid"" : ""lpvdxjh8fydy6qsyz"", ""sessionid"" : ""ystqpjsifhffxwdis"", ""userid"" : ""uk294ojdzhyfqk53p"", ""ip"" : ""127.0.0.1"", ""host"" : ""localhost:3000"", ""browser"" : { ""name"" : ""chrome"", ""version"" : ""67.0.3396.99"", ""major"" : ""67"" }, ""os"" : { ""name"" : ""mac os"", ""version"" : ""10.13.6"" }, ""createdat"" : isodate(""2018-07-20t17:06:32.480z""),  //when the session is created ""lastactivityat"" : isodate(""2018-07-20t17:10:01.166z""), //when the session monitor updates current sessions in bucket storage ""loginat"" : isodate(""2018-07-20t17:06:32.491z""), //user login ""logoutat"" : isodate(""2018-07-20t17:10:07.311z"") //user logout } the mobile session documents will look like the doc below: { ""_id"" : ""yloj68zja6wfnft3b"", ""day"" : 26, ""instanceid"" : ""lpvdxjh8fydy6qsyz"", ""month"" : 7, ""sessionid"" : ""wtrw5snha7wfudxaz"", ""year"" : 2018, ""ip"" : ""200.34.239.117,127.0.0.1"", ""host"" : ""d16877f6.ngrok.io"", ""os"" : { ""name"" : ""ios"", ""version"" : ""11.4.1"" }, ""device"" : { ""type"" : ""mobile"" }, ""app"" : { ""name"" : ""rc mobile"", ""version"" : ""v3.0.2"", ""bundle"" : ""(202)"" }, ""createdat"" : isodate(""2018-07-26t18:57:49.475z""), ""userid"" : ""uk294ojdzhyfqk53p"", ""loginat"" : isodate(""2018-07-26t18:57:49.812z""), ""lastactivityat"" : isodate(""2018-07-26t18:58:03.834z""), ""closedat"" : isodate(""2018-07-26t18:58:03.834z"") } this new feature is being implemented in 3 steps: model design (sessions) monitor implementation this pr will close the issue number: #11461. once the implementation is approved, we need to think about the creation of a cron job that will collect the data every day, aggregating the data and storing in two other collections: sau and mau. </desc> <cmt> initial implementation on server session monitor. </cmt> <cmt> session model created. </cmt> <cmt> session model design done. </cmt>",collect data for monthly/daily active users for a future dashboard
746,"<desc> closes #43704 description of render trimming and maximums bug: pd.options.styler.render.max_columns = 5 pd.options.styler.render.max_rows = 5 df = dataframe(np.random.rand(10,10)) df.columns = pd.multiindex.from_product([[0,1,2,3,4], [0,1]]) df.index = pd.multiindex.from_product([[0,1,2,3,4], [0,1]]) df.index.names, df.columns.names = [""a"", ""b""], [""c"", ""d""] df.style.hide([(0,0), (0,1), (1,0)], axis=1).hide([(0,0), (0,1), (1,0)], axis=0) pre #44248 after #44248 (merged) after this pr </desc> <cmt> col trim on headers </cmt> <cmt> col trim on index names </cmt> <cmt> # conflicts: </cmt> <cmt> #	pandas/tests/io/formats/style/test_style.py </cmt> <iss> bug: styler render trimming does not work with `hide_columns` </iss>",styler hide compatible with max_columns
747,<desc> reduces checkstyle errors for patterns: naked-objects null-object object-mother object-pool observer queue-load-leveling changes involved java docs reordering imports indentations line length issues </desc> <cmt> reduces checkstyle errors in naked-objects </cmt> <cmt> reduces checkstyle errors in null-object </cmt> <cmt> reduces checkstyle errors in object-mother </cmt> <cmt> reduces checkstyle errors in object-pool </cmt> <cmt> reduces checkstyle errors in observer </cmt> <cmt> reduces checkstyle errors in queue-load-leveling </cmt>,resolves checkstyle errors for naked-objects null-object object-mother object-pool observer queue-load-leveling
748,<desc> this pr transforms the slots inside the slider as standalone styled components. this will allow us to support back the classes prop on this component. plaground for testing the classes prop here - </desc> <cmt> add emotion peer dependencies </cmt> <cmt> fixed types & tests </cmt> <cmt> prettier </cmt> <cmt> extract components </cmt>,extract slots as standalone components
749,"<desc> this pr: integrates zero-infinity revamps the configuration process, instead of the confusing to users sometimes-we-override-values, sometimes-we-don't - all values are now explicit unless they are set to auto, then and only then the trainer will set them to the correct or recommended values. massively revamps the way the configuration is done. now splitting the config parsing into 2 phases - one happening at the very end of trainingarguments and then a weak ref global module var is created which can then be queried by various transformers components w/o needing to change any apis. the global object cleanly goes away when trainingarguments goes out of scope. users no longer need to make any special calls - just need to ensure the  trainingarguments object is created before model.from_pretrained() is called (like we do in all examples). phase 2 happens during train where we get a few variables that weren't there during trainingarguments, so the config gets completed here. ds_config is now passed to zero.init in from_pretrained under zero-3 since it now needs several configuration values - this is in preparation for fp32 and other important features. adds new tests for zero-inf and configuration. adds a minor fix in  get_regression_trainer if you're testing this pr please make sure you install deepspeed master branch: git clone  cd deepspeed pip install -e . important changes please note a major change is that now only params that are set to auto will get automatically overriden/set to the correct/recommended values, everything else is left as is. this is to avoid the previously confusing behavior of never being quite sure what gets overridden and what not despite the logger telling what it did override. the new behavior is completely unambiguous. see: examples zero2 zero3 it's ready to release now. 0.3.15 just has a debug print that is loud, fixed in their master. </desc> <cmt> adding z-inf </cmt> <cmt> revamp config process </cmt> <cmt> up version requirement </cmt>",zero-infinity integration plus config revamp
750,"<desc> i've been working on this on and off for the past few days, thought we could open it for more participation, but i've created a spanish translation of the list, and will continue work until it's done. then the task of maintaining parity will begin. i wonder if there is an easier way to do this, i was working on it in a branch for just a day, and it there was lot of drift. also noteworthy, i did a lot of grammar checks on the english list as well because translating to spanish highlights very well where some of the english errs. so edits were done frequently on both, often at the same time. i decided now was good enough to push it, since it's reached parity with the brazilian portuguese copy. </desc> <cmt> first commit for spanish branch </cmt> <cmt> beggining translation </cmt> <cmt> first chunk of translation </cmt> <cmt> dusting off the cobwebs, and changing minor bits to account for this being a translation of another document. </cmt> <cmt> continuing work on the table of contents </cmt> <cmt> finished tables of contents </cmt> <cmt> now onto the software itself. </cmt> <cmt> beggining audio and some grammar: </cmt> <cmt> audio is starting, but also working on grammar up top. </cmt> <cmt> audio section completed </cmt> <cmt> moving through chat clients </cmt> <cmt> trying to maintain rough equivalence. </cmt> <cmt> catching up to master from lewisvo </cmt> <cmt> grammar in both lists </cmt> <cmt> continuing translation. </cmt> <cmt> grammar in both files </cmt> <cmt> continuing translation, but also noticing issues with the english translation. </cmt> <cmt> more side by side grammar fixing: </cmt> <cmt> fixing one, improves the other! </cmt> <cmt> updating links </cmt> <cmt> links for macbuntu outdated, will be outdated again in a month. must remember to update these! </cmt> <cmt> adjusting and fixing links </cmt> <cmt> well we've reached parity with the portuguese translation, it's time to bring this branch into the fold. </cmt> <cmt> spanish merging into the fold </cmt>",created a partial spanish translation:
751,"<desc> added nullabletraits template to represent potential null value. also, modified outputs for empty object and array values in pretty-print mode. now, they are emitted as {} and [] instead of: { } [ ] </desc> <cmt> [jsonserialization] add ability to emit 'null' value </cmt> <cmt> [jsonserialization] compact output for empty objects and arrays </cmt> <cmt> now, they are represented as {} and [] instead of: </cmt> <cmt> { </cmt> <cmt> } </cmt> <cmt> and </cmt> <cmt> [ </cmt> <cmt> ] </cmt> <cmt> [jsonserialization] add basic unit tests for jsonserialization </cmt>",add ability to emit 'null' value.
752,"<desc> currently parse-time lookup diagnoses these, so we need to implement it in sema to prepare for disabling parse-time lookup. there are two cases: local declarations inside a bracestmt are now handled via the same checkredeclarationrequest used for type and global members, because we visit them as part of typecheckdecl(). for this, i added a new finishlookupinbracestmt flag to astscope::lookuplocaldecls(); when set, this stops the lookup at the innermost bracestmt, because for purposes of re-declaration checking we only want to consider other declarations with the same name contained in the same bracestmt. this is because shadowing of local declarations from outer scopes is, in fact, permitted. generic parameters, function parameters and pattern bindings in statements get their own bespoke check. this one is simpler, since we have all the declarations in a sequence; we just iterate over sequence looking for duplicate names. while we're here, delete a couple of bits of dead code as well. </desc> <cmt> ast: remove unused unqualifiedlookupfactory::consumer field </cmt> <cmt> ast: remove unused nameddeclconsumer class </cmt> <cmt> sema: remove dead code from checkredeclarationrequest::evaluate() </cmt> <cmt> astscope: add finishlookupinbracestmt parameter to astscope::lookuplocaldecls() </cmt> <cmt> this will be used to implement re-declaration checking for local </cmt> <cmt> declarations. currently this is handled by parse-time lookup. </cmt> <cmt> to make it work with astscope, we need to perform lookups that </cmt> <cmt> look into the innermost local scope only; for example, this is </cmt> <cmt> an invalid redeclaration: </cmt> <cmt> do { </cmt> <cmt> let x = 321 </cmt> <cmt> let x = 123 </cmt> <cmt> } </cmt> <cmt> but the following is fine, even though both vardecls are in the same </cmt> <cmt> *declcontext*: </cmt> <cmt> do { </cmt> <cmt> let x = 321 </cmt> <cmt> do { </cmt> <cmt> let x = 123 </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt> sema: check for re-declarations in local context in checkredeclarationrequest </cmt> <cmt> sema: check for duplicate parameter and generic parameter names when parser lookup is off </cmt> <cmt> the existing redeclaration checking can be extended for declarations in </cmt> <cmt> local scope, but it won't catch these. </cmt>",implement re-declaration checking for declarations in local context
753,"<desc> uploaded files had wrong download links when the deploy had a sub directory. this misbehavior was caused by the wrong usage of the rtrim method, the 2nd parameter is a list of chars, not a string (this method was inspired by php) </desc> <cmt> switched from rtrim to replace </cmt> <cmt> removed subdirectory start </cmt>",broken download link on uploaded files
754,"<desc> the result of the code example at  a change to the website. i have submitted the spacy contributor agreement. i ran the tests, and all new and existing tests passed. --> no code or tests were changed. </desc> <cmt> fixed token span in pattern matcher example </cmt> <cmt> contributor agreement </cmt>",fixed the token span in the text about the rule-based matching example
755,"<desc> as discussed in #15109. this reverts 7e1ed1f. </desc> <cmt> revert ""units: make systemd-repart.service installable"" </cmt> <cmt> this reverts commit 7e1ed1f3b29162df25064b33dc55ac8cf432bb0b. </cmt> <cmt> systemd-repart is not a user service that should be something people </cmt> <cmt> enable/disable, instead it should just work if there's configuration for </cmt> <cmt> it. it's like systemd-tmpfiles, systemd-sysusers, systemd-load-modules, </cmt> <cmt> systemd-binfmt, systemd-systemd-sysctl which are nops if they have no </cmt> <cmt> configuration, and thus don't hurt, but cannot be disabled since they </cmt> <cmt> are too deep part of the os. </cmt> <cmt> this doesn't mean people couldn't disable the service if they really </cmt> <cmt> want to, there's after all ""systemctl mask"" and build-time disabling, </cmt> <cmt> but those are os developer facing instead of admin facing, that's how it </cmt> <cmt> should be. </cmt> <cmt> note that systemd-repart is in particular an initrd service, and so far </cmt> <cmt> enable/disable state of those is not managed anyway via ""systemctl </cmt> <cmt> enable/disable"" but more what dracut decides to package up and what not. </cmt> <cmt> units: run systemd-repart only if there's configuration for it </cmt>","make systemd-repart static again, but condition it out if no config"
756,"<desc> fixes #5881 the path to python.exe on windows needs to change depending on whether it is installed via the boards manager or git (similar to the compiler paths).  adjust accordingly. an empty ""python"" directory will be created by the boards-manager installer in linux to avoid ""tool not available"" errors, and it will contain a symlink to the real system python executable. tested under linux git, linux board-manager, windows git, and windows board-manager. </desc> <cmt> fix packaged python paths for windows </cmt> <cmt> fixes #5881 </cmt> <cmt> the path to python.exe on windows needs to change depending on whether </cmt> <cmt> it is installed via the boards manager or git (similar to the compiler </cmt> <cmt> paths).  adjust accordingly. </cmt> <cmt> add python-placeholder to make boardsmanager happy </cmt> <cmt> an empty ""python"" directory will be created by the boards-manager </cmt> <cmt> installer.  required because all archs need all tools defined. </cmt> <cmt> make the placeholder include a symlink for ""python"" </cmt>",fix boards-manager install issues on linux and windows
757,"<desc> extends #4011 by three lines. i know we have multiple wallet support in theory, but until it actually appears, a static should be fine. </desc> <cmt> make ccryptokeystore::unlock check all keys. </cmt> <cmt> ccryptokeystore::unlock has a loop to attempt decrypting each key which </cmt> <cmt> only executes once, likely due to a simple mistake when the code was </cmt> <cmt> originally written. </cmt> <cmt> this patch fixes the behavior by making it check all keys. it also adds </cmt> <cmt> a fatal assertion in the case some decrypt but some do not, since that </cmt> <cmt> indicates that the wallet is in some kind of really bad state. </cmt> <cmt> this may make unlocking noticeably slower on wallets with many keys. </cmt> <cmt> dont run full check every time we decrypt wallet. </cmt>",make ccryptokeystore::unlock check all keys (but only once)
758,"<desc> previously i pushed changes to test pip packages, but in the test script i did not add the path to where i actually added the dockerfiles. this commit fixes that. see a jenkins run against my branch:  @sandeep-krishnamurthy </desc> <cmt> clean install script </cmt> <cmt> add test for pip installations </cmt> <cmt> remove debug statements & comments </cmt> <cmt> make test runnable as script and from framework </cmt> <cmt> fix path to dockerfiles </cmt> <cmt> merge changes from origin </cmt>",fix script by adding path to dockerfile
759,<desc> ref #13326. refactor rewrite-test logic to support one case supports multi database dialects modify rewrite test case </desc> <cmt> support multi database in one rewrite test case </cmt> <cmt> support multi database in one rewrite test case </cmt> <cmt> support multi database in one rewrite test case </cmt> <cmt> fix checkstyle </cmt>,refactor rewrite test logic for one case supports multi database dialects
760,"<desc> i am so sorry for this low-level mistake, i will check more carefully next time. </desc> <cmt> enhancement agent kafka report plugin </cmt> <cmt> 1. new options to support multi skywalking cluster use same kafka cluster(plugin.kafka.mm_to_source_alias,plugin.kafka.mm_to_source_separator) </cmt> <cmt> 2. resolve agent has no retries if connect kafka cluster failed when bootstrap </cmt> <cmt> update enum value for kafkaconnectionstatus </cmt> <cmt> add namespace support for kafka reporter plugin </cmt> <cmt> ajust code style </cmt> <cmt> support namespace for kafka fetcher </cmt> <cmt> support namespace for kafka fetcher </cmt> <cmt> update for kafka topic namespace </cmt> <cmt> update agent.config </cmt>",fix a bug that bad namespace spell in agent.config
761,<desc> i was having issues with running acceptance tests on my machine and the error message for retryexception was not helpful in determining the issue. the underlying error is eaten up and not logged. i added an option to timedretrypolicy called log_original_error  so we can log the original error in some circumstances such as running acceptance tests. i decided to do this instead of always logging the error since we probably don't always want it. </desc> <cmt> add option to timedretrypolicy to log original error </cmt> <cmt> adds line </cmt>,log the original error for selenium when starting chrome
762,"<desc> it's and alternative fix for jenkins-35206. this fix may be merged together with #2385, because that pr will be still useful for garbage statuses coming from api calls. - fallback to unknown install state in the case of corrupted xml - fallback to the unknown state if the status does not exist anymore (e.g. plugin has been disabled) - unit tests @reviewbybees @kzantow </desc> <cmt> [jenkins-35206] - add unit tests for the deserialization logic </cmt> <cmt> [jenkins-35206] - install state should be robust against messed statuses when deserializing objects </cmt>",make the installstate object deserialization robust against corrupted files
763,<desc> description: this pr adds a shutdown method to the apilistener and calls it where appropriate during server termination. previously there would be a crash due to use after free of objects in thread local storage by streams in the apilistener. funny enough the flakes reported in #9746 happened due to this. risk level: low testing: new unit and integration test. without appropriate termination the new integration test repros the stacktrace reported in #9746. </desc> <cmt> first pass </cmt> <cmt> unit test </cmt> <cmt> fmt </cmt> <cmt> better comments </cmt> <cmt> newline </cmt>,add shutdown method and call during server termination
764,"<desc> hello, after discovering this tool via this video, i have taken a look at the ssti detection patterns used for the differents supported templating engines. based on that, i have added the missing expressions for the following engines: dot.js dust.js thank you very much in advance. </desc> <cmt> add the expression for the dot engine </cmt> <cmt> add the expression for the dust engine </cmt>","add the expression for the ""dot.js"" and the ""dust.js"" template engines"
765,"<desc> change applies the latest loc patch, and bumps the minor version to 2. contains the fixes for #515 and #539 . microsoft reviewers: open in codeflow </desc> <cmt> apply latest loc patch </cmt> <cmt> update minor version to 2 by request </cmt>",apply latest loc patch and update minor version
766,"<desc> closes #32960 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry xref #34872 </desc> <cmt> enh: allow non-consolidation in constructors </cmt> <cmt> mypy fixup </cmt> <cmt> enh: allow non-consolidation in constructors </cmt> <cmt> bug: respect copy=false in constructing dataframe from dict </cmt> <cmt> whatsnew </cmt> <cmt> clean test </cmt> <iss> dataframe change alters original array used in creation </iss>",honor copy=true when passing dict to dataframe
767,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update lolex typings. </cmt> <cmt> bugfix in tsconfig.json - non-existing compiler option. </cmt>",update lolex typings with nexttick() and new clock.install() signature
768,"<desc> summary copied jsdoc comments from js package repo to typings, so that comments would show up in vscode tooltips properly. also fixed some inaccuracies in these comments. template checklist test the change in your own code. (compile and run.) does not apply, no definitions modified add or edit tests to reflect the change. (run with npm test.) same as above avoid common mistakes. same as above follow the advice from the readme. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: here and here if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. does not apply if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. does not apply </desc> <cmt> added comments to api endpoint methods </cmt> <cmt> * comments copied from spotify-web-api-node repo </cmt> <cmt> added doc comments to oauth flow response models </cmt> <cmt> removed types from @param & @returns </cmt>",added doc comments to api methods and some reponse interfaces
769,<desc> issue: #7499 module format docs: #7498 </desc> <cmt> cli templates: ember => module format </cmt> <cmt> cli templates: marko => module format </cmt> <cmt> cli templates: mithril => module format </cmt> <cmt> cli templates: rax => module format </cmt> <cmt> cli templates: riot => module format </cmt> <cmt> cli templates: svelte => module format </cmt>,update sb init to module format for ember/marko/mithril/rax/riot/svelte
770,<desc> support pausing amqp consumption when producer is paused. all unprocessed transactions consumed from amqp will be rejected with re-queue option. adds to the ability to resume from being paused on startup added via #10541. epe-1185 select one: select any that apply: </desc> <cmt> update test to actually use amqp queue for transactions and test paused producer resuming </cmt> <cmt> make hard-coded block_interval explicit </cmt> <cmt> support pausing production by rejecting/requeueing amqp trx back to amqp </cmt>,"amqp pause production, rejects with requeue"
771,"<desc> try to make the layout match the way it does for the other index classes, similar to what we're doing with series/dataframe tests </desc> <cmt> directories for categorical and range eindexes </cmt> <cmt> dirs for categorical and range index tests </cmt>","directories for categoricalindex, rangeindex tests"
772,"<desc> mapped types can circularly reference themselves (because member resolution is deferred), but array and tuple type instantiations cannot. this causes an issue when a circular homomorphic mapped type is instantiated for an array or tuple type as we now create array and tuple instantiations for such mappings (see #26063). with is pr we quickly detect and stop the runaway recursion that can occur by substituting errortype for the instantiation. we would eventually do this after 50 levels of nested instantiations, but exponential recursive fan-out could keep us from ever getting there. fixes #27881. </desc> <cmt> allow discriminant property to contain some non-unit types </cmt> <cmt> discriminant must include at least one unit type and no instantiable types </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <cmt> handle circular mapped type instantiations for arrays and tuples </cmt> <cmt> add regression test </cmt> <cmt> accept new baselines </cmt>",fix circular mapped type instantiations for arrays and tuples
773,"<desc> just submitting this pull request into a new supports branch, which we could use to make everything all, er, supportsy. see #818. i've added a function called nativecssdetect() (which does the work) and a couple of examples in the form of the flexbox and flexboxlegacy tests. these give the correct results using the native api in firefoxaurora and opera 12.14 and give the correct results using normal feature detection in chrome. notes: the function currently only supports the f(prop, value) interface, not the f(any old condition string) interface, because the former seemed much more useful it also takes 2 additional boolean args to specify whether or not to test all prefixed variants of the property and value respectively i've put in a fallback to the at-rule, because opera 12.14 only partially implements the javascript api (the part the implemented would have been fine for this actually, but hey) i expect we'd actually want to integrate this with testallprops() / testprops(), so for most tests we can just extend them to e.g.: return testpropsall('flexwrap', 'wrap'); i'll have a go at a version integrated into testallprops() and testprops(). early feedback very welcome. </desc> <cmt> initial version of nativecssdetect() - only accepts a string e.g. '(flex-wrap:reverse)'; would quite like to overload the interface </cmt> <cmt> revised version of nativecssdetect - this time only allows (prop, value) interface, because it's probably more common. also updated flexbox and flexboxlegacy tests to show how it could be used. </cmt>",first crack at an attempt to use css.supports() internally (#818)
774,"<desc> via-supporting keymaps for both solder and hotswap think6.5 pcbs. disables mousekey support to make the firmware fit. uses layout_all on the solder board since it supports things like iso, split left shift, split backspace and a 7u bottom row. uses layout_65_ansi_blocker on the hotswap board since the layout is fixed. tested with via v1.2.4 and a solder think6.5. i also committed the via json definitions to the keymap dir, for reference. i'll also commit those to via's keyboards repo. i also updated the usb vendor and product ids for both boards, since via needs those to identify the board properly. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> via support for think6.5 </cmt> <cmt> via support for think6.5 hotswap </cmt> <cmt> via works better with separate layout options </cmt> <cmt> remove the colours used to help develop it in kle </cmt> <cmt> pay better attention to the json linter </cmt>",via support for the think6.5
775,"<desc> this change separates the signal handling trigger in the eval loop from the ""pending calls"" machinery.  there is no semantic change and the difference in performance is insignificant. the change makes both components less confusing.  it also eliminates the risk of changes to the pending calls affecting signal handling.  this is particularly relevant for some upcoming pending calls changes i have in the works. </desc> <cmt> do not clear an existing error when handling signal failures. </cmt> <cmt> factor out make_pending_calls(). </cmt> <cmt> add _pyruntimestate.ceval.signals_pending. </cmt> <cmt> add _pyruntimestate.ceval.pending.busy. </cmt> <cmt> handle signals (mostly) separately. </cmt> <cmt> explicitly handle signals and pending calls separately in the eval loop. </cmt> <cmt> move ""busy"" back into make_pending_calls(). </cmt> <cmt> handle the pending calls flag exclusively in make_pending_calls(). </cmt> <cmt> simplify. </cmt>","stop using the ""pending calls"" machinery for signals."
776,"<desc> this is the second batch of incidental integration tests, sourced primarily from cloud integration tests. there will be overlap with existing cloud integration tests until collection migration is completed. integration tests </desc> <cmt> initial copy of incidental tests. </cmt> <cmt> update incidental test aliases. </cmt> <cmt> rewrite target references for renamed targets. </cmt> <cmt> add incidental tests to ci. </cmt> <cmt> update sanity tests for incidental cloud tests. </cmt> <cmt> copy contrib files into test. </cmt> <cmt> update paths in test. </cmt> <cmt> add support plugins. </cmt> <cmt> update plugin to work around missing deps. </cmt> <cmt> update sanity ignores. </cmt>",second batch of incidental integration tests.
777,"<desc> move on with md2charactercomplex, gyroscope and morphblendmesh. </desc> <cmt> jsm: added module and ts file for gyroscope. </cmt> <cmt> jsm: added module and ts file for morphblendmesh. </cmt> <cmt> jsm: added module and ts file for md2charactercomplex. </cmt>",added more module and ts files
778,"<desc> the memory used by pt run was increasing on consecutive launches. one of the reasons for this to happen was that all the image icons were cached. even though the code had an upperlimit on the maxcached values which was set to 5000, this part of the code was never called unless powertoys was closed. therefore, since all the icons were being cached, the size of the dictionary continued to increase. work around- instead of caching all images and increasing the size of the dictionary, the following changes have been made - reduce the number of cached images to 50. if the number of images increase over the permissible factor (set to 2) of the cached images (ie. 2 * 50), then the ones which are infrequently used would be removed from the dictionary and there be 50 images that are cached. this ensures that the dictionary size is always less than 100. pr checklist applies to #2047. cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx validation steps performed the changes in this pr can be validated by following these steps - take snapshots of the memory usage by using the diagnostic tools of visual studio (debug -> windows -> diagnostic tools). take the first snapshot after all the dlls are loaded and the memory utilization is stabilized. take the next memory snapshot after many queries (don't have to execute an application). the aim is to just load many icons. compare the second snapshot by setting the first one as the baseline. search for memory size diff in bytes for concurrent dictionary with value imagesource. compare this value to that obtained without the changes in this pr, to get the results as shown in the following images. before this change (after about twenty searches)- after this change (after about twenty searches) - outstanding tasks even though this fixes the issue partially, the memory consumed by pt run is still high. it starts off with 160/170 mb and after first launch goes up to 230/250 mb, following which it increases a little on each run. another area where the memory utilization can be improved is the dictionary<int64, weakreference>. the following snapshots are after searching for a few apps using pt run - it seems like this is related to the resourcedictionary of the ui components. the number of elements in this dictionary and the components that they are referring to seem to increase on each run. this needs further investigation. additional information i tried to set a hard limit on the heap size using runtime.config.json and system.gc.heaphardlimit. i did not notice any drastic differences in the garbage collection when the limit was set to values ranging from 20 mb to 200 mb. also, this might differ from system to system so i did not go down this route. references - </desc> <cmt> reducing storage of images </cmt> <cmt> added task.run </cmt> <cmt> cleaned up code and added comments </cmt> <cmt> renamed variable </cmt> <cmt> refactored code </cmt>",partial fix for memory issue - limiting the number of imagesources cached
779,"<desc> in the tomorrow dark theme, the code is jammed up against the gutter. we should be able to use padding on the scroll view and have the editor gracefully handle. this: not this: here are some changes that need to happen in order to make this happen. </desc> <cmt> use padding in the pixel left calculation </cmt> <cmt> now themes can specify padding in the scroll-view so the text isn't </cmt> <cmt> jammed up against the </cmt> <cmt> properly reset the size of layers on resize </cmt> <cmt> otherwise, when a theme has padding in the scroll-view, it will be </cmt> <cmt> scrollable all the time (width:100%). </cmt>",handle themes with padding on the scroll view
780,<desc> the same error happen here again (#6785 (comment)) if someone has access to the site and can run the tests and check if they need to be changed </desc> <cmt> [utlis] add extract_attributes for extracting html tags attributes </cmt> <cmt> [brightcove] add support for brightcove in page embed(fixes #6824) </cmt>,add support for brightcove in page embed(fixes #6824)(fixes #5946)
781,"<desc> this pr addresses many problems with module graph loading introduced in #5029, as well as many long standing issues. ""modulegraphloader"" has been wired to ""moduleloader"" implemented on ""state"" - that means that dependency analysis and fetching is done before spinning up ts compiler worker. basic dependency tracking for ts compilation has been implemented. errors caused by import statements are now annotated with import location. fixes #1692 fixes #5080 fixes #5419 fixes #5815 fixes #5900 </desc> <cmt> move bundle specific logic to main.rs </cmt> <cmt> deduplicate caching of compiled files </cmt> <iss> cache invalidation when recompiling a module </iss> <iss> report original file and line for unsupported scheme when compiling </iss> <iss> import error backtraces </iss> <iss> `@ deno-types` + import map does not resolve jsx types. </iss> <iss> unable to import javascript files from tsx </iss>",ts compiler and module graph
782,"<desc> i've taken @mikemaccana's commit, then added more hints to multiple --host and then copied the changes to the markdown. closes #5372 </desc> <cmt> - unix://path/to/socket should read unix:///path/to/socket like the rest of the documentation (a slash was missing) </cmt> <cmt> - mention that [] options may be specified multiple times on the usage page </cmt> <cmt> docker-dco-1.1-signed-off-by: mike maccana <mike.maccana@gmail.com> (github: mikemaccana) </cmt> <cmt> docker-dco-1.1-signed-off-by: mike maccana <mike.maccana@gmail.com> (github: svendowideit) </cmt> <cmt> add a reference to multiple -h options, and update the other example of -h option </cmt> <cmt> and copy changes to the cli.md file </cmt> <cmt> docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@fosiki.com> (github: svendowideit) </cmt>",docs tweaks to socket options
783,"<desc> description: adjusted tradfri module to use  pytradfri 2.x interface added support for the whole range of white spectrum lightbulbs, instead only 3 predefined values provided by ikea app correctly set minimum and maximum supported light temperatures checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> [light.tradfri] support for pytradfri version supporting full white spectrum </cmt> <cmt> [light.tradfri] checkout pytradfri master </cmt> <cmt> developer docker image adjusted </cmt> <cmt> [light.tradfri] pytradfri 2.2 support for white spectrum bulbs </cmt> <cmt> * upstream/dev: (113 commits) </cmt> <cmt> fix fitbit error when trying to access token after upgrade. (#9183) </cmt> <cmt> upgrade sendgrid to 5.0.1 (#9215) </cmt> <cmt> upgrade pyasn1 to 0.3.3 and pyasn1-modules to 0.1.1 (#9216) </cmt> <cmt> directv: extended discovery via rest api, bug fix  (#8800) </cmt> <cmt> bayesian binary sensor (#8810) </cmt> <cmt> add cloud auth support (#9208) </cmt> <cmt> abode push events and lock, cover, and switch components (#9095) </cmt> <cmt> lint sonarr tests </cmt> <cmt> upgrade pymysensors to 0.11.1 (#9212) </cmt> <cmt> refactor rfxtrx (#9117) </cmt> <cmt> issue #6893 in rfxtrx (#9130) </cmt> <cmt> support for season sensor (#8958) </cmt> <cmt> add counter component (#9146) </cmt> <cmt> fix and optimize digitalloggers platform (#9203) </cmt> <cmt> prevent error when no forecast data was available (#9176) </cmt> <cmt> add ""status"" to sonarr sensor (#9204) </cmt> <cmt> fix worldtidesinfo #9184 (#9201) </cmt> <cmt> update pushbullet.py (#9200) </cmt> <cmt> fix dht22 when no data was read initially #8976 (#9198) </cmt> <cmt> prevent icloud exceptions in logfile (#9179) </cmt> <cmt> ... </cmt> <cmt> removed fix already included in dev </cmt> <cmt> style adjusted </cmt>",full range of  white spectrum lightbulbs support
784,<desc> establish module state convert types to heap types and add them to module state add multi-phase init support </desc> <cmt> add empty module state </cmt> <cmt> convert encoder and decoder types to heap type </cmt> <cmt> convert reader and writer types to heap type </cmt> <cmt> convert multibytecode type to heap type </cmt> <cmt> support multi-phase init </cmt> <cmt> add news </cmt> <cmt> fix type names </cmt>,adapt _multibytecodec to multi-phase initialization
785,"<desc> we added support for dutch to spacy. this pull request includes the actual additions to the spacy code to add the language class. we built the language data (vocab data and pos/ner tagger) on a small corpus (1000 articles from wikipedia), this is available at  the models are not yet very good and we think they could easily be improved further by using a better corpus. the dependency parser has not yet been trained. we documented the process, as well as the next steps in the spacy-dutch repository. this repository also contains scripts to regenerate language data from new corpora. contributers: dafne van kuppevelt, janneke van der zwaan, willem van hage (netherlands escience center). contributer agreement signed by rob van nieuwpoort, director of technologies of the netherlands escience center. motivation and context we work on multiple projects that involve dutch text, and we would like to use spacy for our analyses. by documenting carefully how we construct the language data, we hope this helps others to add new languages. possibly, our description could also be integrated in the spacy documentation. how has this been tested? we added a new test for the language dutch. we ran this test in python 2.7 and 3.5 environments and they passed. there are hardly any interactions with these additions to the rest of the code. to check the sanity of the language data and models, we inspected the outcome for some example sentences and we calculated the performance of the models.  details can be found in the spacy-dutch repository screenshots (if appropriate): types of changes bug fix (non-breaking change fixing an issue) new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my code follows spacy's code style. my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. </desc> <cmt> add directory and initial (empty) files for language dutch </cmt> <cmt> added language class and some language data (with some todos) for dutch </cmt> <cmt> added nl module for dutch </cmt> <cmt> added language dutch to init file </cmt> <cmt> update dutch language data </cmt> <cmt> - use dutch tag map </cmt> <cmt> - remove tokenizer exceptions </cmt> <cmt> update language data with tag map from ud_dutch </cmt> <cmt> merge github.com:explosion/spacy into dutch </cmt> <cmt> merge github.com:explosion/spacy into dutch </cmt> <cmt> fixed bug in init_model so that it runs for dutch </cmt> <cmt> signed contributer agreement by rob van nieuwpoort </cmt>",support for dutch in spacy
786,"<desc> suppose we have: package-a package-b package-c the following works as expected: lerna bootstrap --ignore=package-@(a|b) the message is: ignoring packages that match 'package-@(a|b)' and the following packages are bootstrapped: package-c the following does not work as expected: lerna bootstrap --ignore=package-{a,b} the message is: ignoring packages that match 'package-a,package-b' and the following packages are bootstrapped: package-a (incorrect) package-b (incorrect) package-c the latter glob is expanded to an array even before reaching filterpackage in packageutilities. (notice the difference in messages). however, the logic regarding negation (i.e. maybenegate) was only within glob.some, which would not work in the case that glob.length > 1. this pr changes the boolean reducer depending on the desired negation (i.e. array.prototype.some for the standard case, and array.prototype.every for the negated case. </desc> <cmt> add failing test </cmt> <cmt> fix ignore with certain globs </cmt>",fix --ignore flag when globs are expanded to an array
787,<desc> this allows a mismatching href and as value when the params are manually provided in the href's query. this mismatching can occur when you are using the new experimental custom-routes feature and you are rewriting to a dynamic route we currently aren't able to parse the params automatically since we don't ship the custom-routes to the client so we can't find where the as value is pointing to client-side x-ref: #9700 (comment) </desc> <cmt> allow mismatch href and as when manually provided </cmt>,allow mismatching href and as when manually provided
788,"<desc> form validation follows comma-separated list of media types defined on newly-added admin setting. this pr also fixes a known vulnerability where a given user could upload files of any type with drag-and-drop (for this particular test we are accepting image/png only): good file bad file closes #1058 closes #756 </desc> <cmt> added ""fileupload"" settings group </cmt> <cmt> providing access to settings subscription in order to setup client-side upload objects </cmt> <cmt> applying newly-added file upload settings. </cmt> <cmt> updating jalik:ufs and jalik:ufs-gridfs </cmt> <cmt> blocking drag and drop file uploads of any kind. </cmt>",added settings for file upload type and size limit
789,<desc> this change will help to distinguish h264 and hevc via mask form usage and help to update ui for hevc support </desc> <cmt> adjustment to report qsv availability in mask form </cmt> <cmt> ui adjustment for mask usage </cmt>,report in mask form for supported codec(s)
790,"<desc> this pr adds a new api that creates the follow index and starts the follow changes from leader index into the newly created follow index. the api looks the same as the existing follow index api, with the big difference that it creates the follow index. the create and follow api, creates a follow index based on the indexmetadata of the leader index, then waits for the shards to become available and the delegate to the existing follow index api. relates to #30102 </desc> <cmt> added create and follow api. </cmt> <cmt> renamed followexisting* internal names to just follow* </cmt> <cmt> and fixed tests </cmt>",add create and follow api
791,"<desc> this pull request fixes [jenkins-15408]. the problem is caused by a bug in reopenablerotatingfileoutputstream, as is demonstrated by the unit test testrotation() failing (on windows only). this pull request fixes the issue and thereby the unit test. this also contributes to fixing [jenkins-12768]. </desc> <cmt> fixed reopenablerotatingfileoutputstream to work on windows </cmt>",rotation of slave launch logs on windows
792,"<desc> carry of pr #20902 allow the docker daemon to run inside a user namespaced parent process.  original patch by @hallyn; i've added a change to revert to ""real"" chroot when inside a userns that came about since the original patch. i have tested this capability inside lxc running an ubuntu:xenial image with a binary built from this pr patchset.  to successfully run the docker daemon i used the following command line: dockerd -d -s vfs --oom-score-adjust=0 inside a user namespace, writing to the oom_score_adj special proc file fails, and i can't get any backend driver to work outside of vfs. i cannot run the docker engine inside of a runc container with user namespaces enabled due to how the /sys/fs/cgroups mount is handled under runc. therefore it is hard to write a test that integrates well with our ci system without requiring a working lxc setup until we solve this problem in runc. </desc> <cmt> don't create devices if in a user namespace </cmt> <cmt> if we are running in a user namespace, don't try to mknod as </cmt> <cmt> it won't be allowed.  libcontainer will bind-mount the host's </cmt> <cmt> devices over files in the container anyway, so it's not needed. </cmt> <cmt> the chrootarchive package does a chroot (without mounting /proc) before </cmt> <cmt> its work, so we cannot check /proc/self/uid_map when we need to.  so </cmt> <cmt> compute it in advance and pass it along with the tar options. </cmt> <cmt> use real chroot if daemon is running in a user namespace </cmt> <cmt> the namespace unshare+pivot root is not possible when running inside a </cmt> <cmt> user namespace, so fallback to the original ""real"" chroot code. </cmt> <cmt> docker-dco-1.1-signed-off-by: phil estes <estesp@linux.vnet.ibm.com> </cmt>",allow engine to run inside a user namespace
793,"<desc> in order to maintain a cleaner commit history, i made a new branch and will be closing the other pr. this is the only way i see of giving this work a cleaner commit history. @larson-carter </desc> <cmt> create check-suite.yml </cmt> <cmt> update readme.md </cmt>",create github action to run tests
794,"<desc> this adds an error message that can help better identify the issue when an old/invalid state instance is used when createstate is called. related issues fixes #11975 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> init </cmt> <cmt> added error message to assert </cmt> <cmt> removing unrelated changes </cmt> <iss> better error message for assertion '_state._widget == null': </iss>",error message for createstate assertion
795,"<desc> as we work on reusing microsoft.reactnative source files in the desktop rn project, having pch files in the root folder makes it difficult to use local for the desktop project pch files because it picks them up fro the microsoft.reactnative project. in this change we move the microsoft.reactnative pch files into a pch subfolder and add the subfolder path to the includes path for the microsoft.reactnative project. after that, other projects will not see our pch files unless they explicitly add the new path to their include paths (which they better not to do). microsoft reviewers: open in codeflow </desc> <cmt> move pch files into a pch subfolder. </cmt> <cmt> change files </cmt>",move microsoft.reactnative pch files in a pch subfolder
796,"<desc> what did you implement: closes #3018 how did you implement it: i added a build.ps1 that mirrors the behavior of the build.sh bash script. of note, the zipdirectory method doesn't allow creating a zip in the file that it's zipping, so i create it in root and then copy it back to the publish. how can we verify it: on a windows machine, run serverless create -t aws-csharp ./build.ps1 # note that a deploy-package.zip is created in bin/release/netcoreapp1.0/publish serverless deploy # succeeds, deploys the package zip serverless invoke -f hello # returns ""hello world"" response todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources enable ""allow edits from maintainers"" for this pr change ready for review message below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add uild.ps1 and update tests&docs </cmt> <cmt> remove chmod doc line, not necessary </cmt>",add build.ps1 and update tests&docs
797,"<desc> what did you implement: updated docs closes #xxxxx how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> updating branch </cmt> <cmt> spotinst - reformatting docs to be more readable </cmt>",spotinst - reorganizing guide structure for readability
798,"<desc> in some caffe prototxt,the layer type of convolutiondepthwise is ""depthwiseconvolution"",using the caffe2ncnn tool generate the ncnn.param file maybe loss the group_num param. </desc> <cmt> add armv7 int8 conv3x3s1,using vaddw to replace vadd and vmovl </cmt> <cmt> fix the caffe2ncnn  bug that ""depthwiseconvolution"" loss group num param </cmt>","fix the caffe2ncnn that ""depthwiseconvolution"" loss group num param"
799,"<desc> [this is the forward port of #2134 changes relative to the version committed on 1.0-maint: mapping of new commands to features: borg export-tar and borg diff use manifest.operation.read borg recreate uses manifest.operation.check borg debug dump-manifest uses manifest.no_operation_check as all other debug commands. ] this should allow us to make sure older borg versions can be cleanly prevented from doing operations that are no longer safe because of repository format evolution. this allows more fine grained control than just incrementing the manifest version. so for example a change that still allows new archives to be created but would corrupt the repository when an old version tries to delete an archive or check the repository would add the new feature to the check and delete set but leave it out of the write set. this is somewhat inspired by ext{2,3,4} which uses sets for compat (everything except fsck), ro-compat (may only be accessed read-only by older versions) and features (refuse all access). this implements #1806 </desc> <cmt> add minimal version of in repository mandatory feature flags. </cmt> <cmt> this should allow us to make sure older borg versions can be cleanly </cmt> <cmt> prevented from doing operations that are no longer safe because of </cmt> <cmt> repository format evolution. this allows more fine grained control than </cmt> <cmt> just incrementing the manifest version. so for example a change that </cmt> <cmt> still allows new archives to be created but would corrupt the repository </cmt> <cmt> when an old version tries to delete an archive or check the repository </cmt> <cmt> would add the new feature to the check and delete set but leave it out </cmt> <cmt> of the write set. </cmt> <cmt> this is somewhat inspired by ext{2,3,4} which uses sets for </cmt> <cmt> compat (everything except fsck), ro-compat (may only be accessed </cmt> <cmt> read-only by older versions) and features (refuse all access). </cmt> <cmt> add tests for mandatory repository feature flags. </cmt> <cmt> permit manifest version 2 as well 1 one. </cmt>",add minimal version of in repository mandatory feature flags. (master)
800,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> updated type declarations </cmt> <cmt> and since the root file had a .prettierrc i ran prettier on it </cmt> <cmt> new tests </cmt> <cmt> also ran prettier here as well </cmt>,updated definitions to include changes since v1.2
801,"<desc> change implemented schema validation using valijson added manifest schemas for preview and v1 manifests changed manifest object model to better reflect v1 manifests changed manifestlocalization to be std::map based for easier future locale processing implemented merge logic for multiple file manifests validation existing tests and added new tests validated all 3000+ manifests currently in winget-pkgs passed manifest validation note: after this change, we might need to revisit and relax restrictions in some of v1 manifest schemas as i found around 300+ manifests in current winget-pkgs will fail in new restrictions imposed by v1 manifest schemas microsoft reviewers: open in codeflow </desc> <cmt> vcxitems for valijson </cmt> <cmt> vcxitems for schemas </cmt> <cmt> initial check </cmt> <cmt> second check </cmt> <cmt> working snapshot </cmt> <cmt> fix </cmt> <cmt> preview compatibility fix </cmt> <cmt> v2 compatibility fix </cmt> <cmt> working snapshot 2 </cmt> <cmt> new tests </cmt>",implement v1 manifest  and schema validation
802,"<desc> reopening #28009 (after addressing comments on the closed pr) adds documentation to the guides about how to get session middleware back when using the api_only flag. without this, it's not clear that session middleware has special cases to handle with the api_only flag. hopefully will help people avoid this problem: </desc> <cmt> document how to add session middleware back </cmt> <cmt> without this, it's not clear that session middleware has special cases to handle with the api_only flag </cmt> <cmt> clarify session management middleware sections </cmt> <cmt> addresses some comments in original pr for docs on using session management middleware in api apps </cmt>",document how to add session middleware to an api app
803,"<desc> while streaming from obs on an unstable connection, i have found instances where obs will hang until it is force quit. during some testing with arut/nginx-rtmp-module proxying connections i found that when the obs that was streaming to nginx-rtmp-module had network issues it would cause the obs to hang and never recover. i eventually identified that the server was sending a netstream.publish.badname status message that was never handled. more information from adobe about that error can be found on their site. i would like obs to not hang when there are network glitches. i tested this on macos by making a build on my macbook pro and did the following: from the nginx config: application stream { live on; publish_notify on; play_restart on; } steps: turn off wifi and connect the macbook pro via ethernet start obs via the command line start a custom stream to an nginx-rtmp server disconnect the ethernet plug it back in 10 seconds later i checked the logs and status bar to see if the system reconnected. it would not reconnect when using obs in master but would reconnect when using this branch. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> obs-outputs: handle rtmp netstream.publish.badname response </cmt> <cmt> adobe media server and nginx-rtmp can return this status response to a </cmt> <cmt> publisher if the key is already being used to publish. </cmt> <cmt> obs-outputs: log unhandled rtmp status responses </cmt> <cmt> rtmp status responses that are not handled are currently silently ignored </cmt> <cmt> making it difficult to identify issues. </cmt>",handle netstream.publish.badname from rtmp server
804,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description i fixed the 2 last critic error discover by lgtm. is a false positif, cmd is type ut8 and can't overflow because the standart defined his value between 0 and 255. but i add a condition to prevent regression. add a threshold of 5000 ->  test plan run the test suite closing issues work on #16493 </desc> <cmt> remove useless cast </cmt> <cmt> fix lgtm error root/libr/socket/socket_http_server.c </cmt> <cmt> add regression prevention if </cmt>",fix 2 last critic error lgtm
805,"<desc> if an override b.f() is more visible than a base method a.f(), it is possible that an override c.f() of b.f() cannot see the original method a.f(). in this case, we would encounter linker errors if we referenced the method descriptor or method dispatch thunk for a.f(). make this work by treating b.f() as the least derived method in this case, and ensuring that the vtable thunk for b.f() dispatches through the vtable again. fixes rdar://problem/48330571, </desc> <cmt> silgen: support vtable thunks for 'modify' accessors </cmt> <cmt> when checking if a vtable override is abi compatible with the </cmt> <cmt> base class method, make sure to check yields too. </cmt> <cmt> also, add support for coroutines to vtable thunks, using code </cmt> <cmt> that i've copy and pasted and tweaked from witness thunks. </cmt> <cmt> (it would be nice to combine witness thunks and vtable thunks </cmt> <cmt> into a single code path for 'method thunks', but that requires </cmt> <cmt> some additional refactoring, so live with the copy and paste </cmt> <cmt> for now). </cmt> <cmt> sema: remove dead code concerning 'default constructible' classes </cmt> <cmt> we used to try to emit a 'default initializer' in a class with a superclass, </cmt> <cmt> as long as the superclass was 'default initializable', meaning it had at </cmt> <cmt> least one designated initializer where all parameters had a default </cmt> <cmt> expression. </cmt> <cmt> however this code path was never taken, because the designated initializer </cmt> <cmt> inheritance mechanism supercedes it. probably it became dead once we </cmt> <cmt> implemented inheritance of initializers with default arguments. </cmt> <cmt> irgen: more precise check lines for test/irgen/weak_import_native.swift </cmt> <cmt> sema: don't emit stubs to override inaccessible superclass initializers </cmt> <cmt> there was a behavioral difference between binary modules and textual interfaces. </cmt> <cmt> since a binary module includes information about all members, including private </cmt> <cmt> and internal members, we would emit overrides for all designated initializers </cmt> <cmt> when subclassing a class, including those we cannot access. </cmt> <cmt> this was problematic because then we reference the superclass initializer's </cmt> <cmt> method descriptor, which had to be forced to have public linkage so that the </cmt> <cmt> subclass could reference it. </cmt> <cmt> however a textual interface only includes public members so any such </cmt> <cmt> initializers were simply dropped. the irgen hack is thus no longer necessary </cmt> <cmt> when textual interfaces are used. </cmt> <cmt> in reality neither behavior is correct because the presence of inaccessible </cmt> <cmt> initializers should inhibit the inheritance of any designated initializer; </cmt> <cmt> however i'm going to try to fix that separately since it is a source breaking </cmt> <cmt> change and thus needs to be staged in as a warning. the latter fix is </cmt> <cmt> tracked by <rdar://problem/51249311>. </cmt> <cmt> stdlib: managedbuffer.init(_donotcallme:) was abi in swift 5 and should be @usablefrominline </cmt> <cmt> irgen: remove hack giving method descriptors of open class initializers public linkage </cmt> <cmt> this was done even for non-public inits because subclasses would always </cmt> <cmt> override the base class's designated initializers, even if they were </cmt> <cmt> inaccessible. </cmt> <cmt> this is an abi break, however in practice the only affected class </cmt> <cmt> initializer was managedbuffer.init(_donotcallme:()), and we can just </cmt> <cmt> make it @usablefrominline. </cmt> <cmt> silgen: correctly emit vtables when an override is more visible than the base </cmt> <cmt> if an override b.f() is more visible than a base method a.f(), it is </cmt> <cmt> possible that an override c.f() of b.f() cannot see the original method </cmt> <cmt> a.f(). </cmt> <cmt> in this case, we would encounter linker errors if we referenced the </cmt> <cmt> method descriptor or method dispatch thunk for a.f(). </cmt> <cmt> make this work by treating b.f() as the least derived method in this </cmt> <cmt> case, and ensuring that the vtable thunk for b.f() dispatches through </cmt> <cmt> the vtable again. </cmt> <cmt> fixes <rdar://problem/48330571>, < </cmt>",correctly emit vtables when an override is more visible than the base [5.1]
806,<desc> add a new symbolic function broadcast_tensors() to support exporting torch.broadcast_tensors() function. this is required by exporting torch.distribution.normal() function. add a new symbolic function normal() to support exporting torch.distribution.normal() function. add relative tests for normal and uniform ops as well. </desc> <cmt> enable the support to torch.distribution.normal op </cmt> <cmt> add tests for test_dist_uniform. </cmt>,enable aten:normal op and add tests for aten:uniform op.
807,"<desc> please, could you take a look at this code? @greens @mablewiczs @mgoralczyks @dczarneckas @pkacprowiczs @mmateusiaks </desc> <cmt> new dth for dome mouser </cmt> <cmt> dth improvement, bug fix </cmt> <cmt> small improvement, adjusted checkinterval, changed icons, removed some comments </cmt>",wwst-1636 new dth for dome mouser - dmmz1
808,"<desc> this pr is for code changes as well as a spec for #1043 closes #1043 cla signed. if not, go over here and sign the cla requires documentation to be updated this pr includes the code changes that enable users to set an initial position (top left corner) and launch maximized. there are some corner cases: multiple monitors. the user should be able to set the initial position to any monitors attached. for the monitors on the left side of the major monitor, the initial position values are negative. if the initial position is larger than the screen resolution and the window is off-screen, the current solution is to check if the top left corner of the window intersect with any monitors. if it is not, we set the initial position to the top left corner of the nearest monitor. if the user wants to launch maximized and provides an initial position, we launch the maximized window on the monitor where the position is located. testing: to test: check-out this branch and build on vs2019 launch terminal, and open settings. then close the terminal. add the following setting into json settings file as part of ""globals"", just after ""initialrows"": ""initialposition"": ""1000, 1000"", ""launchmode"": ""default"" my test data: i have already tested with the following variables: 1. showtabsintitlebar true or false 2. the initial position of the top left corner of the window 3. whether to launch maximized 4. the dpi of the monitor test data combination: non-client island window (showtabsintitlebar true) three monitors with the same dpi (100%), left, middle and right, with the middle one as the primary, resolution: 1980 * 1200, 1920 * 1200, 1920 * 1080 launchmode: default in-screen test: (0, 0), (1000, 500), (2000, 300), (-1000, 400), (-100, 200), (-2000, 100), (0, 1119) out-of-screen: (200, -200): initialize to (0, 0) (200, 1500): initialize to (0, 0) (2000, -200): initialize to (1920, 0) (2500, 2000): initialize to (1920, 0) (4000 100): initialize to (1920, 0) (-1000, -100): initialize to (-1920, 0) (-3000, 100): initialize to (-1920, 0) (10000, -10000): initialize to (1920, 0) (-10000, 10000): initialize to (-1920, 0) (0, -10000): initialize to (0, 0) (0, -1):  initialize to (0, 0) (0, 1200):  initialize to (0, 0) launch mode: maximize (100, 100) (-1000, 100): on the left monitor (0, -2000): on the primary monitor (10000, 10000): on the primary monitor left monitor 200% dpi, primary monitor 100% dpi in screen: (-1900, 100), (-3000, 100), (-1000, 100) our-of-screen: (-8000, 100): initialize at (-1920, 0) launch maximized:  (-100, 100): launch maximized on the left monitor correctly left monitor 100% dpi, primary monitor 200% dpi in-screen: (-1900, 100), (300, 100), (-800, 100), (-200, 100) out-of-screen: (-3000, 100): initialize at (-1920, 0) launch maximized: (100, 100), (-1000, 100) for client island window, the test data is the same as above. issues: if we set the initial position on the monitor with a different dpi as the primary monitor, and the window ""lays"" across two monitors, then the window still renders as it is on the primary monitor. the size of the window is correct. </desc> <cmt> spec version 1 for set terminal initial position </cmt> <cmt> fix the spec title </cmt> <cmt> add a new function to read initial position properties </cmt> <cmt> test version - 9-6 </cmt> <cmt> spec for code review updates </cmt> <cmt> code change 9-11 </cmt> <cmt> temporary changes 9 12 </cmt> <cmt> enable setting an initial position for terminal and maximization launch </cmt> <cmt> remove empty lines </cmt> <cmt> remove empty lines </cmt> <iss> be able to set an initial position for the terminal </iss>",enable setting an initial position and maximization launch for terminal
809,<desc> added ability to export as newline separated json (nsj) as well as appropriate language. also added language to import.py that indicates nsj is already accepted as an import type. </desc> <cmt> add export support for new-line separated json </cmt> <cmt> added comments in export and import and refactoring export </cmt> <cmt> refactor launch_writer </cmt>,add ability to export as newline separated json (nsj)
810,"<desc> add large tensor support to optimizers and 1 activation function hard_sigmoid adam_update ftml_update mp_sgd_mom_update mp_sgd_update rmsprop_update rmspropalex_update sgd_mom_update sgd_update signsgd_update signum_update nagmom mp_nagmom lamb mp_lamb ftrl adagrad please feel free to remove inapplicable items for your pr. all changes have test coverage: code is well-documented: to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change modified:   src/operator/optimizer_op-inl.h modified:   src/operator/tensor/elemwise_unary_op.h tested hard_sigmoid with lt input : pass >>> import mxnet as mx >>> mx.nd.hard_sigmoid(data=mx.nd.random_normal(shape=(1, 2**32 + 1))) [[0.9424413 0.6548008 0.7086881 ... 0.53579605 0.37985992 0.20645571]] <ndarray 1x4294967297 @cpu(0)> rest of the *_update functions can't be tested with random_normal inputs as they give nans as result (even for shape < 2**32) hence not tested. but they don't give a segmentation fault (which previously was the problem due to lack of large tensor support). </desc> <cmt> fix hard sigmoid </cmt> <cmt> change int i to index_t i for all kernel map functions </cmt>",add lt support for nn optimizers and 1 activation function
811,"<desc> offscreen render, mouse and keyboard event sending functionality using the content api. this relies on my other pull-request successfully being merged into native-mate, because the offscreen-render callback sends the image data in a uint8clampedarray, and i couldn't return that without the things i added to native-mate. </desc> <cmt> offscreen render support base </cmt> <cmt> setoffscreenrender and api docs added </cmt> <cmt> mouse event handling and keyboard event handling (not totally working yet) </cmt> <cmt> conflicts: </cmt> <cmt> atom/browser/api/atom_api_window.h </cmt> <cmt> atom/browser/native_window.cc </cmt> <cmt> key event sending update. </cmt> <cmt> changed stringarray options to regular js objects with boolean values for better readability from the js side </cmt> <cmt> reset native-mate to the original repo </cmt> <cmt> resetting debug changes </cmt> <cmt> whoops, missed a line last time. </cmt>",adding support for offscreen render and keyboard/mouse event sending to browser-window.
812,"<desc> addresses part of #12927 and part of #9250 this pr renames file.py into _file.py in the sklearn.cluster module. in particular, please note that: i rename dbscan_.py into _dbscan.py. same for optics_ and mean_shift_ i renamed k_means_.py into _k_means.py. since _k_means.pyx already existed, i had to rename it too. i chose _k_means_fast.pyx but no strong opinion. same for hierarchical. ping @adrinjalali 	@thomasjpfan 	@rth 	@glemaitre. again, lint issue can be ignored and are triggered by new files being created. </desc> <cmt> first files </cmt> <cmt> some more </cmt> <cmt> some more </cmt>",mnt make files private for cluster module
813,"<desc> made py3 fixes to conf.py.  docs now compile on py3 (good job @phaebz, @kermit666 and joris). also worked around recent breaking change to ipython ipython/ipython#4504, which somewhat deflates my theory that by having our own copy we can avoid having other packages changes break our build (they can, if they change the packages it depends on). </desc> <cmt> bld/doc: fix conf.py on py3 </cmt> <cmt> bld/doc: fix ipython_directive to workaround ipython/4504 </cmt>","fix ipython directive, py3 and recent ipython changes"
814,"<desc> this pr performs a bit of maintenance on various np.dtype methods (see the individual commits). most prominently is a fix to signature of __mul__, which had a few problems: multiplication by 0 does not return none. multiplication of a flexible dtype returns a flexible dtype; not necessarily just void. in principle any object implementing the __index__ protocol is a valid multiplication value; not just integers. </desc> <cmt> sty: use the pipe operator to represent unions in np.dtype </cmt> <cmt> enh: use the concrete mappingproxytype class over the mapping abc </cmt> <cmt> maint: removed a duplicate attribute </cmt> <cmt> maint: fixed the signature of dtype.__mul__ </cmt> <cmt> * multiplication by 0 does not return none </cmt> <cmt> * multiplication of a flexible dtype returns a flexible dtype; not just void </cmt> <cmt> * in principle any object implementing the __index__ protocol is a valid multiplication value; not just integers. </cmt> <cmt> maint: set the return-dtype of dtype.base and dtype.subdtype to any </cmt> <cmt> whether the return dtype is equivalent to the initial dtype depends on whether the initial dtype is structured or if it has fields of a fixed size </cmt> <cmt> tst: update the dtype typing tests </cmt>",misc typing maintenance for np.dtype
815,<desc> see bitcoin/bitcoin#4735 (the dependency on cfeerate moving shouldn't matter here) </desc> <cmt> remove print() from core functions </cmt> <cmt> break dependency on util. </cmt> <cmt> move strprintf define to tinyformat.h </cmt> <cmt> this avoids a dependency on util.h if just tinyformat is needed. </cmt> <cmt> remove all other print() methods </cmt> <cmt> all unused. </cmt>,remove print() from core classes
816,"<desc> my work is based on the work that was done to add --numstat. mind the singular and plural forms of the output. add a field of shortstat in struct opts and follow the things --numstat do. remove the corresponding information from the projects.md regards, he sun </desc> <cmt> add the --shortstat flag to examples/diff.c </cmt> <cmt> fix the output format of diff </cmt>",examples/diff:add the shortstat flag to examples/diff.c
817,<desc> this should fix #912. it was righteously mentioned by @bakkot. </desc> <cmt> add fix for parens of binaryexpression with instanceof op embedded into arrowfunctionexpression. </cmt> <cmt> add new test :rocket:. </cmt> <iss> omited parentheses for objectexpression of binaryexpression enclosed into arrowfunctionexpression </iss>,fix binary expression instanceof in arrow function expression
818,<desc> this fixes a flaky test:  i also took this opportunity to convert the package manager spec to javascript and use async and await instead of waitsfor. </desc> <cmt> convert package-manager-spec to js </cmt> <cmt> use async/await in package-manager-spec </cmt>,fix flaky package manager spec
819,<desc> took the latest version from  the previous version of this file is no longer compatible with grpc 1.7.x/1.8.x and causes compilation errors. </desc> <cmt> updateed cpp_generator.cc to be compatible with the latest grpc version </cmt> <cmt> preserved the original license </cmt>,updated cpp_generator.cc to be compatible with the latest grpc version
820,<desc> creating a new page on hosting a sample asp .net core in container using docker compose @rick-anderson  edit: internal review url </desc> <cmt> create docker-compose-https.md </cmt> <cmt> docker compose draft. </cmt> <cmt> use right env variable format in compose file </cmt>,hosting an asp.net core image with docker compose
821,"<desc> fixes #4817. when the --update-checksums flag is set, yarn would know to ignore a checksum mismatch between yarn.lock and the repository, and instead update the yarn.lock file with the proper checksum(s). added new tests. to manually check this: change one or more of the package checksums in yarn.lock delete node_modules (optionally also run yarn cache clean) run yarn => checksum mismatch error will be received. run yarn --update-checksums => will install successfully and fix the damaged checksums in yarn.lock </desc> <cmt> test(cli): update package checksum </cmt> <cmt> update package checksum when there is a checksum mismatch between the repo and the lockfile </cmt> <cmt> feat(cli): update package checksum on mismatch </cmt> <cmt> provide the option to update the package checksum when there is a mismatch between the repo and the </cmt> <cmt> local yarn.lock file </cmt> <cmt> 4817 </cmt> <iss> moving repositories without recreating yarn.lock? </iss>",add --update-checksums to cli install
822,"<desc> we are adding dispatchcommand to the export of react native renderers. right now product code is calling uimanager.dispatchviewmanagercommand which we need to get rid of to migrate to fabric. this export will work for fabric and paper and will be called via generated code in react native for each view manager command. for facebook employees, you can see more information here: </desc> <cmt> add dispatchcommand to the public export of the react native renderers </cmt> <cmt> fixup invalid check </cmt>",add dispatchcommand to react native renderers
823,<desc> this field has been deprecated in favor of of the match_subject_alt_names field which provides more flexible matching. san list can still be specified via transport_socket_options's san list override and verified via verifysubjectaltname risk level: low testing: local test on linux (bazel test //test/...) </desc> <cmt> remove support for v2 verify_subject_alt_name field </cmt> <cmt> remove support for v2 verify_subject_alt_name field </cmt>,remove support for verify_subject_alt_name in certificatevalidationcontext
824,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> credit-key files including tests </cmt> <cmt> fixing tslint errors </cmt> <cmt> made file prettier </cmt>",add a typed version of the creditkey-js package
825,"<desc> that pass optimizes load and store offsets, turning a load of (x + y) into a load of x with a load offset of y, where y is a small enough constant. by setting global_base, we can ensure that valid memory locations start above a certain value, avoiding overflows that would invalidate using a load/store offset. this wastes a little static storage space which is then never touched, but it doesn't take space in the wasm file (we emit data segments without it). the cost is only in somewhat larger constants for static global locations, which might take more room as lebs, and a little wasted ram at runtime. the benefit, on the other hand, is using load/store offsets in more places, saving code size and compile time, and appears much bigger in practice. on asm2wasm we always did this, whereas with the wasm backend we did the bad half, but not the good half... by mistake. that is, we set global_base higher, but still never ran the optimization for it. all this pr does is fix that, that is, it does not change global_base - so this pr regresses nothing, and just helps. specifically, with this pr we shrink the final wasm by over 1% (e.g. on hello libc++). in theory the wasm backend could optimize such things (in which case we would not need to raise global_base). but it doesn't seem to do so in all cases, see #7715  the constant value of 1024 has been used in asm2wasm in practice for a long time, and seems slightly better than other reasonable values (i re-measured now on the wasm backend). </desc> <cmt> wip [ci skip] </cmt> <cmt> fix </cmt> <cmt> comment </cmt>",use --post-emscripten pass with wasm backend
826,<desc> this pr includes only the changes i had to make to services.sh in order to get e2e working in #3651. @bgrant0607 </desc> <cmt> extra echo in services.sh e2e test to get it to pass </cmt> <cmt> adds trailing semi-colon as per pr comment </cmt>,fixes endpoint propagation failure in services e2e
827,"<desc> module.instantiatewasm is a callback the user provides, and then the user is in change of fetching and instantiating the wasm. in that code path emscripten never sees the wasm binary, which means we cannot create a wasmoffsetconverter. with this pr we will not hang on startup, and we will still detect problems, but the sanitizer's own stack traces will mark function names as ""unknown"". that will limit the santizer's usefulness, but they do still detect errors, and the browser's own stack traces may be enough to diagnose things. fixes #13424 </desc> <cmt> fix #13424 </cmt> <cmt> typo </cmt> <iss> offset-converter and caller-provided instantiatewasm hooks </iss>",avoid using wasmoffsetconverter when module.instantiatewasm
828,<desc> the other day i noticed the service module behaving strangely if i only specified enabled=yes and left out the state argument (it would enable the service but error out the first run). here's my attempt at cleaning up this code path a little. please review. tested on centos 6.3 </desc> <cmt> changed the service module to terminate early if only changing the enabled state. </cmt> <cmt> expanded the documentation slightly. </cmt> <cmt> additional example in service documentation. </cmt>,service module changed to terminate early if only enabled specified
829,"<desc> the correlative issues: #4439 #4455 </desc> <cmt> remove unnecessary null check  before instance of (#4321) </cmt> <cmt> add zookeeper maven dependency so that on change registery can run the demo (#4352) </cmt> <cmt> polish apache/incubator-dubbo#4347 : dubbo+nacos throw classnotfound </cmt> <cmt> polish apache/incubator-dubbo#4330 : add @com.alibaba.dubbo.config.annotation.service support </cmt> <cmt> [dubbo-4355] fix dubbo.jar do not contain ""serialization-protobuf-json"" module issue (#4356) (#4364) </cmt> <cmt> * include protobuf-json jar to dubbo </cmt> <cmt> polish apache/incubator-dubbo#4330 : optimization </cmt> <cmt> [dubbo-4299]fix npe when pojoutils realize null element in collection(#4299) (#4300) </cmt> <cmt> * fix npe when pojoutils realize null element in collection(#4299) </cmt> <cmt> * add unit tests for bugfix of pojoutils npe(#4299) </cmt> <cmt> * revert import (#4299) </cmt> <cmt> fix qos configuration cannot work after added 'qos-enable' style support (#4378) </cmt> <cmt> fixes #4377 </cmt> <cmt> polish apache/incubator-dubbo#4330 : refactor code </cmt> <cmt> polish apache/incubator-dubbo#4409 : [enhancement] @enabledubboconfig reduces the duplicated dubboconfigconfiguration registration </cmt> <cmt> allow @service and @reference to merge attributes form annotations in lower levels of the annotation hierachy. (#4078) </cmt> <cmt> * allow @service and @reference to merge attributes form annotations in lower levels of the annotation hierachy. </cmt> <cmt> * remove author information & not introduce all dependencies for test </cmt> <cmt> format file: pom.xml of bom module (#4376) </cmt> <cmt> synchronized local variables or parameters should be set to final (#4325) </cmt> <cmt> * synchronized local variables or parameters should be set to final </cmt> <cmt> * remove unused import </cmt> <cmt> fix bug about nacos (#4308) </cmt> <cmt> * fix bug </cmt> <cmt> * add trim </cmt> <cmt> polish apache/incubator-dubbo#4330 : add @com.alibaba.dubbo.config.annotation.reference support </cmt> <cmt> polish apache/incubator-dubbo#4353 : in dubbo-2.7.2, dubbo + nacos throw 404 error </cmt> <cmt> polish apache/incubator-dubbo#4439 : nacos regsitry supports the wildcard service name </cmt> <cmt> # conflicts: </cmt> <cmt> #	dubbo-demo/dubbo-demo-annotation/dubbo-demo-annotation-consumer/pom.xml </cmt> <cmt> #	dubbo-demo/dubbo-demo-annotation/dubbo-demo-annotation-provider/pom.xml </cmt> <cmt> #	dubbo-demo/dubbo-demo-xml/dubbo-demo-xml-consumer/pom.xml </cmt> <cmt> #	dubbo-demo/dubbo-demo-xml/dubbo-demo-xml-provider/pom.xml </cmt> <cmt> #	dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/nacosregistry.java </cmt>",nacos registry enhancement & register reference bean
830,"<desc> closes #22905 closes #18338 closes #19420 closes #21184 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> tst: fixed timezone issues post datetimearray </cmt> <cmt> test dataframe.stack with tz data </cmt> <cmt> test merge_asof with by_col tz-aware </cmt> <cmt> datetimeindex.to_period converting to utc </cmt> <cmt> lint </cmt> <iss> bug: unstacking multiindex with datetime tz-aware data raises valueerror: cannot create a datetimetzblock without a tz </iss> <iss> df.stack() on single column datetime with timezone causes loss of timezone </iss> <iss> bug: merge_asof with tz-aware datetime ""by"" parameter raises </iss> <iss> bug: to_period behaves different between timestamp and datetimeindex with timezones </iss>",fixed timezone issues post datetimearray refactor
831,<desc> description: adding support for homematic slo (outdoor brightness sensor) danielperna84/pyhomematic#176 i added the device to discover_sensors and added the unit_of_measurement & icon checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> add ipbrightnesssensor </cmt> <cmt> add illumination unit & icon </cmt>,adding support for hmip-slo (outdoor brightness sensor)
832,<desc> this pull request adds some rules to our wap project that suppress existing rules that were removing vital files. closes #2625 i even added a validation phase! </desc> <cmt> wap: add some workarounds to ensure that terminal continues to build </cmt> <cmt> fixes #2625. </cmt> <cmt> make sure that cpprest_2_10.dll exists (sanity) </cmt> <iss> vs2019.3 wapproj changes broke our precarious packaging situation </iss>,add some workaround to ensure that our package builds on 16.3
833,"<desc> description: i am proposing a few small changes to the feedreader component: moved the code that regularly updates the feed into own method so that subclasses can override this behaviour. the default feedreader is still updating at the top of the clock. moved the maximum entry filter into own method so that subclasses can override this behaviour and filter the feed differently. the default feedreader is still chopping off the feed after 20 entries. made the previously hard-coded event type configurable so that subclasses can introduce their own event type schema. the default feedreader is still publishing as feedreader. introduced a dedicated feed id attribute so that subclasses can introduce their own feed id schema. the default feedreader is still using the feed url as its id. breaking change: currently, parsing the feed is considered a failure if the bozo flag in the underlying feedparser is set. the bozo flag is set if the initial parsing fails, however, the library then tries a less restrictive approach parsing the feed which may still succeed. this change in the feedreader component still logs a message if the bozo flag is set, but then tries to access the feed to see if entries are present. as a bonus, i added unit tests for the feedreader component which are currently missing altogether. the background for all the changes above is a planned extension (already work in progress) to transform the geo_rss_events sensor into a component which will then be based on the feedreader component. if preferable, i can separate the non-breaking changes from the breaking changes. related issue (if applicable): n/a pull request in home-assistant.github.io with documentation (if applicable): n/a example entry for configuration.yaml (if applicable): configuration options have not changed. checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> moved regular updates definition to own method to be able to override behaviour in subclass </cmt> <cmt> moved filter by max entries to own method to be able to override behaviour in subclass </cmt> <cmt> event type used when firing events to the bus now based on variable to be able to override behaviour in subclass </cmt> <cmt> feed id introduced instead of url for storing meta-data about the feed to be able to fetch the same feed from different configs with different filtering rules applied </cmt> <cmt> keep the status of the last update; continue processing the entries retrieved even if a recoverable error was detected while fetching the feed </cmt> <cmt> added test cases for feedreader component </cmt> <cmt> better explanation around breaking change </cmt>",make feedreader component more extendable
834,"<desc> this is the same change as #4029, but updated per @fat: we don't take pulls against gh-pages, you need to change the docs in the -wip branch original description from #4029: two of the three apps listed are for linux/windows.  i adjusted the wording to clarify, as i originally skipped this section because i'm not using os x. just a simple change. note: this is just a pull request for the gh-pages branch. </desc> <cmt> two of the three apps are for linux/windows; adjust accordingly </cmt> <cmt> compiled; ignoring bootstrap.css change to avoid conflicts </cmt>",adjust wording for apps (on 2.1.0-wip)
835,"<desc> fixes rdar://problem/47220065. </desc> <cmt> sema: fix crash when override checking encounters circularity </cmt> <cmt> getinterfacetype() will return an errortype if the declaration is currently </cmt> <cmt> being validated, which can happen if override checking triggers associated </cmt> <cmt> type inference. </cmt> <cmt> i believe this is <rdar://problem/47220065>. </cmt> <cmt> ast: fix crash in getcontextsubstitutions() when a class has a malformed superclass type </cmt> <cmt> it is possible for getsuperclassdecl() to return a non-null type, while </cmt> <cmt> getsuperclass() returns an errortype. in this case, getcontextsubstitutions() </cmt> <cmt> could crash because the walk of the superclass chain via getsuperclass() </cmt> <cmt> might not find the context class. </cmt> <cmt> instead of crashing in asserts builds, let getcontextsubstitutions() </cmt> <cmt> silently build an invalid substitution map here, just as it does in no-asserts </cmt> <cmt> builds. </cmt> <cmt> silgen: add regression test for </cmt>",a couple of small circularity fixes
836,<desc> cherry picked from commit cc3e43c original pr #49940 issue #49608 /lib/ansible/modules/windows/setup.ps1 </desc> <cmt> fix facts memtotal_mb rounding on vmware and swaptotal_mb conversion from kb to mb </cmt> <cmt> (cherry picked from commit cc3e43cb2051d210ebb7dfbea2cd3674b1ecf616) </cmt> <cmt> add changelog fragment </cmt>,fix memtotal_mb rounding on vmware and swaptotal_mb conversion from kb to mb
837,"<desc> converted our bug template to the new issue forms syntax. this will enable more structured data on incoming bugs, that looks like this: you can try out any of the new templates from this pr here. microsoft reviewers: open in codeflow </desc> <cmt> basic conversion of bug report markdown to yaml </cmt> <cmt> copying a known-working yaml issue template </cmt> <cmt> convert simple bug report to issue templates </cmt> <cmt> syntax cleanup </cmt> <cmt> just trying to get issue templates to work </cmt> <cmt> slowly building back issue template </cmt> <cmt> adding textareas </cmt> <cmt> add issue markdown </cmt> <cmt> add environment commands, remove markdown </cmt> <cmt> refine environment commands </cmt> <cmt> further refine environment prompts, test markdown </cmt> <cmt> uniqueness of issue template </cmt> <cmt> try to bring back markdown with link </cmt> <cmt> add back troublershooting note </cmt> <cmt> fix troubleshooting markdown </cmt> <cmt> embded links in text </cmt> <cmt> remove test yamls </cmt>",use issue forms for bug template
838,"<desc> closes #10233 closes #12610 previously, the message count for every room is increased upon message addition but is not updated upon the deletion of a message #12610. so, upon the removal of messages, the message count of rooms shows the wrong message count. now the message count of each room is updated upon message deletion, which makes the message count of each room error-free. so it will be better if we sum up the four values(4 different types of rooms: privategroupmessages, channelmessages, directmessages, livechatmessages) to get the exact total message count. </desc> <cmt> [fix] message count of private and public channels upon deletion/pruning </cmt> <cmt> [fix] message count statistics for admin info page </cmt> <iss> message count in statistics is strange </iss> <iss> not displayed the number of users and messages in private and public channels on the page /admin/rooms </iss>",wrong message count statistics in admin info page
839,"<desc> update spanish translations and fix some grammar mistakes. jira: none </desc> <cmt> complete and fix the spanish translation on setup </cmt> <cmt> correct the random names, fixing the denominations, translate of the english words, and fixing random and incorrect denominations like ""cabinet"" or ""distribuciones"". </cmt> <cmt> complete and fix the spanish translation on setup </cmt>",update spanish translation of usetup.
840,"<desc> this pull request changes the default app to allow you to launch http/file urls or html files directly in a window from the command line. this will allow you to test pages and sites directly in electron without having to create the standard app boilerplate around waiting for the app to be ready, creating the browser window, and loading the url. you'll now be able to do: electron  electron ./site/index.html electron file:///users/me/sites/page.html </desc> <cmt> use const for fs/path requires </cmt> <cmt> extract helper function to load specified app </cmt> <cmt> add support for launching http url directly </cmt> <cmt> add support for launching html files directly </cmt> <cmt> support opening file: urls directly </cmt> <cmt> loadpackagepath -> loadapplicationpackage </cmt> <cmt> tweak help message for new path options </cmt>",launch url or html file directly
841,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint whatwg-streams provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [whatwg-streams] make stream classes generic </cmt> <cmt> [whatwg-streams] add transform streams </cmt>","make classes generic, add transform streams"
842,<desc> description [] fixes #22951  build fails on ubuntu 21.10 from (presumably) clang behavior changes and missing includes (the includes may not be required on macos compiler) verification [] performed a complete build on ubuntu 21.10 successfully </desc> <cmt> fix compile on ubuntu 21.10 </cmt> <cmt> add missing c++17 optional refs in ui </cmt> <iss> compilation fails in ubuntu 21.10 presumably due to clang version behavior change </iss>,fix build failures in ubuntu 21.10
843,"<desc> change change telemetrytracelogger to be per context add parent activity id concept to replace the subexecutionid send summary event upon each telemetrytracelogger destruction validation due to lack of test infra support for telemetry, i manually run and see telemetry events and also set breakpoints to verify the summary events. microsoft reviewers: open in codeflow </desc> <cmt> snap1 </cmt> <cmt> infra done </cmt> <cmt> log summary event </cmt> <cmt> send summary event </cmt> <cmt> fix tests </cmt> <cmt> fix selected installer telemetry </cmt>",make telemetry logger per context and send summary event on destruction
844,"<desc> use black to auto-format all .py files. update flake8 config to exclude very large files (lemmatization tables etc.) update code to be compatible with flake8 rules fix various small bugs, inconsistencies and messy stuff in the language data update docs to explain new code style (black, flake8, when to use # fmt: off and # fmt: on and what # noqa means) once #2932 is merged, which auto-formats and tidies up the cli, we'll be able to run flake8 spacy actually get meaningful results. at the moment, the code style and linting isn't applied automatically, but i'm hoping that the new github actions will let us auto-format pull requests and post comments with relevant linting information. enhancement, code style i have submitted the spacy contributor agreement. </desc> <cmt> auto-format test </cmt> <cmt> ignore e731 in flake8 </cmt> <cmt> lambda vs. def </cmt> <cmt> auto-format spacy/bin </cmt> <cmt> auto-format top-level modules </cmt> <cmt> auto-format spacy/displacy </cmt> <cmt> auto-format top-level modules </cmt> <cmt> auto-format spacy/tokens </cmt> <cmt> flake8: ignore python artifacts and big files </cmt> <cmt> mostly lemmatizer lookup tables and similar </cmt> <cmt> auto-format spacy/lang </cmt>",tidy up and auto-format .py files
845,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> update system.md </cmt> <cmt> added some system queries (1st attempt). </cmt> <cmt> update system.md </cmt> <cmt> added some system queries (1st attempt). </cmt> <cmt> update system.md </cmt> <cmt> added some system queries (1st attempt). </cmt>,doc change. added some system queries (1st attempt).
846,"<desc> users should be aware that these documents aren't actively maintained by the netdata team. i also cleaned up the beginning of the pfsense installation procedure. i didn't implement any of the suggestions from #9499, as those are more complex and forward-thinking. just trying to stop the short-term support issues. component name area/docs area/packaging </desc> <cmt> add notice about community-maintained </cmt> <cmt> update netdata version </cmt>",add notices to freebsd/pfsense docs that they are community-supported
847,"<desc> tests have been failing recently on the master branch because the ./meteor self-test create test runs out of memory. the release-1.6 branch contains a few commits that successfully limit memory usage by forcing garbage collection periodically (throttled to once every 500ms). this pr back-ports those commits to master, which i hope will fix the failing tests. </desc> <cmt> allow programmatic garbage collection via gc(). </cmt> <cmt> throttle requestgarbagecollection to once per 500ms. </cmt> <cmt> with meteor 1.6 / node 8, i noticed _buildlocalpackages taking multiple </cmt> <cmt> seconds on initial server startup and restart, and the problem seems to be </cmt> <cmt> that we call the global.gc function too often. this wasn't a problem in </cmt> <cmt> previous versions of node, as far as i know, but it makes sense to heed </cmt> <cmt> the comment in tools/utils/gc.js, now that it matters. </cmt>",enable throttled garbage collection (borrowed from release-1.6).
848,"<desc> this pr syncs portable-simd in up to rust-lang/portable-simd@a838552 in order to address the type inference breakages documented on nightly in #90904 by removing the vector + scalar binary operations (called ""autosplats"", ""broadcasting"", or ""rank promotion"", depending on who you ask) that allow {scalar} + &'_ {scalar} to fail in some cases, because it becomes possible the programmer may have meant {scalar} + &'_ {vector}. a few quality-of-life improvements make their way in as well: lane counts can now go to 64, as llvm seems to have fixed their miscompilation for those. {i,u}8x64 to __m512i is now available. a bunch of #[must_use] notes appear throughout the module. some implementations, mostly instances of impl core::ops::{op}<simd> for simd that aren't {vector} + {vector} (e.g. {vector} + &'_ {vector}), leverage some generics and where bounds now to make them easier to understand by reducing a dozen implementations into one (and make it possible for people to open the docs on less burly devices). and some internal-only improvements. none of these changes should affect a beta backport, only actual users of core::simd (and most aren't even visible in the programmatic sense), though i can extract an even more minimal changeset for beta if necessary. it seemed simpler to just keep moving forward. </desc> <cmt> use new bitmask intrinsics with byte arrays </cmt> <cmt> update contributing.md for the fact that travis is no longer used </cmt> <cmt> update contributing.md for the fact that travis is no longer used </cmt> <cmt> sprinkle the crate with #[must_use] </cmt> <cmt> fix outdated workflow badge </cmt> <cmt> fix outdated workflow badge </cmt> <cmt> attempt to support to 64 lanes </cmt> <cmt> impl deref.rs<&self> for simd<t, _> </cmt> <cmt> instead of implementing each ""deref"" pattern for every single scalar, </cmt> <cmt> we can use type parameters for simd operating on &self. </cmt> <cmt> we can use a macro, but keep it cleaner and more explicit. </cmt> <cmt> impl assign.rs<u> for simd<t, _> </cmt> <cmt> instead of implementing {op}assign traits for individual scalar type args </cmt> <cmt> to simd<_, _>, use parametric impls that reassert the bounds of the binary op. </cmt> <cmt> generically implement horizontal_{and,or,xor} </cmt> <cmt> uncomment avx512 byte vector conversions </cmt> <cmt> resolves my comment in #197, at least for now; #187 is pending but since these are already here, just commented, it seemed to make sense to me to re-enable them anyway. </cmt> <cmt> impl unary.rs for simd<{i,u}{8,16,32,64,size}, _> </cmt> <cmt> in order to assure type soundness, these ""base"" impls </cmt> <cmt> need to go directly on simd<t, _> for every scalar type argument. </cmt> <cmt> a bit of cleanup of ops.rs is still warranted. </cmt> <cmt> drop splats for simd<t, _> </cmt> <cmt> unfortunately, splatting impls currently break several crates. </cmt> <cmt> rust needs more time to review possible mitigations, so </cmt> <cmt> drop the impls for the impl add<t> for simd<t, _> pattern, for now. </cmt> <cmt> impl op<&'_ rhs> for &'_ lhs </cmt> <cmt> merge portable-simd#195 - portable-simd:trait-ops </cmt> <cmt> generic core::ops for simd<t, _> </cmt> <cmt> in order to maintain type soundness, we need to be sure we only implement an operation for simd<t, _> where t: simdelement... and also valid for that operation in general. while we could do this purely parametrically, it is more sound to implement the operators directly for the base scalar type arguments and then use type parameters to extend the operators to the ""higher order"" operations. </cmt> <cmt> this implements that strategy and cleans up simd::ops into a few submodules: </cmt> <cmt> - assign.rs: core::ops::*assign </cmt> <cmt> - deref.rs:  core::ops impls which ""deref"" borrowed versions of the arguments </cmt> <cmt> - unary.rs: encloses the logic for unary operators on simd, as unary ops are much simpler </cmt> <cmt> this is possible since everything need not be nested in a single maze of macros anymore. the result simplifies the logic and allows reasoning about what operators are valid based on the expressed trait bounds, and also reduces the size of the trait implementation output in rustdoc, for a huge win of 4 mb off the size of struct.simd.html! this addresses a common user complaint, as the original was over 5.5 mb and capable of crashing browsers! </cmt> <cmt> this also carries a fix for a type-inference-related breakage, by removing the autosplatting (vector + scalar binop) impls, as unfortunately the presence of autosplatting was capable of busting type inference. we will likely need to see results from a crater run before we can understand how to re-land autosplatting. </cmt> <cmt> merge commit 'a8385522ade6f67853edac730b5bf164ddb298fd' into simd-remove-autosplats </cmt> <cmt> force splatting in simd test </cmt>",sync portable-simd to remove autosplats
849,"<desc> if we issue check table statement on distributed table, segment fault error will occur. the problem is that shard_info.pool could be null and we shouldn't create rmoteblockinputstream on null connections. </desc> <cmt> rebase master </cmt> <cmt> fix check distribute_table crash issue </cmt>",fix check table distributed_table crash issue
850,"<desc> update checkhashable to verify that different values hash differently -- we can do this with hash(into:) because we can eliminate hash collisions by trying different seeds. switch minimalhashable* types to use _hash(into:) as the primary hashing interface. </desc> <cmt> [test] minimaltypes: move ==, < definitions into the corresponding type (nfc) </cmt> <cmt> [test] minimalhashable{value,class}: implement customstringconvertible </cmt> <cmt> this makes it easier to understand failure traces in test logs. </cmt>",review & update hash testing to use hasher's new features
851,"<desc> implement an interface for services to register metrics. metrics property is optional to interface ibroker for now, so it was implemented only on networkbroker that is currently using it.. localbroker doesn't have it, we can figure something out later the better way to implement in both brokers. how to test or reproduce types of changes new feature (non-breaking change which adds functionality) checklist i have read the contributing doc changelog </desc> <cmt> add metrics to services </cmt> <cmt> add ddp-streamer metrics </cmt> <cmt> temp localbroker metrics </cmt>",add metrics capability to services
852,"<desc> the term aggregation is misleading. bundled edges is a better definition for this type of edge. closes #962 </desc> <cmt> renamed aggregation to bundled edges in src </cmt> <cmt> renamed aggregation to bundled edges in color schemes </cmt> <cmt> updated docs </cmt> <cmt> updated manual tests </cmt> <iss> rename ""aggregration"" edge to something better understandable </iss>",rename aggregation edge to bundled edges
853,"<desc> fixes #2412 . note that the qps family of tests will still not build, as these use numerous banned features (lambdas, local templates) . however, this should enable all of the other tests and c++ library to build in gcc 4.4 . </desc> <cmt> remove lambda function with lambda capture to allow building with pre-lambda </cmt> <cmt> compilers </cmt> <cmt> remove brace initialization for gcc-4.4 compatibility </cmt>","fixes for older c++ compilers (remove lambdas, brace init, and nullptr ambiguity)"
854,"<desc> this code change achieves witching from using docvalue_fields and _source extraction to using the fields api. it helps simplify the ql code, but does also come with a small drawback which will become visible in fieldhitextractortests where some tests are not needed anymore. any query (especially sql) on fields that have _source disabled, but are indexed (accessible through docvalue_fields), will not be possible anymore. this pr, also, improves bwc checks when it comes to running queries in a mixed-versions cluster (a rolling upgrade scenario) by using a minimum compatibility version when creating a search request against es and re-trying the request if the search proves to be executed on at least one incompatible shard. the retrial happens on a node that has an older version, the original request (sql/eql request) being sent through transport layer. the node receiving the retried request will re-parse it and create another query dsl to be sent to es. addresses #67727. prs in this merge: #68467 #68602 #68745 </desc> <cmt> integrate ""fields"" api into ql (#68467) </cmt> <cmt> adapt nested fields extraction from ""fields"" api output to the new un-flattened structure (#68745) </cmt> <cmt> ql: retry sql and eql requests in a mixed-node (rolling upgrade) cluster (#68602) </cmt>","""fields"" api implementation in ql"
855,"<desc> there was a problem with missing processes and values were 30% less in apps.cpu chart than in system.cpu chart. collect data for all processes and threads (it was collected without threads) take into account different units for cpu time in freebsd eliminate spikes fixes #4037 fixes #3245 component name apps.plugin cpu time statistics for processes in freebsd is represented in microseconds, not in ticks. </desc> <cmt> read all threads </cmt> <cmt> fix cpu time factor for freebsd </cmt>",fix process statistics collection for freebsd in apps.plugin
856,"<desc> this pull requests makes np.complexfloating generic with respect to np.floating. the main advantage of this is to make it easier to access the .real/.imag type of np.complexfloating sub-classes as is illustrated below. examples from typing import typevar import numpy as np floattype = typevar('floattype', bound=np.floating) def get_real(complex_value: 'np.compexfloating[floattype]') -> floattype: return complex_value.real </desc> <cmt> enh: make np.complexfloating generic w.r.t. to np.floating </cmt> <cmt> tst,maint: fixed an incorrect type comment </cmt>",make np.complexfloating generic w.r.t. np.floating
857,"<desc> be able to execute only specific tests. this is inspired by  you can replace temporarily tinytest.add or tinytest.addasync by tinytest.only or tinytest.onlyasync so only the tests added using only* are going to be executed. this is helpful when only a few tests are failing, so you can focus on them. there are small updates to the readme as well. </desc> <cmt> introducing only and onlyasync to tinytest </cmt> <cmt> introducing only and onlyasync to tinytest (removing debug logs) </cmt> <cmt> adding support to onlyasync also in  testasyncmulti </cmt>",tinytest adding new api: only and onlyasync
858,"<desc> shippable.yml, ansible-test, integration tests </desc> <cmt> switch tests from rhel 7.5 to 7.6. </cmt> <cmt> (cherry picked from commit 6745ee7cc86c50f79b24fb701d1e4680320a576b) </cmt> <cmt> remove ci platform: freebsd/10.4 </cmt> <cmt> (cherry picked from commit e6ffc4f89a27853e2ce983bc51a982b5a138d1bd) </cmt> <cmt> support skip of platforms by version in tests. (#48826) </cmt> <cmt> * support skip of platforms by version in tests. </cmt> <cmt> previously a remote platform could be skipped completely using the alias: </cmt> <cmt> skip/{platform} such as skip/rhel </cmt> <cmt> now a specific platform version can be skipped using the alias: </cmt> <cmt> skip/{platform}{version} such as skip/rhel7.6 </cmt> <cmt> this feature is available for platforms specified with the --remote option. </cmt> <cmt> * add skip by version to the docs. </cmt> <cmt> (cherry picked from commit 8066acc90c13595039812bd8f9eb1fcaaca1a890) </cmt> <cmt> add --raw option to ansible-test shell command. </cmt> <cmt> it is currently supported only with the --remote option. </cmt> <cmt> this makes it easier to troubleshoot new instances which are not </cmt> <cmt> yet supported by the setup scripts used by ansible-test. </cmt> <cmt> (cherry picked from commit 0826a008039c45f4fcf2d428c9267decdaeb7de2) </cmt> <cmt> fix ansible-test skip warning message. </cmt> <cmt> (cherry picked from commit 3b705efc93fdf6553c05d139dfb49fe6a5aa6483) </cmt> <cmt> fix lookup_passwordstore test skipping. (#49178) </cmt> <cmt> * fix lookup_passwordstore test skipping. </cmt> <cmt> skip all of rhel instead of specific versions. </cmt> <cmt> skip all of centos < 7 instead of specific versions. </cmt> <cmt> this makes the test more robust when testing newer versions. </cmt> <cmt> tests could be executed on rhel if epel was installed during the test. </cmt> <cmt> (cherry picked from commit 704dae2cda5ef3a7303b37de7bb0004f0a2ba581) </cmt>",backport test infra updates and test fixes.
859,"<desc> change udp_server interface to pass in desired socket receive/send buffer size, and set them during socket preparation. set socket option so_rxq_ovfl to enalbe counting packets dropped in receive buffer. </desc> <cmt> adjust receiv buffer via setsockopt for udp_server's listening socket. </cmt> <cmt> since this socket is used for all incoming traffic, its current buffer </cmt> <cmt> 1mb is appearantly too small. change it to 10 mb for now. </cmt> <cmt> change to pass in value </cmt>",change udp_server receive/send buffer size and set so_rxq_ovfl
860,"<desc> this pr adds two experimental components to be used for internal focus management handling. furthermore, this pr fixes a bug with scope component refs correctly detaching. tabfocuscontainer contains tabbable keyboard focus to within its children, where tabbing gets wrapped to the beginning. tabbablescope collects host components that are keyboard tabbable so that tabfocuscontainer can handle the tab navigation through said components. </desc> <cmt> initial commits </cmt> <cmt> [react-interactions] add focuscontain and tabbablescope ui components </cmt>",add tabfocuscontainer and tabbablescope ui components
861,<desc> regarding suggestion after pr #19966 about a need to comment the modified line. </desc> <cmt> initial commit </cmt> <cmt> update base 20.06.2021 </cmt> <cmt> merging branch 'main' into issue_#19949 (after updating fork's base). </cmt> <cmt> in corrected_std func use kr dummy var hope to please the linter </cmt> <cmt> add comment in corrected_std </cmt> <cmt> explain the kr variable </cmt> <cmt> resolve a merge conflict. don't understand why it was there </cmt>,doc fixes typo and comment in example plot_grid_search_stats.py
862,<desc> this pr wants @colinfinck to fix the whs x64 tester. </desc> <cmt> [win32nt_apitest] add tests for truncated and extended handle to ntgdideleteobjectapp test </cmt> <cmt> [win32k] fix an assert to ignore the upper 32 bits of a passed in gdi handle </cmt>,fix handling of upper 32 bits of gdi handles on x64
863,"<desc> as a result of discussion in #45403 i've come to conclusion that this is in fact a documentation issue and not a functional issue with the module (which is supported by #45403 (comment)). i also have in mind that i'd rather not be making functional changes to this module but instead, get started on the new api module (as in #41875). anyway, hopefully this does some good to help people use this module right now. linode ansible version </desc> <cmt> attempt to explain linode_id a bit better. </cmt> <cmt> don't include in any example that creates a linode. </cmt> <cmt> based on comments in </cmt> <cmt> > </cmt> <cmt> add simple creation example. show how to pass linode_id. </cmt>",clarify how to create/delete linode machines with linode_id.
864,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add types for @woocommerce/woocommerce-rest-api </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",add type definitions for @woocommerce/woocommerce-rest-api
865,"<desc> when parsing for ansi color codes, succeeding codes will remove previous colors instead of adding new classes while ignoring existing ones. this will fix #70416. also added some unit tests and modified one existing one to account for the change. </desc> <cmt> remove existing ansi colours when adding new ones </cmt> <cmt> avoids color conflicts by removing previous colors when new ones added. </cmt> <cmt> fixes #70416. </cmt> <cmt> modify / add tests for succeeding ansi color codes </cmt> <cmt> note: modifies interference test behavior; prior test </cmt> <cmt> asserted undesired behavior. </cmt> <iss> debug console doesn't properly handle succeeding color escape sequences </iss>",correctly handle succeeding ansi color codes (fix #70416)
866,"<desc> this change migrates a number of remaining maplike<t> entries to map<t>, as well as adds a number of additional functions for working with both maplike<t> and map<t>. the changes in the compiler itself add an additional performance improvement, shaving another ~400ms off of the total emit time of monaco and angular. this also disables the tslint restriction on use of the in operator, as offline performance tests i've run show that using in is faster than both hasownproperty and obj[key] when merely testing for the presence of a key. the in operator also works better when paired with delete, which is faster at removing entries from a map<t> than setting the entry to undefined. </desc> <cmt> migrated more maplikes to maps </cmt> <cmt> migrate additional maplikes to maps. </cmt>",migrate more maplikes to maps
867,<desc> use itemgroup to print vars properties trivial change for build debugging purposes only. upgrades the custom vars target to use collections of msbuild items instead of manually adding a new message task for each msbuild property to print. informational adding new properties to the vars target resulted in a lot of boilerplate code. microsoft reviewers: open in codeflow </desc> <cmt> use itemgroup to print vars properties </cmt> <cmt> move items into target </cmt> <cmt> rename jsengineitems </cmt> <cmt> pad vc metadata to a multiple of 4 (32) </cmt> <cmt> add customitems group </cmt>,categorize vars target's items
868,"<desc> this pr introduces a new doc on the writing process for the gatsby docs. it's been on the to-do list for a while as we've engaged with contractors and team members, and pulls together information into one outcome-driven place (writing greenfield docs). in particular, this doc was written to help the process of writing learning materials for topics that aren't well known or understood as that's been a blocker for some writers in the past. it also takes the opportunity to educate contributors about our standards and conventions throughout the discovery and content writing process. feedback welcome! n/a n/a </desc> <cmt> feat: add new post on gatsby docs writing process </cmt> <cmt> fix: add proper nouns to style guide </cmt> <cmt> feat: additional links, markdown syntax + a11y </cmt>",new doc on gatsby's docs writing process
869,"<desc> the fix in #6297 doesn't work where the child to insert before is an element rather than a component, e.g. the video element. check if the child to insert before is an element, as well as checking if it has an el_ change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) </desc> <cmt> fix: consider children that are elements in addchild </cmt> <cmt> add test </cmt>",addchild with index should allow for children that are elements
870,<desc> since @staars builded the ccloader tasmota driver to flash the zigbee module cc253x and the bt module cc2541 it is usefull to have the firmwares in the repo. the pull request is done against the latest dev branch the code change is tested and works on tasmota core esp8266 v.2.7.4.7 the code change is tested and works on tasmota core esp32 v.1.0.4.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> ccloader firmware cc2541 </cmt> <cmt> zigbee 2530 firmware </cmt> <cmt> del </cmt>,ccloader firmware for zigbee and bt
871,<desc> these changes resolve all issues described in #8593 except for the linker issue. </desc> <cmt> fix compiler error due to mismatched braces (broken in f5fd897c1d) </cmt> <cmt> endian.h is not available on qnx </cmt> <cmt> add support for 64 bit qnx builds </cmt> <cmt> fix compiler error with brace initializer (conflicts with #8492) </cmt> <cmt> fix compiler error for empty default ctor for std::atomic<int> variables </cmt>,fix qnx 7.0 support #8593
872,"<desc> i hereby agree to the terms of the cla available at:  this makes a minor improvement to the deltasum function (that is backwards compatible) and adds a new function called deltasumtimestamp. the small improvement is to eliminate one of the state bools. i realized that having both seen_first and seen_last is unnecessary. since both bools would always have the same value, removing one of them is backwards compatible with old deltasum state data. the new function, deltasumtimestamp, works similarly but also keeps track of the timestamp of the first value seen and the last value seen. i found that in materialized views that were ordered by a tostartoffiveminute bucket, the merges were happening in a random order, so the delta sums were all incorrect. by storing the timestamp of the first and last value that is added to a particular deltasumtimestamp state, we can properly order them during merges. this makes it work well in materialized views. big thanks to clickhouse devs for taking my prs. as always any and all feedback is appreciated. new aggregate function deltasumtimestamp for summing the difference between consecutive rows while maintaining ordering during merge by storing timestamps </desc> <cmt> remove uneeded bool in deltasum impl </cmt> <cmt> add deltasumtimestamp aggregatefunction, docs&test </cmt> <cmt> improve deltasumtimestamp doc </cmt>","add deltasumtimestamp + docs, tests & minor improvement to deltasum"
873,"<desc> this pull request fixes a number of things related to the annotations of various np.generic subclasses: 3434da8 & e171b2b: adds previously missing types to the constructors. 3434da8: adds missing builtin baseclasses to the likes of np.str_ and np.float128. 8f2c26d: make np.datetime64 a subclass of np.generic (again), thus partially reverting numpy/numpy-stubs#31 (comment). the issues encountered in the linked comment have been partially addressed by explicitly defining a few __r<op>__ methods. once the, currently untyped, magic methods in np._arrayorscalarcommon have been annotated then the remaining issues will likelly resolve themselves. d6b0c70: per the discussion in #17172 this limits the np.generic.real and .imag properties to numeric np.generic subclasses. on the side of caution i've also included np.object_ and np.void, as the latter two may or may not contain numeric types (any thoughts on this?). </desc> <cmt> maint: added missing types to various generic constructors </cmt> <cmt> maint: added missing builtin super-classes to a number of generics </cmt> <cmt> maint: explicitly define real and imag for a number of generic subclasses </cmt> <cmt> maint: make datetime64 a generic subclass (again) </cmt> <cmt> maint: removed the supportsint protocol from complexfloating constructors </cmt> <cmt> tst: add tests for the new generic constructors </cmt>",fix various issues with the np.generic annotations
874,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them: there's a pr with incomplete typings create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> adding typings for url-parse </cmt> <cmt> fixup! import urlsearchparams types </cmt> <cmt> adding typings for parse function </cmt> <cmt> changes to tsconfig and tslint </cmt> <cmt> fixes to the type definitions </cmt> <cmt> adding missing tslint file </cmt>",adding type definitions for url-parse npm package
875,"<desc> opened for issue #1462 this pr fixes the assertequals parameter order in the arrange-act-assert module. assertequals should be expected,  actual. currently these are reversed and in the incorrect order. </desc> <cmt> corrected assertequals order for expected, actual. </cmt> <cmt> corrected assertequals order for expected, actual. </cmt>",fixes issue #1462 - unit test assertequals parameters are reversed
876,"<desc> quoting @colindekker on #26822: the underlying packages of remote-redux-devtools, redux-devtools-instrument has received an update to support redux 4.x so currently when using redux 4.x , typescript compilation breaks because this type definition uses redux 3.x's genericstoreenhancer instead of the redux 4.x storeenhancer tyoe. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> chore: bumped redux version to 4.x & correct genericstoreenhancer import </cmt> <cmt> redux 4 typings uses generic parameter defaults </cmt> <cmt> as of typescript 2.3 there is [support for generic parameter defaults]( </cmt>",bumped redux version to 4.x & correct (generic)storeenhancer import & typescript 2.3
877,"<desc> this pr is following my own intuition that rustfix should never inject bugs into working code (even if that comes at the expense of it failing to fix things that will become bugs). fix #56327 </desc> <cmt> do not lint dyn tokens under macros. </cmt> <cmt> the existing keywordidents lint blindly scans the token stream for a </cmt> <cmt> macro or macro definition. it does not attempt to parse the input, </cmt> <cmt> which means it cannot distinguish between occurrences of dyn that </cmt> <cmt> are truly instances of it as an identifier (e.g. let dyn = 3;) </cmt> <cmt> versus occurrences that follow its usage as a contextual keyword (e.g. </cmt> <cmt> the type box<dyn trait>). </cmt> <cmt> in an ideal world the lint would parse the token stream in order to </cmt> <cmt> distinguish such occurrences; but in general we cannot do this, </cmt> <cmt> because a macro_rules definition does not specify what parsing </cmt> <cmt> contexts the macro being defined is allowed to be used within. </cmt> <cmt> so rather than put a lot of work into attempting to come up with a </cmt> <cmt> more precise but still incomplete solution, i am just taking the short </cmt> <cmt> cut of not linting any instance of dyn under a macro. this prevents </cmt> <cmt> rustfix from injecting bugs into legal 2015 edition code. </cmt> <cmt> some tests illustrating where the revised lint does and does not apply. </cmt> <cmt> regression test for rust-lang/rust#56327. </cmt> <iss> edition compatibility lints: warning about `dyn` in a macro incorrectly </iss>",skip dyn keyword lint under macros
878,"<desc> you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information i used the script written by @remitamine at #6497 (comment) to remove all extractors with age limit over 17. i then checked to see if it missed anything with grep -rvil age_limit youtube_dl/extractor | grep porn and yourporn.py showed up. i tried every sexy keyword i could think of and also found camtube.py cammodels.py camwithher.py </desc> <cmt> [yourporn] add missing age limit </cmt> <cmt> [camtube] add missing age limit </cmt> <cmt> [cammodels] add missing age limit </cmt> <cmt> [camwithher] add missing age limit </cmt>",add missing age limit to a couple of sites
879,<desc> this will allow users to set the numexecutors for jenkins on startup after helm install without having to change the config.yaml file or using the jenkins ui to configure the numexecutors. will allow users to easily use values.yaml file for everything instead of having to make specific changes to other template files. dco signed </desc> <cmt> update values.yaml </cmt> <cmt> add variable for numexecutors so users can change for config file. </cmt> <cmt> update config.yaml </cmt> <cmt> allow config num executors to use variable from values file </cmt> <cmt> update chart.yaml </cmt> <cmt> update chart version and bumped. </cmt> <cmt> update readme.md </cmt> <cmt> update readme for new variable </cmt>,add numexecutors as a variable in values file
880,"<desc> not sure if anybody is going to read it there, but we can point to it if people don't do it ;) the naming and location comes from git, not sure if that breaks your ascetic sensibilities, @tanoku. maybe we should ask the pending prs to start doing it to get the ball rolling. </desc> <cmt> conventions: update error code names </cmt> <cmt> readme: add rules about writing release notes as they happen </cmt>",add notice about release notes
881,<desc> has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> wip on integrating with vue </cmt> <cmt> yarn lock </cmt> <cmt> no need to return props from setup </cmt> <cmt> use useresult for more concise and better type safety </cmt> <cmt> fix regression </cmt> <cmt> wip: migrate to apollo </cmt> <cmt> wip: mostly working with pollinterval </cmt> <cmt> apollo -> urql </cmt>,integrating urql w/ unified context branch
882,"<desc> closes #9906 done the cross linking as mentioned in the issue linked above. i have reviewed my changes in staging (look for the latest deployment event in your pull request's timeline, then click view deployment). for content changes, i have completed the self-review checklist. </desc> <cmt> add further reading links </cmt> <cmt> fixes github#9906 </cmt> <cmt> fix link </cmt> <cmt> add further reading links </cmt> <cmt> fixes github#9906 </cmt> <cmt> linking </cmt> <cmt> fixes github#9906 </cmt> <cmt> linking </cmt> <cmt> linking </cmt> <cmt> added further reading section </cmt> <iss> add ""further reading links"" between end-user and org guides for codespaces </iss>",adds further reading links to certain codespaces docs
883,"<desc> the repcode handling logic was slightly off in the original version of this api - this pr aims to fix it by: 1) keeping track of a dedicated repcode array, and 2) persist the repcodes array through each block. i've aimed to make the handling logic as clear to read as possible since we will need a similar process in the sequence compression api. test plan: manual spot checking (roundtrips silesia.tar with compression api) modify the unit test. previously, it turns out that setting the litprobability field to something like 0.5 in the rdg_genbuffer() function would almost always cause the unit test to fail. with this pr, it no longer does. </desc> <cmt> overhaul repcode handling logic </cmt> <cmt> improve unit test </cmt> <cmt> fix incorrect repcode setting </cmt> <cmt> let block reps persist </cmt>",improve repcode handling in sequence extraction api
884,"<desc> #5603 what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where ""xxx"" is the issue number) if adding a new feature, the pr's description includes: </desc> <cmt> simply fix inject extends </cmt>",merge inject when extending a component
885,"<desc> matrix keymap renamed to layout for both hardware configurations (alvicstep and stapelberg) added layout_pretty to both configurations all keymaps refactored to use qmk_keyboard_h include, and new matrix names includes default_pretty keymap, a duplicate of default keymap modified to use new layout_pretty matrix added info.json file for configurator support fixed a missing accent in the stapelberg readme </desc> <cmt> matrix refactor </cmt> <cmt> keymap refactor </cmt> <cmt> configurator support </cmt> <cmt> stapelberg readme formatting fix (missing grave accent) </cmt>",kinesis refactor and configurator update
886,"<desc> since we only call one parsing function (i.e. parsebraceitemlist, parsedecl, or parseexprorstmt), the parser stops at the end of the node anyways. it's not necessary to limit the lexer to set an artificialeof. as a ground work, modify the parser to not parse the body if the completion happens in the signature don't restore the parser position after the second pass because it's just not necessary. the parser here lives only for the single second pass. use getresultinterfacetype() to get the result type in typecheckfunctionbodyuntilrequest. so we can type check the body without type checking the signature of the func decl. (this change is actually not needed but i think this is an improvement) </desc> <cmt> [sema] use getresultinterfacetype() to get the result type </cmt> <cmt> in typecheckfunctionbodyuntilrequest. so we can type check the body </cmt> <cmt> without typechecking the signature. </cmt> <cmt> [codecompletion] don't use temporary lexer in the second pass </cmt> <cmt> since we only call one parsing function (i.e. parseabstructfunctionbody, </cmt> <cmt> parsedecl, or parsestmtorexpr), the parser stops at the end of the node. </cmt> <cmt> it's not necessary to limit the lexer to set an artificialeof. </cmt> <cmt> to minimize the parsing range, modify the parser to *not* parse the body </cmt> <cmt> if the completion happens in the signature. </cmt> <cmt> [codecompletion] don't restore the parser position after the second pass </cmt> <cmt> this is just not necessary. this parser lives only for the single second </cmt> <cmt> pass. </cmt>",stop using temporary lexer in the second pass
887,<desc> contrib/inventory/apstra_aos.py ansible version ansible 2.3.0 (inventory_blueprint e1900d7755) last updated 2017/02/14 16:37:40 (gmt -700) config file = configured module search path = default w/o overrides i added a new type of output format for the apstra dynamic inventory when a blueprint name is provided. the inventory now support both device and blueprint mode. the main difference is the value used as the inventory_hostname. in device mode we are using the serial_number in blueprint mode we are using the node name as defined in the blueprint. in addition to that i also added the ability to provide parameters with environment variables in addition to the ini file. i updated the description to explain these changes </desc> <cmt> add a new output format when a blueprint name is provided </cmt> <cmt> add author name </cmt>,inventory/apstra_aos - add a new output format when a blueprint name is provided
888,"<desc> adding types declaration for module slashy   add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add splashy types definitions </cmt> <cmt> add splashy test </cmt>",add types declaration for module splashy
889,"<desc> updates the terminal's scroll response to new output. the terminal will not automatically scroll if... a selection is active, or the viewport is at the bottom of the scroll history #2529 - spec #3863 - implementation closes #980 closes #3863 requires documentation to be updated updates the _scrolloffset value properly in terminalcore when the cursor moves. we calculate a new _scrolloffset based on if we are circling the buffer and how far below the mutable bottom is. we specifically check for if a selection is active and if the viewport is at the bottom, then use that as a condition for deciding if we should update _scrolloffset to the new calculated value or 0 (the bottom of the scroll history). manual testing. though i should add automated tests. new output new output when circling new output when circling and viewport is at the top </desc> <cmt> naive implementation (but it works) </cmt> <cmt> add behavior for multiple flags </cmt> <cmt> now this works with the circling buffer! </cmt> <cmt> remove my lazy enum approach </cmt> <cmt> update the schema </cmt> <iss> feature request: pause output or scrolling on click (and make it a setting) </iss> <iss> feature request: preserve scroll position while not ""at bottom"" </iss>",implement preventing auto-scroll on new output
890,"<desc> #35776 broke importing inaccessible extern crates, which should work with a warning (c.f. #31362). fixes #36747, fixes #37020, and fixes #37021. r? @nrc </desc> <cmt> support importing inaccessible extern crates with a warning again. </cmt> <cmt> add regression test. </cmt> <iss> ice when documenting crate that triggers pr 31362 warning </iss> <iss> regression: unresolved import </iss> <iss> regression: no method in scope </iss>",fix importing inaccessible extern crates (with a warning)
891,"<desc> with the removal of the (standalone) firefox building code in pr #9566 (a year and a half ago), these files are now completely unused. hence it doesn't really make sense to keep building them as part of gulp locale, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). with the removal of the (standalone) firefox building code in pr #9566 (a year and a half ago), these files are now completely unused in the github repository[1]. hence it doesn't really seem necessary to keep fetching them with gulp importl10n, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). the patch also allows an additional simplification, for the gulp locale and gulp mozcentral commands, since it's now possible to stop writing l10n files to the extensions/firefox/ folder and instead just copy them similar to other build targets. update l10n files </desc> <cmt> [firefox] stop building the metadata.inc/chrome.manifest.inc files during gulp locale (pr 9566 follow-up) </cmt> <cmt> with the removal of the (standalone) firefox building code in pr 9566 (a year and a half ago), these files are now completely unused. </cmt> <cmt> hence it doesn't really make sense to keep building them as part of gulp locale, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). </cmt> <cmt> [firefox] stop fetching the chrome.properties files during gulp importl10n (pr 9566 follow-up) </cmt> <cmt> with the removal of the (standalone) firefox building code in pr 9566 (a year and a half ago), these files are now completely unused in the github repository[1]. </cmt> <cmt> hence it doesn't really seem necessary to keep fetching them with gulp importl10n, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). </cmt> <cmt> the patch also allows an additional simplification, for the gulp locale and gulp mozcentral commands, since it's now possible to stop writing l10n files to the extensions/firefox/ folder and instead just copy them similar to other build targets. </cmt> <cmt> --- </cmt> <cmt> [1] they're obviously still used in mozilla-central, for fallback messages displayed through pdfstreamconverter.jsm, but that doesn't make it necessary to keep them *here* as far as i'm concerned. </cmt> <cmt> update l10n files </cmt>",remove unused addon l10n files (pr 9566 follow-up)
892,"<desc> what do these changes do? this is the first step for implementing a offline data i/o api: what works: # generate experiences rllib train --env=cartpole-v0 --run=pg --config='{""output"": ""s3://bucket/data""}' # consume experiences rllib train --env=cartpole-v0 --run=dqn \ --config='{""input"": ""/tmp/data"", ""input_evaluation"": ""simulation""}' # consume experiences from s3 files rllib train --env=cartpole-v0 --run=dqn \ --config='{""input"": [""s3://bucket/f1"", ""s3://bucket/f2""], \ ""input_evaluation"": ""simulation""}' # consume experiences from different sources rllib train --env=cartpole-v0 --run=dqn \ --config='{""input"": {""sampler"": 0.5, ""/tmp/data"": 0.5}}' what's next: trajectory postprocessing and multi-agent support add a non-batched input format counterfactual evaluation (also need some way to get the reward timeline) documentation #3363 </desc> <cmt> output io </cmt> <cmt> evaluator support </cmt> <cmt> stub </cmt> <cmt> update </cmt> <cmt> return spec </cmt> <cmt> json writer </cmt> <cmt> no clip act </cmt> <cmt> os </cmt> <cmt> json writer working </cmt> <cmt> smart open </cmt> <cmt> paginate </cmt> <cmt> writer </cmt> <cmt> io working </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> compression options </cmt> <cmt> add tests </cmt>",basic offline data io api
893,"<desc> fixes #7849. enhance geturl() method. add switch case for oracle  in datasourceconnectionurlutil. add switch case for sqlserver   in datasourceconnectionurlutil. add switch case for mariadb   in datasourceconnectionurlutil. add unit case. add unit case  for oracle in datasourceconnectionurlutiltest . add unit case  for sqlserver in datasourceconnectionurlutiltest . add unit case  for mariadb in datasourceconnectionurlutiltest . </desc> <cmt> enhance geturl support oracle, sqlserver, mariadb </cmt> <cmt> add test case for oracle, sqlserver, mariadb </cmt> <cmt> modify code style </cmt> <iss> support more databases for datasourceconnectionurlutil </iss>",enhance  datasourceconnectionurlutil and add test case
894,"<desc> #86255 introduced a 30% regression in page faults and a 3% regression in max-rss in the ctfe-stress benchmarks. that's most likely happened because it separated allocation from initialization of the vec which defeats the zero-optimization. currently there's no allocation api that is fallible, zeroing and returns a slice, so this pr introduces one and then uses that to solve the problem. in principle vec.resize(len, 0) could be optimized to use alloc::grow_zeroed where appropriate but that would require new specializations and new plumbing in rawvec. </desc> <cmt> add box::try_new_zeroed_slice() </cmt> <cmt> currently there is no api that allows fallible zero-allocation of a vec. </cmt> <cmt> vec.try_reserve is not appropriate for this job since it doesn't know </cmt> <cmt> whether it should zero or arbitrary uninitialized memory is fine. </cmt> <cmt> since box currently holds most of the zeroing/uninit/slice allocation apis </cmt> <cmt> it's the best place to add yet another entry into this feature matrix. </cmt> <cmt> use zeroed allocation instead of eagerly initializing the memory </cmt>",use zeroed allocations in the mir interpreter instead eagerly touching the memory
895,"<desc> i responded to #721 with a brief summary of all the features, and was asked to update the readme with the summary. this pr does that. this also expands a couple of the sections at the start of the doc. i think they make thing clearer, but also a bit more verbose. if you like, we can drop those edits, and just keep the features list, though i think a link to the usage readme, is clearer than a link to available here, and is still just as terse. </desc> <cmt> expanded the features section. </cmt> <cmt> this commit expands the features section to offer a summary of all currently available features, and updates the doc's intro too. </cmt> <cmt> made the link to the usage readme more specific. </cmt> <cmt> this makes the hypertext of the link in the main readme to the usage readme less ambiguous. </cmt>",update the main readme to summarise all the features.
896,"<desc> this is my initial pass at supporting coroutine mocking via a new mock subclass, coroutinemock. it can be used to mock out coroutines and have them validate as coroutines: >>> mock = coroutinemock() >>> asyncio.iscoroutinefunction(mock) true test that a coroutine was awaited: class testtests(unittest.testcase): def test_assert_awaited(self): async def main(): mock = coroutinemock() with self.assertraises(assertionerror): mock.assert_awaited() await mock() mock.assert_awaited() asyncio.run(main()) also awaited_with, awaited_once_with, etc. things that i could use advice on: some of the code has been borrowed by asynctest ( inspect.iscoroutine will return false for coroutinemock objects. this is because the check is isinstance(object, types.coroutinetype), and coroutinetypes are concrete. i've looked into using something like, register, but it doesn't work here, so i need someway to make a mock look like a types.coroutinetype but i am unsure how. in coroutinemockassert tests, i have asyncio.events._event_loop_policy unset because it causes the env to change when running tests if it is not unset. there is probably a better way to do this where the environment doesn't get polluted? i plan on working on getting more example test cases for the coroutinearguments test section, would be happy for advice though. and i will be writing up the documentation once the code has settled. </desc> <cmt> initial commmit adding asyncio mock support. </cmt> <cmt> adding async support to the mock library. </cmt> <cmt> removes superfluous changes. </cmt> <cmt> cleans up comments. </cmt> <cmt> fixes inspect and attribute error issues. </cmt> <cmt> fixes test_unittest changing env because of version issue. </cmt> <cmt> removes newlines from inspect. </cmt> <cmt> removes unneeded comment and newlines. </cmt> <cmt> fixes async tests. removes inspect fix. </cmt> <cmt> fixes environment test issue. </cmt> <cmt> adds argument tests. </cmt>",adds asyncmock for asyncio mock library support
897,"<desc> this pr collects some changes that turn out to be necessary for implementing depnodes based on stable hashes (see #42294). the commits are self-contained and mostly straightforward. the most interesting change here is the introduction of defindices for things that are not part of the ast: some pieces of crate metadata now have a defindex too.  r? @nikomatsakis </desc> <cmt> ich: make stablehashingcontext work with any tyctxt, not just the global one. </cmt> <cmt> ich: add some hashstable implementations. </cmt> <cmt> incr.comp.: make workproductid opaque so we don't accidentally rely on being able to reconstruct obj-file names from one. </cmt> <cmt> allocate defindices for global crate metadata. </cmt> <cmt> this allows for treating global crate metadata the same as regular metadata with regard to incr. comp. </cmt>",some preparatory refactorings for hash-based depnodes
898,"<desc> fixes #35524 (80% solution) this pr makes the parser parse @link tag and the language service offer symbols for entity names found at the beginning of those tags. links are stored redundantly with comment text, so they're only used to provide (1) a span to an editor to format in some way (2) a symbol for the declaration of the link's target. future prs parse # as type-space element access: class#method. as well as, possibly, the normal ts syntax class[""method""], which doesn't currently parse either. open questions i parse @see {@link ...} as a @see with no reference and a link in its comment text. i think that's ok. i intentionally do not parse { @link x}, with a space separating { and @. i saw this only twice in my corpus, but @amcasey points out that it's easy to support with an additional skipwhitespace call. i originally skipped it because i had slightly less lookahead when the next token after { was @, but that made the code unreadable, so i dropped it. resolved questions i introduced jsdoctext and jsdoclink nodes into the ast, which better reflects the semantic relation of comments to their tags. it is more expensive, though, it means that jsdoc comment text is treated as a first-class member of the parse tree now. </desc> <cmt> initial scribbles </cmt> <cmt> compiles but provides spans instead of location pairs </cmt> <cmt> probably need to fork the services/server types and provide a conversion </cmt> <cmt> with session.tofilespan. not sure where to put the conversion. </cmt> <cmt> switch to documentspan </cmt> <cmt> in theory this is already better supported, but not sure practise bears </cmt> <cmt> that out. </cmt> <cmt> builds w/protocol types + conversions </cmt> <cmt> cleanup:better names and scrub todos </cmt> <cmt> fix test harness too </cmt> <cmt> misc </cmt> <cmt> 1. simplify protocol after talking to @mjbvz. </cmt> <cmt> 2. add more tests. </cmt> <cmt> 3. initial notes about where to add parsing. </cmt> <cmt> parse and store links in the compiler </cmt> <cmt> the text of the link is still stored in the comment text, but that's now </cmt> <cmt> kept in an object instead of just a string. each link has the parse for </cmt> <cmt> the entity reference, if there is one. </cmt> <cmt> needs lots more tests -- this just makes all the existing jsdoc tests </cmt> <cmt> pass. </cmt> <cmt> more tests and some fixes </cmt> <cmt> fix other failing tests </cmt> <cmt> fix bad merge </cmt> <cmt> polish parser </cmt> <cmt> improve names and array types </cmt> <cmt> slight tweaks </cmt> <iss> editor support for @see and {@link} in jsdoc comments tags </iss>",editor support for link tag
899,"<desc> bugfix : legacy spring annotation-driven issues on placeholder. refactor: the binder for dubbo's config beans in order to adapter for spring framework and spring boot 1.x/2.0 enhancement : extraction of the ops methods for spring boot acutator run test-cases follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> update </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> manually merge pull request #1486, to make travis ci and codecov work after apache incubator transition. </cmt> <cmt> polish alibaba/dubbo#1306 </cmt> <cmt> merge remote-tracking branch 'dubbo_remote/master' </cmt> <cmt> 2.5.x merge to master </cmt> <cmt> optimize imports </cmt> <cmt> optimize imports </cmt>",spring framework / spring boot enhancements
900,"<desc> fix 8808 first of all, thank you for your contribution! :-) please makes sure that these checkboxes are checked before submitting your pr, thank you! make sure that you propose pr to right branch: bugfix for master, feature for latest active branch feature-x.x. make sure that you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. extra checklist: if isbugfix : make sure that you add at least one unit test for the bug which you had fixed. elif isnewfeature : update api docs for the component. update/add demo to demonstrate new feature. update typescript definition for the component. add unit tests for the feature. </desc> <cmt> anchor scroll supports complete href link </cmt> <cmt> anchor scroll supports complete href link, e.g. </cmt> <cmt> anchor scroll supports complete href link - test </cmt> <cmt> anchor scroll supports complete href link, e.g. </cmt>",bugfix for 2.x stable - anchor scroll supports complete href link
901,"<desc> this pr adds an additional ocr_lang argument to the __init__ method of layoutlmv2featureextractor  which specifies which teserract model to use when applying tesseract ocr. fixes #14511 @nielsrogge </desc> <cmt> added the lang argument to apply_tesseract in feature_extraction_layoutlmv2.py, which is used in pytesseract.image_to_data. </cmt> <cmt> added ocr_lang argument to layoutlmv2featureextractor.__init__, which is used when calling apply_tesseract </cmt> <cmt> updated the documentation of the layoutlmv2featureextractor </cmt> <iss> layoutxlmprocessor applies the english tesseract model </iss>",layoutlmv2featureextractor now supports non-english languages when applying tesseract ocr.
902,"<desc> prior to this pr, something broke the signatures of wrapped dg methods. this was reflected in docs.streamlit.io (where things like st.text(body) were written as st.text()) and in the python console (e.g. help(st.text)). it was probably broken in ides too. that's because we use some magic to make our signatures cleaner, and something broke that magic. i fixed that now and added tests. </desc> <cmt> fix signatures of wrapped dg functions </cmt> <cmt> lint </cmt>",clean signatures of wrapped deltagenerator methods
903,"<desc> first of two prs to separate array casting/inference out of index.__new__.  once both are in place, we'll be able to do all inference/casting up-front and simplify the constructor quite a bit.  we'll also be able to look into sharing code between index/series/array, and address a handful of outstanding issues with the index constructor. </desc> <cmt> ref: refactor array casting out of index.__new__ </cmt> <cmt> docstrings </cmt>",separate casting out of index.__new__
904,"<desc> this updates the include/exclude configs to output/remove files in the traces correctly and adds tests for the configs. related issues linked using fixes #number errors have helpful link attached, see contributing.md related issues linked using fixes #number errors have helpful link attached, see contributing.md make sure the linting passes by running yarn lint </desc> <cmt> use micromatch for excludes and add tests </cmt> <cmt> update compiled </cmt>",update include/exclude handling for output tracing
905,"<desc> description: this pr adds support for custom stream queries per device and media type to media_extractor. example entry for configuration.yaml (if applicable): media_extractor: default_query: worst customize: media_player.kd55x8507c: video: bestvideo music: bestaudio playlist: worstaudio[ext=mp4] default query if no settings provided is  best. user can override default value or set custom query per device and media type. examples: bestvideo - best video only stream best - best video + audio stream bestaudio[ext=m4a] - best audio stream with m4a extension worst - worst video + audio stream bestaudio[ext=m4a]/bestaudio[ext=ogg]/bestaudio - best m4a audio, otherwise best ogg audio and only then any audio more about format queries  but: my settings: media_extractor: default_query: best customize: media_player.kd55x8507c: video/videoonly: bestvideo video/best: best audio/best: bestaudio[ext=m4a] my chromecast device (sony bravia with android tv) does not support these media content types  it supports media_content_type attributes like: video/blablabla audio/blablabla my service call data is: {""entity_id"": ""media_player.kd55x8507c"", ""media_content_id"": "" checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add support for different stream formats </cmt> <cmt> encapsulate logic inside mediaextractor class </cmt>",add support for custom stream queries for media_extractor
906,<desc> ander's work on destructuring assignment has incorporated two features : emitting default parameters and emitting rest parameters. this pull request is to add test cases for these two features. </desc> <cmt> add tests covering emitting default parameters natively in es6 </cmt> <cmt> add tests covering emitting rest parameters natively in es6 </cmt>,add tests for rest and default
907,"<desc> following #28413, #28396, and #28395, these are all pretty straightforward refactors. arithmetic_op, comparison_op, and logical_op are going to become the ops that we call block-wise.  hopefully also pandasarray will use them directly. other follow-ups i have in mind: move should_extension_dispatch and dispatch_to_extension_op so we dont need runtime imports get rid of eval_kwargs entirely, they're not really necessary at this point see if we can use numexpr for comparison/logical ops docstrings address inconsistencies in when we call extract_array address inconsistencies in how series methods handle __finalize__ and alignment simplify logical_op's na_op </desc> <cmt> ref: implement logical and comparison array ops </cmt> <cmt> implement arithmetic_op </cmt>","implement arithmetic, comparison, logical ops on arrays"
908,<desc> a number of regressions were patched also.     the ubl g29 p2 and p4 press and hold had stopped working.   it is very possible this is broken in the bugfix_v1.1.x branch also. the main purpose of the pull request is to get the 3-point mesh tilting to use the lsf algorithm just like the grid based mesh tilt.   this simplifies the logic and reduces the code size some what.   but the real reason to do it is the 3-point case can be solved exactly.    and by feeding these numbers into the lsf algorithm it provides a way to check all that code for 'correctness'. </desc> <cmt> fix regression of x & y on max7219 debug led's </cmt> <cmt> make g29 p1 and g29 p2 changes available to everybody. </cmt> <cmt> back to default configurations for pull request </cmt>,convert ubl mesh tilting to all use the same algorithm
909,"<desc> fix issue #642 (aztec decoding: incorrect decoding of codes with u/s b/s). this is a 1-line addition to core/src/main/java/com/google/zxing/aztec/decoder/decoder.java add test case core/src/test/resources/blackbox/aztec-1/dlusbs.png and matching .txt change number of test cases. the original code fails tests for core on the added test case; the source change fixes that. </desc> <cmt> update decoder.java </cmt> <cmt> add files via upload </cmt> <cmt> dlusbs.png and dlusbs.txt is a test case for the d/l [digit] u/s b/s sequence, which should end in upper mode, not digit mode </cmt> <iss> core: aztec decoding incorrect for codes with u/s b/s </iss>",return to upper mode after u/s b/s sequence.
910,"<desc> .s16 sign extends on loads, but it seems to be the same as .u16 on stores. since our ir doesn't support primitives for integers smaller than 32 bits, implement the logic manually. in the future we might want to handle 16 and 8 bit operations at its respective level on the ir and use 32 bits operations on the decompilation step when the target api doesn't support smaller integers. while we are at it, abstract the code to avoid repeating logic. used by pc builder simulator used by doom 2016 </desc> <cmt> shader/memory: implement ldl.s16 and lds.s16 </cmt> <cmt> shader/memory: move unaligned load/store to functions </cmt> <cmt> shader/memory: implement unaligned ldl.s16 and lds.s16 </cmt> <cmt> shader/memory: implement stl.s16 and sts.s16 </cmt>","implement ldl.s16, lds.s16, stl.s16 and sts.s16"
911,"<desc> a fix for #8398. </desc> <cmt> core: when we can't enqueue onfailure= job show full error message </cmt> <cmt> let's ask for the full error message and show it, there's really no </cmt> <cmt> reason to just show the crappy errno error. </cmt> <cmt> core: don't trigger onfailure= deps when a unit is going to restart </cmt> <cmt> this adds a flags parameter to unit_notify() which can be used to pass </cmt> <cmt> additional notification information to the function. we the make the old </cmt> <cmt> reload_failure boolean parameter one of these flags, and then add a new </cmt> <cmt> flag that let's unit_notify() if we are configured to restart the </cmt> <cmt> service. </cmt> <cmt> note that this adjusts behaviour of systemd to match what the docs say. </cmt> <cmt> fixes: #8398 </cmt> <cmt> update news to explain new onfailure= behaviour </cmt>",trigger onfailure= only if restart= is not in effect
912,"<desc> the issue was: if someone mentions an user that is not following the thread, that user (the user mentioned) would not get a notification. also fixes #14019 by always using the sender as the email from </desc> <cmt> fix sending notifications to mentions on threads </cmt> <cmt> always use the sender name as email from field </cmt> <iss> mentions email inside discussions uses the wrong name property </iss>",fix sending notifications to mentions on threads and discussion email sender
913,<desc> this pull request add the support of can iso-tp address extensions in the socket module by enhancing getsockaddrarg and getsockname. note to core developpers : i believe this pull request should be backported back to python 3.3 where socketcan support have been added. </desc> <cmt> added support for can_isotp protocol </cmt> <cmt> added unit tests for can isotp </cmt> <cmt> updated documentation for iso-tp protocol </cmt>,bpo-30987 - support for iso-tp protocol in socketcan
914,<desc> pylint rule unused-import isn't prompting error anymore - removing disabled rule from charts and connectors modules. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> removed disabled pylint rule unused_import from dao.py in charts module </cmt> <cmt> removed disabled pylint rule unused_import from connector_registry.py in connectors module </cmt>,reenable pylint rule unused-import in charts and connectors modules
915,"<desc> previously, if you attempted to run a spec window and an atom process was already running it would run the specs in the already running process which prevented the spec output from being seen. this also updates the bundled version of apm to include apm test. </desc> <cmt> remove initialization repetition from a second atom process </cmt> <cmt> run test processes separately </cmt> <cmt> update apm to include apm test </cmt>",always launch atom as a separate process (when just running specs)
916,"<desc> this fixes #1551. servers now respond to unparseable arguments with the invalid_argument status and the text of the deserialization error, instead of crashing. </desc> <cmt> added failing tests for server bad argument handling </cmt> <cmt> fixed server to handle invalid arguments without breaking </cmt> <iss> node rpc server cannot recover from malformed requests </iss>",handle invalid arguments sent to the node server
917,"<desc> this pr adds rate limits to post /api/users and post /api/users/:user_id. it's currently static, but we can make it configurable if needed. also changed tests not to use rate limits (except for the tests that need them). </desc> <cmt> add rate limits for user resources. </cmt> <cmt> disable rate limiting in tests (except for tests that need it). </cmt>",add rate limits to user creation/update
918,"<desc> added a new style guide rule for ""prefer the hooks api as the default"", plus an example of looking up action stack traces in the essentials tutorial. also switched all the ""default explanation"" expanders in the style guide to use an mdx component, and added back some margin between paragraphs inside those explanations. </desc> <cmt> add style guide link to header as ""best practices"" </cmt> <cmt> tweak styling for style guide detailed explanation paragraphs </cmt> <cmt> add ""use hooks api"" style guide rule </cmt> <cmt> add action stack trace example </cmt>","add ""use hooks"" style guide rule and ""action stack trace"" tutorial example"
919,"<desc> tested it out and works nicely. things which are not very nice and would like to get feedback: naming of methods in groupservice.ts, notice that the setting is named showtabs so i was trying to be consistent with that currently the editorgroupservice does not react on showtabs changed in the configuration - the partservice does that and lets the editorgroupservice know. the alternative would be the editorgroupservice does this but then needs to check the part service if zen mode is active (which would require an additional method in part service) fixes #17207 </desc> <cmt> editorgroupservice: managing of tabs visibility </cmt> <cmt> zenmode: hide tabs </cmt> <iss> zen mode could have an option to show only the current tab </iss>",isidorn/tabs in editor group service
920,<desc> made few corrections changes for easy navigation and easy reading </desc> <cmt> fix url bug caused by typo </cmt> <cmt> update url with the new correct source </cmt> <cmt> fix broken url caused by dead source </cmt> <cmt> made adjustment to the docs for easy navigation </cmt>,updated the docs in deploying-to-gatsby-cloud
921,"<desc> this is a small improvement for mapactions and mapmutations helpers. it allows users to pass functions in the helpers so that reducing some redundant method definitions. the feature is like a counterpart of passing function in mapstate. for example: const vm = new vue({ store, template: <input @input=""oninput""> methods: mapactions({ oninput (dispatch, event) { // first argument is as same as this.$store.dispatch dispatch('inputtext', { text: event.value }) } }) }) the above code is equivalent with the below (note that inputtext is a bit redundant since it is just an bridge method between oninput and the action): const vm = new vue({ store, template: <input @input=""oninput""> methods: { ...mapactions(['inputtext']), oninput (event) { this.inputtext({ text: event.value }) } }) }) in addition, this syntax is more effective when we map namespaced modules. methods: mapactions('some/module', { oninput (dispatch, event) { // dispatch is already namespaced here. // so the below line will call some/module/inputtext action. dispatch('inputtext', { text: event.value }) } }) i did not implement this syntax for mapgetters because we already can do the same thing with mapstate. close #750 </desc> <cmt> feat: allow to pass function value in mapactions/mapmutations </cmt> <cmt> feat: extend mapactions/mapmutations types for function usage </cmt>",allow to passing functions in mapactions/mapmutations (fix #750)
922,<desc> this pr fixes the behavior re: pathprefix identified in #8155. essentially: uses withprefix helper in all programmatic navigation removes manual prefix in onclick handler in link adds a number of unit tests and e2e tests </desc> <cmt> fix: prefix navigate calls with pathprefix </cmt> <cmt> fixes #8155 </cmt> <cmt> test: fix unit tests and add a few new ones </cmt> <cmt> e2e: update integration tests </cmt>,use path prefix in navigate/replace/push calls
923,<desc> we already have a page in docs  i have updated the existing page with content from site-showcase-submissions and set the link as available. i also think it would be better if we add a redirect for site-showcase-submissions to submit-to-site-showcase @shannonbux @jlengstorf @m-allanson </desc> <cmt> pulling from master </cmt> <cmt> pull from source </cmt> <cmt> updating submit to site showcase </cmt>,updating 'submit-to-site-showcase' stub in docs
924,<desc> new toggle is added into fancyzones settings to enable/disable snapping windows to zones across monitors when moving windows using windows snap hotkeys. references pr checklist validation steps performed manually tested for correct functionality and regressions on single and multi-monitor environment. </desc> <cmt> make moving window across monitors optional </cmt> <cmt> update tests </cmt>,make snapping windows using windows snap hotkeys across monitors optional
925,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. continuation of #36041 after pr was closed because of inactivity. </desc> <cmt> update typings to styled-system v5 </cmt> <cmt> update system usage to include all properties </cmt> <cmt> correct jsdoc comment spacings </cmt> <cmt> actually correct jsdoc comment format </cmt> <cmt> correct and test jsdoc comment spacing locally </cmt> <cmt> the last three commits all have to do with correcting jsdoc spacing, but </cmt> <cmt> unfortunately, the first two did not correct the issue. this commit </cmt> <cmt> corrects the issue and is tested locally. i would prefer to squash all </cmt> <cmt> these commits into the first, but will leave them for now. </cmt> <cmt> update styled system typings </cmt> <cmt> add createparser and createstylefunction functions </cmt> <cmt> update types/styled-system/index.d.ts </cmt> <cmt> update gridtemplateareasprops interface </cmt> <cmt> add textshadow and shadows style functions </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix shadows </cmt> <cmt>  </cmt>",update typings to v5 (continued)
926,"<desc> i hereby agree to the terms of the cla available at:  add connection pool for postgresql table/database engine and dictionary source. should fix #21444. </desc> <cmt> add connection pool </cmt> <cmt> add test </cmt> <cmt> better </cmt> <iss> postgresql engine: pqxx, new command started while previous is active </iss>",add connection pool for postgres engine
927,"<desc> with this pr we improve type argument inference by inferring from the contextual type of a generic function call to the return type of the generic function. for example: function emptyarray<t>(): t[] { return []; } let a1: string[] = emptyarray();  // string inferred for t let a2: number[] = emptyarray();  // number inferred for t previously the two assignments above would error because {} was inferred for t. we now infer from the contextual type (i.e. the type of the variable to which the function result is assigned). a more elaborate example: function arrayfilter<t>(f: (x: t) => boolean): (a: t[]) => t[] { return a => a.filter(f); } function arraymap<t, u>(f: (x: t) => u): (a: t[]) => u[] { return a => a.map(f); } function compose<a, b, c>(f: (x: a) => b, g: (x: b) => c): (x: a) => c { return x => g(f(x)); } const positives: (a: number[]) => number[] = arrayfilter(x => x >= 0); const lengths: (a: string[]) => number[] = arraymap(s => s.length); const evenlengths: (a: string[]) => number[] = compose(arraymap(s => s.length), arrayfilter(x => x % 2 === 0)); let a1 = positives([1, 2, -3, 4, -5]);            // [1, 2, 4] let a2 = lengths(['a', 'bb', 'ccc', 'dddd']);     // [1, 2, 3] let a3 = evenlengths(['a', 'bb', 'ccc', 'dddd']); // [2, 4] inferences made from generic function return types have lower priority than inferences made from arguments to the generic function. for example, the type of s is inferred as string (not object) in the following: function filter<t>(a: t[], f: (x: t) => boolean): t[] { return a.filter(f); } let a: object[] = filter(['a', 'bb', 'ccc', 'dddd'], s => s.length > 2); this pr is a precursor for inferring higher order function types when no inferences can be made for one or more type parameters. const wrapper = compose(x => [x], y => ({ p: y }));  // (x: {}) => { p: {}[] } we currently infer (x: {}) => { p: {}[] }, but ideally we'd infer <a>(x: a) => { p: a[] }. that's next on the list. fixes #15680. </desc> <cmt> revise type inference data structures </cmt> <cmt> initial implementation of return type inference </cmt> <cmt> clean up implementation </cmt> <cmt> accept new baselines </cmt> <cmt> fix fourslash test </cmt> <cmt> fix linting errors </cmt> <cmt> inferencecontext is-a typemapper instead of has-a typemapper </cmt> <cmt> move return type inference to infertypearguments function </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>",infer from generic function return types
928,"<desc> fix the title/link for ""supported platforms"", which got lost in a previous toc reorg. move ""code signing"" under ""application distribution"", because it's unclear what the difference between ""packaging"" and ""distribution"" is, and also this was the only item under ""packaging"". cc: @electron/wg-docs-tools pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> docs: fix link to supported platforms in toc </cmt> <cmt> docs: move code signing under the distribution heading </cmt>",reorganize application distribution links in table of contents
929,<desc> description: this change adds support for multiple disks to be configured and monitored. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3678 example entry for configuration.yaml (if applicable): sensor: - platform: hddtemp host: 192.168.1.2 disks: - /dev/sda - /dev/sdb checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> add support for multiple disks. </cmt> <cmt> merge upstream </cmt> <cmt> fix lint error. </cmt>,add support for multiple disks to be monitored.
930,<desc> we were modifying the passed in dictionary in-place in order to handle an edge case of working_dir. this was causing failures in serve as the passed dictionary was stored and used for more deployments in the future. this modifies the logic to not modify the dictionary and instead pass along the parent's working dir as a separate parameter. closes #18403 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix validation logic </cmt> <cmt> working </cmt> <iss> [runtime_env] [serve] updating deployment that uses working_dir causes backend_state.update() to fail </iss>,don't modify passed runtime_env dictionary when validating
931,"<desc> this pr: ports test_trainer_distributed to run with pytest - it will skip if gpus < 2. includes various improvements via refactoring now 3 use cases of distributed testing by extending testcaseplus with a whole set of convenient features: feature 1: a set of fully resolved important file and dir path accessors. in tests often we need to know where things are relative to the current test file, and it's not trivial since the test could be invoked from more than one directory or could reside in different sub-directories. this class solves this problem by sorting out all the basic paths and provides easy accessors to them: pathlib objects (all fully resolved): test_file_path - the current test file path (=__file__) test_file_dir - the directory containing the current test file tests_dir - the directory of the tests test suite examples_dir - the directory of the examples test suite repo_root_dir - the directory of the repository src_dir - the directory of src (i.e. where the transformers sub-dir resides) stringified paths - same as above but these return a string, rather than a pathlib object test_file_path_str test_file_dir_str tests_dir_str examples_dir_str repo_root_dir_str src_dir_str feature 2: get a copy of the os.environ object that sets up pythonpath  correctly, depending on the test suite it's invoked from. this is useful for invoking external programs from the test suite - e.g. distributed training. def test_whatever(self): env = self.get_env() # now call the external program, passing env to it all these are also documented in testing.rst. fixes: #8058 @sgugger, @lysandrejik, @sshleifer </desc> <cmt> move the helper code into testing_utils </cmt> <cmt> port test_trainer_distributed to work with pytest </cmt> <cmt> improve docs </cmt> <iss> [testing] port test_trainer_distributed to run with pytest </iss>",port test_trainer_distributed to distributed pytest + testcaseplus enhancements
932,"<desc> i hereby agree to the terms of the cla available at:  references to gcc 9 replaced to gcc 10 in build instructions (all languages). detailed description / documentation draft: as gcc 9 is not supported, build instructions now correctly require to install gcc 10. </desc> <cmt> development instructions updated to gcc 10 from gcc 9 </cmt> <cmt> reverted tiny mistake added in previous commit. more reference to gcc 9 replaced </cmt>",hrissan/dev instructions gcc 9 to gcc 10
933,<desc> also fixes a race condition that's common with slow connection @miloskozak i think this will cover most of the issues you had with defined mode </desc> <cmt> support for using stored apisecret in denied mode and add auth headers to report requests </cmt> <cmt> use status.json instead of status.js and wait for it to load </cmt>,support for using stored apisecret in denied mode to load settings
934,<desc> fixes #128786 </desc> <cmt> create helper class for event with reply pattern in terminal </cmt> <cmt> part of #128786 </cmt> <cmt> adopt requeststore in pty host </cmt> <cmt> support timeout in requeststore </cmt> <cmt> fixes #128786 </cmt> <cmt> docs </cmt> <cmt> move request store to common </cmt> <cmt> add request store test </cmt> <iss> add a maximum timeout for resolve variable/detach instance requests in pty host </iss>,"add requeststore helper, adopt in ptyhost and add timeout support"
935,"<desc> cleanup in the examples/csharp directory: make the helloworld example using dotnet cli the default (helloworld-from-cli -> helloworld) mark the original helloworld using the legacy .csproj project as ""still fully supported but legacy"" (helloworld -> helloworldlegacycsproj) convert routeguide to the new-style .csproj projects (leads to simplification and easier maintenance) update the readmes accordingly. note: after this is merged and the release is cut, i'll need to do a pass on grpc.io site to make sure the docs there capture the new directory names from this pr. </desc> <cmt> convert route_guide to .netcore project </cmt> <cmt> move helloworld -> helloworldlegacycsproj </cmt> <cmt> make new-style .csproj helloworld the default </cmt> <cmt> rename route_guide -> routeguide </cmt> <cmt> upgrade c# helloworld and routeguide to v1.13.1 </cmt> <cmt> update the readme files </cmt> <cmt> upgrade helloworldlegacycsproj to grpc1.13.1 </cmt>",cleanup and update c# examples
936,"<desc> call the luaoc bridge function , when the oc function return type is bool, i get the returntype from const char *returntype = [methodsig methodreturntype]; is ""b"". platform : ios 10.3. </desc> <cmt> update remote repo </cmt> <cmt> revert ""update remote repo"" </cmt> <cmt> this reverts commit c92200d0ac4203c32048ea902e92535dcb4d0935. </cmt> <cmt> returntype bool </cmt>",luaoc static function return type bool
937,"<desc> this pr simplifies zca whitening by not forming the covariance matrix or the full diagonal matrix. instead it uses the svd of the data itself and broadcasting division, which is mathematically equivalent but faster and more numerically stable. tested numerically by the following import numpy as np import numpy.random as npr import numpy.linalg as linalg def princomps_old(flat_x): sigma = np.dot(flat_x.t, flat_x) / flat_x.shape[0] u, s, _ = linalg.svd(sigma) principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 1e-5))), u.t) return principal_components def princomps_new(flat_x): n_examples = flat_x.shape[0] u, s, vt = linalg.svd(flat_x / np.sqrt(n_examples)) s_expand = np.hstack((s, np.zeros(vt.shape[0] - n_examples, dtype=flat_x.dtype))) principal_components = (vt.t / np.sqrt(s_expand**2 + 1e-5)).dot(vt) return principal_components x = npr.randn(64, 784) #a batch of mnist data flat_x = x - x.mean(axis=0) print(np.allclose(princomps_old(flat_x), princomps_new(flat_x))) #true </desc> <cmt> implemented zca_whitening without forming covariance matrix or explicit call to diag for eigenvalues </cmt> <cmt> made principal_components self.principal_components </cmt>",improvements to numerical stability and performance for zca whitening
938,"<desc> add or update assignment expression documentation for: faq - design reference - expressions reference - lexical analysis  automerge-triggered-by: @matrixise </desc> <cmt> (docs) add := to list of operators </cmt> <cmt> (docs) add operator precedence for := to reference - expressions </cmt> <cmt> (docs) replace faq for ""why can't i use an assignment expression?"" </cmt> <cmt> (docs) remove docs todo </cmt>",additional documentation for assignment expressions
939,"<desc> change #82216 removed now deprecated target x86_64-sun-solaris from ci, thus making it no longer possible to use $ rustup target add x86_64-sun-solaris to install given target (see #85098 for details). since there should be a period of time between the deprecation and removal, this pr brings it back (while keeping the new one as well). please, correct me if i am wrong; my assumption that these docker scripts are being used to build artifacts later used by rustup might be incorrect. closes #85098. </desc> <cmt> update docker to build the deprecated target alongside the new one </cmt> <cmt> improve comment </cmt> <iss> `x86_64-sun-solaris` target was removed without warning in rust 1.52 </iss>",bring back x86_64-sun-solaris target to rustup
940,"<desc> wavm tends to cause significant memory usage even when fixes like #6983 are in place. this pr includes two changes that reduce the memory usage of wavm by a large margin. first: avoid generation of debug information; this was actually done at a per-wasm-opcode resolution so it was very memory intensive and also tended to wedge things in to a global cache that would never be freed. second: free the wavm module after we no longer need it once a moduleinstance is created from it </desc> <cmt> remove generation of debug info from wavm code generation </cmt> <cmt> generation of debug info consumes a massive amount of memory and quite a bit of it seems to get lodged in the global llvmcontext meaning it becomes a leak in the current design of wavm. removing this as we don't need it </cmt> <cmt> don't hold on to wavm module object any longer than needed </cmt> <cmt> after creating a moduleinstance from a module, we really don't need to hold on to the module any longer. it's a memory sink. refactor the one instance we needed the module and free it after that </cmt>",reduction of wavm memory usage
941,<desc> fixes #16733 this small pr updates the description of the sub-sample size to take into account the addition of the max_samples parameter in version 0.22. </desc> <cmt> update description of random forest estimators regarding sub-sample size </cmt> <cmt> use backslashes for max_samples </cmt> <iss> description of bootstrapping for randomforest estimators </iss>,doc update docstring of rfs regarding max_samples
942,"<desc> haven't tested this yet. letting jenkins do the work. @caisq fyi. note that we should keep our docker hub images on ubuntu 16.04 because that fixes the bugs users encounter. note for others looking at this change: we're downgrading to ubuntu 14.04 for official releases so that it links against the older version of glibc and allows for wider compatibility. </desc> <cmt> revert ""update ci docker images to ubuntu 16.04"" </cmt> <cmt> this reverts commit d7dc1304053428849f47981f3e77ad1fe88d59dd. </cmt> <cmt> fix the old dockerfile </cmt> <cmt> delete trusty add-apt-repository </cmt> <cmt> fixes </cmt> <cmt> upgrade protobuf </cmt>",switch back to ubuntu 14.04 for our releases.
943,"<desc> entry 1: update contributing.md to reflect current maven version requirement </desc> <cmt> update contributing.md </cmt> <cmt> the build no longer works with maven 3.5.3.  if you try it, you end up with this: </cmt> <cmt> [info] --- maven-enforcer-plugin:3.0.0-m2:enforce (display-info) @ jenkins-parent --- </cmt> <cmt> [warning] rule 0: org.apache.maven.plugins.enforcer.requiremavenversion failed with message: </cmt> <cmt> 3.5.4+ required to use incrementals. </cmt> <cmt> [info] ------------------------------------------------------------------------ </cmt> <cmt> [info] reactor summary: </cmt> <cmt> [info] </cmt> <cmt> [info] jenkins main module 2.199-snapshot ................. failure [ 44.098 s] </cmt> <cmt> update contributing.md </cmt>",update documented maven requirement: 3.5.3 -> 3.5.4
944,"<desc> the project filters bar chart doesn't have min heights and the 1pt values look kinda odd because there are so many: it's super annoying to get project filters working in dev, so i just faked some data. i added a bunch of zeroes into the fake data and it looked like this: you can see that all of the zero databits are sandwiched together at the bottom. after this pull, the fake data looks like this: the reason this happens is because previously, min-heights were applied as css and weren't factored into the stacking of the bars. if there were multiple bars with min-heights, they would just stack on top of each other and whatever bar was last would be on top. this doesn't seem like an ideal behavior to me, so rather than try to replicate it, i'm just adding things here and there to make the old stuff look semi dece. </desc> <cmt> add minheights for project filters chart </cmt> <cmt> search for specific classname and apply 1 </cmt> <cmt> use legacy browsers as it has a better color b) </cmt>",min heights for project filters
945,<desc> as discussed in #3554 the tokens in the tokenizer have to be shifted if adding a new token into aka resizing an embedding layer other than the last one. of course this applies only for an adaptiveembedding with more than one layer. this implementation adds a function to move an added token in the tokenizer to a specific position. this is closely related to the pr #4759 </desc> <cmt> fixed resize_token_embeddings for transfo_xl model </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixed resize_token_embeddings for transfo_xl. </cmt> <cmt> added custom methods to transfoxlpretrainedmodel for resizing layers of </cmt> <cmt> the adaptiveembedding. </cmt> <cmt> updated docstring </cmt> <cmt> fixed resizinhg cutoffs; added check for new size of embedding layer. </cmt> <cmt> added test for resize_token_embeddings </cmt> <cmt> fixed code quality </cmt> <cmt> fixed unchanged cutoffs in model.config </cmt> <cmt> fix resize tok transfo xl </cmt> <cmt> added feature to move added tokens in tokenizer. </cmt> <cmt> fixed code quality </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added feature to move added tokens in tokenizer. </cmt> <cmt> fixed code quality </cmt>,added feature to move added tokens in vocabulary for transformer-xl
946,"<desc> breaking change: state off is now state standby. affects user defined scripts, automations, etc. description: similar changes as roku integration #28148 currently, if service media_player.select_source is called when entity is in standby mode, ps4 will be turned on first and then will change source. this pr would allow this feature to be accessible from the ui, as the select source dropdown is not available if using state off.  state standby is also the more accurate state. related issue (if applicable): fixes # pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> change state off to state standby </cmt> <cmt> update docstring </cmt>",change ps4 state off to state standby
947,"<desc> x] add or edit tests to reflect the change. (run with npm test.) x] follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. none of the above apply; this is a simple syntax error, possibly caused by a change in a dependency, unsure. when i compile with the latest typescript it fails with an error that it can't extend passport.strategy and suggests ""implements"" instead -- this change works and fixes the problem. </desc> <cmt> created feature branch update_passport_facebook </cmt> <cmt> fix compile error in typescript 3.4; passport.strategy is an interface and must be implemented, not extended </cmt>","fix compile error w/ passport-facebook, latest passport typings, typescript 3.4"
948,"<desc> see jenkins-56499. entry 1: issue, there is a synchronized method on api token usage stat, which will cause thread hang on changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) </desc> <cmt> update apitokenstats.java </cmt> <cmt> remove the synchronized on method updateusageforid if token usage stats diabled </cmt> <cmt> update apitokenpropertyconfiguration.java </cmt> <cmt> change the default value for api token usage stats to false </cmt>",remove synchronized on method updateusageforid for api token usage stat
949,"<desc> the idea is that the ci job checks if the user forgot to run the amalgamation script. update: see also #106 and #509 also, it sets the date to be locale/timezone independent. to make it be reproducible, the date is picked from the git commit instead of the current time. </desc> <cmt> output date in a locale independent way </cmt> <cmt> add ci for checking amalgamation </cmt>",detect if amalgamation is needed
950,"<desc> what did you implement: re-work for #2861 and #2907 added top level commands to the framework core. serverless plugin serverless plugin - shows list of sub commands serverless plugin install - downloads plugin and automatically adds to serverless.yml. serverless plugin uninstall - removes the plugin from serverless.yml file serverless plugin list - list all available/known plugins from the plugin repo serverless plugin search - search for match out of list. how did you implement it: i have restored the code from #2907 and applied some slightly updates, but the basic spec has not changed how can we verify it: please run the following commands serverless plugin list serverless plugin search --query / -q {query string} serverless plugin install --name / -n {plugin name} serverless plugin uninstall --name / -n {plugin name} todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> initial commit for adding plugin command </cmt> <cmt> add if-check to uninstall </cmt> <cmt> update using chai-as-promised </cmt> <cmt> add tracking method </cmt> <cmt> add document </cmt>",add plugin command to provide for users how find and install / uninstall
951,"<desc> as noted in #61890 (comment) and #62295 (comment), the 1.10 changes to the openstack cloud provider node name computation (in #58502, #61000, and #61890) broke existing deployments that provisioned instances with credentials matching their instance names. it also did not account for version skewed kubelets, which can run 1.8 and 1.9 versions against a 1.10 master, and still register based on instance name. this pr reverts the incompatible changes to restore pre-1.10 behavior. further improvements to handle instances with names that cannot be used as node names are tracked in #62295 /assign @dims /sig openstack restores the pre-1.10 behavior of the openstack cloud provider which uses the instance name as the kubernetes node name. this requires instances be named with rfc-1123 compatible names. </desc> <cmt> revert ""specify dhcp domain for hostname"" </cmt> <cmt> this reverts commit da5ccf7fb72666de47113442eaca7d2efd5fb507. </cmt> <cmt> revert ""split out the hostname when default dhcp_domain is used in nova.conf"" </cmt> <cmt> this reverts commit 9a8c6db448f200ddd9a06813affab804b183de20. </cmt> <cmt> revert ""openstack: register metadata.hostname as node name"" </cmt> <cmt> this reverts commit eaac0f5489de823f9e5805c53855560ae1a64156. </cmt>",restore pre-1.10 openstack instance naming behavior
952,"<desc> there are 2 proposed fixups in discussions in #23280 which i have not implemented: an overhaul to return types and an option type for the two *chainstate functions: #23280 (comment) the change reintroduces stringy return types and is quite involved. it could be discussed in a separate pr. passing in the unix time to verifychainstate instead of a callback to get the time: #23280 (comment) i'm not sure it matters much whether it's a callback or just the actual unix time. also, i think verifydb can take quite a while, and i don't want to impose that the function have to ""run quickly"" in order to have it be correct. if reviewers feel strongly about either of the two fixups listed above, please feel free to open a pr based on mine and i'll close this one! </desc> <cmt> node/chainstate: use max_future_block_time </cmt> <cmt> docs: make loadchainstate comment more accurate </cmt> <cmt> style-only: rename *chainstate return values </cmt> <cmt> init: use clang-tidy named args syntax </cmt>","post-""chainstate loading sequence coalescence"" fixups"
953,"<desc> this is the work to fix #4677. currently, it caches middleware instances per player in an object whose keys are player ids and the value is an array of arrays. the inner array associates middleware factories and the middleware instances. tests need to be added and updated as well. change has been verified in an actual browser (chome, firefox, ie) </desc> <cmt> cache mw instances per type, player, and factory in that order </cmt> <cmt> associate mw factories with instances per player id </cmt> <cmt> clear mw cache on player dispose </cmt> <iss> middleware gets recreated on source change, duplicating event handlers bound within </iss>",cache middleware instances per player
954,"<desc> what did you implement: closes #5398 how did you implement it: in #5594, cleanvariable does not clean whitespaces if variable is double-quote string literal. atter this pr, it also does not clean whitespace if variable is single-quote string literal. how can we verify it: npm install -g exoego/serverless#single-quote-fallback sls deploy below and confirm it completes successfully. service: aws-nodejs provider: name: aws runtime: nodejs8.10 functions: hello: handler: handler.hello events: - schedule: ${env:schedule, 'rate(2 hours)'} - schedule: ${env:schedule, ""rate(3 hours)""} todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add tests for #5398 </cmt> <cmt> do not remove spaces in single-quote literal. </cmt>",preserve whitespaces in single-quote literal fallback
955,<desc> there was a regression at some point where the files under static/ were not properly prebuilt into the less cache causing them to be recompiled on the fly during runtime. this would slow down the very first launch of atom on a machine before ~/.atom/compile-cache would be populated. it would also slow down the first launch after an update whenever a stylesheet under static/ had been changed. this saves ~500ms off of the very first atom launch on a machine by not having to compile the following less files on the fly: static/atom.less static/text-editor-shadow.less node_modules/atom-space-pen-views/stylesheets/select-list.less you can see this slow down by deleting ~/.atom/compile-cache/less and then restarting atom with --safe. </desc> <cmt> don't include fallback imports for static files </cmt> <cmt> precompile atom-space-pen-views stylesheets </cmt>,fix static .less prebuilt cache
956,"<desc> added documentation in readme, man page, man page markdown, and main-conf.c in usage and print_nmap_help functions. </desc> <cmt> update readme.md </cmt> <cmt> added grepable format information. </cmt> <cmt> added more command line options </cmt> <cmt> added json, list, grepable, and interactive. </cmt> <cmt> generated new man page using ronn </cmt> <cmt> based on updated markdown file. </cmt> <cmt> additional output options </cmt> <cmt> add additional help documentation </cmt> <cmt> added serval flags to usage and nmap_help functions: </cmt> <cmt> output flags for xml,binary,json,list,grepable </cmt> <cmt> added --output-format and --output-file </cmt> <cmt> added --banners </cmt> <cmt> added --connection-time </cmt>",added documentation for recently added flags
957,<desc> removing some left over files in react-native-win32 from a documentation solution that isn't being used in the new code location. microsoft reviewers: open in codeflow </desc> <cmt> remove remanents of old doc format </cmt> <cmt> change files </cmt>,remove remnants of old doc format
958,"<desc> this patch set adds and fixes a variety of things, such as: adds the cluster-level authentication api adds bucket index management api adds the full-text search api adds missing events from bucket class adds specific event definitions for query response classes adds much more test code from the documentation fixes a lot of function definitions this patch set does not bring these definitions fully in-line with 2.4.5, but it gets them much closer. many definitions are written directly from the sdk's source code, because the sdk docs don't cover a lot of uses. java docs have been used in many places where the node sdk docs were missing. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).     increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> couchbase: fix bucket key parameter types </cmt> <cmt> documentation says key type is string or buffer, not any. </cmt> <cmt>  </cmt> <cmt> couchbase: add connect/error events to bucket interface </cmt> <cmt> couchbase: add optional properties for errors </cmt> <cmt> ""code"" was not optional, but it is definitely not included on all errors. </cmt> <cmt> i've added two more properties that i've seen in the couchbase source code. </cmt> <cmt> couchbase: add enough features to get the front-page sample working </cmt> <cmt> the first page of the couchbase documentation contains the code that is now </cmt> <cmt> in couchbase-tests.ts (except that i've left out the underdocumented </cmt> <cmt> cluster.authenticate() call). for this, i've added the index management </cmt> <cmt> methods on the bucket manager interface as well as specific definitions </cmt> <cmt> for the events on the query response interfaces. </cmt> <cmt> couchbase: add authenticator api </cmt> <cmt> it's marked ""uncommitted,"" but it's in the main page sample, so... </cmt> <cmt> couchbase: add the basic full-text search api </cmt> <cmt> needs some fixes to the bucket query call, but that will be fixed here in a </cmt> <cmt> bit. </cmt> <cmt> couchbase: split query api, add searchquery + ftsqueryresponse.meta props </cmt> <cmt> several important fixes. </cmt> <cmt> couchbase: add fts facet and sorting capabilities </cmt> <cmt> couchbase: add more samples, make query callbacks optional </cmt> <cmt> the samples force us to recognize that the query callbacks are optional. </cmt> <cmt> couchbase: add version number and add me </cmt> <cmt> even though this doesn't cover everything in the latest sdk, that's the </cmt> <cmt> version i based my changes on. </cmt>",lots of missing things from v2.4.5 sdk
959,"<desc> these are some minor edits i made when experimenting with the superkoalio file. they do not change any functionality, but i figured i might as well propose them for the master. </desc> <cmt> spelling fixes in comments </cmt> <cmt> use mathutils clamp over manual implementation </cmt> <cmt> remove unused but instantiated vector2 </cmt>",spelling fixes and cleanup in superkoalio test
960,<desc> improved reporting of where the missed slot is when it reports incomplete rounds. added tracking of timestamps on blocks to identify when a slot is missed. this is the release/2.0.x version of #9000 </desc> <cmt> improved reporting of where the missed slot is when it reports incomplete rounds. </cmt> <cmt> added the timeslot time to the failure information. </cmt>,improved reporting in nodeos_forked_chain_lr_test - 2.0.x
961,"<desc> continuation of the work for the fs polyfill in support of #3403. specifically this adds internal implementations of the directory classes used in node and exported by yet to be implemented deno fs polyfill methods fs.opendir(), fs.opendirsync(), or fspromises.opendir(). </desc> <cmt> feat: additional node fs polyfill support for directories </cmt>",continuation of node fs polyfill with directory support
962,"<desc> even if the good opengl version is available, framebuffer support is done as an extension, not in the native opengl. this fix should bind dynamically all the framebuffers methods from the correct arb/ext.  ref: tito@kivy, kivy/kivy@c76fed7 fixing include paths to be able to compile cocos2d-x using external visual studio solution. this way we can have completely separate vs solution containing our project + referencing original cocos2d-x projects, without need to copy all the files. </desc> <cmt> opengl access violation fix </cmt> <cmt> revert ""opengl access violation fix"" </cmt> <cmt> this reverts commit 7eb0e3397d1468e042b75ab4e0d6a2b83206d343. </cmt> <cmt> opengl access violation fix </cmt>",opengp framebuffer access violation fix + fixing include paths
963,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). there's not a lot of documentation on this feature on the website but it works for me in a production site. increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> missing comment </cmt> <cmt> merged upstream </cmt> <cmt> missing comment </cmt> <cmt> merge master </cmt> <cmt> merged </cmt> <cmt> add iteratee property shorthand for uniq in underscore </cmt> <cmt> undo bad commit </cmt> <cmt> can also pass array of array of data to chartist </cmt>",chartist - add another possible series type to ichartistdata
964,"<desc> closes #1136 hopefully everything is okay here, this is my first pr so let me know if not! </desc> <cmt> fixed typos in errors.js </cmt> <cmt> revert ""fixed typos in errors.js"" </cmt> <cmt> this reverts commit 99085af24c0440f9c0d723cfcc560d2cf2e90b85. </cmt> <cmt> fixed typos in errors.js </cmt> <iss> typo in cli error for deps about docker </iss>",fix typos in cli errors.js
965,"<desc> sub pr #7229 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> add constants.java </cmt> <cmt> optimize the constants to the utils package for the client module </cmt>",optimize the constants to the utils package for the client module. part 5
966,<desc> fixes #6579 fixed also aws partition references in few other spotted places. confirmed there's no issues in changes by running all integration tests against pr </desc> <cmt> fix: support differet aws partitions </cmt> <cmt> fix: ensure necessary iam role for handling existing cognito pools </cmt> <cmt> fixes #6579 </cmt>,ensure needed access roles when handling existing cognito pools
967,<desc> this pr converts many but not all of the uses in the codebase. as a result building rust issues a lot of warnings. i didn't have time to fix all those...i'll try to fix more but i thought it made sense to post the pr anyway. </desc> <cmt> declare &foo[] to be obsolete syntax. modify the obsolete mechanism to </cmt> <cmt> support warnings. </cmt> <cmt> replace all uses of &foo[] with &foo[..] en masse. </cmt>,make &foo[] syntax issue a warning (but still work)
968,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> rewrite with es6 modules, update definitions </cmt> <cmt> remove unused dom compile option </cmt> <cmt> remove any from test </cmt> <cmt> add space after header </cmt>","rewrite with es6 modules, update definitions, add missing properties"
969,"<desc> basically, a config constant was not type declared in a way that makes the next typescript compiler happy. this pr aims to fix that by separating the type and the value. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: mholt/papaparse#494 </desc> <cmt> update </cmt> <cmt> update upstream changes </cmt> <cmt> update upstream changes </cmt> <cmt> separate type and value for node_stream_input </cmt> <cmt> add test for node_stream_input </cmt> <cmt> format </cmt>",fix node_stream_input for typescript/next test
970,"<desc> i wanted to start using vscode. it wasn't easy. i wrote some tasks that allow us to build the various flavors of openconsole and windows terminal from one of the tasks. i also wrote a task that allows registration of the loose windows terminal package and a shortcut one to launch it. also it was grinding away at its own intellisense forever because it was indexing obj, bin, packages, etc. i excluded those. things should be easier now for folks in general. i expect we'll make more task types in the future. </desc> <cmt> initial revision of getting f5 to work in vscode. </cmt> <cmt> clean/build/deploy things are working. use attach for debug because appxs are launched in an interesting way. check in the settings so the intellisense doesn't get overeager at reading millions of bin/obj/packages/etc files. </cmt> <cmt> make building a bit more complex with selections, revert openconsole script change to use inbox powershell not pwsh. </cmt>",create settings/tasks definitions for vscode builds and registration
971,"<desc> right now, rnn.compute_output_shape returns the same output shape for all the cell states when return_state=true. however, in a stacked rnn, the states could come from different cells with different number of units. since _keras_shape is set with the output of compute_output_shape (in _add_inbound_node), _keras_shape (and also k.int_shape) will be wrong for these cell state tensors. for example, the following simple seq2seq model will fail before this fix: encoder_in = input((none, 5)) encoder_out, *state = rnn([lstmcell(16), lstmcell(32)], return_state=true)(encoder_in) decoder_in = input((none, 5)) decoder_out = rnn([lstmcell(16), lstmcell(32)])(decoder_in, initial_state=state) because state_spec of the decoder is computed based on incorrect _keras_shapes. valueerror: an initial_state was passed that is not compatible with cell.state_size. received state_spec=[<keras.engine.topology.inputspec object at 0x1225dbeb8>, <keras.engine.topology.inputspec object at 0x1225db7b8>, <keras.engine.topology.inputspec object at 0x1225ea588>, <keras.engine.topology.inputspec object at 0x1225ea4a8>]; however cell.state_size is (32, 32, 16, 16) </desc> <cmt> fix: compute_output_shape for stacked rnn cells with different number of units </cmt> <cmt> test for compute_output_shape </cmt>",fix stacked rnn compute output shape
972,"<desc> test that strings that contain embedded null characters are passed to udf's consolidate ""test param"" tests to reduce the amount of boilerplate code test more error conditions when building udf arguments, and returning udf values handle pyfloat_asdouble() errors </desc> <cmt> test that str params with embedded null chars are passed to sqlite functions </cmt> <cmt> refactor most set param tests </cmt>",expand test suite for sqlite udf's
973,<desc> simplify reference handling and merge two connection object members: remove superfluous pyobject * member isolation_level from connection object (self->begin_statement carries the information we need) introduce get_begin_statement() helper for converting isolation level to begin statement simplify sqlite3.connection.__init__ by using get_begin_statement use ac to remove reference handling for the isolation level parameter </desc> <cmt> remove connection isolation_level </cmt> <cmt> factor out get_begin_statement() </cmt> <cmt> use get_begin_statment() in connection __init__ </cmt> <cmt> clean up </cmt>,simplify isolation_level handling in sqlite3
974,"<desc> this pr offers a fix for pr 16162's problem with causing td3 tests to fail/timeout often. pr 16162 added a sleep to _nextvaluenotready causes td3 tests to become flakey. this pr removes that sleep from the c'tor of _nextvaluenotready, but keeps the sleep in place inside impala's learner_thread such that the original issue should remain fixed. see also this discussions here:  i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip. </cmt> <cmt> wip. </cmt>",having added sleep to _nextvaluenotready causes td3 tests to become flakey.
975,"<desc> after re-reading the changes i made on the last pr, i felt like it needed more elaboration. hopefully, you'll find this more accurate. </desc> <cmt> elaborate more on 2.2 </cmt> <cmt> elaborate more on 2.2 </cmt>",elaborate on 2.2 (use only built-in error object)
976,<desc> this pr develops the tests for tf.data kernel implementations in c++. it designs a test base class and adds the tests for rangedataset and mapdataset. </desc> <cmt> add the test base for tf.data c++ kernels </cmt> <cmt> add the test for rangedataset kernel </cmt> <cmt> add the test for mapdataset kernel </cmt>,add the tests for some tf.data kernels
977,<desc> dtst saves all trace sessions to binary file. the format of binary file is simple serialized sessions. dtsf restores all trace sessions from binary file. </desc> <cmt> add memory diff dump function </cmt> <cmt> add base snapshot dump </cmt> <cmt> add resotring function </cmt> <cmt> fixed some bugs </cmt> <cmt> fixed code format </cmt>,add dtst and dtsf commands for save and restore sessions.
978,"<desc> adds getstringview as a convenience function to get string_view from a string returning an empty string_view on null pointer. </desc> <cmt> added missing endtable() call to verifyobject() </cmt> <cmt> verifyobject called verifytablestart() but not endtable(). this made verifier::verifycomplexity() increase depth_ with each table, not with the depth of tables. </cmt> <cmt>  </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added check to verifyalignment </cmt> <cmt>  </cmt> <cmt> add getstringview (convenience function to get string_view from a string returning an empty string_view on null pointer) like getstring, getcstring </cmt>","add getstringview like getstring, getcstring"
979,"<desc> this speeds up the compilation time of main.swift in the benchmark suite from taking a minute or two to about a second. nfc. starts a string perf test suite called stringtests which is off-by-default, but allows us to place some lower-level targeted benchmarking. </desc> <cmt> [benchmark] speed up compilation time of suite </cmt> <cmt> this speeds up the compilation time of main.swift in the benchmark </cmt> <cmt> suite from taking a minute or two to about a second. nfc. </cmt> <cmt> [benchmark] add string test suite (off by default) </cmt> <cmt> starts a string perf test suite called stringtests which is </cmt> <cmt> off-by-default, but allows us to place some lower-level targeted </cmt> <cmt> benchmarking. </cmt>",speed up compilation time; add string benchmarks
980,"<desc> cherry-pick from master roll crbug:  npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> disable calculatenativewinocclusion on win ci </cmt> <cmt> update appveyor.yml </cmt>",fix visibility tests on windows
981,"<desc> fix dependencies in benchmarks fix a wrong library search directory order when building swift-frontend with bootstrapping rdar://85911944 </desc> <cmt> cmake: fix dependencies in benchmarks </cmt> <cmt> with libswift the compiler invocation also depends on the core libraries, because the compiler executable needs them. </cmt> <cmt> rdar://85911944 </cmt> <cmt> cmake: fix a wrong library search directory order when building swift-frontend with bootstrapping </cmt>",fix two bootstrapping related problems
982,"<desc> @renne optional compiler directives added to support output function of mcp23008/mcp23017 using sensor29 command. need to add defines to user_config.h //    #define use_mcp230xx_output // enable mcp23008/mcp23017 output support through sensor29 commands (+1k code) //    #define use_mcp230xx_displayoutput // enable mcp23008/mcp23017 to display state of output pins on web ui (+0k2 code) sensor29 commands are extended as follows: sensor29 pin,pinmode,pullup pin = pin number of mcp device (0 to 7 for mcp23008 and 0 to 15 for mcp23017) pinmode = 5 for output (1 through 4 already documented in wiki) pullup = 0 default to low on power-up/reset pullup = 1 default to high on power-up/reset if save_state (setoption0 == 1) is enabled, then pull-up is ignored during reset/power-up and last known state will apply once pin is in pinmode 5 the followng commands turn pin on and off sensor29 pin,on    // turn pin on sensor29 pin,off   // turn pin off sensor29 pin,t     // toggle current state of pin </desc> <cmt> mcp23008/mcp23017 - extend sensor29 command to enable output </cmt> <cmt> mcp23008/mcp23017 - extend sensor29 command to enable output </cmt> <cmt> add mcp230xx_output and use_mcp230xx_displayoutput to user_config.h </cmt>",mcp23008/mcp23017 - extend sensor29 command to support output
983,<desc> add eps for roi_perspective_transform op avoid dividing zero. </desc> <cmt> track_official_repo </cmt> <cmt> track offical update </cmt> <cmt> push before pull </cmt> <cmt> pull before pr </cmt> <cmt> pull before push </cmt> <cmt> pull before push </cmt> <cmt> pull before push </cmt> <cmt> pull before push </cmt> <cmt> pull before push </cmt> <cmt> pull before push </cmt> <cmt> pull before pr. </cmt> <cmt> pull before pr </cmt> <cmt> pull before pr </cmt> <cmt> pull before pr </cmt> <cmt> fix_roi_transform_bug </cmt>,fix roi_perspective_transform op dividing zero bug
984,"<desc> this pr adds logic to check whether a credential file exists and if we are in headless mode, it will skip the ""activation"" phase. added unit tests in the cli_test </desc> <cmt> do not create credential file in headless mode </cmt> <cmt> linter </cmt>",do not automatically create credential file when in headless mode (#467)
985,"<desc> currently, the runtime isn't reset following a redirect or a send_file, so any time taken to process those actions is added to the time for the subsequent request. </desc> <cmt> escape regex in controller_runtime_test to actually check that the activerecord message appears </cmt> <cmt> reset activerecord::logsubscriber runtime at the start of each request </cmt> <cmt> previously the runtime was reset implicitly when #cleanup_view_runtime was called at the end of most requests. however, this doesn't happen when the request redirects, or send_file is called.  consequently, the activerecord runtime recorded in the logs included the time taken for both the current request and the previous redirect.  explicitly resetting at the start of each request ensures that this can't happen, no matter what occurs previously. </cmt>",activerecord::logsubscriber.runtime should be reset at the start of each request
986,"<desc> the kubelet always clears reason and message in generateapipodstatus even when the phase is unchanged. it is reasonable that we preserve the previous values when the phase does not change, and clear it when the phase does change. when a pod is evicted, this ensures that the eviction message and reason are propagated even in the face of subsequent updates. it also preserves the message and reason if components beyond the kubelet choose to set that value.  if reason/message are changed (due to preemption -> eviction) the most recent value is preserved. to preserve the value we need to know the old phase, which requires a change to convertstatustoapistatus so that both methods have access to it. fixes #103623 the reason and message fields for pod status are no longer reset unless the phase also changes. </desc> <cmt> kubelet: preserve reason/message when phase changes </cmt> <cmt> the kubelet always clears reason and message in generateapipodstatus </cmt> <cmt> even when the phase is unchanged. it is reasonable that we preserve </cmt> <cmt> the previous values when the phase does not change, and clear it </cmt> <cmt> when the phase does change. </cmt> <cmt> when a pod is evicted, this ensurse that the eviction message and </cmt> <cmt> reason are propagated even in the face of subsequent updates. it also </cmt> <cmt> preserves the message and reason if components beyond the kubelet </cmt> <cmt> choose to set that value. </cmt> <cmt> to preserve the value we need to know the old phase, which requires </cmt> <cmt> a change to convertstatustoapistatus so that both methods have </cmt> <cmt> access to it. </cmt> <cmt> kubelet: avoid allocating multiple times during status </cmt> <cmt> noticed while reviewing this code path. we can assume the </cmt> <cmt> temporary slice should be about the same size as it was previously. </cmt> <cmt> kubelet: make condition processing in one spot </cmt> <cmt> the list of status conditions should be calculated all together, </cmt> <cmt> this made review more complex. readability only. </cmt> <iss> [failing test] [sig-node] inodeeviction [slow] [serial] [disruptive][nodefeature:eviction] when we run containers that should cause diskpressure should eventually evict all of the correct pods </iss>",ensure that reason and message are preserved on pod status
987,"<desc> also contains some cleanup and doc comment additions so i could make sense of the code. fixes #73109 closes #73175 r? @matthewjasper </desc> <cmt> improve instance docs </cmt> <cmt> validator: print mir instance on failure </cmt> <cmt> remove adjustment::derefmove </cmt> <cmt> it does the same thing as deref now </cmt> <cmt> shim.rs: improve docs a bit </cmt> <cmt> shim.rs: call fnptr, not self </cmt> <cmt> the call terminator only works with fndef and fnptr types. </cmt> <cmt> it happened to work with self so far because it was always </cmt> <cmt> substituted with the real type before being used. </cmt> <iss> ice: -zvalidate-mir: broken mir in libcore </iss>",avoid creating call terminators calling self
988,"<desc> also fixed the issue of ( </desc> <cmt> issue #1712: adding getting dpi support for ios and android. </cmt> <cmt> issue #1712: adding win32 support. </cmt> <cmt> issue #1712: moved ccdevice.cpp to platform/win32. </cmt> <cmt> issue #1712: getting dpi support for blackberry. </cmt> <cmt> issue #1712: updating project setting for blackberry. </cmt> <cmt> issue #1712: adding empty ccdevice.cpp for linux, mac and marmalade. </cmt> <cmt> issue #1712: getting dpi support for linux. </cmt> <cmt> fixed #1712: adding default dpi for marmalade and mac since i don't know how to get dpi for these platforms. </cmt>","adding a class named ""ccdevice"" and getting dpi suport for android, ios, win32, linux, blackberry."
989,<desc> json-iterator indented encoding was not stdlib-compatible for objects with custom marshaljson implementations. this pr switches to use the json stdlib for pretty-printing json encoding as preparation for moving off of json-iterator. hoisted from #105030 for early review/merge apimachinery: pretty-printed json and yaml output is now indented consistently / /sig api-machinery </desc> <cmt> use stdlib json encoder for yaml and pretty-json marshaling </cmt> <cmt> fix pretty-printed fixtures </cmt> <cmt> compact pretty-printed compatibility fixtures when decoding </cmt>,use json stdlib for pretty-printer encoding
990,"<desc> adds a per-profile setting for setting the audio sound for the bell. the setting is bellsound, it accepts a path. we'll use the file at that path as the sound for the bell. if it doesn't exist, then oh well, so sound for you. it'll also secretly accept an array of paths. if you provide an array, it will pick one at random. closes #8366 i work here tests - lol this is the hackathon, i'm just messing around requires documentation to be updated i'm not suggesting that anyone go to this post and download a zip full of honk.mp3s. i'm definitely not suggesting you add it to your settings like ""bellsound"": [ ""c:\\users\\migrie\\downloads\\memes\\honks\\honk1.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk2.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk3.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk4.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk-muffled1.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk-muffled2.mp3"", ""c:\\users\\migrie\\downloads\\memes\\honks\\honk-muffled3.mp3"" no, don't do that. honk-001.mp4 it surprisingly works elevated we should probably accept env vars in these paths we may only want one mediaplayer per terminal, rather than one per pane we may want to validate the paths, and discard ones that don't exist. alternatively, meh </desc> <cmt> it honks </cmt> <cmt> many honks </cmt> <cmt> oh yea, it was that easy </cmt> <cmt> allow a single item as a list with length 1 </cmt> <iss> specify an audio file for the audible bell </iss>",enable changing the bell sound
991,"<desc> hi, from the feedback of my beta testers i made these changes to exasol: *) new object type connections is now supported *) added ""visibleif"" checks to verify the user has sufficient privileges to access the meta tables for users, connections and roles objects. *) reformat source using dbeaver formatter kind regards karl </desc> <cmt> new con object; users only show if sufficient privs </cmt> <cmt> added connection object and added fields to user object </cmt>",new database object connection and privilege checks added
992,<desc> fixes #6017 microsoft reviewers: open in codeflow </desc> <cmt> make alert track its xamlroot's size changes </cmt> <cmt> change files </cmt> <iss> resizing window when alert's contentdialog is open breaks focus trap zone and overlay (xaml islands only) </iss>,alert should track its xamlroot's size
993,"<desc> implement time_parse(<time_str>, <pattern_str>) function which allows to parse a time string according to the specified pattern into a time object. the patterns allowed are those of java.time.format.datetimeformatter. supersedes: #55095 closes #54963 </desc> <cmt> issue #37303 - invalid variance fix </cmt> <cmt> testcase added for #37303 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> sql: implementing time_parse function for parsing strings </cmt> <cmt> review comments fixes </cmt> <cmt> localtime to offsettime </cmt> <cmt> added docs for time_parse </cmt> <iss> sql: implement time_parse </iss>",implement time_parse function for parsing strings into time values
994,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. </desc> <cmt> translate task #1 - #4 </cmt> <cmt> add translation of zhang-suen-thinning and markov algorithm </cmt>",translated some chinese curriculum files
995,"<desc> fixes: #1616 this issue is caused when we insert a value into the array, it will try to calculate an offset this way we can maintain focus when we add/remove elements. i've found a  test where checking for olddom effectively fails focus so this is not the way to go. seems like removing the focuselement is having some side-effects :/ a more effective approach would be to see if the node we are comparing to has an old version or not. <-- this is also faulty.... removed my fix since it introduced a faulty scenario in the new focus test i added. we'll need a more reliable way to check for offsets (which is hard with checking on .type) or reintroduce .focuselement. the only thing that could fix it in both scenario's according to me is when we could say hey this element is a new one (inserted). that way we could say olddom for this new element is null. this is because the algo notices we have an offset but doesn't know where so it starts looking for the first type match and sets the olddom to that (which didn't used to work like that) but now it does.... the full erroneous scenario is as follows: we render our ui correctly we add an element on position 1 of the array while diffchildren when we arrive at our last button we notice that there is no corresponding child we loop over the children button1 is now on position 2 (where button 2 was) they are equal on type button button2 is now on position 3 (where button 3 was) they are equal on type button button3 is now on position 4 (empty), this loops over the array to find the first button occurrence which in this case is button1. this will trigger the olddom setting since oldchild.type won't be a button and thus make button3 use the olddom of button1 switching their position wondering if it's better to revisit the focus approach where when inserting it constructed an erroneous parentvdom.childnodes. in the end it all boils down to offsets being hard to manage without keys. </desc> <cmt> tests: add big test for multiple scenarios </cmt> <cmt> feat: don't compare when there is no olddom present </cmt> <iss> position of last child changes on state change </iss>",- don't compare when oldvnode has no dom
996,"<desc> fixes to the visibility of views move container to workspace <name> rewrote workspace{,_output}_{prev,next} and patched that into workspace_by_name so it works with the move command </desc> <cmt> refactored workspace_next/prev </cmt> <cmt> refactored view visibility </cmt> <cmt> - replace visibilty mask integers with an enum </cmt> <cmt> - set output's visibilty mask on creation </cmt> <cmt> - added update_visibility to manually update a containers visibility (e.g. when it moved to an invisible workspace) </cmt> <cmt> added ""move container to workspace"" </cmt> <cmt> makes the previous commit actually testable </cmt> <cmt> changed workspace_{outout_,}{next,prev} to return workspace </cmt> <cmt> so it can be reused for ""move container to workspace next"" </cmt>","implemented ""move container to workspace"""
997,"<desc> a while ago i submitted a pr to make vertical centering of the arrows dynamic to the arrow height, using transform translate. since ie8 doesn't support transforms, i thought i'd include the old fixed position offset using margin top, but use the \9 hack on the value to make it only apply to ie8. i guess there was an issue with gulp, and a pr to remove the \9 merged, causing the offset to register with all browsers, and making the arrows slightly off center. the gulp issue is curious to me, because bootstrap uses the \9 method, but i also appreciate that \9 is a clumsy trick, and my feeling is that if someone is using ie8 they can suffer a slightly off center arrow, in the interest of modernity and simplicity as such, i removed the fallback in this pr. </desc> <cmt> removed style for ie8 fallback </cmt> <cmt> removed style for ie8 fallback </cmt> <cmt> removed style for ie8 fallback </cmt>",correct issue with vertically centering arrow
998,<desc> added docker ee specific fixes/work arounds so that the moby integration tests can be used against it. </desc> <cmt> match not implemented error check to others </cmt> <cmt> protect environment for system integration tests </cmt> <cmt> do not use deprecated call for apiclient </cmt>,docker ee integration test fixes
999,<desc> description: starling bank are switching to v2 of their api. this pr updates the home assistant integration to use the new api. non-breaking change. no documentation update required. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> bump starlingbank to v2 api </cmt> <cmt> fixed incorrect call </cmt>,update starling bank integration to v2 api
1000,"<desc> closes #19705, closes #20084. pushes scipy minimum version to 1.1.0. pushes numpy minimum version to 1.14.5. pushes matplotlib minimum version to 2.2.2 for compatibility with python3.7 drop 3.6 builds. configure azure builds to run on ubuntu focal 20.04 lts. adds one bionic 18.04 lts azure build with scipy from conda-forge and python 3.7 move the linux 32bit build from ubuntu to debian 10 as debian still support 32bit and is distributed with python 3.7. before i start fixing the version conflicts, please, let me know if the defined set of builds fits your requirements. thanks. maybe ping ... @ogrisel , @thomasjpfan , @rth ? </desc> <cmt> push scipy min version to 1.0.0 </cmt> <cmt> update all ubuntu images to 20.04 focal. </cmt> <cmt> add ubuntu images 18.04 bionic and scipy fron conda-forge. </cmt> <cmt> fix conditions. </cmt> <cmt> pin python 3.6 for ubuntu bionic. </cmt> <cmt> change pipeline name. </cmt> <iss> [rfc] minimal scipy version for 1.0 (or 0.26) release </iss> <iss> drop python 3.6 support for 1.0 </iss>",ci push scipy minimum version to 1.1.0. remove python 3.6 from builds.
1001,"<desc> for 1/2 the plugins in x-pack, the integtest task is now a no-op and all of the tests are now executed via a test, yamlresttest, javaresttest, or internalclustertest. this includes the following projects: security, spatial, stack, transform, vecotrs, voting-only-node, and watcher. a few of the more specialized qa projects within these plugins have not been changed with this pr due to additional complexity which should be addressed separately. related: #60630 related: #56841 related: #59939 related: #55896 </desc> <cmt> most of security </cmt> <cmt> security internalcluster </cmt> <cmt> finish up security </cmt> <cmt> security:qa </cmt> <cmt> spatial </cmt> <cmt> stack </cmt> <cmt> transform </cmt> <cmt> vectors </cmt> <cmt> voting-only-node </cmt> <cmt> watcher - internalclustertest </cmt> <cmt> watcher qa </cmt>",convert second 1/2 x-pack plugins from integtest to [yaml | java]resttest or internalclustertest
1002,"<desc> ultimately, this is caused by the sway_abort that does not exit in this case. it calls wlc_terminate, which itself does not exit if there is not current display. added some very minor fix here and there while browsing through the code ; they each have their separate commit. </desc> <cmt> removed p as a valid cli option </cmt> <cmt> the get-socketpath long option had an undocumented short alternative </cmt> <cmt> as p. it has been removed. </cmt> <cmt> however, the code in the options array is still the 'p' char. </cmt> <cmt> no options when using sway as ipc client </cmt> <cmt> sway used to attempt sending an ipc command composed of every argument </cmt> <cmt> after the first non-option argument encountered. </cmt> <cmt> now, raises an error if an option is encountered before the intended command. </cmt> <cmt> some options such as -h or -v take effect when parsing, so they still </cmt> <cmt> apply. </cmt> <cmt> fixed swaymsg command name in sway(5) doc </cmt>",fix segfault when trying to use sway as ipc without a sway instance
1003,<desc> added a sentence for clarity on sorted union bonfire. (the previous commit is simply me updating my local copy to match the master here.) </desc> <cmt> updated description for sorted union bonfire for clarity. </cmt> <cmt> updating local branch. </cmt>,update description on union sort bonfire challenge for clarity
1004,<desc> fix #24208 offset option can be function (popper.js) add support for calculate and dynamically change offset position for dropdown menu. function call always when call popper.js modifierfn. with this code i can change any dropdown position as on picture const dropdownmegatoggle = $('.dropdown-toggle--mega'); dropdownmegatoggle.dropdown({ offset: function(data) { let popper = data.popper; let reference = data.reference; let w = $(window).width(); let buttonoffset = dropdownmegatoggle.offset(); popper.top = 100; reference.width = w / 2; // f*cking popper.js crutch popper.left = w / 2 - popper.width / 2 - buttonoffset.left; return data } }); fix : #24223 </desc> <cmt> offset option can be function (popper.js) </cmt> <cmt> fix...add function type for offset option </cmt>,offset option for dropdown can be function
1005,"<desc> arguments for tasks that are ready to dispatch can get evicted before the task gets dispatched to a worker. this pr moves these tasks back to the waiting queue. it also adds an index for the dispatch tasks to speed up lookup when there are many tasks queued. this pr modifies the clustertaskmanager class to call directly into the taskdependencymanager to wait for/cancel task dependencies. this is so that the clustertaskmanager can cancel the task dependencies once the task is dispatched (or removed), instead of canceling the first time that the arguments become ready. fixes some new flakiness in test_array. i noticed that the test still fails with a mysterious objectlosterror, but this other error also seemed to show up when the new scheduler is disabled. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add index for tasks to dispatch </cmt> <cmt> task dependency manager interface </cmt> <cmt> unsubscribe dependencies and tests </cmt> <cmt> nodemanager </cmt>",move tasks from ready to dispatch to waiting on argument eviction
1006,"<desc> description: this pr adds support for recording history to an apache kafka topic. related issue (if applicable): home-assistant/home-assistant.io#9836 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): apache_kafka: ip_address: localhost port: 9092 topic: home_assistant_1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. </desc> <cmt> add support for apache kafka </cmt> <cmt> simplified </cmt> <cmt> revert ""simplified"" </cmt> <cmt> this reverts commit fde4624e07a44edcaa728666777e7cfd789d68f6. </cmt> <cmt> revert ""revert ""simplified"""" </cmt> <cmt> this reverts commit 5ae57e64c29f9e1cdbba6545420f4c2003d664e2. </cmt> <cmt> completed </cmt> <cmt> updated requirements </cmt> <cmt> updated .coveragerc </cmt>",add support for recording history to apache kafka
1007,"<desc> this pr changes the type key and type shortcut behavior to hold enter to accept instead of hold and release, so that it is consistent with the esc behavior. it was also observed that in tab ordering for remap keyboard and remap shortcuts windows the cancel key would get highlighted before ok which is not in the left to right order, so that has been swapped. pr checklist applies to #2661 (closes #2661) cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments the onaccept lambda was split into two parts, onpress and onrelease in onpress we perform all the accept logic followed by detectkeybox.hide() but we do not perform the resetuistate and unregisterkeys() the resetting of ui state along with disabling the key delay handler is done in onrelease. because of this, we stop swallowing input only when enter key is released, and this allows us to avoid the issue where pressing enter triggers the type key button again. onpress is performed in case of the long press delay handler (along with the primary button color change even though that would appear for just a few milliseconds but the user can notice it) onrelease is performed in case of the key release delay handler so that when user lets go of enter key everything in the kbm state is cleared up we define onaccept as onpress followed by onrelease so that primary button click behavior remains unchanged validation steps performed used ok and cancel options from the type key/shortcut screen by clicking with mouse and also using hold enter and hold esc. </desc> <cmt> changed to hold enter </cmt> <cmt> changed code such that hold enter does not trigger a re-open </cmt> <cmt> fixed tab ordering </cmt> <iss> [kbm] hold enter and hold esc to dismiss should be consistent with each other </iss>",kbm - change behavior to hold enter to accept rather than hold and release
1008,"<desc> hashes the deployment names in the cluster snapshot.  this is necessary because the cluster snapshot automatically converts all keys to camelcase, which can lead to collisions for consumers of a snapshot if two deployments have different names which map to the same name when converted to camel case (e.g. my_deployment, my_deployment and mydeployment). previously, for an unversioned deployment, the internal version hash was being exposed in the actor metadata.  this pr changes it to say ""unversioned"" in this case. closes #17870. closes #17872 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> show ""unversioned"" in actor metadata </cmt> <cmt> hash deployment names </cmt> <cmt> update test </cmt> <iss> [serve] deployment names converted to camel case in cluster snapshot </iss> <iss> [serve] [dashboard] snapshot exposes internal hash of unversioned actor's version number </iss>",fix formatting bugs in cluster snapshot
1009,"<desc> the module only checks for existance of the database when dropping. added a check also when creating a database. more importantly, added the ability to change the owner if the database exists but is not the same as the owner specified. </desc> <cmt> check for database ownership </cmt> <cmt> bugfix in sql query </cmt>",allow change of ownership and checks for existing database
1010,<desc> add a possibility to add a start search index in array.find(). also adds a rfind function to search backwards in the array (this mimics the string.rfind() function). closes #5020. </desc> <cmt> add 'from' argument to array.find() </cmt> <cmt> add 'rfind' function to array </cmt> <cmt> add documentation for array.find and array.rfind </cmt>,"add array.find(what, from) and array.rfind(what, from)"
1011,"<desc> this should add support for the ssh+git:// and git+ssh:// protocol schemes. the behavior is to pass directly through to the ssh:// protocol scheme. so, as atrocious as this is, this is a protocol that people use. from everything i can tell, they're both functionally identical to ssh:// and are treated as such in this pr. here is an example of it being used in the linux kernel git core </desc> <cmt> updating http parser to accept a + in the schema </cmt> <cmt> handle git+ssh:// and ssh+git:// protocols support </cmt>",support for ssh+git and git+ssh protocols
1012,"<desc> this pr makes backends take in a starlette request instead of a flask request.  for the servehandle api, serverequest has been modified to match starlette request instead of flask request.  all docs and code samples have been updated. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> support starlette request in web request </cmt> <cmt> add long string to test </cmt> <cmt> lint </cmt> <cmt> lint </cmt> <cmt> clean up prints </cmt> <cmt> lint </cmt> <iss> [serve] support starlette request type </iss>",migrate from flask.request to starlette request
1013,<desc> add a o(n^2) and a o(n*log(n)) solution for the problem. </desc> <cmt> add longest increasing subsequence solution in c++ </cmt> <cmt> add more efficient solution to longest increasing subsequence problem in c++ </cmt>,add longest increasing subsequence in c++
1014,<desc> @rocketchat/core the latest release 0.63 made a change that made all contextual bars to be scrolling with the button instead of the button being a sticky. this was suppose to be a fix to user info tab. reverted the style changes in contextual-bar.css file and fixed user info tab with a wrapper. </desc> <cmt> revert contextual bar style </cmt> <cmt> fix user info with a wrapper </cmt>,button on user info contextual bar scrolling with the content
1015,"<desc> allowing for the lack of a function row, and the addition of some keys in the center, this layout approximates the default qwerty keyboard layout of kinesis's line of advantage keyboards. the main difference between this and the default is the remapping of most of the thumb keys. </desc> <cmt> added keymap variant to approximate kin adv </cmt> <cmt> moving around modifiers to match ka better </cmt>",keymap to approximate kinesis advantage line of keyboards
1016,"<desc> drupal's json:api module supports includes, a method for including relationships data. this pr adds very simple and basic support for creating gatsby data out of the data in the included property of the json:api result. this way only data that is used is included in gatsby, without having to fetch all data for a certain resource type. see #21379 for the full motivation. updated documentation in the readme.md of the gatsby-source-drupal plugin. addresses #21379 </desc> <cmt> add support for drupal json:api includes. </cmt> <cmt> update readme with info about includes support. </cmt>",add drupal json:api includes support
1017,"<desc> add inlinecollapsed={true|false} prop for menu, handle icon size, text display and submenu inside menu, and auto tooltip for menu item. use context to pass collapsed prop from layout.sider to menu. don't need customized css code anymore. close #6484 </desc> <cmt> add menu[inlinecollapsed] prop </cmt> <cmt> inline menu should not trigger handleclick </cmt> <cmt> add tooltip for collapsed menu item </cmt> <cmt> add documentation for inlinecollapsed </cmt> <cmt> menu will get collapsed status from layout.sider </cmt>",better collapsed sider and menu
1018,<desc> bael-1265: using lambdas instead of anonymous classes </desc> <cmt> code for test article: different types of bean injection in spring </cmt> <cmt> adding junits for test article: different types of bean injection in spring </cmt> <cmt> bael-1265: adding junit for article </cmt> <cmt> bael-1265: closing executorservice in junit </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> bael-1265: using lambdas instead of anonymous classes </cmt>,radutamas/bael 1265 update junit with lambdas
1019,<desc> fixes #1491 this pr and #1456 both provide datasets for sentiment analysis. but seems both good. </desc> <cmt> add early draft of imdb.py and unit test </cmt> <cmt> add imdb_test.py </cmt> <cmt> add imdb and unit test </cmt>,add imdb dataset without need of nltk
1020,"<desc> this pr is an alternative to #23903. it bumps the existing copyright headers as we did every year, and adds the missed copyright headers. a small fix has been applied to the copyright_header.py in order to prevent such weird bumping as 2021 --> 2021-2017. </desc> <cmt> script: fix copyright_header.py </cmt> <cmt> this change prevents updating copyright years from ""2021"" to </cmt> <cmt> ""2021-2017"". </cmt> <cmt> scripted-diff: bump copyright headers </cmt> <cmt> -begin verify script- </cmt> <cmt> ./contrib/devtools/copyright_header.py update ./ </cmt> <cmt> -end verify script- </cmt> <cmt> commits of previous years: </cmt> <cmt> * 2020: fa0074e2d82928016a43ca408717154a1c70a4db </cmt> <cmt> * 2019: aaaaad6ac95b402fe18d019d67897ced6b316ee0 </cmt> <cmt> scripted-diff: insert missed copyright headers </cmt> <cmt> -begin verify script- </cmt> <cmt> ./contrib/devtools/copyright_header.py insert contrib/guix/libexec/build.sh </cmt> <cmt> ./contrib/devtools/copyright_header.py insert contrib/guix/libexec/codesign.sh </cmt> <cmt> ./contrib/devtools/copyright_header.py insert contrib/tracing/log_raw_p2p_msgs.py </cmt> <cmt> ./contrib/devtools/copyright_header.py insert contrib/tracing/log_utxocache_flush.py </cmt> <cmt> ./contrib/devtools/copyright_header.py insert contrib/tracing/p2p_monitor.py </cmt> <cmt> ./contrib/devtools/copyright_header.py insert test/lint/lint-files.sh </cmt> <cmt> -end verify script- </cmt>",insert and bump copyright headers
1021,"<desc> closes #34966 tests added / passed (all tests passed except those which were auto-cancelled for taking too long) ensure all linting tests pass, see here for how to run them whatsnew entry allows default resolvers to be used with input resolvers in pandas.dataframe.eval. previously cases such as this would break: import pandas as pd df = pd.dataframe({'a':[0,1,2], 'b':[7,8,9]}) d = {'c': 5} df.eval('a+b*c', resolvers=[d]) with pandas.core.computation.ops.undefinedvariableerror: name 'a' is not defined as explained in #34966. following this update, the above works as expected. added a test similar to the above: tests.frame.test_query_eval.testdataframeeval.test_eval_resolvers_combined </desc> <cmt> bug: default+input resolvers in df.eval, gh34966 </cmt> <cmt> allow default resolvers to be used with input resolvers in dataframe.eval. resolves gh34966 </cmt> <cmt> add whatsnew entry </cmt> <iss> doc: confusing 'resolvers' kwarg documentation for dataframe.query() </iss>","allow use of both default+input resolvers in df.eval, gh34966"
1022,"<desc> this adds the ability to enable, disable and toggle the state of the combo feature without having to recompile if want to disable the feature. this makes it useful, if you have modes where combos are actually in the way (such as when gaming). thread on reddit my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add ability to enable/disable combos </cmt> <cmt> update documentation for combo feature </cmt>",allow combo feature to be enabled/disabled live
1023,<desc> updated this comparison doc to account for asp.net core 3.0 preview 4.    the compare doc uses an include called benefits.md which was also updated.  minor updates overall. current published version of this doc: </desc> <cmt> updated to v3 preview 4 for core + framework comparison </cmt> <cmt> update to v3 preview 4 for core + framework compare </cmt>,v3 preview 4 update to core vs 4.x compare
1024,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: new component pr include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> added props for upsell </cmt> <cmt> removed patch version </cmt>",update gestalt types to be in sync with 14.28
1025,"<desc> please refer to the individual commit messages for additional details. </desc> <cmt> [messagehandler] convert the deletestreamcontroller helper function to a ""private"" method instead </cmt> <cmt> [messagehandler] add a non-production/testing check to ensure that wrapreason is called with a valid reason </cmt> <cmt> there shouldn't be any situation where reason isn't either an error, or a cloned ""error"" sent via postmessage. </cmt>",some additional (small) clean-up of the code
1026,"<desc> two charts (timeseries table and mixed timeseries (via echarts)) do not currently have advanced analytics, but were tagged as though they do. this pr removes the tag for timeseries table in two spots - in the repo (why is this even here?) and in the superset-ui plugin (why is this not the one we're using?). it also removes it from the relevant part of the echarts plugin. brings in the 0.17.83 release for this change. before: after: go to the viz gallery, select the advanced analytics tag, and make sure these two don't show up. includes db migration (follow approval process in sip-59) </desc> <cmt> removing aa tag from timetablechartplugin </cmt> <cmt> package bump for echarts (removes aa tag there) </cmt> <cmt> package-lock bump for new echarts plugin </cmt>",remove advanced analytics tag for 2 charts
1027,"<desc> follow-up on #37577 (comment) restricted indices (currently only .security-6 and .security) are special internal indices that require setting the allow_restricted_indices flag on every index permission that covers them. if this flag is false (default) the permission will not cover these and actions against them will not be authorized. however, the monitoring apis were the only exception to this rule. this exception is herein forfeited and index monitoring privileges have to be granted explicitly, using the allow_restricted_indices flag on the permission, as is the case for any other index privilege. </desc> <cmt> w00p w00p </cmt> <cmt> test monitoring on restricted indices for monitoring collector </cmt> <cmt> breaking change note </cmt>",remove implicit index monitor privilege
1028,"<desc> currently numbers in <label> et. al. are interpreted as localized string lookups.  this means if the skinner actually wants a number in a label they have to do complicated stuff. this is a workaround until we remove the number interpretation and force use of $localize[] post-gotham.  with refactored code it's a 2-liner, so not exactly a maintenance burden. </desc> <cmt> [info] factor out parsing of [] so it can be used to parse other strings </cmt> <cmt> [info] [] parsing can use the new replacestring() function </cmt> <cmt> [info] adds [] to info labels, allowing skinners to specify a number. required as by default numbers are taken as a reference into localized strings.  in future, this will be dropped in favour of [] only being used as this will benefit translation </cmt>",allow use of $number[] to specify a number in xml tags
1029,"<desc> description: now that we take tags as a vector of statname pairs, change the other args to also pass via statname. this will reduce redundant converstions between string and statname and also reduce acquisition of the symbol table lock. risk level: low testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> initial commit </cmt> <cmt> format and fix empty metricimpl constructor. </cmt> <cmt> encapsulate encoding of default-constructed statname. </cmt> <cmt> rename member var for consistency </cmt>",cleanup apis and avoid extra conversions between statname and string.
1030,"<desc> fixes: #8673 when the inferred path already exists, throw generic error to provide better error message. </desc> <cmt> throw an error if the inferred output path already exists. </cmt> <cmt> simplify file exists check </cmt> <iss> deno 1.6 compile getting error: is a directory (os error 21) </iss>",throw error when the inferred output path already exists during compile
1031,<desc> simpler and more straight forward code for computing the arg_list string. improve appearance of __new__ in help(). </desc> <cmt> cleaner way to build the arg list with a trailing comma when required </cmt> <cmt> fix appearance of __new__ in help() </cmt>,minor improvement to the namedtuple implementation
1032,"<desc> we have had a plyicon native viewmanager for awhile but no ts wrapper for using it. we've run into cases where multiple repos are registering the native component but only 1 can do it.  having the wrapper lets us centralize that. while adding an example showing how to use this with the emoji font i found that emsize is kind of needed there but wasn't in how we use it internally, so i added that as something optional that can be set, and refactored iconviewmanager to use a shadownode. in the future we can rename iconviewmanager to glyphviewmanager and move around folders and names but until we have a strategy for non-lean core stuff i'm leaving it where it is. microsoft reviewers: open in codeflow </desc> <cmt> conver iconviewmanager to use shadownode, add emsize prop </cmt> <cmt> add glyph helper component </cmt>",add <glyph> component and example
1033,"<desc> original pull-request #32584 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix </cmt> <cmt> rabbitmq fix </cmt>",cherry pick #32584 to 21.12: rabbitmq fix
1034,"<desc> make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, ""[airflow-xxx] my airflow pr""  here are some details about my pr, including screenshots of any ui changes: support (exclusively) official slack library v2. retain existing functionality and interface slightly change structure (eg remove some properties) remove a redundant check that was made in both hook and operator this pr addresses issue #8433 tests.operators.test_slack_operator tests.hooks.test_slack_hook.slackhooktestcase commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 </desc> <cmt> add support for slackclient v2 </cmt> <cmt> code style </cmt> <cmt> update tests </cmt> <cmt> update tests </cmt>",update slack operator to support slackclient v2
1035,<desc> this pr adds support for the organization feature at auth0 so that people using typescript can use it in a type-safe way. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add types for auth0 organizations </cmt> <cmt> add tests </cmt> <cmt> fix typescript issues </cmt> <cmt> rename types to explicitly mention organizations </cmt> <cmt> update formatting </cmt> <cmt> bump version </cmt>,add support for organizations in auth0
1036,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> added ecore types. </cmt> <cmt> little fix. </cmt> <cmt> little marks. </cmt> <cmt> fixed default export. </cmt> <cmt> import/export marks. </cmt> <cmt> fixed default export. </cmt> <cmt> marks. </cmt> <cmt> test. </cmt> <cmt> test. </cmt> <cmt> -deleted wrong def econtent in eobject </cmt> <cmt> -marks in epackage and epackageregistry </cmt> <cmt> interface resource, parse, second parameter 'loader' has to be optional. </cmt>","marks for interface resource, parse method."
1037,"<desc> this pr adds support to the stable/mongodb chart to be deployed as a replica set configuring primary, secondary and arbiter nodes. other changes: when deploying in replica-set mode, it uses stateful-sets with headless-svc and volumeclaimtemplates for persistence. when using replica-set mode, pod-disruption-budgets are configurable too it allows to overwrite the default config file with a config map replica set parameters are configurable through values.yaml two values.yaml availables, values.yaml and values-production.yaml please do not merge until i say the contrary as i need to make publish the new version of the docker image. </desc> <cmt> refactor mongodb chart to support replica set </cmt> <cmt> update pullpolicy </cmt>",refactor mongodb chart to support replica set configurations
1038,"<desc> updated stop-only to the version that only finds describe.only, context.only and it.only and does not find "".only"" in comments add npm run warn-only precommit and npm run stop-only prepush </desc> <cmt> chore: upgrade stop-only and catch them </cmt> <cmt> run stop-only first on precommit </cmt> <cmt> just warn on precommit .only </cmt> <cmt> testing </cmt> <cmt> testing done </cmt> <cmt> run stop-only on git prepush hook </cmt>",update stop only and catch em
1039,"<desc> since many widget classes use sprite & scale9sprite at the same time, when the user change scale9enabled properties, we removed the previous added sprites and re-added them again. now the ui::scale9sprite supports setscale9enabled method, so i changed the old implementation. in this pr, i also had fixed some minor bugs of ui::scale9sprite and added the tests </desc> <cmt> refactor getscale9enabled to isscale9enabled </cmt> <cmt> refactor uibutton </cmt> <cmt> refactor imageview </cmt> <cmt> refactor slider control </cmt> <cmt> refactor loadingbar </cmt> <cmt> refactor layout </cmt> <cmt> fix minor bugs of uislider and remove unused header include in listview </cmt>",refactor ui::widgets to use ui::scale9sprite instead of extension::scale9sprite
1040,"<desc> this pull request addresses issue #6170 (and the issues mentioned in there - #800 and #3876). adds support for the following: zeroes in the episode portion of the filter, including episode #0 for specials e.g. 1x00;. open-ended filters now match future seasons e.g. 1x01-; will match all episodes from season 2 and later. this is issue #3876 which had been closed. matches episodes specified like 1x01 in the article title (this is an extension of issue #800). it looks like this also fixes #2749 (although i'm not convinced there was an actual problem there, but the use case works with this pull request). note: this pull request includes a commit (ee0359c) which has been factored out to allow all the pull requests i am submitting to merge without conflicts. </desc> <cmt> rss parse torrent episodes like 1x01 as well as s01e01. closes #2749. </cmt> <cmt> --hg-- </cmt> <cmt> branch : magao-dev </cmt> <cmt> rss allow infinite range to extend beyond current season. closes #800, #3876, #6170. </cmt> <cmt> --hg-- </cmt> <cmt> branch : magao-dev </cmt> <cmt> rss episode filter refactoring and logging (prep for later commits). </cmt> <cmt> --hg-- </cmt> <cmt> branch : magao-dev </cmt> <cmt> allow episode zero (special) and leading zeroes in rss episode filter. </cmt> <cmt> --hg-- </cmt> <cmt> branch : magao-dev </cmt> <iss> rss episode filter ""single number"" don't work </iss>","rss episode filter improvements. closes #800, #2749, #3876, #6170."
1041,"<desc> now rpms created with grunt will respect the --install-dir flag. also, the rpm summary uses the grunt description variable. this is a partial implementation of issues discussed in pr #5339 . resolving icons in the atom.desktop file using the system icon path will be taken care of in another pr. also, automated builds of rpm packages for upload to atom.io should now build against '/usr' instead of '/usr/local'. </desc> <cmt> fixes rpm install path and icon location </cmt> <cmt> this makes atom a better desktop citizen relocating to where the usual install </cmt> <cmt> directory is (like on the debian package) and also fix the icon using absolute </cmt> <cmt> paths, breaking icon-themes. </cmt> <cmt> depend on $path to find executable in atom.desktop </cmt> <cmt> with the atom atom executable now located in /usr/bin instead </cmt> <cmt> of /usr/local/bin, it should always be available as part of the </cmt> <cmt> system path. thus hardcoding the filepath is not needed. also, this </cmt> <cmt> increase the flexibility of relocating the rpm at installation time </cmt> <cmt> (not just build time) since the user or sys admin need only make </cmt> <cmt> sure that the atom executable is in the system path and the </cmt> <cmt> atom.desktop file will work correctly. </cmt> <cmt> place atom.png icons in standard system locations </cmt> <cmt> this is so that the atom.desktop file will be able to find the </cmt> <cmt> ""atom"" icon when requested. this adds the dependency of imagemagick </cmt> <cmt> to convert atom.png to varying resolutions, although, only during </cmt> <cmt> the rpm build process (not during actual install). so the result </cmt> <cmt> is ultimatly no different for the end user. </cmt> <cmt> also, fixed an absolute path from the rpm build process and made </cmt> <cmt> it relative. it was hardcoded in the spec file to </cmt> <cmt> ""/tmp/atom-build/atom/*"", so builds that were made elsewhere would </cmt> <cmt> have broken when attempting to package into an rpm. now rpm packaging </cmt> <cmt> should work from a build made anywhere. also needed to modify </cmt> <cmt> script/mkrpm so that it copies the build files in such a way that </cmt> <cmt> they can more easily be dealt with in the spec file in a relative </cmt> <cmt> way. </cmt> <cmt> add linux icons </cmt> <cmt> add linux icons </cmt> <cmt> revert ""fixes rpm install path and icon location"" </cmt> <cmt> this reverts commit b92e6f5a2dc111d5f681a1c8db19115b370c63cc. </cmt> <cmt> remove some hardcoded paths from atom.spec.in </cmt> <cmt> also, fix a couple lines in atom.spec.in that either weren't </cmt> <cmt> really doing anything or were inconsistent with the rest of the </cmt> <cmt> script. </cmt> <cmt> mkrpm honors the '--install-dir' option of grunt </cmt> <cmt> also, atom.spec now uses the description provided by grunt instead </cmt> <cmt> of hardcoding its own description. </cmt> <cmt> automated rpm package builds to '/usr' </cmt> <cmt> this is instead of the default of '/usr/local'. targeting '/usr' </cmt> <cmt> is more in line with what most rpm distros expect. </cmt>",make atom.spec.in use grunt variables
1042,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> update uishell components. </cmt> <cmt> fix lint errors. </cmt>",update uishell components for 7.10.x
1043,"<desc> relands #74469 and incorporates #77959 from @cyanglaz   + additional changes in 829756e, 28f74e4. the last two commits handle this situation: it doesn't generate generated_main.dart if there isn't need for it. that is, no plugin uses dartpluginclass in the pubspec. generated_main.dart is deleted if there  isn't any platform resolution.  this is the case if you delete a plugin from pubspec.yaml and then hot reload/restart. use the new target in all cases. fixes #52267 </desc> <cmt> always regenerate dartpluginrestrant </cmt> <cmt> fix typo in name </cmt> <cmt> tests </cmt> <cmt> review </cmt> <cmt> remove extra imports </cmt> <cmt> fix windows tests </cmt> <cmt> remove debugging logs </cmt> <cmt> fix </cmt> <cmt> revert ""reverts ""implement dartpluginclass support for plugins #74469"" (#78623)"" </cmt> <cmt> this reverts commit 5efc7169ebd621f3501d4c7d12ab2e10cbe9eb74. </cmt> <iss> implement dartpluginclass support for plugins </iss>",reland the dart plugin registry
1044,"<desc> #1308 fix some spelling errors of method names in file named 'utilall.java' these changes seem trivial, but it's an international project and i think the right naming helps other developers understand it. the utilall.computeeclipsetimemilliseconds was modified to utilall.computeelapsedtimemilliseconds (i think this method is to calculate the elapsed time by giving the start time.) 'computnextmorningtimemillis' was modified to 'computenextmorningtimemillis ' 'computnexthourtimemillis' was modified to 'computenexthourtimemillis ' 'computnextminutestimemillis' was modified to 'computenextminutestimemillis ' 'computnexthalfhourtimemillis' was modified to 'computenexthalfhourtimemillis ' nothing. follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> hotfix: fixed a spelling error for a method name. </cmt> <cmt> hotfix: fixed some spelling error for methods </cmt>",fix some spelling errors of method names.
1045,<desc> updated vs props and makefiles of googlemock to reflect the new location of googletest. please refer to issue #772 </desc> <cmt> changed the gtestdir marco value to reflect the new dir of googletest. </cmt> <cmt> updated the value of gtest_dir to reflect the googletest dir. </cmt>,fixed googletest dir issue for building googlemock.
1046,"<desc> i added a new link to a git course that my team worked on. it's a free course, based on github. i also changed the order of links on the git section to meet the alphabetical order. </desc> <cmt> adding new git course and putting in alphabetical order </cmt> <cmt> mentioning author </cmt>",added new git course link
1047,<desc> d05e816 : the current block in graphviz output is highlighted even when graph.gv.current is false. added a logical check to fix it. f5e3f60 : else if blocks are off by one indentation level </desc> <cmt> fix filling current block when graph.gv.current=false </cmt> <cmt> fix incorrect indentation </cmt>,fixes to graphviz related code
1048,<desc> this pull request fixes the following: fixes the wp8 shader compiler by adding missing files to project fixes the allocatortest by deleting the objects created in the first test pass before starting the second test pass. fixed mutex_init for winrt and wp8 added base/allocator to wp8 and universal app projects updated libcoco2d dll name from 3.3 to 3.4 removed unused files. </desc> <cmt> removed 3dexport.h as it no longer exists </cmt> <cmt> removed unused winrt ccplatformdefine.h </cmt> <cmt> added missing files </cmt> <cmt> added base/allocator files </cmt> <cmt> used createmutexex for winrt and wp8 </cmt> <cmt> delete first pass of allocations before starting second pass </cmt> <cmt> updated dll name from 3.3 to 3.4 </cmt> <cmt> added base/allocator files </cmt>,wp8 and windows 8.1 universal app fixes
1049,<desc> adds an integration test that demonstrates that the previous hosts retry host predicate works. risk level: low testing: n/a docs changes: n/a release notes: n/a platform specific features: n/a </desc> <cmt> host pred: add integration test for previous host predicate </cmt> <cmt> adds an integration test that demonstrates that the previous host retry </cmt> <cmt> predicate can be used to avoid retrying the same host. </cmt> <cmt> format </cmt> <cmt> spelling </cmt>,add integration test for previous hosts
1050,"<desc> control: add adctrajectory speed_fallback when full_stop. control: reset integral when gear_neutral or full_stop. control:reset the station pid after switching from reverse to forward. localization: compensate the translation between imu and center. </desc> <cmt> control:reset the station pid after switching from reverse to forward </cmt> <cmt> fix [idg-apollo-4330]. </cmt> <cmt> the station pid parameter is reset in reverse gear, but the station pid </cmt> <cmt> is not reset after switching from reverse to forward, only the speed pid </cmt> <cmt> parameter is reset </cmt> <cmt> solution: </cmt> <cmt> reset the station pid after switching from reverse to forward </cmt> <cmt> control: reset integral when gear_neutral or full_stop. </cmt> <cmt> fix [idg-apollo-4329]. </cmt> <cmt> move too fast after shifting or when entering self-driving. </cmt> <cmt> cause: </cmt> <cmt> after shifting or entering autonomous driving, no integral zeroing </cmt> <cmt> is carried out, resulting in excessive initial control when re-entering control </cmt> <cmt> solution: </cmt> <cmt> reset integral when gear_neutral or full_stop. </cmt> <cmt> localization: compensate the translation between imu and center. </cmt> <cmt> fix [idg-apollo-4350]. </cmt> <cmt> the lateral control error is too big. </cmt> <cmt> cause: </cmt> <cmt> the translation between the imu and vehicle center is not compensated </cmt> <cmt> for localization, thus the publish location of the vehicle is not </cmt> <cmt> correct. </cmt> <cmt> solution: </cmt> <cmt> add the translation between imu and vehicle center when calculating the </cmt> <cmt> location of the vehicle. </cmt> <cmt> control: add adctrajectory speed_fallback when full_stop. </cmt> <cmt> fix [idg-apollo-4361]. </cmt> <cmt> the car cannot stop immediately during the parking phase. </cmt> <cmt> cause: </cmt> <cmt> in the parking phase, the adctrajectory type changes to speed_fallback, </cmt> <cmt> resulting in failure to access fullstop. </cmt> <cmt> solution: </cmt> <cmt> add adctrajectory speed_fallback when full_stop. </cmt>",improve control performance and compensate imu translation for localization.
1051,<desc> augments #6697 to emit readonly modifier in declaration file for get-only accessors in classes. </desc> <cmt> emit readonly in declaration file for get-only accessors in classes </cmt> <cmt> adding more test cases </cmt> <cmt> accepting new baselines </cmt>,readonly in declaration files (part 2)
1052,"<desc> i added a feature #248, which enables to submit with keyboard (ctrl+enter or cmd+enter) on script console. but the feature included a multi submit bug, so i fixed it. in addition, i move the code written in script console jelly to hudson-behavior.js. hereby, shortcut key on script console can be used at any other place, for example scriptler-plugin. </desc> <cmt> handling shortcut key only when firing 'keydown' event </cmt> <cmt> move handling code to behavior rule file </cmt>",fix multi submit with shortcut key
1053,"<desc> cherry-picking this pr to 5.3 to unblock performance for #32041 </desc> <cmt> aliasanalysis: better handling of init_enum_data_addr and init_existential_addr. </cmt> <cmt> look ""through"" those instructions when trying to find the underlying objects. </cmt> <cmt> (cherry picked from commit c7c2c139af1d7db455ee918ee2af02f8ea422a6c) </cmt> <cmt> aliasanalysis: consider a take from an address as an write </cmt> <cmt> currently we only have load [take] in ossa which needed to be changed. </cmt> <cmt> (copy_addr is not handled in membehavior at all, yet) </cmt> <cmt> even if the memory is physically not modified, conceptually it's ""destroyed"" when the value is taken. </cmt> <cmt> optimizations, like temprvalueopt rely on this behavior when the check for may-writes. </cmt> <cmt> this fixes a memorylifetime failure in temprvalueopt. </cmt> <cmt> (cherry picked from commit 547d527258bfdb9b64132dd96fcb4744d0cabfaa) </cmt> <cmt> aliasanalysis: handle copy_addr in membehaviorvisitor. </cmt> <cmt> only let copy_addr have side effects if the source or destination really aliases with the address in question. </cmt> <cmt> (cherry picked from commit c82f78b218530c2fb02fe1b475c266e21b199cda) </cmt> <cmt> siloptimizer: a new ""templvalueopt"" optimization pass for copy_addr </cmt> <cmt> optimizes copies from a temporary (an ""l-value"") to a destination. </cmt> <cmt> %temp = alloc_stack $ty </cmt> <cmt> instructions_which_store_to %temp </cmt> <cmt> copy_addr [take] %temp to %destination </cmt> <cmt> dealloc_stack %temp </cmt> <cmt> is optimized to </cmt> <cmt> destroy_addr %destination </cmt> <cmt> instructions_which_store_to %destination </cmt> <cmt> the name templvalueopt refers to the temprvalueopt pass, which performs a related transformation, just with the temporary on the ""right"" side. </cmt> <cmt> the templvalueopt is similar to copyforwarding::backwardpropagatecopy. </cmt> <cmt> it's more restricted (e.g. the copy-source must be an alloc_stack). </cmt> <cmt> that enables other patterns to be optimized, which backwardpropagatecopy cannot handle. </cmt> <cmt> this pass also performs a small peephole optimization which simplifies copy_addr - destroy sequences. </cmt> <cmt> copy_addr %source to %destination </cmt> <cmt> destroy_addr %source </cmt> <cmt> is replace with </cmt> <cmt> copy_addr [take] %source to %destination </cmt> <cmt> (cherry picked from commit 9e92389fa59fedf03940dadee49d155899630c99) </cmt>","a new ""templvalueopt"" optimization for copy_addr"
1054,"<desc> this pull request allows flying shuttle to collect metrics from both compilation pipelines to ensure pages are invalidated when branched code logic is evaluated. by side effect, flying shuttle will now invalidate pages when _document changes. </desc> <cmt> add flying shuttle plugin to server compilation </cmt> <cmt> ignore build artifacts in flying shuttle manifest </cmt> <cmt> add comments explaining what's going on </cmt> <cmt> emit shuttle manifest after both compilations </cmt>",server file inclusive flying shuttle
1055,<desc> reported in #42740 ec2_group ansible version </desc> <cmt> fix spurious changed=true when int is passed as tag </cmt> <cmt> fix for all aws module using compare_aws_tags </cmt> <cmt> handle improperly stringified protocols and allow inconsistency between none/-1 on non-tcp protocols </cmt>,fix ec2_group for numbered protocols (gre)
1056,"<desc> cherry-picking #27198. the first commit is new because we don't have typecheckstorage.cpp in the 5.1 branch. the second commit is from the original pr. explanation: we were rejecting the following valid code: @propertywrapper struct foo<value> { var wrappedvalue: value } class bar { // error: class stored properties not supported in classes; did you mean 'static'? @foo static var bool: bool = true } the problem here was that we were using the backing variable's static spelling, which is not present (because we haven't created its pattern binding at the time we access the spelling), so the check was falling down to calling getcorrectstaticspellingfordecl() which returned class as the spelling since the context is a class. we should be using the original variable's static spelling instead (we already use its static-ness to decide whether the backing variable should be static or not, might as well use its static spelling too). scope: property wrapper usage inside a class issue: sr-11478 testing: swift ci risk: low. this allows code that was previously rejected (incorrectly) reviewed by: @jrose-apple </desc> <cmt> [codesynthesis] when creating the pattern binding for the backing variable, use the original property's static spelling </cmt> <cmt> [test] adds some tests </cmt>",fix a bug with static property wrapper being rejected in a class
1057,"<desc> adds a bash script to automate changing into each of the examples/ directories and try to run npm i and gatsby build. this script is useful for trying to identify which of the example sites aren't working with the latest version of gatsby (using the next tag). some caveats: this script is slow. it currently takes hours to run, because it's building each example individually. some of the builds will fail because the folder structure for that example is different. e.g., examples/creating-source-plugins/ contains multiple gatsby sites, each in their own folder. this script won't catch all those edge cases. it's mainly an attempt to handle all the easy cases, while identifying individual failing examples that need to be investigated manually. examples/readme.md sc-38579 </desc> <cmt> chore: delete outdated recipes examples </cmt> <cmt> revert ""chore: delete outdated recipes examples"" </cmt> <cmt> this reverts commit 2dcb7858e149c754f9d31b7d9e8b03d7dd1fca31. </cmt> <cmt> wip: attempt a build script in node (works for small subsets of examples) </cmt> <cmt> chore: replace node build script with bash script (fixes parallelization crashing) </cmt> <cmt> chore: improve documentation in build script </cmt>",add a bash script to test building out examples
1058,<desc> seems that 1 or 2 channel tracks come in directly as pcm_int_lit while >2 channel tracks are wrapped in ms acm to preserve channel mapping. </desc> <cmt> dev </cmt> <cmt> dev </cmt> <cmt> add 16 bit audio handling for pcm int little and a_ms_acm tracks with pcm int little </cmt>,add 16 bit pcm audio track detected including ms acm for >2 channels
1059,"<desc> if the flutter_tool's .packages is missing, run pub get offline in the directory. makes #41681 a bit better, though it still crashes on the first run. </desc> <cmt> workaround for cache issue </cmt> <cmt> fix imports </cmt>",handle missing .packages file in the flutter tool for prebuilt artifacts
1060,"<desc> since majority of es6 feature will have to emit for es5, es3, this pull request is to re-factoring emitjavascript such that we will have separate functions for emit a node in native es6 and down-level es5/es3 without having to check the compileroption.target for every kind of node. </desc> <cmt> refactoring emitter for emit es6 features natively </cmt> <cmt> refactoring emitter for emit es6 features natively </cmt> <cmt> conflicts: </cmt> <cmt> src/compiler/emitter.ts </cmt>",re-factoring emitter for emitting es6 feature natively and down-level
1061,"<desc> what's in this pull request? this pr fixes the build for powerpc64le, and fixes a couple of tests. even with this pr, there are still two failing tests on powerpc64le, and working ""out of the box"" is dependent on the following commit being merged into swift-llvm/stable: apple/swift-llvm@d7ad443 resolved bug number: (sr-) n/a before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> use ""powerpc64{le}"" instead of ""ppc64{le}"" </cmt> <cmt> a mix of ""powerpc64"" and ""ppc64"" existed, causing build failures. </cmt> <cmt> standardise on ""powerpc64"" and ""powerpc64le"", which are commonly used in </cmt> <cmt> target triples, such as those generated by config.guess. </cmt> <cmt> use tiocsti instead of tiocgwinsz in glibc test </cmt> <cmt> validation-test/stlib/glibc.swift was failing on powerpc64le due to the </cmt> <cmt> missing tiocgwinsz symbol.  since (from what i can tell) this is just a </cmt> <cmt> random tty ioctl, replace it with a different ioctl that should be more </cmt> <cmt> commonly defined. </cmt> <cmt> fix persistentvector test for powerpc64{le} </cmt> <cmt> this test has a check for 32/64bit, include powerpc64{le} in this check. </cmt>",powerpc64{le} build and test fixes
1062,"<desc> -- some cleanup performed -- buildall.sh script -- generate_protos.sh script that regenerates proto files (as a result, it turned out lots of generated files are out of data, so i regenerated them when possible) these files are handcrafted, so i left them as they are for now: csharp/src/protocolbuffers.test/testprotos/unittest.cs csharp/src/protocolbuffers.test/testprotos/unittestcustomoptions.cs csharp/src/protocolbufferslite.test/testprotos/unittest.cs csharp/src/protocolbufferslite.test/testprotos/unittestlite.cs </desc> <cmt> add buildall script for mono </cmt> <cmt> draft of generate_protos.sh </cmt> <cmt> got rid of the outdated mono subdirectory </cmt> <cmt> rename fieldpresence to correct name </cmt> <cmt> regenerate some proto files after clscompliance has been dropped </cmt> <cmt> remove c# files not referenced in any project </cmt> <cmt> regenerated unittestdropunknownfields.cs </cmt> <cmt> regenerated unittestextraslite.cs </cmt> <cmt> regenerated unittestimportpubliclite </cmt> <cmt> regenerated unittestimportlite.cs </cmt>",c# generate_proto.sh and buildall.sh scripts
1063,"<desc> there are a few tiny packages that seem like they might be out of place. this pr moves their contents around so that they vanish. joegallo@galactic:~/code/elastic/elasticsearch $ for dir in $((find x-pack -type d -name ilm; find x-pack -type d -name slm) | grep src | sort | sed -e ""s/^\\.\\///g"" | grep -v -e '(^docs|^client)' | grep -v build | grep -v -e '(qa|test)'); do echo $dir $(ls $dir/*.java | wc -l); done x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm 83 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/slm 8 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/slm 1 # tiny! x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ilm 85 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/slm 4 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/slm 2 # tiny! x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/ilm 15 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/slm 8 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/core/ilm 1 # tiny! x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/ilm 18 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm 5 after joegallo@galactic:~/code/elastic/elasticsearch $ for dir in $((find x-pack -type d -name ilm; find x-pack -type d -name slm) | grep src | sort | sed -e ""s/^\\.\\///g"" | grep -v -e '(^docs|^client)' | grep -v build | grep -v -e '(qa|test)'); do echo $dir $(ls $dir/*.java | wc -l); done x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm 83 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/slm 9 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ilm 85 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/slm 6 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/ilm 15 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/slm 8 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/ilm 19 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm 5 </desc> <cmt> move snapshotretentionconfigurationtests </cmt> <cmt> to o.e.xpack.core.slm, so it will match snapshotretentionconfiguration </cmt> <cmt> move snapshotlifecyclestats </cmt> <cmt> to o.e.xpack.core.slm, so it will match snapshotlifecyclemetadata and </cmt> <cmt> snapshotlifecyclepolicy </cmt> <cmt> move lifecyclepolicytestsutils </cmt> <cmt> move lifecyclepolicytestsutils (again) </cmt> <cmt> it seems more at home with all its callers in </cmt> <cmt> x-pack/plugin/ilm/src/test </cmt>",tidy up some ilm and slm packages
1064,<desc> we built an rl environment within and motivated by openai gym framework and we would be happy to share the link in gym docs. </desc> <cmt> opensim as one of the external environments </cmt> <cmt> typo in 'environments' </cmt>,info about the osim-rl environment added to external environments
1065,"<desc> follows #43686 closes #43637 closes #43644 closes #43703 tests added / passed whatsnew entry (note part of the bug seems to have been created by hiding levels which is a new feature in 1.4.0). this pr has two parts: addressing the bug fixes as per above. the key change made here was to add a single line: if r not in self.hidden_rows: in the loop, and in _translate_latex update for the new object structure that is input to it. refactoring the code so that the main part of the code is now easier to grok: def _translate(...): # calls _translate_header() # callls _translate_body() def _translate_header(...): # calls _generate_col_header_row() # calls _generate_index_names_row() def _translate_body(...): # calls _generate_trimmed_row() # calls _generate_body_row() and tests were update and comprehensive tests for the issues added. </desc> <cmt> ignore hidden rows in loop </cmt> <cmt> add latex 43644 test </cmt> <cmt> add latex 43644 test </cmt> <iss> bug: `styler.to_latex` does hide rows after `hide_index([subset])` </iss> <iss> bug: styler hide_index hide_columns misaligns multiindex </iss> <iss> bug: styler render trimming rows does not work with `hide_index` </iss>",styler multiindex hiding indexes and columns alignment
1066,"<desc> i don't think this is quite complete yet but this is the initial implementation for making boolean attributes like muted set the property video.muted = {{boolean}} and the attribute video.setattribute('muted', 'muted') when changing the value. also, in html5's createel, we were setting/updating attributes for various properties but we were only setting the attributes and not also the properties but also autoplay was happening first rather than last which caused autoplay to fail because muted and playsinline weren't necessary set by that time. </desc> <cmt> fix: pull out boolean attributes and have them set/check both attribute and property </cmt> <cmt> set initial attributes for both props and attrs in correct order </cmt> <cmt> add a comment about settingsattrs ordering </cmt>",make boolean attributes set and check both the associated property and the attribute
1067,<desc> this fixes the name of the --max-tasks-per-child parameter whose name was changed in celery 4.x and adds a --max-memory-per-child of 1/4 of total memory. port of mozilla#364 </desc> <cmt> fix celery worker cli parameter name that was changed in celery 4.x. </cmt> <cmt> set celery worker --max-memory-per-child to 1/4th of total system memory. </cmt>,fix celery worker --max-tasks-per-child for celery 4.x.
1068,"<desc> there is an error message when compile with latest build tool for android. /godot_dev/platform/android/java/src/com/google/android/vending/expansion/downloader/impl/downloaderservice.java:575: error: the wifi_service must be looked up on the application context or memory will leak on devices < android n. try changing  to .getapplicationcontext()  [wifimanagerleak] mwifimanager = (wifimanager) getsystemservice(context.wifi_service); ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ explanation for issues of type ""wifimanagerleak"": on versions prior to android n (24), initializing the wifimanager via context#getsystemservice can cause a memory leak if the context is not the application context. change context.getsystemservice(...) to context.getapplicationcontext().getsystemservice(...). 1 errors, 0 warnings this pr will fix the error and update to latest gradle. </desc> <cmt> fix possible memory leak for android </cmt> <cmt> /godot_dev/platform/android/java/src/com/google/android/vending/expansion/downloader/impl/downloaderservice.java:575: error: the wifi_service must be looked up on the application context or memory will leak on devices < android n. try changing  to .getapplicationcontext()  [wifimanagerleak] </cmt> <cmt> mwifimanager = (wifimanager) getsystemservice(context.wifi_service); </cmt> <cmt> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </cmt> <cmt> explanation for issues of type ""wifimanagerleak"": </cmt> <cmt> on versions prior to android n (24), initializing the wifimanager via </cmt> <cmt> context#getsystemservice can cause a memory leak if the context is not the </cmt> <cmt> application context. change context.getsystemservice(...) to </cmt> <cmt> context.getapplicationcontext().getsystemservice(...). </cmt> <cmt> 1 errors, 0 warnings </cmt> <cmt> update to latest gradle </cmt>",fix possible memory leak for android and update gradle
1069,"<desc> add or edit tests to reflect the change. types/chrome/test/index.ts doesn't have any tests for chrome.commands at all, so i didn't make any changes so far. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: chrome.commands </desc> <cmt> run prettier </cmt> <cmt> add missing 'tab' parameter </cmt>",add missing 'tab' parameter to chrome.commands
1070,<desc> this pr adds code snippet testing to the security apis that were missing this info and removes these exceptions from the build.gradle file. related to #30665 </desc> <cmt> [docs] enabled testing in authenticate api </cmt> <cmt> [docs] adds more tests for security apis </cmt>,adds testing for security apis
1071,"<desc> this updates ansible-pull as described in issue #2464 and the ansible-pull docs to conform to current available options and usage. </desc> <cmt> help ansible-pull work better in bootstap environment </cmt> <cmt> add option to specify inventory.  no default is defined since </cmt> <cmt> ansible-playbook already does this and it allows an ansible.cfg in the </cmt> <cmt> git repository to take precedence. </cmt> <cmt> overall, this should help ansible-pull work with less setup in advance, </cmt> <cmt> which should be helpful in kickstart scenarios.  much of this was </cmt> <cmt> discussed in issue #2464. </cmt> <cmt> update ansible-pull documentation </cmt> <cmt> remove errant and unneeded import of ansible.constants </cmt>",updates to ansible-pull and ansible-pull docs
1072,"<desc> we want to deprecate jenkins and move the tests to travis. this pr is still wip. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> [tune] sort test execution </cmt> <cmt> create tune py_test directives </cmt>",move jenkins tests to travis
1073,"<desc> closes #30590 tests added / passed n/a passes black pandas n/a passes git diff upstream/master -u -- ""*.py"" | flake8 --diff n/a whatsnew entry n/a decided to add all valid strings for all the types in the table about dtypes.  i didn't want to decide which ones to leave out, and if we want to leave some of them out, we should decide whether they should be removed from the code as well (e.g., 'sparse[int, 0]') had to reformat the table so it would look nice, by splitting the list of strings into multiple lines (e.g., a merged cell) </desc> <cmt> doc: add strings for dypes in basic.rst </cmt> <iss> doc: add info on dtype strings </iss>",add strings for dtypes in basic.rst
1074,"<desc> this pull request implements following changes add hindi translation for weather report, morning, noon, evening, night add hindi translation for help file and could you please add your name to the translators list? (see above) closes: #429 </desc> <cmt> feat(translation): hindi translation for we-lang </cmt> <cmt> feat(translation): add hindi translation for help file </cmt> <iss> hindi translation </iss>",hindi translation for we-lang and help file
1075,"<desc> as part of the extensible values source work, this pr extracts some of the hard-coded valuessource types from valuessourceconfig. related to #42949 </desc> <cmt> rename valuessourcetype -> builtinvaluessourcetype </cmt> <cmt> extract empty/script/missing behavior from valuessourceconfig </cmt> <cmt> pull valuessourcetype out as an interface </cmt> <cmt> javadoc for (new) valuessourcetype </cmt> <cmt> move withscript vs under bytes </cmt> <cmt> todo notes for points that are still confusing </cmt>",extract empty/script/missing valuessource behavior to an interface
1076,"<desc> query results api response should include the bare minimum fields if this is an api call (dashboard, query) and not an authenticated user. we need to move the serialization logic into redash.serializers and apply the relevant checks. </desc> <cmt> avoid catching errors on text widgets' load(), as they don't have a visualization and therefore do not return any promise </cmt> <cmt> throw error when failing to load widgets on public dashboards - in case something needs to be done with it at a later time, and it's the right thing to do anyway </cmt> <cmt> use promise.resolve instead of checking for undefined </cmt> <cmt> call serialize_query_result instead of directly calling to_dict </cmt> <cmt> filter unneeded query result fields for unauthenticated users </cmt> <cmt> test for serialization filtering </cmt>",query result api response shouldn't include query information for non authenticated users
1077,"<desc> i2c slave might stil have something to send when esp826 starts i2c, thus keeping the bus stuck. happens e.g. when power failure/reset during transmission. thanks to work of drmpf there is a solution. implemented as separate method (wire.status()) so as not to interfere with existing. method (status)returns one of the five statuses. 0 or i2c_ok is ok. other status codes are for hanging scl or hanging sda usage: wire.begin();                                 //like normal if (wire.status() != i2c_ok) serial.writeln(error_msg);                 //something wrong with i2c bus //that cannot be recovered. //perform power cycle //or search for other masters on bus; </desc> <cmt> i2c bus reset with info to user </cmt> <cmt> i2c slave might stil have something to send when esp826 starts i2c, thus </cmt> <cmt> keeping the bus stuck. </cmt> <cmt> happens e.g. when power failure/reset during transmission. </cmt> <cmt> thanks to work of drmpf there is a solution. </cmt> <cmt> implemented as separate method so as not to interfere with existing. </cmt> <cmt> usage: </cmt> <cmt> wire.begin(); </cmt> <cmt> if (wire.status() != i2c_ok) serial.writeln(""something wrong with i2c </cmt> <cmt> bus that cannot be recovered. perform power cycle or search for other </cmt> <cmt> masters on bus.""; </cmt> <cmt> i2c bus reset with info to user </cmt>","i2c bus reset with status info to user, re issue 1025"
1078,"<desc> reverted changes in genericaliasobject.c to commit 463c7d3 (right before pep 612) via a clean git checkout 463c7d3d149283814d879a9bb8411af64e656c8e -- genericaliasobject.c. implemented pep 612 behavior only in collections.abc.callable in pure python. pr 1/2, another update to typing.py is coming later, but that's not urgent. the intention of this change is to conform more strictly to pep 612. specifically, this snippet: as before, parameters_expressions by themselves are not acceptable in places where a type is expected  the current implementation leaks extra behavior into all builtin genericalias types just for the sake of collections.abc.callable, which is out of the scope of the pep. since there is no need to support paramspec in other places, it's valid to not have them in __parameters__ of all builtin generics. except for collections.abc.callable. this will also speed up builtin genericalias as it has to do less checks, and reduce the amount of confusing code in genericalias (though it defers that to collections.abc.callable.) </desc> <cmt> revert genericaliasobject.c to prior to pep 612 </cmt> <cmt> implement pep 612 behavior in collections.abc.callable </cmt> <cmt> simplify the python logic a little </cmt>",change pep 612 implementation to pure python
1079,"<desc> the hacks for gl are not just ugly, but also bad for code size in some cases, it turns out (apparently closure will not optimize as much in their presence). this is a step towards #8421, the changes for which end up causing closure to emit worse code if not for this pr. </desc> <cmt> reorder when we render the pre js code in jsifier.js. doing it after libraries means we can know at pre render time which library code is included </cmt> <cmt> remove some closure ignores, which are bad for code size </cmt>",remove some closure compiler hacks
1080,"<desc> this update is needed for docker#330 (which currently has the regression introduced by moby/libnetwork#241) bump libnetwork to 92d1fbe1eb0883cf11d283cea8e658275146411d full diff: moby/libnetwork@09cdcc8...92d1fbe relevant changes included (omitting some changes that were added and reverted in this bump): moby/libnetwork#2433 fix parseip error when parseip before get addressfamily fixes moby/libnetwork#2431 parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0] moby/libnetwork#2289 this was a regression introduced in moby/libnetwork#2416 fix hardcoded af_inet for ipv6 address handling moby/libnetwork#2440 bump hashicorp go-sockaddr v1.0.2, go-multierror v1.0.0 bump hashicorp/go-multierror v1.0.0, add errwrap v1.0.0 full diff: hashicorp/go-multierror@fcdddc3...v1.0.0 bump hashicorp/go-sockaddr v1.0.2 full diff: hashicorp/go-sockaddr@6d291a9...v1.0.2 relevant changes: hashicorp/go-sockaddr#25 add android os hashicorp/go-sockaddr#28 add go.mod </desc> <cmt> bump lib network to 92d1fbe1eb0883cf11d283cea8e658275146411d </cmt> <cmt> full diff: </cmt> <cmt> relevant changes included (omitting some changes that were added _and_ reverted in this bump): </cmt> <cmt> - docker/libnetwork#2433 fix parseip error when parseip before get addressfamily </cmt> <cmt> - fixes docker/libnetwork#2431 parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0] </cmt> <cmt> - </cmt> <cmt> - this was a regression introduced in docker/libnetwork#2416 fix hardcoded af_inet for ipv6 address handling </cmt> <cmt> - docker/libnetwork#2440 bump hashicorp go-sockaddr v1.0.2, go-multierror v1.0.0 </cmt> <cmt> bump hashicorp/go-multierror v1.0.0, add errwrap v1.0.0 </cmt> <cmt> full diff: </cmt> <cmt> bump hashicorp/go-sockaddr v1.0.2 </cmt> <cmt> full diff: </cmt> <cmt> relevant changes: </cmt> <cmt> - hashicorp/go-sockaddr#25 add android os </cmt> <cmt> - hashicorp/go-sockaddr#28 add go.mod </cmt> <iss> parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0] </iss>",bump libnetwork and dependencies to 92d1fbe1eb0883cf11d283cea8e658275146411d
1081,"<desc> account for x and y probe offset when indicating current position [] on grid when displaying mesh map. also, adjust the default safe home position to be on a grid point to allow easy validation, i.e. we expect the grid z offset value at the home position to be very close to 0, depending on how reproducible the z probing is. after doing a g29 p1, the mesh topology displayed using g29 t would show larger than expected z errors when compared with the z height displayed on the lcd screen. this turned out to be due to the code for finding the nearest mesh point to the current nozzle position not taking the x and y z probe offsets into account. this fix makes it easier to verify the mesh using the lcd readout z value. </desc> <cmt> account for x and y probe offset when indicating current position on grid when displaying mesh map. </cmt> <cmt> try to home on a grid point to better allow checking mesh center </cmt>",ubl g29 t current position fix
1082,"<desc> we need this to address issue #565 (which is blocking merging c# into master). this also reveals that despite style guide says that repeated fields should use name in plural form, the generated code doesn't really reflect that (in sense providing sane names for the generated members). correct naming of fields in addressbook.proto (""phones"" and ""persons"") results in code that's a bit wierd (e.g. method addpersons adds a single person)  @jskeet  fyi </desc> <cmt> update addressbook.proto to proto3 </cmt> <cmt> fix c++ example </cmt> <cmt> fix python example </cmt> <cmt> fixed java example </cmt>",update addressbook.proto and examples code to proto3
1083,"<desc> see  this makes it possible to build a bitcode enabled ios app if you're using a local engine built with bitcode. the plan here is to make this a bit more accessible to early adopters who want to test it. they can test it by either using flutter build aot --target-platform=ios --bitcode --profile --local-engine=ios_profile, or by setting enable_bitcode to true in their xcode project (and building with a local engine).  we're not yet vending engine binaries with bitcode - i'd like to enable this as a hidden flag for now that people can start testing and validating. @jonahwilliams mentioned this should get analytics - i'm not really sure how to do that but would be happy to add some. this also really wants an integration test, but that would be very expensive to do right now - we'd have to checkout the engine sources for the framework commit, build them (and we can't use goma), and then use a local engine.  i've added some unit tests to the parts of the build system i changed, except for xcode_backend.sh which isn't really testable (i've tested it manually). related issues part of #15288 i added the following tests: tests that building aot with and without bitcode support makes the expected invocations and modifies the generated assembly as expected. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> bitcode start </cmt> <cmt> merge </cmt> <cmt> temp </cmt> <cmt> merge </cmt> <cmt> ? </cmt> <cmt> wire up bitcode arg, cleanup </cmt> <cmt> revert enable_bitcode for all projs </cmt> <cmt> revert dev and examples </cmt> <cmt> revert templates </cmt> <cmt> more </cmt> <cmt> tests </cmt> <cmt> tests </cmt>",enable bitcode compilation for aot
1084,<desc> see #5841 -- i used a version of path.relative that should work on all platforms. </desc> <cmt> fix css url rewriting for application deployed under a sub path </cmt> <cmt> fixes #5837 </cmt> <cmt> use a reproduced pathrelative in css minifier </cmt> <cmt> we can't use plugin.fs here so we'll keep replicating stuff. </cmt>,mquandalle fix path minifiers css
1085,"<desc> change this change fixes the case when opensource returns a nullptr.  the command will now inform the user depending on the case: there are no sources, so we suggest adding one. there are sources, but the requested source did not match one.  we list the configured sources. testing manually confirmed all cases. </desc> <cmt> fix attempting to search when no source value is returned </cmt> <cmt> be helpful in case a bad name was used </cmt>",fix crash when opensource returns nullptr
1086,<desc> r? @oli-obk  fixes rust-lang/miri#449 </desc> <cmt> miri engine: lazily allocate memory for locals on first write </cmt> <cmt> make storagelive lazy as well </cmt> <cmt> fix miri engine debug output for uninitialized locals </cmt> <cmt> initialize unsized locals when copying to the for the first time </cmt> <cmt> implement by-value object safety </cmt>,unsized locals and by-value dyn traits
1087,"<desc> when we select a color for the tab, we update the foreground color of the text so that it maintains acceptable contrast with the new tab color. however, we weren't also updating the foreground color of the close button. this is understandable though, because apparently this wasn't fixable until mux 2.4 arrived. i'm not a xaml expert, but i know that setting this key only works when we're using mux 2.4, so i'm assuming something about the tabview implementation changed in that release. this pr is marked as a draft until #5778 is merged, then i'll re-target to master. #5778 - pr to move to mux 2.4 this bug was introduced with the tab color picker in #3789 closes #5780 i work here a light tab color: a dark tab color: </desc> <cmt> move to microsoft.ui.xaml 2.4.0 </cmt> <cmt> this fixes #5780, but it _only_ works on mux 2.4 apparently. </cmt> <iss> tab close button doesn't color properly when changing tab color </iss>",update the tab's close button color to match the tab text color
1088,"<desc> fixes tree reduction failing on new instance type p3dn.24xlarge, which was raised here: dmlc/gluon-nlp#520 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change adds a fallback for cudadevicegetp2pattribute topology information to use cudadeviceenablepeeraccess when the former is inconsistent across instance types. fixes tree reduction breaking when cudadevicegetp2pattribute provides wrong information. on p3dn.24xlarge using cuda 9.0, we observe that the cudadevicegetp2pattribute topology looks different compared to when we use cuda 9.0 with p3.16xlarge: // check that all p2p connections are detected by getp2pattribute // if yes, then continue as before // if not, then fallback to using cudadeviceenablepeeraccess saved in p2p_matrix //   (from enablep2p() in src/kvstore/comm_tree.h) // // we have observed that with cuda 9.0 p3.16xlarge: // //   0 2 2 3 3 1 1 1                . v v v v . . . //   2 0 3 2 1 3 1 1                v . v v . v . . //   2 3 0 3 1 1 2 1                v v . v . . v . //   3 2 3 0 1 1 1 2                v v v . . . . v //   3 1 1 1 0 2 2 3                v . . . . v v v //   1 3 1 1 2 0 3 2                . v . . v . v v //   1 1 2 1 2 3 0 3                . . v . v v . v //   1 1 1 2 3 2 3 0                . . . v v v v . // //        matrix                       p2p_matrix // cudadevicegetp2pattribute   cudadeviceenablepeeraccess // // here, they are correctly detected, because the 2s and 3s correspond to // links that have p2p connections between them. however for cuda 9.0 p3dn.24xlarge: // //   0 2 2 1 1 1 1 1                . v v v v . . . //   2 0 1 2 1 1 1 1                v . v v . v . . //   2 1 0 1 1 1 2 1                v v . v . . v . //   1 2 1 0 1 1 1 2                v v v . . . . v //   1 1 1 1 0 2 2 1                v . . . . v v v //   1 1 1 1 2 0 1 2                . v . . v . v v //   1 1 2 1 2 1 0 1                . . v . v v . v //   1 1 1 2 1 2 1 0                . . . v v v v . // //        matrix                      p2p_matrix // cudadevicegetp2pattribute   cudadeviceenablepeeraccess // // the fastest connections (3 i.e. double nvlink) are not recognized as being a //   connection </desc> <cmt> add fallback for gpu topology detection using cuda 9.2 </cmt> <cmt> add fallback for gpu topology detection using cuda 9.2 </cmt> <cmt> add log </cmt> <cmt> update 3rdparty to master </cmt> <cmt> add fallback for gpu topology detection using cuda 9.2 </cmt> <cmt> add log </cmt> <cmt> update 3rdparty to master </cmt> <cmt> bring 3rdparty packages to upstream/master </cmt> <cmt> rebase to master </cmt>",fix tree reduction on new instance type p3dn.24xlarge
1089,"<desc> updated to a more efficient version of bubble sort by adding decrements after loop and changing loop type. </desc> <cmt> updated to more efficient version if array size is scaled. </cmt> <cmt> changed loop from ""for"" to ""do-while"". added decrement at end of do loop to decrease size of array tested after each iteration. </cmt> <cmt> updated to more efficient version if array size is scaled. </cmt>",bubble sort updated to efficient version
1090,"<desc> there are multiple terminology such as checkpointxxx savingxxx and model for the checkpointmanager feature which makes it confusing. also, it's more accurate to change frequency to interval since freq = 1 / interval. this pr makes adjustment to the docs and terminology. </desc> <cmt> [jvm-packages] move cache files to tmp dir and delete on exit </cmt> <cmt> [jvm-packages] update docs and unify terminology </cmt>",update docs and unify the terminology
1091,"<desc> the @types/eureka-js-client package was missing the definitions for the requestmiddleware function definition. according to the docs, this is an optional property, and as such has been marked as a nullable field. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added requestmiddleware hook </cmt> <cmt> contributor list addition </cmt> <cmt> marking requestmiddleware as nullable </cmt> <cmt> marked all eurekaconfig props as nullable </cmt> <cmt> reverted eureka-js-client version format </cmt> <cmt> added middleware interface to prevent original eurekaconfig fields from being nullable </cmt>",added custom request middleware hook definition
1092,"<desc> this imports in.h, in6.h and l2tp.h from kernel-5.0. fixes #12300. </desc> <cmt> linux: move netdevice.h from shared/linux to basic/linux </cmt> <cmt> as the header linux/if_arp.h includes linux/netdevice.h. </cmt> <cmt> linux: also import linux/in.h and in6.h from kernel-5.0 </cmt> <cmt> now linux/in.h has better conflict detection with glibc's </cmt> <cmt> netinet/in.h. so, let's import the headers. </cmt> <cmt> note that our code already have many workarounds for the conflict, </cmt> <cmt> but in this commit does not drop them. let's do that in the later </cmt> <cmt> commits if this really helps. </cmt> <cmt> linux: also import l2tp.h from kernel-5.0 </cmt> <cmt> the l2tp_attr_udp_zero_csum6_{tx,rx} attributes are introduced by </cmt> <cmt> 6b649feafe10b293f4bd5a74aca95faf625ae525, which is included in </cmt> <cmt> kernel-3.16. to support older kernel, let's import the header. </cmt> <cmt> fixes #12300. </cmt> <iss> systemd-242 unable to build with kernel 3.14 (l2tp_attr_udp_zero_csum6_tx missing) </iss>",import more headers from kernel-5.0
1093,"<desc> this shouldn't be merged until we're ready to attempt the initial full deploy, which could break beyond what we can ensure in tests. since this introduces a lot of additional ci i'm trying to keep the window of enforcing 3.8 tests passing in addition to 3.6 to just 3.8 tests at a minimum. the ideal situation is we merge this, deploy 3.8 to great success, then remove all of 3.6. but if the 3.8 deploy doesn't go well, we should keep enforcing 3.6 + 3.8 tests passing. note, visual snapshotting is disabled on 3.8, and when we make the switch to it i'll enable it in the pr and don't think there'll be any differences. gonna need to change repo settings again for these new check titles. and again when 3.6 is removed. </desc> <cmt> move query-valid-python-version to lib, add sanity check for sentry_python_version mismatch </cmt> <cmt> remove sanity check since sentry_python_version is only set if direnv succeeds; chicken egg </cmt> <cmt> revert ""remove sanity check since sentry_python_version is only set if direnv succeeds; chicken egg"" </cmt> <cmt> this reverts commit d69ad1e990f2bb42c6e57e54bdd820a5ba2484ec. </cmt> <cmt> fix: let sentry_python_version override get-pyenv-version </cmt> <cmt> fix </cmt> <cmt> evan you happy now? </cmt> <cmt> fix, lol </cmt> <cmt> [skip ci] evan pls </cmt> <cmt> few small ci updates </cmt> <cmt> go away unboundlocal </cmt> <cmt> is this going to be 2x2 instances? </cmt> <cmt> fix: can't use psycopg-binary 2.9.x in 3.8 with django 2.2 </cmt> <cmt> revert ""fix: can't use psycopg-binary 2.9.x in 3.8 with django 2.2"" </cmt> <cmt> this reverts commit d7a4765b1d84969a5123190e89f3d6a3d5634d18. </cmt> <cmt> change to explicitly test only 3.6.13 for now, also adopt </cmt> <cmt> python-version 3.6.13 matrix everywhere </cmt> <cmt> add 3.8 </cmt> <cmt> make check titles consistent by making python version come first </cmt>",add required testing on python 3.8.12
1094,"<desc> per the discussion on the issue tracker, the behavior of the pure python implementation of datetime, date and time are out of whack with the equivalent from _datetimemodule.c. since the c version is almost certainly what's being used almost everywhere, this shouldn't have any real behavioral changes. the equivalent bug in pypy3 has been fixed for some time. </desc> <cmt> add failing test for pure python datetime subclasses </cmt> <cmt> bring pure python (datetime|date|time).replace behavior in line with c </cmt>",make (datetime|date|time).replace return subclass type in pure python
1095,"<desc> with this we are changing the webpack devtool to eval in the development and we no longer use source map. source map with babel is always problematic and cra don't use it. also, it takes time longer than other eval. we also can't use cheap sourcemap devtools because of chrome has some bugs on it. we also cleanup some source map based error enhancements we did and how we handle errors. </desc> <cmt> change the dev time devtool to eval. </cmt> <cmt> now we don't use source-map and all the helpers used for that. </cmt> <cmt> source map is slow and cheap source maps doesn't work well in chrome. </cmt> <cmt> we also remove error enhancements which is also based on source-maps. </cmt> <cmt> additionally, we now simplified the client side error handling </cmt> <cmt> and always throw the actual error so we can check it from the console. </cmt> <cmt> simply error handling and always log the stack to the console. </cmt>",devtool change and error handing
1096,"<desc> fixes issue #6884 #6884 closes #6884 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> add randomenv example to examples folder. </cmt> <cmt> convert warning into error message when using an lstm in a non-shared-vf network (after the warning, the program would crash). </cmt> <cmt> lint. </cmt> <cmt> fix issue #6884. lstm + non-shared vf nn + ppo crashes when using a tuple action space. </cmt> <cmt> lint </cmt> <iss> [rllib] using lstm model raises valueerror (tuple obs_space, similar to #3367) </iss>",lstm + non-shared vf + ppo + tuple actions
1097,"<desc> this pull request is for install openpose under jetpack 3.3, cuda 9,  cudnn 7 and opencv 3. i have made changes to files and tested on my jetson tx2 </desc> <cmt> add files to install openpose under jetpack 3.3 </cmt> <cmt> add installation instructions for jetpack 3.3 </cmt>",add files for install openpose under jetpack 3.3
1098,"<desc> which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # </desc> <cmt> added support for eplus </cmt> <cmt> no message </cmt> <cmt> no message </cmt> <cmt> added replicator port </cmt> <cmt> removed replicator config from nodes </cmt> <cmt> added http version </cmt> <cmt> condition to avoid duplication </cmt> <cmt> allowing replicator to run in all nodes </cmt> <cmt> bug fix for nginx </cmt> <cmt> updated inactiveservercleaner plugin logic </cmt> <cmt> support for configmap to bootstrap artifactory </cmt> <cmt> * art-ha-nginx-bugfix: </cmt> <cmt> updated inactiveservercleaner plugin logic </cmt> <cmt> bug fix for nginx </cmt> <cmt> # conflicts: </cmt> <cmt> #	stable/artifactory-ha/chart.yaml </cmt> <cmt> #	stable/artifactory-ha/readme.md </cmt> <cmt> #	stable/artifactory-ha/templates/artifactory-plugin-inactiveservercleaner.yaml </cmt> <cmt> #	stable/artifactory-ha/templates/artifactory-primary-statefulset.yaml </cmt> <cmt> #	stable/artifactory-ha/templates/nginx-deployment.yaml </cmt> <cmt> configmap support for nginx.conf </cmt> <cmt> updated readme. </cmt> <cmt> updated artifactory version </cmt> <cmt> node affinity support </cmt> <cmt> fixed case </cmt> <cmt> # conflicts: </cmt> <cmt> #	stable/artifactory/chart.yaml </cmt>",bumped version + added support for nginx configmap
1099,"<desc> previously, we have three-layer storage abstraction which actually is not necessary. this pr update it to two-layer abstraction. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> simpler store </cmt> <cmt> format </cmt>",simplify the workflow storage layer
1100,"<desc> no functional changes, let's just make nspawn easier to maintain. </desc> <cmt> nspawn: split out mount related functions into a new nspawn-mount.c file </cmt> <cmt> nspawn: split all port exposure code into nspawn-expose-port.[ch] </cmt> <cmt> nspawn: split out network related code to nspawn-network.[ch] </cmt> <cmt> nspawn: split out cgroup related calls into nspawn-cgroup.[ch] </cmt> <cmt> nspawn: split out machined registration code to nspawn-register.[ch] </cmt> <cmt> nspawn: split out --uid= logic into nspawn-setuid.[ch] </cmt> <cmt> nspawn: remove nspawn.h, it's empty now </cmt> <cmt> nspawn: sort and clean up included header list </cmt> <cmt> let's remove unnecessary inclusions, and order the list alphabetically </cmt> <cmt> as suggested in coding_style now. </cmt>",split up nspawn.c into multiple smaller .c files
1101,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. add it to notneededpackages.json. </desc> <cmt> prettier </cmt> <cmt> feat(point): add x, y value </cmt>","add x,y value of point"
1102,"<desc> an ownershipintroducingvalue is a value with owned ownership that is not a result of forwarding ownership from some other value. it is similar to the notion of ""rc identity"" that we talk about in the low level arc optimizer. i am adding this support so given a specific value, we can walk up the def-use graph and find all of the ownership introducing values (what one would call in the low level arc optimizer an ""rc identity set""). as an example, consider the following sil: %0 = @owned $(klass, int) %1 = @owned $klass (%2, _) = destructure_tuple %0 %3 = tuple(%1, %2) in this case, the set of ownership introducing values for %3 would be (%0, %1). in order to implement phi elimination, i need to be able to ascertain all of the owned value introducers for a specific incoming value so i can see if i can convert all of the liveranges associated with the incoming value could be converted to guaranteed if we could flip the phi argument. </desc> <cmt> [ownership] add a new construct: ownedvalueintroducer for dealing with non-forwarding owned values at a higher level. </cmt> <cmt> this is a similar concept to ""rc-identity"" that we talk about in the low level </cmt> <cmt> arc optimizer. the main idea is that all owned values in a program can be </cmt> <cmt> partitioned into two different kinds of values: </cmt> <cmt> 1. introducer values that exist independently of any other local values in the </cmt> <cmt> function. it is a point of truth from which the owned objects lifetime extends </cmt> <cmt> from and is in a certain sense an initialization (in a category theoretic sense) </cmt> <cmt> in the lifetime of the underlying object that we are manipulating. </cmt> <cmt> 2. forwarding values do not represent an object lifetime that is ""truly"" </cmt> <cmt> independent of any other value locally: its liveness comes from passing on </cmt> <cmt> liveness from some introducer or some other forwarding value. </cmt> <cmt> the reason why i am adding this new construct is that i am beginning to </cmt> <cmt> implement a new form of arc optimization that enables us to convert @owned sil </cmt> <cmt> phi arguments to @guaranteed phi arguments. as part of that, i need to have a </cmt> <cmt> way to in a systematic way finding the underlying incoming values (using the </cmt> <cmt> logic used to determine forwarding in the ownership verifier). </cmt> <cmt> this is the first part of that effort, defining the ontology we are going to </cmt> <cmt> work with. keep in mind this is just a seed ontology, if i missed any ""owned </cmt> <cmt> introducers"" (i am sure i did), feel free to add them. </cmt> <cmt> [ownership] implement getsingleownedvalueintroducer and getallownedvalueintroducers(). </cmt> <cmt> these enable robust walking up the def-use ossa graph to find the value that </cmt> <cmt> introduces an independent underlying owned value, looking through forwarding </cmt> <cmt> insts. </cmt>","add an ""applysite"" like wrapper for ownershipintroducingvalues and add utilities for finding them."
1103,"<desc> task ids are a way to express a relationship between related internal requests. this change preserves the task id for internal requests of the startdatafeedpersistenttask, similarly to how rollupjobpersistenttask does it. relates #52314 </desc> <cmt> datafeedjob task id </cmt>",preserve task id for ml datafeed
1104,"<desc> i added the ""mark all as complete"" checkbox as requested by @boushley and also added the ""press enter to save this task"" tooltip on the input field. </desc> <cmt> add ""mark all as complete"" checkbox bound to a writeable computed observable and minor code cleanup. </cmt> <cmt> add the ""press enter"" tooltip that appears after a delay when the user has entered a value and stops typing </cmt>","add ""mark all as complete"" checkbox and ""press enter"" tooltip."
1105,<desc> this pr fix the ship bug with chain fork and stride enabled. select one: select any that apply: </desc> <cmt> fix ship truncate problem with stride </cmt> <cmt> fix truncate problem when there's gap in catalog </cmt> <cmt> avoid unnecssary reopen files </cmt>,fix ship truncate problem with stride - 2.1
1106,<desc> this patch is adding integration tests for the grafana_datasource module. grafana_datasource.py </desc> <cmt> add setup_grafana role for integration tests </cmt> <cmt> grafana_datasource: add integration tests for elastic datasource </cmt> <cmt> grafana_datasource: add integration tests for influxdb datasource </cmt> <cmt> grafana_datasource: add integration tests for postgres datasource </cmt> <cmt> grafana_datasource: add integration tests for cloudwatch datasource </cmt>,add integration tests for grafana_datasource module
1107,"<desc> here a new attribute @main is added. the type or extension that it is added to must have a static function () -> void or () throws -> void visible from the attribute. if it does, that function will be called at process launch. the same restrictions that apply to the existing @uiapplicationmain and @nsapplicationmain apply to the new attribute as well. </desc> <cmt> added executable entry-point via @main type. </cmt> <cmt> when a type (class, enum, or struct) is annotated @main, it is required </cmt> <cmt> to provide a function with the following signature: </cmt> <cmt> static func main() -> () </cmt> <cmt> that function will be called when the executable the type is defined </cmt> <cmt> within is launched. </cmt> <cmt> @main: added $main func to @main type. </cmt> <cmt> previously, the function was being added to the list of top level decls </cmt> <cmt> in the source file as that list was being iterated, leading to iterator </cmt> <cmt> issues. </cmt> <cmt> here, the function is instead added to the nominal type decl which is </cmt> <cmt> decorated with @main.  doing so requires calling the $main function with </cmt> <cmt> the metatype for the nominal type. </cmt> <cmt> the workaround for the iterator invalidation issue which had been </cmt> <cmt> applied previously, namely changing the type of the decls member of </cmt> <cmt> sourcefile from std::vector<decl *> to smallvector<decl *, 16> is </cmt> <cmt> reverted. </cmt> <cmt> @main: allowed attribute on extensions. </cmt> <cmt> previously the @main attribute could only be applied to </cmt> <cmt> nominaltypedecls.  here, that limitation is lifted so that the attribute </cmt> <cmt> can be applied to extensiondecls. </cmt> <cmt> @main: enable main function to throw. </cmt> <cmt> se-0281 was accepted with the modification that the main function should </cmt> <cmt> be allowed to be throwing.  here support for enabling that is added. </cmt> <cmt> support is implemented in two steps: </cmt> <cmt> (1) the $main wrapper function is modified to be throwing </cmt> <cmt> static func $main() throws { </cmt> <cmt> return try main() </cmt> <cmt> } </cmt> <cmt> whenever the main function is throwing (it remains non-throwing when </cmt> <cmt> $main is not throwing). </cmt> <cmt> (2) the @main entry point is modified to be </cmt> <cmt> sil [ossa] @main : $@convention(c) (int32, unsafemutablepointer<optional<unsafemutablepointer<int8>>>) -> int32 { </cmt> <cmt> entry(%argc : $int32, %argv : $unsafemutablepointer<optional<unsafemutablepointer<int8>>>): </cmt> <cmt> %the_main_type = metatype $@thin themaintype.type </cmt> <cmt> %the_main_func = function_ref @themaintype.main() : $@convention(method) (@thin themaintype.type) -> @error error </cmt> <cmt> try_apply %the_main_func(%the_main_type) : $@convention(method) (@thin themaintype.type) -> @error error, normal success, error failure </cmt> <cmt> success(%_ : $()): </cmt> <cmt> %success_code_builtin_int32 = integer_literal $builtin.int32, 0 </cmt> <cmt> br bb1(%success_code_builtin_int32 : $builtin.int32) </cmt> <cmt> failure(%error : @owned $error): </cmt> <cmt> %_ = builtin ""errorinmain""(%error : $error) : $() </cmt> <cmt> end_lifetime %error : $error </cmt> <cmt> %error_code_builtin_int32 = integer_literal $builtin.int32, 1 </cmt> <cmt> br bb1(%error_code_builtin_int32 : $builtin.int32) </cmt> <cmt> exit(%code_builtin_int32 : $builtin.int32): </cmt> <cmt> %code = struct $int32 (%code_builtin_int32 : $builtin.int32) </cmt> <cmt> return %code : $int32 </cmt> <cmt> } </cmt> <cmt> whenever the main function is throwing (and consequently $main also is). </cmt> <cmt> in the non-throwing case, (a) the try_apply instruction is replaced with an </cmt> <cmt> apply instruction, (b) the body of the success block is appended to the </cmt> <cmt> entry block, and (c) the success and failure blocks are removed. </cmt>",attribute to add an entry point to a type.
1108,"<desc> new features others tensor transforms on gpu normalize to_grayscale vflip hflip crop center_crop pad rotate resize </desc> <cmt> add to_grayscale, normalize </cmt> <cmt> add rotate </cmt> <cmt> add vfip and hflip </cmt> <cmt> add crop center_crop </cmt> <cmt> add utils </cmt> <cmt> add utils </cmt> <cmt> update utils, add raise for some cases </cmt> <cmt> add padding, support constant, reflect, replicate, circular same as paddle.pad </cmt> <cmt> update rotate </cmt> <cmt> using utils func in [v|h]flip </cmt> <cmt> add get-image-[n,c,w,h] axis utils </cmt> <cmt> add get-image-[n,c,w,h] axis utils </cmt> <cmt> align </cmt> <cmt> update </cmt> <cmt> remove default value in utils func </cmt> <cmt> add assert for pad </cmt> <cmt> update assert paddle image </cmt> <cmt> support rotate fill func </cmt> <cmt> raise valueerror for pad </cmt>",support transforms for paddle tensor image
1109,<desc> i hereby agree to the terms of the cla available at:  disallow building uniqxxxxstates of other aggregation states detailed description / documentation draft: fixes #24461 affects all releases so i it should be backported but i'm unsure how the process works. </desc> <cmt> disallow building a uniqxxxxstate on top of another aggregation state </cmt> <cmt> fixes </cmt> <cmt> add tests for chained unique*state </cmt> <iss> crash when chaining different uniq*state </iss>,fix crash when chaining uniqstates
1110,"<desc> fixes #12771 bugfix yes no, but a deprecation filename has been moved from the asset modules generator options to the parser options. the old option will still work, but is deprecated and should be removed from docs module.parser.asset.filename or rule.parser.filename (for type asset) also in module.parser[""asset/resource""].filename removed: module.generator.asset.filename and module.generator[""asset/resource""].filename </desc> <cmt> update tooling </cmt> <cmt> move filename processing from asset generator to parser </cmt> <cmt> remove memory leak from asset generator </cmt> <iss> webpack 5 memory leak in watch mode </iss>",fix memory leak in asset generator
1111,"<desc> this is #39785 with one additional small but important thing in linking.cpp fixed -- that fixes the test that failed over there about the tbd entries. thank you @douggregor for the work! pulling here to get a toolchain going and this merged over the weekend. fix a few minor issues in the type checker and silgen to properly cope with distributed functions defined within extensions of distributed actors. while here, centralize the logic that adds the ""remote"" function. ... and since this uncovered a problem with the mangling for distributed functions, fix that, too. fixes rdar://84325525. </desc> <cmt> add support for distributed functions in extensions of distributed actors. </cmt> <cmt> fix a few minor issues in the type checker and silgen to properly cope with </cmt> <cmt> distributed functions defined within extensions of distributed actors. </cmt> <cmt> while here, centralize the logic that adds the ""_remote_"" function. </cmt> <cmt> fixes rdar://84325525. </cmt> <cmt> add test case </cmt> <cmt> use a non-conflicting mangling for distributed thunks. </cmt> <cmt> distributed thunks were using the same mangling as direct method </cmt> <cmt> reference thunks (i.e., for ""super"" calls). although not technically </cmt> <cmt> conflicting so long as actors never gain inheritance, it's confusing </cmt> <cmt> and could cause problems in the future. so, introduce a distinct </cmt> <cmt> mangling for distributed thunks and plumb them through the demangling </cmt> <cmt> and remangler. </cmt> <cmt> [distributed] fix dist thunk mangling in linking.cpp as well </cmt>",add support for distributed functions in extensions of distributed actors (fixed linking too)
1112,"<desc> resolve #78836 revert #74559 this reverts the change to use segment ordinals in composite terms aggregations due to a performance degradation when the field is high cardinality. </desc> <cmt> revert ""update docs that composite agg no longer uses global ords (#74754)"" </cmt> <cmt> this reverts commit ec799ab27e32470d6abbb1897d38693654fbe0a9. </cmt> <cmt> revert ""avoid global ordinals in composite aggregation (#74559)"" </cmt> <cmt> this reverts commit 5cfcb2f4dbcb52fae24ba44574f8eaf1bcf2299b. </cmt> <cmt> conflicts: </cmt> <cmt> server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/compositevaluescollectorqueue.java </cmt> <cmt> server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/ordinalvaluessource.java </cmt> <cmt> server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/termsvaluessourcebuilder.java </cmt> <cmt> server/src/test/java/org/elasticsearch/search/aggregations/bucket/composite/singledimensionvaluessourcetests.java </cmt>",revert 74559 (avoid global ordinals in composite)
1113,"<desc> the waitfor.js example does not work, because the twitter account used in the example doesn't exist and twitter changed the structure of their page. this should work now, i used the senchainc account as in the tweets.js example. i made some further changes to the example to display the ui change that was waited for and to exit the program if an error occurs. also added a coffeescript version. the pizza.js  example did loop through item and length as well, leading to undefined being output. (the coffeescript version does the right thing :-) ...) </desc> <cmt> use spaces throughout. </cmt> <cmt> use an existing twitter account and update name changes in new twitter. </cmt> <cmt> use shorter default timeout. </cmt> <cmt> don't throw error on timeout, use phantom.exit instead. </cmt> <cmt> change meaning of message parameter to show what has happenend. </cmt> <cmt> add coffeescript version of waitfor.js. </cmt> <cmt> loop only through divs, not length and item. </cmt>",fixes for waitfor and pizza examples
1114,"<desc> docker hub uses standard docker layer caching to cache artifacts between builds. this is different from e.g., travis, which mounts home directory folders from a cache it downloads / uploads out of line. currently, all of our builds start with a fresh maven image which has no cache at all, so every build downloads the world. we can prepare a zipkin-builder image which contains a package cache to speed up our downstream builds. after the first version of this image is pushed, i'll point the dockerfiles to use it instead of maven. this builder image would have no value if code changes caused it's docker cache key to be invalidated (the docker cache key is the file hashes computed for a given copy command, etc), so we use a special .dockerignore file to exclude as much as possible. some of the linked issues in the comments provide more background on this approach (ideally copy would accept inclusions / exclusions as arguments but there seems to be no desire to implement that in dockerfile). in this pr, i have added a skiplens property that can be used in the build to not build lens. it's used here, but i think it could be useful in general development since i know i've found myself waiting for a zipkin-lens build to finish despite not needing lens for the particular dev task. the zipkin-builder image has a special dockerignore file that attempts to only copy in pom.xml and package.json files into the build context. this means that the result of a maven build is only invalidated when these change, which is rare. this means that there would be two scenarios: a master commit that only contains code changes (no changes to pom or package.json). the zipkin-builder and zipkin builds would be started together. zipkin-builder would end without doing anything since it's cache key, which does not include code, is unaffected. zipkin will build and not download the world since it uses zipkin-builder's cached repositories. a master commit that does change pom or package.json. the zipkin-builder and zipkin builds would be started together. zipkin-builder would start from scratch, downloading the world. zipkin will start and will use the latest, now outdated, zipkin-builder when building. this means it won't download the world, but only the new dependencies since the previous one. this is pretty fast, since i notice that the majority of the world is maven itself with all its plugins, and those don't change so often. after these builds finish, following commits would go back to scenario 1 until a next set of dependency updates. downstream projects zipkin-aws and zipkin-gcp will download more stuff on scenario 1. while it'd be possible to prepare builders for each of them, i think the delta in dependencies is small enough that we don't need to worry about that (the prime culprits, maven and spring-boot will be in zipkin-builder for use by all the buildz). while it's a bit annoying having this extra image, once it's set up it should all manage itself automatically so hopefully it is not too complex. </desc> <cmt> try adding a builder image. </cmt> <cmt> finish </cmt> <cmt> comment </cmt>",add a builder docker image to use when building other images.
1115,<desc> performance optimization others getblob is very often used function and majority of it is executed under critical section so it is good to optimize it as much as possible. in this pr we add assumption that objects in cache are there e.g. we instruct compiler to generate code layout in favour of situation that objects are cached. performance improvement is x < 1% on mobilenetv1_int8 clx </desc> <cmt> first set of fixes </cmt> <cmt> - make more likely to getblob find a blobs </cmt> <cmt> - lint </cmt>,make getblob assuming elements are cached
1116,"<desc> small follow-ups to  #19935: removal of unused keyidhasher  class (comment in 19935) removal of an outdated comment, which referred to an old problem with the no longer supported boost 1.46 and boost::unordered_map, now replaced by std::unordered_map. (comment in 19935) </desc> <cmt> refactor: remove unused keyidhasher </cmt> <cmt> doc: remove outdated comment </cmt> <cmt> no longer relevant because boost 1.46 is no longer supported and </cmt> <cmt> std::unordered_map is used instead of boost::unordered_map in ccoinsmap. </cmt>",hasher cleanup (follow-up to 19935)
1117,"<desc> #243 added a single-endpoint configuration option for an elasticache replication group that used dns polling to determine when a failover had occurred. this had the drawback of requiring the application to ensure the jvm did not cache dns lookups. additionally, it left the read slave(s) of the replication group unused; only the master node would ever be queried. this pr adds an elasticachereplicationgroupserversconfig (such a long class name!) for the specification of all nodes in the replication group (as auto-discovery is unsupported in redis elasticache). a new elasticachereplicationgroupconnectionmanager then uses info replication to determine the role of each node and polls each node at a configurable interval (default: 1000ms - same as cluster polling) to determine if the role has changed. example code: public static void main(string[] args) { config config = new config(); config.useelasticachereplicationgroupservers().addnodeaddress(args); redisson r = redisson.create(config); r.flushdb(); ratomiclong al = r.getatomiclong(""testlong""); while (true) { try { system.out.println(system.currenttimemillis() +"":""+ al.addandget(1)); } catch (throwable t) { system.out.println(""exception: "" + t); t.printstacktrace(system.out); } try { thread.sleep(1000); } catch (interruptedexception ignored) {} } } output (foo-002 is promoted while program runs): java -jar test.jar foo-001.cache.amazonaws.com:6379 foo-002.cache.amonaws.com:6379 1441997395811:1 1441997396819:2 1441997397822:3 ... 1441997422911:31 exception: org.redisson.client.redisexception: readonly you can't write against a read only slave.. channel: [id: 0xddd6cc97, /10.0.x.x:42009 => foo-001.cache.amazonaws.com/10.0.y.y:6379] command: commanddata [promise=defaultpromise@644b9548(incomplete), command=rediscommand [name=incrby, subname=null], params=[testlong, 1], codec=org.redisson.client.codec.stringcodec@469956b0] ... 1441997435035:32 1441997436041:33 ... note exception still occurs for the command that was pending against foo-001 when failover happened, but will succeed on retry after the failover has been detected. </desc> <cmt> elasticache replication group server configuration </cmt> <cmt> uses ""info replication"" to determine which node is master and which are </cmt> <cmt> slaves. </cmt> <cmt> no need to invoke slavedown(). also some non-functional cleanup </cmt>",master / slave configuration for elasticache replication group
1118,<desc> add more tests for generatedkey delete invalid class named datasourceservice.java </desc> <cmt> fix bug waittoleratetimedifferenceifneed </cmt> <cmt> add maxtoleratetimedifferencemilliseconds = 10 </cmt> <cmt> rename to  assertgeneratekeywithmultiplethreads() </cmt> <cmt> add assertgeneratekey() </cmt> <cmt> rename to  assertgeneratekeywithsinglethread() </cmt> <cmt> modify assertgeneratekeywithmultiplethreads() </cmt> <cmt> add assertgeneratekey1() </cmt> <cmt> rename to assertgeneratekeywithclockcallback() </cmt> <cmt> add assertgeneratekey3() </cmt> <cmt> rename to assertgeneratekeywithclockcallbackbeyondtoleratetime() </cmt> <cmt> modify assertgeneratekeywithclockcallbackbeyondtoleratetime() </cmt> <cmt> add assertgeneratekey2() </cmt> <cmt> use     @sneakythrows </cmt> <cmt> rename to assertgeneratekeybeyondmaxsequencepermillisecond() </cmt>,add some tests for generatedkey
1119,"<desc> this p.r. adds a new optional argument to tools/test.py: --images_out_dir if specified, detection results will be plotted on the images and saved to the specified directory. it is only applicable to single gpu testing and used for debugging and visualization. you don't need a gui available in your environment for using this option. this should be an alternative solution to some issues requesting this feature (#2407 #2240 #1405) the show_result method of basedetector has been refactored to use mmdet.apis.inference. i'm not sure if this was the right approach because there was a todo comment regarding the merge. </desc> <cmt> use apis/inference in detectors show_result </cmt> <cmt> add images_out_dir arg to test apis </cmt> <cmt> include --images_out_dir in assertion </cmt> <cmt> fix single class parsing </cmt> <cmt> remove single class hack </cmt> <cmt> move import </cmt> <cmt> add example of saving results </cmt>",add option to save the result images of running tools/test
1120,"<desc> see #315. pipe and redirection are working well in my linux and windows computer. </desc> <cmt> use os.execl to ""run"" subcommand on unix </cmt> <cmt> see </cmt> <cmt> use subprocess on windows </cmt> <cmt> os.execl has strange behavior on windows. </cmt>","use os.execl to ""run"" subcommand on unix ( close #315 )"
1121,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixed wrong argument types for aggregate functions with low cardinality arguments. #4919 </desc> <cmt> remove lowcardinality from aggregate function argument types. #4919 </cmt> <cmt> added test. #4919 </cmt>,fix types for aggregate functions with low cardinality arguments.
1122,"<desc> @ctiller @nicolasnoble @tbetbetbe @murgatroid99: this is a lot of code, but aside from license headers and path renames it's a straight copy out of google-internal source control. except at the end with the tossed-in addition of the stock_pb2 file. that's temporary and todoed appropriately. </desc> <cmt> fill out the foundation package. </cmt> <cmt> add the _framework.common package. </cmt> <cmt> it's rather unimpressive at the moment with just </cmt> <cmt> one module. </cmt> <cmt> add the _framework.base package. </cmt> <cmt> add the _framework.face package. </cmt>",bring the rest of python rpc framework into grpc.
1123,"<desc> keep redirectcontroller links consistent as discussed in  change links from github.com to api.rubyonrails.org details keep redirectcontroller links consistent there are two links defined to redirectcontroller, with backticks and without them. this commit removes the link without backticks for the sake of consistency as discussed here. change links from github.com to api.rubyonrails.org the guide's guidelines do not mention anything against linking to the github repo, but it describes how to link to api.rubyonrails.org works. so i guess that it's better to link ""api.rubyonrails.org"" when is possible, for instance: classes, modules, and methods. </desc> <cmt> keep redirectcontroller links consistent. </cmt> <cmt> there are two links defined to redirectcontroller, with backticks and </cmt> <cmt> without them. </cmt> <cmt> this commit removes the link without backticks for the sake of </cmt> <cmt> consistency as discussed here: </cmt> <cmt> change links from github.com to api.rubyonrails.org </cmt> <cmt> the guide's guidelines do not mention anything against linking to the github </cmt> <cmt> repo, but it describes [how to link][] to api.rubyonrails.org works. </cmt> <cmt> so i guess that it's better to link ""api.rubyonrails.org"" when is possible, </cmt> <cmt> for instance: classes, modules, and methods. </cmt> <cmt> [how to link]: </cmt>",fix links inconsistency on active storage overview guide [ci-skip]
1124,"<desc> description: add an option to control the percentage of requests we apply fault to using http headers. see #10648 for more details. risk level: low, new functionality. testing: added unit tests docs changes: updated release notes: updated </desc> <cmt> implement abort request percentage request </cmt> <cmt> format fixes </cmt> <cmt> fix typo </cmt> <cmt> add support for 2 more headers </cmt> <cmt> update docs </cmt> <cmt> update version history </cmt>",control % of requests faults are applied to with http headers
1125,<desc> others others migrate 2.0 api example for gradients and append_backward update api into paddle 2.0 in sample code variable --> tensor refine to display doc zh doc pr: paddlepaddle/docs#2685 </desc> <cmt> modify sample code </cmt> <cmt> variable -> tensor </cmt>,[api 2.0]migrate api example for gradients/append_backward/program_guard
1126,"<desc> i started with @gjedeer 's work and then worked on making tor support more tightly integrated.  since downloadmanager does not let you set the proxy settings, i wrote a basic, custom download manager for downloading over tor.  this does not touch the video streaming at all, so with ""use tor"" enabled, video streaming will not go over tor.  that'll require exoplayer, i think. ideally, newpipe would represent the state of tor in the ui somehow.  orbot will broadcast out the status, and its easy to receive that with a broadcastreceiver.  the open question is how to represent the state of tor in the ux.  the states are off, starting, on, stopping. </desc> <cmt> test tor code </cmt> <cmt> use httpsurlconnections since youtube.com always uses https </cmt> <cmt> this helps enforce that the connection is encrypted. if for whatever reason </cmt> <cmt> an unencrypted connection is created, an exception will be thrown. </cmt> <cmt> add a title plus summary to ""use tor"" preference </cmt> <cmt> if orbot is installed, then default to using tor </cmt> <cmt> if the user has not changed the ""use tor"" preference, then the default </cmt> <cmt> should be to use tor if orbot is installed. the user can still override it </cmt> <cmt> by going an unchecking ""use tor"". </cmt> <cmt> setup tor at app start, and config immediately when pref is changed </cmt> <cmt> this adds an application subclass to get the oncreate() method, which is </cmt> <cmt> called once at the first start up of the app, before any activity starts. </cmt> <cmt> tor is configured there to ensure it is setup before anything happens. </cmt> <cmt> this also moves the ""use tor"" pref listener to a more appropriate place. </cmt> <cmt> whenever an activity resumes and tor is enabled, request it start </cmt> <cmt> this makes sure that orbot is running when the user expects it to be. if </cmt> <cmt> newpipe is configured to use tor, then going to a newpipe screen should </cmt> <cmt> ensure tor is running. </cmt> <cmt> checking on ""use tor"" when orbot is not installed starts install </cmt> <cmt> if the user turns on ""use tor"" and they are missing orbot, bring them to </cmt> <cmt> the screen to install tor. </cmt> <cmt> android provides global vars for the actual download directories </cmt> <cmt> download files via tor when tor is enabled </cmt> <cmt> downloadmanager does not let you set its proxy or change how it connects to </cmt> <cmt> the internet.  so we have to make a custom one, unfortunately.  this is a </cmt> <cmt> very basic downloader with none of the special sauce that makes the </cmt> <cmt> built-in downloadmanager handy. </cmt> <cmt> make progress notification for tor downloader  (closes #39) </cmt>",tor support for all except streaming
1127,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description so when i was working on #17434 i've seen that the read macros have hardcoded little endian and hot fixed that, now i've fixed rest of the hardcoded endianity that was left and added test on big endian ppc64 binary </desc> <cmt> add line info test, fix rest of endianity problems </cmt> <cmt> add dwarf tests for big endian </cmt> <cmt> add ppc64 register mapping </cmt>",fix big endian dwarf parsing ##bin
1128,"<desc> the interesting part of prophetnet is its decoder which can do n-gram causal language modeling. so it could be very interesting to load a pre-trained prophetnet decoder model into an encoder-decoder design with - let's say - a longformer encoder for long-range sequence modeling. due to some narrow-minded thinking on my part, this didn't work previously. from transformers import encoderdecodermodel encoderdecodermodel.from_encoder_decoder_pretrained(""allenai/longformer-large-4096"", ""microsoft/prophetnet-large-uncased"") as one can see none of pre-trained decoder weights are loaded into the model. the reason is because prophetnetforcausallm was badly modularized in prophetnetforcausallm. merging this pr would make it possible to load any prophetnet decoder into an encoder-decoder model and fine-tuning an ""build-it-yourself"" encoder decoder would become much easier, e.g.: from transformers import encoderdecodermodel import torch model = encoderdecodermodel.from_encoder_decoder_pretrained(""allenai/longformer-large-4096"", ""microsoft/prophetnet-large-uncased"") input_ids = torch.tensor([10 * [1]]) labels = torch.tensor([10 * [0]]) loss = model(input_ids, decoder_input_ids=labels, labels=labels).loss loss.backward() the above use-case might also be interesting for @ibeltagy actually. breaking changes this does introduce a pretty heavy breaking change to prophetnetforcausallm. however, the only reason this class was created was to make it useable with encoderdecodermodel and this arguably failed a bit the first time since it made it way too difficult to load pretrained prophetnet models into the encoderdecodermodel. i guess i see this more of solving a bug then ""new design"". also there are no pre-trained prophetnetforcausallm models on the model hub and i highly doubt anybody has really used this class. i want to use the same pattern for bartforcausallm and t5forcausallm, so it'd be great to get this merged even though there are some breaking changes. </desc> <cmt> improve </cmt> <cmt> finish </cmt>",make prophetnetmodel really compatible with encoderdecoder
1129,"<desc> in test_runtime_env_complicated.py there is a test that installs an environment while starting other tasks, and checks that the installation does not block the other tasks.  the assert was that ray.get() on the task should return in less than 0.1 seconds.  but in the wild, we've observed a time of 0.157s here  this pr bumps the timeout from 0.1s to 1.0s.  since environments take at least 10-40 seconds to install, even when ray is already in the pip cache, the test still behaves as intended, though if we make future optimizations that bring the env installation under 1 second, this test may start to pass spuriously. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> bump 0.1s timeout to 0.5s </cmt> <cmt> bump to 1.0 </cmt>",partially deflake test_runtime_env_complicated by bumping 0.1s timeout to 0.5s
1130,<desc> correct default return value for softap fix eclipse debug level handling </desc> <cmt> fix strange eclipse bug debuglevel not accepted when internal name to short? </cmt> <cmt> merge remote-tracking branch 'remotes/esp8266/master' </cmt> <cmt> correct default return value for softap </cmt>,correct default return value for softap + fix eclipse debug level handling
1131,"<desc> op(rank_loss) error message enhancement for both c++ and python, and provide unittest. op(similarity_focus) error message enhancement for both c++ and python, and provide unittest. op(squeeze) error message enhancement for c++. </desc> <cmt> enhance rank_loss error message, test=develop </cmt> <cmt> enhance similarity_focus error message, test=develop </cmt> <cmt> enhance squeeze error message, test=develop </cmt>","op(rank_loss, similarity_focus, squeeze) error message enhancement"
1132,<desc> related issue (if applicable): fixes # the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.5 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> use arduino esp32 1.0.5 (= espressif32 @ 3.1.0) </cmt> <cmt> use for esp32 stage git version </cmt> <cmt> disable esp32 stage as default core </cmt> <cmt> use esp32 1.0.5 release </cmt>,use esp32 1.0.5 core (release)
1133,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> add blob & file type for readfile api </cmt> <cmt> blob -> file </cmt>",addblob & file type for readfile api
1134,"<desc> fixes #170 by merging in props to link. also fixes the docs to mention that classname can be passed, which was already being merged in link. </desc> <cmt> [added] support for extra props in links, fixes #170 </cmt> <cmt> updated link docs to include the mention of aditional props </cmt> <iss> dangerouslysetinnerhtml </iss>",merge props passed to link #170
1135,"<desc> should have been only unit tests but then i realized that aspect ratio for none responsive chart was totally broken. so i decided to clean up the whole canvas initialization process and i hope to not have broken too many things :) this pr includes: correctly handles aspect ratio on chart creation (see unit tests for the many cases) properly restore initial canvas render size and overridden style on destroy fix default aspectratio for radar chart and associated samples move most of the canvas initialization in the core.controller.js new test/core.controller.tests.js currently testing ar and responsiveness (see screenshot below) new command switch to run specific tests (gulp unittest --inputs=test/core.controller.tests.js) more details in commit messages </desc> <cmt> gulp command switch to run specific test files </cmt> <cmt> add the --inputs command switch to the unittest and unittestwatch tasks, to be able to run unit tests from the specified files only (e.g. gulp unittest --inputs=test/core.element.tests.js;test/core.helpers.tests.js). </cmt> <cmt> fix initial aspect ratio when not responsive </cmt> <cmt> when responsive is false and no canvas height explicitly set, the aspectratio option wasn't applied because of the canvas default height. prevent the retinascale method to change the canvas display size since this method is called for none responsive charts, but instead make the resize() responsible of these changes. also, as discussed some time ago, moved most of the core.js logic into core.controller.js. clean up the destroy process and make sure that initial canvas values are properly saved and restored. </cmt> <cmt> fix radar default aspect ratio and samples </cmt> <cmt> now that the aspect ratio is correctly handled, fix samples for charts with aspect ratio of 1 which was vertically too large. also fix the default aspect ratio for radar charts which wasn't applied when creating a chart directly using new chart(ctx, { type: 'radar' }). </cmt>",fix aspect ratio and add responsive unit tests
1136,"<desc> it was pointed out in #23030 that we might be able to get rid of our weak linking of getauxval() (have_weak_getauxval) entirely, with only android being a potential holdout: i wonder if it's time to get rid of have_weak_getauxval. i think it's confusing. either we build against a c library that has this functionality, or not. we don't do this weak linking thing for any other symbols and recently got rid of the other glibc backwards compatibility stuff. unless there is still a current platform that really needs it (android?), i'd prefer to remove it from the build system, it has caused enough issues. after looking at android further, it would seem that given we are moving to using std::filesystem, which requires ndk version 22 and later, and getauxval has been available in the since api version 18, that shouldn't really be an issue. support for api levels < 19 will be dropped with the ndk 24 release, and according to one website, supporting api level 18+ will cover ~99% of devices. note that in the ci we currently build with ndk version 22 and api level 28. the other change in this pr is removing the include of headers for arm intrinsics, from the check for strong getauxval() support in configure, as they shouldn't be needed. including these headers also meant that the check would basically only succeed when building for arm. this would be an issue if we remove weak linking, as we wouldn't detect getauxval() as supported on other platforms. note that we also use getauxval() in our rng when it's available. i've checked that with these changes we detect support for strong getauxval() on alpine (muslibc). on linux, previously we'd be detecting support for weak getauxval(), now we detect strong support. note that we already require glibc 2.17, and getauxval() was introduced in 2.16. this is an alternative / supersedes #23030. </desc> <cmt> build: remove arm includes from getauxval() check </cmt> <cmt> then the check will work on platforms other than arm. </cmt> <cmt> build: remove support for weak linking getauxval() </cmt> <cmt> it was [pointed out in #23030]( </cmt> <cmt> > i wonder if it's time to get rid of have_weak_getauxval. i think it's confusing. either we build against a c library that has this functionality, or not. we don't do this weak linking thing for any other symbols and recently got rid of the other glibc backwards compatibility stuff. </cmt> <cmt> > unless there is still a current platform that really needs it (android?), i'd prefer to remove it from the build system, it has caused enough issues. </cmt> <cmt> after looking at android further, it would seem that given we are moving to using std::filesystem, which [requires ndk version 22 and later]( </cmt> <cmt> the other change in this pr is removing the include of headers for arm intrinsics, from the check for strong getauxval() support in configure, as they shouldn't be needed. including these headers also meant that the check would basically only succeed when building for arm. this would be an issue if we remove weak linking, as we wouldn't detect getauxval() as supported on other platforms. note that we also use getauxval() in our rng when it's available. </cmt> <cmt> i've checked that with these changes we detect support for strong getauxval() on alpine (muslibc). on linux, previously we'd be detecting support for weak getauxval(), now we detect strong support. note that we already require glibc 2.17, and getauxval() was introduced in 2.16. </cmt> <cmt> this is an alternative / supersedes #23030. </cmt>","improve gexauxval() detection, remove getauxval() weak linking"
1137,"<desc> the following commits allow micropython to build on openbsd. among other things, fixes #27. </desc> <cmt> malloc.h is obsolete. </cmt> <cmt> on openbsd map_anonymous is called map_anon. </cmt> <cmt> fix undefined termcap symbols on openbsd. </cmt> <cmt> e.g.: </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tgetnum' </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tgoto' </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tgetflag' </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tputs' </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tgetent' </cmt> <cmt> /usr/lib/libreadline.so.4.0: undefined reference to tgetstr' </cmt> <cmt> tested on linux too, works. </cmt> <cmt> mention that gnu make is required. </cmt> <cmt> does not build with bsd make. </cmt> <iss> malloc.h is obsolete </iss>",make micropython build on openbsd.
1138,"<desc> this adds an initial dataset.stats() framework for debugging dataset performance. at a high level, execution stats for tasks (e.g., cpu time) are attached to block metadata objects. datasets have stats objects that hold references to these stats and parent dataset stats (this avoids stats holding references to parent datasets, allowing them to be gc'ed). similarly, datasetpipelines hold stats from recently computed datasets. currently only basic ops like map / map_batches are instrumented. todo placeholders are left for future prs. in addition, we also collect statistics about iterator timings (time spent waiting / processing / in user code). here's a sample output of getting stats in one of the most advanced use cases: iterating over a split of a dataset pipeline in a remote task: import ray import time def pause(x): time.sleep(.0001) return x ds = ray.data.range(10000) ds = ds.map(lambda x: str(x + 1)) pipe = ds.repeat(5).map(pause).random_shuffle_each_window() @ray.remote def consume(p, stats=false): for x in p.iter_batches(): if stats: print(p.stats()) a, b = pipe.split(2) ray.get([consume.remote(a), consume.remote(b, true)]) (consume pid=723600) == pipeline window 2 == (consume pid=723600) stage 0 read: 200/200 blocks executed in 0.13s (consume pid=723600) * wall time: 117.63us min, 6.6ms max, 413.57us mean, 82.71ms total (consume pid=723600) * cpu time: 116.3us min, 6.48ms max, 380.74us mean, 76.15ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 1 map: 200/200 blocks executed in 0.3s (consume pid=723600) * wall time: 294.12us min, 2.55ms max, 918.35us mean, 183.67ms total (consume pid=723600) * cpu time: 292.68us min, 829.32us max, 554.42us mean, 110.88ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.41s (consume pid=723600) * wall time: 8.06ms min, 18.29ms max, 9.37ms mean, 1.87s total (consume pid=723600) * cpu time: 572.05us min, 3.43ms max, 992.16us mean, 198.43ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.85ms (consume pid=723600) * in format_batch(): 15.28ms (consume pid=723600) * in user code: 429.99us (consume pid=723600) * total time: 18.07ms (consume pid=723600) (consume pid=723600) == pipeline window 3 == (consume pid=723600) stage 0 read: [execution cached] (consume pid=723600) stage 1 map: [execution cached] (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.46s (consume pid=723600) * wall time: 7.97ms min, 27.64ms max, 9.79ms mean, 1.96s total (consume pid=723600) * cpu time: 592.86us min, 1.75ms max, 1.01ms mean, 201.85ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.2ms (consume pid=723600) * in format_batch(): 10.03ms (consume pid=723600) * in user code: 292.8us (consume pid=723600) * total time: 11.86ms (consume pid=723600) (consume pid=723600) == pipeline window 4 == (consume pid=723600) stage 0 read: [execution cached] (consume pid=723600) stage 1 map: [execution cached] (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.42s (consume pid=723600) * wall time: 8.04ms min, 16.93ms max, 9.48ms mean, 1.9s total (consume pid=723600) * cpu time: 662.75us min, 3.33ms max, 972.26us mean, 194.45ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.18ms (consume pid=723600) * in format_batch(): 9.98ms (consume pid=723600) * in user code: 284.75us (consume pid=723600) * total time: 11.78ms (consume pid=723600) (consume pid=723600) ##### overall pipeline time breakdown ##### (consume pid=723600) * time stalled waiting for next dataset: 2.74ms min, 701.09ms max, 491.05ms mean, 1.96s total (consume pid=723600) * time in dataset iterator: 315.69ms (consume pid=723600) * time in user code: 1.21ms (consume pid=723600) * total time: 5.0s </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> format </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> remove </cmt> <cmt> fix </cmt> <cmt> add todo </cmt> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> update </cmt>",initial stats framework for datasets
1139,<desc> @robmadole so this could be merged because upgrading.md and changelog.md are not part of the build system. i'm repeating this so maybe the next time i will remember :) </desc> <cmt> fix link to upgrading guide </cmt> <cmt> remove caravan code from the table </cmt> <cmt> caravan code didn't change and was not supposed to change because f8ff </cmt> <cmt> is the last available code in the pua </cmt>,bugfix/fix changelog and upgrading guide
1140,"<desc> this updates the release notes for the breaking changes to -usehd option and the getinfo rpc. also, bumps the manpages to current master. </desc> <cmt> doc: bump manpages to 0.15.99 </cmt> <cmt> doc: update release notes for 0.16.0 </cmt>",update release notes and manpages for 0.16
1141,"<desc> reverts #16535 and #16751 in an effort to fix #17008 and #17006, skips a runtime_env test. </desc> <cmt> revert ""[core] iterate over entire dispatch queue instead of returning when worker unavailable (#16535)"" </cmt> <cmt> this reverts commit 54d66ac6378ece17d609fae349230ca1bb341742. </cmt> <cmt> revert ""[core] [runtime env] [tests] add c++ unit test for dispatch queue nonblocking behavior (#16751)"" </cmt> <cmt> this reverts commit 13a133817b48a127830778972a71f034029573df. </cmt> <iss> [placeholder] actor creation tasks very infrequently hang (<0.05% of the time) </iss>",reverts full dispatch queue iteration prs.
1142,"<desc> description: first step to configurate lovelace from the ui, adding id's to cards in ui-lovelace.yaml related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> id is added to cards without id in ui-lovelace.yaml when loaded </cmt> <cmt> hound </cmt> <cmt> remove ui-lovelace.yaml </cmt>",adding id to lovelace cards in ui-lovelace.yaml
1143,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. </desc> <cmt> create electronic-json-storage.d.ts </cmt> <cmt> create electronic-json-storage-tests.ts </cmt> <cmt> update electronic-json-storage-tests.ts </cmt> <cmt> update electronic-json-storage-tests.ts </cmt>,type definitions and tests for electron-json-storage
1144,"<desc> bug fixes others fix and enable test_multiprocess_dataloader_static random fail fix #25265 not need to keep order if there is only 1 place check thread_done_event on read queue timeout reduce data shape to reduce share memory use for ci only have 64m in /dev/shm tested 1000 times locally, test script as follows: export cuda_visible_devices=0,1 for i in {1..1000} do echo $i make test args=""-r test_multiprocess_dataloader_static -v"" done </desc> <cmt> fix test_multiprocess_dataloader_static random fail. test=develop </cmt> <cmt> enable test. test=develop </cmt>",fix test multiprocess dataloader static
1145,"<desc> partly extracted and inspired by  the problem in #38226 is that in some corner cases multiple calls to endsnapshot were made concurrently, leading to non-deterministic behavior (beginsnapshot was triggering a repository finalization while one that was triggered by a deletesnapshot was already in progress) fix by: making all endsnapshot calls originate from the cluster state being in a ""completed"" state (apart from on short-circuit on initializing an empty snapshot). this forced putting the failure string into snapshotsinprogress.entry. adding deduplication logic to endsnapshot also: streamlined the init behavior to work the same way (keep state on the snapshotsservice to decide which snapshot entries are stale) closes #38226 note: i ran a few thousand iterations of the snapshotresiliencytests for these changes and they came back green, </desc> <cmt> fix concurrent ending step 1 </cmt> <cmt> reenable test </cmt> <cmt> nicer </cmt> <cmt> worsk </cmt> <cmt> worsk </cmt> <cmt> bck </cmt> <cmt> add asserts </cmt> <cmt> add asserts </cmt> <cmt> remove pointless assert </cmt> <cmt> cleaner </cmt> <iss> testabortedsnapshotduringinitdoesnotstart fails with classcastexception </iss>",fix concurrent snapshot ending and stabilize snapshot finalization
1146,"<desc> i wasn't aware, but it seems like next doesn't do a fresh build every time next build is run -- unchanged files that have already passed through babel are skipped on subsequent runs. unfortunately, that breaks message extraction (via babel-plugin-react-intl) in this example: on subsequent runs it'll fail to extract messages in unchanged files, leaving the list of strings shorter than it should be (or just completely empty)! this pr fixes that case by simply removing the .next directory before building. it also relaxes the requirement in the helper script forbidding duplicate message ids -- they're allowed if their corresponding messages are identical, which is the same rule enforced by babel-plugin-react-intl on a per-file basis. </desc> <cmt> remove next folder before build in with-react-intl </cmt> <cmt> relax message id requirement in with-react-intl </cmt>",fix message extraction script on consecutive builds
1147,"<desc> this pr adds support for prepending sass code before the actual entry file. it's common for developers to import their sass mixins and variables once on their project config so they don't need to import them on every file that requires it. frameworks like gatsby and nuxt.js already support that handy feature. the way it works is: /// next.config.js module.exports = { experimental: { sassoptions: { prependdata:  /// scss code that you want to be /// prepended to every single scss file. , }, }, } fixes #11617 and duplicates </desc> <cmt> add support for sass-loader's prependdata option </cmt> <cmt> add integration tests </cmt> <iss> global sass imports don't work when you use variables, mixins, functions, etc! </iss>",add support for sass-loader prependdata option
1148,"<desc> update of the rgb_led struct layout to a more efficient layout. this improves the key to led lookup complexity from o(n) to o(1), in addition, the usage of the data in the effects is simpler as it removes the need to hoist grabbing data from the struct to use in the effect and allows the compiler to optimize the loop easier. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> initial conversion of the rgb_led struct </cmt> <cmt> converting last keyboard & updating effects to take advantage of the new structure </cmt> <cmt> new struct should not be const </cmt> <cmt> updated docs </cmt>",per led (key) type rgb matrix effects - part 2)
1149,"<desc> nesting does not currently work if you set depth to something greater than one. the reason is that self.opts.depth doesn't get set on nestedmodelserializer instances before the instance checks for relationship fields within itself, so those relationship fields do not get instantiated as nestedmodelserializers themselves. def get_fields(self): # add in the default fields default_fields = self.get_default_fields() for key, val in default_fields.items(): if key not in ret: ret[key] = val for key, field in ret.items(): field.initialize(parent=self, field_name=key) return ret when get_default_fields() is called, relationship fields are instantiated as nestedmodelserializers by get_nested_field() if self.opts.depth is set. so with depth=2 let's say you have base_instance, nested_instance_level1, and nested_instance_level2. when nested_instance_level1 is instantiated by base_instance, nested_instance_level2 should also get instantiated in that moment because field processing all happens on init. in other words, when get_default_fields() is called on base_instance, all the nested instances are supposed to get instantiated recursively at that time. however, field.initialize() doesn't get called in base_instance until after get_default_fields. this means that self.opts.depth is not set on nested_instance_level1 when it calls its own get_default_fields, so its relationship fields don't get instantiated as nestedmodelserializers.  base_instance has no trouble instantiating nested_instance_level1 because we pass in ""depth"" through the serializer's meta options. the result is that only the first nesting level gets serialized no matter what you put for depth in the meta options. so two commits here. one reimplements depth handling by setting the depth on the nestedmodelserializer definition in get_nested_field(), ensuring each instance always has self.opts.depth available on instantiation. the other modifies @gkappel's depthtest so that it tests two levels of nesting. </desc> <cmt> changed depthtest to have depth=2 </cmt> <cmt> changed definition of nestedmodelserializer to correct depth handling </cmt>",fix nesting issue with depth >=2
1150,"<desc> chart, dashboard, owners, database endpoints are paginated with page_size 20 by default and setting page size to 2000 to get the full list of result change format for start date from dec 18, 2020 to 12/18/2020 01:03:44 pm  test plan manual testing requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix: start date format for executation log </cmt> <cmt> fix: paginated query </cmt>",fix start date format and paginated query
1151,"<desc> make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. add some description to dubbo-website project if you are requesting to add a feature. if this contribution is large, please follow the software donation guide. </desc> <cmt> fix addr cache bug </cmt> <cmt> fix router chain loop err </cmt>",fix semaphore usage error when calculating address.
1152,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add attachmentdata to multipart insert method </cmt> <cmt> add attachment insert method return type </cmt>",add attachment type and insert attachment method return type
1153,<desc> fixes #17693 added a test for pr #17713 closes #17713 ready for review </desc> <cmt> fixed value error for incremental pca </cmt> <cmt> fix flake8 under-indent error </cmt> <cmt> fix flake8 e127 </cmt> <cmt> one more flake8 under-indent correction </cmt> <cmt> fixed parenthesis and order of operations for mean_correction </cmt> <cmt> added test for fix incremental pca value error </cmt> <iss> incremental pca - valueerror: array must not contain infs or nans </iss>,added test for incremental pca value error fix
1154,<desc> added support to the high-level rest client for the create snapshot api call.  this required several changes to toxcontent which may need to be cleaned up in a later pr.  also added several parsers for fromxcontent to be able to retrieve appropriate responses along with tests. </desc> <cmt> progress on parsers. </cmt> <cmt> parsing successful with tests. </cmt> <cmt> more progress. </cmt> <cmt> more progress. </cmt> <cmt> more progress. </cmt> <cmt> more progress. </cmt> <cmt> added docs tests. </cmt> <cmt> docs fixes. </cmt>,add create snapshot to high-level rest client
1155,<desc> issue fixed: #3872 eventbridge trigger on localstack defaults to default event bus even though a new one is passed. </desc> <cmt> add cfn support: kms::alias </cmt> <cmt> fix issues when deploying sls template with custom event bus </cmt> <cmt> * update event::rule service model </cmt> <cmt> * update serverless and plugin version </cmt> <cmt> * update integration test </cmt> <cmt> issue fixed: </cmt> <cmt> #3872 eventbridge trigger on localstack defaults to default event bus even though a new one is passed. </cmt>,fix sls deploy event with custom bus
1156,<desc> for #3947. keep same style with junit's assertthat </desc> <cmt> use static method for sqlstatementassert </cmt> <cmt> add expected for sqlstatementassert.assertsqlstatement </cmt> <cmt> rename sqlstatementassert.assertsqlstatement() to assertion() </cmt> <cmt> add assertmessage for assertion </cmt> <cmt> remove useless sql case id </cmt> <cmt> use static assert for parametermarkerassert & tableassert </cmt> <cmt> use static assert for projectionassert </cmt> <cmt> use static assert for groupbyassert </cmt> <cmt> use static assert for orderbyassert </cmt> <cmt> use static assert for paginationassert </cmt> <cmt> use static assert for predicateassert </cmt> <cmt> use static assert for insertnamesandvaluesassert </cmt> <cmt> use static assert for altertableassert </cmt> <cmt> rename package of parametermarkerassert </cmt>,use static method for sqlstatementassert.assertis
1157,"<desc> xxxxx xxxxx xxxxx follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> add sync connect to avoid connect failed error </cmt> <cmt> support echo service </cmt>",support triple echo and fix conn bug
1158,"<desc> backport pr #31442 to beta </desc> <cmt> split dummy in region inference graph into distinct source and sink nodes. </cmt> <cmt> why do this: the regiongraph representation previously conflated all </cmt> <cmt> of the non-variable regions (i.e. the concrete regions such as </cmt> <cmt> lifetime parameters to the current function) into a single dummy node. </cmt> <cmt> a single dummy node leads dfs on a graph 'a -> '_#1 -> '_#0 -> 'b to </cmt> <cmt> claim that '_#1 is reachable from '_#0 (due to 'a and 'b being </cmt> <cmt> conflated in the graph representation), which is incorrect (and can </cmt> <cmt> lead to soundness bugs later on in compilation, see #30438). </cmt> <cmt> splitting the dummy node ensures that dfs will never introduce new </cmt> <cmt> ancestor relationships between nodes for variable regions in the </cmt> <cmt> graph. </cmt> <cmt> regression tests for issue #30438. </cmt> <cmt> fix #30438. </cmt>",split dummy-idx node to fix expand_givens dfs
1159,"<desc> various changes in support of 5 extruders (augmenting #6264) this should do the trick, completing 5 extruder support. i searched throughout the code for ""e3"" / ""e3"" and made sure that ""e4"" / ""e4"" is also included. if we want to compile a list of changes required to bump the number of extruders, combine this commit with those from #6264. config formatting cleanup apply added ubl options to all configuration_adv.h files </desc> <cmt> macros to print floats, hiding imprecision </cmt> <cmt> apply ubl mesh bounds to remaining configs </cmt> <cmt> updates to support 5 extruders </cmt> <cmt> patch configs comment formatting </cmt>",more patches for 5 extruders
1160,"<desc> feature_segwit.py has tests for some legacy wallet behavior, but otherwise does not really need the legacy wallet. those parts now require --legacy-wallet to be provided (as with other legacy wallet tests). other parts of the test are changed to work with descriptor wallets as well. </desc> <cmt> tests: use descriptors for feature_segwit multisig setup </cmt> <cmt> when setting up the multisig addresses in feature_segwit.py, use </cmt> <cmt> descriptors rather than addmultisigaddress. </cmt> <cmt> tests: restrict feature_segwit legacy wallet import tests </cmt> <cmt> a portion of feature_segwit deals with the legacy wallet ismine and </cmt> <cmt> import behavior. this is now hidden behind --legacy-wallet </cmt> <cmt> tests: add feature_segwit.py --descriptors to test_runner.py </cmt>",reduce feature_segwit.py usage of the legacy wallet
1161,"<desc> this pr changes a bunch of internal code related to data handling, but does not change public apis. adds a new object git_pool which is a paged memory allocator converts attrs and diffs to use git_pool allocator for strings converts revwalk to use git_pool for its lightweight commit objects imports new hashtable implementation from  adds two wrappers for khash tables - git_khash_str and git_khash_oid converts all usage of git_hashtable to khash tables the net effect of these changes is that we should be more memory efficient for small allocations in a number of cases, plus some of the issues with the cuckoo hashing in git_hashtable should go away (e.g. before the khash change, i could not successfully revwalk the core git repo). a note on git_pool usage: it is most appropriate to use pool allocation only when you do not have to free individual objects and want to bulk free everything when you are done. so, for example, all of the small strings that result from loading in a .gitattrbutes file or all of the lightweight commit objects that must be kept in memory during a revwalk are good scenarios. </desc> <cmt> implement git_pool paged memory allocator </cmt> <cmt> this adds a git_pool object that can do simple paged memory </cmt> <cmt> allocation with free for the entire pool at once.  using this, </cmt> <cmt> you can replace many small allocations with large blocks that </cmt> <cmt> can then cheaply be doled out in small pieces.  this is best </cmt> <cmt> used when you plan to free the small blocks all at once - for </cmt> <cmt> example, if they represent the parsed state from a file or data </cmt> <cmt> stream that are either all kept or all discarded. </cmt> <cmt> there are two real patterns of usage for git_pools: either </cmt> <cmt> for ""string"" allocation, where the item size is a single byte </cmt> <cmt> and you end up just packing the allocations in together, or for </cmt> <cmt> ""fixed size"" allocation where you are allocating a large object </cmt> <cmt> (e.g. a git_oid) and you generally just allocation single </cmt> <cmt> objects that can be tightly packed.  of course, you can use it </cmt> <cmt> for other things, but those two cases are the easiest. </cmt> <cmt> convert attrs and diffs to use string pools </cmt> <cmt> this converts the git attr related code (including ignores) and </cmt> <cmt> the git diff related code (and implicitly the status code) to use </cmt> <cmt> git_pools for storing strings.  this reduces the number of small </cmt> <cmt> blocks allocated dramatically. </cmt> <cmt> convert revwalk to use git_pool </cmt> <cmt> this removes the custom paged allocator from revwalk and </cmt> <cmt> replaces it with a git_pool. </cmt> <cmt> moving power-of-two bit utilities into util.h </cmt> <cmt> adding stash to hashtable implementation </cmt> <cmt> adding a small stash of nodes with key conflicts has been </cmt> <cmt> demonstrated to greatly increase the efficiency of a cuckoo </cmt> <cmt> hashtable.  see: </cmt> <cmt>  </cmt> <cmt> for more details. </cmt> <cmt> import khash.h from attractivechaos/klib </cmt> <cmt> convert hashtable usage over to khash </cmt> <cmt> this updates khash.h with some extra features (like error checking </cmt> <cmt> on allocations, ability to use wrapped malloc, foreach calls, etc), </cmt> <cmt> creates two high-level wrappers around khash: git_khash_str and </cmt> <cmt> git_khash_oid for string-to-void-ptr and oid-to-void-ptr tables, </cmt> <cmt> then converts all of the old usage of git_hashtable over to use </cmt> <cmt> these new hashtables. </cmt> <cmt> for git_khash_str, i've tried to create a set of macros that </cmt> <cmt> yield an api not too unlike the old git_hashtable api.  since </cmt> <cmt> the oid hashtable is only used in one file, i haven't bother to </cmt> <cmt> set up all those macros and just use the khash apis directly for </cmt> <cmt> now. </cmt>",memory pools and khash hashtables
1162,"<desc> some requests can reference index names on a remote cluster, yet most don't. when (locally) authorizing requests that can not reference remote indices, the security code takes a (cached) shortcut to first check if the request is authorized for any index, before doing the in-detail authorization on the actual indices. this pr moves the ""allows remote indices"" property to the indices request away from security code, with the goal that it's useful to non-security code as well (rather than duplicating it in the other places). nb it's rare that non-security code filters requests of different types by this property, if that exists at all. but conceptually i don't think the security code should decide which requests reference remote indices. </desc> <cmt> make allows remote indices a request property </cmt>","move ""allows remote indices"" to a request property"
1163,"<desc> @rocketchat/core closes #7408 this feature allows someone with ""view-room-administration"" permission to list all groups with the api call /api/v1/groups.list similar modifications should be done in the other groups api calls to ensure users with the proper permissions can do the same thing via api than with the web interface (such as delete & modify groups) </desc> <cmt> fix #7408 </cmt> <cmt> indent fixes </cmt>",allows admin to list all groups with api
1164,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. </desc> <cmt> added missing attributes for noble peripheral </cmt> <cmt> added new contributor name for reference </cmt>,added missing attributes for noble peripheral class
1165,<desc> with the 'receiver' as an argument and static dispatch. part of ufcs implementation (#16293). r? </desc> <cmt> allow passing self as an argument to methods </cmt> <cmt> part of ufcs (#16293) </cmt> <cmt> tests </cmt> <cmt> allow self as an arg in extension methods </cmt> <cmt> tests </cmt>,allow calling methods like functions
1166,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add types for ackextension and timesyncextension </cmt> <cmt> use new type definitions in tests </cmt>",add cometd 4.0.0 types for  ackextension and timesyncextension
1167,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ok, so this is weird, but this functionality isn't actually documented. segment support told our team about it. include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add updated types for id </cmt> <cmt> add tests </cmt>",update user().id() method to reflect undocumented functionality
1168,"<desc> updates xcode_backend.sh to use (mostly) assemble apis. this almost completes the migration, though i still need to move the asset unpack step - this is slightly more complicated due to the module format. should have no new external behavior, but does allow us to more easily wire up new features like font-subset, dart-defines, and obfuscation (which was never implemented for ios?) fyi @dnfield fixes #32925 </desc> <cmt> [flutter_tools] move ios to assemble </cmt> <cmt> fix dependencies and paths </cmt> <iss> re-implement existing ios and android build in terms of --legacy flutter assemble targets </iss>",migrate xcode_backend.sh to flutter assemble
1169,"<desc> see the commit messages for more details. </desc> <cmt> locking system overhaul, add condition variables </cmt> <cmt> this commit simplifies the locking system: ccriticalsection becomes a </cmt> <cmt> simple typedef for boost::interprocess::interprocess_recursive_mutex, </cmt> <cmt> and ccriticalblock and ctrycriticalblock are replaced by a templated </cmt> <cmt> cmutexlock, which wraps boost::interprocess::scoped_lock. </cmt> <cmt> by making the lock type a template parameter, some critical sections </cmt> <cmt> can now be changed to non-recursive locks, which support waiting via </cmt> <cmt> condition variables. these are implemented in cwaitablecriticalsection </cmt> <cmt> and waitable_critical_block. </cmt> <cmt> cwaitablecriticalsection is a wrapper for a different boost mutex, </cmt> <cmt> which supports waiting/notification via condition variables. this </cmt> <cmt> should enable us to remove much of the used polling code. important </cmt> <cmt> is that this mutex is not recursive, so functions that perform the </cmt> <cmt> locking must not call eachother. </cmt> <cmt> because boost::interprocess::scoped_lock does not support assigning </cmt> <cmt> and copying, i had to revert to the older critical_block macros that </cmt> <cmt> use a nested for loop instead of a simple if. </cmt> <cmt> condition variable for outbound connection slots </cmt> <cmt> keep a global counter for noutbound, protected with its own waitable </cmt> <cmt> critical section, and wait when all outbound slots are filled, rather </cmt> <cmt> than polling. </cmt> <cmt> this removes the (on average) 1 second delay between a lost connection </cmt> <cmt> and a new connection attempt, and may speed up shutdowns. </cmt>",condition variables instead of polling
1170,"<desc> this extends the current matthews_corrcoef to handle the multiclass case. also fixes #7929 and #8354 the extension is defined here:  (pdf is behind a paywall, but the author has a website with details here  and my implementation follows equation (2) in this paper:  the new implementation can handle both the binary and multiclass case. i've left in the original binary case implementation for now (it is a bit faster and more clear as to what is going on). i've added new tests that inspect properties of the multiclass case as well as ensure that the multiclass case reduces to the binary case. there's not much else to say. this is a pretty straight forward change. </desc> <cmt> added support for multiclass mcc </cmt> <cmt> cleaned up implementation and referenced original paper </cmt> <cmt> accidently added temporary work </cmt> <iss> why am i getting 32 bit response for confusion_matrix when all the inputs are 64 bit? </iss>",added support for multiclass matthews correlation coefficient
1171,<desc> resolve binding pattern before using it fail early if pattern binding is incorrect </desc> <cmt> [csgen] resolve binding pattern before using it </cmt> <cmt> this change makes constraint generation logic consistent with </cmt> <cmt> how patternbindingentryrequest::evaluate handles pattern binding </cmt> <cmt> entries. </cmt> <cmt> [csgen] fail early if pattern binding is incorrect </cmt> <cmt> it's possible for typechecker::typecheckpattern to produce </cmt> <cmt> either no type or type containing error. that should be detected </cmt> <cmt> early and immediately fail constraint generation. </cmt>,a couple of improvements to pattern binding handling
1172,"<desc> this pull request fixes three problems we found in buildkite pipeline 3.0. the first is a missing skip_mac variable on the brew updater step, causing that step to fail any builds started with skip_mac='true'. the second problem was that the contracts builder step had a timeout of 10 minutes, but took about 10 minutes to run. the default timeout for that step has been increased to 30 minutes. the third is that contract builders were incorrectly using the pinned u18 dockerfile. this is changed to the unpinned u18 dockerfile to match the current contracts pipeline. tested buildkite build 16702 buildkite beta build 1839 none. none. none. </desc> <cmt> add $skip_mac to ""brew updater"" step </cmt> <cmt> increase timeout of ""ubuntu 18.04 - contract builder"" step from 10 to 30 minutes </cmt>",increase contracts builder timeout + fix $skip_mac
1173,<desc> the documentation said gcc >= 8 was needed to build serenity but my current 8.3.0 didn't work. after testing i noticed gcc >= 9 was necessary so i updated the documentation. gcc-9 is only available on debian testing so i added instructions for switching to and from debian testing as well. </desc> <cmt> documentation: serenity requires gcc 9 or higher </cmt> <cmt> gcc 8.3.0 (which is the current version in debian 10 stable) seems to </cmt> <cmt> fail at building ak. new people might get stuck when they try to run </cmt> <cmt> make inside the ./build folder and fail at building serenity. </cmt> <cmt> documentation: debian gcc-9 installation instructions </cmt> <cmt> we already have installation instructions for ubuntu but not yet for </cmt> <cmt> debian. gcc-9 is not available on debian stable so instructions for </cmt> <cmt> switching to and from debian testing are added. </cmt>,updated gcc version requirement in buildinstructions.md
1174,"<desc> during our perf test against elasticsearch, we noticed two synchronized block in the call stack of fetching doc values, which i think is necessary and cause a serious gc issue for us, especially when ""size"" param is large and fetch docvalue fields. there is a synchronized block for getting from fielddatacaches map, which is unnecessary when cache != null. and getforfield method is called for every hit thus blocking at here impact performance a lot. we suggest changing to double checked locking and only do synchronize when cache==null. we see threads waiting on getforfield method in our jfr recording. gradle test all passed in my local. for reference, below is a sample query we used for testing: { ""stored_fields"": ""_none_"", ""docvalue_fields"": [""user_number""], ""size"": 33000, ""query"": { ""bool"": { ""must"": [ { ""match_all"":{} } } } } this pr links to #27350 @jasontedor @s1monw </desc> <cmt> double checked locking </cmt> <cmt> assign to cache </cmt> <cmt> one line </cmt> <cmt> add comment </cmt>",reduce synchronization on field data cache
1175,"<desc> i found a few instances http urls and made them into https urls. don't worry, i've tried and tested the new urls and they all work . in the obscure case that you go to one of these urls, i just want to let you know, rest assured, that someone spent half an hour tracking down http urls that should be https that aren't, and manually converting them to https, for your protection (psh, it's not like most browsers these days do it automatically). </desc> <cmt> update http to https in solarized </cmt> <cmt> upgrade http to https for 'burger in your shell' </cmt> <cmt> upgrade http to https for tmux.github.io </cmt>",a few minor http to https upgrades
1176,"<desc> this creates two new documents. ""jsx in depth"" attempts to describe all of jsx, covering the occasionally-relevant edge cases and weird bits. it should be a document you can go to, to get your weird jsx questions answered. ""react without jsx"" just explains how to use react without jsx. some docs in the old site are now obsoleted. ""jsx spread attributes"" and ""jsx gotchas"" along with a number of the jsx-specific tips are just part of ""jsx in depth"" now. i just removed the translations of the no-longer-there docs. dunno what else to do with them. thanks @spicyj for answering a zillion of my jsx questions in person this afternoon ;-) but still i'm sure i am mis-explaining some things here, so i'd appreciate a sharp-eyed review of this content. </desc> <cmt> get started on jsx </cmt> <cmt> fix the conflict </cmt> <cmt> change title to make downloading easier </cmt> <cmt> react without jsx </cmt> <cmt> be nicer to jsx haters </cmt> <cmt> another chunk of docs </cmt> <cmt> jsx in depth, last bit </cmt> <cmt> roll some tips into the jsx section </cmt> <cmt> fix some subtitles </cmt>",jsx in depth and react without jsx
1177,<desc> stm32h743iit6 arm cortex-m7 run in 400mhz ltdc + onborad sdram + onboard qspi flash direct drive 7 inch (1024 * 600) tft screen (tft_color_ui is now available.  other ui will be compatible and added later) </desc> <cmt> stepper driver anti reverse protection </cmt> <cmt> biqu-bx variants </cmt> <cmt> sync upstream bugfix-2.0.x </cmt> <cmt> delete anti protect to avoid conflict becasue of upstream will be added first </cmt> <cmt> restore config </cmt> <cmt> stm32h7 spi reg error </cmt>,btt skr-se-bx (stm32h743iit6 arm cortex m7) and biqu_bx_tft70
1178,<desc> just truncate name internally as in iphone to load font with path but you still need to add all fonts to .plist file another version #7557 that load font directly by path you don't even need to add it to plist file merge only one </desc> <cmt> load font v2 </cmt> <cmt> mac fonts tests </cmt>,mac custom font fix v2
1179,"<desc> introduces fontconfig, an object that isolates font-related settings in our profiles users can now define font settings in their json as so: ""font"":{ ""face"": ""consolas"", ""size"": 12 } backwards compatible with the currently expected way of defining font settings in the json, note however that upon hitting 'save' in the sui, these settings will be rewritten to the font-object style in the json (as above). #1790 closes #6049 cla signed. if not, go over here and sign the cla documentation updated. if checked, please file a pull request on our docs repo and link it here: #xxx i work here existing functionality works, new functionality works </desc> <cmt> initial </cmt> <cmt> complete </cmt>",group font options in the json into a single object
1180,"<desc> per discussion, adds context=default to file module to specify a return to default selinux context.  drops implicit behavior of reverting selinux context if se* options are removed. </desc> <cmt> add context=default option to file module </cmt> <cmt> this adjusts behavior of file module such that removal of se* option </cmt> <cmt> does not revert the file's selinux context to the default.  in order to </cmt> <cmt> go back to the default context according to the policy, you can use the </cmt> <cmt> context=default option. </cmt> <cmt> add example playbook of file module's selinux capabilities </cmt> <cmt> add another example to file_secontext.yml </cmt> <cmt> demonstrate what happens when there is no default context in the policy. </cmt>",update secontext behavior in file module
1181,"<desc> demo.mov proof of concept for ""wizard"" workflow. features: a super simple reactive store <stepcontainer> and <step> abstraction example usage: <template> <step-container :currentstep=""step""> <step :stepnumber=""1""> step 1 </step> <step :stepnumber=""2""> step 2 </step> </step-container> <button @click=""step++""> next step </button> </template> <script> export default { setup() { return { step: ref(1) } } } </script> just need to wrap your component inside <step> and pass a stepnumber prop. it uses a render function - this is a good use case for a render function, since we dynamically filter ctx.props. i think we should use templates where we can, since they give us lots of nice optimizations. </desc> <cmt> add basic store </cmt> <cmt> add step container and steps </cmt> <cmt> update yarn lock </cmt>",step abstraction wizard for unified gui
1182,"<desc> remove trailing whitespace as per the policy established by the meteor style guide. correct a minor spelling error in the find_upwards() comments. </desc> <cmt> remove trailing whitespace </cmt> <cmt> as per the ""whitespace"" section of the meteor style guide, remove trailing whitespace. </cmt> <cmt>  </cmt> <cmt> fix spelling error in find_upwards() comments </cmt>",remove trailing whitespace + fix misspelling
1183,<desc> these are unlikely to cause practical issues but after bootstrapping with fuck; fuck shellcheck gave me an error in my bashrc. </desc> <cmt> fix shellcheck sc2046 </cmt> <cmt> further reading: </cmt> <cmt> fix shellcheck 2068 </cmt> <cmt> further reading: </cmt>,fix a couple small shellcheck errors
1184,<desc> this pull request introduces /cc to search for instruction while ignoring case. (/ci is occupied but searching immediate value). this pr will help fixing rizinorg/cutter#1594 $ r2 -n /bin/true 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00001425   # 2: jmp rax 0x00001473   # 2: jmp rax 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x0000528b   # 2: jmp rcx 0x00001425   # 2: jmp rax 0x00001473   # 2: jmp rax 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x0000528b   # 2: jmp rcx </desc> <cmt> introducing /cc for case insensitive </cmt> <cmt> use r_str_ncasecmp </cmt>,introducing /cc for case insensitive instruction search
1185,<desc> add a unit test to callback pattern. assert that the callback method is called using a counter </desc> <cmt> add unit test to show that the callback method is called. </cmt> <cmt> add unit test to show that the callback method is called. </cmt>,add unit test to callback method
1186,<desc> right now we would mark sitepage as dirty because we generate contentdigest using updatedat field which isn't passed to sitepage node. </desc> <cmt> don't mark sitepage dirty if just updateat changed </cmt> <cmt> run queued queries only after oncreatenode api </cmt>,don't mark sitepage node as dirty if node data didn't change
1187,"<desc> github-pull: #20403 rebased-from: c46c18b github-pull: #20403 rebased-from: 2498b04 github-pull: #20403 rebased-from: 99d56e3 github-pull: #20403 rebased-from: ca8cd89 </desc> <cmt> wallet: refactor getclosestwalletfeature() </cmt> <cmt> don't upgrade to hd split if it is already supported </cmt> <cmt> it is unnecessary to upgrade to feature_hd_split if this feature is </cmt> <cmt> already supported by the wallet. because upgrading to feature_hd_split </cmt> <cmt> actually requires upgrading to feature_pre_split_keypool, users would </cmt> <cmt> accidentally be upgraded to feature_pre_split_keypool instead of nothing </cmt> <cmt> being done. </cmt> <cmt> fixes the issue described at </cmt> <cmt>  </cmt> <cmt> wallet: fix and improve upgradewallet result responses </cmt> <cmt> wallet: fix and improve upgradewallet error responses </cmt>","upgradewallet fixes, improvements, test coverage"
1188,<desc> this requires making several types trivial and properly initialize them whenever they are called. we can't enable this code-base wide yet due to microprofiler invoking ub on some structures. </desc> <cmt> core: silence wclass-memaccess warnings </cmt> <cmt> this requires making several types trivial and properly initialize </cmt> <cmt> them whenever they are called. </cmt> <cmt> core/cmake: enforce wclass-memaccess </cmt> <cmt> treat -wclass-memaccess as an error. </cmt>,silence wclass-memaccess warnings and enforce it
1189,"<desc> with this pr we always defer resolution of conditional types when one or both of the check and extends types are generic (as determined by typeflags.instantiable). now, only when neither is generic do we perform further assignability checks to see if we can resolve a conditional type. fixes #28824. </desc> <cmt> resolve conditional type only when check and extends types are non-generic </cmt> <cmt> accept new baselines </cmt> <cmt> add regression test </cmt> <cmt> accept new baselines </cmt> <iss> nested `exclude` has unexpected behavior </iss>",defer resolution of conditional types with generic check or extends types
1190,"<desc> closes #31469 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> reg: dataframe.__setitem__(slice) is positional, closes #31469 </cmt> <cmt> whatsnew </cmt> <iss> regr: __setitem__ with integer slices on int/rangeindex is broken (label instead of positional) </iss>","dataframe.__setitem__(slice, val) is positional"
1191,<desc> this pr makes the changes needed for #891. it also updates the documentation to reflect the change. </desc> <cmt> mark command as optional for docker run </cmt> <cmt> docs: mark command as optional for docker run </cmt>,891 mark command as optional for docker run
1192,"<desc> khronos webgl group recommend the following sequence when compiling and linking shaders: compileshader(x) compileshader(y) linkprogram(z) check for link errors (and display compilation errors as required). i.e. don't check the shader compilation status unless the link fails. this allows any inherent parallel ability of the browser to be exploited (chrome does overlap shader compilation with main thread execution) and requires fewer webgl calls, but also makes supporting the upcoming khr_parallel_shader_compile extension much easier, and reduces jank when compiling complex shaders. tested with chrome, ff, ie11, and edge. </desc> <cmt> move error checking and display </cmt> <cmt> add new webgl enum </cmt> <cmt> remove redundant param </cmt> <cmt> mereg </cmt> <cmt> only get errors when required </cmt> <cmt> minor optimisations </cmt>",rework shader compile/link error checking
1193,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #18766 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> node: remove redundant widen of query type to any </cmt> <cmt> node: rename url types for clarity </cmt> <cmt> node: add and share parsedurlquery type </cmt>",remove redundant widen of query type to any + tidy up
1194,"<desc> removes the ios8 compat setting and makes ios8 compat behavior the default one adds a setting which allows the user to disable video/pictures airplay capabilities which defaults to on by disabling the new setting from 2. and in combination with the bumped libshairplay from this pr all ios9 users can restore at least music streaming features. though ios9 users will loose any sort of metadata when streaming music (no progress/duration info, no album thumb, no artist, no album, no title). thats as far as we can get atm for ios9 clients. @martijnkaijser is it a problem to reuse those language ids? i guess until the language addons are synced users would get the old text for this setting - right? </desc> <cmt> [depends/shairplay] - updated libshairplay to the current master which supports ios9 clients (also bumped on win32) </cmt> <cmt> [airplay] - evaluate the new ""enable airplay video and pictures"" setting - this allows the ios9 users to restore at least music streaming capabilities (by disabling video/pictures support) </cmt> <cmt> [settings] - make the ios8 compatibility setting a ""enable airplay video and pictures support"" setting </cmt> <cmt> [airplay] - make ios8 compatibility mode the new default and don't use a setting for it </cmt> <cmt> [airplay] - fixed broken ""stop"" for stopping picture streaming via airplay </cmt>",restore ios 9 music streaming capability
1195,<desc> fix #9627 tensor core example:  enabling tensor core for float16 cudnn conv has been tested to provide significant speedup. </desc> <cmt> enable tensor core for conv cudnn </cmt> <cmt> fix cpplint error </cmt> <iss> need to add tensor core support for conv cudnn op </iss>,enable tensor core for cudnn conv
1196,"<desc> support for multiple pid default values was recently added, but the configuration option was never documented in configuration.h. makes this feature discoverable to users. n/a #17738 </desc> <cmt> add multiple pid defaults to configuration </cmt> <cmt> add test for multiple pid defaults </cmt>",add multiple pid defaults to configuration.h
1197,"<desc> adds buck files for nuclide integration support fixes some pzstd includes and shortens the tests a little bit </desc> <cmt> improved zstd_compressblock_opt_extdict_generic </cmt> <cmt> job_number -eq 9 </cmt> <cmt> .travis.yml: test jobs 12-15 </cmt> <cmt> .travis.yml: optimized order of short tests </cmt> <cmt> .travis.yml: different tests for ""master"" branch </cmt> <cmt> fixed </cmt> <cmt> improved #232 fix </cmt> <cmt> add buck files for nuclide support </cmt> <cmt> clean imports and shorten tests </cmt> <cmt> * dev: </cmt> <cmt> updated news </cmt> <cmt> fixed msan warnings in legacy decoders </cmt> <cmt> fix cmake build </cmt> <cmt> updated news </cmt> <cmt> edits as per comments, and change wildcard 'x' to '?' </cmt> <cmt> fix visual studios project </cmt> <cmt> fix pool.c threading.h import </cmt> <cmt> fix zstdmt_compress.h include </cmt> <cmt> fixed commented issues </cmt> <cmt> updated format specification to be easier to understand </cmt> <cmt> improved #232 fix </cmt> <cmt> fixed </cmt> <cmt> .travis.yml: different tests for ""master"" branch </cmt> <cmt> .travis.yml: optimized order of short tests </cmt> <cmt> .travis.yml: test jobs 12-15 </cmt> <cmt> job_number -eq 9 </cmt> <cmt> improved zstd_compressblock_opt_extdict_generic </cmt> <cmt> revert unnecessary change to logging.h </cmt>",add buck files for nuclide integration
1198,"<desc> note that i have changed the security handshaker code to accept a read buffer containing leftover bytes read by the generic handshakers, but i haven't bothered to allow passing leftover bytes from the security handshaker to the transport code.  i think that shouldn't be necessary, because the security handshakers all create wrapped endpoints, so they handle the leftover bytes internally.  (of course, this issue will go away once we get around to converting the security handshakers to use the new api.) this is yet another small piece of #7507. </desc> <cmt> change handshaker api to use a read buffer to pass leftover bytes read </cmt> <cmt> between handshakers. </cmt> <cmt> updated tests. </cmt> <cmt> clang-format </cmt>",change handshaker api to support passing leftover bytes read between handshakers.
1199,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. hello! naver whale is chromium based browser. this browser has a slightly different extension api than the existing browser. check this this code is based on chrome/index.d.ts. removing and adding some definition. the comment i added are in korean. because it only supports korean in official documents. </desc> <cmt> add new package: naver-whale </cmt> <cmt> change ts version </cmt>",adding types for naver whale extension
1200,<desc> i hereby agree to the terms of the cla available at:  fix cannot find column error for queries with sampling. was introduced in #24574. fixes #26522 </desc> <cmt> fix unknown column bug in sampling. </cmt> <cmt> fix unknown column bug in sampling. </cmt> <iss> 21.7+ cannot find column in source stream in a query with sampling </iss>,fix unknown column with sampling
1201,<desc> been using these types on a project for work for the last ~3 weeks. have been going well so far! </desc> <cmt> added stripe-node typings for webhook verification </cmt> <cmt> - see example on the stripe-node github for webhook signing here: </cmt> <cmt> updated stripe-node types version </cmt>,stripe-node updated typings for webhook verification
1202,"<desc> added a bigquery operator to transfer data to google cloud storage. also added a hook for gcs, and an operator to download files from gcs to local file system. </desc> <cmt> add bigquery to google cloud storage operator. </cmt> <cmt> more documentation for bigquery to gcs operator. </cmt>",bigquery and google cloud storage operators
1203,<desc> since esp32 build variants are normal builds. activating esp32 build variant selection moved to platformio_tasmota32.ini so all esp32 standard definitions are there. all variants can now be builded without changing setup files. platformio_override.ini is now needed only for special use cases the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> update platformio.ini </cmt> <cmt> make selecting esp32 versions possible </cmt> <cmt> without using override file </cmt>,move esp32 build variants selection out of pio override file...
1204,<desc> we are checking device names in addition to major/minor numbers to ensure we distinguish devices from each other. fixes #10841 component name diskstats module of proc plugin check if all diskstats charts are available for all disks in the system. verify if the names of charts and families are correct. </desc> <cmt> check disk name in mountinfo </cmt> <cmt> check disk name when searching for the disk </cmt> <cmt> check disk name on renaming </cmt> <iss> incorrect disk identification in the diskstats plugin </iss>,check device names in diskstats plugin
1205,"<desc> hello, i already made a pr some time ago (pr #1713) that allows to install module from .tgz packages (generated with the npm pack command). but there is a little issue: when updating a package with the pm2 install foo.tgz command, it does not updates the package and it starts a new instance of the already installed package. this pr fixes this issue. regards, </desc> <cmt> do not display output on pm2_silent </cmt> <cmt> pm2_silent </cmt> <cmt> upgrade yamljs to 0.2.7 </cmt> <cmt> npm publish 1.1.1 </cmt> <cmt> fix: allows to update an installed module from a tgz package </cmt>",allows to update packages from tarball generated with 'npm pack'
1206,"<desc> this pr is for the gatsby-image plugin. placeholders and layout-adjusting elements are unnecessary in the accessibility tree, so i have removed them using the aria-hidden attribute. this prevents assistive technologies from recognizing blank elements.   fixes #20181 </desc> <cmt> fixed </cmt> <cmt> fixed index and added testing </cmt> <iss> [gatsby-image] fluid image has a blank accessibility element </iss>",added aria-hidden attribute to layout elements
1207,<desc> this will resolve issues around circular dependency management. it will also make sure that the integration_test package is tied tightly to api changes in the flutter sdk at a specific version. @nturgut @yjbanov @jonahwilliams </desc> <cmt> migrate integration_test to flutter repo </cmt> <cmt> run the tests </cmt>,move package:integration_test to flutter/flutter
1208,"<desc> hello, i humbly request that my nordic layout for the ut47 be merged with the main repository. i've played around with it and made some changes i think would be valuable to other nordic ut47 users out there. a basic description of the layout, in addition to a somewhat large .png file with an overview of the keymap is included in the readme.md file. as a side note: my experience with keymap files is quite limited, and there is a chance that my code can be trimmed (especially at the top in the definitions), any suggestions are welcome. thank you for your time! </desc> <cmt> pulling updated master </cmt> <cmt> add files via upload </cmt> <cmt> added a nordic layout for ut47 </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> add files via upload </cmt> <cmt> update to readme and keymap files </cmt> <cmt> update readme.md </cmt> <cmt> changed cover image </cmt> <cmt> update readme.md </cmt> <cmt> typo fix </cmt> <cmt> delete config.h </cmt> <cmt> delete keymap.c </cmt> <cmt> delete readme.md </cmt> <cmt> delete rules.mk </cmt>",adding a nordic layout for ut47
1209,<desc> fixes #8827 some baselines unrelated to the changes i made have been modified or even deleted. for example report an error when compiler-options input is empty object.errors.txt was deleted but i can't seem to locate the test even in master. </desc> <cmt> add new error for rest parameters </cmt> <cmt> add error message for rest parameter properties </cmt>,new rest parameter properties error message
1210,"<desc> use public paths in module augmentation test documented module augmentation / we have a notion of what we consider ""public paths"". however, this does not apply to type imports which makes it harder to teach (""ok here, but not ok there""). since we already make types public by documenting that the paths are public we might as well export them directly which means we can simplify how we teach public paths. the existing patterns continue to work but are more likely to break during refactoring. the patterns we now document are tested in ci and therefore a lot more robust. implementation choices separate script does not slow down test:unit allows parallel testing (which we haven't set up for mocha) can be included in test suite that runs with typescript nightlies </desc> <cmt> [core] simplify module augmentation </cmt> <cmt> test in ci </cmt>",support public paths in module augmentation
1211,"<desc> with this pr, when a node is the left hand expression of a property access, element access, or call expression, and the type of the node includes type variables with constraints that are nullable, we fetch the apparent type of the node before performing control flow analysis such that narrowings apply to the constraint type. for example: type item = { (): string; x: string; } function f1<t extends item | undefined>(obj: t) { if (obj) { obj.x;     // ok obj[""x""];  // ok obj();     // ok } } prior to this pr, the property access, element access, and call expressions above were errors. fixes #14091. fixes #14415. </desc> <cmt> obtain apparent type before narrowing type variables </cmt> <cmt> new behavior only for type variables with nullable constraints </cmt> <cmt> add tests </cmt>",improve type guards for type variables
1212,"<desc> please merge both commits separate. first commit: refactored the api layer: do not handle api response after pipelining this has a big underlying problem each task in the pipeline can modify the options e.g. add a proper permission context if we chain after the pipeline, we don't have access to the modified options object and then we pass the wrong options into the tojson function of a model the tojson function decides what to return based on options this is the easiest solution for now, but i am going to write a spec if we can solve this problem differently if we want to use the tojson function to determine which model fields to return, we cannot do that without this change! note: i thought about a util for the response format, but i decided against at the moment, because i am not sure if we have to change a fundamental concept of how the api works (who returns what, who returns json, how do we guarantee that the options object is everywhere accessible, how are headers generated etc.). see for example this here - it only happens because the outer api level wants to add headers based on the state of a model. second commit: removed bypassing option filtering in user model the tests were red on the first and i investigated why i had to create a pr with both commits, because the second commit is a result of the correctness of the first commit the logic in the user model bypasses filtering options! that is wrong, because if we filter out certain options e.g. include the tests from the previous commit fail because of this if we don't fix this logic, the tests won't pass, because as said, you can bypass certain logic e.g. remove roles from include this has worked before, because we passed the wrong options via the api layer was introduced here 014e2c8, because of #6122 add proper tests to proof that these queries work!! </desc> <cmt> refactored the api layer: do not handle api response after pipelining </cmt> <cmt> no issue </cmt> <cmt> - this has a big underlying problem </cmt> <cmt> - each task in the pipeline can modify the options </cmt> <cmt> - e.g. add a proper permission context </cmt> <cmt> - if we chain after the pipeline, we don't have access to the modified options object </cmt> <cmt> - and then we pass the wrong options into the tojson function of a model </cmt> <cmt> - the tojson function decides what to return based on options </cmt> <cmt> - this is the easiest solution for now, but i am going to write a spec if we can solve this problem differently </cmt> <cmt> removed bypassing option filtering in user model </cmt> <cmt> no issue </cmt> <cmt> - the logic here bypasses filtering options! </cmt> <cmt> - that is wrong, because if we filter out certain options e.g. include </cmt> <cmt> - the tests from the previous commit fail because of this </cmt> <cmt> - if we don't fix this logic, the tests won't pass, because as said, you can bypass certain logic e.g. remove roles from include </cmt> <cmt> - this has worked before, because we passed the wrong options via the api layer </cmt> <cmt> - was introduced here </cmt> <cmt> - add proper tests to proof that these queries work!! </cmt>",api layer refactoring && avoid bypassing filtering options in user model
1213,"<desc> updated the pinout for the rgb led strips for the saturn60 updated the layouts because there were major changes to the pcb electrical matrix added more keymaps to cover the main layouts and updated via keymap updated the info.json file for the qmk configurator to support the new available layouts my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added iso, utilitarian layouts and updated rgb pin position </cmt> <cmt> added info.json and added updated keymaps </cmt> <cmt> [keymap] updated tsangan keymap and added birgus special </cmt>",titan60 led and keymap updates
1214,"<desc> this pr has two changes to the pins_cohesion3d_remix.h file: an sd card section was added.  if sdsupport and lpc_sd_onboard are enabled in the config files then the onboard sd card will be available to both the usb virtual disk and to marlin.  the lcd's sd card can not be made available because this card uses the same spi pins for both sd cards. a fysetc minipanel 12864 section was added.  a custom exp2 cable is required because the sck and mosi on the card's exp2 connector are shared with the onboard sd card.  if rgb operation is required then a custom exp1 cable is needed because the card's exp1 connector doesn't run signals to the rgb pins.  all custom pins come from the ethernet connector. also added logical pin maps for the ethernet, exp1 and exp2 connectors. </desc> <cmt> 1) enable onboard sd card acess, 2) add fysetc minipanel 12864 pins </cmt> <cmt> set the neopixel pin to the correct pin </cmt>","cohesion 3d remix onboard sd card, fysetc minipanel"
1215,"<desc> to fix some ci failures. for details see the commit messages </desc> <cmt> cmake: fix a libswift bootstrapping problem with -enable-array-cow-checks </cmt> <cmt> the checks must not be enabled in the first 2 bootstrapping stages. </cmt> <cmt> revert ""disable cow checks for some bots to unblock ci"" </cmt> <cmt> this reverts commit fb77d2ea4e25bb6822e78e274c9c05a3a67073be. </cmt> <cmt> cmake: clean bootstrapping modules when compiling with boostrapping-with-hostlibs </cmt> <cmt> in this build mode there must not be a swiftmodule in the bootstrapping directories. </cmt> <cmt> in case such a module is there from a previous ""bootstrapping"" build, give a warning and remove it. </cmt> <cmt> build-presets: don't fully bootstrap when doing a check-incremental on the stdlib </cmt>",fix some problems related to bootstrapping
1216,<desc> really simple so don't need a readme notes </desc> <cmt> added definitions for source-map-support </cmt> <cmt> added definitions for detect-indent </cmt> <cmt> added definitions for open </cmt> <cmt> added definitions for exit </cmt> <cmt> added definitions for mkdirp </cmt> <cmt> added definitions for gracefull-fs </cmt> <cmt> added definitions for jsesc </cmt> <cmt> added definitions for assertion-error </cmt> <cmt> added definitions for buffer-equal </cmt>,added definitions for a batch of small npm modules
1217,<desc> fixes a failure of proj.android/build_native.py when there are spaces in the folder path. </desc> <cmt> updates </cmt> <cmt> fixed failure in call to make when the android app folder contains spaces in the path. </cmt>,android build_native.py with spaces in path
1218,<desc> this pr resolves the issue #35628. the two places where there were descriptions about returned params were inconsistent. i have made them consistent w.r.t. code. </desc> <cmt> untracked files </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> stack dump detached </cmt> <cmt> gradient doc changed </cmt>,gradient doc changed to accurately show the returned params
1219,<desc> backport 46062 - fix calling deprecate with correct arguments to 2.6 basic.py ansible version ansible 2.6.7 </desc> <cmt> fix calling deprecate with correct arguments (#44726) </cmt> <cmt> this fixes #44702 </cmt> <cmt> (cherry picked from commit 66eec42f53462e931030b26011054acdcb1febcc) </cmt> <cmt> backport pr#44726 - fix deperecate call </cmt>,backport/2.6/44726 fix calling deprecate with correct arguments
1220,"<desc> (replaces #369) fixing several merge issues: sidebar width:  selectbox on sidebar:  deck height:  graphviz charts are centered instead of left-aligned a lot of elements are now wider than they used to be. sidebar color vegalite chart width broken message_deduping.py e2e test bad media breakpoint in sidebar.tsx get dataframe(..., height=foo) working again </desc> <cmt> fix cypress test </cmt> <cmt> fix margin problem </cmt> <cmt> restore defaultpropsfor deckglchart </cmt> <cmt> restore padding </cmt> <cmt> fixing popover </cmt> <cmt> fix sidebar widget z-index without hack </cmt> <cmt> center icons </cmt> <cmt> fix ""for teams"" url </cmt> <cmt> temporary fix for graphviz chart alignment. </cmt> <cmt> don't use two-letter class name ""oi"" for open iconic as it can clash with styletron </cmt> <cmt> fix sidebar color when screen is narrow </cmt> <cmt> fix left and right padding in main content area. </cmt> <cmt> fix sidebar expand/collapse icon color. </cmt> <cmt> fix vegalite chart dimensions </cmt> <cmt> fix message_deduping e2e test, and rename .stfullscreenframe to .fullscreenframe since it's not an st element. </cmt>",fix broken code from typescript pr
1221,"<desc> this pr makes the tf transfoxl model compliant with amp. all the slow tests are passing as well for these models. these two models cannot be xla compliant for now, as it seems that tf.where cannot be used in xla if the x and y parameters are none. see the _get_global_attn_indices method which has this case. i have opened an issue on the tf repo in order to ask if it is an expected behavior or a bug. </desc> <cmt> fix amp </cmt> <cmt> apply style </cmt>",making tf transfoxl model compliant with amp
1222,"<desc> this pr adds three things, refactors the socket and h2o_conn_t, adding get_peername callback to obtain the peer address (instead of providing a pointer to struct sockaddr) adds get_sockname callback to obtain the local address the fastcgi handler uses get_sockname callback to build server_addr and server_port properties of fcgi_params amends #346 </desc> <cmt> provide callback for obtaining peer address _and local address_ </cmt> <cmt> emit server_addr and correct server_port to fcgi_params </cmt>",provide getsockname and getpeername wrappers (send server_(addr|port) to fastcgi)
1223,"<desc> note that this is an api change for 5.0.0, but fixes compatibility with the 4.1 branch. see pull request #2971. </desc> <cmt> add rowattributes getter to pageiterator </cmt> <cmt> [sw]: cherry-picked commit from 4.1 branch </cmt> <cmt> format code with clang-format </cmt>",add rowattributes getter to pageiterator and format code
1224,"<desc> going through the tests in tests/scalars, tests/indexes/datetimes, tests/indexes/timedeltas, tests/indexes/period, there is a lot of duplication and a lot of thematically inappropriate placement.  this is a natural result of tests being added over the years. one result of this, though, is that its easy to miss certain corner cases (#17991, #7996). there are two things i'd like to do here.  first is gather tests specific to tslibs modules so they can be self-contained.  this pr starts that for tslibs.parsing. second is to go through tests.indexes centralize arithmetic tests, deduplicate where needed (#18026).  this is a big task without an immediate payoff, so i want to get the go-ahead before jumping in. tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> move tests specific to tslibs.parsing </cmt> <cmt> whitespace cleanup </cmt>",separate tests specific to tslibs modules
1225,"<desc> step 1 in the compatibility steps for the manylinux / pip10 conversion next step - drop vendored pip9, patch and vendor pip10 </desc> <cmt> drop cacert.pem copy task from vendor script </cmt> <cmt> update patched version of pip-tools for vendoring </cmt> <cmt> update piptools patch </cmt> <cmt> update patches </cmt> <cmt> revendor piptools for update </cmt>",update piptools (work in progress)
1226,"<desc> in setup where resources are distributed into nested stacks, api gateway resource may not be present in main stack. with #7663 we've changed behavior, and assume there's no api gateway if it doesn't appear in main stack. still it broke for services relying on e.g. serverless-plugin-split-stacks plugin. this patch ensures that if there are http events configured we unconditionally attempt to find the rest api id and it's deployment. additionally improved configuration check to be based on deployment id and not just rest api id (if there's no deployment, then we're also incapable on applying any stage settings) </desc> <cmt> fix(aws api gateway): improve configuration validation </cmt> <cmt> confirm on deployment not just rest api </cmt> <cmt> fix(aws api gateway): fix handling stage settings when in nested stack </cmt> <cmt> uncoditionally search for rest api if http events are configured </cmt>",fix handling of stage specific setting for split stacks case
1227,"<desc> it seems that all bounds in type aliases are entirely ignored, not just type bounds. this extends the warning appropriately. i assume this should be made a hard error with the next epoch? i can't see any reason to accept these programs. (and suddenly enforcing these type bounds would be a breaking change.) </desc> <cmt> clarify 'trait bounds ignored' wording </cmt> <cmt> warn about more ignored bounds on type aliases </cmt>",warn about more ignored bounds in type aliases
1228,"<desc> this series of commits deals with broken links to the source code. it also refactors some repetitive codes from rustdoc. the most important commit, 1cb1f00, describes the rationale; this will fix a half of #16289. other commits are reasonably independent to each other and can be made into indiviudal prs at the request. notes on the broken source links as of bda97e8 (i've used this to check the pr works as intended), there are 281 (!) such broken links. they can be further classified as follows: 178 links to incorrect item types. this is the first half of #16289, and this pr fixes all of them. 89 links to redirect pages. they are not technically ""broken"" but still doesn't give a source code. i have a fix for this in mind, which would make a redirect page slightly fat. 14 links to incorrect defid in the gotosrc parameter. this is #15309, and affects many liballoc reexports in libstd but nothing else (curiously). i'm yet to track this down; might be a metadata bug (not sure). 0 links to the crate reexported as a different name. this is the second half of #16289, and seems not hard to fix but i'm running out of time. prevalence of this kind of bugs calls for a full link verifier integrated into the testing process. :s </desc> <cmt> rustdoc: fixed a missing rendering of foreignstaticitems. </cmt> <cmt> rustdoc: refactored various uses of itemtype. </cmt> <cmt> in particular, itemtype variants are no longer reexported. since </cmt> <cmt> we already do namespace them via item_type mod, it's fine. </cmt> <cmt> rustdoc: removed foreign{function,static} item types. </cmt> <cmt> they are just (unsafe) functions and static items to most users </cmt> <cmt> and even compilers! the metadata doesn't distinguish them, so rustdoc </cmt> <cmt> ended up producing broken links (generated ffi.*.html, links to </cmt> <cmt> fn.*.html). it would be best to avoid this pitfall at all. </cmt> <cmt> rustdoc: avoid rendering foreign items to the sidebar. </cmt> <cmt> otherwise the generated documentation is 30% larger. the sidebar </cmt> <cmt> renders an entry for each item to all items, so large modules have </cmt> <cmt> o(n^2) items rendered in the sidebars. not a correct solution, but </cmt> <cmt> at least it works. </cmt>","remove foreign{function,static} item types"
1229,"<desc> previously: a node was considered an orphan if there were no inbound edges of any kind. however, all edges could be cyclic, with no path to the root. now: if the graph has a root node and there is a path to the root node, then it will not be considered an orphan. test plan: added unit tests note: this slows bundling down by 2.5x, but so far bundling seems to be the only thing impacted on the initial build. we will follow with performance optimization for bundling. </desc> <cmt> isorphanednode checks for path to root </cmt> <cmt> iterate nodes to copy instead of traversing </cmt>",isorphanednode checks if there is a path to the root
1230,"<desc> resolves #150. this pr introduces a solution to the long-standing problem of wanting to use @apply with classes that don't exist in the same css tree. this issue most commonly comes up when someone is working with vue and wants to use @apply in the <style> block of a single file vue component. it seems like basically every vue project is setup to run postcss on every <style> block independently instead of on the final concatenated css, which means if you have 100 components, tailwind is run 100 independent times, and each run is isolated and can't see any of the classes in the other runs. this pr solves this by always generating all of tailwind's utilities (including those registered by plugins) and using it as a fallback table for @apply if the class can't be found. i'm not ready to fully commit to this without getting folks to try it out and report feedback, so this pr only enables this functionality if you add an experiments key to your tailwind config file: module.exports = { // ... experiments: { shadowlookup: true } } because this is an opt-in experiment, it's going to remain undocumented outside of this pr for now, and i reserve the right to yank it or break it without following semver, so please don't rely on this functionality for production sites right now, just test it out locally and give me your feedback. </desc> <cmt> fallback to shadow table </cmt> <cmt> refactor duplication </cmt> <cmt> only enable shadow lookup if shadowlookup experiment is enabled </cmt> <iss> consider not relying on previously defined mixin in file for ""@apply"" </iss>",allow @apply-ing utility classes that aren't explicitly defined but would be generated
1231,"<desc> description: reland: #67155 fixes analysis error caused by landing of material migration, and g3 error caused by moving of fuchsia lib. </desc> <cmt> [null-safety] migrate app dependencies of flutter driver </cmt> <cmt> remove wrong headers </cmt> <cmt> update analysis_options.yaml comment </cmt> <cmt> update web smoke test </cmt> <cmt> fix cirrus yaml </cmt> <cmt> fixes for material migration and g3 </cmt>",migrate app side flutter driver to null-safety
1232,"<desc> this pr adds the abilility to override custom extension attributes during merging. this will only work for attributes that are writable, i.e. attributes registered with a default value like default=false or attribute that have both a getter and a setter implemented. token.set_extension('is_musician', default=false) doc = nlp(""i like david bowie."") with doc.retokenize() as retokenizer: attrs = {""lemma"": ""david bowie"", ""_"": {""is_musician"": true}} retokenizer.merge(doc[2:4], attrs=attrs) assert doc[2].text == ""david bowie"" assert doc[2].lemma_ == ""david bowie"" assert doc[2]._.is_musician enhancement i have submitted the spacy contributor agreement. </desc> <cmt> add helper to check if underscore attr is writable </cmt> <cmt> allow overwriting extension attributes during merging (see #3314) </cmt> <cmt> validate extensions first and fix bulk merge </cmt> <cmt> fix whitespace </cmt> <cmt> support custom attributes in retokenizer.split </cmt>",allow setting of custom attributes during retokenization (closes #3314)
1233,"<desc> also covers all related articles (bael-3976) all tests pass (all manual) added docker command line in comments in each test to be up and runing quickly upgraded code and dependencies to spring-data-elasticsearch-4.0.0 (released last week) and elastic search 7.6.2. caot be more up to date than that. </desc> <cmt> upgraded libs, moved to resthighlevelclient </cmt> <cmt> fixed tests </cmt> <cmt> fixed tests </cmt> <cmt> fixed format </cmt> <cmt> removed articleservice </cmt> <cmt> fixed most tests </cmt> <cmt> fixed mapping and tests </cmt> <cmt> fixed formatting according to eclipse formatter </cmt> <cmt> upgrade to 4.0.0.release </cmt> <cmt> added back elasticsearch dependency </cmt> <cmt> removed unecessary dependencies </cmt> <cmt> removed unecessary dependencies </cmt>",bael-3676 fix failing manual test in sping-data-elasticsearch module
1234,"<desc> pr for issue #3788 current implementation adds a new jsxnamespace compile option that can specify the jsx namespace (factory) when jsx mode is react. --jsx react --jsxnamespace mydomlib results in emits being mydomlib.createelement i was thinking an alternative would be to just use the existing --jsx option where ""preserve"" and ""react"" are special reserved values. in this setup the above would be achieved by just doing -- jsx mydomlib </desc> <cmt> initial check in - support other jsx factories issue #3788 </cmt> <cmt> - added jsxnamespace compile option </cmt> <cmt> - when jsx mode is ""react"", jsxnamespace optionally specifies the emit namespace for react calls, eg ""--jsxnamespace mydomlib"" will emit calls as mydomlib.createelement (instead of react.createelement) </cmt> <cmt> - symbol specified by jsxnamespace must be present, else compile error is generated (same handling as is done for react symbol when no jsxnamespace is specified) </cmt>",support for other jsx factories
1235,<desc> fixes issue: #2528 added search parameters for the following files: binomial coefficient boolean parenthesization box stacking coin change edit distance </desc> <cmt> add search parameters for binomial coefficient </cmt> <cmt> add search parameters for boolean parenthesization </cmt> <cmt> add search parameters for box stacking </cmt> <cmt> add search parameters for coin change </cmt> <cmt> add search parameters for edit distance </cmt>,add search parameters for some dp problems
1236,"<desc> i had somehow missed #4510 and was a bit surprised to find out about this undocumented hack to get featuregroup to work. thinking about it, i think the approach in itself is sane, but the real problem lies in the naming of the event property - layer is very specific to featuregroup's utilization of the property. on the other hand, there's probably a lot of code out there that use this property, so i'm going for deprecating this property, although actually removing it is not something we need to do soon. instead, i added two properties: sourcetarget - this is the original target of the event, the object it was first fire on before any propagation occured propagatedfrom - this is exactly the same as the current layer; that is, the previous object in the chain of object propagating the event (to be honest, i don't feel 100% about the name of this property, so feel free to suggest a better one) ideally, we should have made this analog to the dom's target and currenttarget, but we already use the property target with the same semantic as the dom's currenttarget, so that will unfortunately not work. </desc> <cmt> add sourcetarget and propagatedfrom to events </cmt> <cmt> also documents events' target, sourcetarget, propagatedfrom </cmt> <cmt> and layer properties. </cmt> <cmt> fixes #4510. </cmt> <cmt> use propagatedfrom, which is equivalent of the original code </cmt>",clean up and document event propagation properties
1237,"<desc> let security_connector mange the pending handshakes on server side remove tcp argument in handshake_done callback signature add a security_connector_shutdown api add a handshake_shutdown api to shutdown tcp do nothing if handshake_done with ok status and null endpoint </desc> <cmt> move pending tcp management from server to connector </cmt> <cmt> make security_connector manage pending handshaker, while handshaker owns tcp </cmt> <cmt> format </cmt>",refactor security connector and handshake
1238,"<desc> allow using a custom host name for endpoints and health checks. this enables auto host re-write to work with eds risk level: low, new opt in field. testing: unit tests docs changes: inline docs in the protocs. release notes: added to version_history.rst fixes #10408 </desc> <cmt> code </cmt> <cmt> test </cmt> <cmt> fromat fix </cmt> <cmt> format </cmt> <cmt> unit test </cmt> <cmt> version history </cmt> <iss> eds: support auto host re-write </iss>",introduce hostname for endpoints and health checks
1239,"<desc> easy answers to where tslib.ints_to_pytimedelta and tslib.normalize_date belong, so this moves those. starts populating the tslibs.__init__ namespace; leaves updating imports for later. cleans up a couple of unnecessary imports elsewhere. </desc> <cmt> move ints_to_pytimedelta, normalize_date, fixup imports and tests </cmt> <cmt> extra import </cmt>","implement tslibs.__init__, move easy bits of tslib"
1240,<desc> description: adds rtsp stream support for uvc (unifi video client) integration. returns 1 of the 3 rtsp uris that already existed in the camera object; prioritizes highest quality rtsp stream from the available enabled streams. **pull request with documentation for home-assistant.io (if applicable): not needed. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: </desc> <cmt> add support_stream to supported_features. </cmt> <cmt> implement stream_source with channel rtsp uris. </cmt> <cmt> add tests for stream support. </cmt> <cmt> make stream_source async. </cmt> <cmt> removed unused import. </cmt>,add rtsp stream support for uvc (unifi video client) integration
1241,<desc> adds a websocket command to fetch the openzwave network statistics local tests pass. your pr cannot be merged unless tests pass i have followed the development checklist the code has been formatted using black (black --fast homeassistant tests) i have reviewed two other open pull requests in this repository. </desc> <cmt> add network_statistics websocket command </cmt> <cmt> add tests </cmt>,add ozw network_statistics websocket command
1242,"<desc> i hereby agree to the terms of the cla available at:  changelog category: translation for #9983 </desc> <cmt> docsup-1062 (#112) </cmt> <cmt> * added first draft </cmt> <cmt> * minor fixes </cmt> <cmt> * fixed anchors </cmt> <cmt> * yet another fixes </cmt> <cmt> * and the minorest fixes </cmt> <cmt> * apply suggestions from doc review </cmt> <cmt> * fixed terminology in ru (access entity, throws exception) </cmt> <cmt> * fixed typo </cmt> <cmt> * fixed typo </cmt> <cmt> fixed link. </cmt> <cmt> clickhousedocs-626: fixed links. </cmt>","en review, ru translations for rbac docs"
1243,<desc> this updates the gles rendering methods to use cpicturebuffer like the gl rendering method does. this will be needed for getting and transferring colourspace information </desc> <cmt> linuxrenderergles: update yuvbuffer to cpicturebuffer </cmt> <cmt> renderermediacodec: update yuvbuffer to cpicturebuffer </cmt> <cmt> renderervaapigles: update yuvbuffer to cpicturebuffer </cmt> <cmt> renderervtbgles: update yuvbuffer to cpicturebuffer </cmt>,update rendering method to use cpicturebuffer
1244,<desc> this pr will begins the first steps of moving dashboard into spa while using the new dashboard api's dashboard/:id/charts and /dashboards/:id. thanks for @suddjian for the pairing! :) test plan updates to existing tests and end tests as need. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> add hook for future async api calls </cmt> <cmt> test to see conflict </cmt> <cmt> add async middleware and update reducers </cmt> <cmt> working async dashboard load </cmt> <cmt> implement getcharts api </cmt> <cmt> add user permissions to explore and dashboard bootstrap data </cmt> <cmt> integrate api calls with getinitial state </cmt> <cmt> update namings </cmt> <cmt> accept an id or a slug in the dashboard charts api </cmt> <cmt> add permissions function </cmt> <cmt> fix merge </cmt>,refactoring dashboard to use api's instead of bootstrapdata
1245,"<desc> hi, this pull request fixes issue #1002 by adding a new cmake flag nv_caffe and #ifdef where needed to distinguish between the standard caffe and nvcaffe. this has been tested with the official nvidia docker image nvcr.io/nvidia/caffe:18.12-py2. do you think it would be possible to test this automatically using travis too? i'm happy about any feedback. </desc> <cmt> add flag to use nvcaffe instead normal caffe </cmt> <cmt> add installation details for nv_caffe flag </cmt>",add support for nvidia nvcaffe
1246,"<desc> small addition, we need to set priorities for a couple of our deployments, such as keycloak. @unguiculus it adds priorityclassname as a field to the values and template, this allows us to prioritize keycloak deployment over other applications on our cluster, as they depend on keycloak for logging in anyway. dco signed </desc> <cmt> added priorityclassname as option </cmt> <cmt> added docs and changed values.yaml </cmt> <cmt> bump keycloak chart version </cmt>",add priorityclassname as option to keycloak
1247,"<desc> this pr is a first cut at support multiple-block returns. it changes the data model to allow multi-block returns, but does not implement it yet for any tasks. part 1/3 of #18317 skipping test test_dataset_pipeline.py::test_pipeline_actors is blocked on #19659 </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wi </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> fix shuffle </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> format </cmt> <cmt> update </cmt> <cmt> updae </cmt>",initial pass at support multiple-block returns for read and transform tasks
1248,<desc> backport of #40725 this can wait until 2.6.0 is released before merging into stable-2.6. win_group_membership ansible version 2.6 </desc> <cmt> refactor/fix win_group_membership to use sids for internal comparisons (#40725) </cmt> <cmt> * refactor win_group_membership to use sids for comparisons instead of name parsing </cmt> <cmt> * carry over previous doc cleanup changes </cmt> <cmt> * remove trailing whitespace from docs </cmt> <cmt> (cherry picked from commit bcb49f25752be489e00a71836aecd0ae1b8fcef4) </cmt> <cmt> added changelog fragment </cmt>,win group membership sid refactor 2.6
1249,<desc> follow the advice from the readme. avoid common mistakes. </desc> <cmt> add correct options for collection.set method.  issue #18593. </cmt> <cmt> make collection.slice method </cmt> <cmt> min parameter optional to match documentation.  issue #18593. </cmt> <cmt> allow sync to accept a collection as it's second argument. </cmt> <cmt> allow sort option for backbone collection.add and push.  issue #18593. </cmt>,issue #18593.  various fixes for backbone.
1250,"<desc> messing around with github actions, trying to see if this is possible: we will run checks only on the submitted project euler solution and not all. improve project euler validate solutions script i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> update validate solution script to fetch one solution </cmt> <cmt> update workflow file with the updated pe script </cmt>",validate only submitted project euler solution
1251,"<desc> adds the tensortransfer instruction in the same block as the corresponding graph_op instruction. also updates the naming logic to make sure names are unique across all devices. in the send_recvs.swift example, the name for the while block in the cpu and tpu turned out to be the same causing a runtime error in tensorflow. resolves sr-8372. </desc> <cmt> add tensortransfer instruction to the same block as the graph operation. </cmt> <cmt> bugfix to niquify names. </cmt> <cmt> updated the tests to run loop canonicalization. </cmt>",fix the code that inserts tensortransfer instructions to respect dominance
1252,"<desc> adjust the filtering on data endpoint when a context parameter is used. for a requested time range (t1, t2) filter out the matching charts when their  last_entry_t < t1 is true component name database </desc> <cmt> test fix for k8s </cmt> <cmt> remove charts that have data before the ""after"" point in time </cmt> <cmt> remove incognito rrdr dimension flag </cmt>",fix the context filtering on the data query endpoint
1253,"<desc> remove cluster's and listener's tls_context since we are using transport socket's tls_context/ refactor the sslsockettest : centralize the server configuration in one place --configureserverandexpiredclientcertificate function. note: the test could be further refactored by leveraging this function i modified, but i feel that is not worth the large amount of effort and current code also provides a bit flexibility of configuration (e.g. specifies various config like cert_hash, cert_spki in place) move createprotocoltestoptions to unnamed namespace. even though superiority of unnamed namespace over static is more applied to user-defined types rather than variables and functions (i.e. static no longer deprecated in standard and should do the same thing for latter two), it is still good to keep it in the unnamed namespace like other internal helper functions . also, unnamed namespace should be encouraged for such usage in general risk level: low testing:  local tests and ci run (all tests passed) </desc> <cmt> remove tls context </cmt> <cmt> deprecate tls_context in listener and cluster in favor of transport </cmt> <cmt> socket </cmt> <cmt> fix typo </cmt> <cmt> format </cmt>",deprecate cluster's and listener's tls_context in favor of transport socket
1254,<desc> i was going through the gatsby themes tutorial and ran into issues with the referenced theme-ui components being deprecated  i updated the css and code samples accordingly. </desc> <cmt> update with changes from gatsby </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update docs to no longer use deprecated theme-ui layout and instead use theme-ui components </cmt>,update building a theme docs to no longer use deprecated theme-ui components
1255,"<desc> fixes  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> apply human-friendly formatting to info.json </cmt> <cmt> correct layout_all data </cmt> <cmt> corrects the layout data for the layout_all macro. </cmt>",nix studio oxalys80 configurator layout data correction
1256,"<desc> issue: partially related to #4903 today we have an option to extend  webpack config by providing the function like this: module.exports = (basicconfig, mode, defaultconfig) => { /*...*/ } where defaultconfig is a few rules bigger than a basicconfig. i think it brings more confusion rather a benefit. reduced the basicconfig and changed to the signature to: module.exports = ({ config, mode }) => { /*...*/ } why object? because it's much easier to extend and deprecate in the future. removed a minor prop (defaultconfigname) that is passed forme the frameworks to core. this prop is kinda not needed. </desc> <cmt> remove ""defaultconfigname"" prop and use ""defaultconfig"" as a single config to be extended </cmt> <cmt> rename configtype to mode </cmt>",core - simplify custom webpack config
1257,"<desc> while trying to match function types, detect and fix any missing arguments (by introducing type variables), such arguments would get type information from corresponding parameters and aid in producing solutions which are much easier to diagnose. diagnostic only supports closures at the moment, but could be easily expanded to other types of situations e.g. function/member calls. </desc> <cmt> [cssimplify] further restrict tuple splat behavior </cmt> <cmt> issingleparam used to return true regardless of type of </cmt> <cmt> the identified single parameter, but splat only makes sense </cmt> <cmt> if such type is a tuple or a type variable which could later </cmt> <cmt> be resolved to tuple. otherwise it makes it hard to diagnose </cmt> <cmt> missing arguments. </cmt> <cmt> [constraintsystem] fix missing arguments </cmt> <cmt> while trying to match function types, detect and fix any missing </cmt> <cmt> arguments (by introducing type variables), such arguments would </cmt> <cmt> get type information from corresponding parameters and aid in </cmt> <cmt> producing solutions which are much easier to diagnose. </cmt> <cmt> [constraintlocator] add special locator for synthesized arguments </cmt> <cmt> [cssimplify] while attempting to synthesize missing arguments account for ""implode"" case </cmt> <cmt> in situations like this: </cmt> <cmt> swift </cmt> <cmt> func foo(_: (int, int) -> void) {} </cmt> <cmt> foo { $0.0 + $0.1 } </cmt> <cmt>  </cmt> <cmt> parameters are expected to be a single tuple by mistake, to account </cmt> <cmt> for that solver can generate n new arguments and bind a single existing </cmt> <cmt> argument to tuple formed from them. </cmt>",diagnose missing arguments in closures via fixes
1258,"<desc> previously, there could be deadlock when many spilling/restore objects happen concurrently. imagine all io workers are occupied to restore objects while the object store is about to oom. the put request will fail, and the plasma store needs to spill objects, but all io workers are already occupied by restore ops. this pr fixes this issue by having a separate pool for spill/restore workers. it basically removes the concept of io workers (it will be just an internal concept within worker pool abstraction) and introduces spillworker and restoreworker. this pr doesn't actually allow users to set a separate pool size for spill/restore workers. i think having the same size for both pools is fine for now, and implementing it in the future upon demand is trivial. it also introduces tests for io worker methods within worker pool (which we didn't have for some reason). #11789 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> in progress. </cmt> <cmt> add status </cmt> <cmt> in progress. </cmt>",introduce spillworker & restoreworker pool to avoid io worker deadlock.
1259,"<desc> restores similar behavior to make rules, where: the step order was always the same, e.g. the testsuite order in make check make check-stage1-{cfail,rpass} would always run cfail before rpass ./x.py test--stage 1 src/test/{compile-fail,run-pass} is now equivalent r? @alexcrichton </desc> <cmt> rustbuild: use a btreemap for the ruleset for determinism. </cmt> <cmt> rustbuild: sort rules by the order of matching cli paths. </cmt>",use deterministic step ordering and respect path order on the command-line.
1260,"<desc> this is the same pr as #12569, which was intended to fix an exception when syncfs encounters a directory which already exists. modifications to the original pr: i have squashed the commits because the final diff was only one line. i hope this is fine with you @vinnyog. a new test has been added (which is what prevented #12569 from getting merged). closes #12562. </desc> <cmt> use mkdirtree in idbfs.syncfs to avoid a crash when syncing existing directories </cmt> <cmt> add test for syncfs with an already existing directory </cmt> <iss> idbfs syncfs should not throw error when directory timestamps change </iss>",fix syncfs with existing directories
1261,"<desc> you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: searched the bugtracker for similar pull requests read adding new extractor tutorial read youtube-dl coding conventions and adjusted the code to meet them checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information the  niconico extractor has been broken following site changes, and also served files that couldn't be downloaded in a single yt-dl run because the server cancelled the download in the absence of a regular heartbeat post. the corresponding module in yt-dlp has been actively maintained and additional search extractors have been implemented, as well as adding support for the heartbeat function for downloads. this pr adapts the current version of the yt-dlp module to yt-dl conventions, in particular replacing f'strings' and yield from. the playlist limit in download tests from yt-dlp is implemented. additionally, if the optional threading module is available, the heartbeat function is enabled for dmc-type downloads. this requires a small change to downloader/__init__.py credit goes to @cxwudi, @animelover1984 and @pukkandan for recent changes on the yt-dlp version, and see also below for other contributors. the pr should fix these issues where extraction failed: resolve #29225 resolve #29974 resolve #30003 resolve #30316 resolve #30395. the pr should fix these issues where downloading needed a heartbeat: resolve #14582 resolve #19261 resolve #24093. </desc> <cmt> [test:download] only extract enough videos for playlist_mincount </cmt> <cmt> [niconico] back-port extractor from yt-dlp </cmt> <cmt> add nico search extractors, fix extraction </cmt> <iss> [niconico] downloading long videos requires heartbeat signals </iss> <iss> unable to download from nicovideo.jp </iss> <iss> [niconico] support encrypted official videos </iss> <iss> nicovideo.jp issue </iss> <iss> unable to download from nicovideo (niconico) </iss> <iss> nicovideo; unable to find url </iss> <iss> niconico dl not working </iss> <iss> [niconico]unable to find video url </iss>",back-port extractor and add new search extractors from yt-dlp
1262,"<desc> additionally report deprecations at earliest possible moment </desc> <cmt> fix(aws api gateway): ensure to log deprecation at initialization stage </cmt> <cmt> chore: register ""aws alexa"" commit message scope </cmt> <cmt> refactor(aws alexa): remove obsolete condition </cmt> <cmt> fix(aws alexa): ensure to log deprecation at initialization stage </cmt> <cmt> fix(aws cloudfront): ensure to log deprecation at initialization stage </cmt> <cmt> fix: ensure to log deprecation at initialization stage </cmt> <cmt> fix(analytics): ensure to send payload when having all meta </cmt>",ensure to report all deprecations
1263,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> the subtitlestyle prop is missing. it's in the material ui docs and the property works, but i'm getting a ts compiler error because its not in this typings file. </desc> <cmt> adds props to gridtile </cmt> <cmt> removes the children prop that i added </cmt>",adds missing subtitlestyleprops to gridtile
1264,"<desc> this pr fixes #121493. the main issue here is that we can't use color alone to signify state (see 1.4.1), so we have to update our focus state to invert the colors (just like in our list widget) to improve the focus state. originally i was scoping this to the quick pick but then also saw that the suggest widget relies on these colors, so i went ahead and updated those as well. this updates: default focus foreground & background colors for quick pick/suggest items focused highlights/labels/icons/keybindings to pass color contrast introduces: list.focushighlightforeground which defaults to the current highlight color quickinputlist.focusforeground which defaults to list.activeselectionforeground editorsuggestwidget.selectedforeground which defaults to list.activeselectionforeground dark theme is almost unnoticeable as the colors were close, but the light theme has the more noticeable changes. also, since the focus bg is so strong here i was unable to find an alternate color that worked for highlights (when filtering) so for now i set that color to be white. open to feedback on all of these changes. dark light other themes </desc> <cmt> update quick pick focused state </cmt> <cmt> add listfocushighlightforeground </cmt> <iss> quick pick focused item does not meet color contrast of 3:1 </iss>",update quick pick list widget focus colors
1265,"<desc> we should support safe c++ worker api according the doc, this pr remove some dependencies on ray core, such as: errortype, workertype, language, tasktype, buffer, localmemorybuffer, rayobject, taskarg, taskargbyreference, taskargbyvalue. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> remove coreworkerprocess </cmt> <cmt> remove some enum dependency of ray core </cmt> <cmt> begin to move arguments.h </cmt> <cmt> remove dependence of ray::taskarg </cmt> <cmt> remove some dependency of ray core </cmt>",remove some api dependencies on ray core
1266,"<desc> closes #32380 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry i deprecated the squeeze keyword. i think i got every points this keyword was used. i hope that i considered every point necessary to deprecate a keyword. i tried to use other points were a keyword was deprecated as example. </desc> <cmt> start deprecating squeeze option in groupby </cmt> <cmt> deprecate squeeze option </cmt> <cmt> change issue number in whats new </cmt> <cmt> run flake diff </cmt> <iss> deprecate groupby() squeeze option </iss>",32380 deprecate squeeze in groupby
1267,<desc> the completion suggester ignores the original weight of the suggestion when duplicates are removed. this change fixes this bug and keeps the best weighted suggestion among the duplicates. it also removes the custom implementation of the top docs suggest collector now that  closes #35836 </desc> <cmt> iter </cmt> <cmt> iter </cmt> <cmt> remove obsolete javadocs </cmt> <iss> skip_duplicates ignores weight </iss>,fix duplicate removal when merging completion suggestions
1268,"<desc> as discussed in 2cb51f7. i haven't implemented the symlink, because it was previously broken for os x as well (the shared library had an .so extension) and i'd rather prefer pushing the users to do the right thing. if you think i should do otherwise, please comment. </desc> <cmt> fixed dll name on windows in xgboost.libpath </cmt> <cmt> added support for os x to xgboost.libpath </cmt>",fixed shared library loading in the python package
1269,<desc> also adding tests for fixed ices </desc> <cmt> syntax: parse global paths in patterns </cmt> <cmt> closes #6449 </cmt> <cmt> rustc: prevant an out of bounds access in typeck </cmt> <cmt> closes #7092 </cmt> <cmt> rustc: fix a dynamic borrow error in resolve </cmt> <cmt> closes #8208 </cmt> <cmt> closes #10980 </cmt> <cmt> test: add a test for fixed issue #10763 </cmt> <cmt> closes #10763 </cmt> <cmt> test: add test for fixed issue #11736 </cmt> <cmt> closes #11736 </cmt> <cmt> test: add a test for fixed issue #11844 </cmt> <cmt> closes #11844 </cmt> <cmt> rustc: avoid out of bounds in check_match </cmt> <cmt> closes #12116 </cmt> <cmt> rustc: avoid an unwrap() in check_match </cmt> <cmt> closes #12369 </cmt> <cmt> test: add a test for fixed issue #12567 </cmt> <cmt> closes #12567 </cmt> <cmt> test: add test for fixed issue #12796 </cmt> <cmt> doesn't close #12796 because the error message is awful. </cmt>,fix a number of compiler ices
1270,<desc> this will allow experimenting with the remove to string transformer before we're ready to turn it on by default. this doesn't work for web yet since we use dart2js instead of the frontend_server for producing kernel fixes #53174 </desc> <cmt> work on wiring up extra gen snapshot options </cmt> <cmt> add gradle test </cmt> <iss> enable the usage of  --delete-tostring-package-uri in the flutter tool </iss>,expose extra frontend options through build apk/ios/macos
1271,"<desc> this pr removes gltf rigged simple model which seems no longer necessary. #13571 btw, i think we can also remove outlined box model. (what's this model for?) what do you think? </desc> <cmt> remove riggedsimple model from gltf extension example. </cmt> <cmt> remove gltf riggedsimple model. </cmt>",remove gltf rigged simple model
1272,"<desc> moves the python tests to the python subdir. adds a libbcc.a target for those statically inclined. </desc> <cmt> move python tests to tests/python </cmt> <cmt> they didn't quite make sense where they were. at one point 'cc' meant </cmt> <cmt> compiler, and yes they were testing the compiler. now lets use the </cmt> <cmt> convention that different tests/ subdirectories test different bindings </cmt> <cmt> (c, python, other). </cmt> <cmt> add libbcc.a compilation and test binary </cmt> <cmt> this creates a new static library target for bcc. add one trivial c test </cmt> <cmt> case that links against it. </cmt>",move cc/*py tests to python subdir and introduce c standalone test binary
1273,"<desc> this passes make check on my osx machine. pcwalton should probably review this. </desc> <cmt> add realloc method to rust_kernel </cmt> <cmt> allocate rust_ivec buffers out of the kernel pool </cmt> <cmt> the duplication of upcalls is due to the fact that the runtime is </cmt> <cmt> shared between stage0/rustc and stage1/rustc. once snapshots are </cmt> <cmt> updated, they should be de-duplicated. </cmt>",allocate ivecs out of the kernel pool
1274,"<desc> this is a continuation of the tidying up of the keyboard code. there is something a bit funny about the handling of the backslash character in windows. i suspect this is because the backslash key is in a different place on german keyboards. can someone with a german keyboard check the backslash still works on windows. note i've put the work in a branch (jr-keyboard) to avoid a git wtf award when i inevitably click the ""merge now and don't ask for confirmation"" button </desc> <cmt> change order of key lookup to allow actions to be mapped to numeric </cmt> <cmt> keypad keys </cmt> <cmt> include multimedia keys in the global key map. this completes the changes </cmt> <cmt> to cbuttontranslator::translatekeyboardstring. </cmt> <cmt> ignore case of key names in keyboard.xml </cmt> <cmt> vk_keymap[vk_oem_102] was set to xbmck_less and in the us layout that </cmt> <cmt> xbmc uses, it should be xbmck_backslash. </cmt> <cmt> tidy up xbmc_keysym.h </cmt> <cmt> add enum for the ckey.vkey values used in xbmc </cmt> <cmt> use windows keyboard layout not the us layout </cmt>",tidy up and comment keyboard handling
1275,"<desc> refs: #34157 creating this for discussion. idea is to make it easier for extensions to work with patterns that should be relative to the workspace. we typically ask for a string for the pattern and now we could add an or-type for a workspace relative pattern described by workspacepattern. the pattern will be matched against the provided base folder and can be relative (e.g. not starting with the workspace path or **). export interface documentfilter { /** * a language id, like typescript. */ language?: string; /** * a uri [scheme](#uri.scheme), like file or untitled. */ scheme?: string; /** * a glob pattern, like *.{ts,js}. */ pattern?: string | workspacepattern; } export interface workspacepattern { base: workspacefolder; pattern: string; } before doing more polish, @jrieken @dbaeumer for initial input. </desc> <cmt> introduce irelativepattern and use in extension api </cmt> <cmt> :lipstick: </cmt>",introduce irelativepattern and adopt in documentfilter/filewatcher/filesearch
1276,"<desc> this pr adds the scriptcode to the list of preferred locales as well as provides a new locale resolution algorithm that considered the preferred locale list instead of just the default (first) locale. locale resolution algorithm: i would like to have opinions on overhead vs time complexity of dart data structures. the algorithm i use first places all of the app's supported locales into a series of hashmaps, keyed by ""substring-hashes"" of their properties. for example, consider the locale zh-hant_tw. this locale is broken into zh, zh-hant, zh_tw, and zh-hant_tw. each of these four go into a corresponding hashmap that maps unique ""substrings"" to the first instance of that combination. with this system, both zh-hant_tw and zh-hant_hk map to the same locale when only considering languagecode and scriptcode and acts as if we chose the first occurrence. then, we loop over all preferred locales and match against the 4 hashmaps in order of most specific to least specific. to emulate the behavior of selecting a more specifically matched but less preferred locale, we delay matching by only a languagecode and nothing else until the next locale in the user's preferred locale is considered and does not have a better match. in the case of the default (first) locale, since the default locale is usually highly preferred over any secondary locale, we make an exception to the above rule and allow matches by only language code to resolve instantly. breaking changes this pr potentially introduces breaking changes to the localization bindings api. the localeresolutioncallback breaking change (from supporting list<locale> instead of a single locale) has been avoided by providing a higher priority localelistresolutioncallback that is called before the current one if it is provided. however, there are other places (see binding.dart) where the api is likely going to have to change to pass the list around instead of the single locale on the observers and callbacks there. </desc> <cmt> define localelistresolutioncallback </cmt> <cmt> locale list resolution </cmt> <cmt> working locale resolution system for locale lists </cmt>","new locale resolution algorithm to use full preferred locale list, include scriptcode in locale."
1277,"<desc> i've never heard the term ""oneshot"" modifier key before. i've only heard of the terms ""sticky key"" or ""dead key"". so when i was searching through the qmk docs, i couldn't find this feature. i think updating the docs as proposed will assist for other people searching as well. ref: issue #212 </desc> <cmt> update glossary; oneshot key = sticky/dead key </cmt> <cmt> update advanced_keycodes; oneshot = sticky/dead keys </cmt>","add the words ""sticky/dead keys"" to ""one shot"" docs sections"
1278,"<desc> this pr fixed two bugs with imageviewer, related to image rotations: the image looked shrank after rotation due to the window not being updated properly. the window is resized even if the image is small enough to rotate within the window. </desc> <cmt> imageviewer: use the same function to resize the window </cmt> <cmt> imageviewer used two different logic to resize the display window, which </cmt> <cmt> leads to confusing behaviour for rotate function. now all the resizing </cmt> <cmt> behaviour goes through the existing resize_window function. </cmt> <cmt> imageviewer: do not return early when the scale is not changed </cmt> <cmt> when the image is rotated, the scale is still the same, but the window </cmt> <cmt> needs to be still resized. </cmt> <cmt> imageviewer: do not resize the window if the image fits into the window </cmt>",preserve the aspect ratio on rotate
1279,"<desc> built on #10864, which should be reviewed & merged first </desc> <cmt> reduce server memory usage </cmt> <cmt> (this needs more testing/analysis to prove that it's safe) </cmt> <cmt> switch from a lock free stack to an mpscq protected by a spinlock for incoming requests. the mpscq is unbounded and so needs (much) less memory allocated up front. </cmt> <cmt> memory_profile_test shows this reduces initial server creation cost from 4mb to 1.5kb. </cmt> <cmt> merge github.com:grpc/grpc into serve_fries </cmt> <cmt> increase default cq count from 1 to num_cpus </cmt>",switch default cq count for thread manager to num_cpus
1280,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> feat(mongoose): added flag for new url parser </cmt> <cmt> feat(mongoose): added test for usenewurlparser flag </cmt> <cmt> feat(mongoose): bumped up mongoose version </cmt>",added flag for usenewurlparser in connectionoptions
1281,"<desc> hi david, i added a few options in regards to security of websites. this is mainly targeting http headers. with the urls to scanning services one would be able to tweak and improve their site(s) easily. regards, joki </desc> <cmt> add http header of content type options </cmt> <cmt> add websites for security scans </cmt> <cmt> check hsts preload status and eligibility </cmt> <cmt> add x-frame-options (xfo) section </cmt> <cmt> provide link captions </cmt> <cmt> add rfc 7034 </cmt>",add a few security-related entries
1282,"<desc> improve the aclk sync thread shutdown sequence sets a shutdown in progress flag so that no more commands will be accepted and the current queue of the commands will be ignored adds a -w parameter to check database for corruption and also attempt to fix it. adds a -w parameter to compact the database during startup if a database corruption is detected, it will attempt to fix it automatically (only applies to the dimension and chart tables) parameters added (in netdata -h) -w check-sqlite-database        check metadata database integrity and exit. -w fix-sqlite-database          check metadata database integrity, fix if needed and exit. -w compact-sqlite-database      reclaim metadata database unused space and exit. component name aclk sync, database stop the agent and execute in turn to simply check the database execute netdata -w check-sqlite-database to check and fix if needed the database execute netdata -w fix-sqlite-database to compact the database execute netdata -w compact-sqlite-database a sample output of a corrupted database would look like this when -w check-sqlite-database is executed 2021-11-24 23:28:28: netdata info  : main : running database check on /home/stelios/netdata-staging/netdata/var/cache/netdata/netdata-meta.db 2021-11-24 23:28:28: netdata info  : main : checking table chart 2021-11-24 23:28:28: netdata info  : main : ---> row 4300 missing from index sqlite_autoindex_chart_1 2021-11-24 23:28:30: netdata info  : main : ---> row 439125 missing from index sqlite_autoindex_chart_1 2021-11-24 23:28:30: netdata info  : main : ---> non-unique entry in index sqlite_autoindex_chart_1 2021-11-24 23:28:31: netdata error : main : errors reported -- run with -w fix-sqlite-database 2021-11-24 23:28:31: netdata info  : main : checking table dimension 2021-11-24 23:28:39: netdata info  : main : ---> row 1350373 missing from index ind_d1 2021-11-24 23:28:41: netdata info  : main : ---> row 1744253 missing from index ind_d1 2021-11-24 23:28:42: netdata error : main : errors reported -- run with -w fix-sqlite-database </desc> <cmt> set a flag to do aclk sync thread shutdown </cmt> <cmt> attempt to dequeue a cmd in case the queue is full and someone is blocked </cmt> <cmt> drop tables and recreate instead of deleting </cmt> <cmt> add commands to check the database -w check-database, fix-database, compact-database </cmt> <cmt> split the database setup to config and cleanup part </cmt> <cmt> add checks during database setup and cleanup to detect corruption to the dimension and chart tables </cmt> <cmt> add full database check and refactor code </cmt>",add commands to check and fix database corruption
1283,<desc> i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #2583'. </desc> <cmt> hill cipher implementation in java </cmt> <cmt> determinant of a matrix </cmt> <cmt> delete hillcipher.java </cmt> <cmt> add files via upload </cmt> <cmt> delete determinantofmatrix.java </cmt> <cmt> determinantofmatrix </cmt> <cmt> finding determinant of a matrix. </cmt> <cmt> inverse of a square matrix </cmt> <cmt> this feature finds inverse of a matrix using gaussian elimination. </cmt> <cmt> update inverseofmatrix.java </cmt> <cmt> sparcity of a matrix </cmt> <iss> calculate sparcity of a given matrix. </iss>,sparcity of a matrix [hacktoberfest]
1284,"<desc> this pr contains the following changes: unify the file / directory watcher functions in tsc and tsserver; for inferred projects, add the ability to detect newly added tsconfig.json files in from the same directory up to the root path; for configured projects, add the ability to detect implicitly added/removed source files (e.g., when the tsconfig.json file doesn't have a files array, and source files are added to or removed from the directory) from the same directory down recursively. (fix #5076, #4643) for tsconfig.json file without a files array, also added support to detect file addition / removal under tsc --watch. (fix #4553) points worth notice: inferred projects and configured projects have different kinds of directory watchers: for inferred projects, the sole purpose of a directory watcher is to detect newly added tsconfig.json files; and the addition normally happens from the current path up. also, it doesn't matter which project the watcher belongs to, all inferred projects can share one set of watchers if their root files happen to be in the same folder. for configured projects, each project has a recursive directory watcher of the path where its config file is located at. it does matter which project the watcher belongs to. currently the recursive watchers are supported in node 4.0 for both osx and windows. if the node version is before that, the recursive watcher might not work reliably. </desc> <cmt> change filewatcher in sys for node 4 </cmt> <cmt> unify the node filewatcher in sys.ts and server.ts </cmt> <cmt> bug fixes </cmt> <cmt> temp save </cmt> <cmt> redesigned directory watchers </cmt> <cmt> add directory watcher to tsc </cmt> <cmt> use fs.watch for all directory watchers and some bug fixes </cmt> <cmt> update comments </cmt> <cmt> incorporating changes from #3780 </cmt> <cmt> merge branch microsoft/master </cmt>",add directory watcher for tsserver and tsc
1285,"<desc> deepchecks is a python package for comprehensively validating your machine learning models and data with minimal effort. this includes checks related to various types of issues, such as model performance, data integrity, distribution mismatches, and more. </desc> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt>",add deepchecks to python -> general purpose machine learning
1286,"<desc> there unfortunately was a copy'n'paste problem with some of the integration idempotency tests, which did force some change because command changed. after fixing this, it turned out that init and shm_size have no idempotency checks. (extracted from #48546) docker_container ansible version 2.8.0 </desc> <cmt> fix tests: use same command if not testing command option. </cmt> <cmt> fix idempotency of init option. </cmt> <cmt> fix shm_size idempotency (it is included in inspect results from docker api version 1.22 on). </cmt>",fix tests and idempotency for init and shm_size
1287,"<desc> commit message: in order to speed up eds, don't necessarily visit every proto field to count its validity as warningvalidationvisitor does. this yields a ~30% speed improvement in processing very large updates in eds. risk level: medium, new feature behind a command line flag. testing: unit and bechmark tests. docs changes: these are probably wrong, thus the draft-ness. release notes: eds can now ignore unknown dynamic fields, for a ~30% improvement in update processing time. behind --ignore-unknown-dynamic-fields </desc> <cmt> add the ability to ignore unknown fields in eds. </cmt> <cmt> repair some merge damage and move the conditional down a layer as htuch requested. </cmt>",optionalize counting of unknown fields
1288,"<desc> changes to provide api in objective-c to the values and names for enums. </desc> <cmt> sync to thomasvl/protobuf head </cmt> <cmt> added new api to gpbenumdescriptor to enable introspection of enum values. </cmt> <cmt> refactored implementation so that this contains a minimum of added code. </cmt> <cmt> clarified comments regarding behavior in the presence of the alias_allowed option. </cmt> <cmt> added unit tests for new functionality and for the alias case. </cmt> <cmt> oops, fixed spelling error. </cmt> <cmt> more commentsmithing. </cmt> <cmt> addressed tom's comment on the pull request. </cmt> <cmt> noticed two more instances of fixes in the earlier commit. </cmt>",add ability to introspect list of enum values
1289,"<desc> i was doing some looking around sema and i noticed how large the method exprrewriter::coercecallarguments was. being a good citizen, i refactored out an obvious subroutine into (you guessed it!) a subroutine! </desc> <cmt> [gardening] refactor out computation of a callee's level into its own helper function. </cmt> <cmt> exprrewriter::coercecallarguments is a huge function that is difficult to reason </cmt> <cmt> about. this just moves an obvious subroutine into a real subroutine. </cmt> <cmt> [gardening] cleanup control flow in computecalllevel to reduce indentation level. </cmt>",refactor computation of call level into subroutine from exprrewriter::coercecallarguments
1290,"<desc> using cmake, nvidia's nvc++ adds the -a compiler flag (""strict""), causing compilation error if newlines are missing from the end of source files. nvc++ (not to be confused with nvcc) is detected as the pgi c++ compiler and this patch may therefore also apply to that. proposed changes involve newlines, only. </desc> <cmt> allow compilation with nvc++ </cmt> <cmt> add newlin to color_sinks.cpp </cmt>",allow compilation with nvc++ (and possibly pgi)
1291,"<desc> this is to add a tower_settings module which provides the ability to get, modify tower settings, which are at /api/v2/settings/all. new module pull request tower_settings ansible version devel </desc> <cmt> add the tower_settings module </cmt> <cmt> add tower_settings module </cmt>",add 'tower_settings' module for managing ansible tower settings
1292,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> mapbox-gl: geolocatecontrol support v0.39.0 </cmt> <cmt> :warning: breaking changes </cmt> <cmt> geolocatecontrol breaking changes </cmt> <cmt> the option watchposition has been replaced with trackuserlocation </cmt> <cmt> the camera operation has changed from jumpto (not animated) to fitbounds (animated). an effect of this is the map pitch is no longer reset, although the bearing is still reset to 0. </cmt> <cmt> the accuracy of the geolocation provided by the device is used to set the view (previously it was fixed at zoom level 17). the maxzoom can be controlled via the new fitboundsoptions option (defaults to 15). </cmt> <cmt> new option showuserlocation to draw a ""dot"" as a marker on the map at the user's location </cmt> <cmt> mapbox-gl: support pitch-alignment v0.39.0 </cmt> <cmt> add new icon-pitch-alignment and circle-pitch-alignment properties </cmt>",geolocationcontrol and pitch-alignment support v0.39.0
1293,"<desc> currently plugin just resolves url() paths relative to the main sass entry file. resolve-url-loader adds the ability to use paths relative to the file where the url() is being used. by default if not configured in the gatsby-plugin-sass, the loader is not being used, but you can activate it and also configure resolve-url-loader plugin with the options it provides. usage has been also documented in the readme.md of the gatsby-plugin-sass fixes #7776, #6438 </desc> <cmt> using resolve-url-loader if configured in the options </cmt> <cmt> documenting how to use resolve-url-plugin plugin </cmt> <cmt> fixing small typo </cmt> <iss> how to use resolve-url-loader with gatsby-plugin-sass in v2? </iss>",add option to enable resolve-url-loader
1294,"<desc> when parsing an ignore or attribute file, we should skip a utf8 bom. fixes #5071 </desc> <cmt> ignore: test we can handle an ignore file with bom </cmt> <cmt> ensure that we can read and parse an ignore file with a utf8 bom. </cmt> <cmt> ignore: skip utf8 bom in ignore file </cmt> <iss> .gitignore parsing: bom not skipped </iss>",skip utf8 bom in ignore files
1295,"<desc> fixes for a few outstanding issues. shap contribution dependency plots (an alternative to partial dependency plots). so far only 1d dependency plots are implemented, and no ggplot version. e.g., for a specific class in multiclass classification: set.seed(123) x <- as.matrix(iris[, -5]) is.na(x[sample(nrow(x) * 4, 30)]) <- true # introduce some missing values - will be shown in purple mbst <- xgboost(data = x, label = as.numeric(iris$species) - 1, nrounds = 20, max_depth = 2, eta = 0.1, subsample = .5, nthread = 2, objective = ""multi:softprob"", num_class = 3, verbose = 1) # for class 1 (versicolor) xgb.plot.shap(x, model = mbst, trees = seq(from=1, by=3, length.out=20), target_class = 1, top_n = 4, n_col = 2, col = rgb(0, 0, 1, 0.5), pch = 16, pch_na = 17) </desc> <cmt> [r] fix predict contributions for data with no colnames </cmt> <cmt> [r] add a render parameter for xgb.plot.multi.trees; fixes #2628 </cmt> <cmt> [r] update rd's </cmt> <cmt> [r] remove unnecessary dep-package from r cmake install </cmt> <cmt> silence type warnings; readability </cmt> <cmt> [r] silence complaint about incomplete line at the end </cmt> <cmt> [r] initial version of xgb.plot.shap() </cmt> <cmt> [r] more work on xgb.plot.shap </cmt> <cmt> [r] enforce black font in xgb.plot.tree; fixes #2640 </cmt> <cmt> [r] if feature names are available, check in predict that they are the same; fixes #2857 </cmt> <cmt> merging upstream changes </cmt>",maintenance nov 2017; shap plots
1296,"<desc> related to #49553 but i don't think it'll fix it currently, rustdoc doesn't expose proc-macros all that well. in the source crate, only their definition function is exposed, but when re-exported, they're treated as a macro! this is an awkward situation in all accounts. this pr checks functions to see whether they have any of #[proc_macro], #[proc_macro_attribute], or #[proc_macro_derive], and exposes them as macros instead. in addition, attributes and derives are exposed differently than other macros, getting their own item-type, css class, and module heading. function-like proc-macros are lumped in with macro_rules! macros, but they get a different declaration block (i'm open to tweaking this, it's just what i thought of given how function-proc-macros operate): proc-macro attributes and derives get their own pages, with a representative declaration block. derive macros also show off their helper attributes: there's one wrinkle which this pr doesn't address, which is why i didn't mark this as fixing the linked issue. currently, proc-macros don't expose their attributes or source span across crates, so while rustdoc knows they exist, that's about all the information it gets. this leads to an ""inlined"" macro that has absolutely no docs on it, and no [src] link to show you where it was declared. the way i got around it was to keep proc-macro re-export disabled, since we do get enough information across crates to properly link to the source page: until we can get a proc-macro's docs (and ideally also its source span) across crates, i believe this is the best way forward. </desc> <cmt> handle proc-macros as macros instead of functions </cmt> <cmt> disable proc-macro re-export inlining </cmt> <cmt> proc-macros don't emit their attributes or source spans across crates. </cmt> <cmt> this means that rustdoc can't actually see the docs of a proc-macro if </cmt> <cmt> it wasn't defined in the active crate, and attempting to inline it </cmt> <cmt> creates an empty page with no docs or source link. in lieu of attempting </cmt> <cmt> to fix that immediately, this commit forces proc-macro re-exports to </cmt> <cmt> never inline, which at least creates usable links to complete </cmt> <cmt> documentation. </cmt> <cmt> add test for proc-macro re-export </cmt>",give proc-macros their own pages
1297,"<desc> gatsby-transformer-json is a great plugin to parse raw json. although the plugin works perfectly with well-structured json files, it's faile to read and parse some type of files like topojson. the ""troubleshooting"" section within plugin's readme suggests rewriting the data, which not possible most of the time. trying to import those files directly inside a js file results in adding them to the app bundle and that would increase the size of all pages, as i discovered in #16651 issue. related to #16651 </desc> <cmt> add another usecase for using the static folder </cmt> <cmt> editing </cmt>",importing json files correctly outside graphql
1298,"<desc> this pr backports fixes and improvements for gbm and drm prime to leia. #15949 #15922 #15946 #15963 #15964 #16184 #15928 all prs may not be needed, but would be good to include in kodi v18.3 / libreelec 9.2. ping @lrusak build and runtime tested with libreelec on a asus tinkerboard s. </desc> <cmt> cwinsystemgbm: only lock the front buffer if something is rendered </cmt> <cmt> cdrmutils: rework modifiers flag selection </cmt> <cmt> cdrmutils: fallback to drmmodeaddfb2 if drmmodeaddfb2withmodifiers fails </cmt> <cmt> gbm: override processinfo and use deinterlace half by default on arm </cmt> <cmt> videobufferdrmprime: extract class </cmt> <cmt> videobufferdrmprime: extract interface </cmt> <cmt> videobufferdrmprime: add map/unmap callbacks </cmt> <cmt> dvdvideocodecdrmprime: getpicture only works for drm_prime pix fmt </cmt> <cmt> dvdvideocodecdrmprime: update process info in get format callback </cmt> <cmt> cdrmutils: explicitly set the caps we want (atomic brings them in) </cmt> <cmt> ceglfence: add class to help with egl sync objects </cmt> <cmt> crendererdrmprimegles: use ceglfence to sync rendering </cmt> <cmt> crendererdrmprimegles: update vbo's to be similar to clinuxrenderergl </cmt> <cmt> crendererdrmprimegles: add override methods for erenderfeature and escalingmethod </cmt>",backport fixes and improvements for gbm and drm prime
1299,<desc> clang tidy remove performance-unnecessary-value-param as error but keep as warning because clang-tidy can auto-fix it. trie tree fixed general code quality iso c++11 standard conformity fixes lgtm alert closes #1057 added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines </desc> <cmt> attempt to fix trie-tree code </cmt> <cmt> clang-tidy fixes </cmt> <cmt> remove performance-unnecessary-value-param as error - this has auto-fix </cmt> <cmt> make test() static </cmt>,fixed trie_tree for code quality and docs & clang-tidy error check
1300,"<desc> i went till i hit the next major roadblock: mutation observers. this library is used by youtube. details in the individual commits. </desc> <cmt> libweb: check if scripting is disabled before running script </cmt> <cmt> this is not a full check, it's just enough to prevent script execution </cmt> <cmt> in domparser. </cmt> <cmt> libweb: add domparser </cmt> <cmt> this allows you to invoke the html document parser and retrieve a </cmt> <cmt> document as though it was loaded as a web page, minus any scripting </cmt> <cmt> ability. </cmt> <cmt> this does not currently support xml parsing. </cmt> <cmt> this is used by youtube (or more accurately, web components polyfills) </cmt> <cmt> to polyfill templates. </cmt> <cmt> libweb: make clone_node capable of cloning document fragments </cmt> <cmt> used by web components polyfills. </cmt> <cmt> libweb: use the element factory in clone_node </cmt> <cmt> it was directly creating a new element object instead of creating the </cmt> <cmt> appropriate element. </cmt> <cmt> for example, document.body.clonenode(true) would return an element </cmt> <cmt> instead of an htmlbodyelement. </cmt> <cmt> libweb: add the cloning steps in clone_node </cmt> <cmt> this will be used in htmltemplateelement later to clone template </cmt> <cmt> contents. </cmt> <cmt> this makes the clone functions non-const in the process, as the cloning </cmt> <cmt> steps can have side effects. </cmt> <cmt> libweb: make adopted_from no longer take a const document reference </cmt> <cmt> nodes implementing the adoption steps can modify the passed in </cmt> <cmt> document, for example htmltemplateelement does so to adopt it's </cmt> <cmt> contents into the new document. </cmt> <cmt> libweb: implement the cloning steps for <template> elements </cmt> <cmt> libweb: implement the adoption steps for <template> elements </cmt> <cmt> while i'm here with the cloning steps, let's implement this too. </cmt> <cmt> libweb: make wrappergenerator generate nullable wrapper types </cmt> <cmt> previously it was not doing so, and some code relied on this not being </cmt> <cmt> the case. </cmt> <cmt> in particular, set_caption, set_t_head and set_t_foot in </cmt> <cmt> htmltableelement relied on this. this commit is not here to fix this, </cmt> <cmt> so i added an assertion to make it equivalent to a reference for now. </cmt> <cmt> libweb: implement node.contains </cmt> <cmt> used by web components polyfills. </cmt>",implement/fix a bunch of stuff required by web components polyfills
1301,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add kk980 </cmt> <cmt> fix </cmt> <cmt> fix config.h </cmt> <cmt> modified readme.md </cmt> <cmt> fix </cmt> <cmt> modified format. </cmt> <cmt> modified image. </cmt> <cmt> modified rules.mk </cmt> <cmt> modified rules.mk + # </cmt> <cmt> pull </cmt> <cmt> fix info.json: keys dislocation </cmt>",fix info.json (keys dislocation) for qmk_web_configurator of kk980.
1302,"<desc> translate almost files but next 3 files are yet. content-tracing-ko.md - 50% app-ko.md - 0% browser-window-ko.md - 0% to avoid confusion i removed 2 files(app-ko, browser-window-ko). (thanks for dalinaum) and remove remote buffer section in both remote.md(en, ko) files as section is outdated. </desc> <cmt> fix typos, update some files </cmt> <cmt> update apis, check grammars </cmt> <cmt> revert ""update apis, check grammars"" </cmt> <cmt> this reverts commit d1eb971263f72deae84541d12b3bdd6d5972365a. </cmt> <cmt> revert ""revert ""update apis, check grammars"""" </cmt> <cmt> this reverts commit 5e083473e7b4d3a6014d35e68618594765151afe. </cmt> <cmt> update changes as upstream </cmt> <cmt> prepare update forked repo </cmt> <cmt> update as upstream </cmt> <cmt> translate little files into korean </cmt> <cmt> fix typos, improve grammer </cmt> <cmt> update as upstream, fix typos </cmt> <cmt> update as upstream </cmt> <cmt> translate web-view-tag-tag-ko.md, improve grammer </cmt> <cmt> update as upstream </cmt> <cmt> update as upstream, translate 2 files, fix some typos </cmt> <cmt> fix some typos, update as upstream </cmt> <cmt> translate more files, fix outdated remote.md section </cmt> <cmt> translate content-tracing(50%), remote docs. </cmt> <cmt> fix remote buffer section as outdated. </cmt> <cmt> merge remote-tracking branch 'atom/master' </cmt>","translate docs to ko #3, fix outdated section"
1303,"<desc> @akien-mga i've alleviated the life of kinematic character by healing the jumping problem joking apart i've fixed it that was caused by untreated shape scaling, i've also removed the useless error code reported during shape deletion. fixes #15417 </desc> <cmt> fixed bullet collision shapes scale </cmt> <cmt> removed useless error print on bullet shapes </cmt> <iss> kinematic character 3d demo shows buggy kinematicbody/gridmap collisions with bullet </iss>",fixed #15417 kinematics char jumping
1304,<desc> #2111 imageviewmanager: changed image to reactimage/canvas moved all image related files to their own folder. reactimage: canvas wrapper to play nice with reactimagebrush overrides arrangeoverride to provide reactimagebrush the available size (needed for 'center' and 'repeat' reactimagebrush: xamlcompositionbrushbase that switches source brush based on resizemode uses compositioneffectbrush for 'repeat' resizemode bordereffect: header-only implementation of win2d-like bordereffect (used in windows::ui::composition apis) includes effectbase as we will probably need to add more effects in the future (e.g. blur) microsoft reviewers: open in codeflow </desc> <cmt> move imageviewmanager to its own folder </cmt> <cmt> add bordereffect impl </cmt> <cmt> switch from image to canvas </cmt> <cmt> add reactimagebrush (name tbd) </cmt> <cmt> wip: couple of fixes </cmt> <cmt> add reactimage canvas wrapper </cmt>,implement 'center' and 'repeat' resizemodes
1305,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> updated xrmstatic properties page, utility, and panel  to match the pattern that mobil was doing, and be defined as interfaces.  this also makes allows for variables to easily be tyepd i.e. var p: xrm.page. </cmt> <cmt> also retyped getinitalvalue for booleans and optionsetvalues to be their correct respective types. </cmt> <cmt> fixed linitng issues and fixed header so it could be parsed by the dt bot </cmt> <cmt> fixed other lint-ing issues.  not sure what to do about the header being unparsable.  added commas, maybe that will help? </cmt> <cmt> fix for @types/xrm missing context.getversion #16528.   also fixed td bot parsing of definitions by making one line, and updating tslint to allow for the long line. </cmt> <cmt> moved to one line. </cmt> <cmt> merge update </cmt>",@types/xrm - fix for  missing context.getversion #16528
1306,<desc> update metal driver to use new samplergroupinfo. we're no longer keeping track of which textures / samplers are already bound to the command encoder as the process was error-prone and isn't worth the effort for now. also fixed a memory leak when creating a new depth texture inside of createrendertargetr. fixes #1008 </desc> <cmt> fix memory leak </cmt> <cmt> rework enumeratesamplerbuffers </cmt> <iss> ios hello-pbr example is crashing in metaldriver::draw </iss>,fix metal sampler binding and memory leak
1307,<desc> this pr revises our logic for building cfa graphs for try-catch-finally statements. two changes are implemented by this pr: previously we'd include every cfa node in the try block as a possible antecedent in the exception case. now we only include cfa nodes representing assignments and array mutations. previously we didn't consider the possible effects in the finally block of exceptions in the catch block. we now do. fixes #34797. </desc> <cmt> revise creation of control flow graph for try-catch-finally statements </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <iss> throw in catch causes type narrowing in finally block </iss>,fix control flow analysis in try-catch-finally
1308,"<desc> fixes rdar://problem/46973064. </desc> <cmt> sema: add a pretty stack trace entry when checking error handling </cmt> <cmt> sema: fix crashes when a call of a closure value is missing a 'try' </cmt> <cmt> two problems here: </cmt> <cmt> - the interpolatedstring instance variable was not always initialized before </cmt> <cmt> being checked for null </cmt> <cmt> - in the non-null case, we were assuming the result of callexpr::getcalledvalue() </cmt> <cmt> was non-null, but it's null if the callee is not a function declaration </cmt> <cmt> fixes <rdar://problem/46973064>. </cmt>",fix crashes when a call of a closure value is missing a 'try' [5.0]
1309,<desc> this pr adds a new api into the kubelet server which could return statistical information about a container. such information is retrieved through cadvisor rest api. this pr introduced the following third party dependencies: cadvisor because we need to use some data structure there and its client library. testify for its mock library objx because testify depends on it. the test coverage now for pkg/kubelet is improved from 58.1% to 59.9% the current code is not wired with kubelet now. will add it in another pr. </desc> <cmt> add cadvisor into third_party </cmt> <cmt> add /containerstats </cmt> <cmt> gopath... </cmt> <cmt> testify </cmt> <cmt> unit test for cadvisor </cmt> <cmt> more unit test for getcontainerstats() </cmt> <cmt> more unit test </cmt> <cmt> unit test for getcontainerstats() </cmt>,letting kubelet retrieve container stats from cadvisor
1310,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> feat(ali-oss): add types of refresh token </cmt> <cmt> fix(ali-oss): change comment length </cmt>,add def of refresh token in options
1311,<desc> somehow the code was dropped somewhere along the road... </desc> <cmt> add jwt token creds test_case </cmt> <cmt> the jwt code was dropped somewhere in a merge. put it back </cmt> <cmt> add a jwt test case for interop test </cmt> <cmt> formatting </cmt>,put back c++ jwtcredentials code and add a test case in interop test.
1312,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> update prettier 400col width </cmt> <cmt> update for 4.3 </cmt>,tabulator-tables - update for version 4.3
1313,"<desc> this pr is second version for fixing #10751. first version is #10811. please see #10751 about original problem. in master, uuid default functions are not dumped to db/schema.rb, because they are not extracted to postgresqlcolum. in first version, i modified postgresqlcolum.extract_value_from_default method to return a function name string when default argument is uuid generator. but i've understood this was wrong approach, because extract_value_from_default method must extract value. </desc> <cmt> fix typo. </cmt> <cmt> migration dump uuid default functions to schema.rb. fixes #10751. </cmt>",dump uuid default functions to schema.rb [2nd version]. fixes #10751.
1314,"<desc> this pr fixes #7164. the context menu entries ""evaluate expression"" and ""set execution point to line"" are now only enabled when a debug session is active. other than that, it was possible to run the program while a debug session is active. after the program finishes, the stop button gets disabled. this makes it impossible to exit the debug mode. i have disabled the run button while the debug mode is active. this is my first pr to an open-source project, so please let me know if i did something wrong :) </desc> <cmt> hackstudio: disable run button while debugging </cmt> <cmt> this commit disables the run button while we </cmt> <cmt> are in debug mode. otherwise the stop button </cmt> <cmt> gets disabled when we run the program while </cmt> <cmt> we are in debug mode. this would prevent us </cmt> <cmt> from exiting the debug mode. </cmt> <cmt> hackstudio: disable debug specific context entries </cmt> <cmt> context menu entries like evaluate expression and </cmt> <cmt> move execution to line action should only be enabled </cmt> <cmt> when a debug session is running. otherwise they should </cmt> <cmt> be disabled. </cmt> <iss> hackstudio: debugger context menu items should be disabled when not debugging </iss>",disable debugging context menu entries
1315,"<desc> the health was not checking the size returned by fread, so it could work with less data than available. considering that the next steps would be to parser the json content, this mean that it would not start correctly the silencers. component name health to test whether everything is ok, run the script to test stopping in sometime before a reset command, stop and restart the netdata. it cannot display the error message of the code, instead it must give the info message. </desc> <cmt> health_alert </cmt> <cmt> the file health/healht.c on line 56 did not check the return of the fread </cmt> <cmt> , so netdata could work with incomplete data </cmt> <cmt> health_alert </cmt> <cmt> the free functions was initially called in a wrong place. </cmt>",health could not read properly the health silencers file
1316,"<desc> fixes #1358 there were 2 issues: files were deleted, but a few of them were re-created during cleanup. chart and host directories were not deleted. both are fixed now. </desc> <cmt> strip binaries in makeself packages </cmt> <cmt> properly cleanup deleted files of obsolete charts from disk; fixes #1358 </cmt> <iss> ephemeral containers - netdata does not cleanup </iss>","delete files of obsoleted charts, from disk"
1317,"<desc> what types of changes does your pr introduce? put an x in all boxes that apply improve a description </desc> <cmt> add loremify </cmt> <cmt> add loremify, an lorem ipsum generator. </cmt> <cmt> add trello </cmt> <cmt> - adds the awesome trello app; </cmt> <cmt> - improve description of loremify, geting off redudancy since the list is for mac os x. </cmt> <cmt> add trello </cmt> <cmt> - adds the awesome trello app; </cmt> <cmt> - improve description of loremify, geting off redudancy since the list is for mac os x. </cmt> <cmt> update the trello description </cmt> <cmt> - add the word kanban at the description. </cmt>",add word 'kanban' for trello description.
1318,"<desc> #3068 hook up property keyboarddismissmode in scrollviewmanager. -when manipulation starts and if keyboarddismissmode is on-drag, issue tryhide though sip event handler. -some tweak to sip event handler code to be able to share in the rnw's code base, and call getforuicontext instead of getforcurrentview on newer build. -add logic to only hook up coreinputview when element is in the tree, otherwise we may get null uicontext and results in crash. microsoft reviewers: open in codeflow </desc> <cmt> revert ""revert ""support scrollview keyboarddismissmode"" (#3692)"" </cmt> <cmt> this reverts commit 55ef15e59835abc086f256b08e79bd9c87d419e8. </cmt> <cmt> properly support scrollview keyboarddismissmode </cmt> <cmt> change files </cmt>",support scrollview keyboarddismissmode - with crash fixed
1319,"<desc> description: add wrapper around newly allocated slotimpl. this was missed in pr 8135. which means newly created tls are deallocated in the old way( destructed on owner destruction possible race, but the race window is really small, see issue #7902 ) risk level: medium testing: n/a docs changes:  n/a release notes: n/a </desc> <cmt> resolve the life-cycle race between a slotimpl and callbacks pointing to it. </cmt> <cmt> add minor comment </cmt> <cmt> fixes for feedbacks from matt </cmt> <cmt> fix format </cmt> <cmt> add tidy error fixes </cmt> <cmt> fixes for matt feedbacks, 2 </cmt> <cmt> fixes for feedbacks matt 3 </cmt> <cmt> fix clang-tidy errors. </cmt> <cmt> refactor out the schedule-cleanup-callback complexity by firing a post callback on destruction of the ref-count shared_ptr </cmt> <cmt> fix header order </cmt> <cmt> fix comment </cmt> <cmt> add more comment to the tls </cmt> <cmt> if only i know how to run typo ci locally </cmt> <cmt> add wrapper around new slot </cmt>",add the missing wrapper around slotimpl allocation.
1320,<desc> get pixel color for a full window and connect functionality to ui. the copy to clipboard button and rgb values update with the mouse movement. references pr checklist detailed description of the pull request / additional comments current mouse input issue on a second monitor due to different dpi settings. validation steps performed checked color conversion with online hex to rgb conversions. </desc> <cmt> implement get pixel within wpf window </cmt> <cmt> added dpi awarness </cmt> <cmt> small fix </cmt> <cmt> [intern] added dpi awarness </cmt> <cmt> thread with mouse color on full screen </cmt> <cmt> merge ui xaml </cmt> <cmt> remove dpi awareness settings </cmt> <cmt> backend connection complete and clipboard added </cmt>,add get pixel logic and connect to ui
1321,<desc> added additional assertion that input image is not empty. </desc> <cmt> fix gpu test for demosaicing: </cmt> <cmt> check that input images was loaded correctly </cmt> <cmt> added additional check in cv::gpu::demosaicing that source is not empty </cmt>,fix for gpu demosaicing test
1322,<desc> make use of rpc arena to avoid protobuf copying and destructing which are really expensive for complicated structures. this is a split of #17828 #17805 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> s1 </cmt> <cmt> up </cmt>,cpu improvement of protobuf in gcs
1323,"<desc> reported in #750. includes fix to the test, which wasn't catching this bug. </desc> <cmt> fix: tests now catch bug reported in #750 (in hdf5 output layer) </cmt> <cmt> fix: both data and label now copied correctly in hdf5 output layer </cmt>",fix for bug in hdf5 output layer
1324,<desc> jenkins-20023 this change moves jenkins.docli() to own rootaction. </desc> <cmt> [jenkins-20023] add support for java -jar jenkins-cli.jar help <cmdname> </cmt> <cmt> [jenkins-20023] display detailed cli command info via jenkins ui </cmt> <cmt> [jenkins-20023] generate usage for cli commands registered via climethod annotation </cmt>,make cli interface help more accesible
1325,"<desc> this pr consists of 2 fixes. the first fix is in verifier.cc, as discussed in #44852. the second fix is for retrieving axis_value data in arg_min_max.cc. since the axis could be of type int64, it will cause an issue when retrieving it as int32 on big endian machines - it only retrieves the first 4 bytes which are the most significant bytes on big endian machines. retrieve it as int64 at first and then convert it to int32 will be safer and more consistent. edit: push another fix for lsh_projection_test, as discussed in #44982. </desc> <cmt> change return type of getintptr() and correct endainness when needed </cmt> <cmt> fix unguarded data type conversion from int64 to int in arg_min_max.cc </cmt> <cmt> fix a typo </cmt>","fix for tf lite verifier, arg_min_max op and lsh_projection_test on big endian machine"
1326,"<desc> what do these changes do? fork() api will fork an actor handle explicitly that we could use it to do a other ray.calls. for serializer, we implicitly do fork when serializing recursively. for example: class myobject { private rayactor actor; } class myobject { private myobject1 obj1; } class myobject1 { private rayactor actor; } if the actor object actor is a field of another object obj(myobject), when we pass  obj by ray.call, the obj.actor's handleid will be changed to another id. n/a </desc> <cmt> change the way to generate actor handle id. </cmt> <cmt> lint </cmt>",allow actor handle to be serialized without forking
1327,"<desc> update ndarrayiter api doc with csrndarray inputs update document for kv.init, kv.push add test for #7676 preview: </desc> <cmt> update doc for ndarrayiter </cmt> <cmt> update kvstore doc. remove int64 restriction for row_ids in rowsparse pull </cmt> <cmt> add exception test for sparse op </cmt>",update doc for sparse related apis
1328,"<desc> re-enabling some warnings that are required per sdl - going towards #6918. c4996, c4700, and c4611 were no longer needed. c4244 fixed with an explicit static cast to int. the only remaining suppressions blocking us from sdl compliance are coming from folly(4244 and 4267 being set off from toascii.h), which i will address next. </desc> <cmt> restore c4700 </cmt> <cmt> restore c4996 </cmt> <cmt> restore c4611 </cmt> <cmt> c4244 local fix & restore </cmt> <cmt> change files </cmt>",restoring warnings for sdl compliance
1329,"<desc> runtime tested on rpi4 with justboom dac, justboom digi and hifiberry digi-pro that's it from my side, i think i'm through all the i2s cards i have here </desc> <cmt> asoc: justboom-dac: use modern dai_link style </cmt> <cmt> asoc: rpi-wm8804-soundcard: use modern dai_link style </cmt>","justboom-dac, rpi-wm8804-soundcard: use modern dai_link style"
1330,"<desc> review with ""hide whitespace changes"" is recommended. remove requireraw mock remove requiredemo mock (but make sure attempting to render a non-existent demo throws) skip transpiling code created by loader this was fairly expensive to do with large markdown files and we don't really need it. we can write es5 code directly instead. test plan ie 11 ""works"" localized content ssr and csr ""works"": </desc> <cmt> preparemarkdown only handles markdown </cmt> <cmt> [docs] remove requireraw mock </cmt>",remove mocks of require.context in markdown loader
1331,"<desc> this is a hodge-podge addressing a few of the items in #17652.  individual commits should be item-specific(ish). remove unused lib.arrmap de-privatize _checknull_with_nat fix a couple of c warnings caused by timedelta_struct remove period._comparables </desc> <cmt> remove unused func </cmt> <cmt> remove unused period._comparables </cmt> <cmt> fix c warnings, whitespace; remove unused func </cmt> <cmt> de-privatize _checknull_with_nat </cmt>",cross off a few tslibs-todos
1332,"<desc> the second part in a series of prs for adding annotation to np.core.multiarray. the improvements introduced by this pr fall in one of the following two categories: the addition of literal int-values for constants such as np.may_share_exact. the addition of dtype-support to the array constuctors that were recently moved from _asarray to multiarray (xref #18642). examples from typing import type_checking import numpy as np if type_checking: # note: revealed type is 'literal[0]' reveal_type(np.may_share_bounds) # note: revealed type is 'numpy.ndarray[any, numpy.dtype[numpy.floating*[numpy.typing._64bit*]]]' reveal_type(np.asarray(1, dtype=np.float64)) </desc> <cmt> maint: move 9 constants from np to np.core.multiarray </cmt> <cmt> maint: move 4 array constructors from np.core._asarray to np.core.multiarray </cmt> <cmt> enh: use literals for the constants when possible </cmt> <cmt> enh: add basic dtype-support to 4 array constructors </cmt> <cmt> enh: allow array and empty_like to pass through subclasses if dtype=none </cmt> <cmt> tst: update the typing tests for np.core.multiarray </cmt>",add annotations to np.core.multiarray part 2/4
1333,"<desc> here are my copyedits to the byterun chapter. nothing major, mostly just typo fixes and formatting changes. there are three queries in the pr, on (new) lines 144, 314, and 393. </desc> <cmt> started editing -- fixed em-dashes, standardized headers, etc... </cmt> <cmt> copyedits </cmt> <cmt> end of first pass </cmt> <cmt> edits and changes to header levels </cmt> <cmt> final pass edits </cmt>",copyedits to byterun interpreter chapter
1334,"<desc> backport #2402, #2416, #2419 and #2708 into 0.10 release branch. also bumps c# and core version. </desc> <cmt> remove chatty log messages on windows </cmt> <cmt> zero-out channel after creation </cmt> <cmt> better socket kick for windows. </cmt> <cmt> now calling tcp_shutdown will in fact close the socket, which cascades into properly cleaning out all the pending requests. </cmt> <cmt> the tcp_server_windows's shutdown logic had to be rewritted (simplified) in order to take this into account. </cmt> <cmt> fix race in server shutdown </cmt> <cmt> pick up nuget package version from cmdline param and fix nuget build </cmt> <cmt> introduce version.cs as single source of truth of grpc c# version </cmt> <cmt> make build_packages.bat provide version of grpc.native.csharp_ext dependency </cmt>",backport c# related fixes to 0.10 branch.
1335,"<desc> run lint for python and coffee scripts in the cibuild. </desc> <cmt> :lipstick: fix violations against pylint. </cmt> <cmt> add wrapper script for pylint. </cmt> <cmt> run pylint in cibuild. </cmt> <cmt> skip the check for lib.github. </cmt> <cmt> add coffeelint to dependencies. </cmt> <cmt> add wrapper script for coffeelint. </cmt> <cmt> do not warn about 80 columns in coffeelint, it's not required. </cmt>",lint python and coffee scripts
1336,"<desc> since the endianness of test dataset is little-endian, conversions are required on big-endian machines.  related issue is also written in #1730 this pr fixes small part of the issue, and we need to convert more to pass all onnx tests by pytest. however, this enables all of onnx-mlir test to pass. the test cases are written in test code i would like to hear your comments or suggestions about this approach. </desc> <cmt> added big-endian support by converting little-endian data in numpy_helper </cmt> <cmt> convert byte ordering only in test which uses little-endian data (removed previous modification to numpy_helper.py) </cmt> <cmt> removed unnecessary modification for onnf test </cmt> <cmt> removed unnecessary blank </cmt>",convert endianness of test dataset to pass tests of onnx-mlir on big-endian machines
1337,"<desc> ref: kubernetes/org#2456 as a part of cleaning up inactive members (those with no activity within the past 18 months), this commit removes the following people from various owners files: @balajismaniam @gmarek @jianhuiz @madhusudancs @mbohlool @nikhiljindal @csbell this pr replaces #99073, #99075 and #99077 / /assign @liggitt </desc> <cmt> *: move balajismaniam to emeritus_approvers </cmt> <cmt> *: move gmarek to emeritus_approvers </cmt> <cmt> *: remove jianhuiz from reviewers </cmt> <cmt> *: remove madhusudancs from reviewers </cmt> <cmt> owners_aliases: remove csbell from feature-approvers </cmt> <cmt> *: remove mbohlool from reviewers </cmt> <cmt> *: remove nikhiljindal from owners </cmt>",remove inactive members from owners - jan 2021
1338,"<desc> they (security measures) are good in general, however there are some (valid) usages that require turning these off. gui screenshot webui screenshot </desc> <cmt> update options dialog layout in webui </cmt> <cmt> add option to control webui clickjacking protection </cmt> <cmt> some users actually want embedding webui into their custom build iframe. </cmt> <cmt> closes #7370. </cmt>",add options to control webui security measures
1339,<desc> since mi desk lamp isnt used by most users make it off by default the code change pass travis tests. your pr cannot be merged unless tests pass </desc> <cmt> 6.4.1.16 </cmt> <cmt> update to 6.5.0.4 </cmt> <cmt> make mi desk lamp default off </cmt> <cmt> mi desk lamp can be activated in my_user_config.h by setting uncommenting //#define rotary_v1 </cmt>,midesk lamp not default activated
1340,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. cc:/ @peombwa @ddyett @zengin </desc> <cmt> merge  from definitelytyped/master </cmt> <cmt> update local definatelytyped </cmt> <cmt> update typings to 1.13 </cmt> <cmt> fixed linting errors </cmt>",update microsoft-graph typings to 1.13
1341,<desc> reduce many overheads in saving and loading multi-threading save and load still use text format. binary format will be added after this pr. both saving and loading are about 10x faster now. </desc> <cmt> remove protobuf </cmt> <cmt> add version number </cmt> <cmt> remove pmml script </cmt> <cmt> use float for split gain </cmt> <cmt> fix warnings </cmt> <cmt> refine the read model logic of gbdt </cmt> <cmt> fix compile error </cmt> <cmt> improve decode speed </cmt> <cmt> fix some bugs </cmt> <cmt> fix double accuracy problem </cmt> <cmt> fix bug </cmt> <cmt> multi-thread save model </cmt> <cmt> speed up save model to string </cmt> <cmt> parallel save/load model </cmt> <cmt> fix some warnings. </cmt>,speed up saving and loading model
1342,<desc> this patch adds a new class_mode to keras.preprocessing.image.imagedatagenerator.flow_from_directory method. this new class_mode is 'identical' and it allows to generate minibatches where the target values are identical to input values. it makes working with autoencoders trivial. this issue has been described in #4260. the patch also contains tests that ensure that the input images are not the same numpy array as target images. </desc> <cmt> identical class_mode code. </cmt> <cmt> new directory iterator testing function </cmt>,add a directory iterator option to allow to work easily with autoencoders (issue #4260)
1343,"<desc> when we moved from the workflow trigger event pull_request to pull_request_target (which we changed to allow forks to run visual snapshots), it resulted in a change of the pull request base sha. instead of relying on the github context for the merge base, we should use git merge-base to find the base sha. the merge base sha is then used to use a three-way comparison for prs (comparing the pr head sha against latest master and the merge base). </desc> <cmt> add merge base output for job --> input to action-visual-snapshot </cmt> <cmt> move to visual-diff job </cmt>",fix merge base for visual snapshots
1344,"<desc> this pr includes a test that i've enabled in #13358 and another test that we've discussed in #13462 as well as some random cleanup while i'm at it. </desc> <cmt> update dom fixture lockfile </cmt> <cmt> bring back onsubmit bubble test </cmt> <cmt> i found a test that was written more than 5 years ago and probably never </cmt> <cmt> run until now. the behavior still works, although the api changed quite </cmt> <cmt> a bit over the years. </cmt> <cmt> seems like this was part of the initial public release already: </cmt> <cmt>  </cmt> <cmt> add test to make sure interim native events are prevented </cmt> <cmt> for more information, see #13462 </cmt> <cmt> make sure all dom mutations are cleaned up </cmt>",improve test harness of submit events
1345,"<desc> closes #2732 </desc> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <cmt> update data for nc 6/21 </cmt> <iss> nc, ms, or, ri state and county data not updated for 6-21 </iss>",2732 update june 21 data for nc
1346,"<desc> 1/ updates nimble to the release version 1.1.0 2/ adds mqtt discovery for homeassistant users under 'setoption19 1' yes, i know this is the 'old' way, but the 'new' way is unsuited to tasmota discoverable sensors this also adds publish of each sensor on a separate topic, not related to the publishing tasmota (only if setoption19). 3/ removes ble stats from /sensors mqtt (never should have been there) - publishes instead to /ble 4/ sets the default address filter in ble to 0 - public static addresses only this hides random addresses created by mobiles.  if you want these (e.g. you want to hear covid announcments), do bleaddrfilter 1.  most users will not want to see them. 5/ add mi32option5 if mi32option5 1 then only mi devices which have blealias defined for them will be heard by mi.  all devices are removed at the point of setting 1. related issue (if applicable): fixes # the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> nimble release 1.1.0 </cmt> <cmt> ha discovery via mqtt for ble mi sensor devices </cmt> <cmt> update nimble to 1.1.0 release. </cmt> <cmt> remove ble stats from sensor, publish in ble. </cmt> <cmt> set default address filter to 0 </cmt> <cmt> add ha mqtt discovery to mi </cmt>",update nimble to release verison 1.1.0 + adds mqtt discovery for mi sensors using new ble
1347,"<desc> meta: mark the other image file formats as binary in .gitattributes we had rules for .png and .jpg files, but we have not maintained the list as support for other file formats has been added. to test these changes test files have been committed for each of these formats. this change updates the list with all of the binary image file types i was able to find in the tree at the time of writing. meta: cleanup stale rules from .gitignore the wild card rules at the top of the .gitignore came from a time when the build wrote back to the git repository and placed files right next to the source. (original commit that introduced them 37c27e2, they were later consolidated into the root .gitignore in 802d4dc) we have since moved to cmake, and these rules have become obsolete, and they just cause issues where we need to go and add negations for these rules in order for things to work. a previous change attempted to remove the top wild card rules (pr #4565) but it was later reverted, as they forgot to remove the top ignore everything rule '*', so all files were ignored. this change just removes all of these rules that no longer make sense, restoring a bit of sanity. .o,.d,*.a rules were also from when the build wrote to the repository, they are now defunct. the same goes for the *endpoint.h and cmakefiles rules. the lowercase build directory can be removed as we've standardized on the uppercase 'build' directory as the root of the build output dir. </desc> <cmt> meta: cleanup stale rules from .gitignore </cmt> <cmt> the wild card rules at the top of the .gitignore came from a time when </cmt> <cmt> the build wrote back to the git repository and placed files right next </cmt> <cmt> to the source. (original commit that introduced them 37c27e2e, they were </cmt> <cmt> later consolidated into the root .gitignore in 802d4dc) we have since </cmt> <cmt> moved to cmake, and these rules have become obsolete, and they just </cmt> <cmt> cause issues where we need to go and add negations for these rules in </cmt> <cmt> order for things to work. </cmt> <cmt> a previous change attempted to remove the top wild card rules (pr #4565) </cmt> <cmt> but it was later reverted, as they forgot to remove the top ignore </cmt> <cmt> everything rule '*', so all files were ignored. this change just removes </cmt> <cmt> all of these rules that no longer make sense, restoring a bit of sanity. </cmt> <cmt> *.o,*.d,*.a rules were also from when the build wrote to the repository, </cmt> <cmt> they are now defunct. the same goes for the *endpoint.h and cmakefiles </cmt> <cmt> rules. </cmt> <cmt> the lowercase build directory can be removed as we've standardized on </cmt> <cmt> the uppercase 'build' directory as the root of the build output dir. </cmt> <cmt> meta: mark the other image file formats as binary in .gitattributes </cmt> <cmt> we had rules for .png and .jpg files, but we have not maintained the </cmt> <cmt> list as support for other file formats has been added. to test these </cmt> <cmt> changes test files have been committed for each of these formats. </cmt> <cmt> this change updates the list with all of the binary image file types i </cmt> <cmt> was able to find in the tree at the time of writing. </cmt>",cleanup stale rules form .gitignore + update .gitattributes
1348,"<desc> as the new textcat_multilabel component has been released as part of v3, it should be documented in some more detail as well. v3 migration guide warning note on textcat architectures warning note on ""normal"" textcat to point to changed functionality in comparison to v2 added the component to some lists of built-in components added the link to the api sidebar. unfortunately it splits over 2 lines though (cf image). @ines: wat do you think? docs update i have submitted the spacy contributor agreement. </desc> <cmt> add multi-label textcat to menu </cmt> <cmt> add infobox on textcat api </cmt> <cmt> add info to v3 migration guide </cmt> <cmt> small edits </cmt> <cmt> further fixes in doc strings </cmt> <cmt> add infobox to textcat architectures </cmt> <cmt> add textcat_multilabel to overview of built-in components </cmt> <cmt> spelling </cmt>",textcat scoring fix and multi_label docs
1349,"<desc> doc fixes and limiting options to supported services </desc> <cmt> update documentation for rax module </cmt> <cmt> only list the services supported </cmt> <cmt> don't put in unncessary required: false </cmt> <cmt> use better formatting for the example </cmt> <cmt> only accept supported services for rax module </cmt> <cmt> even though others are possible, fail early on unsupported ones. </cmt>",minor fixes to the rax module
1350,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> update test </cmt> <cmt> added missing axis field </cmt>,added missing axis field to hover options
1351,"<desc> vendoring: vishvananda/netlink 734d02c libnetwork  ed311d0 update check-config.sh to check for optional modules needed for secure datapath fixes #22185 fix for moby/libnetwork#1247 fixes crash at boot when xfrm modules are missing or are not autoloaded for the bugs with an issue open, refer to the issue description. for the crash, move the following file somewhere else and boot the daemon: /lib/modules/$(uname -r)/kernel/net/xfrm/xfrm_user.ko - more info about the crash originally reported offline by @fxdgear and @lk4d4 on  antegros and gentoo linux erro[0001] could not create netlink handle on initial namespace: protocol not supported panic: runtime error: invalid memory address or nil pointer dereference goroutine 1 [running]: panic(0x1467cc0, 0xc420012100) /home/moroz/go/src/runtime/panic.go:500 +0x1a1 github.com/vishvananda/netlink.(*handle).linkbyname(0x0, 0xc42085a6c0, 0xf, 0x20220c0, 0x68b249, 0x20220b8, 0x68b0d9) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/vishvananda/netlink/link_linux.go:759 +0x37 github.com/docker/libnetwork/drivers/bridge.newinterface(0x0, 0xc4205f7f40, 0xc4202a0f28) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/interface.go:41 +0xb9 github.com/docker/libnetwork/drivers/bridge.(*driver).createnetwork(0xc42061c000, 0xc4205f7f40, 0x0, 0x0) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/bridge.go:628 +0x39d github.com/docker/libnetwork/drivers/bridge.(*driver).populatenetworks(0xc42061c000, 0x5, 0x1645258) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:48 +0x1e8 </desc> <cmt> vendoring vishvananda/netlink 734d02c </cmt> <cmt> vendoring libnetwork  ed311d0 </cmt>","update check-config.sh, netlink and libnetwork vendoring"
1352,"<desc> based off #19946 </desc> <cmt> [v1.x] migrate to use ecr as docker cache instead of dockerhub (#19654) </cmt> <cmt> [v1.x] update ci build scripts to install python 3.6 from deadsnakes repo (#19788) </cmt> <cmt> * install python3.6 from deadsnakes repo, since 3.5 is eol'd and get-pip.py no longer works with 3.5. </cmt> <cmt> * set symlink for python3 to point to newly installed 3.6 version. </cmt> <cmt> * setting symlink or using update-alternatives causes add-apt-repository to fail, so instead just set alias in environment to call the correct python version. </cmt> <cmt> * setup symlinks in /usr/local/bin, since it comes first in the path. </cmt> <cmt> * don't use absolute path for python3 executable, just use python3 from path. </cmt> <cmt> disable unix-gpu-cu110 pipeline for v1.x build since we now build with cuda 11.0 in windows pipelines. (#19828) </cmt> <cmt> [v1.x] for ecr, ensure we sanitize region input from environment variable (#19882) </cmt> <cmt> * set default for cache_intermediate. </cmt> <cmt> * make sure we sanitize region extracted from registry, since we pass it to os.system. </cmt> <cmt> [v1.x] address ci failures with docker timeouts (v2) (#19890) </cmt> <cmt> * add random sleep only, since retry attempts are already implemented. </cmt> <cmt> * reduce random sleep to 2-10 sec. </cmt> <cmt> [v1.x] ci fixes to make more stable and upgradable (#19895) </cmt> <cmt> * test moving pipelines from p3 to g4. </cmt> <cmt> * remove fallback codecov command - the existing (first) command works and the second always fails a few times before finally succeeding (and also doesn't support the -p parameter, which causes an error.) </cmt> <cmt> * stop using docker python client, since it still doesn't support latest nvidia 'gpus' attribute. switch to using subprocess calls using list parameter (to avoid shell injections). </cmt> <cmt> see </cmt> <cmt> * remove old files. </cmt> <cmt> * fix comment </cmt> <cmt> * set default environment variables </cmt> <cmt> * fix gpu syntax. </cmt> <cmt> * use subprocess.run and redirect output to stdout, don't run docker in interactive mode. </cmt> <cmt> * check if codecov works without providing parameters now. </cmt> <cmt> * send docker stderr to sys.stderr </cmt> <cmt> * support both nvidia-docker configurations, first try '--gpus all', and if that fails, then try '--runtime nvidia'. </cmt> <cmt> fix cd </cmt> <cmt> fix cudnn version for cu10.2 buiuld </cmt> <cmt> war the dataloader issue with forked processes holding stale references (#19924) </cmt>",attemp to fix cd for v1.8.x
1353,<desc> i hereby agree to the terms of the cla available at:  changelog category: documentation for  #17832 </desc> <cmt> edited original article </cmt> <cmt> added russian translation </cmt> <cmt> minor fixes </cmt> <cmt> fixed typos </cmt> <cmt> resolving symling issue </cmt> <cmt> resolving symlink issue </cmt> <cmt> fixed a mistake </cmt> <cmt> minor improvements </cmt>,edited and translated to russian
1354,"<desc> the validate parameter was missing from the constructor's signature (it was already documented in the text lower down, but missing from the signature). clarify that the style parameter is for the fmt parameter, not for log messages. on my first read of the documentation i thought this was saying that logging had built-in support for {format} style log messages. </desc> <cmt> doc: logging.formatter: add missing validate argument </cmt> <cmt> this is already documented in the text lower down, it was just missing </cmt> <cmt> from the constructor's signature. </cmt> <cmt> doc: logging.formatter: clarify what the style parameter is for </cmt> <cmt> i found this confusing: on my first read of the documentation i thought </cmt> <cmt> this was saying that logging had built-in support for {format} </cmt> <cmt> style log messages. </cmt>","add missing validate parameter, clarify style parameter"
1355,"<desc> skydive is a network analyzer tool, which helps in analyzing sdns and network and with this pr ansible api and lookup modules are added to query skydive objects using skydive python client. opened new pr closing the earlier skydive pr #50136 new module pull request skydive </desc> <cmt> skydive node and edge module </cmt> <cmt> skydive node and edge module </cmt> <cmt> skydive node and edge module </cmt>",pr to include support for skydive node and edge modules with ansible
1356,"<desc> what do these changes do? rllib agents now declare their resource requests to tune, so as a user you don't have to. also add a --queue-trials option to tune, which will allow a trial to be scheduled even if it somewhat exceeds the resource capacity of the cluster. this should allow rllib to work with autoscaling clusters in many cases. couple caveats: if the cluster has 0 gpus it won't queue, this is to avoid hangs forever if the cluster would not add more gpus in the future. it's possible some odd shaped resource requests will queue but not trigger auto-scaling, or remain infeasible after autoscaling (e.g. request num cpus greater than the max any single machine can offer). this can be mitigated by just using big machines and setting the autoscaling threshold lower. </desc> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt> <cmt> updates </cmt>",automatically determine rllib resources and add queueing mechanism for autoscaling
1357,"<desc> a common user feedback for rllib developers is that its learning curve is quite steep. this pr aims to start a clean-up and code clarification process with the example of the pg algorithm. adds experimental jsonschema checking. adds lots of comments to algo code. adds readme.md to pg directory, linking to the correct doc section(s). minor other cleanups (docstrings, type annotations, etc..). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt>",first attempt at cleaning up algo code in rllib: pg.
1358,<desc> added an algorithm to approximate the area under a curve i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. </desc> <cmt> a recursive insertion sort </cmt> <cmt> added doctests and typehints </cmt> <cmt> added arc length and numerical integration calculators </cmt> <cmt> fixed doc test </cmt> <cmt> fixed some conversion errors </cmt> <cmt> fixed some commenting </cmt> <cmt> deleted numerical integration to allow 1 file per push </cmt> <cmt> changed string formatting method </cmt> <cmt> added program to calculate trapezoidal area under curve </cmt> <cmt> deleted files ensure 1 pull request per file </cmt> <cmt> file name changed </cmt>,area under a curve algorithm
1359,<desc> the role management api documentation ( this change was discussed briefly in #32635 (comment) </desc> <cmt> [docs] split roles apis into separate pages </cmt> <cmt> [docs] addresses gradle errors </cmt> <cmt> [docs] fixes get roles api examples </cmt> <cmt> [docs] small edits </cmt>,splits the roles api documentation into multiple pages
1360,"<desc> for issue #97. once you create a request, just run r.request.curl for the curl command. for example: >>> import requests >>> r = requests.get("" >>> r.request.curl 'curl -l -x get -h ""accept-encoding:gzip"" -h ""user-agent:python-requests.org"" "" still have the following to do: oauth </desc> <cmt> first commit of curl command from request </cmt> <cmt> using build_url and also including headers </cmt> <cmt> ive never seen anyone use the --'s unix command options </cmt> <cmt> small cleanup </cmt> <cmt> more small cleanup </cmt> <cmt> adding check when _enc_data in none </cmt> <cmt> whitespace </cmt>",issue #97 - turn a request into a curl command string
1361,"<desc> fix the issue #12825 in the file python/mxnet/ndarray/contrib.py, the two functions then_func and else_func don't accept any parameter. the following example works. import mxnet as mx a, b = mx.nd.array([1]), mx.nd.array([2]) pred = a * b < 5 then_func = lambda: (a + 5) * (b + 5) else_func = lambda: (a - 5) * (b - 5) outputs = mx.nd.contrib.cond(pred, then_func, else_func) print (outputs[0]) please feel free to remove inapplicable items for your pr. tiny changes. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change fix example for mxnet.nd.contrib.cond fix typo in src/engine/{engine.cc, threaded_engine.h} </desc> <cmt> fix typo in src/engine </cmt> <cmt> fix example for mx.nd.contrib.cond </cmt>",fix example for mxnet.nd.contrib.cond and fix typo in src/engine
1362,"<desc> in visual studio, we currently trigger directory watchers when saving an open file. in projects with sufficiently large dependencies (i.e., the asp.net core angular template), this causes the module resolution cache to be entirely invalidated, thereby triggering a seconds-long updategraph operation to occur. this change aims to prevent this scenario by checking if the file whose change triggered the directory watcher is still open and, if so, not invalidating the cache. </desc> <cmt> stop invalidating resolution when file stays open </cmt> <cmt> add test </cmt>",stop invalidating module resolution cache when saving an open file
1363,<desc> /area code-organization deviceplugin and pluginregistration are external facing apis. currently we are forcing folks to import them from k8s.io/kubernetes which is not optimal. we should instead make them available from the k8s.io/kubelet repo to make it easier for them. related to #82437 does this pr introduce a user-facing change?: external facing apis in pluginregistration and deviceplugin packages are now available under k8s.io/kubelet/pkg/apis/ </desc> <cmt> move pkg/kubelet/pluginregistration and deviceplugin </cmt> <cmt> change-id: i06adcb43bd278b430ffad2010869e1524c8cc4ff </cmt> <cmt> update bazel build files </cmt> <cmt> change-id: ia3917cec1453c0b22a958faf8c22bccd79242d14 </cmt>,move external facing kubelet apis to staging
1364,"<desc> add in a chart for the vault-operator which issue this pr fixes: fix as pr based off of the etcd-operator </desc> <cmt> starting work on the vault operator </cmt> <cmt> get us some chart-y goodness! </cmt> <cmt> starting work on the vault operator </cmt> <cmt> get us some chart-y goodness! </cmt> <cmt> vault operator chart lints </cmt> <cmt> time to see if it works? </cmt> <cmt> vault operators deploys! </cmt> <cmt> need to test on a real k8s instance, now </cmt> <cmt> starting work on the vault operator </cmt> <cmt> get us some chart-y goodness! </cmt> <cmt> vault operator chart lints </cmt> <cmt> time to see if it works? </cmt> <cmt> vault operators deploys! </cmt> <cmt> need to test on a real k8s instance, now </cmt> <cmt> don't set the etcd-operator to cluster-wide </cmt> <cmt> cuz that'd be bad, mmkay? </cmt> <cmt> validated to be awesome! </cmt> <cmt> last step is to update docs </cmt> <cmt> updated readme with all of the values </cmt> <cmt> updated values </cmt> <cmt> things noticed while documenting them </cmt>",introducing the vault operator chart
1365,"<desc> this runs git diff in the current repo and applies any git patches as code review comments on github. this allows authors to batch apply any auto lint/formatting suggestions and allow gh workflows to run after applying them. the previous method had the github actions token commit the changes, which does not allow workflows to trigger. see </desc> <cmt> rm other workflows </cmt> <cmt> testing </cmt>",git patch --> github review suggestion
1366,"<desc> enable structural opaque types by default remove the -enable-experimental-structural-opaque-types frontend flag ban opaque types in parameter position, per the acceptance decision of se-0328. note that this restriction applies to some appearing anywhere in the parameter type, including positions that do not consume values from the caller, e.g. func test() -> ((some p) -> void) -> void { ... } resolves: rdar://85275081 </desc> <cmt> [frontendoptions] enable structural opaque result types and remove </cmt> <cmt> the -enable-experimental-structural-opaque-types frontend flag. </cmt> <cmt> [sema] ban opaque types in parameter position. </cmt>",enable structural opaque result types.
1367,"<desc> this is part 2 of the 3 major pull requests i plan to do for adding tvos (appletv4) support to mainline. this basically allows us to compile kodi core for arm64 targets. i think its pretty straight forward. once this is in jenkins can build ios builds for arm64 (by simply manually building ios with arm64 cpu set). i plan to do beta, rc and final releases for ios 32bit and 64bit aswell once this is in (for krypton then). cydia supports providing both builds and doesn't allow to install the 64bit one on 32bit devices so this would be save. @wsnipex and maybe @koying or whoever is interested in looking it over. thx to @mrmc and @linusyang once again for finding the needed bits. @linusyang i think you have a much easier live in the future once this was merged (with your custom 64bit builds hehe). </desc> <cmt> [darwin/support] - cleaned up osx and ios support scripts </cmt> <cmt> [darwin/support] - some cleanups for the codesign script, added codesigning of python eggs (by extracting, signing, repackaging them) </cmt>",make kodi core arm64 aware
1368,"<desc> this is an easy place to start, and these functions are probably safe. please review with it in mind that i want to add more fuzz tests later. while the fuzz tests are included in cpython and compiled / tested on a very basic level inside cpython itself, the actual fuzzing happens as part of oss-fuzz ( (this will be necessary sometimes because e.g. the fuzz test should never enter python's interpreter loop, whereas some apis only expose themselves publicly as python functions.) the corresponding oss-fuzz pr adding cpython to oss-fuzz is google/oss-fuzz#731 this particular set of changes is part of testing python's builtins, tracked internally at google by b/37562550. btw, i think the code here is pretty questionable, and am not happy with how complex it is to add a new fuzz test. i'd appreciate input on how to make this friendlier.  i'm also new to cpython and c/c++ development as a whole and suspect i've done everything wildly wrong. (in particular, i think the fuzzer should be written in c, but can't figure out how to make that compile -- see commit cb9cdc0). </desc> <cmt> add basic fuzz tests for a few common builtin functions. </cmt> <cmt> this is an easy place to start, and these functions are probably safe. </cmt> <cmt> please review with it in mind that i want to add more fuzz tests later. </cmt> <cmt> while the fuzz tests are included in cpython and compiled / tested on a </cmt> <cmt> very basic level inside cpython itself, the actual fuzzing happens as </cmt> <cmt> part of oss-fuzz ( </cmt> <cmt> include the tests in cpython is to make sure that they're maintained </cmt> <cmt> as part of the cpython project, especially when (as some will) they </cmt> <cmt> use internal implementation details in the test. </cmt> <cmt> (this will be necessary sometimes because e.g. the fuzz test should </cmt> <cmt> never enter python's interpreter loop, whereas some apis only expose </cmt> <cmt> themselves publicly as python functions.) </cmt> <cmt> this particular set of changes is part of testing python's builtins, </cmt> <cmt> tracked internally at google by b/37562550. </cmt> <cmt> remove fuzzing of hash() per comment by kcc / oss-fuzz-team. </cmt> <cmt>  </cmt> <cmt> move llvmfuzzertestoneinput into cpython and tweak how test discovery occurs. </cmt> <cmt> i'm still not happy with how many times i need to repeat the fuzz test name. </cmt> <cmt> this can go wrong way too easily. :/ </cmt> <cmt> move the fuzzer to c++ so that it builds. </cmt> <cmt> it's possible there's a way to compile this with clang and then link it with </cmt> <cmt> clang++, but i don't know how to do that. </cmt> <cmt> specifically, compilation fails with this: </cmt> <cmt> $cc $cflags \ </cmt> <cmt> -d _py_fuzz_one -d _py_fuzz_$fuzz_test \ </cmt> <cmt> -wno-unused-function \ </cmt> <cmt> $($out/bin/python3-config --cflags) -g -o1 \ </cmt> <cmt> $fuzz_dir/fuzzer.c -o $out/$fuzz_test -lfuzzingengine \ </cmt> <cmt> $($out/bin/python3-config --ldflags) </cmt> <cmt> with errors like: </cmt> <cmt> /usr/local/bin/../include/c++/v1/new:234: undefined reference to operator delete(void*)' </cmt> <cmt> but it works just fine with this: </cmt> <cmt> $cxx $cxxflags \ </cmt> <cmt> -d _py_fuzz_one -d _py_fuzz_$fuzz_test \ </cmt> <cmt> -wno-unused-function \ </cmt> <cmt> $($out/bin/python3-config --cflags) -g -o1 \ </cmt> <cmt> $fuzz_dir/fuzzer.c -o $out/$fuzz_test -lfuzzingengine \ </cmt> <cmt> $($out/bin/python3-config --ldflags) </cmt> <cmt> presumably there are ways to do this in c, so for expediency i'm doing it in c++ </cmt> <cmt> right now, with the minimal possible c++ changes (extern ""c""), so that if i need </cmt> <cmt> to change it back to c in code review, it won't be too hard. </cmt> <cmt> run the fuzz smoke tests on a little more input, just for kicks. </cmt> <cmt> (i.e. just to get increased confidence we won't immediately crash on fuzzing.) </cmt> <cmt> i'm using s# because i'd like to minimize the diff between python 2 and 3. </cmt> <cmt> make the _fuzz module optional. </cmt>","add fuzz tests for float(str), int(str), unicode(str)"
1369,"<desc> general reference: #2339 description: change css output file name to style.css fix test against css file update documentation after output file rename bump package.json after running npm run build documents change in changelog.md i have read the contributing document. additional notes as i noticed, the styling for boilerplate come from the npm package called main.css and it seems to be a bit confusing on a first look. since that package is strongly connected to this project, we might consider: rename it to something that will not affect filename e.g.: html5-boilerplate-styling reorganize repositories to use scoped packages (with @ symbol) e.g.:  @html5-boilerplate/styling </desc> <cmt> change css output file name to style.css </cmt> <cmt> fix test against css file </cmt> <cmt> update documentation after output file rename </cmt> <cmt> bump 'package.json' after running build </cmt>",rename main.css to style.css in build process
1370,"<desc> these used to make sense when we had static allocations in js. we'd use the ""bump"" to track the total size, which was increased by the js compiler, and at runtime we'd have static_base and statictop. now that we disallow static allocations from the js compiler, we don't need them. note that we do still track ""staticbump"" in the metadata from finalize. that is the total size of static memory from lld, which never changes. we use it to compute where the stack begins (which determines the rest of memory layout). in principle since all that layout was done by lld, we could just receive it from there instead of computing it in emscripten.py. perhaps finalize should return the value of __heap_base and other relevant globals? is there a list of all of them? see #11860 </desc> <cmt> remove static_bump setting and statictop variable </cmt> <cmt> remove static* runtime vars </cmt> <cmt> fix </cmt> <cmt> fix test </cmt>",remove static* js vars and static_bump setting
1371,"<desc> removes mentions of asm.js and other unneeded things, and focuses on hopefully more useful content. also fixes the aspect ratio of some of the pngs, which were converted oddly from the svg. this affected the landing page on github </desc> <cmt> wip [ci skip] </cmt> <cmt> more </cmt>",improve the main emscripten landing pages
1372,"<desc> as per my observations based on error stack and googling the things: animal sniff plugin is a bit strict on getting the signatures right especially when the complied java version is different than the target version and there is method signature changes. error: java.lang.nosuchmethoderror: java.nio.bytebuffer.mark()ljava/nio/bytebuffer; maybe these are existing issues but there were caught now at compile time after we upgraded the plugin. as this is blocking the maven release for version 8.10.14, reverting the release commit as well as it contains new dependency jars generated. eg: tools/java/java-build/target/java-build-1.0-snapshot-jar-with-dependencies.jar </desc> <cmt> revert ""metadata updates for release 8.10.14 (#2354)"" </cmt> <cmt> this reverts commit 6e2bbb0c05fece3d1dfcd19cb12b27d03acfde4b. </cmt> <cmt> revert metadata updates for release 8.10.14 (#2354) as the dependency jars generated has issues reported by animal-sniff plugin </cmt> <cmt> revert ""'animal-sniffer-maven-plugin' changes: version is upgraded and extracted into root pom.xml (#2349)"" </cmt> <cmt> this reverts commit e7c4f396917ca64e7618f7dd4788aee509d42332. </cmt> <cmt> making changes back that we mistakenly reverted falsehood commit </cmt>",reverting animal sniff plugin version update pr #2349 and release pr of 8.10.14 #2354
1373,<desc> issue: #1796 fixed the jest incompatibility with mock-fs by switching to jest.mock() unit tests should pass </desc> <cmt> chore(package): update jest to version 21.0.1 </cmt> <cmt> closes #1796 </cmt> <cmt> remove mock-fs and replace it with jest.mock() </cmt>,update jest to the latest version
1374,<desc> fixes #991 assign equation colors starting with the first unused color manual tests </desc> <cmt> fix two pane crash on closing window </cmt> <cmt> merge master </cmt> <cmt> recycle equation colors </cmt> <iss> equation colors should be recycled as soon as they are no longer in use to maximize contrast </iss>,recycle equation colors when no longer in use
1375,"<desc> that pass is a pure optimization: it removes calls to atexit when they would be ignored anyhow (exit_runtime == 0). this removes a warning in atexit's implementation that was never actually called before: we used to always run that pass, so if exit_runtime == 0 then we never had any calls to atexit anyhow. now that we only run the pass when optimizing, leaving that warning would be a noticeable change (and it broke some tests actually!) so just remove it. with that, this is essentially nfc except that non-optimized builds may be a little larger (containing calls to atexit that end up doing nothing). helps webassembly/binaryen#3043 </desc> <cmt> run --no-exit-runtime only when optimizing. see </cmt> <cmt> remove a warning that was never actually shown </cmt>",only run --no-exit-runtime when optimizing
1376,"<desc> merge with contrib: opencv/opencv_contrib#2506 relates #16736 opencv_contrib's sift.cpp history. todo: (backlog #16736) 2 disabled sift tests (backlog #16736) fix c++ compatibility? cv::xfeatures2d::sift::create() (problem is due msvs ambiguous errors) fix python bindings compatibility? cv.xfeatures2d.sift_create() (backlog #16736) fix java bindings compatibility? org.opencv.features2d.sift.create() fix samples / docs allow_multiple_commits=1 </desc> <cmt> [move sift.cpp] fixed contrib code to match the hal </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] fixed hal headers location </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] fix overflow issue when computing diagonal </cmt> <cmt> - with big images the int multiplication can overflow </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] update sift.cpp </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] optimize sift with avx2 </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] parallelize calcdescriptors and builddogpyramid. simplify 2 lines of avx2 instructions </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] multithreading findscalespaceextremacomputer. sort the keypoints afterwards to make the output stable </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] use tls instead of mutex in sift </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] remove unnecessary _mm256_round_ps </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] updated internal calls to linear resize to use bit-exact version </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] xfeatures2d: apply cv_override/cv_final </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] opencv: use cv::autobuffer<>::data() </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] xfeatures2d: use updated tls api </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] merge pull request opencv/opencv_contrib#2301 from ab-dragon:conditionally_compute_dog_pyramid </cmt> <cmt> build dog pyramid if useprovidekeypoints is false </cmt> <cmt> the builddogpyramid operation need not be performed unconditionally. in cases where it is not needed, both memory and speed performance can be improved </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] sift: perf tests and trace regions </cmt> <cmt> original commit: </cmt> <cmt> [move sift.cpp] sift: avoid inplace calls of gaussianblur </cmt> <cmt> - should unlock ipp optimizations </cmt> <cmt> original commit: </cmt> <cmt> features2d(sift): code from nonfree module </cmt> <cmt> features2d(sift): patent expiration note </cmt> <cmt> merge upstream branch </cmt> <cmt> [move sift.cpp] refactored xfeatures2d in the same style as features2d </cmt> <cmt> original commit: </cmt>",move sift to main repository
1377,"<desc> when running a custom install of chrome, and not downloading chromium (with the puppeteer_skip_chromium_download, image snapshots are unable to start up.  i ran across this issue when running storyshots inside a docker container already containing a chrome installation. add a config parameter to use a chrome executable path, instead of downloading chromium inside of puppeteer.  if no parameter is selected, defaults to undefined and operates as normal. add a parameter and check if it references the correct chrome.  in my case: /usr/local/bin/chrome </desc> <cmt> feature: add config to supply executable chrome path to puppeteer </cmt> <cmt> update readme </cmt>",feature/config custom chrome executable path
1378,<desc> upgrade typescript example to chakra ui v1 upgrade to react 17 patch some missing parts and fix broken icons in non typescript example add example how to persist color mode when you refresh the page:  source: </desc> <cmt> upgrade to chakra ui v1 </cmt> <cmt> update theming in chakra ui example to match v1 </cmt> <cmt> fix icons </cmt> <cmt> set container height to fill screen height </cmt>,update chakra ui examples to v1
1379,"<desc> fixes #87718 the problem was that synth_type_param_count was already subtracted from named_type_param_count, so this ended up being subtracted again. this caused expected_min to overflow, and ultimately resulting in weird and wrong behaviour. i've also added another test not present in the original issue but caused by the same bug. </desc> <cmt> fix overflow when calculating expected_min in generics diagnostics </cmt> <cmt> add regression tests </cmt> <iss> ice: 'assertion failed: num_missing_args > 0', compiler/rustc_typeck/src/structured_errors/wrong_number_of_generic_args.rs:234:17 </iss>",explicit_generic_args_with_impl_trait: fix min expected number of generics
1380,"<desc> fixes googleapis/google-cloud-ruby#1327 this only fixes the immediate bug on the client side. it looks like this is still an issue on the server side but thinking that can be done in a follow up pr. it looks like the crash happens because there are stack-allocated things that are reachable through ruby finalizers. normally these stack-allocated objects are safe because their scope is local to the function they're used in. but in the case that a thread is killed during the middle of this rpc function call, finalizers wind up hitting use-after-free errors (only on os x) when they reference something on the killed (and apparantly freed) thread's stack. in general it looks like it's not safe to put anything on stack that's reachable through ruby finalizers. looking into this: slight variation of repro in that issue that just falls off of main while there's an active rpc on a child thread, so that same crash happens under lldb: greeter_server.rb tweaked to: def say_hello(hello_req, _unused_call) sleep 10 helloworld::helloreply.new(message: ""hello #{hello_req.name}"") end greeter_client def main stub = helloworld::greeter::stub.new('localhost:50051', :this_channel_is_insecure) user = argv.size > 0 ?  argv[0] : 'world' thd = thread.new do message = stub.say_hello(helloworld::hellorequest.new(name: user)).message p ""greeting: #{message}"" end sleep 3 end under lldb on os x: first the client starts an rpc and calls run_batch. in here, it stack allocs run_batch_stack it then initializes the run_batch_stack and sets the recv_data_buffer of the ""c-core"" batch pointing to a member of that run_batch_stack lldb shows: (lldb) breakpoint set --file rb_call.c --line 697 breakpoint 2: where = grpc_c.bundlegrpc_run_batch_stack_fill_ops + 663 at rb_call.c:697, address = 0x0000000102102c67 (lldb) continue process 38291 resuming process 38291 stopped * thread #5: tid = 0x50844, 0x0000000102102c67 grpc_c.bundlegrpc_run_batch_stack_fill_ops(st=0x00000001034ffd00, ops_hash=4304184960) + 663 at rb_call.c:697, name = 'greeter_client*', stop reason = breakpoint 2.1 frame #0: 0x0000000102102c67 grpc_c.bundlegrpc_run_batch_stack_fill_ops(st=0x00000001034ffd00, ops_hash=4304184960) + 663 at rb_call.c:697 694 	            &st->recv_metadata; 695 	        break; 696 	      case grpc_op_recv_message: -> 697 	        st->ops[st->op_num].data.recv_message.recv_message = &st->recv_message; 698 	        break; 699 	      case grpc_op_recv_status_on_client: 700 	        st->ops[st->op_num].data.recv_status_on_client.trailing_metadata = (lldb) print &st->recv_message (grpc_byte_buffer **) $3 = 0x00000001034fffb8 then continue until segfault: (lldb) continue process 38291 resuming process 38291 stopped * thread #1: tid = 0x50821, 0x000000010213deab grpc_c.bundleprocess_data_after_md(exec_ctx=0x00007fff5fbff3f0, bctl=0x0000000102808690) + 59 at call.c:1202, queue = 'com.apple.main-thread', stop reason = exc_bad_access (code=1, address=0x1034fffb8) frame #0: 0x000000010213deab grpc_c.bundleprocess_data_after_md(exec_ctx=0x00007fff5fbff3f0, bctl=0x0000000102808690) + 59 at call.c:1202 1199	                                  batch_control *bctl) { 1200	  grpc_call *call = bctl->call; 1201	  if (call->receiving_stream == null) { -> 1202	    *call->receiving_buffer = null; 1203	    call->receiving_message = 0; 1204	    finish_batch_step(exec_ctx, bctl); 1205	  } else { where the 0x1034fffb8 address in exc_bad_access (code=1, address=0x1034fffb8) is pointing the earlier &st->recv_message </desc> <cmt> add test in that sends a sigint to client while its making an rpc ona </cmt> <cmt> child thread - segfaults on mac </cmt> <cmt> allocated run batch stack on the heap </cmt> <cmt> conform test to formatter </cmt> <cmt> malloc run_batch_stack after type checks </cmt> <cmt> wording fix in comments </cmt>",handle dropped ruby threads during active calls - client side
1381,<desc> my submission is formatted according to the guidelines in the contributing guide all changes have been squashed into a single commit </desc> <cmt> added litelink in url shorteners </cmt> <cmt> corrected ordering in url shorteners </cmt>,added litelink for url shorteners
1382,"<desc> future releases of atom-shell will be published to the releases page, instead of uploading to s3. </desc> <cmt> add process.getcurrentstacktrace(), returning v8::getcurrentstacktrace(). </cmt> <cmt> add a simple wrapper of github api. </cmt> <cmt> accept still-preview apis. </cmt> <cmt> correctly deal with api errors. </cmt> <cmt> create new release note or get the existing one when uploading. </cmt> <cmt> :lipstick: find the release even when commit isn't tagged. </cmt> <cmt> handle the assets uploading in the github api library. </cmt> <cmt> upload the asset after release note is created. </cmt> <cmt> silence the output of upload script. </cmt> <cmt> upload both atom-shell and node's headers. </cmt> <cmt> publish the release after the uploading is end. </cmt> <cmt> get the body of release with current $editor. </cmt> <cmt> :lipstick: fix cpplint warnings. </cmt>",upload atom-shell's binaries with releases api
1383,"<desc> this also rewrites the hello world example to use the generated code. this resolves #5418. note: code generated here will only work if using a copy of protoc patched with protocolbuffers/protobuf#1274. the modified example depends on the ""google-protobuf"" npm package, which has not yet been published. code generated by this generator is not api-compatible with code dynamically generated by grpc using protobuf.js. most importantly, request and response objects must be protobuf message objects, not plain javascript objects. i chose a couple of names kind of arbitrarily: service code from ""filename.proto"" is generated in ""filename_grpc_pb.js"" if ""name.proto"" contains a service ""greeter"", then the client constructor is require('name_grpc_pb.js').greeterclient and the service definition is require('name_grpc_pb.js').greeterservice. </desc> <cmt> created a node grpc plugin </cmt> <cmt> rewrite node greeter example to use generated code </cmt> <cmt> minor change to node generator, and add a folder </cmt> <iss> node.js protoc plugin </iss>",create a protoc plugin for node.js grpc
1384,"<desc> some minor parts of ast and hir were not visited by the visit::walk_xxx methods - some identifiers, lifetimes, loop labels, attributes of exported macros - but nothing as serious as in, for example, #28364. added a convenience macro for visiting lists (including options) removed some pre-deref-coersions &** noise from visitors r? @nrc </desc> <cmt> fill in some missing parts in the default ast visitor </cmt> <cmt> + add helper macro for walking lists (including options) </cmt> <cmt> fill in some missing parts in the default hir visitor </cmt>",fill in some missing parts in the default ast and hir visitors
1385,"<desc> this is mostly to get the grunt work of the way. this is split up into multiple commits to hopefully make it more manageable to review. note that these are not full implementations, and the bindings mostly get the low hanging fruit. also implements some attributes that i kept out because they had dashes in them. therefore, this closes #2905. </desc> <cmt> libweb: make all existing html elements ""final"" </cmt> <cmt> libweb: add all html elements between a and f </cmt> <cmt> libweb: add all html elements between l and q </cmt> <cmt> libweb: add all html elements between s and v </cmt> <iss> libweb: some attributes may have a dash in them </iss>",add all currently missing html elements
1386,"<desc> preview : </desc> <cmt> add percpu to export module </cmt> <cmt> correct an issue on quiet mode, refresh time is not take into account </cmt> <cmt> add system and uptime to the export module </cmt> <cmt> avoid crach on olds kernels (issue #554) </cmt> <cmt> change documentation - add color keyword (issue #527) </cmt> <cmt> add docker plugin </cmt>",add docker plugin on angularjs web ui
1387,<desc> i am working to get all languages in grpc/grpc to share a common set of proto files. this is the first in a series of prs to fix #526 </desc> <cmt> moving test.proto to an outer directory so others can depend on it. </cmt> <cmt> move .proto files up for reuse </cmt> <iss> proto proliferation </iss>,move proto files up the tree to prepare for sharing.
1388,"<desc> #3599 the goal was to match the behavior of $near in tests to mongo as close as possible in tests. as such, all the tests i added or updated have been run on server mongo before i started fixing the code. here's the issues i discovered: in mongo, sort as an option overrides $near sort completely and does not use $near as a tie-breaker. when using $near to query an array with an update, mongo always uses the first matching index to update. mongo and minimongo differ in the behavior of observe and applying changes. this seemed out of scope and possibly not an issue for this ticket. mongo does not throw an error on find with $near when it's not a top-level operator like ""{$and:{$near"". instead, it throws an error on fetch(). as such, i thought the current behavior of minimongo (throwing an error on find) is acceptable. </desc> <cmt> sort overrides $near sort - minimongo (#3599) </cmt> <cmt> using $near to query with an update (#3599) </cmt> <cmt> more test cases for update with $near (#3599) </cmt> <cmt> comment grammar (#3599) </cmt>",match $near behavior in minimongo to mongo
1389,"<desc> this pr makes sure that no mask_indices are predicted for padded tokens and thus ensures that the loss for padded tokens is always ignored.  training run is started for wav2vec2 in flax. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> fix_torch_device_generate_test </cmt> <cmt> remove @ </cmt> <cmt> x::qxx </cmt> <cmt> xmerge branch 'master' of </cmt> <cmt> :wqa:merge branch 'master' of </cmt> <cmt> :wmerge branch 'master' of </cmt> <cmt> :wqa:	merge branch 'master' of </cmt> <cmt> start adding tests </cmt> <cmt> correct wav2vec2 pretraining </cmt>",correctly pad mask indices for pretraining
1390,"<desc> a paragraph in the contribution guidelines, following a comment by @reshamas #12878 (comment) </desc> <cmt> doc: instructions for stalled prs </cmt> <cmt> doc: topic -> sections </cmt> <cmt> the goal of this change is to make it easier to find the corresponding </cmt> <cmt> information. </cmt>",how to deal with stalled pr
1391,"<desc> depends on #19882 the transactions table only included the sampling key clause in april (for on prem). there is no possible migration there without migrating to a new table. people may have already created that table and there is no support for data migrations in snuba yet. if we start having users using tracing/preformance on prem, who created the table long before that they may run into troubles when they have enough data in the transactions table to trigger the sampling rate. snuba would reject those queries. this honors the flag introduced in #19882 </desc> <cmt> disable sampling on tag facet </cmt> <cmt> remove option </cmt>",fix(discover) honor discover2.tags_facet_enable_sampling when applying sampling
1392,"<desc> fixes #5484 this change prepares us to use rntester as the primary app for end-to-end ui integration tests.  currently we use our own app inside e2etest.  this will limit us as we'd need to create test pages from scratch.  we already have a lot of potential test coverage with rntester, and we can add whatever pages we want to it as well, so let's use rntester instead. this change moves the 6 existing test pages over to rntester and makes the necessary changes to the test app to load rntester instead of the current app. microsoft reviewers: open in codeflow </desc> <cmt> first batch of changes </cmt> <cmt> change files </cmt> <cmt> lint </cmt> <iss> convert existing e2e test pages to rntester pages </iss>",move e2etest pages into rntester
1393,"<desc> closes #21063 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry the _gotitem implementation for dataframe seems a little strange so there may be a more comprehensive approach, but this should prevent the issue for the time being didn't add whatsnew yet since none existed for 0.23.1. happy to add if we are ok with this fix </desc> <cmt> added test for failure </cmt> <cmt> prevented unlimited recursive aggregation </cmt> <cmt> lint fixup </cmt> <iss> segfault in dataframe.apply with duplicate column names and multiple aggfuncs </iss>",prevent unlimited agg recursion with duplicate col names
1394,"<desc> fixes #6769 when vswhere is missing (or we fail to find msbuild tools), we fail to print an error message before exiting microsoft reviewers: open in codeflow </desc> <cmt> print error message when vswhere is missing </cmt> <cmt> change files </cmt>",print error message when vswhere/msbuild tools are missing
1395,"<desc> for #69955 </desc> <cmt> quick omni - very basic first registry </cmt> <cmt> quick omni => quick access </cmt> <cmt> quick access - very basic first help entries </cmt> <cmt> quick access - operate on picker from providers </cmt> <cmt> quick access - test coverage </cmt> <cmt> quick access - implement help provider </cmt> <cmt> quick access help bugixes </cmt> <cmt> quick access :lipstick: </cmt> <cmt> quick access - contribute help for standalone and workbench separately </cmt> <cmt> quick input - allow to set aria-label </cmt> <cmt> quick access - improved help grouping </cmt> <cmt> quick access - allow provide to return disposable and cancel token properly </cmt> <cmt> quick access - implement ""go to line"" </cmt> <cmt> quick access - implement view handler </cmt>",first cut quick access providers
1396,"<desc> this fix carries #35609, and removed the getblkioweightdevices as it is not compiled in windows. this fix closes #35609. </desc> <cmt> remove import of opencontainers/runc in windows </cmt> <cmt> we are planning to remove supports for non-linux platform in </cmt> <cmt> runc ( </cmt> <cmt> import here is the only thing that i found in docker that is windows-related </cmt> <cmt> so fixing this would remove the rest of windows code in runc. </cmt> <cmt> this changes some functions in daemon_windows to be the same as </cmt> <cmt> daemon_unix to use runtime-spec public api instead of runc. </cmt> <cmt> remove getblkioweightdevices in daemon_windows.go as it is not needed </cmt>",carry #35609 (remove import of opencontainers/runc in windows)
1397,"<desc> changed a method call to comply with coding conventions adding a pair of parenthesis to eliminate a warning given when postgres specs were run. warning was: ""/vagrant/rails/activerecord/test/cases/adapters/postgresql/uuid_test.rb:63: warning: ambiguous first argument; put parentheses or even spaces"" </desc> <cmt> changing method call according to coding conventions </cmt> <cmt> fix to remove warning on postgres adapter test. </cmt> <cmt> warning was: ""/vagrant/rails/activerecord/test/cases/adapters/postgresql/uuid_test.rb:63: </cmt> <cmt> warning: ambiguous first argument; put parentheses or even spaces"" </cmt>",fix to remove warning in postgres adapter test
1398,"<desc> like the view method, the subject methods now accept an optional result tensor. the pr includes two new unit tests : expand and repeattensor. also fixes #59. </desc> <cmt> initial commit for harmonized expand/expandas </cmt> <cmt> expand unit test pass </cmt> <cmt> expand/view doc++ </cmt> <cmt> initial commit for harmonized repeattensor </cmt> <cmt> repeattensor unit test </cmt> <cmt> harmonized repeattensor works (unit tested) </cmt> <cmt> repeattensor doc updated </cmt> <iss> torch.repeattensor() doesn't work with non-contiguous tensor </iss>","harmonized expand, expandas and repeattensor"
1399,<desc> close the file handlers before deleting the logging handlers so that there is no resource warning. since the handlers are a weakreference i tried to close them by calling self.close on __del__ but not all handlers have the lock attribute which resulted in attributeerror. shutdown handles the attributeerror and other scenarios but it will be a much cleaner if we close the handlers during weakref deletion instead of calling shudown which might miss some places. additionally shutdown is also registered at exit which should clean up the current handlers i hope but doesn't handle the ones that were deleted. attached tests and a news entry. kindly correct me if i am wrong on the approach since this is my first non-easy pr and i would like some help on this fix hoping the fix will not be much complex. </desc> <cmt> close resources before deleting logging handlers </cmt> <cmt> add news entry </cmt>,close resources before deletion of logging handlers
1400,"<desc> adds support for via configurator to the southpaw fullsize by switchplate peripherals. adds support for via configurator to the southpaw fullsize my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> begin work on spfs, migrating ancient config </cmt> <cmt> qmk breaks if there's a dash in the board name </cmt> <cmt> update info.json </cmt> <cmt> make indicator leds work </cmt> <cmt> build a readme </cmt> <cmt> change title to match official gb thread name </cmt> <cmt> add an ansi wkl layout for simplicity </cmt> <cmt> adjustments as per pullreq recommendations </cmt> <cmt> remove unused functions from other keymap </cmt> <cmt> add via configurator support </cmt> <cmt> remove layers to fix via </cmt> <cmt> re-add extra via layers since it seems to work now </cmt> <cmt> replace tabs with spaces </cmt> <cmt> update readme.md </cmt>",add via configurator support to southpaw fullsize
1401,"<desc> in #19910, it was pointed out that raising an exception from a future callback would cause the channel spin thread to terminate. if there are outstanding events on the channel, this will cause calls to channel.close() to block indefinitely. this commit ensures that the channel spin thread does not die. instead, exceptions will be logged at error level. this pr fixes #19910. </desc> <cmt> gracefully handle errors from callbacks. </cmt> <cmt> in </cmt> <cmt> raising an exception from a future callback would cause the channel spin </cmt> <cmt> thread to terminate. if there are outstanding events on the channel, </cmt> <cmt> this will cause calls to channel.close() to block indefinitely. </cmt> <cmt> this commit ensures that the channel spin thread does not die. instead, </cmt> <cmt> exceptions will be logged at error level. </cmt> <cmt> remove todo </cmt> <cmt> remove line of dead code </cmt> <iss> python channel close can deadlock when keepalive timeout happens </iss>",gracefully handle errors from future object callbacks.
1402,<desc> continue pr #5057 </desc> <cmt> refactor physicscontact inherits from eventcustom; simplify emitting collision events </cmt> <cmt> fix compile error </cmt> <cmt> remove the workaround cast </cmt> <cmt> conflicts: </cmt> <cmt> cocos/physics/ccphysicscontact.h </cmt> <cmt> issue #3716: refactor physics contact </cmt> <cmt> closed #3716: edit lua support </cmt>,"physicscontact should be inherited from eventcustom, it will simplify the logic of emitting collision events"
1403,<desc> makes progress on #404 replace utstring_printf with std::snprintf for formatting instead of string concatenation note that std::snprintf requires c++11 </desc> <cmt> removed unnecessary utarray include </cmt> <cmt> removed ut_string from logging </cmt> <cmt> fix formatting </cmt>,remove ut string from logging
1404,"<desc> this pr is quite large as it sets the foundation for the changes needed to enable stricter type checking when sending our telemetry events. there are plenty more locations in the code that i haven't touched as this pr was starting to get out from under me, but this gives plenty of examples of what stricter type checking would look like. this will replace gdpr comments with typings which will force the event sent to match the classification provided. this is part of the work for #75527 </desc> <cmt> added command line information to display details about collected telemetry </cmt> <cmt> telemetry tooling exploration </cmt> <cmt> changing telemetry calls to be strongly typed </cmt>",initial strict typing support for telemetry events
1405,<desc> since we've now switched to using travis' native caching feature. cc: @xhmikosr </desc> <cmt> rm travis env vars for giving savage access to defunct custom caching system </cmt> <cmt> reverts a1c170ed373d9076ecf76d264220a6a636239f17 </cmt> <cmt> rm travis env vars used for defunct custom caching system </cmt> <cmt> reverts part of 42697a4ecb2c034c9e88e245932b3914dfd1206c </cmt>,remove travis env vars used for defunct custom caching system
1406,"<desc> this pr fixes #85058 </desc> <cmt> distinguish context key factory from type </cmt> <cmt> improvements to context keys </cmt> <cmt> introduce false & true context keys (#85058) </cmt> <cmt> fixes #85058: handle ismac, islinux, iswindows directly </cmt> <iss> consider keybinding platform context keys on start up </iss>","special handling for ismac, iswindows, islinux"
1407,<desc> @rocketchat/core closes #4371 this adds translatable names and descriptions to the permissions also this pr will sort alphabetically  the en.i18n.js file update: display the technical permission name too </desc> <cmt> work in progress </cmt> <cmt> translate permissions names </cmt> <cmt> and add descriptions to them </cmt> <cmt> remove prefix from the i18n strings (not sorted) </cmt> <cmt> clean up code </cmt>,real permissions names and descriptions
1408,"<desc> chrome_version.h is generated dynamically by bootstrap.py, so it shouldn't be in version control (git). </desc> <cmt> update from original </cmt> <cmt> remove chrome_version.h from git </cmt> <cmt> chrome_version.h is dynamically generated by bootstrap.py so it </cmt> <cmt> shouldn't be in git </cmt> <cmt> add chrome_version.h to gitignore </cmt>",fix create_chrome_version_h so it will generate chrome_version.h only if needed
1409,"<desc> adds the ability to set the lift off distance between the sensor and the surface. currently the default is set to 0x02 (please refer to the datasheet). using #define pmw3360_liftoff_distance xxx will allow the user to set the wanted distance. e.g. #define pmw3360_liftoff_distance 0x27 tested and working add lift off distance change my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> sensor code add </cmt> <cmt> update documentation </cmt>",add configuration of pmw3360 lift off distance
1410,"<desc> commit 87a5346 cherry-picked changes into the 17.03 branch to make the client skip auto-removing containers on api 1.25 and up. some changes got lost during that cherry-pick, resulting in 17.03 clients to not fall back to the old behavior when connecting to api version 1.24 or below. this patch addresses this issue for the 17.03 branch by copying the hostconfig.autoremove property to a local variable before it is overridden in containercreate(). this change is not needed on ""master"" (17.04-dev), which does not have this problem. thanks to @jlhawn  for finding this bug. i also added integration tests in a second commit (32dbb5c), so that we can merge those tests to master </desc> <cmt> [17.03.x] fix autoremove on pre 1.25 api </cmt> <cmt> commit 87a53468b230e6592c547f29f6279a640e368445 cherry-picked </cmt> <cmt> changes into the 17.03 branch to make the client </cmt> <cmt> skip auto-removing containers on api 1.25 and up. </cmt> <cmt> some changes got lost during that cherry-pick, </cmt> <cmt> resulting in 17.03 clients to not fall back to </cmt> <cmt> the old behavior when connecting to api version </cmt> <cmt> 1.24 or below. </cmt> <cmt> this patch addresses this issue for the 17.03 </cmt> <cmt> branch by copying the hostconfig.autoremove property </cmt> <cmt> to a local variable before it is overridden </cmt> <cmt> in containercreate(). </cmt> <cmt> this change is not needed on ""master"" (17.04-dev), </cmt> <cmt> which does not have this problem. </cmt> <cmt> thanks to josh hawn for finding this bug. </cmt> <cmt> add integration tests for client- and daemon-side auto-remove </cmt>",fix autoremove on older api
1411,"<desc> as explained in here, the current computation for precision matrix which uses the inverse of covariance matrix might lead to some instability problem. i think that it is better to compute prec matrix based on scale_tril. </desc> <cmt> stable precision matrix </cmt>",make precision matrix computation in mvn stable
1412,"<desc> fixes #1034 reverts the change that introduced an itemrepeater in place of a listview because of a crashing bug when used with the applicationview api. see microsoft/microsoft-ui-xaml#2011. it is worth noting that i tried to use an itemscontrol instead of a listview but ran into stackoverflow errors for some reason. if anyone can figure out the root cause i think using an itemscontrol would be preferred. launch 2 instances of calculator in graphing mode, ensure that the second instance does not crash on launch make sure equation list and variable list still function as expected </desc> <cmt> replace itemrepeater with listview </cmt> <cmt> allow animations </cmt> <cmt> undo temp key change </cmt> <cmt> remove animation </cmt> <iss> multi instance graphing calculator causes crash </iss>",work around crash by replacing itemrepeater with listview
1413,<desc> the unused ignorecache setting has been removed and so you can't run puppet through this module anymore on puppet 6. 475d69d </desc> <cmt> make puppet module useable on puppet 6 (#46044) </cmt> <cmt> the unused ignorecache setting has been removed and so you </cmt> <cmt> can't run puppet through this module anymore. </cmt> <cmt> see pup-8533 / </cmt> <cmt> (cherry picked from commit 475d69da69d81947c61b47902d198c40e3c72dce) </cmt> <cmt> changelog </cmt>,backport/2.7/46044 make puppet module useable on puppet 6
1414,<desc> mostly so that ctpc works on the arm split branch. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> initial refactor of ergo42 to split common </cmt> <cmt> prevent fallthrough for diode_direction </cmt>,refactor ergo42 to use split_common
1415,<desc> fix issue identified with current scheme for capturing onblock transaction traces. see #9135 (comment) & #9135 (comment) the previous scheme would report an onblock trace for the case where a block is aborted with a valid onblock followed by a non-aborted block with an invalid onblock. added new controller signal block_start for plugins to use to know when a new block starts. added an is_onblock to trace.hpp so this code does not have to be duplicated across various plugins. develop version of #9170 </desc> <cmt> add is_onblock so logic does not have to be duplicated accross multiple plugins </cmt> <cmt> verify block_num of on_block trace to account for possible aborted block followed by a block with no onblock. also moved is_onblock to trace.hpp </cmt> <cmt> add new block_start signal </cmt> <cmt> use new block_start signal as reliable way to clear out cached transaction state </cmt> <cmt> use new block_start signal as reliable way to clear out cached transaction state </cmt> <cmt> use clear_cache method </cmt>,fix onblock trace tracking - develop
1416,"<desc> what do these changes do? the new gcs allows the user to request notifications on specific keys in a table or log. if the key is empty, then no notification is received. this pr adds an empty notification when the client subscribes to an empty key, so that the client can do a read simultaneously with the subscribe. this may impact gcs throughput since extra responses are returned. </desc> <cmt> publish an empty notification for empty keys </cmt> <cmt> add failure callback to table::subscribe, add unit test for new behavior </cmt>",publish a notification for empty keys in the gcs
1417,<desc> in this docs are broken or wrong links and i added a note #14228 </desc> <cmt> update(docs): mark gatsby internal docs for update </cmt> <cmt> update(docs): mark gatsby internal docs for update </cmt>,mark more gatsby internal docs for update
1418,"<desc> added fast path rendering for textblocks when possible. currently textblocks are created using inlines in react-native, even when the textblock doesn't have any nested children, which negatively affects performance in uwp. more documentation here. modified from #2777 avoided editing from text.js so don't need to fork code from react-native. instead edited rawtextviewmanager and textviewmanager. microsoft reviewers: open in codeflow </desc> <cmt> added parent nodes to rawtextmanager, added fast text ability for interpolation </cmt> <cmt> undo textinput changes, removed comments </cmt> <cmt> removed map and used reactinstance instead </cmt> <cmt> removed blank space and unneeded include </cmt> <cmt> removed unneeded concrete casting </cmt>",fast path text from native code
1419,<desc> this pr gets rid of the unnecessary 'run automatic scan' button from the content setting dialogs. it also unifies the behaviour across media types (in particular brings music in sync) </desc> <cmt> changed: make the music set content dialog behave as the video one </cmt> <cmt> it now asks if you want to refresh content if the scraper was changed </cmt> <cmt> changed: get rid of the 'run automatic scan' button from the content setting dialogs </cmt>,get rid of the 'run automatic scan' buttons in the content dialogs
1420,"<desc> currently, if someone tries to pass value that does not implement debug or display to a formatting macro, they get a very verbose and confusing error message. this pr changes the error messages for missing debug and display impls to be less overwhelming in this case, as suggested by #85844. i was a little less aggressive in changing the error message than that issue proposed. still, this implementation would be enough to reduce the number of messages to be much more manageable. after this pr, information on the cause of an error involving a debug or display implementation would suppressed if the requirement originated within a standard library macro. my reasoning was that errors originating from within a macro are confusing when they mention details that the programmer can't see, and this is particularly problematic for debug and display, which are most often used via macros. it is possible that either a broader or a narrower criterion would be better. i'm quite open to any feedback. fixes #85844. </desc> <cmt> improve errors for missing debug and display impls </cmt> <cmt> update test stderr files </cmt> <iss> reduce verbosity of e0277 for `debug` and `display` </iss>",better errors for debug and display traits
1421,"<desc> fixes #75884. this is best reviewed one commit at a time. r? @guillaumegomez originally i tried to do a much broader refactoring that got rid of init_lints altogether. my reasoning is that now the lints aren't being run anymore (after #73566), there's no need to ignore them explicitly. but it seems there are still some lints that aren't affected by setting lint_mod to a no-op: deny(pub_use_of_private_extern_crate) deny(const_err) warn(unused_imports) (there are possibly more, these are just the ones that failed in the rustdoc test suite). some of these seem like we really should be warning about, but that's a much larger change and i don't propose to make it here. so for the time being, this just adds the unknown_lints and renamed_or_removed_lints passes to the list of lints rustdoc warns about. </desc> <cmt> minor refactors </cmt> <cmt> rename debugging_options -> debugging_opts to match rustc </cmt> <cmt> this way the rustdoc field names are the same as the rustc field names. </cmt> <iss> rustdoc does not warn about unknown, renamed, or removed lints </iss>",warn about unknown or renamed lints in rustdoc
1422,<desc> add owners file update logo add hlftoolsversion and mounttls options. update persistence in line with helm best practices. none </desc> <cmt> add owners file </cmt> <cmt> add hyperledger fabric logo </cmt> <cmt> add hlftoolsversion to values.yaml </cmt> <cmt> add mounttls to values.yaml </cmt> <cmt> update persistence according to helm best practices </cmt> <cmt> bump version up </cmt>,update owners + bug fixes and best-practices
1423,"<desc> i hereby agree to the terms of the cla available at:  data type nested now supports arbitrary levels of nesting. introduced subcolumns of complex types, such as size0 in array, null in nullable, names of tuple elements, which can be read without reading of whole column. detailed description / documentation draft: continuation of #14963. this closes #18826. </desc> <cmt> allow to read subcolumns of complex types </cmt> <cmt> better storing info about subcolumns </cmt> <cmt> allow to extract subcolumns from column </cmt> <cmt> better subcolumns for arrays </cmt> <cmt> allow to read subhcolumns from other storages </cmt> <cmt> fix rename of columns </cmt> <cmt> fix storagelog </cmt> <cmt> avoid double reading of subcolumns </cmt> <cmt> fix alters of nested </cmt> <cmt> fixes related to nested </cmt> <cmt> implement nested with multiple nesting </cmt> <cmt> implement nested with multiple nesting </cmt> <cmt> implement nested with multiple nesting </cmt> <cmt> implement nested with multiple nesting </cmt> <iss> cannot access named tuple element by its name using dot </iss>",allow nested with multiple nesting and subcolumns of complex types
1424,"<desc> fixes a number of issues: headings underliners now have the correct length newline+tabs in descriptions are replaced by two newlines to make a proper paragraph properly parse internal hyperlinks in constants description fix broken internal links due to missing newlines show method header even when it has no description, to have something to reference in hyperlinks last part of and thus closes #3064. </desc> <cmt> sync classes ref with code </cmt> <cmt> enhance xml to rst converter </cmt> <cmt> fixes a number of issues: </cmt> <cmt> - headings underliners now have the correct length </cmt> <cmt> - newline+tabs in descriptions are replaced by two newlines to make a proper paragraph </cmt> <cmt> - [br] are replaced by two newlines, making a proper paragraph </cmt> <cmt> - properly parse internal hyperlinks in constants description </cmt> <cmt> - fix broken internal links due to missing newlines </cmt> <cmt> - show method header even when it has no description, to have something to reference in hyperlinks </cmt> <iss> write a documentation exporter to restructuredtext format </iss>",enhance xml to rest converter
1425,"<desc> in order to work with the existing hasteimpl and plugin system of react-native, the built npm package should have all the haste modules in the libraries folder.  currently they are split across the libraries folder and lib/libraries, which causes us to require a custom haste impl, which the default rn getplugins infrastructure doesn't pick up. this will also be a requirement in 0.60 when react-native drops haste entirely. in order to do this i moved the existing js flow files in libraries into src/libraries. added a build step that copies the js files from src/libraries into libraries. modified the ts build to output the transformed js files in the libraries folder instead of the lib/libraries folder microsoft reviewers: open in codeflow </desc> <cmt> move vnext/libraries to vnext/src/libraries </cmt> <cmt> build vnext/src/libraries directly to vnext/libraries </cmt>",consolidate built files into libraries folder
1426,"<desc> original pull-request #16504 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> shrink sequence gtid set </cmt> <cmt> when use mysql master -> mysql slave -> clickhouse materializemysql </cmt> <cmt> engine </cmt> <cmt> and mysql slave enable slave_parallel_worker the gtid in .metadata won't </cmt> <cmt> shrink. </cmt> <cmt> like this: </cmt> <cmt>  </cmt> <cmt> update mysqlgtid.cpp </cmt> <cmt> update mysqlgtid.h </cmt> <cmt> shrink sequence gtid set </cmt>",cherry pick #16504 to 20.8: shrink sequence gtid set
1427,"<desc> while working with the tft refactoring, i had to do a lot of tests with the tft init code. but is very annoying to flash and re-flash to do simple tests. i wanted a way to talk to marlin, and it execute my custom code. so i created a support for a custom gcode that is used only for devs. i named it m9999. the code of m9999 is what the dev need, when he needs it. this way, i could create my own test code, and do a lot of testing sending commands to marlin, without need to flash every time. when enable marlin_dev_mode and dev_custom_gcode, the developer can write custom code in the file: marlin/src/gcode/dev_custom_gcode.h. after the initial skeleton, i added this file in the .gitignore, so it won't be committed by mistake. easier to test marlin when developing! enable: dev_custom_gcode marlin_dev_mode </desc> <cmt> new custom gcode to help developers test their code while working in marlin </cmt> <cmt> to avoid devs commit their custom tests </cmt>",support for debug codes - dnnn
1428,<desc> fixes #16675. following the suggestions in this ticket this pr improves the error message when users try to use dynamic imports while having es2015 as module in the compiler options. </desc> <cmt> make error message for dynamic imports when module is es2015 more helpful </cmt> <cmt> accept baselines for new import call expression error in es2015 </cmt>,better error message for dynamic import with es2015 modules
1429,"<desc> it is fine to resolve the types of exported classes in es6: export class c { } var c = new c() but not for commonjs exported classes: module.exports.c = class { } var c = new c() // should error jsdoc type aliases are an exception since they are always exported implicitly, not by [property] assignment to module.exports or exports. fixes #24492 </desc> <cmt> fix resolution of exported types in commonjs </cmt> <cmt> it is fine to resolve the types of exported classes in es6: </cmt> <cmt> js </cmt> <cmt> export class c { </cmt> <cmt> } </cmt> <cmt> var c = new c() </cmt> <cmt>  </cmt> <cmt> but not for commonjs exported classes: </cmt> <cmt> js </cmt> <cmt> module.exports.c = class { </cmt> <cmt> } </cmt> <cmt> var c = new c() // should error </cmt> <cmt>  </cmt> <cmt> fixes #24492 </cmt> <cmt> all jsdoc type aliases are available locally in commonjs modules </cmt> <iss> in js, crash on incorrect type reference of a module.exports property assignment </iss>",fix exported type resolution in commonjs
1430,"<desc> this adds a callback when an object store node runs out of memory to choose objects to spill, after first attempting to make space through eviction of objects not currently referenced. since spilling is asynchronous, the object store client must try to create the object again. once the object spilling is complete, the object creation will succeed. a todo is to modify the object store to respond to the client asynchronously. this is so that, in the case that we can definitely make enough space by spilling other objects, the object store client does not have to retry the create call on a timer and we do not block the object store while the objects are being spilled. this pr also introduces some changes to the way configs are passed around the cluster to accommodate passing around the object spilling config, which is a json string. long-term, we should have a less brittle way to pass around arbitrary config values. closes #9849. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> automatic spill </cmt> <cmt> object spilling enabled flag </cmt> <cmt> fix config issues </cmt> <iss> [object spilling] automatically spill objects on outofmemory </iss>",add policy to automatically spill objects on outofmemory
1431,"<desc> i was fiddling around on the menus in this pr: #12024 i was finding it strangely tedious to have to click the global nav menus to open them. hover-opening seemed lie it'd be more natural. not sure others will agree, but if they do, we can merge this pr after that one. curious what others think, e.g. @junlin test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> hover opens menus </cmt> <cmt> hover opens menus </cmt> <cmt> linting, removing some styles i added </cmt> <cmt> moving usestate up (non-conditional) </cmt> <cmt> just a tweak to prevent a conflict. </cmt>",global nav menus open on hover
1432,"<desc> hope this is fine. i replaced the star import in tests.serializers as ""explicit is better than..."" (and code validators like pyflakes don't work very well with them). i also added a test that makes sure that all fields from the fields meta-attribute are passed as expected. </desc> <cmt> bye bye star import </cmt> <cmt> added test that makes sure that fields with </cmt> <cmt> dictionaries as data are returned as expected and </cmt> <cmt> not turned into string representations </cmt> <cmt> added test for modelserializer meta fields </cmt> <cmt> returning as expected </cmt>","tests for pull #358 ""return dictionaries as is"""
1433,<desc> when a page is auto prerendered we delay updating the aspath until after mount to prevent breaking hydration. to prevent the url from flashing this moves the populating of aspath into the router fixes: #8749 </desc> <cmt> prevent updating url when delaying aspath </cmt> <iss> prerendered pages incorrectly edit router state during hydration </iss>,prevent url from being updated while aspath is delayed
1434,"<desc> tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry oversight from my other pr syncing 3.9 builds </desc> <cmt> update actions-39.yaml </cmt> <cmt> update azure-windows-39.yaml </cmt> <cmt> update actions-39-slow.yaml </cmt>",add numba back to 3.9 env
1435,"<desc> follow up for this comment on pr #12745. previously i was tracking base time for all fibers, regardless of whether they were inside of a profiler, because the place where i started the timer didn't yet know if it was in a profilemode. i could move where i start/stop the timer somewhere else- where it would know- but this approach seemed simpler. it has a small potential downside of not measuring ""base"" time for the profiler component itself- but i think this is okay because (1) that time should be minimal and (2) it isn't really actionable for a developer. questions should i remove the conditionals around stopbaserendertimerifrunning? (is it worth having them?) caveats we pause/resume the global render timer even outside of a profilemode tree. this only updates a single numeric value though; it doesn't modify any attributes on a fiber. </desc> <cmt> conditionally start/stop base timer only within profile mode tree </cmt> <cmt> added test to ensure profilertimer not called outside of profiler root </cmt>","only measure ""base"" times within profilemode"
1436,<desc> document how to set up so11y for cluster add label filter to aggregate metrics from dedicated labels. update self.yaml add ui template for so11y. </desc> <cmt> fix some issues for so11y </cmt> <cmt> update ui </cmt>,update prometheus fetcher for so11y
1437,"<desc> mcu that supports emergency_parser. add emergency_parser to lpc tests & update emergency_parser comment in configuration_adv.h to call out the other non-supported platforms. catch potential build-breaking changes from being merged like #17953. #17955 and prs #17953 & #17961 </desc> <cmt> add emergency_parser to lpc tests </cmt> <cmt> update emergency_parser comment </cmt> <cmt> emergency_parser has not been implemented for esp32, stm32f1/4/7, or teensy 3.5/3.6 mcus. </cmt>",add emergency parser to lpc tests
1438,"<desc> fixes #10507 to silence the futurewarning in categoricalencoder, i replace str with np.str_ in calls to np.issubdtype as @rth proposed. n/a </desc> <cmt> replace str with np.str_ in calls to np.issubdtype </cmt> <cmt> add test </cmt> <cmt> fix futurewarning in tests </cmt> <iss> futurewarning in categoricalencoder due to np.issubdtype </iss>",fix futurewarning in categoricalencoder due to np.issubdtype (#10507)
1439,"<desc> based on the discussion in the pitch, tweak concurrentvalue checking for functions: collapse all of the logic about concurrently-executing local functions into a simple ""local capture"" check don't require the parameter and result types of a @concurrent function (type) to conform to concurrentvalue. </desc> <cmt> [concurrency] simplify checking for local functions. </cmt> <cmt> treat them as local captures and require them to be @concurrent. </cmt> <cmt> [concurrency] don't diagnose non-concurrentvalue parameters/result type of @concurrent functions. </cmt> <cmt> thanks to jordan rose and john mccall, who pointed out why this checking was unnecessary. </cmt> <cmt> as a drive-by, ensure that we diagnose parameter references properly. </cmt>",improve concurrentvalue checking for functions
1440,"<desc> hey, this is continuation of work done by @drogus. basically it moves actionview outside of actionpack to its own directory. av still remains dependency on ap, i will be working on this in coming weeks. however, after discussing it with @drogus, both of us agreed that it would be good to have those commits in master. (they are basically just moving files, not much changes is code itself) because: @kaspth is working on his gsoc loofah project - it touches actionview so it will be super hard to solve conflicts either for him or me once one of our branches get merged. it'll be hard for me if somebody will make some changes in master to rebase it. / </desc> <cmt> add bare actionview gem to the root directory </cmt> <cmt> this commit creates structure for action view gem and is first of a </cmt> <cmt> series of commits extracting action view from action pack. </cmt> <cmt> move actionpack/lib/action_view* into actionview/lib </cmt> <cmt> actionview version should be 4.1.0 </cmt> <cmt> move template tests from actionpack to actionview </cmt> <cmt> remove unneeded files </cmt> <cmt> add actionpack as actionview's development dependency </cmt> <cmt> actionview still relies on actionpack in some of the tests. </cmt> <cmt> remove unneeded test fixtures in av </cmt> <cmt> copy company test fixture to av (fixes failing test) </cmt> <cmt> remove digestor fixtures from ap </cmt> <cmt> they were moved to actionview/ and are not used in actionpack </cmt> <cmt> fix digestor tests </cmt> <cmt> remove require to ap stuff that left </cmt> <cmt> template test were moved to av </cmt>",extract actionview to separate directory
1441,"<desc> ticks three checkboxes in #8982. </desc> <cmt> libjs: replace string const& with stringview in various temporal aos </cmt> <cmt> this is especially helpful where we already pass stringview literals </cmt> <cmt> and only compare them with others, e.g. overflow and largest/smallest </cmt> <cmt> unit, in which case there's no need to actually allocate a string. </cmt> <cmt> libjs: implement temporal.plaintime.prototype.tostring() </cmt> <cmt> libjs: implement temporal.plaintime.prototype.tolocalestring() </cmt> <cmt> libjs: implement temporal.plaintime.prototype.tojson() </cmt>","implement temporal.plaintime.prototype.to{string,localestring,json}()"
1442,"<desc> see #3445 </desc> <cmt> modify borg check unit test so it ""hangs"", see #3444 </cmt> <cmt> it doesn't infinitely hang, but slows down considerably. </cmt> <cmt> (cherry picked from commit a68d28bfa4db30561150c83eb6a0dca5efa4d9e8) </cmt> <cmt> check --repair: fix malfunctioning validator, fixes #3444 </cmt> <cmt> the major problem was the ('path' in item) expression. </cmt> <cmt> the dict has bytes-typed keys there, so it never succeeded as it </cmt> <cmt> looked for a str key. this is a 1.1 regression, 1.0 was fine. </cmt> <cmt> the dict -> stabledict change is just for being more specific, </cmt> <cmt> the check triggered correctly as stabledict subclasses dict, </cmt> <cmt> it was just a bit too general. </cmt> <cmt> (cherry picked from commit e09892caec8a63d59e909518c4e9c230dbd69774) </cmt>","fix for borg check --repair malfunction, #3444 (master)"
1443,"<desc> fixes #2130 by taking inspiration from #2466 changes inputtypes, audio, video, input, postmessage and daturi tests to use the addtest function isntead of adding the values directly to the modernizr object. that way they also provide a css class. </desc> <cmt> refactor audio- and video- to be more like csscolumns-tests. that way they also provide a css class. </cmt> <cmt> refactor inputtype tests to be more like csscolumns-tests. that way they also provide a css class. </cmt> <cmt> refactor postmessage tests to be more like csscolumns-tests. that way it also provides a css class. </cmt> <cmt> refactor datauri tests to be more like csscolumns-tests. that way it also provides a css class. </cmt> <iss> modernizr.inputtypes no class set. </iss>",use addtest for some tests like inputtypes
1444,"<desc> this refactors the gcsactormanager to remove some of its dependencies. this also adds a unit test for checking that the actor is dead after node death vs worker death. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> parametrize test </cmt> <cmt> regression test and logging </cmt> <cmt> test no restart after actor deletion </cmt> <cmt> unit tests </cmt> <cmt> refactor to subscribe to and lookup from worker failure table </cmt> <cmt> refactor actormanager to remove dependencies </cmt> <cmt> revert ""regression test and logging"" </cmt> <cmt> this reverts commit 835e1a9091b51ca8efb00392d4cc4a665145de24. </cmt> <cmt> revert ""parametrize test"" </cmt> <cmt> this reverts commit f31272082831ba1a494816dd5511d87b24eca4c9. </cmt> <cmt> revert ""test no restart after actor deletion"" </cmt> <cmt> this reverts commit 114a83de14329aa6ab787c80cd5757cf074a9072. </cmt> <cmt> doc </cmt> <cmt> merge </cmt> <cmt> revert ""refactor to subscribe to and lookup from worker failure table"" </cmt> <cmt> this reverts commit 6aa13a05178d0b9aa1db9dee5c978c911b74fa3a. </cmt>",actor manager refactor and unit tests
1445,"<desc> doesn't effect typing speed by using the ""absolute positioning flexbox repaint hack"" </desc> <cmt> use flexbox to arrange panes </cmt> <cmt> rename .row and .column to .pane-row and .pane-column </cmt> <cmt> bootstrap's .row and .column css was influencing our pane rows and </cmt> <cmt> columns. </cmt> <cmt> use absolute divs to limit repaints on keypresses </cmt>",this replaces custom pane resizing with flexbox
1446,<desc> according the source code there are missed required parameter 'el: raphaelelement' in methods insertafter() and insertbefore() methods of raphael.d.ts </desc> <cmt> update raphael.d.ts </cmt> <cmt> add required parameter 'el: raphaelelement' to insertafter() and insertbefore() methods </cmt> <cmt> update raphael.d.ts </cmt> <cmt> add required parameter 'el: raphaelelement' to raphaelset.insertbefore() and raphaelset.insertafter() </cmt>,rapaelelement' to insertafter() and insertbefore() methods
1447,"<desc> upgrade abseil submodule and bazel dependency to 20210324.2 abseil/abseil-cpp@278e0a0 i've reverted the podspec change since that needs some additional work that @veblush is working on. the podspec will be upgraded once that is done. </desc> <cmt> update submodule abseil-cpp to abseil lts 20210324, patch 2 </cmt> <cmt> update bazel dependencies and generate projects </cmt>","upgrade abseil to lts 20210324, patch 2"
1448,"<desc> with this pr i'm looking to add some features to serenityos chess that are present in most popular chess platforms, which would make the program more capable. this includes: + copy board state as fen string + replay moves and navigate move history with arrow keys + import games using pgn files to replay and analyze them + highlight squares and draw arrows on the board for illustration please notify me about any issues you may (and probably will) find, i'm glad to get to them as soon as possible and try to resolve them.   : ) </desc> <cmt> chess: change keyboard shortcuts </cmt> <cmt> use some better keyboard shortcuts that make more sense and are more </cmt> <cmt> common, instead of random function keys. </cmt> <cmt> chess: added ability to copy board state as fen </cmt> <cmt> you can now copy the board state as forsyth-edwards notation. you can </cmt> <cmt> then paste this into other chess programs/games, or into ours when </cmt> <cmt> it gets implemented. </cmt> <cmt> chess: add ability to replay moves </cmt> <cmt> this patch allows the user to go back and forward in move history </cmt> <cmt> to replay moves from the game. this is view-only however, and as soon </cmt> <cmt> as a move is made the board returns to it's current state. this will </cmt> <cmt> work well for replaying games loaded in with pgn files, once that's </cmt> <cmt> implemented. </cmt> <cmt> chess: added abilty to import pgn files </cmt> <cmt> this patch allows the user to load games using pgn files. the parsing </cmt> <cmt> is not complete and has a bunch of work left to be done, but it's </cmt> <cmt> okay for our use case here. it can load all of the games our pgn </cmt> <cmt> exporter can save. as the chess program impoves so can the pgn parser. </cmt> <cmt> chess: added ability to put markings on the board </cmt> <cmt> with this patch you can use right-click to mark a square on the board. </cmt> <cmt> you can add modifier keys to the click to change to alternate color </cmt> <cmt> (with ctrl) or secondary color (with shift). if you right-click and </cmt> <cmt> drag from one square to another you will create an arrow. the </cmt> <cmt> markings go away as soon as you left-click on the board or the board </cmt> <cmt> state changes. </cmt> <cmt> note: the arrows sometimes look weird, and horizontal ones get cut </cmt> <cmt> off. they also don't account for alpha. this is not a bug in </cmt> <cmt> chess code, rather, likely in the fill_path() function that's </cmt> <cmt> used to draw the arrows. if anyone might know what's up with </cmt> <cmt> that i urge you to take a look. :) </cmt>","add fen copy, replay functionality, pgn import, board markings"
1449,"<desc> you use react native more, the more native parts you will touch. need more advanced articles about this part. </desc> <cmt> add two articles about writing native component in ios </cmt> <cmt> add two articles about writing native component in ios </cmt>",more article about native component
1450,"<desc> fixes #11269. fixes #12865. see also #9499 allow a callable to be passed to refit in *searchcv to balance score and model complexity. this interface adds flexibility in identifying the ""best"" estimator. the function passed to parameter refit incorporate of which metric to optimise. hence users can use multi-metric evaluation with this interface. 2 test cases added: test_refit_callable() add an example of choosing the mode with the least mean_test_score test_refit_callable_multi_metric() test the same example in a multi-metric evaluation setting added documentation describing this feature to users(see additions in _search.py under model_selection directory) added a example(plot_grid_search_refit_callable.py) of demonstrating the usage of this interface under examples/model_selection/ this implementation passes all test suites by running make checklist: rewrite test case for refit=callable using simple dummy refit function. rewrite test case for refit=callable using similar example in multi-metric eval settings add functions in _search.py to pass the above tests documentation polishing </desc> <cmt> allow for refit=callable in *searchcv to balance score and model complexity #11269. </cmt> <cmt> update comments in test case #11269 </cmt> <cmt> add test cases and add multi-metric scoring support </cmt> <iss> allow for refit=callable in *searchcv to balance score and model complexity </iss> <iss> allow gridsearchcv() to account for model variance to select .best_estimator_ </iss>",allow for refit=callable in *searchcv to add flexibility in identifying the best estimator #11269
1451,"<desc> basically, my change was very simple - switch from sum operations to subtraction to avoid type casting in checks and type overflow during flieloginputstream work, especially in cases where property log.segment.bytes was set close to the integer.max_value and used as a position inside nextbatch() function. all related unit tests are working as intended. no new tests (probably) required. </desc> <cmt> slightly improved batch position checks, extended type to avoid overflow errors </cmt> <cmt> second approach to the batch position checks overflow problem, avoiding unnecessary type conversion. </cmt>",improved fileloginputstream batch position checks in order to avoid type overflow related errors
1452,"<desc> this attempts to fix the annoying new add-ons being disabled thing in pvr. it removes the clients table from pvr, and uses the standard add-ons table for ids now instead, and only disables new add-ons when they don't have a user set configuration. add-ons won't be disabled when they have the following in addon.xml in the pvr extension point (this only applies to pvr add-ons): needs_configuration=false it also stops the add-ons from being disabled when the database is reset. ping @jalle19 you had another pr for this some time ago, can you test this please </desc> <cmt> added: caddondatabase::getaddonid() </cmt> <cmt> [pvr] changed: removed the special clients table for pvr, and use the add-on ids from the addonmanager </cmt> <cmt> [pvr] changed: no longer disable all new add-ons when creating a new pvr db </cmt> <cmt> [pvr] fixed: don't disable all new add-ons by default, only the ones that need configuration </cmt> <cmt> by default, all add-ons are marked as needing a configuration. overrule in addon.xml, by adding needs_configuration=false to the pvr extension point </cmt>",fix add-ons new being disabled
1453,"<desc> we currently have windowsbrush code in the microsoft fork of react-native. this change ports that code into react-native-windows as forked files, to help get us off the microsoft fork. also added a test page to rntester as there is currently no test code that uses windowsbrush. addresses #3788 microsoft reviewers: open in codeflow </desc> <cmt> merge </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> move windowsbrush stuff over from fork </cmt> <cmt> added rntester page </cmt> <cmt> change files </cmt>",port windowsbrush code into react-native-windows
1454,"<desc> this cleans up that code and makes us only include what we need. this doesn't help builds with metadce, that removed unneeded stuff anyhow, but does help other levels, and the python code is also cleaner this way i think. it also helps a lot in modes that can't use metadce like main module (see test updates). this also uncovered a minor bug with tempret0 which we need for dynamic linking, and wasn't being imported. before we just happened to work since we imported all the library functions anyhow. </desc> <cmt> only emit necessary things in asmlibraryarg in the wasm backend </cmt> <cmt> wip [ci skip] </cmt> <cmt> fix </cmt> <cmt> cleaner </cmt> <cmt> python3 fix </cmt> <cmt> cleanup </cmt> <cmt> nicer </cmt> <cmt> nicer </cmt> <cmt> remove unused var </cmt> <cmt> fix </cmt>",stop importing all libraryfunctions into the wasm module in the wasm backend
1455,"<desc> addresses one of the files in issue #8278 make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> added small test for bigquery sensor </cmt> <cmt> removed file from missing_test_files </cmt>",added test for bigquery sensor
1456,"<desc> r? @manishearth  note that the commit e898015 doesn't exist like this in the clippy repo. i didn't want to do a full sync, because this would've included at least one new lint, which i wanted to avoid a week before beta is branched. this just reverts one commit from the last sync. </desc> <cmt> revert ""pass clippy args also trough rustflags"" </cmt> <cmt> special sync of 'e89801553ddbaccdeb2eac4db08900edb51ac7ff' </cmt>",revert change from last sync
1457,"<desc> fixes below warnings using raw strings and !=. fixes isalive attribute error. ./glances/config.py:108: deprecationwarning: invalid escape sequence \ self.re_pattern = re.compile('(\.+?\)') ./glances/outputs/glances_curses.py:700: syntaxwarning: ""is not"" with a literal. did you mean ""!=""? if p is not 'load': ./glances/amps/glances_systemd.py:20: deprecationwarning: invalid escape sequence \/ """""" ./glances/amps/glances_systemv.py:20: deprecationwarning: invalid escape sequence \/ """""" ./glances/amps/glances_nginx.py:20: deprecationwarning: invalid escape sequence \/ """""" ./glances/amps/glances_default.py:20: deprecationwarning: invalid escape sequence \/ """""" new feature: no fixed tickets: #1585 </desc> <cmt> fix deprecationwarning regarding invalid escape sequence. fix syntaxwarning regarding literal comparison. </cmt> <cmt> use is_alive instead of isalive for python 3.9 compatibility. </cmt>",fix warnings and improve python 3.9 compatibility.
1458,"<desc> this is xref #27700 (comment) closes #13420 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add test for issue 13420 </cmt> <iss> dataframe.groupby(grp, axis=1) with categorical grp breaks </iss>",add tests for groupby categorical values with axis=1
1459,"<desc> the module defaults for gcp aren't up-to date with the current gcp modules, breaking the module defaults functionality for a lot of gcp_* modules. in pr #60172 the gcp facts modules were changed to info modules. but the module defaults weren't updated, and still refer to the to the removed gcp_*_facts modules instead of gcp_*_info. not all existing gcp modules are present in the module defaults this pr changes all the gcp_*_facts references into gcp_*_info, and adds the missing gcp_* modules to the module defaults for gcp module defaults for gcp following playbooks throws an error about missing arguments, despite the fact that they are present in the module_defaults - name: setup gcp components hosts: localhost connection: local gather_facts: no module_defaults: gcp_compute_instance_info: zone: europe-west1-b group/gcp: project: project-name-123456 auth_kind: serviceaccount service_account_file: ""../credentials.json"" scopes: -  tasks: - name: load instance info gcp_compute_instance_info: filters: - name=test-instance-1 register: test_instance - name: setup gcp components hosts: localhost connection: local gather_facts: no module_defaults: group/gcp: project: project-name-123456 auth_kind: serviceaccount service_account_file: ""../credentials.json"" scopes: -  tasks: - name: create an instance gcp_filestore_instance: name: test_object zone: us-central1-b tier: premium file_shares: - capacity_gb: 2660 name: share1 networks: - network: default modes: - mode_ipv4 state: present play [setup gcp components] ****************************************************************************************************************************************************************************************************************** task [load instance info] ******************************************************************************************************************************************************************************************************************** fatal: [localhost]: failed! => {""ansible_facts"": {""discovered_interpreter_python"": ""/usr/bin/python""}, ""changed"": false, ""msg"": ""missing required arguments: zone, auth_kind""} play recap *********************************************************************************************************************************************************************************************************************************** localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0 play [setup gcp components] ****************************************************************************************************************************************************************************************************************** task [create an instance] ********************************************************************************************************************************************************************************************************************* fatal: [localhost]: failed! => {""ansible_facts"": {""discovered_interpreter_python"": ""/usr/bin/python""}, ""changed"": false, ""msg"": ""missing required arguments: auth_kind""} play recap *********************************************************************************************************************************************************************************************************************************** localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0 </desc> <cmt> renamed gcp_*_facts to gcp_*_info </cmt> <cmt> added missing gcp modules to gcp module defaults group </cmt>",add missing gcp modules to module defaults
1460,"<desc> added support for new wireless receiver with oled display to comet46 keyboard. the oled related code was based on those of the crkbd and helix. the keymaps ""default"" and ""satt"" have been modified to support oled. the previous ""default"" keymap was renamed to ""default-rgbled"" files were modified to follow the code style of this project checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> add oled support for comet46 </cmt> <cmt> fix length of char ""name"" of keylogger.c </cmt> <cmt> update ssd1306 </cmt> <cmt> fix rules.mk </cmt> <cmt> update led-receiver keymap </cmt> <cmt> update oled related code </cmt> <cmt> add mod_state_reader & modify led_state_reader </cmt> <cmt> update oled related files </cmt> <cmt> update kemaps </cmt> <cmt> update readme </cmt> <cmt> change default-oled-display to default </cmt> <cmt> add osm compatibility to mod_state_reader </cmt> <cmt> code formatting </cmt> <cmt> use progmem to store code_to_name </cmt> <cmt> clean up satt keymap </cmt> <cmt> rename default-led keymap to defult-rgbled </cmt>",comet46 add support for oled
1461,"<desc> i've changed the way the and input component decides whether there is an error or not. input doesn't have any state related to errors any more. instead the error is hold completely inside props. some examples: // this will show an error <input name=""input"" error=""this is an error"" /> // these will not show an error <input name=""input"" /> <input name=""input"" error={undefined} /> <input name=""input"" error={null} /> this is more declarative than having to call seterror and removeerror and allows components to use the input more concisely. additionally i also made type=""text"" default for the input (although this is something debatable). </desc> <cmt> make type optional and fall back to 'text' </cmt> <cmt> fix tabs -> spaces </cmt> <cmt> make error prop more declarative </cmt> <cmt> also respect error={null} on input </cmt>",make input component more useful (respects error prop declaratively)
1462,"<desc> a port of #12412 to 1.3.x branch. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> infer dtype in symbolblock import from input symbol </cmt> <cmt> fix lint issues and make existing tests pass </cmt> <cmt> add tests for importing a fp64 model into symbol block </cmt> <cmt> fixing failing test for test symbol block </cmt> <cmt> set context in unit tests </cmt> <cmt> add tests for fp16, add default dtype in infer_param_types </cmt> <cmt> use tmp directory as root for loading from model zoo to avoid race condition </cmt> <cmt> fixing naming and parameter selection in test case </cmt> <cmt> fixing failing gpu tests </cmt> <cmt> make unit test more deterministic to get param name </cmt> <cmt> override cast in symbol block, handle grouped symbol </cmt> <cmt> handle multiple symbolic input usecase </cmt> <cmt> add tests to verify behavior of symbolblock.cast </cmt>",infer dtype in symbolblock import from input symbol (v1.3.x)
1463,"<desc> fixes #52671 reverts return_timestamps from nxos, ios, iosxr #50261, #52670, #50323, #50095 timestamps can be implemented in task using </desc> <cmt> revert ""nxos_command:run_commands results failure when commands array size >1 (#52670)"" </cmt> <cmt> this reverts commit 0df5b92af37d43da20125dc418f1cb92390a8a25. </cmt> <cmt> revert ""added timestamps to nxos_command module (#50261)"" </cmt> <cmt> this reverts commit e1509433144572e5010d0ced72a2129600dd8bd4. </cmt> <iss> nxos_command:run_commands is broken when return_timestamps set to false </iss>","revert nxos, ios, iosxr return_timestamps"
1464,"<desc> #2749 returned the negative levels to pre-#1562 behavior. i.e., skipping stepsize positions every iteration. this pr emulates #1562-like stepping by applying the stepsize skip every other position. this pr addresses #2827. benchmarks silesia.tar on gcc-10: silesia.tar on clang-13: status i believe this pr is ready for merge. </desc> <cmt> stagger application of stepsize in zstd_fast </cmt> <cmt> this replicates the behavior of @terrelln's zstd_fast implementation. that </cmt> <cmt> is, it always looks at adjacent pairs of positions, and only applies the </cmt> <cmt> acceleration every other position. this produces a more fine-grained </cmt> <cmt> acceleration. </cmt> <cmt> decompose step into two variables </cmt> <cmt> this avoids an additional addition, at the cost of an additional variable. </cmt> <iss> compression ratio for --fast=2 and higher became significantly worse. expected? </iss>",stagger stepping in negative levels
1465,"<desc> guards against min/max being macros. sometimes, particularly when microsoft's windows.h is included, min/max are defined as macros, interfering with use of std::numeric_limits::min() and the like.  to guard against this, the function name is wrapped in an extra set of parenthesis, which inhibits function-style macro expansion. two separate commits here: one for document.h and one for test code. </desc> <cmt> guard against min/max being macros in document.h </cmt> <cmt> sometimes, particularly when microsoft's windows.h is included, min/max </cmt> <cmt> are defined as macros, interfering with use of </cmt> <cmt> std::numeric_limits::min() and the like. </cmt> <cmt> to guard against this, the function name is wrapped in an extra set of </cmt> <cmt> parenthesis, which inhibits function-style macro expansion. </cmt> <cmt> guard against min/max macros in tests too </cmt>",guard against min/max being macros in a cross-compiler way
1466,"<desc> issue: #9261 before this pr, every c++ completionqueue object creation ended up calling grpc_init  which acquires a mutex g_init_mu to increment the number of grpc-init invocations. this is ok if the number of completion queues being created was small. however, in case of c++ synchronous server, a completion queue is create for every call. this ends up making g_init_mu one of top created mutexes in sync servers. this pr makes calling grpc_init optional when creating c++ completionqueue objects. it is always set to true by default but if a c++ completionqueue  is being created by passing a grpc_completion_queue * pointer i.e the following constructor (which is what sync c++ server calls when creating a per-call completion queue), it is okay to not call grpc_init. class completionqueue : private grpclibrarycodegen { .. explicit completionqueue(grpc_completion_queue* take); .. } this change is safe because if we got a grpc_completion_queue * structure, we must have already called grpc_init(). benchmark results i added a new benchmark bm_createdestroycpp2 (didn't previously include it as a part of the pr because i thought it is trivial - but on a second thought, i think it is a good idea :)) locks are down from 3 to 1 on master (with bm_createdestroycpp2 temporarily ported): sreek@sreek-dev:~/workspace/grpc (master) $ bins/counters/bm_cq --benchmark_filter=bm_createdestroycpp2 run on (12 x 3501 mhz cpu s) 2017-03-29 10:54:34 benchmark                     time           cpu iterations ----------------------------------------------------------- bm_createdestroycpp2        215 ns        215 ns    3230778 locks/iter:3 atm_cas/iter:0 atm_add/iter:3 allocs/iter:1 on this pr branch: sreek@sreek-dev:~/workspace/grpc (init-free-cq) $ bins/counters/bm_cq --benchmark_filter=bm_createdestroycpp2 run on (12 x 3501 mhz cpu s) 2017-03-29 10:56:15 benchmark                     time           cpu iterations ----------------------------------------------------------- bm_createdestroycpp2        160 ns        160 ns    4413813 locks/iter:1 atm_cas/iter:0 atm_add/iter:3 allocs/iter:1 </desc> <cmt> do not call grpc_init() for per-call-completion-queues created by a c++ </cmt> <cmt> synchronous server </cmt> <cmt> do not call grpc_init() for per-call-completion-queues created by a c++ </cmt> <cmt> synchronous server </cmt>",do not call grpc_init() for per-call-completion-queues created by a c++ sync server
1467,"<desc> this pr is to fix: the link of tf.contrib.learn.estimator. as we can see in the note section of kernel method tutorial, the two below highlighted link was broken and i can see from the latest source code the second one was fixed while the first one wasn't pointed to the correct place; note: this document uses a deprecated version of ${tf.estimator}, which has a ${tf.contrib.learn.estimator$different interface}. it also uses other contrib methods whose ${$version_compat#not_covered$api may not be stable}. the accurate link of input function section. it should be @{$get_started/premade_estimators#create_input_functions$this section on input functions} instead of #input_fn. </desc> <cmt> fix several broken links in kernel method tutorials </cmt> <cmt> forgot to save when rebase master </cmt> <cmt> fix different interface link in kernel method </cmt>",fix two external anchor link in kernel method tutorial
1468,"<desc> unregister when exiting react only to actual device insertion/removal, ie do not reenumerate the usb bus to find a cec adapter when a cd is inserted... i don't see any risk here, but doing a pr since we're close to release. </desc> <cmt> [win] properly filter wm_devicechange message to reenumerate usb bus only on usb hid device insertion and removal </cmt> <cmt> [win] cosmetics for previous commit (d2377c86) </cmt>",fix a couple device notifications issues
1469,"<desc> add support for group layers when parsing json output from tiled as requested in issue #4099.  along the way, i believe i discovered some problems with the way phaser parses infinite tiled maps and fixed those as well.  infinite map layers might still have 'offsetx' and 'offsety' properties but these were previously being ignored.  they are now accounted for properly. i have tested all these changes against the phaser3-examples both visually and with the 'tester' script and everything that worked before the changes works the same as after my changes.  i added several tests to the examples repo in my local working copy that tested groups and an infinite map to ensure those parts work as well.  those examples are not a part of this pr as they were on top of the examples repo and not this one. here is a quick summary of changes: added logic to each of the layer type parsers (tiled, object, and image) to account for group layers. added a file with a single function that creates the important state that needs to be inherited from a group. uses an iterative approach to traversing the group hierarchy with a stack rather than recursion. all hierarchy is flattened to a single array of layers and the group layers are discarded after they are accounted for. layer names are prepended with any containing group names separated by slashes ('/') updated documentation for the tilemap gameobject to mention support for layers and the renaming that can occur. updated error reporting when an invalid tile layer name is requested in order to pre-empt any confusion surround the renaming of layers.  now lists the valid layer names. </desc> <cmt> support for tiled groups and infinite map fixes </cmt> <cmt> - added support for tiled group layers (issue #4099) </cmt> <cmt> - fixed some layer offset bugs for infinite maps </cmt> <cmt> updates for supporting group layers </cmt> <cmt> - updated documentation to mention support for groups and naming layers </cmt> <cmt> - added more verbose output when an unknown layer name is specified </cmt> <cmt> > error output now lists the valid layer names </cmt> <cmt> - added functions to return array of tile, object, or image layer names </cmt>",support for tiled layer groups
1470,"<desc> i've added the option to specify the button field of the webmouseevent that was being sent, because without that my example (selecting text with sent events) didn't work - i also set the text and unmodifiedtext fields on char and rawkeydown events, because without that the actual ""typed"" key didn't appear in my inputs. i also set the type of the keycode to char16 and removed the failing condition on an undefined vkey, because without this i wouldn't have been able to type characters other than the ones on the english keyboard. </desc> <cmt> adding option to specify the button of webmouseevent. </cmt> <cmt> added text and unmodifiedtext setting when sending char type keyboard events, and made the type of the character read char16, so i can simulate char events from non-english origins. </cmt> <cmt> added documentation about the changes </cmt>",option to specify button on a mouseevent and text on a keyboardevent when using sendinputevent
1471,"<desc> added save and reset buttons. added warning message for unsaved settings. #1564 - settings ui epic </desc> <cmt> add settings ui string localization (#7833) </cmt> <cmt> <!-- enter a brief description/summary of your pr here. what does it fix/what does it change/how was it tested (even manually, if necessary)? --> </cmt> <cmt> moved all strings into resources file for localization. </cmt> <cmt> <!-- other than the issue solved, is this relevant to any other issues/existing prs? --> </cmt> <cmt> <!-- please review the items on the pr checklist before submitting--> </cmt> <cmt> * [ ] closes #xxx </cmt> <cmt> * [x] cla signed. if not, go over [here]( </cmt> <cmt> * [ ] tests added/passed </cmt> <cmt> * [ ] documentation updated. if checked, please file a pull request on [our docs repo]( </cmt> <cmt> * [ ] schema updated. </cmt> <cmt> * [x] i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx </cmt> <cmt> <!-- provide a more detailed description of the pr, other things fixed or any additional comments/features here --> </cmt> <cmt> <!-- describe how you validated the behavior. add automated tests wherever possible, but list manual validation steps taken as well --> </cmt> <cmt> add save button </cmt>",add save button to settings ui
1472,<desc> this ports the following utilities to libmain: allocate aplay asctl bt this also adds a syscall wrapper for gethostname which is used by the bt utility. </desc> <cmt> allocate: port to libmain :^) </cmt> <cmt> aplay: port to libmain </cmt> <cmt> asctl: port to libmain :^) </cmt>,port to libmain + add sycall wrapper for gethostname
1473,"<desc> closes #23878 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> bug/tst - do not multiply period diff result by freq scaling factor </cmt> <cmt> tst - reference issue number in test </cmt> <iss> bug: non-standard frequency period arithmetic </iss>",bug - remove scaling multiplier from period diff result
1474,"<desc> this fixes #1054.  this is a strange interaction between the following: convenience method like request.get() called the result of url.parse(x) passed as the uri option the request results in a cross-protocol redirect. </desc> <cmt> add test for regression introduced in c052e9c </cmt> <cmt> when the result of url.parse() is passed to one of the convenience </cmt> <cmt> methods like request.get(), then cross-protocol redirects will fail </cmt> <cmt> later on.  see #1054. </cmt> <cmt> fix #1054 </cmt> <iss> failing https redirect since version 2.41.1 </iss>",fix redirects when passing url.parse(x) as url to convenience method
1475,"<desc> the following pr is a clumsy way to implement #11940 basically i've replicated the readme logic as well trying to generalise it whenever possible. i'd love to get your thoughts as well some hints about how to test this, eventually. i put some notes in the code - i hope you might clarify those points. // </desc> <cmt> added changelogurl to local extension rapresentation </cmt> <cmt> propagate the changelog url from the zip file if any </cmt> <cmt> add getchangelog method to iextension and its impl </cmt> <cmt> display the changelog nav bar </cmt> <cmt> generalise and resuse markdown rendering function </cmt> <cmt> get changelog url in installed extension as well </cmt> <cmt> provide correct localized strings </cmt>",provide a changelog tab when this file is bundled in the package
1476,<desc> still running into issues running ti on ubuntu 18.04 even though successful compilation. </desc> <cmt> update readme and fix execute_process </cmt> <cmt> updated readme with 18.04 instructions </cmt> <cmt> added commands from hyperlink </cmt> <cmt> added instructions for cuda 10.1 install </cmt> <cmt> updated ubuntu 18.04 instructions </cmt>,updating ubuntu 18.04 quick start instructions
1477,<desc> description: adds the 'lx' unit for the light sensor (e.g xiaomi aquara illumination sensors). related issue (if applicable): fixes #14129 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> add support for light sensors with lx unit </cmt> <cmt> add test for light sensor with 'lx' unit </cmt> <iss> homekit doesn't support light sensors with unit 'lx' </iss>,add support for light sensors with 'lx' unit to homekit
1478,<desc> @adichat </desc> <cmt> add anagram_search js file </cmt> <cmt> add instructions </cmt> <cmt> rewrite instructions for js implementation </cmt> <cmt> add two helper function skeletons and main function </cmt> <cmt> add functionality to remove white spaces and build a character count hash table </cmt> <cmt> add functional code </cmt> <cmt> add tests </cmt>,add javascript solution for anagram search
1479,"<desc> refer to #542 . with this, we can get rid of mingw in windows. and it is easier to build r-package in osx as well. also, it is easier to build gpu version for r-package in windows. @laurae2 any comment?  can you also help to test the new build? </desc> <cmt> add r's library file to vs project and cmake. </cmt> <cmt> support using dll built by vs. </cmt> <cmt> better search for the library file. </cmt>",compile r package by custom tool chain.
1480,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues fix apache/skywalking-ui#119 </desc> <cmt> update doc for ui deploy </cmt> <iss> move the deploy document to skywalking repo </iss>,update doc for ui deploying
1481,"<desc> follow-up to #4463. at minimum, we want to run python and c++ tests. in particular, we want to ensure that the generated python wheel is broadly compatible, e.g. on following platform combinations: windows server 2008 r2 without gpu windows server 2012 r2 with gpu + cuda 9.0 windows server 2016 with gpu + cuda 10.0 windows server 2019 with gpu + cuda 10.1 </desc> <cmt> add cmake option to use bundled gtest from dmlc-core </cmt> <cmt> consistently apply openmp flag to all targets </cmt> <cmt> build xgboost with gtest </cmt>",add python and c++ tests for windows gpu target
1482,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). #17239 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. jquery can export jquerystatic if global.document is available. module.exports = global.document ? factory( global, true ) : function( w ) { if ( !w.document ) { throw new error( ""jquery requires a window with a document"" ); return factory( w ); }; this also corrects the factory signature and makes the import form import * as $ from 'jquery'; possible. </desc> <cmt> [jquery] false | false = false </cmt> <cmt> [jquery] factory() is not a global. </cmt> <cmt> [jquery] fix export. </cmt>",module should export factory or jquerystatic
1483,"<desc> add retext-spell in order to spell-check our docs and fix a couple of spelling errors. also add an update-dictionary script to make adding new words to the dictionary easier. motivation being able to auto-check words means that we can keep the gatsby style easier. method i created dictionary.txt by running retext-spell once and then extracting/sorting the ""mispelled"" words. i looked over the file by hand to find any obvious misspellings, brand name capitalizations, and locale-specific spellings and applied them. there's more stuff that we can improve/regularize, such as putting filenames and code in backticks, but i can leave it to follow-up prs and community maintainers. todo make sure that emoji are spell-checked correctly. script to update dictionary if new words are used. caveats if ""new words"" are used, they have to be added to the dictionary. i'll write a script to enable that but it may get cumbersome having to constantly update the dictionary with new words (or it might catch some misspellings more, who knows!) follow-up prs backticks on function names like usestaticquery backticks on package names (e.g. gatsby-source-filesystem) standardize more brands and term names: gatsby/gatsbyjs graphql ""cms"" (we have like five different ways we pluralize cms) </desc> <cmt> try to get spelling to work </cmt> <cmt> more stuff </cmt> <cmt> try again </cmt> <cmt> this was a mustako </cmt> <cmt> this was a mistake </cmt> <cmt> make a dictionary </cmt> <cmt> revert old docs </cmt> <cmt> updated dictionary </cmt> <cmt> fix some spelling errors </cmt> <cmt> fix some spelling errors </cmt> <cmt> update dictionary </cmt> <cmt> fix some more typos </cmt> <cmt> more stuff </cmt> <cmt> more stuff </cmt> <cmt> more stuff </cmt> <cmt> more stuff </cmt> <cmt> go through entire list </cmt>",add retext-spell to check spelling
1484,"<desc> add a new keymap for kbd67/hotswap, designed for people who both code and have to write math in non-latex environments on os x. checklist: my code follows the code style of this project. i have read the contributing document. ( tested on a physical kbd67. </desc> <cmt> custom keymap. </cmt> <cmt> fix magic layer, enable unicode. </cmt> <cmt> update readme. </cmt> <cmt> make unicode config change keymap-local. </cmt>",new kbd67/hotswap keymap for writing both code and math
1485,"<desc> this fixes the problem described in  the last commit makes sure that the order of the list in the musicvideo library node when accessed through the music library is the same as the default order in the video library. right now it's alphabetical which imo doesn't make much sense. this only happens when accessed through the music library because when accessed through the video library we use the custom library node defined in library://video/musicvideos/ instead of videodb://musicvideos/ which is used by the music library. i'm happy to drop the last commit if it isn't accepted for gotham. </desc> <cmt> cvideodburl: fix option name ""artistid"" instead of ""actorid"" for musicvideos </cmt> <cmt> videodb: don't duplicate join statements in musicvideo album sql queries </cmt> <cmt> videodatabasedirectory: make sure to translate all ids in the path of a grouped node into url parameters (fixes #14333) </cmt> <cmt> fix predefined sorting of musicvideo nodes (when accessed through the music library) </cmt>",only show albums of the selected musicvideo artist
1486,"<desc> fixes #3927 component name external bash collector module apcupsd. add chart for online flag with 0/1. only send that metric when the reported ups stats are invalid. </desc> <cmt> add chart for online status for bug #3927 </cmt> <cmt> add chart for online status for bug #3927 </cmt> <iss> apcupsd: connection loss further collects data, but it should stop </iss>",apcupsd add check for ups online
1487,"<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. related #2786 </desc> <cmt> fix typehints in project_euler/problem01 </cmt> <cmt> squashed commit of the following: </cmt> <cmt> commit 6801d073b31bf702814861cd3b07b634ca295bfa </cmt> <cmt> author: archaengel <god11341258@gmail.com> </cmt> <cmt> date:   mon oct 5 16:40:10 2020 -0700 </cmt> <cmt> fix typehints in project_euler/problem01 </cmt> <cmt> commit 29afc3af114abd1b99dc3f7c8fc99128229db131 </cmt> <cmt> author: archaengel <god11341258@gmail.com> </cmt> <cmt> date:   mon oct 5 15:06:34 2020 -0700 </cmt> <cmt> add typehints and default argument for project_euler/problem_01 </cmt> <cmt> add default args, typehints, and expand variable names for pe prob 02 </cmt> <cmt> add style improvements for first solution of pe problem 02 </cmt> <cmt> add default arg and typehints for second solution of pe problem 02 </cmt> <cmt> add default arg for third solution of pe problem 02 </cmt> <cmt> add style improvements for 1st soln of pe problem 03 </cmt> <cmt> add default arg and typehints for 2nd soln of pe problem 03 </cmt> <cmt> add default arg for 3rd soln of pe problem 03 </cmt> <cmt> remove unnecessary newlines </cmt> <cmt> remove unnecessary newlines </cmt> <cmt> fix end of file for 2nd soln in pe problem 03 </cmt> <cmt> add style improvements to solutions for pe problem 04 </cmt>",add style improvements to solutions for project euler problem 04
1488,"<desc> mysqlnd_field_type_name is not used anywhere. my research turned up nothing. it looks like a leftover from some previous functionality. either i am too dumb to understand or get_parameter_metadata is just dead code. i can't see any references to this method anywhere. stat triggers is a functionality that doesn't seem to be used anywhere. it doesn't look like it harms performance, but if nobody uses it then it might be prudent to just drop this functionality and have cleaner code. </desc> <cmt> remove mysqlnd_field_type_name </cmt> <cmt> remove get_parameter_metadata </cmt> <cmt> drop mysqlnd statistics triggers </cmt> <cmt> this functionality is not used productively in php and it's not used in </cmt> <cmt> any of the extensions to my knowledge. since it looks like this functionality </cmt> <cmt> isn't required by anyone, let's clean up mysqlnd and drop it. </cmt>","mysqlnd refactoring (remove mysqlnd_field_type_name, get_parameter_metadata, and mysqlnd stat triggers)"
1489,"<desc> in this commit i have: added javadoc to every file except for the java files in the ""heap"" package i took the files with spaces and renamed them so they don't have spaces let me know what you think and my work so far. </desc> <cmt> in this commit i have: </cmt> <cmt> added javadoc to every package except for ""heaps"" </cmt> <cmt> i have also deleted these files in my commit </cmt>",javadoc and no spaces in file names
1490,"<desc> i have followed (at least) the pr section of the contributing guide. closes #29338 problem: with inputprops={{ classname: browser-default }} on a textfield component, input element has two of the same classname: browser-default. before: code sandbox:  after: code sandbox: </desc> <cmt> [inputbase] handle classname item in inputprops separately </cmt> <cmt> [inputbase] add test </cmt> <iss> [textfield] classname passed in `inputprops` is added twice to `input` element </iss>",do not repeat the same classname
1491,"<desc> this pr is related to #1956. vs 2019 has been released recently and the latest cmake 3.14.1 supports it. therefore we can reorder generators (and platform toolsets) to try to build lightgbm with vs 2019 firstly. due to that cmake dropped the possibility to specify architecture inside generator name (win64), we can set it via -a option, which was presented in cmake since 3.1 and we require >=3.8 for windows (it's shorter and better than setting cmake_generator_platform directly and allows to handle all generators in the same way). i'm doubt about only one thing: whether we need to specify -t host= option or not. its default behavior differs in vs 2019 compared to all other versions: 2019: by default this generator uses the 64-bit variant on x64 hosts and the 32-bit variant otherwise. 2017: by default this generator uses the 32-bit variant even on a 64-bit host. this option controls the following: -- check for working cxx compiler: c:/program files (x86)/microsoft visual studio/2017/enterprise/vc/tools/msvc/14.16.27023/bin/hostx86/x64/cl.exe -- works |------| ^ | v |------| -- check for working cxx compiler: c:/program files (x86)/microsoft visual studio/2017/enterprise/vc/tools/msvc/14.16.27023/bin/hostx64/x64/cl.exe -- works refer to  remaining things: add a link to msvc redistributable 2019 here; it's still unavailable from ms support site done!; add a bullet for matching boost binaries with vs 2019 here; latest 1.70.0b1 doesn't contain 14.2 version. upd: ... but 1.70 does: </desc> <cmt> set platform via a option </cmt> <cmt> style hotfix </cmt> <cmt> updated r installation script </cmt> <cmt> updated python installation script </cmt> <cmt> updated ci test script </cmt>",better compatibility with visual studio 2019
1492,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> upgrade to viewer v7.2 </cmt> <cmt> release notes: </cmt> <cmt> upgrade to viewer v7.4 </cmt> <cmt> release notes: </cmt> <cmt> added getdefaultgeometry method </cmt> <cmt> added getdefaultgeometry method </cmt> <cmt> added missing methods to navigation class: </cmt> <cmt> - getworldpoint </cmt> <cmt> - screentoviewport </cmt> <cmt> added missing method to viewer3dimpl class: </cmt> <cmt> - viewporttoray </cmt> <cmt> added missing methods to navigation and viewer3dimpl classes </cmt> <cmt> getdocumentnode returns any rather than object </cmt> <cmt> added interface to specify api endpoint </cmt> <cmt> move properties to top of the class </cmt> <cmt> update type definitions for viewer. </cmt>,add missing members and properties
1493,"<desc> this pr changes (delete as applicable) nothing, it's a bug fix i don't understand why this works, but for some reason in tween.js, the play method needs this.parent.**manager.**makeactive(this); when state is pending_remove or remove.  however, when this.parentistimeline in the play method, this.parent.makeactive(this); is sufficient. </desc> <cmt> #3190 tweens/timeline parent.makeactive missing </cmt>",fix #3190 tweens/timeline parent.makeactive missing
1494,"<desc> i fixed some of the style errors flake8 was showing from the changes we made yesterday.  i also excluded the setup.py file, which i suppose isn't necessary since we are only testing flake8 on 3.6 and the reason for exclusion was a 2.7 issue.  i've also added build stages so the style test only runs after all of the pytest suites run.  seemed complicated but it works. </desc> <cmt> added flake8 back in and added jobs for style and unit tests </cmt> <cmt> lets see if these build stages work </cmt> <cmt> this is annoying </cmt> <cmt> fixed some style issues </cmt> <cmt> added some steps to the build process </cmt> <cmt> trying a different config to see if that works </cmt> <cmt> build-matrixes? </cmt> <cmt> this is complicated </cmt> <cmt> matrix setup </cmt> <cmt> ugh </cmt> <cmt> well it works for 2.7 help me ken! </cmt> <cmt> only running pyflakes on 3.6, test next build step on 2.7 and 3.6 </cmt> <cmt> try again </cmt> <cmt> fingers crossed </cmt> <cmt> fingers crossed x2 </cmt> <cmt> fix parsing error </cmt> <cmt> make it pretty </cmt> <cmt> final before merge </cmt>","re-enable flake8 testing, add build stages to travis testing"
1495,"<desc> prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  returns a reference to the eventemitter, so that calls can be chained. </desc> <cmt> update in return type of ""on() event"" method. </cmt> <cmt> now the return type from the ""on"" methods that are part of ""events"" are ""this"". now attach events to some object is chainable. </cmt> <cmt> added ready event on chainable method. </cmt>","johnny five - add return type to ""on() event method"" according to its parent class."
1496,"<desc> three small datatype-related fixes that most importantly make 24-bit flacs sound correct. no more playback noise! libaudio: rescale integer samples correctly in flac loader the flac samples are signed, so we need to rescale them not by their bit depth, but by half of the bit depth. for example, a 24-bit sample extends from -2^23 to 2^23-1, and therefore needs to be rescaled by 2^23 to conform to the [-1, 1] double sample range. this makes all flac files sound double as loud, which is expected behavior. libaudio: fix overflow on 24-bit flac lpc data when computing sample values from a linear predictor, the repeated multiplication and addition can lead to very large values that may overflow a 32-bit integer. this was never discovered with 16-bit flac test files used to create and validate the first version of the flac loader. however, 24-bit audio, especially with large lpc shifts, will regularly exceed and overflow i32. therefore, we now use 64 bits temporarily. if the resulting value is too large for 32 bits, something else has gone wrong :^) this fixes playback noise on 24-bit flacs. </desc> <cmt> libaudio: use size_t in loops </cmt> <cmt> this is more idiomatic :^) </cmt> <cmt> libaudio: rescale integer samples correctly in flac loader </cmt> <cmt> the flac samples are signed, so we need to rescale them not by their bit </cmt> <cmt> depth, but by half of the bit depth. for example, a 24-bit sample </cmt> <cmt> extends from -2^23 to 2^23-1, and therefore needs to be rescaled by 2^23 </cmt> <cmt> to conform to the [-1, 1] double sample range. </cmt> <cmt> libaudio: fix overflow on 24-bit flac lpc data </cmt> <cmt> when computing sample values from a linear predictor, the repeated </cmt> <cmt> multiplication and addition can lead to very large values that may </cmt> <cmt> overflow a 32-bit integer. this was never discovered with 16-bit flac </cmt> <cmt> test files used to create and validate the first version of the flac </cmt> <cmt> loader. however, 24-bit audio, especially with large lpc shifts, will </cmt> <cmt> regularly exceed and overflow i32. therefore, we now use 64 bits </cmt> <cmt> temporarily. if the resulting value is too large for 32 bits, something </cmt> <cmt> else has gone wrong :^) </cmt> <cmt> this fixes playback noise on 24-bit flacs. </cmt>",fix 24-bit flac audio and related issues
1497,"<desc> checklist closing issues: #issue i wrote some lines in the radare2book i found that the original mips.gnu assembler is using some really old binutils codes, so i migrate some new mips support components from the current master branch of binutils-gdb, fit them into radare2's old headers and make some adjustments to let them act like before. i run ""make tests"" before pr and found nothing is broken for now. </desc> <cmt> refresh old files with current binutils codes(copyrights notes are not updated for now) </cmt> <cmt> add remain components from binutils-gdb </cmt> <cmt> update original copyright messages </cmt> <cmt> modify mips disassembler to match output style </cmt> <cmt> try to fix wrong jalx argument decoding </cmt>",improve mips support(mips.gnu) by migrating new codes from binutils
1498,"<desc> cherry pick #37340 to 5.5 re-apply #37531 </desc> <cmt> revert ""future-proof the layout of asynctask."" </cmt> <cmt> this reverts commit 7eb105236a10107fa63db325bc3fc0ccfc3f547c. </cmt> <cmt> [tasklocals] enable sync functions to bind task-locals; keep storage in tls </cmt> <cmt> [tasklocals] propagate task-locals through async{} </cmt>","pick task locals in sync functions, reapply asynctask layout"
1499,"<desc> add support mks mini12864 v3 for robin e3p board and fix pin add mks mini12864 v3 pin define for mks robin e3p board add support read card file by lcd (sd on lcd) mks_robin_e3/e3d, mks_robin_nano_v2, mks_robin_e3p, mks_robin_nano_v3 board, if use mks mini12864 v3 add #define lcd_screen_rot_180 function (default: disable) </desc> <cmt> bugfix 2.0.x </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> bugfix 2.0.x </cmt> <cmt> add support mini12864 v3 for e3p board </cmt>","mks mini12864 v3 for robin e3p, etc."
1500,<desc> this fixes the problem that the application crashes when dragging a file to a non-valid index in the table. at the same time the file will be opened in this case. i add a signal/slot to communicate with extendtablewidget and mainwindow and validate index after drop anything. </desc> <cmt> add signal if file dropped </cmt> <cmt> check if index is valid </cmt> <cmt> send signal and return if index is invalid and file was dropped </cmt> <cmt> connect dropsignal to fileopen </cmt>,source trigger patch file drop
1501,"<desc> description: this patch adds support for controlling roller shades through the cover component on the lutron platform. pull request in home-assistant.github.io with documentation (if applicable):  as with the lutron light component, no configuration is necessary (or available) as shades are detected automatically. checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> adding support for lutron radio ra2 shades as cover components. </cmt> <cmt> adding initial version of the lutron shades component. </cmt>",adding support for lutron covers
1502,<desc> fixes accidental breaking change introduced in 1.5.0. we can probably fix this in an even more robust/intelligent way but this should fix it for 99.9999% of people as-is. </desc> <cmt> add failing test </cmt> <cmt> only wrap with variants if rules don't already contain any variants </cmt> <cmt> remove stale test </cmt>,support manual @variants in addcomponents for <1.5 backwards compat
1503,"<desc> hi this is part of #51430. i'm a first time contributor, so i started with a small task adding a bit of documentation for from impls. </desc> <cmt> added comment for from trait implementation: boxed string slice to string </cmt> <cmt> added comments for trait implementations. </cmt>",add documentation for from impls
1504,"<desc> this is #3170, but with prop iteration inlined into patchdomelement() so that the loop can be reused to capture special prop values. </desc> <cmt> (restructure) prevent terser 5 from inlining functions </cmt> <cmt> we are heavily reliant on reduce_funcs, which was removed in terser 5, but [will be added back in 5.2.2 or 5.3]( </cmt> <cmt> in the meantime, we have to disable reduce_vars to prevent function inlining, although this has a large size cost since it also prevents variable inlining. </cmt> <cmt> create .ignore-me </cmt> <cmt> delete .ignore-me </cmt> <cmt> create ignore-me.js </cmt> <cmt> update to microbundle 0.13.2 to get terser 5.7 </cmt> <cmt> update package exports to drop es5-esm build </cmt> <cmt> remove temp file </cmt> <cmt> remove node-13-exports workaround </cmt> <cmt> remove references to preact.module.js </cmt> <cmt> remove all .module.js files </cmt> <cmt> fix coverage reporting and babel transpilation </cmt> <cmt> [test] manually inline diffprops </cmt> <cmt> remove unused import </cmt> <cmt> update microbundle to allow turning off function inlining </cmt> <cmt> small size tweak for createcontext </cmt> <cmt> inline prop iteration into patchdomelement and reuse the loop to capture special prop values. </cmt>",restructure prevent terser inlining (alt)
1505,<desc> what do you think about creating a file just for frameworks alone? now only for js it exists.. we could differentiate the resources for programming languages & frameworks? </desc> <cmt> removed explore flask link - not free </cmt> <cmt> sorted things.. </cmt> <cmt> sorting..:bowtie: </cmt>,removed false link and sorted things..
1506,"<desc> alternate to #27955 (can't push to their remote) but with a more robust distance measurement. closes #27955 distance of 90 was correct for a clock width of 260 as found in previous versions ( repro: @eps1lon please find the issue reproduced here:  when you click/drag the selector over one of the outer numbers (0-12) you will realize that unless you add a significant buffer to the inner circle, it will select/snap to the inner numbers (13-24) instead. </desc> <cmt> fix hours distance value </cmt> <cmt> distance of 90 was correct for a clock width of 260 as found in previous versions. now that clock_width = 220, the distance needs to be reduced by the same ratio to ~76.15 or 76 in order to get the correct time value. </cmt> <cmt> robust distance detection </cmt>",fix to narrow hover area for am hours in am/pm clock
1507,"<desc> the fix itself is worthless. the main goal here is to check in an interesting test case. rdar://problem/31302713 </desc> <cmt> sema: narrow fix for a circular protocol conformance checking case </cmt> <cmt> we go to look at the conforming protocols of an associated type </cmt> <cmt> but we haven't built the generic environment for the associated </cmt> <cmt> type's protocol yet. </cmt> <cmt> in the test case given, we find the conformance later via a </cmt> <cmt> different path, so everything continues to work. </cmt> <cmt> substitutionmap::lookupconformance() is hopefully getting a </cmt> <cmt> makeover soon, and this hack will go away. </cmt> <cmt> fixes <rdar://problem/31302713>. </cmt> <cmt> ast: repent for my sins by adding new assertions </cmt> <cmt> since the previous fix is essentially a hack to dodge an </cmt> <cmt> assertion, i'm adding stronger assertions to </cmt> <cmt> abstracttypeparamdecl::getsuperclass() and </cmt> <cmt> getconformingprotocols(). </cmt>",workaround for issue with multi-file fake recursive conformance
1508,"<desc> minimal fix to ensure that all returns have line numbers. skipping news as i think pep 626 is covered well enough already. i expect this to be a temporary fix for 3.11, as we will implement a proper fix for line number propagation. </desc> <cmt> guarantee that line number is set for returns. </cmt> <cmt> add test for linenumber of return in nested try statements. </cmt> <cmt> remove misleading comment </cmt>",force return_value bytecodes to have line numbers
1509,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> fix invalid table maxheight prop type </cmt> <cmt> add tests and remove erroroneous patch version </cmt>,fix incorrect type in table component maxheight prop
1510,<desc> while cleaning up the visual studio project i noticed that there are a few view related files scattered in the xbmc root directory (i.e. xbmc/) which could be moved into their own directory (and for linux into their own library) to clean things up a bit and make them easier to find. if accepted this will need some xcode work. </desc> <cmt> move view related files into new view folder and lib </cmt> <cmt> [win32] update vs project files </cmt>,move all view related files into xbmc/view
1511,"<desc> i really hope i don't have to do this again and this fixes the seo issue once and for all... </desc> <cmt> 4.0, 4.1 and 4.2 docs: add canonical tag. </cmt> <cmt> fix duplicate example by redirecting it. </cmt> <cmt> fix redirect. </cmt>","add canonical tag for 3.3, 3.4, 4.0, 4.1 and 4.2 and fix a few redirects"
1512,<desc> adding space to -l flag causes swiftc  to produce abstract error. this pr aims at improving usability to -l flag by allowing it to take a space. resolves sr-14122. </desc> <cmt> -l flag accepts space and emits without space to llvm frontend </cmt> <cmt> add tests to check if adding space doesn't break invocation </cmt>,improve usability of -l flag
1513,"<desc> added a new python script for testing amqp cases select one: select any that apply: </desc> <cmt> amqp tests python </cmt> <cmt> updates to make back node work </cmt> <cmt> removed test not relevant for this change </cmt> <cmt> fixed comments, took out commented and unnecessary code </cmt> <cmt> took out unneeded key copying </cmt> <cmt> took out extraneous wallet operations </cmt> <cmt> took out extraneous setting of amqp address </cmt> <cmt> added amqp-tests to cmake file </cmt> <cmt> upped timeout </cmt> <cmt> fixed cmake conflict </cmt> <cmt> added create ampq queue </cmt> <cmt> added -rabbit to test name </cmt> <cmt> set number of producers to 3 to avoid timeouts </cmt>",added a new python script for amqp specific tests - develop
1514,"<desc> meta: exclude libwasm parser.cpp from sonar cloud static analysis we need to exclude this file from analysis for now, as there is a bug in the sonar-runner tool where it crashes when trying to understand the use of ak::variant in libwasm/parser/parser.cpp see #10122 for details + link to the bug report to sonar cloud. meta: remove unused caching from sonar cloud configuration i was experimenting with using caching while doing the initial prototype of the sonar cloud workflow. however the cache size for the static analysis data ended up being large enough that it would put us over the git hub actions limit. given that we currently only run this pipeline once a day, it seems reasonable to just remove caching. if in the future we decide to run the pipeline on every pr, caching would become crucial as the current un-cached analysis time is around 1 hour and 50 minutes. if we did this we would need to move the pipeline to azure devops where we have effectively infinite cache available. </desc> <cmt> meta: remove unused caching from sonar cloud configuration </cmt> <cmt> i was experimenting with using caching while doing the initial prototype </cmt> <cmt> of the sonar cloud workflow. however the cache size for the static </cmt> <cmt> analysis data ended up being large enough that it would put us over the </cmt> <cmt> git hub actions limit. given that we currently only run this pipeline </cmt> <cmt> once a day, it seems reasonable to just remove caching. </cmt> <cmt> if in the future we decide to run the pipeline on every pr, caching </cmt> <cmt> would become crucial as the current un-cached analysis time is around </cmt> <cmt> 1 hour and 50 minutes. if we did this we would need to move the pipeline </cmt> <cmt> to azure devops where we have effectively infinite cache available. </cmt> <cmt> meta: exclude libwasm parser.cpp from sonar cloud static analysis </cmt> <cmt> we need to exclude this file from analysis for now, as there is a bug in </cmt> <cmt> the sonar-runner tool where it crashes when trying to understand the use </cmt> <cmt> of ak::variant in libwasm/parser/parser.cpp </cmt> <cmt> see #10122 for details + link to the bug report to sonar cloud. </cmt>",work around crash in sonar cloud static analysis
1515,"<desc> documentation for the email and jira watcher actions provide example keystore commands to store sensitive data, like passwords. this corrects those keystore commands to include the required add keyword. also includes a supporting update to encourage use of keystore for secure credentials. resolves #40132 </desc> <cmt> correct keystore commands for email and jira actions for watcher </cmt> <cmt> update depcrecation note to recommend keystore for secure creds </cmt> <iss> docs for keystore commands for email and jira actions incorrect </iss>",correct keystore commands for email and jira actions in watcher
1516,"<desc> as discussed in #2461 , dropped the 'lib' prefix from shared library name in mingw as well. python package works with mingw again. added apveyor ci for mingw and python i don't think it is necessary to run two appveyor jobs for jvm; and, perhaps, can live without a debug job for msvc2013 some 'g++ 4.8 or higher' defines seemed to (unintentionally?) miss versions above 4 </desc> <cmt> for mingw, drop the 'lib' prefix from shared library name </cmt> <cmt> fix defines for 'g++ 4.8 or higher' to include g++ >= 5 </cmt> <cmt> fix compile warnings </cmt> <cmt> [appveyor] add mingw with python; remove redundant jobs </cmt>",shared library prefix and appveyor ci
1517,"<desc> this pr refactors the previous pipeline into a format that is inline with openexr uncompressing pipeline, and adds support to rle compression format. setting up for a future pr that adds support for dwaa and dwab compression. by filling the output array with white color, #17887 exposed an incorrect offset in the decoding algorithm. the first pixel line was being shifted up, this was also fixed. refactors into openexr uncompress pipeline. adds rle compression support. fixes line indexing. adds support for float32 pixeltype - except for piz_compression dev example pr example you can see the example no longer shows that white line on the bottom of the image, since the indexing is now correctly handled. </desc> <cmt> exrloader: refactor </cmt> <cmt> exrloader: clean up </cmt>",rle support and uncompress refactor.
1518,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add sentence class to brill tagger </cmt> <cmt> update natural package version </cmt> <cmt> run prettier, remove patch version </cmt>",add sentence class for tagger to natural package
1519,"<desc> this makes it possible to specify the default android overscroll indicator using themedata. internal feedback has requested we add this to ease migration to the new default behavior. i am hesitant to pile on to themedata again, we have ben trying to prune it lately, but i do not think adding a scrollbehaviortheme is appropriate for this case/migration period.  related issues/changes #87839 #82906 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> add theme support for choosing overscroll indicator </cmt> <cmt> docs </cmt>",add theme support for choosing android overscroll indicator
1520,"<desc> credit goes to @alex-700 who found this while trying to fix a suggestion in clippy. while if, try, for and await expressions get the span of the original expression when desugared, while loops got the span of the scrutinee, which lead to weird code, when building the suggestion, that randomly worked:  i'm wondering, if desugaringkind should get a variant whileloop and instead of using the span of the ast::exprkind::while expr directly, a new span with self.mark_span_with_reason should be used, like it is done with for loops. there was some fallout, but i think that is acceptable. if not, i need some help to find out where this can be fixed. </desc> <cmt> use correct span on while (let) lowering </cmt> <cmt> update_tests </cmt>",fix span of while (let) expressions after lowering
1521,<desc> this fills out the rest of the blend modes for premultiplied alpha using the design of @westlangley. this does this by renaming the existing premultipliedalpha blend mode: three.premultipliedalphablending = 6; and instead calling it: three.premultipliedalphanormalblending = 6; and then adding these following modes: three.premultipliedalphaadditiveblending = 7; three.premultipliedalphasubtractiveblending = 8; three.premultipliedalphamultiplyblending = 9; this also adds the ability to use custom blending modes with premultiplied alpha - which i am sure would be useful in the future: three.premultipliedalphacustomblending = 10; i've updated the relevant examples as well. </desc> <cmt> add the rest of the blending modes to premultipliedalpha mode. </cmt> <cmt> # conflicts: </cmt> <cmt> #	examples/webgl_materials_transparency.html </cmt> <cmt> #	src/renderers/webgl/webglstate.js </cmt> <cmt> some more upgrades of dev to match the premultiplied multiple blend modes. </cmt>,"additive, subtractive, multiply, custom premultipliedalpha blend modes"
1522,"<desc> this pr makes the following changes: remove logicalkeyboardkey.keylabel make physical/logicalkeyboardkey.debugname getters make physical/logicalkeyboardkey() factory constructors, which cache non-predefined instances. reasons: it has been planned to remove keylabel because it brings confusion to usage, and complexity to expanding code related with logical keys. the keylabel is a duplicate information to flutterid. it is possible to construct an instance with the same flutterid and different keylabel, but what does it even mean? an alternative way is to keep keylabel as a getter, but for now it doesn't seem necessary. the keylabel is not used anywhere in keyboard-related algorithms, nor does it seem like a necessary part for client-side processing. since flutterid is the deciding property for a logical key, keylabel only serves for explanation. it's like another debugname but available at run time. with debugname being turned into a getter, the logical/physicalkeyboardkey classes no longer needs to override hashcode and operator ==. this allows the key instances to be used in a const context and removes a linter exception (prefer_const_literals_to_create_immutables), such as const <logicalkeyboardkey>[ logicalkeyboardkey.keya, logicalkeyboardkey.keyx, ]  // this would trigger compiler error before <logicalkeyboardkey>[ const logicalkeyboardkey.keya, const logicalkeyboardkey.keyx, ]  // this would trigger linter error i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> impl </cmt> <cmt> fix fuchsia key </cmt>",remove keylabel and debugname from logical/physicalkeyboardkey
1523,"<desc> find in this picture the process that used most of the cpu: yes, i know it is torrents, but the legend does not help. when there are many dimensions, the legend requires quite some focus to find the most important one. the solution well, before this pr the dashboard decides for the number of fraction digits, based on each number alone. it used no fraction digits for values above 1000, 1 fraction digit for values above 100, 2 fraction digits for values above 10, etc up to 4 fraction digits. this pr tries something different. it decides the number of fraction digits for all dimensions of a chart, based on the visible y-range of the chart! the algorithm for deciding the number of fraction digits is the same, but all the dimensions get the same, so the numbers are easily distinguishable. let's see: a lot better. what is nice, is that when you click on a dimension to select it, the y-range of the chart changes, so the detail on the numbers changes too immediately: so, netdata has a small range and 2 fraction digits: but x, has a bigger range and 1 fraction digits: if the range is too small, you still get up to 4 digits (this chart ranges from 0.9995 to 1.0048): side effects there are always side effects: before this pr, this chart did not have any fraction digits. it is annoying i know, but i made a little change to make it easier to accept it: before this pr values from 1 to 100 would get 2 fraction digits. after this pr, values 1 to 10 get 2, but 10 to 100 get 1. this makes it a little bit less annoying. this pr also fixes an issue where charts were randomly loosing some legend information (date and units). also, chart y-axis labels are now using the same formatting as the legends: </desc> <cmt> fixed an issue where units and date were randomly not rendered on charts </cmt> <cmt> removed debugging strings </cmt> <cmt> legends now have uniform but dynamic number of fraction digits </cmt>",uniform but dynamic number of fraction digits at the legends
1524,"<desc> about awd format :  in short, it's a lightweight format, faster to load, faster to parse than all ascii/utf based 3d formats. a first draft version of parser is available on this fork  (has been developed to run with modified version of three.js) the first step is to cleanup the actual version, in order to make it work on the actual dev branch, with minimal features : parse geometries as buffergeometry parse meshes instance as mesh parse containers as object3d find a way to handle meshes with multi-materials (away3d feature) next steps : handle primitives support for morph and skeletal animations lights and cameras materials and embed textures? ... </desc> <cmt> quickely add awdloader </cmt> <cmt> fix awdloader </cmt> <cmt> cleanup awdloader + added sample page with simple awd scene </cmt> <cmt> start support for texture loading </cmt> <cmt> basic material support + external texture loading </cmt>",support for awd format (away3d)
1525,"<desc> new features apis add nansum api x = np.array([[float('nan'), 0.3, 0.5, 0.9], x = paddle.to_tensor(x) out1 = paddle.nansum(x)  # [2.7] out2 = paddle.nansum(x, axis=0)  # [0.1, 0.5, 0.5, 1.6] out3 = paddle.nansum(x, axis=-1)  # [1.7, 1.0] out4 = paddle.nansum(x, axis=1, keepdim=true)  # [[1.7], [1.0]] </desc> <cmt> add nansum api </cmt>",add nansum api to math
1526,"<desc> this pr adds my layout for the chimera ortho and planck keyboards. i've had these changes pending for a good while, hence why there's two layouts in one pr. both of these are the same layout, hence the same branch and singular pr. if there's an issue with this, let me know and i'll split things up into two pr's. don't think there's much else worth mentioning here. </desc> <cmt> clone default chimera-o layout </cmt> <cmt> make changes for base layer </cmt> <cmt> enable mouse suppport flag </cmt> <cmt> implement majority of dad layout </cmt> <cmt> add mouse movement keys </cmt> <cmt> fine tune mouse control and fix tap toggle </cmt> <cmt> fix mouse button locations </cmt> <cmt> set adpater led colors for layers </cmt> <cmt> increase responsiveness of key taps </cmt> <cmt> update layout for thumb comfort </cmt> <cmt> rename layout and add readme </cmt> <cmt> add comments to keymap </cmt>",add dcompact layout for chimera ortho and planck keyboards
1527,"<desc> the nearbygpscoordinate function uses coordinate[0] and coordinate[1] as a string array, not a single string. the function worked when i used ""[""0"", ""0""] as unknown as string"" as the input, which means it actually should have a string array. hope this can be approved to fix this issue. as mentioned in the commit message, i also changed the test to reflect the usage. </desc> <cmt> changed type of coordinate to string[] from string. the function itself uses coordinate[0] and coordinate[1] as latitude and longitude, so the old type led to a typeerror when you tried to input the coordinate array. </cmt> <cmt> the test has been changed to reflect the change in input. </cmt> <cmt> changed the type of faker.address.nearbygpscoordinate's parameter coordinate from string[] to readonlyarray<string>. </cmt>",changed faker.address.nearbygpscoordinate() coordinate parameter type from string to readonlyarray<string>
1528,<desc> add set -ex to build scripts as well as bazel flags for incompatible versions. also change dockerfile for debian-based docker container </desc> <cmt> change debian jessie backports url </cmt> <cmt> add set -ex to some scripts for debugging </cmt> <cmt> add two bazel flags </cmt>,changes to build files for patch release
1529,"<desc> build successful:  i hope in the future we will be able to drop requirements_rtd.txt completely, but now pip still fails to resolve conflicts with preinstalled old (1.8.5) sphinx and latest breathe. </desc> <cmt> update requirements_base.txt </cmt> <cmt> update requirements_rtd.txt </cmt>",simplify rtd config and use latest sphinx
1530,"<desc> closes #9109 thanks, @dimazuien! cy.request() now accepts a generic in typescript for specifying the type of the request body make the type of response body of cy.request generic. why was this change necessary? => generic helps users write type-safer code. what is affected by this change? => n/a any implementation details to explain? => n/a </desc> <cmt> fix </cmt> <cmt> better name. </cmt> <iss> generic for cy.request response body </iss>",can specify the responsebody type of cy.request
1531,"<desc> fix two issues that would case crashes for programs using swift concurrency in back-deployed scenarios: cannot back-deploy mangled names including isolated parameters. exclusivity checking was broken in some cases (rdar://83064974). don't refer to the isa mask any more; we don't back-deploy far enough for it to matter. make sure we set rpaths properly when linking. implement  swiftnativensobject in the back-deployed libswift_concurrency and swizzle it in to back-deployed @objc actor types. </desc> <cmt> always use the same tls context as the runtime for back-deployed concurrency </cmt> <cmt> the exclusivity checking support for concurrency relies on having access </cmt> <cmt> to the thread-local set of active memory accesses. teach the </cmt> <cmt> back-deployed concurrency library to use the same tls context as the </cmt> <cmt> runtime, which fortunately hasn't change. this fixes the </cmt> <cmt> concurrency exclusivity-checking test in back-deployed configurations </cmt> <cmt> that's tracked by rdar://83064974. </cmt> <cmt> (cherry picked from commit 27472854174f77a03265875a171069c213c4d78f) </cmt> <cmt> cannot back-deploy mangled names including isolated parameters. </cmt> <cmt> isolated parameters were introduced with concurrency, so don't mangle </cmt> <cmt> names including them in back-deployed code. </cmt> <cmt> (cherry picked from commit 24c761b74a1a8828e1109f76b8c4da0b3272a849) </cmt>","concurrency back-deployment fixes for exclusivity, isolated parameters, @objc actors"
1532,"<desc> i made the mistake of writing the method result::unwrap as fn unwrap_err(&self) -> t { unwrap(self) }. this patch fixes that bug, and also does some cleanup of time.rs. </desc> <cmt> fix option::unwrap_err. </cmt> <cmt> switch chain calls to use option::chain method </cmt>",fix a bug in result::unwrap_err (and minor cleanup)
1533,"<desc> use the family argument (and others) when creating the kube-load-balancer-source-cidr in proxy-mode=ipvs. this is needed when the family is not the default ""family inet"", that is for a ipv6-only clusters. fixes #68338 release note: </desc> <cmt> fix issue #68338 </cmt> <cmt> the ipset kube-load-balancer-source-cidr is not recogized as </cmt> <cmt> a hash set </cmt> <cmt> fix issue #68338 </cmt> <iss> the ipset kube-load-balancer-source-cidr is not recogized as a hash set </iss>",include all used hash types in compare when creating ipsets
1534,"<desc> this change aggregates events sending, and reports them at most once per second. also i've added events for viewing a query/widget/visualization, when looking at a dashboard. </desc> <cmt> report events at most once per second </cmt> <cmt> report event for viewing widget/visualization/query </cmt>",make sure events are reported at most once per second
1535,<desc> more ribust handling of labes insafari for state diagrams. resolves #1269 workaround for issue with getbbox in safari have read the contribution guidelines targeted develop branch </desc> <cmt> #1269 work around for inaccurate bounding box results in safari. </cmt> <cmt> #1269 work around for inaccurate bounding box results in safari. fix for multiple lines </cmt> <iss> state transition label renders incorrect on safari </iss>,bug/1269 fix label background on safari
1536,"<desc> this is related to bpo-37417: os.sched_setaffinity doesn't properly handle errors that arise during iteration of the mask argument: python 3.9.0a0 (heads/master:d52a83a, jun 26 2019, 15:13:41) type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import os >>> bad_iter = map(int, ""0x"") >>> os.sched_setaffinity(0, bad_iter) valueerror: invalid literal for int() with base 10: 'x' the above exception was the direct cause of the following exception: traceback (most recent call last): file ""<stdin>"", line 1, in <module> systemerror: <built-in function sched_setaffinity> returned a result with an error set it looks like this bug is also present on all versions of python 3. i've attached a patch with a fix and a regression test. </desc> <cmt> add a test for error handling in os.sched_setaffinity. </cmt> <cmt> fix error handling in os.sched_setaffinity. </cmt>",os.sched_setaffinity does not handle errors during iteration.
1537,"<desc> ec2_vpc_nat_gateway ansible version ansible 2.3.0 (devel e35a757ee7) last updated 2017/01/12 16:42:33 (gmt +1000) config file = configured module search path = default w/o overrides check if eip exists before deleting it after deleting the nat gateway, the eip sometimes seems to cease to exist afterwards. check if it exists before deleting it. otherwise you get: failed to release eip eipalloc-abdc1234: an error occurred (invalidallocationid.notfound) \ when calling the releaseaddress operation: the allocation id 'eipalloc-abcd1234' does not \ exist"", ""success"": false} also fix some flake8 issues in a separate commit </desc> <cmt> check if eip exists before deleting it </cmt> <cmt> after deleting the nat gateway, the eip sometimes seems to </cmt> <cmt> cease to exist afterwards. check if it exists before deleting it. </cmt> <cmt> otherwise you get: </cmt> <cmt>  </cmt> <cmt> failed to release eip eipalloc-abdc1234: an error occurred (invalidallocationid.notfound) \ </cmt> <cmt> when calling the releaseaddress operation: the allocation id 'eipalloc-abcd1234' does not \ </cmt> <cmt> exist"", ""success"": false} </cmt> <cmt>  </cmt> <cmt> fix flake8 errors with ec2_vpc_nat_gateway </cmt>",fix eip release in ec2_vpc_nat_gateway
1538,<desc> also remove currently unused interruptmsgproc param from sendmessages. i guess some squashing can be done (but i'm worried that interruptmsgproc is planned to be used in sendmessages later). </desc> <cmt> net: cconnman: make some methods const </cmt> <cmt> net: make cnetmsgmaker more const </cmt> <cmt> net: pass interruptmsgproc as const where possible </cmt>,turn some methods and params/variables const
1539,<desc> this fixes a case where // /* */ became /* /* */ */ but the comment in the test is still duplicated because of babel's ast format (babel/babel#12769). fixes part of #5787 (so at least the produced code is syntactically valid now). </desc> <cmt> add test </cmt> <cmt> fix the incorrectly nested comment printing </cmt>,fix astring generation of nested comment
1540,<desc> improve heading structure of landing page the full strapline is too long for a heading. it also caused installation and usage to be be on the lowest heading level and didn't translate to the visual representation of the landing page before: after: fixes issues with skipped headings did not check every page under  /components or /api since they're mostly auto-generated. especially for demos i'm not that concerned with skipped headings. the demo should not be concerned with the context it's embedded in. </desc> <cmt> [docs] improve heading structure </cmt> <cmt> [docs] fix incorrect heading structure for /styles/api </cmt> <cmt> [docs] reduce /customization/breakpoints demos </cmt> <cmt> [docs] improve a11y story of /customization/color#color-tool </cmt>,fix various issues with heading structure
1541,"<desc> hi @kazuho !! h2o_mruby supports simple reverse proxy method. please review it :) backends = [ "" "" "" "" ] r = h2o::request.new if r.uri == ""/proxy.html"" r.reprocess_request backends[rand(backends.length)] else # pass to next normal handler h2o.return h2o::declined end </desc> <cmt> add h2o::request#reverse_proxy </cmt> <cmt> add h2o::request#reverse_proxy test </cmt>",support simple reverse proxy feature in mruby handler
1542,"<desc> this patch set enables prefix delegation for a link that shows up later than the ones running the dhcpv6 client. this functionality is useful when the upstream link has been enabled long before local networking is connected or enabled; should any of the later links need prefix delegation, the dhcpv6 clients of the uplinks are restarted to acquire prefixes. fixes #9758 </desc> <cmt> networkd-dhcp: rename function and reduce its logging </cmt> <cmt> rename dhcp6_verify_link() to dhcp6_get_prefix_delegation() in order </cmt> <cmt> to be clearer in what it does. reduce unnecessary logging. </cmt> <cmt> networkd-dhcp6: request prefix delegation for a new link </cmt> <cmt> request prefix delegation for a new downstream link that is enabled </cmt> <cmt> after any number of upstream dhcpv6 links. submit the request after </cmt> <cmt> the link has been configured with a link-local address. </cmt> <cmt> if the upstream dhcpv6 client has already been configured to request </cmt> <cmt> prefixes, attempt to re-assign any possible prefixes between the </cmt> <cmt> already existing links and the new one. if no prefixes are yet </cmt> <cmt> acquired, nothing will happen right away and any prefixes will be </cmt> <cmt> distributed after a reply from the dhcpv6 server. </cmt> <cmt> if none of the already existing downstream links have requested </cmt> <cmt> dhcpv6 prefixes to be assigned, enable prefix delegation for each </cmt> <cmt> client and restart them one by one if they are already running. this </cmt> <cmt> causes the dhcpv6 clients to re-acquire addresses and prefixes and </cmt> <cmt> to re-distribute them to all links when receiving an updated </cmt> <cmt> response from their respective dhcpv6 servers. if the dhcpv6 client </cmt> <cmt> in question was not already running, it is set to request prefixes </cmt> <cmt> but not restarted. </cmt> <cmt> when an error occurs while setting or restarting the dhcpv6 client, </cmt> <cmt> log the incident and move over to the next link. </cmt> <cmt> fixes #9758. </cmt> <iss> dhcpv6 pd not requested for later appearing downstream interfaces </iss>",dhcp6 pd enable later link
1543,"<desc> this pr fixes some inconsistencies relating to any and keyof any as the constraint type in a mapped type. specifically, the mapped types { [p in any]: t } and { [p in keyof any]: t } both now yield a type corresponding to { [x: string]: t }. fixes #19152. </desc> <cmt> properly handle mapped types with 'keyof any' </cmt> <cmt> mapped type { [p in any]: t } should yield { [x: string]: t } </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <iss> mapped generic type with <any> parameter inferred as ""any"" </iss>",fix 'any' and 'keyof any' in mapped types
1544,"<desc> steam games were not showing up while searching using powertoys run. this was happening as they were internet shortcut files with a url file extension. references list of uri schemes -  pr checklist applies to #3425 cla signed. if not, go over here and sign the cla tests added/passed detailed description of the pull request / additional comments changes made in this pr - filter out steam internet shortcut files and obtain their icon. update description to internet shortcut application instead of win32 application. this is the first step towards having separate subtitles so that we can update it for pwas as well. since internet shortcut files don't have run as admin functionality, removed that context menu icon if it is an internet shortcut file. validation steps performed steam games show up - </desc> <cmt> search shows up steam games </cmt> <cmt> formatting </cmt>",fix for steam games not showing up
1545,"<desc> forward port of 5dcce06 wip mostly to see if it passes ci lib/ansible/parsing/vault lib/ansible/cli/ ansible version ansible 2.3.0 (vault_password_bytes_port 91f0e02738) last updated 2017/03/07 14:56:29 (gmt -400) config file = /home/adrian/.ansible.cfg configured module search path = default w/o overrides python version = 2.7.13 (default, jan 12 2017, 17:59:37) [gcc 6.3.1 20161221 (red hat 6.3.1-1)] </desc> <cmt> retain vault password as bytes in 2.2 </cmt> <cmt> prior to 2.2.1, the vault password was read in as byes and then remained </cmt> <cmt> bytes all the way through the code.  a bug existed where bytes and text </cmt> <cmt> were mixed, leading to a traceback with non-ascii passwords.  in devel, </cmt> <cmt> this was fixed by changing the read in password to text type to match </cmt> <cmt> with our overall strategy of converting at the borders.  this was </cmt> <cmt> backported to stable-2.2 for the 2.2.1 release. </cmt> <cmt> on reflection, this should not have been backported as it causes </cmt> <cmt> passwords which were originally non-utf-8 to become utf-8.  people will </cmt> <cmt> then have their working 2.2.x vault files become in-accessible. </cmt> <cmt> this commit pipes bytes all the way through the system for vault </cmt> <cmt> password.  that way if a password is read in as a non-utf-8 character </cmt> <cmt> sequence, it will continue to work in 2.2.2+.  this change is only for </cmt> <cmt> the 2.2 branch, not for 2.3 and beyond. </cmt> <cmt> why not everywhere?  the reason is that non-utf-8 passwords will cause </cmt> <cmt> problems when vault files are shared between systems or users.  if the </cmt> <cmt> password is read from the prompt and one user/machine has a latin1 </cmt> <cmt> encoded locale while a second one has utf-8, the non-ascii password </cmt> <cmt> typed in won't match between machines.  deal with this by making sure </cmt> <cmt> that when we encrypt the data, we always use valid utf-8. </cmt> <cmt> fixes #20398 </cmt> <cmt> (cherry picked from commit 5dcce0666a81917c68b76286685642fd72d84327) </cmt> <cmt> remove the read_vault_password_file in dataloader. </cmt> <cmt> doesn't look like anything is using it at the moment </cmt> <cmt> and it duplicates cli.cli.read_vault_password_file. </cmt> <cmt> will revist to see if it makes more sense in dataloader </cmt> <cmt> once this works. </cmt> <cmt> merge fixup </cmt>",vault password as bytes forward port
1546,"<desc> fixes #17844 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change this pr copies the mshadow thresholding approach to ensure, that softrelu is numerically stable for large inputs values. </desc> <cmt> fix numerically unstable fused softrelu op </cmt> <cmt> implement test for softrelu numerical stability </cmt> <iss> hybridized softrelu on the gpu is not numerically stable </iss>",fix softrelu fused operator numerical stability
1547,"<desc> this is a continuation/split-off from #22986, where i tried to deduplicate the cython code for unique/factorize, and add a return_inverse kwarg to unique at the same time. this didn't fully work because there was a performance impact that was deemed unacceptable. i've opened cython/cython#2660 to figure out why (resp. have a directive to allow force-compilation of different parameter values, which would solve this more elegantly), and @robertwb told me that it's likely the use of kwargs, but also suggested the possibility to use explicit templating on return_inverse. first i tried unification without any kwargs in 858f54e - this still had the same perf impact as in #22986. then i added the explict templating in 4ed354a, which successfully avoids the perf impact, but is a bit uglier in the pxi.in. finally, i've readded the kwargs in 906cd50 to keep the diff here smaller, and this doesn't have an impact. i've had many unsuccessful tries to run the asvs for all those combinations over the weekend, so i'm going back to explicitly testing the unique-code here (code at the end). the overview is as follows (for completeness i've added the #22986 and the commit immediately prior on master; all results in milliseconds): >>> df e5196aaac6 99e640186e caea25a8b9 858f54e5e4 4ed354a954  906cd50e83 0d6dad0ca1 #22986~1     #22986     master  no kwargs  templated tmpl+kwargs  pr+master stringindex        16.220276  16.023982  15.967190  15.706223  15.624902   14.952832  15.480224 categoricalindex    1.274368   1.289882   1.231592   1.400420   1.247882    1.250814   1.327520 intindex            2.743178   2.778960   2.722282   3.115781   2.818848    2.802402   2.877664 uintindex           2.760333   2.773203   2.714546   3.037279   2.786909    2.800675   2.914427 rangeindex          2.765113   2.773916   2.804379   3.071501   2.801661    2.803809   2.816012 floatindex          4.734558   4.576122   4.575152   5.043915   4.518481    4.548134   4.732967 timedeltaindex      4.361350   4.238442   4.187650   4.601932   4.369402    4.409724   4.422439 stringseries       59.779114  58.508761  57.742805  58.343838  58.266719   57.043169  58.619018 categoricalseries   2.708816   2.666240   2.627852   2.895955   2.664937    2.658149   2.715396 intseries           5.078922   4.991856   4.928836   5.480455   5.108894    5.096692   5.434841 uintseries          5.127376   4.984227   5.027707   5.445736   5.155703    5.080125   5.211029 rangeseries         5.218271   5.013379   4.973759   5.531086   5.193241    5.091924   5.197651 floatseries         7.126269   6.959626   6.988052   7.738704   6.977395    6.978753   7.215513 timedeltaseries     5.146969   4.985955   5.024334   5.551364   5.153091    5.108740   5.158593 or, relatively to the commit on master i was basing myself on: >>> df.divide(df.iloc[:, 2], axis=0) e5196aaac6 99e640186e caea25a8b9 858f54e5e4 4ed354a954  906cd50e83 0d6dad0ca1 #22986~1     #22986     master  no kwargs  templated tmpl+kwargs  pr+master stringindex         1.015850   1.003557        1.0   0.983656   0.978563    0.936472   0.969502 categoricalindex    1.034733   1.047329        1.0   1.137081   1.013227    1.015607   1.077889 intindex            1.007676   1.020820        1.0   1.144547   1.035472    1.029431   1.057078 uintindex           1.016868   1.021608        1.0   1.118890   1.026658    1.031729   1.073633 rangeindex          0.985999   0.989138        1.0   1.095252   0.999031    0.999797   1.004148 floatindex          1.034842   1.000212        1.0   1.102458   0.987613    0.994095   1.034494 timedeltaindex      1.041479   1.012129        1.0   1.098930   1.043402    1.053031   1.056067 stringseries        1.035265   1.013265        1.0   1.010409   1.009073    0.987884   1.015174 categoricalseries   1.030810   1.014608        1.0   1.102024   1.014112    1.011529   1.033314 intseries           1.030450   1.012786        1.0   1.111917   1.036531    1.034056   1.102662 uintseries          1.019824   0.991352        1.0   1.083145   1.025458    1.010426   1.036462 rangeseries         1.049160   1.007966        1.0   1.112053   1.044128    1.023758   1.045015 floatseries         1.019779   0.995932        1.0   1.107419   0.998475    0.998669   1.032550 timedeltaseries     1.024408   0.992361        1.0   1.104895   1.025627    1.016799   1.026722 so long story short, this pr prepares the hashtable-backend to support return_inverse=true, which plays into #21357 #21645 #22824, and will also allow to easily solve #21720. code for the above timings: import pandas as pd import numpy as np import pandas.util.testing as tm import timeit hash = pd.__git_version__[:10] k = 10 ** 5 rep = 10 number = 100 tic = timeit.default_timer() tags = ['string', 'categorical', 'int', 'uint', 'range', 'float', 'timedelta'] df = pd.dataframe(index = [x+'index' for x in tags], columns = ['mean', 'std']) np.random.seed(55555) with tm.rngcontext(55555): for tag in tags: idx = getattr(tm, f'make{tag}index')(k=k) t = timeit.repeat('idx.unique()', setup='from __main__ import idx', repeat = rep+1, number = number)[1:] df.loc[tag+'index', 'mean'] = pd.series(t).mean() / number df.loc[tag+'index', 'std'] = pd.series(t).std() / number s = pd.series(idx).sample(frac=2, replace=true) t = timeit.repeat('s.unique()', setup='from __main__ import s', repeat = rep+1, number = number)[1:] df.loc[tag+'series', 'mean'] = pd.series(t).mean() / number df.loc[tag+'series', 'std'] = pd.series(t).std() / number df.to_csv(f'test_{hash}.csv') </desc> <cmt> unify unique/factorize, remove kwargs (perf); enable inverse for unique </cmt> <cmt> template over {return_inverse, ignore_na} for perf </cmt> <cmt> re-add kwargs to method signature </cmt>",add return_inverse to cython-unique; unify unique/factorize-code
1548,"<desc> in the documentation for accounts.loginwith<externalservice>, the forceapprovalprompt option which forces the user consent prompt to appear is missing. the option's implementation can be found here. to add the documentation, i simply copied the description of the option from the same field on accounts.ui.config (seen here) note: i bumped the patch version as the contribution guidelines instructed, though i'm not really sure if i was supposed to (since i didn't really change much code, just added a line to documentation). sorry if i made the wrong call! - i un-bumped the patch version because it looked like that was what was causing build and test to fail, but it ended up still failing anyway. i would be really appreciative if whoever reviews this could let me know whether to bump the patch version or not! </desc> <cmt> adds documentation for accounts-oath forceapprovalprompt </cmt> <cmt> documentation for the forceapprovalprompt option for loginwith<externalservice> was missing - i copied the documentation for the same option from accounts.ui.config </cmt> <cmt> bump patch version of accounts-oauth </cmt>",add documentation for the forceapprovalprompt option of accounts.loginwith<externalservice>
1549,"<desc> fast parsing of ints/doubles as strings as described in #560 note: the null-termination character is never added, always use explicit length </desc> <cmt> added kparsenumbersasstringsflag </cmt> <cmt> added number() to rapidjson::handler </cmt> <cmt> parsenumber() handles kparsenumbersasstringsflag </cmt>",implemented feature as in #560 (ints/doubles as strings)
1550,"<desc> backport of 12524. in running tests on pypy, there were failures due to improper use of the c-api: calling initoperators to initialize the generated ufuncs before calling pytype_ready(pyufunc_type) using the pysequence_fast* functions before calling pysequence_fast which works on cpython but does not always work on pypy we could prevent these mistakes by getting pypy into our ci testing, but there are still test failures due to insufficient ctypes and memoryview support in pypy late writing docstrings into types and objects via _multiarray_umath.add_docstring </desc> <cmt> maint: call pysequence_fast() before any other pysequence_fast* funcs </cmt> <cmt> bug: call pytype_ready before using type </cmt> <cmt> maint: comment, fix from review </cmt> <cmt> sty: bracket if blocks with braces </cmt> <cmt> doc: rearrange comment sequence from review </cmt> <cmt> sty: add space after ""if"" </cmt> <cmt> maint: unify error messages </cmt>",fix improper use of c-api
1551,<desc> adds special handling for void when checking initializers of binding patterns with zero elements. previously checked only that the initializer type was not null or undefined. fixes #30638 </desc> <cmt> add failing tests for destructuring void </cmt> <cmt> handle destructuring zero elements from void </cmt> <cmt> add new baselines for destructuring void </cmt>,add type error when destructuring zero elements from void
1552,"<desc> this pr implement tasks to set development version and exe icon on windows. the editor window still doesn't have a icon because of atom-shell bug: electron/electron#123. </desc> <cmt> use node-rcedit to set development version. </cmt> <cmt> add task to set exe icon. </cmt> <cmt> revert ""only run set-development-version on mac"" </cmt> <cmt> this reverts commit 9a4db9d95db8b179397ec3b77ad76b03d1fe1545. </cmt> <cmt> it's supported on windows now. </cmt>",set version strings and icon for the exe on windows
1553,<desc> fixes #3885 </desc> <cmt> remove legacy session identifier support </cmt> <cmt> remove redundant test </cmt> <cmt> redirect to login to support any invalid session identifiers </cmt> <cmt> be more specific with caught errors </cmt> <cmt> reject empty values in dynamicform </cmt> <iss> datasource is created with empty ssl mode </iss>,fix empty values sent in dynamic form
1554,<desc> cherry-picking #25504 to the 5.1 branch. thanks @jirid! fixes rdar://49639321 </desc> <cmt> [irgen] use singleton metadata strategy in jit mode. </cmt> <cmt> fixedorupdate strategy does not work for non-generic classes in jit mode. </cmt> <cmt> fixes rdar://49639321 </cmt> <cmt> split up test/irgen/jit_metadata_strategy.swift and fix the requires: line </cmt>,use singleton metadata strategy in jit mode [5.1]
1555,<desc> the blob class was missing the text() method which turns the blob arraybuffer into a string representation. this pr adds this. implementation code:  mdn reference:  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. </desc> <cmt> added blob.text() method as it was missing </cmt> <cmt> implementation code: </cmt> <cmt> mdn reference: </cmt> <cmt> added test assertion to text() </cmt>,add text method to blob in node-fetch
1556,"<desc> changes the new throughput generators to track messages per window instead of making per-second calculations which can have rounding errors. also, one of these had a calculation error which prompted this change in the first place. fixes a couple typos. fixes an error where certain json fields were not exposed, causing the workloads to not behave as intended. fixes a bug where we use wait not in a loop, which exits too quickly. adds additional constant payload generators. fixes problems with an example spec. fixes several off-by-one comparisons. this was built and tested extensively prior to the moving of trogdor from tools/ to trogdor/. current update builds but fails in unrelated tests. </desc> <cmt> minor: fix a couple trogdor issues. </cmt> <cmt> fix whitespace issues. </cmt>",improvements and fixes for trogdor payload generators.
1557,"<desc> vxworks does have the <sys/ioctl.h> header file. in this header file fionbio is also defined but the fionbio request is only supported on socket fd. to set the blocking/non-blocking mode, fcntl is supposed to be used. vxworks' file system can respond to the fcntl request of ioctl. </desc> <cmt> fix _py_set_blocking() for vxworks rtos </cmt> <cmt> add news </cmt>",add os.set_blocking() support for vxworks rtos
1558,<desc> users can now rotate/pan/zoom based upon the key-bindings available in the settings even if they only have a trackpad. closes #53 </desc> <cmt> added rotation/panning support for trackpads based upon key-bindings inside of the settings. </cmt> <iss> moving around in the 3d viewport </iss>,added rotation/panning support for trackpads in 3d mode #53
1559,<desc> summary inspired by this comment: #1048 (comment) i thought it may be a good idea to omit node_modules by default when running prettier through cli. kinda fixes #1358. notable changes: adds new --with-node-modules cli flag to opt-out from default behavior adds integration tests inside tests_integration directory. adds new npm script command to run integration tests: test-integration test plan added an integration test suite. </desc> <cmt> ignore node_modules by default </cmt> <cmt> add integration test suite for --with-node-modules cli arg </cmt> <cmt> refactor tests to snapshots </cmt> <iss> add a glob example for how to ignore node_modules </iss>,ignore node_modules when running prettier from cli
1560,<desc> tested. note: see  packages/gitlab/gitlab_common.js   -- a new setting needs to be created to configure the gitlab server location. see client/views/login/services.coffee  -- need a gitlab icon or svg glyph </desc> <cmt> initial commit of oauth2 client support for gitlab #512 </cmt> <cmt> fix overwritten code from clean-up </cmt>,initial implementation of oauth2 client support for gitlab server flow  #512
1561,"<desc> closes #2874  adds ""users"" to the sort by option in issues stream. issues are sorted by user totals in the current date range, however it may be confusing because the user column shows total lifetime users impacted. this confusion is somewhat addressed via a tooltip in #18832 </desc> <cmt> add sort issues by user totals </cmt> <cmt> add sort group by users tests </cmt> <iss> possible to sort by user? </iss>",add sort by users in issue stream
1562,<desc> i hereby agree to the terms of the cla available at:  category: short description: for tsvwithnames/csvwithnames formats column information (columns order) can now be parsed from format headers. this is controlled with input_format_with_names_use_header parameter. </desc> <cmt> in [t|c]svwithnames formats start using column information from header </cmt> <cmt> dropped a few debug leftovers </cmt> <cmt> better naming </cmt>,support for header specified order of columns in tsvwithnames/csvwithnames formats
1563,<desc> also update the rmm plugin code to account for the updated signature of the template class rmm::mr::thrust_allocator<t> (rapidsai/rmm#647). </desc> <cmt> [ci] upgrade cudf and rmm to 0.18 nightlies </cmt> <cmt> modify rmm plugin to be compatible with rmm 0.18 </cmt>,upgrade cudf and rmm to 0.18 nightlies; require rmm 0.18+ for rmm plugin
1564,"<desc> fixed db connection leak problem in the crash_gen tool, and ensured that it releases all db connections upon completion, making memory leak detection easier. no user impact, and no documentation changes are needed. </desc> <cmt> fixed td-2499, ensuring crash_gen tool releases all db connections when completing tests </cmt> <cmt> adjust crash_gen tool to direct logging output to stdout, instead of stderr </cmt>","resolving td-2499, ensuring crash_gen tool releases all resources"
1565,"<desc> this pr is to fix some incorrect anchor links as below. fix the incorrect anchor name ""preparelinux"", which cause cannot direct to correct section with link:  fix </desc> <cmt> fix the incorrect link of preparelinux or preparemacos </cmt> <cmt> fix incorrect link of common_installation_problems also </cmt>",fix some minor incorrect anchor links
1566,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. the added types are available in expect, but are missing in these type definitions. see jest docs on expect: </desc> <cmt> expect: add tobenull(), tobedefined(), tobeundefined() </cmt> <cmt> expect: add expect(...).not </cmt> <cmt> expect: add typings for expect.any() </cmt> <cmt> expect: added tomatchobject() </cmt> <cmt> expect: added tohavebeenlastcalledwith() </cmt>",add missing types to expect
1567,<desc> this pr refactors the integration cli build tests. please note this is only the start of the refactoring and more needs to be done. this pr only gets rid of some boilerplate code which was being repeated in more places. more consolidation has to be done in a future pr. </desc> <cmt> integcli: add some more docker utils </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt> <cmt> integcli: use dockercmdindir in build tests </cmt> <cmt> docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) </cmt>,minor refactor of the build tests
1568,"<desc> fixes #14337, fixes #19228, fixes #14748, fixes #18956, fixes #14282 apologies for the massive pr. the fix for #14337 required me to modify the chaining wrappers for every single function, so i figured i should clean up some of the messy overloads along the way (which also fixed several other issues). unfortunately, this will be a breaking change in terms of what type arguments are accepted. so if anyone was explicitly passing type arguments (e.g. _.chain([]).find<_.lodashexplicitobjectwrapper<any>>('a')), their code may be broken. but i think in the long run this change should be more helpful than harmful, as it removes the need to explicitly pass type arguments in almost all cases. summary of changes: the chain wrapper interfaces have been greatly simplified. instead of many wrapper types (lodashimplicitarraywrapper, lodashimplicitobjectwrapper, lodashimplicitnumberarraywrapper, etc.), there are now only 2 wrapper types: lodashimplicitwrapper and lodashexplicitwrapper. this allows the return types to be more accurate (especially for functions like head and find). cleaned up messy function overloads (removed unnecessary type arguments) made iteratee arguments more consistent - now they all use one of the new iteratee types, unless they have a good reason not to. replaced object and function types with more appropriate types changed many dictionary<t> inputs to just take plain objects, so an index signature is not required please fill out this template: follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. (not appropriate) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> [lodash] improved iterateee parameters, simplified foreach overloads </cmt> <cmt> changed listiterator to stringiterator, cleaned up more issues with flatmap </cmt> <cmt> even more flatmap cleanup </cmt> <cmt> making wrapper types simpler and more accurate (not done) </cmt> <cmt> fixed type inference for foreach callback arguments </cmt> <cmt> converted explicit wrapper types, implemented differencewith </cmt> <cmt> updated more functions to use new-style wrappers </cmt> <cmt> finished updating the remaining methods </cmt> <cmt> # conflicts: </cmt> <cmt> #	types/lodash/index.d.ts </cmt> <cmt> #	types/lodash/lodash-tests.ts </cmt> <cmt> fixed lint errors </cmt> <cmt> fixed parameter type inference when using any (#19228) </cmt> <iss> lodash's _.mapkeys(object, ...) fails if object is type object </iss> <iss> lodash chain methods uses wrong generic type </iss> <iss> lodash missing _.transform as part of the lodashexplicitobjectwrapper </iss> <iss> lodash definitions not working on ts 2.5 </iss> <iss> lodash foreach types broken in v4.14.74 </iss>","better chaining wrappers, overload clean-up"
1569,"<desc> enabled code analysis for the editor. this does not fix 2 issues for ##923 for references pr checklist applies to #910 cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments validation steps performed ran application and editor worked as expected </desc> <cmt> getting analysis up and going </cmt> <cmt> adding in sytlecop and fixing issues </cmt> <cmt> fixing blank lines </cmt> <cmt> fix line issues </cmt> <cmt> fixed a lot of line issues, few auto </cmt> <cmt> moving converters, fixing spacing issues </cmt> <cmt> adjusting event names </cmt> <cmt> fixed a bunch more </cmt> <cmt> fixed a bunch of infos </cmt> <cmt> fixed rest of info items </cmt> <cmt> fix for ca0507 </cmt> <cmt> few more fixes </cmt> <cmt> last stylecop issue </cmt>",code analysis / style cop adjustments for .net
1570,<desc> rounds up fee on ram sells in the system contract to ensure a non-zero fee is always paid. </desc> <cmt> fix fee calculation in sellram and comments </cmt> <cmt> build fail fix </cmt> <cmt> sellram should only succeed if there is a guarantee that the user will at least get some tokens back after the fee is deducted </cmt> <cmt> fix ram fee rounding errors in eosio_system_tests </cmt>,round up fee when selling ram
1571,"<desc> this pull includes the rest of the non-result changing float vectorization. min/max is a little ugly as it needs to propagate nan efficiently. are there platforms were fpu flag propagation is supported but no_floating_point_support is set? the base math is lengthy but simple, all the special cases are to archive optimal performance for these very common operations. base math reductions are not vectorized as they change the results slightly (float add and multiply are not associative) </desc> <cmt> enh: vectorize float min/max operation with sse2 </cmt> <cmt> improves performance by ~1.5/3.0 for float/double. </cmt> <cmt> enh: vectorize base math with sse2 </cmt> <cmt> improves performance by ~1.5/3.0 for float/double for inplace or cpu </cmt> <cmt> cached operations </cmt>",min/max and base math vectorization
1572,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see code below (not applicable) if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header tabulator-tables@4.9.3's package.json has the following: ""main"": ""dist/js/tabulator.js"", ""module"": ""dist/js/tabulator.es2015.js"", the latter has export default tabulator;, the former has: (function (global, factory) { if ((typeof exports === 'undefined' ? 'undefined' : _typeof(exports)) === 'object' && typeof module !== 'undefined') { module.exports = factory(); } else if (typeof define === 'function' && define.amd) { define(factory); } else { global.tabulator = factory(); }) applied to a function that returns the constructor for tabulator, so having export default tabulator in index.d.ts makes sense in either case. </desc> <cmt> add default export to type definition and import it in test </cmt> <cmt> disable prefer-const and get rid of octal literals to pass lint </cmt>",add default export for tabulator-tables
1573,<desc> basic version of data transfer object pattern implementation. </desc> <cmt> #348 - data tranfer object : added module to project. </cmt> <cmt> #348 - data tranfer object : add puml file to etc. </cmt> <cmt> #348 - data tranfer object : implement data transfer object pattern simple version. </cmt> <cmt> #348 - data tranfer object : add puml diagram. </cmt> <cmt> #348 - data tranfer object : customer client request customer details to server at one shot. </cmt> <cmt> #348 - data tranfer object : add readme.md </cmt>,#348 data transfer object design pattern
1574,"<desc> what did you implement: in cloudformation, resources are created based on a dag built from the template file. previously, the lambda function iam policy had references to all log groups like this: {""fn::join"": ["":"", [{""fn::getatt"": [""testfunctionloggroup"", ""arn""]}, ""*""]]}, for every log group. this made the iam policy depend on all the log groups completing so they could be referenced in the policy. this patch makes use of the aws::region and aws::accountid pseudo-parameters to fill in a full arn for the group. after this change, iam policy lines look like: {""fn::sub"": ""arn:aws:logs:${aws::region}:${aws::accountid}:log-group:/aws/lambda/myservice-dev-test-function:*""} the upshot here is that there's no reference to the cfn aws::logs::loggroup resource, so the dependency graph becomes more parallel (allowing cloudformation to do more at once) and makes deploys faster. the one downside to this change is that it could result in lambdas being deployed before their log groups, because currently the lambda depends on the iam role which then depends on the log group. i can add a dependson for each lambda to its respective log group. in practice, i haven't seen this occur because the iam role takes much longer to deploy than the log groups. how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> remove implicit dependency between iam policy and log groups </cmt> <cmt> until now, the iam policy had a dependency on log groups completing </cmt> <cmt> before it could finish because of the use of fn::getatt with a log </cmt> <cmt> group, meaning the policy couldn't provision until all log groups were </cmt> <cmt> ready. </cmt> <cmt> this patch changes the log group reference in the cfn template from: </cmt> <cmt>  </cmt> <cmt> { ""fn::getatt"": [""myfuncloggroup"", ""arn""] } </cmt> <cmt>  </cmt> <cmt> to </cmt> <cmt>  </cmt> <cmt> {""fn::sub"": ""arn:aws:logs:${aws::region}:${aws::accountid}:log-group:/aws/lambda/my-service-dev-myfunction:*""} </cmt> <cmt>  </cmt> <cmt> meaning the policy can be resolved 100% with pseudoparams for log group arns. </cmt> <cmt> this speeds up the cfn initial deploy significantly, and somewhat </cmt> <cmt> improves deployments that add or rename functions. </cmt> <cmt> having this dependency removed is also the first step in allowing log </cmt> <cmt> groups to be moved to a nested stack. </cmt> <cmt> add tests for new fn::sub template style </cmt>",reduce dependency tree depth between iam & log groups
1575,"<desc> while further investigating this as requested, i found some single_file bugs that impacted html output and workers. specifically: single_file with html output would fail to compile, due to embedding the wasm in the js and deleting it, then afterwards trying to embed the deleted wasm in the html. in the case of both html and workers, multiple files would be produced/required (respectively, test.html + test.js and test.js + test.worker.js). most of the lines changed in emcc.py are just indentation, so this will be easier to view with ?w=1. </desc> <cmt> single_file html output fix </cmt> <cmt> single_file worker js output fix </cmt>",single_file html and worker fixes + tests
1576,<desc> issue: #2636 moved manager to core moved default webpack.config.js to core (didn't touch rn) </desc> <cmt> move default webpack.config to core </cmt> <cmt> use default webpack.config from core in angular app </cmt> <cmt> move manager to core and use it in angular app </cmt> <cmt> use core in polymer </cmt> <cmt> use core in react </cmt> <cmt> use core in vue </cmt>,move more things to core
1577,"<desc> fixes #12673 the error only appears when a property initializer references another property before its definition. references to outer variables, etc are still allowed, and instance property initialisers are still allowed to reference static properties. </desc> <cmt> error on forward references for property initializers </cmt> <cmt> the error only appears when a property initializer references another </cmt> <cmt> property before its definition. references to outer variables, etc are </cmt> <cmt> still allowed. </cmt> <cmt> test property initialiser forward reference errors </cmt>",error on forward references in property initializers
1578,"<desc> these changes roughly follow #52551 (comment) after some course correct. add the apikey.id, apikey.name and authentication.type fields to the access_granted, access_denied, authentication_success and (some) tampered_request audit events (apikey.id and apikey.name are present only when authn with an api key) when authn with an api key, the user.realm field now contains the realm name of the user that created the key, instead of the synthetic value of _es_api_key. note that in this circumstance, the user.name field reflects the name of the user that created the key (they are consistent) user.roles contains the role names (only of found/resolved roles) of the user that created the key. it previously wrongly had the role descriptor names from the api key definition. this is now handled separately in #59041 . relates #52551 </desc> <cmt> wip </cmt> <cmt> wip mhhhmm </cmt> <cmt> wip mhmm </cmt> <cmt> nothing here </cmt> <cmt> revert to wrong format </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> tests fix wip </cmt> <cmt> teests compile and authenticationservicetests passes </cmt> <cmt> le tests </cmt> <cmt> limited role changes </cmt> <cmt> authentication type </cmt> <cmt> more tests </cmt> <cmt> filter tests </cmt>",improve auditing of api key authentication
1579,<desc> this pr uses and updated version of biscotto (gjtorikian/biscotto#27) that interprets method references as follows: foo.bar is a class method baz::quux is an instance method this blends in cleanly with the coffeescript literal syntax and brings much joy. the new syntax is used both in the interpretation of {} links in method comments and in the generated docs. </desc> <cmt> switch all documentation links to match coffeescript literal notation </cmt> <cmt> foo::bar for instance methods </cmt> <cmt> foo.bar for class methods </cmt> <cmt> point at biscotto branch on github until atom/biscotto#27 lands </cmt>,use coffeescript literal syntax to reference methods in docs
1580,"<desc> update: refactor check_for_upgrade file - move .zsh-update file migration inside check_for_upgrade - use a trap to remove the lock folder - simplify upgrade script call - rename functions update: remove lock directory if older than one day update: fix trap for sigint and read prompt on non-newline characters fixes #4992 fixes #5286 closes #6646 fixes #7042 fixes #8332 remaining upgrade issues these are not solved by this pr: #2971 #4361 #6732 #6989 #7539 #8003 #8387 #8788 </desc> <cmt> update: refactor check_for_upgrade file </cmt> <cmt> - move .zsh-update file migration inside check_for_upgrade </cmt> <cmt> - use a trap to remove the lock folder </cmt> <cmt> - simplify upgrade script call </cmt> <cmt> - rename functions </cmt> <cmt> update: remove lock directory if older than one day </cmt> <cmt> update: fix trap for sigint and read prompt on non-newline characters </cmt> <iss> upgrade does not respect $home - wrong ownership after upgrade </iss> <iss> alternative to auto-update prompt </iss> <iss> update prompt doesn't appear to work, or does and just repeatidly asks. </iss> <iss> old update.lock will block update </iss>",refactor and fix logic in check_for_upgrade.sh
1581,"<desc> issue link: airflow-6521 description above provides context of the change commit message/pr title starts with [airflow-nnnn]. airflow-nnnn = jira id* unit tests coverage for changes (not needed for documentation changes) commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. * for document-only changes commit message can start with [airflow-xxxx]. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> add optional 'project' parameter to bq hook method getschema </cmt> <cmt> add some param documentation. </cmt> <cmt> remove extraneous comma </cmt>",add project param to bigquery hook .getschema method
1582,"<desc> this pr aims to add proper support of mask in timedistributed wrapper layer. several previous prs have raised questions about this or have attempted to solve it, but i didn't find any perfect solution so far. i may not be able to have a perfect one either but am willing to improve it. the most frequent usage of such layers with masking support might be a hierarchical rnn on a sentence with words with characters, or a paragraph with sentences with words. (e.g., models like this). here are the main ideas/purposes of this pr: for layers like timedistributed(embedding(..., mask_zero=true)) or timedistributed(masking(...)), the layer should call compute_mask() at each time step and stack them. for layers like timedistributed(lstm(...)), the input_mask should be split and fed into the lstm layer at each time step. and if the output_shape changes (e.g., return_sequences=false in lstm), the output_mask of the timedistributed layer should also change correspondingly. the timedistributed layer should support, e.g., input_shape=(none, none). for example, the number of words in a sentence and the number of characters in a word can be different from sample to sample. currently the timedistributed can only support one unspecified input dimension. here are some details of this pr to discuss, which might have better solutions: k.int_shape() may not be available for some mask with theano backend, especially when the inner layer is embedding or masking. this is because _keras_shape is not set in lots of operations in theano_backend if the tensor shape is not changed. i manually create the _keras_shape in compute_mask of these two layers. when input_shape[0] is not none in timedistributed layer, we need to use k.rnn() to dynamically call the inner layer. because k.rnn() can only take 1 tensor input but we need to feed both input and mask, i didn't do anything in this situation. probably we can pass all mask as constants to k.rnn() but i was expecting better solutions. if there's none from the output of k.int_shape, we need to replace it by the output from k.shape, so that reshape can be correctly called. </desc> <cmt> equip timedistributed with mask and unspecified input length </cmt> <cmt> fix bugs in theano. add test on timedistributed + masking </cmt>",handle mask in timedistributed wrapper.
1583,<desc> due to bad formatting the apt-install ... command is not readable on github. also a couple of dependencies for atari-py and box2d-py are missing: cmake zlib1g zlib1g-dev swig. </desc> <cmt> fix linux dependencies. </cmt> <cmt> add linux dependencies for atari-py and box2d-py </cmt>,fix linux dependencies in readme.rst
1584,"<desc> fixes #18831 this pr also includes a package version bump (16.13.1 -> 17.0.0-alpha.0) so that devtools tests will pass ci. pr #19108 broke devtools suspense integration. devtools uses the renderer's version number to figure out what the tag numbers are: react/packages/react-devtools-shared/src/backend/renderer.js lines 156 to 240 45eef8b if (gte(version, '16.6.0-beta.0')) { reacttypeofwork = { block: 22, classcomponent: 1, contextconsumer: 9, contextprovider: 10, coroutinecomponent: -1, // removed coroutinehandlerphase: -1, // removed dehydratedsuspensecomponent: 18, // behind a flag forwardref: 11, fragment: 7, functioncomponent: 0, hostcomponent: 5, hostportal: 4, hostroot: 3, hosttext: 6, incompleteclasscomponent: 17, indeterminatecomponent: 2, lazycomponent: 16, memocomponent: 14, mode: 8, offscreencomponent: 23, // experimental profiler: 12, simplememocomponent: 15, suspensecomponent: 13, suspenselistcomponent: 19, // experimental yieldcomponent: -1, // removed }; } else if (gte(version, '16.4.3-alpha')) { reacttypeofwork = { block: -1, // doesn't exist yet classcomponent: 2, contextconsumer: 11, contextprovider: 12, coroutinecomponent: -1, // removed coroutinehandlerphase: -1, // removed dehydratedsuspensecomponent: -1, // doesn't exist yet forwardref: 13, fragment: 9, functioncomponent: 0, hostcomponent: 7, hostportal: 6, hostroot: 5, hosttext: 8, incompleteclasscomponent: -1, // doesn't exist yet indeterminatecomponent: 4, lazycomponent: -1, // doesn't exist yet memocomponent: -1, // doesn't exist yet mode: 10, offscreencomponent: -1, // experimental profiler: 15, simplememocomponent: -1, // doesn't exist yet suspensecomponent: 16, suspenselistcomponent: -1, // doesn't exist yet yieldcomponent: -1, // removed }; } else { reacttypeofwork = { block: -1, // doesn't exist yet classcomponent: 2, contextconsumer: 12, contextprovider: 13, coroutinecomponent: 7, coroutinehandlerphase: 8, dehydratedsuspensecomponent: -1, // doesn't exist yet forwardref: 14, fragment: 10, functioncomponent: 1, hostcomponent: 5, hostportal: 4, hostroot: 3, hosttext: 6, incompleteclasscomponent: -1, // doesn't exist yet indeterminatecomponent: 0, lazycomponent: -1, // doesn't exist yet memocomponent: -1, // doesn't exist yet mode: 11, offscreencomponent: -1, // experimental profiler: 15, simplememocomponent: -1, // doesn't exist yet suspensecomponent: 16, suspenselistcomponent: -1, // doesn't exist yet yieldcomponent: 9, }; } as of #19108, devtools also decides how to traverse suspense fibers using the tag values as a form of feature detection: react/packages/react-devtools-shared/src/backend/renderer.js lines 1241 to 1247 45eef8b const aresuspensechildrenconditionallywrapped = offscreencomponent === -1; if (aresuspensechildrenconditionallywrapped) { primarychild = fiber.child; } else if (fiber.child !== null) { primarychild = fiber.child.child; } the reason this pr also bumps version numbers is that we previously had multiple suspense implementations published under 16.13.1 (both the npm releases and our ci-built releases that tests run against), so the devtools heuristic failed. to prevent this type of regression from happening again, a larger effort needs to be made in the form of follow up prs to get ci running devtools tests against a range of react releases (not just what's in master). </desc> <cmt> fixed suspense wrapping heuristic </cmt> <cmt> bump package numbers 16.13.1 -> 17.0.0-alpha.0 to fix devtools suspense heuristic </cmt> <iss> error: ""commit tree does not contain fiber 256. this is a bug in react devtools."" </iss>",fix suspense-wrapping heuristic (and bump version numbers)
1585,<desc> this pr includes fixes for b/30130919 also. </desc> <cmt> add oss-parent as parent of libphonenumber-parent </cmt> <cmt> roll back libphonenumber parent changes to unblock release </cmt> <cmt> [maven-release-plugin] prepare release libphonenumber-7.4.5 </cmt> <cmt> [maven-release-plugin] prepare for next development iteration </cmt>,maven pom.xml updates for release 7.4.5
1586,"<desc> related issue = #1905 #1996 in this pr, i try to determine which extension instruction should be used when casting integers. according to my understanding, we should use zext for unsigned int, and sext for signed int. please note that, the original goal of this pr is to determine the instruction for custominttype.  one custominttype should be loaded through globalloadstmt first before casting. after loading, the custominttype would be a ""normal"" integer type (the same type as its computetype). that is to say, we can simply treat the custominttype  and primitive integer type equally here. </desc> <cmt> mod extensin instructions </cmt> <cmt> add tests </cmt> <cmt> mod tests </cmt> <cmt> fix typo </cmt>",use zext instruction to cast unsigned int
1587,"<desc> two fixes here: first, ie11 doesn't do 3d transforms, so we need the fallback. luckily, @supports is dope as hell. second, ie11 has a weird bug with flex: 1 0 auto and min-width on flex items in a variable width parent container. the fix? use width instead. see philipwalton/flexbugs#128 for details. fixes #22882 </desc> <cmt> use @supports to apply transform3d to those who can do it, then provide a non-3d fallback to ie11 </cmt> <cmt> using max-width in flex: 1 0 auto; in ie11 offsets the center-aligned contents </cmt>",fix broken carousel in ie11
1588,"<desc> 5.1 cherry-pick of #23944. fixes rdar://49710077 </desc> <cmt> irgen: assert if its too late to queue up lazy emission </cmt> <cmt> irgen: emit field reflection descriptors for types with custom alignment </cmt> <cmt> the code to decide if field descriptors were going to be emitted was </cmt> <cmt> confusing, so i've refactored it a bit. </cmt> <cmt> irgen: change around how we decide to emit lazy type metadata </cmt> <cmt> the old logic was confusing. the lazytypeglobals map would contain </cmt> <cmt> entries for all referenced types, even those without lazy metadata. </cmt> <cmt> and for a type with lazy metadata, the islazy field would begin </cmt> <cmt> with a value of false -- unless it was imported. </cmt> <cmt> when a non-imported type was finally visited in the ast, we would </cmt> <cmt> try to ""enable"" lazyness for it, which meant queueing up any </cmt> <cmt> metadata that had been requested prior, or immediately emitting </cmt> <cmt> the metadata otherwise. </cmt> <cmt> instead, let's add a separate map that caches whether a type has </cmt> <cmt> lazy metadata or not. the first time we ask for the metadata of a </cmt> <cmt> type, consult this map. if the type has lazy metadata according to </cmt> <cmt> the map, queue up metadata emission for the type. otherwise, emit </cmt> <cmt> metadata eagerly when the type is visited in the ast. </cmt> <cmt> irgen: emit foreign type metadata using the lazy metadata mechanism </cmt> <cmt> instead of a wholly separate lazyness mechanism for foreign metadata where </cmt> <cmt> the first call to getaddrofforeigntypemetadatacandidate() would emit the </cmt> <cmt> metadata, emit it using the lazy metadata mechanism. </cmt> <cmt> this eliminates some code duplication. it also ensures that foreign </cmt> <cmt> metadata is only emitted once per sil module, and not once per llvm </cmt> <cmt> module, avoiding duplicate copies that must be odr'd away in multi-threaded </cmt> <cmt> mode. </cmt> <cmt> this fixes the test case from <rdar://problem/49710077>. </cmt> <cmt> irgen: lazily emit reflection field descriptors </cmt> <cmt> previously even if a type's metadata was optimized away, we would still </cmt> <cmt> emit a field descriptor, which in turn could reference nominal type </cmt> <cmt> descriptors for other types via symbolic references, etc. </cmt> <cmt> irgen: force field descriptors to be emitted when we emit typerefs </cmt> <cmt> emission of typerefs used by the runtime would force type metadata; </cmt> <cmt> do the same for remote reflection-only typerefs. </cmt> <cmt> irgen: stop forcing lazy metadata in a few places </cmt> <cmt> these were all working around other issues that have since been fixed. </cmt>",fix some problems with irgen lazy metadata emission [5.1]
1589,"<desc> fixes #11564 remove the iterative use of plt.subplot that will soon be deprecated. not sure there is something to do for plot_discretization_classification.py, no warning were raised when i tried to reproduce. am i missing something ? </desc> <cmt> change depreciated matplotlib code to new matplotlib api </cmt> <cmt> remove unused params </cmt> <iss> plot_svm_scale_c.py and plot_discretization_classification.py use deprecated plt api </iss>",fix plot_svm_scale_c.py and plot_discretization_classification.py use deprecated plt api
1590,"<desc> streams like inputmemorystream and deflatedecompressor have slightly different semantics. if you try to read 4096 byte from an inputmemorystream that only has 1024 bytes, then it will fail, but you can still go on because the stream is still in a well defined state. doing the same with deflatedecompressor leaves the stream in a not so well defined state because some of the data could have been consumed already, the stream is left in an undefined state. that's why i am adding has_fatal_error and has_recoverable_error instead of a single has_error. </desc> <cmt> streams: distinguish recoverable and fatal errors. </cmt> <cmt> ak: remove history from duplexmemorystream. </cmt> <cmt> that feature was really only useful for compress::deflatedecompressor </cmt> <cmt> but that is now using circularduplexbuffer instead. </cmt> <cmt> ak: move memory streams into their own header. </cmt> <cmt> ak: add duplexmemorystream::copy_into_contiguous_buffer. </cmt> <cmt> ak: add outputmemorystream class. </cmt>",better error handling; move memory streams into their own header.
1591,"<desc> in case of a new cheat sheet, you have used the cheat sheet template. all the markdown files do not raise any validation policy violation, see the policy. all the markdown files follow these format rules. all your assets are stored in the assets folder. all the images used are in the png format. any references to websites have been formatted as text the ci build of your pr pass, see the build status here. this pr covers issue #. </desc> <cmt> update docker_security_cheat_sheet.md </cmt> <cmt> grammar update in the access_control_cheat_sheet.md cheatsheet. (#422) </cmt> <cmt> syncing with the owasp/cheatsheetseries </cmt> <cmt> updated grammar in web_service_security_cheat_sheet </cmt> <cmt> syncing with master branch of owasp/cheatsheetseries </cmt> <cmt> syncing with owasp/cheatsheetseries </cmt> <cmt> update with opa </cmt> <cmt> update kubernetes_security_cheat_sheet.md </cmt> <cmt> update with service mesh </cmt>",update k8s security cs with service mesh & opa
1592,<desc> what's in this pull request? better abi compatibility checks - more aligned with the sil verifier. the devirtualizer now respects the no-opt markers of callee functions. resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> addresses are always abi compatible. </cmt> <cmt> now it is more inline with the check performed by the verifier. </cmt> <cmt> add a more strict check for conversions between metatypes. </cmt> <cmt> now it is more inline with the check performed by the verifier. </cmt> <cmt> [sil-devirtualizer] do not perform a speculative devirtualization for no-opt callees. </cmt>,small fixes for the sil-devirtualizer
1593,"<desc> this pr refactors the rllib train.py script to depend on a new ray.tune module, which implements efficient hyper-parameter search. the overall usage of train.py remains roughly the same, though now it supports two modes: inline args: ./train.py --env=pong-v0 --alg=ppo --num_trials=8 --stop '{""time_total_s"": 3200}' --resources '{""cpu"": 8, ""gpu"": 2}' --config '{""num_workers"": 8, ""sgd_num_iter"": 10}' file-based: ./train.py -f tune-pong.yaml both delegate scheduling of trials to the ray.tune trialrunner class. additionally, the file-based mode supports hyper-parameter tuning (currently just grid and random search). note that though ray.tune should be written to support generic training, right now it has some rl-specific notions like agents and envs, which we should try to remove. </desc> <cmt> clean up train </cmt> <cmt> update </cmt> <cmt> update train script </cmt> <cmt> add tuned examples </cmt> <cmt> add agent catalog </cmt> <cmt> add tune lib </cmt> <cmt> update </cmt> <cmt> fix </cmt> <cmt> tests </cmt> <cmt> remove </cmt> <cmt> train docs </cmt>",initial work on integrating hyperparameter search tool
1594,<desc> modifies randomversionbetween so that it works with unreleased versions. this should make switching a version from unreleased to released much simpler. </desc> <cmt> wip </cmt> <cmt> test: randomversionbetween works with unreleased </cmt> <cmt> modifies randomversionbetween so that it works with unreleased </cmt> <cmt> versions. this should make switching a version from unreleased </cmt> <cmt> to released much simpler. </cmt>,make randomversionbetween work with unreleased versions
1595,<desc> i checked most examples and the only problem left is the depthpassplugin. it fixes a lot of problems like visibility and  the __webglinit hack. performance is similar on all examples. so how do we proceed further?? </desc> <cmt> fix the hack __webglinit for geometry that needs buffer updates. </cmt> <cmt> use recursive projectobject to fix visiblility and make renderdata smaller </cmt>,remove hackery + fix visibility in webglrenderer
1596,"<desc> v1.17.0 is released, add api compatibility data for it generated by doing: git checkout v1.17.0 cp -fr staging/src/k8s.io/api/testdata/head staging/src/k8s.io/api/testdata/v1.17.0 git checkout -b 1.17.0-api-fixtures master git add . git commit -m ... does this pr introduce a user-facing change?: / </desc> <cmt> add v1.17.0 api compatibility data </cmt> <cmt> drop v1.15.0 api test data </cmt>",update api compatibility data for v1.17.0
1597,<desc> backport of #36824 to stable-2.5 fixes documentation and ip configuration where no public ip is defined. azure_rm_networkinterface ansible version 2.5 </desc> <cmt> azure_rm_networkinterface: fixed issue when public ip address should not be created (#36824) </cmt> <cmt> * fixed issue when public ip address should not be created </cmt> <cmt> * adding test for public ip address </cmt> <cmt> * fixed samples </cmt> <cmt> * another fix to sample formatting </cmt> <cmt> * fixed test </cmt> <cmt> * fix test </cmt> <cmt> * fixed test </cmt> <cmt> * another attempt to fix test </cmt> <cmt> * maybe it works now </cmt> <cmt> * still wrong </cmt> <cmt> * improved check per customer request </cmt> <cmt> * removed stupid semicolon </cmt> <cmt> * updated test to match main scenario </cmt> <cmt> * changed ip configurations to list </cmt> <cmt> * another attempt </cmt> <cmt> (cherry picked from commit 89401f13f761c94552fca8eafbaf5bcf54aff40c) </cmt> <cmt> added changelog fragment </cmt>,backport no public ip fix
1598,"<desc> this commit lowers the severity for all settings from critical to warning for all settings that are still present in 8.0.0. releated #79107 === note - i have requested review from @tvernum and @jbaiera since these settings are mostly from areas for which they are familiar. please add others for review if needed. cc: @masseyke @rjernst @pgomulka === note this settings were identified by introducing the following debug code in 8.0.0 and 7.16 and comparing the two lists. if the same setting showed up as deprecated in both 7.16 and 8.0.0 it is included in this pr. if the setting was missing in 8.0.0, no changes since the default is critical. diff --git a/server/src/main/java/org/elasticsearch/common/settings/setting.java b/server/src/main/java/org/elasticsearch/common/settings/setting.java index a56baf6cf3b..8a23f9ce906 100644 --- a/server/src/main/java/org/elasticsearch/common/settings/setting.java +++ b/server/src/main/java/org/elasticsearch/common/settings/setting.java @@ -161,6 +161,12 @@ public class setting<t> implements toxcontentobject { this.defaultvalue = defaultvalue; this.parser = parser; this.validator = validator; +        if(arrays.stream(properties).filter(p -> p.equals(property.deprecated) || p.equals(property.deprecatedwarning)).count() > 0){ +                       system.out.println(""**deprecated setting: "" + key + +                           (arrays.stream(properties).filter( p -> p.equals(property.deprecatedwarning)).count() > 0 ? ""(warning)"" : """")); + + +                    } if (properties == null) { throw new illegalargumentexception(""properties cannot be null for setting ["" + key + ""]""); } </desc> <cmt> initial iter </cmt> <cmt> more iterations </cmt>",reduce deprecation logging severity for settings that are not removed in 8.0
1599,"<desc> this pr is a continuation of #76455 changes overflow renamed to posoverflow and underflow renamed to negoverflow after discussion in #76455 changed some of the parsing code to return invaliddigit rather than empty for strings ""+"" and ""-"".  carry the problem char with the invaliddigit variant. necessary changes were made to the compiler as it depends on int_error_matching. redid tests to match on specific errors. r? @kodraus </desc> <cmt> fill in things needed to stabilize int_error_matching </cmt> <cmt> bring char along with invaliddigit </cmt> <cmt> remove incorrect plural </cmt> <cmt> remove onlysign in favour of invaliddigit </cmt> <cmt> add comment to helper function </cmt>","refactor interrorkind to avoid ""underflow"" terminology"
1600,<desc> added izi in transportation section added zippopotam to geocoding section </desc> <cmt> added cloud vision api </cmt> <cmt> added rekognition api </cmt> <cmt> cloud vision api link fixed </cmt> <cmt> merge </cmt> <cmt> # conflicts: </cmt> <cmt> #	readme.md </cmt> <cmt> added izi in transportation section </cmt> <cmt> added zippopotam to geocoding section </cmt>,added zippopotam and izi in list
1601,"<desc> at the moment you can only get an array of full messages. the link with their attributes are lost. i'd like clients to be able to relate full error messages to their corresponding fields. so i'd like to get e.g. : with this patch it makes the implementation possible with: obj.errors.map { |attr, msg| [attr, obj.errors.full_message(attr, msg)] } </desc> <cmt> add ability to get an individual full error message + test for full_messages. </cmt> <cmt> added test for obj.errors.as_json </cmt>",ability to get single full error message
1602,<desc> there's one user who has an issue that one of raylets cannot schedule tasks anymore because num_worker_not_started_by_job_config_not_exist  > 0. this pr adds better log messages to figure out if the root cause is the job information is not properly propagated from gcs to raylet through redis pubsub. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> done </cmt> <cmt> lint </cmt>,better logs job message failure
1603,"<desc> addresses the handful of remaining feedback from pt. 2, plus adds two new tests: one verifying a multi-topology application with a fkj and its internal topics, another to make sure iq works with named topologies (though note that there is a bit more work left for iq to be fully supported, will be tackled after pt. 3 </desc> <cmt> followup to feedback from pt. 2, cleanup some tests and peel some pt. 3 refactoring up front, plus test for iq </cmt> <cmt> clarify iq status </cmt>",minor followup from pt. 2 and some new tests
1604,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> update: add get command types </cmt> <cmt> update: add consent types </cmt>,"add type of get, consent"
1605,"<desc> implementation of #6345. the code might be a bit complicated, though i tried to make it as de-coupled from the rest of the codebase as possible. the feature is hidden behind an option, and using the default value means no change in behavior and very little additional code execution. </desc> <cmt> initial commit w/ working implementation </cmt> <cmt> bug fixes, code cleanup </cmt> <cmt> add execution guard if option is 0 </cmt>",implementation of #6345 - remember tree hierarchy in db navigator
1606,"<desc> this speeds up testlogview in test_views.py by moving the app instantiation out of setup and  into setupclass. currently the tests are slow because the app instantiation takes 6 seconds each time, and multiple of the test methods are parameterized, slowing the test down further. www tests now completes in 9:08. previously it was ~12minutes. </desc> <cmt> blah. </cmt> <cmt> make fail on purpose. </cmt>",speed up tests by moving app instantiation to class method
1607,"<desc> with quite some discussions on naming of the apis, finally adds 3 new apis: bool objectempty() sizetype membercount() removeallmembers() apis similar to vector::capacity() and vector::reserve() are not added for member, because some possible implementations of associative array may be considered in the future and these apis may not be suitable for those situations. fixes #116 </desc> <cmt> add value::membercount(), memberempty(), removeallmembers() </cmt> <cmt> change memberempty() to objectempty() </cmt> <iss> value::membercount() or value::objectsize() </iss>",three new apis are added for json object type.
1608,<desc> fixes #18837 on sklearn.decomposition set check_finite to false after verifying that the input is checked by one of the internal functions. </desc> <cmt> duplicate check_finite when calling scipy.linalg functions on covariance._empirical_covariance </cmt> <cmt> check_finite=false on incremental_pca </cmt> <cmt> check_finite=false on fastica </cmt> <cmt> check_finite=false on factor_analysis </cmt> <iss> duplicate check_finite when calling scipy.linalg functions </iss>,enh sets check_finite=false in sklearn.decomposition
1609,<desc> this pr adds: adjustments for windows </desc> <cmt> add command to test wipeallpackages </cmt> <cmt> wipe all packages test </cmt> <cmt> tested on mac </cmt> <cmt> additional checks in tests to ensure that exactly two versions of tool are not removed </cmt> <cmt> fix the test to generate a relative symlink </cmt> <cmt> add fake builds in the test </cmt> <cmt> fix the default release track issue on windows </cmt> <cmt> be able to parse absolute and relative paths in meteor.bat </cmt> <cmt> fix wipe-all-packages test for windows </cmt> <cmt> adapt wipe-all-packages command to windows layout </cmt>,wipe all packages on windows
1610,"<desc> related issue = #1905 test case(0.75s -> 0.42s) import taichi as ti ti.init(arch=ti.cpu, kernel_profiler=true, print_ir=true, quant_opt_atomic_demotion=true) quant = true n = 1024 * 1024 * 256 if quant: ci16 = ti.quant.int(16, true) x = ti.field(dtype=ci16) y = ti.field(dtype=ci16) ti.root.dense(ti.i, n).bit_struct(num_bits=32).place(x, y) else: x = ti.field(dtype=ti.i16) y = ti.field(dtype=ti.i16) ti.root.dense(ti.i, n).place(x, y) @ti.kernel def foo(): for i in range(n): x[i] = 1 for i in range(10): foo() ti.kernel_profiler_print() </desc> <cmt> ir for demoting atomic bit struct stores </cmt> <cmt> codegen </cmt>",atomic demotion for bit struct stores
1611,"<desc> this is a basic change.  we have nightwatchtesthooks extending nightwatchglobals, but the globals property is only scoped to nightwatchglobals.  this excludes global before, beforeeach, after, and aftereach functions. it's important to separate before/after and beforeeach/aftereach - they don't get the same arguments. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fixed page_object_path to page_objects_path </cmt> <cmt> added webdriver options to nightwatchoptions </cmt> <cmt> forgot a semicolon </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> changed globals definition to nightwatchtesthooks </cmt> <cmt> separated global hook definitions </cmt>",changed globals from nighwatchglobals to nightwatchtesthooks
1612,"<desc> before: ');@output_buffer.append= ( content_icon row[:content] );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('        ');@output_buffer.append= ( spinner_img );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('      </td> <td class=""content""> ');@output_buffer.append= ( content_link row[:content] );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('      </td> <td class=""message""> '); after: ';@output_buffer.append=( content_icon row[:content] );@output_buffer.safe_append=' ';@output_buffer.append=( spinner_img );@output_buffer.safe_append=' </td> <td class=""content""> ';@output_buffer.append=( content_link row[:content] );@output_buffer.safe_append=' </td> <td class=""message""> '; </desc> <cmt> use actionview::outputbuffer#safe_append= from templates </cmt> <cmt> avoid extra method calls for appending newlines </cmt> <cmt> before: </cmt> <cmt> ');@output_buffer.append= ( content_icon row[:content] );@output_buffer.safe_concat(' </cmt> <cmt> ');@output_buffer.safe_concat('        ');@output_buffer.append= ( spinner_img );@output_buffer.safe_concat(' </cmt> <cmt> ');@output_buffer.safe_concat('      </td> </cmt> <cmt> <td class=""content""> </cmt> <cmt> ');@output_buffer.append= ( content_link row[:content] );@output_buffer.safe_concat(' </cmt> <cmt> ');@output_buffer.safe_concat('      </td> </cmt> <cmt> <td class=""message""> </cmt> <cmt> '); </cmt> <cmt> after: </cmt> <cmt> ';@output_buffer.append=( content_icon row[:content] );@output_buffer.safe_append=' </cmt> <cmt> ';@output_buffer.append=( spinner_img );@output_buffer.safe_append=' </cmt> <cmt> </td> </cmt> <cmt> <td class=""content""> </cmt> <cmt> ';@output_buffer.append=( content_link row[:content] );@output_buffer.safe_append=' </cmt> <cmt> </td> </cmt> <cmt> <td class=""message""> </cmt> <cmt> '; </cmt>",optimize generated erb to reduce method calls
1613,"<desc> extending the gpgpu birds demo so that it can load any gltf model/animation and use meshstandardmaterial to shade. gltf vertices are baked onto a texture. one frame per row texture is passed to the vertex shader along with a frame reference. meshstandardmaterial is applied demo here :  on demo, a new geo is loaded randomly, may be confusing... this is my first pr ever. not sure if this is even helpful or correctly done but would like to learn the process to contribute to three in the future. </desc> <cmt> working and stuff </cmt> <cmt> add models </cmt>",gpgpu birds example with gltf loader and meshstandardmaterial
1614,"<desc> first commit fix a delete crash when testing ticket 12729, caused by buffer pointer not set to null after delete. second commit fix ticket 12729 by tell libcurl ignore content-length of shoutcast file.: when the shoutcast file was 302 redirected, libcurl may return the content-length of the 302 page's body, it cause next read return 0. </desc> <cmt> fix crash in cshoutcastfile::close(), clear buffer pointer after delete. </cmt> <cmt> fix ticket 12729, ignore content-length of shoutcast file. </cmt> <cmt> when the shoutcast file was 302 redirected, libcurl may return the </cmt> <cmt> content-length of the 302 page's body, it cause next read return 0. </cmt>",fix redirected shoutcast ticket 12729
1615,"<desc> what do these changes do? log a warning if the default object store size exceeds 50% of available memory (it should only really consume 30% if all memory is available). the value 50% is chosen here to include the 20% of memory allowed to redis. raise an error if the default object store size exceeds 90% of available memory. exclude shared memory from the reported mem stats, since it is quite misleading and already reported as object store memory. also, report up to the 10 memory consumers. the error looks something like this: traceback (most recent call last): file ""./train.py"", line 153, in <module> run(args, parser) file ""./train.py"", line 142, in run num_gpus=args.ray_num_gpus) file ""/home/eric/desktop/ray-private/python/ray/worker.py"", line 1387, in init head=true, shutdown_at_exit=false, ray_params=ray_params) file ""/home/eric/desktop/ray-private/python/ray/node.py"", line 150, in __init__ self.start_ray_processes() file ""/home/eric/desktop/ray-private/python/ray/node.py"", line 514, in start_ray_processes self.start_plasma_store() file ""/home/eric/desktop/ray-private/python/ray/node.py"", line 414, in start_plasma_store plasma_store_socket_name=self._plasma_store_socket_name) file ""/home/eric/desktop/ray-private/python/ray/services.py"", line 1455, in start_plasma_store object_store_memory, plasma_directory, huge_pages) file ""/home/eric/desktop/ray-private/python/ray/services.py"", line 1313, in determine_plasma_store_config round(avail_memory / 1e9, 2))) valueerror: the default object store size of 3.68 gb will use more than 90% of the available memory on this node (1.54 gb). please reduce the object store memory size to avoid memory contention with other applications, or shut down the applications using this memory. #4877 linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> exclude </cmt> <cmt> format </cmt>",add warning/error if object store memory exceeds available memory
1616,"<desc> this pr implements features that are sufficient to support wordpress-style url rewrites without stepping into the mod_rewrite-hell. for example, with the pr it becomes possible to map /2015/06/15/blogpost/ internally to /index.php/2015/06/15/blogpost/ in case no file was found. the approach is a combination of: the file handler passes the request through to the next handler if it failed to find the file adds internal attribute to redirect handler, so that it could be used for declaring internal redirections with these features, it is possible to support wordpress-like url rewrites by setting the configuration directive like: file.custom-handler: extension: .php fastcgi.spawn: ""php_fcgi_children=10 exec php-cgi"" hosts: ""hostname"": paths: /: file.dir: /www/root/dir   # serve the files, should they exist redirect:                 # if file was not found, retry with /index.php/<path> url: /index.php/ internal: yes status: 307 </desc> <cmt> [lib/handler/file.c] in case of 404, delegate the request to next handler </cmt> <cmt> [redirect] support internal redirects with internal attribute </cmt> <cmt> introduce confvar: fastcgi.send-delegated-uri; default is off considering the fact that fastcgi apps tend to expect to receive original uri after the request is being rewritten </cmt>",implement features sufficient to support wordpress url rewrites
1617,"<desc> this pr deprecates the init(frominputarray:realparts:imaginaryparts:) for dspsplitcomplex and dspdoublesplitcomplex. i've also updated the fft tests to no longer use these deprecated initializers, and to replace the incorrect use of temporary pointers with withunsafemutablebufferpointer. @stephentyrone </desc> <cmt> update fft tests </cmt> <cmt> i removed singleprecisioncomplexconversions and doubleprecisioncomplexconversions - they weren't testing any new api. </cmt> <cmt> 2dsingleprecision, 2ddoubleprecision, 1dsingleprecision, and 1ddoubleprecision have all been updated to no longer use the deprecated initializer and avoid the temporary pointer warnings. </cmt> <cmt> deprecate split complex inits </cmt> <cmt> deprecate init(frominputarray:realparts:imaginaryparts:) for dspsplitcomplex and dspdoublesplitcomplex </cmt>",accelerate deprecate split complex inits
1618,<desc> adds a new tab for windows containers on the run envoy section to illustrate how to use envoy with a windows container. </desc> <cmt> add windows container tabs on run-envoy </cmt> <cmt> format python </cmt> <cmt> add new line at the end </cmt>,win32 docs for run-envoy.rst section
1619,<desc> show confirm message when deleting the following items. destination(alert) query snippet the following items are already shown. dashboard widget group </desc> <cmt> confirm delete a query snippet </cmt> <cmt> confirm delete a destination </cmt> <cmt> confirm delete a data source </cmt>,display confirmation dialog when deleting a item
1620,"<desc> all the markdown files do not raise any validation policy violation, see policy here. all the markdown files follow these format rules. any references to website have been formatted as text you verified/tested the effectiveness of your contribution (e.g.: defensive code proposed is really an effective remediation? please verify it works!). the ci build of your pr pass, see the build status here. this pr covers issue #147. </desc> <cmt> chore: update samesite introduction </cmt> <cmt> chore: update samesite attribute value description </cmt> <cmt> chore: update samesite conclusion </cmt>",css-147 update samesite in csrf cs
1621,"<desc> fix 2 corner cases in test setup: unsigned_long not support as index sort,do not overlay a runtime field with index sort fixes #72733 relates #72692 note: this builds on top of #72692, therefore setting backport_pending </desc> <cmt> fix 2 corner cases in test setup: unsigned_long not support as index sort, </cmt> <cmt> do not overlay a runtime field with index sort </cmt> <cmt> fixes #72733 </cmt> <cmt> unmute </cmt> <cmt> add reason </cmt> <iss> [ci] transformcontinuousit testcontinousevents failing </iss>",fix 2 issues with index sort in integration test
1622,"<desc> i wanted something in the docs that i can link to from each tutorial repo. this was a nightmare to write up and to try and come up with a way for some people to contribute. hey @scissorsneedfoodtoo - you're probably the one who knows the most about working on these. want to give this a look and see if you have any ideas on how to have people contribute to these. i want to be able to accept pr's the main branch so people can fix typos and things. that should be pretty straight forward. changing tests is another story. maybe we should just reserve that for staff for the time being, or permanently. either way, it would be nice to have something in the docs. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. </desc> <cmt> feat(docs): add how to contribute to coderoad tutorials </cmt> <cmt> update json </cmt> <cmt> finish: some docs anyway </cmt> <cmt> more </cmt>",add how to contribute to rdbms repos
1623,<desc> just a pr to fix some of the troubles that i ran into when going from .pipeline(parallelism=15) -> .window(blocks_per_window=15) follow on to #19050 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> mention the actual args </cmt> <cmt> rename pilelining -> windowing? </cmt> <cmt> clarify the docks that this requires kwargs </cmt>,clean up docs around pipelining -> windowing rename
1624,"<desc> updated the test_metadata_upgrade test.  to enable using the 2.1 version i needed to add config change to the streamsupgradetestjobrunnerservice to ensure the ductape passes proper args when starting the streamsupgradetest for testing, i ran the test_metadata_upgrade test and all versions now pass </desc> <cmt> minor: add 2.1 to the metadata_upgrade test </cmt> <cmt> minor: add latest 2.1 to service start cmd to enable proper start args </cmt>",add 2.1 version metadata upgrade
1625,"<desc> hide some implementation details of array types. </desc> <cmt> stdlib: make _arrayprotocol and _arraybufferprotocol internal </cmt> <cmt> stdlib: mark some array buffers implementation details as internal </cmt> <cmt> stdlib: internalize the _uninitializedcount initializer of array buffer </cmt> <cmt> stdlib: mark _arraybuffer, _contiguousarraybuffer, and _slicebuffer internal </cmt> <cmt> stdlib: mark apis on internal types as internal </cmt> <cmt> stdlib: fix the build with resilience enabled </cmt> <cmt> stdlib: mark _arraybuffer apis as internal </cmt>","make array implementation internal, part 2"
1626,"<desc> explanation: by manually experimenting with apis, we found a few cases of nested variables in xcode 9 change to global variables in xcode 10. since the pattern migrator used to handle is only the opposite direction, we need to update the swift-api-digester and the migrator to detect and handle this category of changes. scope of issue: swift 4.2 migrator risk: very low reviewed by: nathan hawes testing: unit tests added. radar: rdar://41658300 </desc> <cmt> swift-api-digester: teach the tool to detect member variables change to global ones. rdar://41658300 </cmt> <cmt> migrator: support the migration from member variables to global ones. rdar://41658300 </cmt> <cmt> migrator: ensure we update unresolved member access correctly to global names. rdar://41658300 </cmt>",handle member variables change to global ones. rdar://41658300
1627,"<desc> importing files from ""the same directory as this file"" was implicitly supported in python2.7 but not python3.  the syntax here works for both. </desc> <cmt> rework a couple of benchmarks to work with both python2 and python3 </cmt> <cmt> adjust relative import statements to use relative syntax </cmt> <cmt> importing files from ""the same directory as this file"" was </cmt> <cmt> implicitly supported in python2.7 but not python3.  the </cmt> <cmt> syntax here works for both. </cmt>",adjust relative import statements to use relative syntax so they work with py2 and py3
1628,<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. </desc> <cmt> i18n italian compliements </cmt> <cmt> first 10 motivational quotes for italian </cmt>,adding first few motivational quotes and compliments in italian
1629,"<desc> checks that it can open as read rather than read/write; this will fix the eperm and ebusy errors on read. makes the error better for eperm and ebusy errors when they do happen on save closes #5102 closes #5107 closes #5112 closes #3231 </desc> <cmt> only check read permission on read </cmt> <cmt> add a better message for eperm errors. </cmt> <cmt> explicitly check if the path to be deserialized is a dir </cmt> <iss> saving read-only file causes dev tools to open </iss> <iss> uncaught error: eperm, operation not permitted when opening a readonly file </iss> <iss> atom can no longer open readonly files </iss> <iss> uncaught error: ebusy, resource busy or locked 'c:\code\ta.mobile\source\tamobile6simulator\bin\debug\trackabout.mobile.log' </iss>",allow opening of readonly files
1630,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixed error when replication connection pool doesn't retry to resolve host, even when dns cache was dropped. </desc> <cmt> add case for host ip change </cmt> <cmt> fix bug with pooled http sessions and host ip change </cmt>",fix bug in pooled sessions and host ip change
1631,"<desc> when performing an in-memory rebase, we should be able to rebase a branch with no common ancestors (that is, the first commit to rebase has no parents). / </desc> <cmt> rebase: test rebase (merge) w/ no common ancestor </cmt> <cmt> rebase: handle no common ancestor for inmemory </cmt>",rebase a branch with no merge base for in-memory
1632,<desc> this adds: a way to make the compiler ice a way to check for ice in cfail tests with should-ice a regression test for issue #65401 i am not sure the attribute added should-ice is the best for this job </desc> <cmt> add header to compiletest to check for ice </cmt> <cmt> add rustc_error(delay_span_bug_from_inside_query) attribute </cmt> <cmt> remove another status code check is should-ice </cmt> <cmt> added test for checking that ices are not hidden </cmt>,making ices and test them in incremental
1633,"<desc> the initcascades function must be called whenever fov, near, far, or aspect fields are changed on a camera so it can be a hot function especially when resizing a window or animating a transition between camera types. i've modified it here to reuse frustum instances rather than create new ones whenever it's called to save on object allocation. i'll be doing the same thing for .update next. temporary live link:  @vhawk edit: looks like the failure is a diff issue from css3d_youtube: error! diff wrong in 0.079 of pixels in file: css3d_youtube </desc> <cmt> clone vertices </cmt> <cmt> pre-init vectors </cmt> <cmt> use cached vectors </cmt> <cmt> avoid making new frustums </cmt>",use cache objects in initcascades
1634,"<desc> uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design this pr adds annotations to the imagespec object in cri api. the expectation is that for windows in order to use non-default runtime classes pods would specify a kubernetse.io/runtimehandler annotation. this would get passed to the cri and used during various image pull and sandbox creation operations. this behavior would be optional and would need to be implemented for each cri independently. usage and more information can be found here:  does this pr introduce a user-facing change?: add annotations to cri-api imagespec objects. kep: </desc> <cmt> cri - adding annotations to imagespec and imagespec to image </cmt> <cmt> cri - updating fake_image_server.go to support annotations in imagespec </cmt>",add annotations to cri imagespec objects
1635,"<desc> 8ab0d65 </desc> <cmt> don't retrieve config in running_config when config is provided for diff (#41400) </cmt> <cmt> * don't retrieve config in running_config when config is provided for diff </cmt> <cmt> * fix for eos, nxos </cmt> <cmt> * add integration test </cmt> <cmt> (cherry picked from commit 8ab0d654f3eb44c715af8d8701eb3246d2abf419) </cmt> <cmt> add changelog </cmt>",don't retrieve config in running_config when config is provided for diff stable 2.5
1636,"<desc> while awesome, the initial type definition was made based on reverse engineering and improper documentation. this inevitably led to a few mistakes and an incomplete definition. documentation is now available, new package version has been published. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> rox-react-native: minor improvements, update documentation links </cmt> <cmt> rox-react-native: remove internal, undocumented, removed in next release method </cmt> <cmt> rox-react-native: upgrade package version, fix freeze options (they were plain wrong) </cmt> <cmt> rox-react-native: fix return type, add readonly attributes </cmt> <cmt> rox-react-native: adding a few missing items </cmt> <cmt> rox-react-native: default value of a flag is optional </cmt> <cmt> rox-react-native: more extensive tests </cmt> <cmt> rox-react-native: make fetcher result an enum </cmt>","fixes, improvements and update to rox-react-native"
1637,"<desc> rename container_option to container, make runtime options have the same code style. rename image name from ray-nest-container to ray-worker-container,  because it can be used in other scenarios, not only in nest container. #16671 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> rename container_option to container </cmt> <cmt> rename ray-nest-container to ray-worker-container </cmt>",rename container option and ray-nest-container
1638,"<desc> others others task node from python side class use these codes to test mp_dp_sharding: from paddle.distributed.fleet.fleet_executor_utils import tasknode task_node = tasknode( program=main_program.clone(), cur_rank=0, max_run_times=1, max_slot_times=1) main_program._pipeline_opt = {} main_program._pipeline_opt['fleet_opt'] = { 'section_program': main_program, 'tasks': [task_node], 'task_id_to_rank': {task_node.task_id(): fleet.worker_index()} } main_program._pipeline_opt['section_program'] = main_program </desc> <cmt> python side task node class </cmt> <cmt> reformat </cmt> <cmt> add ut </cmt> <cmt> add annotation </cmt> <cmt> fix typo </cmt> <cmt> rename </cmt> <cmt> remove useless store </cmt> <cmt> bug fix for some assertions </cmt> <cmt> delay the init of task node </cmt> <cmt> bug fix </cmt> <cmt> clone for task node </cmt> <cmt> update task node </cmt> <cmt> create op for set_program </cmt> <cmt> typo fix </cmt> <cmt> use pointer </cmt> <cmt> bug fix and add annotataions </cmt> <cmt> add log </cmt>",python side fleet executor and task node
1639,"<desc> what's in this pull request? move the core indexing functionality (the indexswiftastwalker) out of sourcekit and into a new index library in swift.  this makes the sourcekit-specific code lighter, leaving only the serialization issues like constructing uidents behind in swiftindexing.cpp.  mostly this was about pulling the sourcekit::uidents out of the indexdataconsumer interface, and using enums to classify the symbols instead. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [index] factor out the dependency between the core indexing walker and sourcekit </cmt> <cmt> the goal is to be able to move the core indexswiftastwalker code out of </cmt> <cmt> sourcekit, leaving only the serialization bits behind. </cmt> <cmt> mostly this replaces some direct uses of uident strings with explicit </cmt> <cmt> enums, and then adds the translation code to produce those enums and to </cmt> <cmt> convert them into uidents in sourcekit. </cmt> <cmt> rdar://problem/22348041 </cmt> <cmt> [index] move core indexing code out of sourcekit </cmt> <cmt> leaving only the sourcekit-specific code (e.g. uid generation) behind in </cmt> <cmt> sourcekit. </cmt> <cmt> rdar://problem/22348041 </cmt> <cmt> [index] move associated type into common macro nfc </cmt> <cmt> now that we have first-class associated types it works the same as the </cmt> <cmt> other simple cases. </cmt>",move indexswiftastwalker out of sourcekit
1640,"<desc> if axios is used with multiple domains, the auth_token will be sent to all of them when using the example code: axios.defaults.headers.common['authorization'] = auth_token this pr adds a comment above the example to that effect and points below for an example using custom instance defaults instead. the pr also adds an example setting user-agent, which is another common case for setting axios.defaults.headers.common. this is a continuation of #3471 which was previously closed. </desc> <cmt> updating the 'global axios defaults' readme to use a safer example </cmt> <cmt> the existing example usage it isn't safe in the general case as it can </cmt> <cmt> lead to auth tokens being leaked to 3rd party endpoints by unexpectedly. </cmt> <cmt> this change instead gives an example using </cmt> <cmt> ""axios.defaults.headers.common"" to set the user-agent, which is an </cmt> <cmt> equally helpful use-case to document. </cmt> <cmt> the 'custom instance defaults' example just below the 'global axios </cmt> <cmt> defaults' example shows a method to set the 'authorization' header </cmt> <cmt> specific to a given api. i've also updated the variable in the 'custom </cmt> <cmt> instance defaults' code to use a semantically more relevant name within </cmt> <cmt> that example. </cmt> <cmt> revert the example instance name in response to pr request </cmt> <cmt> reintroduce the authorization example with a disclaimer about its usage </cmt>",default headers example auth_token comment
1641,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fix bug with incorrect skip indices serialization and aggregation with adaptive granularity. this fixes #6594. </desc> <cmt> fix bad size of marks </cmt> <cmt> fix comment </cmt> <iss> bad size of marks file (versions 19.13.1.11 and 19.13.2) </iss>,fix bad size of marks with skip indices
1642,"<desc> this issue wasn't apparent while using the default system theme, but it was while using nord. these changes make the applet manager use the same color role as the one used by taskbar. i also made the clipboardhistory and network applets use the alpha channel as the icons were being filled with an incorrect background color as well. </desc> <cmt> windowserver: make applet area use the same color role as the taskbar </cmt> <cmt> so far the taskbar has been using the ""button"" as a color role, despite </cmt> <cmt> rest of the applet area using ""window"" color role. although it all </cmt> <cmt> looked alright on most system themes, it broke for the nord theme. </cmt> <cmt> clipboardhistory: make the applet use an alpha channel </cmt> <cmt> network: make the applet use an alpha channel </cmt>",improve the background color consistency of the applets area
1643,"<desc> there are certain widget which only need localizations in combination with a certain parameter or as a default value. in this case, there might be valid code that would break if this check were added. while i defaulted to always adding the debug check to the beginning of build - we should probably discuss the best way to do this. fixes #20406 </desc> <cmt> add assert(debugcheckhasmateriallocalizations(context)); </cmt> <cmt> update tests to work with debugcheck </cmt> <iss> we should assert that localizations are present </iss>",add debug check for localization parent
1644,"<desc> this pr improves the interfaces for the functions encodebase58{check} by using spans, in a similar fashion to e.g. prs #19660, #19687. note that on the master branch there are currently two versions of encodebase58: one that takes two pointers (marking begin and end) and another one that takes a std::vector<unsigned char> const-ref. the pr branch only leaves one generic span-interface, both simplifying the interface and allowing more generic containers to be passed. the same is done for encodebase58check, where only one interface existed but it's more generic now (e.g. a std::array can be directly passed, as done in the benchmarks). </desc> <cmt> util: make encodebase58 consume spans </cmt> <cmt> util: make encodebase58check consume spans </cmt>",make encodebase58{check} consume spans
1645,"<desc> fixes #1236 so that netdata can collect values from snmp string oids fixes #1155, python.d.plugin did not exit when netdata exited. now it does. </desc> <cmt> collect values from snmp string oids; fixes #1236 </cmt> <cmt> python.d.plugin should exit if it cannot send data to netdata; fixes #1155 </cmt> <cmt> really exit on fatal situations, even if no output is possible; fixes #1155 </cmt> <iss> netdata doesn't restart mysql connection when mysql-server is restarted </iss> <iss> snmp, wrong values. </iss>",snmp with string oids; python.d.plugin now exits properly
1646,"<desc> for #10970. i do not know if i misunderstood the requirement, but the first five tests required, as stated in the issue 10970, are already in the master branch. hence, i only wrote tests for the last three classes. -authorityrulebuilder -defaultauthorityruleconfigurationbuilder -authorityruleconfigurationyamlswapper </desc> <cmt> add files via upload </cmt> <cmt> add files via upload </cmt> <cmt> add files via upload </cmt> <cmt> update authorityruleconfigurationyamlswappertest.java </cmt> <cmt> rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/authorityruleconfigurationyamlswappertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/yaml/swapper/authorityruleconfigurationyamlswappertest.java </cmt> <cmt> rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/defaultauthorityruleconfigurationbuildertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/builder/defaultauthorityruleconfigurationbuildertest.java </cmt> <cmt> update and rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/authorityrulebuildertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/builder/authorityrulebuildertest.java </cmt>",add unit test for shardingsphere-infra-authority (issue #10970)
1647,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  turns out there were more methods and properties needed. </desc> <cmt> add unload method to webtwainenv </cmt> <cmt> add containers property to webtwainenv </cmt> <cmt> define arguments for registerevent callback function </cmt>,add methods and properties to webtwainenv
1648,"<desc> since #2086 was well received, i thought i'd start us out. please review (in case my understanding of any changes was incorrect). and then of course we'll need to add whatever has changed regarding model#change, silent, etc. -- but that i'm less sure about. </desc> <cmt> updating contributing to reflect keeping index.html up to date with master </cmt> <cmt> removing view#make from docs </cmt> <cmt> updating model#validate docs </cmt>",edge change log in documentation
1649,"<desc> problem: u2f-api is being deprecated in chrome for feb 2022, so webauthn is needed for registration and verification of u2f devices. overall changes: refactored u2finterface to support newly created publickeycredentialrequestoptions thats being generated in the backend to support all devices whether it was registered with u2f-api or webauthn. in addition, fixed u2f device page to support new device interface structure and support deleting newly registered u2f devices </desc> <cmt> authentication with u2f and webauthn devices fully working </cmt> <cmt> device page, remove device and duplicate device detection working </cmt> <cmt> added webauthn_authentication_server to init fn </cmt> <cmt> removed comments </cmt> <cmt> fixed be test </cmt> <cmt> fixed tests once again </cmt> <cmt> removed fe to split pr </cmt>",support authentication with webauthn registered u2f devices - be
1650,<desc> updates to the script that generates tfrecords from the gldv2 dataset for delf training: capability to filter on the clean training dataset. generation of train and validation splits. converting to tfrecord the train clean and test datasets without train and validation splits generation. converting to tfrecord the train clean and test datasets with train and validation splits generation. </desc> <cmt> first version of working script to download the gldv2 dataset </cmt> <cmt> first version of the defl package installation script </cmt> <cmt> first working version of the delf package installation script </cmt> <cmt> fixed feedback from pr review </cmt> <cmt> push to github of changes to the tfrecord data generation script for delf. </cmt> <iss> [help wanted] delf (deep local features) </iss>,push to github of changes to the tfrecord generation of gldv2 dataset
1651,"<desc> adds glfw_focus_on_show window hint and attribute for issue #1189. this is a platform independent change which preserves behaviour for all applications written to the glfw api. i believe i have implemented all requirements as per ""contributing a feature"" guidelines. if changes are needed i'm happy to do them. i can also clean the commit timeline if needed. </desc> <cmt> add glfw_focus_on_show window hint and attribute for issue #1189 </cmt> <cmt> fixed tab -> space </cmt> <cmt> fixed tab -> space in windows test. </cmt> <cmt> added glfw_focus_on_show as a supported attributed for glfwsetwindowattrib </cmt> <cmt> updated documentation for glfw_focus_on_show </cmt> <cmt> updated readme and news for glfw_focus_on_show </cmt>",focus on show pr for #1189
1652,<desc> also add tests verifying these methods don't throw errors when called on unmounted components improves coverage by covering some branches that were missing! </desc> <cmt> ignore defer definition in coverage </cmt> <cmt> warn if forceupdate is called in constructor </cmt> <cmt> add tests verifying setstate and forceupdate don't error when called on an unmounted component </cmt> <cmt> warn if setstate or forceupdate are called on an unmounted component </cmt>,add debug warnings when calling setstate or forceupdate on an unmounted component
1653,"<desc> text apis: interface name change passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change interface revision, tests, (and when applicable, api doc) can we move it to mxnet.text asap? </desc> <cmt> revise text api names </cmt> <cmt> update </cmt>",interface re-design with name changes
1654,"<desc> these are only updated for easeljs and tweenjs which is part of the createjs suite. the soundjs and preloadjs definitions have not been updated (primarily because i don't use them). i could hold off on the pull request until they are done, but given my schedule i don't know when that will be, so i thought it would be a good idea to at least push these updates. tests were passing when run locally. </desc> <cmt> updated easeljs definitions to v0.7 and tweenjs definitions to v0.5 </cmt> <cmt> added comment on sprite to avoid intellij thinking it was deprecated </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixed missing return type </cmt>",upgrade easeljs definitions to 0.7 and tweenjs to 0.5
1655,<desc> systemctl show is built to be easily parsed by machine. systemctl status is built for human consumption only. use the show command from get_status_dict() when systemd is in use. closes #6341. </desc> <cmt> #6341: check systemd service status with show subcommand </cmt> <cmt> #6341: use shared function for parsing systemd status; check rc code </cmt> <iss> systemd service backend can fail to detect services not running </iss>,"use ''show'', not ''status'', for systemd service state"
1656,"<desc> support int64 (large tensor) for remaining random ops below 8 are supported random.exponential random.gamma random.generalized_negative_binomial random.multinomial random.negative_binomial random.normal random.poisson random.randn please feel free to remove inapplicable items for your pr. all changes have test coverage: code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change added 1 test case each currently nosetests tests/nightly/test_large_array.py results in 42 tests pass (4 fail - unrelated test ops- topk,sort,argsort,reduce) </desc> <cmt> random ops </cmt> <cmt> replace array with uniform </cmt> <cmt> remove dtype </cmt>",large tensor support for random ops
1657,<desc> reducing global usage and refactoring injection in the build system was challenging due to the number of mocks i have created. reduce this by switching to the fakeprocessmanager and reduce the scope of these tests to be unit tests only. also fixes catcherror in frontend_server spawning that caught too much (including a matcher exception) </desc> <cmt> [flutter_tools] remove mocks from dart_test file </cmt> <cmt> [flutter_tools] removing mocking for dart target integration testing </cmt>,remove mocking and simplify dart target tests
1658,"<desc> clean up a couple of members in csapply by passing the selectedoverload instead of individual parameters for things like the function ref kind, choice, and opened type. </desc> <cmt> [cs] stop passing functionrefkind in a couple of places </cmt> <cmt> we can retrieve it from the passed overloadchoice. </cmt> <cmt> [cs] change openedtype -> openedfulltype in a couple of cases </cmt> <cmt> this helps avoid confusion with selectedoverload's </cmt> <cmt> openedtype member. </cmt>",pass selectedoverload in a couple of places
1659,"<desc> in underscore 1.1.4, a test case below will fail: var o = function(str) { return str; }; var fasto = _.memoize(o); equals(o('tostring'), 'tostring', 'checks hasownproperty'); equals(fasto('tostring'), 'tostring', 'checks hasownproperty'); i have fix the bug by changing code ""key in memo"" to ""hasownproperty.call(memo, key)"". hope to merge^o^ </desc> <cmt> remove unused code and avoid variable redeclaration </cmt> <cmt> bug fix for _.memoize when key is derived from prototype </cmt>",bug fix for _.memoize and other little code change
1660,"<desc> currently, the tests for both dropdownbutton and dropdownbuttonformfield are in the same file. this has led to confusing ordering of test cases (ie. dropdownbuttonformfield test sandwiched between two dropdownbutton tests), making it difficult to determine if a test had already been written. this pr separates the tests into two files (dropdown_test.dart and dropdown_form_field_test.dart), renames some of the tests, and formats some of the code. there are no functional changes in this pr. related issues fixes #42483 i added the following tests: n/a before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> separate dropdownbuttonformfield and dropdownbutton test files </cmt> <cmt> dropdownformfield -> dropdownbuttonformfield </cmt> <iss> separate dropdownbuttonformfield tests from dropdown_test.dart </iss>",separate dropdownbutton and dropdownbuttonformfield tests
1661,<desc> add missing bits of documentation and reformat to break long lines and use proper sphinx markers. </desc> <cmt> doc: fixes for doc/source/user/basics.io.genfromtxt.rst. </cmt> <cmt> add missing part of usecols negative index explanation and other </cmt> <cmt> minor redaction fixes. </cmt> <cmt> maint: cleanup doc/source/user/basics.io.genfromtxt.rst. </cmt> <cmt> remove trailing whitespace. </cmt> <cmt> break long lines. </cmt> <cmt> fix some indentation. </cmt> <cmt> use the :: directive to indicate interactive examples. </cmt>,documentation fixes for basics.io.genfromtxt.rst and creation.py
1662,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> add type definitions for eins-modal </cmt> <cmt> added possible .modal() method to htmlelement </cmt>,add .modal() function to eins-modal
1663,"<desc> pretty self-explanatory. the implementation is straight-forward for regular environments, since it only adds logic that is not used in the built-in environments by default. a slightly tricky thing is in vector environments, where kwargs get passed both into reset_async and reset_wait, because the two different classes process them differently. as with any ""big"" change, this definitely needs some more eyes on it. this closes #2399 (at least to the extent that was agreed in the meantime), and subsumes #2511 for simplicity (easier to just include it here than deal with merge conflicts, or wait for synchronization between merges) </desc> <cmt> first find/replace, now tests </cmt> <cmt> fixes to the vector env </cmt> <cmt> make seed keyword only in wrappers </cmt> <iss> [proposal] custom arguments in step and reset methods </iss>",add options to the signature of env.reset
1664,"<desc> uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design /sig cloud-provider /area provider/azure /priority important-soon continue of kubernetes-sigs/cloud-provider-azure#247. this pr adds a new clientconfig and backoff retry for azure cloud provider: add a new clientconfig so that new azure clients could import it without unnecessary dependencies add backoff retry and implements autorest.senddecorator interface. the new backoff retry would be used in the following azure arm clients switch to new clientconfig in azure cloud provider so that the changes won't break existing codes part of kubernetes-sigs/cloud-provider-azure#247 does this pr introduce a user-facing change?: /assign @andyzhangx </desc> <cmt> move client config to a separate package </cmt> <cmt> add backoff retry which implements autorest.senddecorator interface </cmt>",add backoff retries and client config for azure cloud provider
1665,"<desc> i understand that: i'm submitting this pr for reference only. it shows an example of what i'd like to see changed but i understand that it will not be merged and i will not be listed as a contributor on this project. </desc> <cmt> replacing text on top banner </cmt> <cmt> changing modal cta to get started </cmt> <cmt> adding start modal as alternative and changing cta </cmt> <cmt> -changed cta to be more about the switch from 4.7 to the latest 5.8.1, rather than selling pro directly </cmt> <cmt> adding back original download modal </cmt> <cmt> updating copy </cmt> <cmt> adding period </cmt>",new banner and home cta
1666,"<desc> minor fixes related to my changes to the keyboard handling: capslock had the wrong vkey value (xbmc was seeing it as space) rogue oring with ckey::modifier_ralt meant the right alt wouldn't work as a modifier added a keyboard.xml entry to make backslash work on a french keyboard tidy up keyboard.xml to group the multimedia keys together and add mappings for all multimedia keys, some with null values to act as placeholders. i don't think any of this is controversial, but i thought i'd better give the team a chance to vet them. </desc> <cmt> vkey for capslock should be 0x14 not 0x20 </cmt> <cmt> the keyboard.xml mod attribute doesn't distinguish between left and right alt </cmt> <cmt> on a french keyboard backslash is alt gr 8. xbmc sees this as ctrl-alt-backslash. </cmt> <cmt> tidy up multimedia key mappings. add null mappings for unused multimedia keys as placeholders. </cmt>",minor keyboard related tweaks and fixes
1667,<desc> after recent commits both aclk implementations can be compiled in the agent. adds info into the docs on how to choose which one to use and how to verify which one is used component name docs read the docs and see if the info is understandable for our users. </desc> <cmt> add info for dual aclk into readme </cmt> <cmt> add info how to check </cmt>,updates the docu with info about dual aclk
1668,<desc> fixes #6827 before fix struct of struct pf d? a (foo)y cannot find format for struct foo cannot find format for struct foo undefned struct 'foo'. a : 0x00000000  = 0 y : array of struct pf d? a (foo)y // was same as struct of struct after fix pf d[2]? x (foo)y x : 0x00000000 = 0 y : struct<foo> a : 0x00000004 = 0 b : 0x00000008 = 0 struct<foo> a : 0x0000000c = 0 b : 0x00000010 = 0 added tests in r2r #1315 too . </desc> <cmt> refactor and move anal/types.c to util/ </cmt> <cmt> make struct of struct work with .ts and fix ts* </cmt> <cmt> array of struct works now with ts </cmt> <iss> types: array of structs not working </iss>,refactor types and make array of struct work with ts
1669,"<desc> frontenders at airbnb at have been discussing this change for a bit, and we've come to favor one-var-per-variable over one-var-only declarations. two things improve the maintainability of this style over one var for multiple variables: you never have a diff of a line that's removing a ; and inserting a ,. you can't accidentally declare global variables because you have a one-character mistake (semicolon instead of comma): var foo = 1, bar = 2; baz = 3; // added later and (accidentally) declared globally also, make a docstring comment example jsdoc/googleclosurecompiler compatible </desc> <cmt> switch from single var to one-var-per-variable </cmt> <cmt> frontenders at airbnb at have been discussing this change for a bit, and </cmt> <cmt> we've come to favor one-var-per-variable over one-var-only declarations. </cmt> <cmt> two things improve the maintainability of this style over one var for </cmt> <cmt> multiple variables: </cmt> <cmt> 1. you never have a diff of a line that's removing a ; and inserting </cmt> <cmt> a ,. </cmt> <cmt> 2. you can't accidentally declare global variables because you have a </cmt> <cmt> one-character mistake (semicolon instead of comma): </cmt> <cmt> javascript </cmt> <cmt> var foo = 1, </cmt> <cmt> bar = 2; </cmt> <cmt> baz = 3; // added later and (accidentally) declared globally </cmt> <cmt>  </cmt> <cmt> use jsdoc/closure compiler style type annotations </cmt>",switch to one-variable-per-var from many-variables-per-var
1670,<desc> fixes #53974 </desc> <cmt> move terminalprocess to run in renderer process </cmt> <cmt> part of #53974 </cmt> <cmt> don't build terminalprocess module </cmt> <cmt> tidy up terminalprocess </cmt> <cmt> fix most of process proxy </cmt> <iss> test if we can pull terminalprocess into the renderer process </iss>,move terminalprocess into the renderer process
1671,"<desc> there's a bug in the way we determine the selected package in plugins page. it was just checking if the selected package's name is part of the pathname. so if you select gatsby-source-shopify2 or gatsby-source-shopify-storefront, gatsby-source-shopify will also be highlighted (screenshot below) before this pr fixes this issue. this also works with scoped packages. after closes #10951 </desc> <cmt> use regexp to determine selected package </cmt> <cmt> update regex </cmt> <iss> plugin library shows two plugins selected </iss>",fix plugin search result selected style
1672,"<desc> this pr improves our handling of excessively large control flow graphs: if control flow analysis leads to a stack depth of 2500 recursive calls, we now issue an error and disable control flow analysis for the remainder of the containing function or module body. previously we'd simply overflow the call stack. the 2500 recursive call limit was experimentally determined. control flow patterns that cause recursion in the control flow analyzer (such as #11432) overflow the stack somewhere between 2500 and 5000 calls. no rwc tests are affected by this change. fixes #14314 in the sense that it doesn't overflow the stack. however, #14314 still takes >80s to compile. </desc> <cmt> disable control flow analysis in excessively large statement blocks </cmt> <cmt> add test </cmt>",error on excessively large control flow graphs
1673,"<desc> python based scrapers for movies and tv shows (using tmdb as the source). the xml based scrapers are only sort of supported, and there is a desire to move to python scrapers as default for matrix so we can remove the xml scrapers in version 20. the movie scraper has been in use for over a year and tested by members of the team and community. the tv show scraper is newer but based on code from the movie scraper and the tv maze scraper. it has been tested by team members on multiple platforms and community members from the forum. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document documentation for both scrapers already exists, so i don't think any additional documentation is needed. </desc> <cmt> add python tmdb movie scraper </cmt> <cmt> add python tmdb tv show scraper </cmt> <cmt> update addon installdata </cmt> <cmt> set python scrapers as default on new install </cmt>",python3 based movie and tv show scrapers
1674,"<desc> implements wait and retry logic on ray.connect() this takes care of the case where the server is not yet ready, but does not yet cover the case where the server drops mid-connection (still to come). first half of #13353 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [ray_client]: wait until connection ready </cmt> <cmt> change-id: ie443be60c33ab7d6da406b3dcaa57fbb7ba57dd6 </cmt> <cmt> lint </cmt> <cmt> change-id: i30f8e870bbd5f8859a9f11ae244e210f077cedd0 </cmt>",wait for ready and retry on ray.connect()
1675,"<desc> add dilate option for convolution / deconvolution, used for semantic segmentation. detail could be found in the following paper and their code. semantic image segmentation with deep convolutional nets and fully connected crfs. liang-chieh chen, george papandreou, iasonas kokkinos, kevin murphy, and alan l. yuille iclr 2015 </desc> <cmt> add dilate for convolution </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",add dilate option for convolution for semantic segmentation
1676,<desc> fix #8694 </desc> <cmt> test cpu float16 data transform </cmt> <cmt> add isnan etc </cmt> <cmt> small fix </cmt> <cmt> fix containsnan test error </cmt> <cmt> add data_type transform gpu test </cmt> <cmt> add float16 gpu example </cmt> <cmt> fix error </cmt> <cmt> fix gpu test error </cmt> <cmt> initial commit </cmt> <cmt> fix error </cmt> <cmt> small fix </cmt> <cmt> add more gemm fp16 tests </cmt> <cmt> fix error </cmt> <iss> add fp16 gemm support on gpu </iss>,add float16 gemm math function on gpu
1677,"<desc> restorev2() did not work because wildcard match had some issues. enabled rtti for windows as well. </desc> <cmt> if saver.restore(v2) for windows, directory walk did not work correctly </cmt> <cmt> rtti ifdef did disable rtti for windows </cmt> <cmt> with that we find now the files during restore. </cmt> <cmt> need to check for true (=1) instead of s_ok(=0) </cmt> <cmt>  </cmt>",make restorev2() work for windows
1678,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see </desc> <cmt> add support for checksum </cmt> <cmt> fix merge conflict </cmt>,add encoding support to object key
1679,<desc> pr allows custom securitycontext for stable/redmine. this pr does not change current behavior. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> option to customize securitycontext </cmt> <cmt> new line </cmt>,option to customize security context
1680,"<desc> there were still some mentions of ~[t] and ~t, mostly in comments and debugging statements. i tried to do my best to preserve meaning, but i might have gotten some wrong-- i'm happy to fix anything :) </desc> <cmt> update old uses of ~ in comments and debugging statements </cmt> <cmt> update debuginfo metadata to use box instead of ~ </cmt> <cmt> also remove comments that reference the unique_type_id heap_vec_box </cmt> <cmt> metadata, which was removed in 3e62637 and the unique_type_id gc_box </cmt> <cmt> metadata, which was removed in 8a91d33. </cmt> <cmt> update tests to not use old ~ syntax </cmt>",remove mentions of the old tilde owned pointer syntax
1681,<desc> looks something like this: </desc> <cmt> bring back bg. tighten things up. </cmt> <cmt> clean up group detail alerts </cmt> <cmt> soften hard edges </cmt> <cmt> group sidebar pass </cmt> <cmt> bring back old filter nav </cmt> <cmt> play with level indicator </cmt> <cmt> darken bg </cmt> <cmt> shrink subheader </cmt> <cmt> consistent group headers </cmt> <cmt> fix error labels in release streams </cmt> <cmt> collapse 30px margins </cmt> <cmt> clean up event list container </cmt>,add background color and text-based level labels
1682,"<desc> quick example of the issue: interface someinterface { optional?: string; const obj: someinterface = getsomeinterface(); const value = _.get(obj, 'optional', 'defaultvalue'); // ^ value should be of type string since we provided a default value, but it is string | undefined this pr updates lodash.get to exclude undefined when a default value is provided. to use exclude, we had to update typescript version to 2.8.  the file with the relevant change is types/lodash/common/object.d.ts add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update to version 2.8 and fix _.get </cmt> <cmt> fix typescript version header </cmt> <cmt> revert some changes made during find/replace </cmt> <cmt> one more change that wasn't supposed to be added. </cmt>",fix lodash.get to exclude undefined if a default value is provided
1683,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: solid/solid-auth-client@v2.3.1...v2.4.0 (and specifically this pr) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> update api for 2.4 release </cmt> <cmt> specifically, it added the stoptracksession() method. </cmt> <cmt> reflect that tracksession technically is async </cmt> <cmt> it's typically only used for the callback, but it _is_ an async </cmt> <cmt> function: </cmt> <cmt>  </cmt>",update solid-auth-client api for 2.4 release
1684,"<desc> the default kernel launch method doesn't use the dynamic openmp scheduling primitive, which suffers from workload balance problem when doing sparse matrix multiplication. this pr add launchdynamic method to the original kernel class. @zheng-da please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> dynamic omp for dot </cmt> <cmt> update heuristic </cmt> <cmt> add doc </cmt>",use dynamic omp schedule for sparse dot with large matrix
1685,"<desc> adds the option to allow hystrixruntimeexception to be thrown by hystrixcommandaspect. the new property raisehystrixexceptions is supported by both defaultproperties and hystrixcommand. e.g. @defaultproperties( ignoreexceptions = badrequestexception.class, raisehystrixexceptions = {hystrixexception.runtime_exception}) this pattern is extensible should people wish to add support for other hystrix exceptions. pr requested by @dmgcodevil </desc> <cmt> adding option to raise hystrixruntimeexception instead of cause </cmt> <cmt> adding raisehystrixexceptions to defaultproperties </cmt> <cmt> removing change to basicdefaultignoreexceptionstest </cmt>",add option to raise hystrixruntimeexception
1686,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. @karol-majewski @plantain-00 @rbuckton </desc> <cmt> update index.d.ts </cmt> <cmt> support es6. </cmt> <cmt> update memoize-one-tests.ts </cmt>",support es6 import for typescript definition
1687,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> changelog:  the ignoreownvisits option was added in a version < 5.0 but was not added to the types. then removed in 5.0.0 but added again in 5.0.1. use-ackee types of use-ackee uses the exported type serverdetails that got changed to string in v5 of ackee-tracker so i changed the types there as v2 now uses ackee-tracker v5 but didn't changed the api. </desc> <cmt> update ackee-tracker to v5 </cmt> <cmt> update tests </cmt>,update ackee-tracker to v5 and use-ackee to v2
1688,"<desc> this is a rebase of #6494, with one line (which @sdaftuar commented he forgot to remove) deleted. it also adds a commit to add the change to the bips document and the release notes. </desc> <cmt> allow block announcements with headers </cmt> <cmt> this replaces using inv messages to announce new blocks, when a peer requests </cmt> <cmt> (via the new ""sendheaders"" message) that blocks be announced with headers </cmt> <cmt> instead of inv's. </cmt> <cmt> since headers-first was introduced, peers send getheaders messages in response </cmt> <cmt> to an inv, which requires generating a block locator that is large compared to </cmt> <cmt> the size of the header being requested, and requires an extra round-trip before </cmt> <cmt> a reorg can be relayed.  save time by tracking headers that a peer is likely to </cmt> <cmt> know about, and send a headers chain that would connect to a peer's known </cmt> <cmt> headers, unless the chain would be too big, in which case we revert to sending </cmt> <cmt> an inv instead. </cmt> <cmt> based off of @sipa's commit to announce all blocks in a reorg via inv, </cmt> <cmt> which has been squashed into this commit. </cmt> <cmt> rebased-by: pieter wuille </cmt> <cmt> documentation updates for bip 130 </cmt>",direct headers announcement (rebase of #6494)
1689,<desc> 1.1-intro-to-programming-languages 1.2-github-basics 1.3-accessibility 2.1-data-types 2.2-functions-methods 2.3-making-decisions 2.4-arrays-loops </desc> <cmt> migrate 1.1-intro-to-programming-languages id quiz </cmt> <cmt> migrate 1.2-github-basics id quiz </cmt> <cmt> migrate 1.3-accessibility id quiz </cmt> <cmt> migrate 2.1-data-types id quiz to quiz-app </cmt> <cmt> migrate 2.2-functions-methods id quiz to quiz-app </cmt>,migrate existing quizzes indonesian translations to quizz-app
1690,"<desc> this pr removes the outdated herramientas de desarrollo section from contributing_es.md along with the following images, which aren't referenced anywhere anymore: docs/docs/images/open-remote-dev-tools.png docs/docs/images/remote-dev-settings.png docs/docs/images/running-redux-devtools.png closes: #7697 </desc> <cmt> translation: remove section herramientas de desarrollo </cmt> <cmt> refs: </cmt> <cmt> refs: </cmt> <cmt> images: remove open-remote-dev-tools </cmt> <cmt> refs: </cmt> <cmt> images: remove remote-dev-settings.png </cmt> <cmt> refs: </cmt> <cmt> images: remove running-redux-devtools.png </cmt> <cmt> refs: </cmt>",remove outdated section from contributing_es.md
1691,<desc> this is just @gazpachoking's pr #1729 in a mergable state and with the pr feedback that @lukasa left on it. </desc> <cmt> add a test case for request cookies persisting to session. refs #1728 </cmt> <cmt> store the request cookiejar in preparedrequest.cookies fix #1728 </cmt> <cmt> conflicts: </cmt> <cmt> requests/sessions.py </cmt> <cmt> address feedback from #1729 </cmt> <cmt> - make the preparedrequest's cookie jar an implementation detail </cmt>,fix 1728 (fixed up from #1729)
1692,"<desc> this pr has a variety of cleanup changes and fixes to help demonstrate advanced features of ios development like memory mapping and loading retrained models. it also includes some related changes that help shrink the binary footprint of the final executable on ios. </desc> <cmt> work in progress on memory-mapping example for ios </cmt> <cmt> reduce the size of ios binary, demonstrate mmap support </cmt> <cmt> fixed merge problems, cleaned up ios camera example </cmt>",improved ios camera example and binary footprint optimizations
1693,"<desc> this fixes some login and grammatical errors in serbian locales (sr, sr-cyrl) and their tests. two major problems were logic for getting grammatical cases. it was flawed because it didn't consider special cases for multi-digit numbers, just for single digit special cases. along with this, some grammar fixes were made because of different writing of nouns in different tenses (past and future) alongside those without tense (without prefix). here is some info about that on wiki. if that's not enough, i'll try to find something that has specific rules about that but i think it's better that other locale contributors look over this. the tests are adapted to check for new grammar and logic fixes. </desc> <cmt> fix serbian grammar and grammatical case logic </cmt> <cmt> this fixes the grammatical case logic which overlooked some special </cmt> <cmt> cases in serbain language. also this fixes some grammatical errors </cmt> <cmt> concerning cases in serbian language. </cmt> <cmt> update tests for serbian fix </cmt> <cmt> this updates the tests so they will test the new grammar. </cmt>","fix serbian locale (sr, sr-cyrl)"
1694,"<desc> this pull-request #539 should be taken into account to  understand the context about the debate of readonly properties in the scikit-learn api. this pull request is also related to issue #470 logisticregression and linearsvc should have read-write coef_ and intercept_ attributes (it does not fix it but makes it a less dangerous behavior). the following is an example session were the unsuspecting user might overlook a bug: >>> from sklearn.svm import svc >>> from sklearn.datasets import load_iris >>> iris = load_iris() >>> clf = svc(kernel='linear').fit(iris.data, iris.target) >>> clf.coef_ array([[-1.0443518 ,  0.01195155, -1.91966087, -0.81040704], >>> clf.coef_[0, 3] = 0 >>> clf.coef_ array([[-1.0443518 ,  0.01195155, -1.91966087, -0.81040704], </desc> <cmt> enh: mark coef_ as immutable for linear svm models trained in the dual </cmt> <cmt> immutable coef for the sparse svm variant too </cmt> <cmt> mark liblinear coef as immutable too </cmt>",explicitly mark the array returned by the linear svm readonly property coef_ as immutable
1695,"<desc> description:  this config seems let coveralls.io reports stable results: above screenshot has 3 build results with exactly same source code, the top and bottom has only one job in each build, but the middle one has multiple jobs, only one job reports code coverage. so you will see coveralls.io still gave us false negative result.   related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> create one tox env for code coverage report </cmt> <cmt> pytest-cov generated report in project root folder, not tox env folder. </cmt> <cmt> add cov tox env to travis </cmt> <cmt> coveralls seems expecting all build jobs upload </cmt> <cmt> only upload coverage after cov env success </cmt>",try to fix coveralls unstable result
1696,"<desc> this pr mainly contains two pars: add a common interface pyperfsampleprocessor that can be passed to pyperfutil to handle samples from the profiling. this way, users could use customized logic to log / aggregate / output the result samples. abstract current printing logic to a specific pyperfdefaultprinter that is used by the default cli main, and add parsing for enum values. </desc> <cmt> add common interface for pyperf sample handling </cmt> <cmt> better printing for enum values </cmt>",improve pyperf sample handling and output
1697,"<desc> this pr partially addresses xref #26807 in the case of pandas/tests/test_strings.py. it deletes that file and makes a new subpackage pandas/tests/strings/ with 8 new test modules plus a conftest file. i have only moved tests and flattened the structure by moving the tests from being methods to functions -  i haven't changed them in any other way. there are 1814 tests that were in pandas/tests/test_strings.py and are now in pandas/tests/strings/. i tried to keep each test module logically cohesive and less than 1000 lines long - test_strings.py still contains all the tests that don't really fit anywhere else. tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> tst gh26807 split out test_api </cmt> <cmt> tst gh26807 split out test_cat </cmt> <cmt> tst gh26807 split out test_find_replace </cmt> <cmt> tst gh26807 split out test_extract </cmt> <cmt> tst gh26807 split out test_split_partition </cmt> <cmt> tst gh26807 split out test_case_justify </cmt> <cmt> tst gh26807 split out test_string_array </cmt> <cmt> tst gh26807 move pytest fixtures to conftest </cmt>",tst gh26807 break up test_strings
1698,"<desc> this pull request is identical to #803 except that this time it's on the dev branch. problem 1 : when a timer is resumed manually (from code) after being game resumed (automatically from lost of focus), the way _pausedtotal is computed is no longer accurate since it uses the game pause time. problem 2 : if a timer is paused from code after the game has been game paused, it is not considered to be code paused. these problems have to occur if you want to have a pause screen and display it when the game is out of focus, so that, when the user comes back, he can resume manually. in this sequence, you have to code pause your timer when the game is automatically paused. then, the user has to close the pause screen for the timer to be resumed. </desc> <cmt> fixed a problem with the timer class wheere the total pause time would be incorrect after unpausing it twice in a row (game pause followed by code pause). </cmt> <cmt> fixed a problem with the timer class where a timer that is _codepaused after a game pause would not be considered to be _codepaused. </cmt>",fixed various problems with timer class
1699,"<desc> addresses d9a282f#commitcomment-13296796. @punya, if you could take a look, i'd appreciate it. </desc> <cmt> module -> namespace in 'leaflet'. </cmt> <cmt> tabs to spaces for consistency with .d.ts. </cmt> <cmt> added test for 'l.control.zoom' in 'leaflet'. </cmt> <cmt> namespaces are one honking great idea -- let's do more of those in 'leaflet'. </cmt>","add missing ""zoom option"" interface in definitions for 'leaflet'"
1700,"<desc> if requested, automatically download annotations and image files for the coco dataset, including the ""minival"" and ""valminusminival"" annotations provided by ross girshick on dropbox. tested with inspect_model.ipynb and on the command line with python coco.py evaluate --dataset=cocodataset --model=mask_rcnn_coco.h5 --download=true on a machine without the dataset. the latter populates the folder cocodataset with the correct image data and annotation files. </desc> <cmt> nake it easy to train and eval on ms-coco </cmt> <cmt> tested on win/ubu with notebook/cmd line </cmt> <cmt> pep8 compliant </cmt>","automatically download coco image files and annotations, if requested"
1701,<desc> a few examples use normal maps that have not been authored with the opengl normal map handedness convention. in these cases the normal scale y needs to be negated to get the normal maps to display correctly. a mention of normal map handedness is also added to documentation - otherwise it can be hard to find out that the handedness differences exist and how to handle them in three.js. related earlier discussion in issue #11315 </desc> <cmt> fix normal map handedness in a few examples </cmt> <cmt> a few examples use normal maps that have not been authored with the opengl normal map handedness convention. in these cases the normal scale y needs to be negated to get the normal maps to display correctly. </cmt> <cmt> document handling normal map handedness </cmt>,fix and document normal map handedness
1702,"<desc> i did correct some translation, and also i added link to let people visualize the code and test other attributes on it. i will edit this article when i prepare some new things in it, so it become more understandable. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> total change </cmt> <cmt> i changed the definition and the explanation, and make every possibilies of every logical type, and added some pictures of truth table to make the article and the sentences more understandable. </cmt> <cmt> total change </cmt> <cmt> article edited </cmt> <cmt> i did correct some translation, and also i added link to let people visualize the code and test other attributes on it. </cmt> <cmt> i will edit this article when i prepare some new things in it, so it become more understandable. </cmt>",added arabic translation to html/table article
1703,"<desc> refs #15791. this pr fixes some failing protocol module tests when networkservice is enabled. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> fix: always have head.headers available </cmt> <cmt> fix: use stringdatapipeproducer to write string </cmt> <cmt> it can handle large strings correctly. </cmt> <cmt> fix: override registernonnetworksubresourceurlloaderfactories </cmt> <cmt> fix: add dummy uninterceptprotocol implementation </cmt> <cmt> fix: jquery error handler can pass empty string </cmt> <cmt> for some errors jquery would pass empty string in the error handler, </cmt> <cmt> which makes tests pass when they should fail. </cmt> <cmt> chore: fix cpplint warnings </cmt> <cmt> fix: guard registernonnetworksubresourceurlloaderfactories call </cmt> <cmt> it may be called even when networkservice is not enabled. </cmt> <cmt> test: disable protocol.intercepthttpprotocol test </cmt>",migrate protocol module to networkservice (part 5)
1704,"<desc> fix confirmation on canceling an object in the menu_cancelobject.cpp so it cancels the right object. (it would be possible to start the menu from 1 instead of 0. but i suggest to keep it starting from 0 and keeping the active object on the status screen corresponding to the nummeration by t486 s[object].) further i suggest with this pull request to relocate the menu for cancel_objects to the main menu while printing directly below tune. fix and better useability of cancel_objects none so far. update: there is an further an unreportet issue with the nummeration of the menu items. objects above 9 dont show up as numbers.. it shows special digits (ascii hex 3a and so on).. </desc> <cmt> update cancel_object.cpp </cmt> <cmt> update g28.cpp </cmt> <cmt> revert ""update g28.cpp"" </cmt> <cmt> this reverts commit 7e6ed9fb9809326c6ebdc3604808b5fb2124b77c. </cmt> <cmt> revert ""update cancel_object.cpp"" </cmt> <cmt> this reverts commit 292ac9b45ec9b182e43224cb646573b00119d5f8. </cmt> <cmt> fix and move menu_cancelobject </cmt>",fix menu_cancelobject.cpp and move it below tune while busy
1705,"<desc> i was able to fix the warnings try transforming the colour argument to an array. it was intially a tuple the error was 'c' argument looks like a single numeric rgb or rgba sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  please use a 2-d array with a single row if you really want to specify the same rgb or rgba value for all points. before the change after the change the plotting still remains the same #widsml @adrinjalali </desc> <cmt> removing warnings </cmt> <cmt> restructuring comments </cmt> <cmt> removing warnings on plotting by using default colour arguments </cmt> <cmt> removing warnings on examples/neighbors/plot_nca_illustration.py </cmt>",fix warnings in examples/neighbors/plot_nca_illustration.py #14117
1706,"<desc> this isn't fully working, though not stopping the os from booting (the aps are in protected mode, but halted for now) for some reason we have what might be a paging issue. accessing the stack or any memory after lgdt/lidt triggers a page fault, which it for some reason can't handle, so it ends up triple-faulting here. interestingly, the cr2 register shows a fault address that is equal to &s_idt + 0x40, which happens to be idt entry #8 (double fault): gdt=     c01c9240 000007ff idt=     c01c9a40 000007ff cr0=e0000011 cr2=c01c9a80 cr3=00109000 cr4=00000060 same gdt/idt and cr3 as the bsp. also, both gdt and idt look fine in both qemu and bochs debugger. qemu's monitor info mem also shows correct mappings (they also look fine in bochs): 0000000000008000-0000000000009000 0000000000001000 -rw 0000000000100000-0000000000200000 0000000000100000 -rw 00000000c0000000-00000000c0118000 0000000000118000 -rw 00000000c0118000-00000000c01c7000 00000000000af000 -r- 00000000c01c7000-00000000c0800000 0000000000639000 -rw 00000000c0801000-00000000c0802000 0000000000001000 -rw 00000000c0803000-00000000c0804000 0000000000001000 -r- 00000000c0805000-00000000c0815000 0000000000010000 -rw 00000000ffe04000-00000000ffe05000 0000000000001000 -rw 00000000ffe08000-00000000ffe09000 0000000000001000 -rw qemu's monitor info tlb also has entries, but they look a little suspicious: 00000000c07fe000: 00000000007fe000 --------w 00000000c07ff000: 00000000007ff000 --------w 00000000c0801000: 80000000fee00000 x--da---w 00000000c0803000: 800000000ffe1000 x---a---- 00000000c0805000: 8000000000802000 x-------w 00000000c0806000: 8000000000803000 x-------w 00000000c0807000: 8000000000804000 x-------w 00000000c0808000: 8000000000805000 x-------w 00000000c0809000: 8000000000806000 x-------w 00000000c080a000: 8000000000807000 x-------w 00000000c080b000: 8000000000808000 x-------w 00000000c080c000: 8000000000809000 x-------w 00000000c080d000: 800000000080a000 x-------w 00000000c080e000: 800000000080b000 x-------w 00000000c080f000: 800000000080c000 x-------w 00000000c0810000: 800000000080d000 x-------w 00000000c0811000: 800000000080e000 x-------w 00000000c0812000: 800000000080f000 x-------w 00000000c0813000: 8000000000810000 x-------w 00000000c0814000: 8000000000811000 x-------w 00000000ffe04000: 000000000010b000 ---da---w 00000000ffe08000: 0000000000801000 ---da---w notice the phyiscal address bit 63 being set. bad tables? 9e5351a#diff-b10e477bf060d4b90924a2559b177384r320-r373 </desc> <cmt> kernel: add mechanism to identity map the lowest 2mb </cmt> <cmt> ak: add atomic free functions </cmt> <cmt> this allows for using atomic operations on any variables, </cmt> <cmt> not only those wrapped in ak::atomic<t> </cmt>",detect processors and boot them into protected mode
1707,"<desc> submit source support sharedb recently added the ability to send an op's source to the server in share/sharedb#426 this change adds the corresponding flag to doc, and updates the structure of the submitrequest. agent.custom agent.custom is normally just an empty anonymous object, which is meant to hold arbitrary information that consumers wish to store. typing this as record<string, unknown> is quite an aggressive typing, and essentially forces consumers to declare their own overriding type definition file, which is quite unusual for a type definition. this change moves us from record<string, unknown> to simply declaring it as any, because the type is completely consumer-defined. if consumers want stricter typing, they're free to: cast agent.custom extend the agent class declare their own type definition (as they are currently forced to do anyway) op and source typing the source may take any truthy value, so boolean is too we also remove internal references that assume ops are json0; documents may use any arbitrary type, including rich-text, for example remove websocket references sharedb can be run in a purely node.js environment, where it doesn't have access to dom types, such as websocket. in these cases, the typescript compilation errors. sharedb doesn't actually rely on a full websocket implementation, its required properties are listed here. internally, sharedb doesn't even use a websocket on server-side connections. it has a streamsocket, which implements the bare minimum. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> </desc> <cmt> [sharedb] add ""submit source"" support </cmt> <cmt> sharedb recently added the ability to send an op's source to the </cmt> <cmt> server in </cmt> <cmt> this change adds the corresponding flag to doc, and updates the </cmt> <cmt> structure of the submitrequest. </cmt> <cmt> [sharedb] make agent.custom less strict </cmt> <cmt> agent.custom is normally just an [empty anonymous object][1], which is </cmt> <cmt> meant to hold arbitrary information that consumers wish to store. </cmt> <cmt> typing this as record<string, unknown> is quite an aggressive typing, </cmt> <cmt> and essentially _forces_ consumers to declare their own overriding type </cmt> <cmt> definition file, which is quite unusual for a type definition. </cmt> <cmt> this change moves us from record<string, unknown> to simply declaring </cmt> <cmt> it as any, because the type is completely consumer-defined. </cmt> <cmt> if consumers want stricter typing, they're free to: </cmt> <cmt> - cast agent.custom </cmt> <cmt> - extend the agent class </cmt> <cmt> - declare their own type definition (as they are currently forced to do </cmt> <cmt> anyway) </cmt> <cmt> [1]: </cmt> <cmt> [sharedb] less strict op and source typing </cmt> <cmt> - the source may take [any truthy value][1], so boolean is too </cmt> <cmt> strict </cmt> <cmt> - we also remove internal references that assume ops are json0; </cmt> <cmt> documents may use any arbitrary type, including rich-text, for </cmt> <cmt> example </cmt> <cmt> [1]: </cmt>",less strict typings on ops and source
1708,"<desc> fixes #7189  (regression introduced with #7102) additionally ensured old function arn format, when no provisioned concurrency setup is involved, this should help partially solve issues for users of plugins which relied on old template format -> davidgf/serverless-plugin-canary-deployments#71 </desc> <cmt> refactor(aws lambda): ensure natural function reference when no alias </cmt> <cmt> test(aws lambda): improve coverage </cmt> <cmt> expose #7189 </cmt> <cmt> refactor(aws lambda): resolve deep value once </cmt> <cmt> refactor(aws lambda): do not deep merge when not necessary </cmt> <iss> breaking change introduced for custom authorizer lambdas </iss>",fix lamdba permissions setup when authorizer is involved
1709,"<desc> note to reviewers: this pr contains two commits. the first commit ( 4399765) shows what the world will look like once the migration is done. the second commit on top of that (0089896) is a temporary change that allows us to migrate customers over to the new world. once all customers are migrated, the second commit will be reverted. i recommend reviewing the commits separately. this pr reverses the dependency between the services and scheduler layer. prior to this pr, scheduler was depending on services. with this change it is the other way around: this allows the service layers to schedule tasks via the scheduler layer. this work is in preparation of #6827: it will allow us to implement the state restoration manager in the service layer (the restoration manage needs access to the task scheduling api of the scheduling layer). breaking change: this change is expected to only break people that have custom bindings (rare). in those custom bindings, the order of schedulerbinding and servicesbinding will have to be switched around. related issues pre-work for #6827. supersedes #54211, #54202, and  #54151. i added the following tests: modified existing tests to reflect the new dependency chain. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: flutter/website#3918 </desc> <cmt> wip </cmt> <cmt> wip2 </cmt>",reverse dependency between services and scheduler
1710,"<desc> this pr just documents the update process, tries to remove godot-made changes in upstream sources (need testing on msvc!) and gets rid of some unnecessary files. the changes were based on the same 1.0.2h version as before. the last commit then updates to 1.0.2l. </desc> <cmt> openssl: document update process and delete unused files </cmt> <cmt> openssl: sync with pristine upstream 1.0.2h </cmt> <cmt> our necessary custom changes will be reapplied in later commits for clarity, </cmt> <cmt> and saved as patches for future updates. </cmt>",cleanup and document update process from upstream sources + 1.0.2l
1711,"<desc> fix path::split, path::isabsolute, path::getparent, and getcanonicalpath on windows. fixes #13 fixes #14 some edge-case windows pathing may still not work: ""drive relative"" paths: ""c:tmp.txt"" unc paths (network paths): ""\foo\bar"" (will be collapsed to \foo\bar, which may resolve to a different location than expected) ""absolute paths"": ""\foo\bar"" (may or may not resolve to drive root) </desc> <cmt> fix getcanonicalpath on windows </cmt> <cmt> fix isabsolutepath on windows </cmt> <cmt> add split test </cmt> <cmt> add concatenation tests </cmt> <cmt> handle splits correctly with disk designations </cmt> <iss> the win32 implementation of getcanonicalpath doesn't work the same as the base implementation </iss> <iss> path::isabsolute() doesn't work for win32 paths </iss>",fix pathing issues on windows
1712,"<desc> this pr is intended to allow creation or modification of a metric alert rule - including it's triggers, and their actions - all in one call. it does this by introducing a new serializer, unifiedalertruleserializer that adds the triggers fields. it also adds the actions field to the alertruletriggerserializer.   the id field has also been added to triggers and actions so that the fe can send them back for the put requests. unifiedalertruleserializer implements update, create, and validate functions. we also now serialize the actions externally in the alertruletriggerserializer, so that the fe has this data available to show on the listing index page and it is also returned in the unified create/edit calls. it adds backend constraints on the relationships between triggers and their threshold types and values in the validate function. i believe billy will be implementing these constraints on the fe. tests included that send various valid and invalid payloads to the api. they also include a few tests that update a trigger's type and a trigger's threshold value. </desc> <cmt> just switching branches </cmt> <cmt> first draft of unified creation api </cmt>",unified metric rule api - post & put
1713,"<desc> second attempt of #17132, which was reverted due to failure bundling for mac & windows runs the ""yarn install"" from the root of the packages to de-duplicate node requires via hoisting. reduces the overall bundle size by a considerable margin ~80mb, and the compressed app by ~30mb. main changes: moved install path to path.join(os.tmpdir(), 'cypress-build', platform) with a symlink to build in the root for convenience (per @brian-mann request) loosen semver ranges from pinned to ^ for better deduplication of dependencies copy yarn.lock from the root before yarn --production to ensure we are building with the same dependencies we have in the lockfile for develop/testing (allows us to use the ^ rather than pinned versions with more confidence) removes additional unused directories or files demo / test that are taking up space, primarily in image libraries smaller bundle faster install time before: after: </desc> <cmt> refactor: loosen semver ranges for deps </cmt> <cmt> refactor: rename binary script files js -> ts </cmt> <cmt> refactor: update binary script files to be more procedural </cmt> <cmt> refactor: additional script cleanups </cmt> <cmt> yarn lock </cmt>",use hoisted yarn install in binary build
1714,"<desc> change for request #3384 added support for aarch64 updated to debian stretch (nodejs wasn't in the jessie release on aarch64, and it's been stable for 6+ months now, probably time to update and keep them all in sync anyway) </desc> <cmt> update to debian stretch for docker containers </cmt> <cmt> add aarch64/arm64 build </cmt>",aarch64/arm64 support for docker builds
1715,"<desc> fixes an unintended breaking change introduced by #55792, which introduced an output-dir option. if arb-dir is a custom value, existing users of the gen_l10n tool would realize that their output-dir defaults to lib/l10n instead of the input directory. this behavior is a breaking change and likely undesired by most users. this pr introduced a fix to make sure that the output-dir is always the input-dir by default. i added the following tests: a test to ensure that the gen_l10n tool defaults to using the input directory as the output directory if unspecified. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> fix breaking change introduced by gen_l10n output-dir option </cmt> <cmt> fix typo </cmt>",fix unintended breaking change introduced by output-dir option
1716,"<desc> closes #22875 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this is a resubmit of a previous pr i submitted that was approved (#22916). i tried to close and reopen to get a rebuild on travis but i couldn't reopen it because i had deleted my old fork (after accidentally pushing to master). </desc> <cmt> cln gh22785 replace bare excepts by explicit excepts in pandas/io/ </cmt> <cmt> cln gh22875 modify previous commit so flake8 passes </cmt> <cmt> cln gh22875 fix pandas/io/packers.py </cmt> <cmt> cln gh22875 fix other except in pandas/io/packers.py </cmt> <cmt> cln gh22875 incorporated feedback from tests </cmt> <cmt> cln gh22875 delete unnecessary comments and incorporate test feedback </cmt> <iss> replace bare excepts by explicit excepts in pandas/io/ </iss>",cln gh22875 replace bare excepts by explicit excepts in pandas/io/
1717,"<desc> reopening pr with cleaned up style </desc> <cmt> add a bottom affixed element to affix visual tests. </cmt> <cmt> refactor determining affix state into a separate expanded method </cmt> <cmt> in order to handle multiple edge cases, specifically when the document </cmt> <cmt> height is dynamic. </cmt> <cmt> always reposition an affix that is affixed to the bottom. </cmt> <cmt> fix issue where bottom affixed element floats over the footer when the </cmt> <cmt> document height is smaller than the viewport height. </cmt> <cmt> cleanup style </cmt>",charlesbjohnson affix bottom when dynamic height
1718,<desc> in this pr i extend the operator pad for 16x8 quantization mode. this operator is present in mobilenet v1/v2 from keras.applications. </desc> <cmt> added missing operators 16x8 pad operators needed for keras mobilenet v1/v2. </cmt> <cmt> excluded new tests for int16 from tests for acceleration. </cmt>,16x8 reference kernel for pad operator
1719,"<desc> original pull-request #13341 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix moving sum segfault </cmt> <cmt> fix moving sum segfault </cmt>",cherry pick #13341 to 20.5: fix moving sum segfault
1720,"<desc> backbone-relational exports a store class. it also exports a default instance of this class, called store (note the lowercase s), but the latter was missing in the typings. so i added it. the tests that were intended to test for the store export, revealed that store.unregister was typed incorrectly. i fixed that as well. fixing that, i ran into an unwarranted linter error. types/backbone/index.d.ts exports model and collection<tmodel>, where tmodel defaults to model. types/backbone-relational/index.d.ts imports these classes as bmodel and collection, respectively, and defines a model class of its own that extends bmodel. this confused the use-default-type-parameter linter rule when encountering collection<model> on line 166. i disabled the rule on that line. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). this is nowadays automatically included with the tests.  #32883  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. not applicable. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add tests for backbone-relational's exported store instance </cmt> <cmt> add the missing store export to backbone-relational </cmt> <cmt> fix the typing of store.unregister in backbone-relational </cmt> <cmt> disable use-default-type-parameter linter rule in backbone-relational </cmt> <cmt> the linter gives an unwarranted error: it complains that model is the </cmt> <cmt> default type parameter of collection on line 165, column 41 of the </cmt> <cmt> index.d.ts. while it is true that the default parameter is called </cmt> <cmt> model, the type in question has been renamed to bmodel in the current </cmt> <cmt> module. </cmt> <cmt> disable the linter rule in the correct way (see b1deb1c2) </cmt>",add the missing store instance to backbone-relational
1721,"<desc> we want to be able to emit witness_method calls on concrete types and class-constrained archetypes. sil part of #15735. </desc> <cmt> sil: tweak sil verifier condition for witness_method conformance </cmt> <cmt> - existential type cannot appear here at all, don't handle it explicitly </cmt> <cmt> - archetypes can have concrete conformances via their superclass </cmt> <cmt> silgen: use a concrete conformance if we have a witness_method call on a concrete type </cmt>","preliminary ""opaque conformance"" support in sil"
1722,<desc> this does a fair amount of fun to create a common keymap that works across a variety of keyboards! since it has some larger-scale changes (i.e. renaming a layout to a better name) submitting a pr now before i work on 40% support. </desc> <cmt> add userspace to talljoe layout. </cmt> <cmt> move more authority to userspace and create bananasplit layout. </cmt> <cmt> move more things into userspace. </cmt> <cmt> common core example </cmt> <cmt> more work on common layout. </cmt> <cmt> num layer. </cmt> <cmt> talljoe-ansi layout </cmt> <cmt> updates for zeal60 </cmt> <cmt> add zeal60 to 60_ansi_split_bs_rshift </cmt> <cmt> swap escape and grave </cmt> <cmt> num-layer tweaks </cmt> <cmt> more tweaks. </cmt> <cmt> add 1up60rgb to world of layouts. </cmt> <cmt> rename ansi_split_bs_rshift layout to hhkb. </cmt> <cmt> control rgb backlight. </cmt> <cmt> change capslock led </cmt>,talljoe's layout with common keymap.
1723,<desc> no longer preventing default behaviour due to relation of 'touchstart' and 'click' events alter implementation of stopping bubbling add demo of event bubbling </desc> <cmt> * [html5] fix bubbling and <a> component </cmt> <cmt> * [html5] add demo for event bubbling </cmt>,html5 bugfix stop events bubbling
1724,"<desc> closes #26513, related to #28380 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this pr basically deals with three issue: implement keyword aggregation for dataframe.agg implement keyword aggregation for series.agg </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> implement agg for dataframe </cmt> <iss> allow keyword aggregation in dataframe.agg and series.agg </iss>",implement keyword aggregation for dataframe.agg and series.agg
1725,"<desc> this change brings basic support for timeouts to the futex system call when invoked with the futex_wait option. it's currently implemented by taking advantage of the timer queue to wake the thread on timeout. with that implemented libpthread needed to be fixed to actually pass the option through. a test case was added to very the feature works. </desc> <cmt> ak: add timeval_to_timespec and timespec_to_timeval conversion methods </cmt> <cmt> add the ability to easily convert between timeval and timespec. </cmt> <cmt> kernel: refactor timequeue::add_timer to use timeval </cmt> <cmt> the current api of add_timer makes it hard to use as </cmt> <cmt> you are forced to do a bunch of time arithmetic at the </cmt> <cmt> caller. ideally we would have overloads for common time </cmt> <cmt> types like timespec or timeval to keep the api as straight </cmt> <cmt> forward as possible. this change moves us in that direction. </cmt> <cmt> while i'm here, we should really also use the machines actual </cmt> <cmt> ticks per second, instead of the optimal_ticks_per_second_rate. </cmt>",plumb futex wait timeout support throughout.
1726,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: 23611 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> d3-geo strictnullchecks mode: </cmt> <cmt> allow geogeometryobjects type to be null </cmt> <cmt> check existence of optional mehtods before calling them </cmt> <cmt> added null to union type or some results of call </cmt> <cmt> missing space </cmt>",d3 geo strict null check
1727,"<desc> abstract introduces a new option --fragment-retries for retrying fragments in fragment based downloaders (yet dash segments only) with default value of 10 retry attemps. rationale youtube may often return 404 http error for a fragment in dash segments downloader causing the whole download to fail. however if the same fragment is immediately retried with the same request data this usually succeeds (1-2 attemps is usually enough for success) thus allowing to download the whole file successfully. so, we will retry all fragments that fail with 404 http error for now. example urls example videos i've been able to reproduce failing fragments with: rtwddp2uiu0 imiqwgpbquq. videos uploaded to youtube in a last hour are also very likely to be dash segments with failing fragments. demo here is how it looks in action: > py26yt -v  deleting original file test online game. bigdaimon vs _shepherd-imiqwgpbquq.f160.mp4 (pass -k to keep) deleting original file test online game. bigdaimon vs _shepherd-imiqwgpbquq.f140.m4a (pass -k to keep) further improvements this can be adopted for other fragment based downloaders if necessary. </desc> <cmt> [options] add --fragment-retries option </cmt> <cmt> [downloader/fragment] add report_retry_fragment </cmt> <cmt> [downloader/dash] add fragment retry capability </cmt> <cmt> youtube may often return 404 http error for a fragment causing the </cmt> <cmt> whole download to fail. however if the same fragment is immediately </cmt> <cmt> retried with the same request data this usually succeeds (1-2 attemps </cmt> <cmt> is usually enough) thus allowing to download the whole file successfully. </cmt> <cmt> so, we will retry all fragments that fail with 404 http error for now. </cmt> <cmt> [downloader/{common,fragment}] fix total retries reporting on python 2.6 </cmt> <cmt> [downloader/fragment] document fragment_retries </cmt>",add --fragment-retries option (fixes #8466)
1728,<desc> this ensures spr pages with a . in the name end with .html instead of treating it as a custom extension </desc> <cmt> make sure to handle paths with dot in name for spr </cmt>,fix spr handling with dot in name
1729,"<desc> fixes #19677, which is a regression in how onehotencoder and ordinalencoder handle categories having dtype='s'. changed the dtype.kind checks from 'ou' to 'ous' and updated the test. to facilitate the test, also added a dtype arg to _convert_container. examples: >>> _convert_container([['a'], ['b']], ""list"", dtype='s') >>> _convert_container([[1], [2]], ""list"", dtype=np.float32) </desc> <cmt> fix 19677: specify categories with dtype='s' </cmt> <cmt> - add dtype='s' cases to test_encoders_string_categories </cmt> <cmt> - add dtype arg to _convert_container to force dtype when applicable </cmt> <cmt> - _convert_container to list now converts container [[1], [2]] to requested dtype (e.g., [[1.], [2.]]) </cmt> <cmt> flake8 compat </cmt> <iss> onehot/ordinalencoder categories broken for dtype='s' </iss>",fix encoder should accept categories having dtype='s'
1730,"<desc> it is a concise course on react native. i was recommended this by the community devs. no sign in required, direct access. it is a course. read our contributing guidelines </desc> <cmt> add ""data structures and algorithms specialization"" link </cmt> <cmt> update free-courses-en.md </cmt> <cmt> update free-courses-en.md </cmt> <cmt> update free-courses-en.md </cmt>","add- ""introduction to react native"" course"
1731,<desc> adds a banner to the top of the page when a user is not on the latest release documentation. partially addresses #58346 docs.ansible.com </desc> <cmt> add banner to versions that are not latest </cmt> <cmt> move div into script </cmt> <cmt> fix div </cmt> <cmt> move comment </cmt>,add a banner message to warn when not on latest documentation
1732,<desc> this pr fixes #6479 and fix also the ner example that was not working anymore since few weeks. </desc> <cmt> align tf ner example over the pt one </cmt> <cmt> fix dataset call </cmt> <cmt> fix gradient accumulation training </cmt> <cmt> apply style </cmt> <iss> [tftrainer] gradient accumulation error </iss>,fix the tf trainer gradient accumulation and the tf ner example
1733,"<desc> a fix for #21103 </desc> <cmt> homectl: if homed asks for the recovery key to be supplied, query the user for it </cmt> <cmt> fixes: #21103 </cmt> <cmt> pam_systemd_home: prompt user for recovery key if homed asks for it </cmt> <cmt> for accoutns that have no passwords but only a recovery key homed might </cmt> <cmt> ask explicitly for that. honour the request and ask the user for it. </cmt> <iss> `homectl passwd` fails when used on an account with recovery key set </iss>",handle password changing for accounts that have recovery keys correctly
1734,"<desc> throw errors if users don't pass in the correct type of argument to the plugin instead of leaving them in the dark. for occurenceorderplugin, passing in no arguments should still work just in case there are people currently using it without arguments. </desc> <cmt> add argument error handling in optimization plugins </cmt> <cmt> remove undefined check for minchunksizeplugin </cmt>",add argument error handling for optimization plugins
1735,<desc> the cloudbees build/release config has been upgraded to assuming nebula rxjava plugin 2.x which assumes gradle 2. this is an attempt to upgrade this project. see #117 </desc> <cmt> upgrade to nebula 2.x and gradle-rxjava-project-plugin 2.x </cmt> <cmt> disable sample-app </cmt> <cmt> it doesn't work with gradle 2 </cmt>,upgrade nebula plugin and gradle
1736,"<desc> this pr implements changes proposed in kip-495. this change will introduce an /admin/loggers endpoint to the connect worker that can be used to get/modify the log levels of any named logger in the connect worker. the following new configs are introduced: admin.listeners to control where the admin endpoint will be made available. the default value should bring the /admin endpoint along with the existing endpoints. setting it to empty disables the /admin endpoint altogether. any other host:port string create that listener and only bring the admin endpoints on it. the admin.listeners.https. prefix is used to find ssl props for any https endpoints. multiple tests are added to verify adding admin endpoints with various listeners, and to check if the rest endpoints behave as intended. </desc> <cmt> kafka-7772: initial commit </cmt> <cmt> kafka-7772: start admin context only if admin endpoints are on different listeners </cmt> <cmt> kafka-7772: implementation of the logging resource </cmt> <cmt> kafka-7772: add /admin prefix to resource </cmt> <cmt> kafka-7772: add integration tests for loggerresource </cmt> <cmt> kafka-7772: rename and clean up adminurl method in restserver </cmt>",dynamically adjust log levels in connect
1737,"<desc> we had a few different mechanisms for lazy deserialization in the ast. start folding them together into one mechanism, pack some ast nodes better, and eliminate some dead code. should all be nfc </desc> <cmt> [ast] optimize lazy-member storage for nominal type and extension declarations. </cmt> <cmt> save two pointers of storage in iterabledeclcontext (a base class of </cmt> <cmt> nominal type and extension declarations) by storing the lazy member </cmt> <cmt> loader + context data in an astcontext side table. it also makes it </cmt> <cmt> easier to add more lazy context information later on. </cmt> <cmt> [ast] remove lazyloaderarray; it's all dead code. </cmt> <cmt> [ast] fold lazy conformance loading into the lazyiterabledeclcontextdata. </cmt> <cmt> this standardizes on just one side-lookup table for storing </cmt> <cmt> information about lazy deserialization of nominal type and extension </cmt> <cmt> declarations. nfc </cmt>",some cleanups in lazy deserialization
1738,"<desc> i recently renamed editor::setsoftwrap and ::getsoftwrap to ::setsoftwrapped and ::issoftwrapped. i also renamed the config setting and command to match, but we've decided that wasn't a good idea. this pr renames the config setting back to editor.softwrap and the command back to editor:toggle-soft-wrap. fixes #3531 </desc> <cmt> rename editor.softwrapped config option back to editor.softwrap </cmt> <cmt> rename editor:toggle-soft-wrapped back to editor:toggle-soft-wrap </cmt> <iss> soft wrap doesn't work at all </iss>",rename soft-wrapped back to soft-wrap
1739,"<desc> i ran the current the current rails guides site against lighthouse & one of the things it suggested was to add a valid robots.txt file. when i inspected the current robots.txt, it's 404'ing. so i added one copying the html5 boilerplate example. to test this locally i ran rake guides:generate & inspected the output folder. i did look into adding a sitemap also, but i think i'll save that for another pr :) </desc> <cmt> adding a robots.txt to the guide </cmt> <cmt> just adding an allow all robots.txt file </cmt>",adding robots.txt to guide as lighthouse is warning about it
1740,<desc> adds press prop types creates constants for default delay ms fixes a mouse pointer check for safari (no pointer events) ref #15257 </desc> <cmt> add pressprops type to event module </cmt> <cmt> move default press event delays to constants </cmt> <cmt> fix right-click press check for safari </cmt>,add press event prop types and fix a check in safari
1741,"<desc> fixes #6311. this is an alternative approach to #6328. offline discussions have determined that there was not enough review around the idea of type predicates on accessors and properties. this moves them back to signatures, keeps this-based predicates, and continues to infer from type predicates. @mhegazy </desc> <cmt> add test </cmt> <cmt> move type predicates back onto signatures, remove narrowing for property/get type guards. </cmt> <cmt> error on nodes which should not have type predicates. </cmt> <cmt> minor rename. </cmt> <cmt> use names of accessors instead of their entire spans. </cmt> <cmt> added tests. </cmt> <cmt> actually, it makes more sense to error on the predicate annotation than anything else. </cmt> <cmt> removed trailing whitespace for linter. </cmt> <cmt> fixed up fourslash tests to only test functions. </cmt> <cmt> accepted baselines. </cmt>","remove notion of predicates as types, move predicates back to signatures"
1742,"<desc> adds monitor selection, basic properties and a fix to enum_monitors to win-capture plugin </desc> <cmt> use of text macros instead of direct obs_module_text calls </cmt> <cmt> fix for enum_monitors </cmt> <cmt> function enum_monitors would always stop after first found monitor due to wrong return value. </cmt> <cmt> add monitor selection and basic properties </cmt>",add monitor selection and properties to monitor capture (win)
1743,"<desc> closes #17383 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry test case refactoring: moved the existing  index-as-string test cases out of test_groupby.py and into a new test_index_as_string.py file extracted test data generation functions and parameterized existing test cases to clean them up and shorten them. added a new parameterized test case on a series updated test_grouper_column_index_level_precedence to reproduce false warning problem as described in #17383 updated test_grouper_column_index_level_precedence to verify when warnings should not be raised (results in a test failure due to #17383 without this fix) </desc> <cmt> refactor groupby tests for using strings to reference index levels </cmt> <cmt> - extract to separate file (test_index_as_string.py) </cmt> <cmt> - parameterize over test dataframes </cmt> <cmt> - add series test case </cmt> <cmt> - update test_grouper_column_index_level_precedence to reproduce false warning problem as described in gh17383 </cmt> <cmt> - update test_grouper_column_index_level_precedence to verify when warning shouldn't be raised (results in test failure due to gh17383) </cmt> <cmt> fix for gh17383 </cmt> <cmt> added whatsnew entry </cmt> <iss> groupby with matching column and index name emits spurious warning </iss>",refactor index-as-string groupby tests and fix spurious warning (bug 17383)
1744,"<desc> deprecations? spec compliancy? tests added/pass? fixed tickets doc pr breaking changes: this deletes the 'options' export from babel-core. babel options that expect arrays must be arrays, where before strings would be split on commas and single values would be converted to arrays. the cli still supports comma-strings however. hopefully will effect relatively few people. the primary goal of this pr is to get rid of our config.js file that listed options in favor of defaults + validation inside the option manager. the primary user-visible change is the required array inputs. </desc> <cmt> get rid of circular dependencies in babel cli script. </cmt> <cmt> move babel config descriptions to babel-cli. </cmt> <cmt> move option parsing to babel-cli. </cmt> <cmt> remove config.js file in favor of config code. </cmt>",more strictly parse configs and explicitly handle arguments in babel-cli
1745,<desc> i hereby agree to the terms of the cla available at:  mergetree full support for disks3 detailed description / documentation draft: all i/o operations in mergetree are reworked using idisk. mergetree works with s3 as the main storage. merges and mutations work as well. disks3 can be used in storage policy as cold or primary storage. background processing pool settings are now configurable. </desc> <cmt> imergedatapart full s3 support. </cmt> <cmt> mergetreedata full s3 support. </cmt> <cmt> compilation fixes. </cmt> <cmt> mutations and merges s3 support. </cmt> <cmt> fixed removing data part. </cmt> <cmt> mergetree for s3 integration tests and fixes. </cmt> <cmt> code style issues. </cmt> <cmt> enable aws logging. </cmt> <cmt> # conflicts: </cmt> <cmt> #	dbms/src/storages/mergetree/mergetreedata.cpp </cmt>,mergetree full support for s3
1746,"<desc> please refer to the individual commit messages for additional details. </desc> <cmt> replace some instances of implicit function.bind(this) usage, in src/display/api.js, with arrow functions instead </cmt> <cmt> reduce the amount of unnecessary function calls and object allocations, in messagehandler, when using streams </cmt> <cmt> with pr 11069 we're now using streams for operatorlist parsing (in addition to just textcontent parsing), which brings the nice benefit of being able to easily abort parsing on the worker-thread thus saving resources. </cmt> <cmt> however, since we're now creating many more readablestream there appears to be a tiny bit more overhead because of it (giving ~1% slower runtime of browsertest on the bots). in this case we're just going to have to accept such a small regression, since the benefits of using streams clearly outweighs it. </cmt> <cmt> what we *can* do here, is to try and make the streams part of the messagehandler implementation slightly more efficient by e.g. removing unnecessary function calls (which has been helpful in other parts of the code-base). to that end, this patch makes the following changes: </cmt> <cmt> - actually support transfers in messagehandler.sendwithstream, since the parameter was being ignored. </cmt> <cmt> - inline the sendstreamrequest/sendstreamresponse helper functions at their respective call-sites. obviously this causes some amount of code duplication, however i still think this change seems reasonable since for each call-site: </cmt> <cmt> - it avoids making one unnecessary function call. </cmt> <cmt> - it avoids allocating one temporary object. </cmt> <cmt> - it avoids sending, and thus structure clone, various undefined object properties. </cmt> <cmt> - inline objects in the messagehandler.{send, sendwithpromise} methods. </cmt> <cmt> - finally, directly call comobj.postmessage in various methods when transfers are *not* present, rather than calling messagehandler.postmessage, to further reduce the amount of function calls. </cmt> <cmt> change the internal stream property, as sent when streams are used, from a string to a number </cmt> <cmt> given that the stream property is an internal implementation detail, changing its type shouldn't be a problem. by using numbers instead, we can avoid unnecessary string allocations when creating/processing streams. </cmt>",various messagehandler improvements when using streams
1747,"<desc> what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) for issue #5324 , i have added some ts declarations generatorapi, promptmoduleapi in @vue/cli pluginapi in @vue/cli-service test utilities function declaration in @vue/cli-test-utils i added test for these declarations. also i linted the code by dtslint with some necessary rules according to the readme of definitelytyped . test by npx tsc -p packages/@vue/cli/types/tsconfig.json known issue it seems there are some problem in webpack's declaration. so ""skiplibcheck"": true should be set in tsconfig.json when use pluginapi in .ts. by the way, i formated and linted the codes whithout adding config file (like tslint.json, .prettierrc) to vue-cli repo. besides, vscode may report error for *.d.ts caused by eslint parser of cli repo.  i believe i should avoid adding extra config files/codes or changing eslintignore.  core maintaner do this will be better, if necessary. add i used yarn link to verify the declarations of @vue/cli, @vue/cli-service, @vue/cli-test-utils in my own plugin repo. vscode can finish code completion even in .js file according declaration of @vue/cli-test-utils pluginapi and generatorapi can be used in .ts file  normally i hope this pr will be helpful. appendix for @vue/cli-test-utils,i  added declaration to cli-test-utils folder directly, like createtestproject.d.ts we can organize the file structure  better, but it may cause break change. or there is good way i overlooked. </desc> <cmt> feat(cli-service): add declaration for pluginapi </cmt> <cmt> fix #5324 </cmt> <cmt> feat(cli): add declaration for generatorapi,promptmoduleapi </cmt> <cmt> fix #5324 </cmt> <cmt> feat(cli-test-utils): add declaration for test utilities </cmt> <cmt> fix #5324 </cmt>","feat(cli,cli-service,cli-test-utils): add ts declaration"
1748,"<desc> / #48187 </desc> <cmt> updating dockerfile.rocm to use rocm 4.1 </cmt> <cmt> updating ci scripts to use rocm 4.1 </cmt> <cmt> switching rocm tf to use the new hipfft library (instead of rocfft). </cmt> <cmt> for rocm 4.0 and prior, hipfft was a header-only ""library"" that was shipped along with the rocfft library. rocm tf code uses the hipfft apis defined in the ""hipfft.h"" header file, which was part of the package for rocfft library. rocm tf would dynamically load the ""rocfft"" library at runtime. </cmt> <cmt> from rocm 4.1 onwards, it seems hipfft is a separate library from rocfft, and rocm tf needs to use the ""hipfft"" library insteaf of the ""rocfft"" library. specifcally, rocm tf needs to </cmt> <cmt> * pick up the ""hipfft.h"" header from the hipfft install area (instead of the rocfft install area). </cmt> <cmt> * dynamically load the the ""hipfft"" library instead of the ""rocfft"" library </cmt> <cmt> this commit has the two above changes </cmt> <cmt> this change is required because without this change, the unit-tests that called the hipfft api ( hipfftsetworkarea ) were failing when run with rocm 4.1 (and without the changes in this commit). </cmt> <cmt> rocm tf continues to build (with rocm 4.1) without the changes in this commit, because the old ""hipfft.h"" file in the rocfft install area is still present (do not know whether that is by design or accident) </cmt> <cmt> unit-tests known to call the hipfftsetworkarea api </cmt> <cmt>  </cmt> <cmt> //tensorflow/python/kernel_tests/linalg:linear_operator_circulant_test_gpu </cmt> <cmt> //tensorflow/python/kernel_tests/signal:dct_ops_test </cmt> <cmt> //tensorflow/python/kernel_tests/signal:mel_ops_test </cmt> <cmt> //tensorflow/python/kernel_tests/signal:mfcc_ops_test </cmt> <cmt> //tensorflow/python/kernel_tests/signal:spectral_ops_test </cmt> <cmt> //tensorflow/python/ops/parallel_for:control_flow_ops_test_gpu </cmt> <cmt>  </cmt> <cmt> updating the mapping of gcn arch name tokens to feature strings. </cmt> <cmt> prior to this commit, the gcn arch name ""gfx908:+sramecc"", would get mapped to </cmt> <cmt> * { target : ""gfx908"", feature_string : ""+sram-ecc""} </cmt> <cmt> this commit changes the mapping to the following </cmt> <cmt> * { target : ""gfx908"", feature_string : ""+sramecc""} </cmt> <cmt> (notice the dash ""-"" is gone from ""+sram-ecc"") </cmt> <cmt> the llvm version being picked up by tf in this branch ( develop-upstream-qa-rocm42 ) seems have changes withing it (as compared to the version being picked up in the develop-upstream-qa-rocm41 branch), which require this change in the mapping. </cmt> <cmt> this mapping is expected to be in a state of flux until all the amdgpu target-id related changes have been pushed out to the upstream llvm repo, and tf llvm pointer is updated to pick those changes. </cmt> <cmt> add clang 13 header for rocm configure </cmt> <cmt> re-enabling subtests that were disabled due to jira ticket - 236756 </cmt> <cmt> re-enabling unit-tests that were disabled due to jira ticket - 248713 </cmt> <cmt> revert ""adding no_rocm tag to rocm unit-tests that regress with rocm 3.9"" </cmt> <cmt> this reverts commit 7301217ef410b9a0490bff6e717715ad2aeb1428. </cmt> <cmt> re-enabling some unit-tests that regressed starting rocm 3.8 </cmt> <cmt> they were disabled in the following commit </cmt> <cmt>  </cmt> <cmt> adding no_rocm tag to //tensorflow/python/kernel_tests:extract_image_patches_grad_test_gpu </cmt> <cmt> this unit-test starts to fail when we switch from rocm 4.0.1 to rocm 4.1.0 </cmt> <cmt> qa did not detect this regression because this test passes in the branch they were using to qualify rocm 4.1.0 ( develop-upstream-qa-rocm41 ) </cmt> <cmt> in addition to other changes (between develop-upstream-qa-rocm41 and tip of develop-upstream), the testcase itself seems to have changed. we need to root-cause the regression, fix it and re-enable the test. </cmt> <cmt> copy-pasting the error log here for reference </cmt> <cmt>  </cmt> <cmt> ====================================================================== </cmt> <cmt> fail: test_allnone_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> test_allnone_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> ---------------------------------------------------------------------- </cmt> <cmt> traceback (most recent call last): </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 185, in test_allnone_gradient </cmt> <cmt> self._variableshapegradient([none, none, none, none]) </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 173, in _variableshapegradient </cmt> <cmt> self.assertless(err, 1e-4) </cmt> <cmt> assertionerror: nan not less than 0.0001 </cmt> <cmt> ====================================================================== </cmt> <cmt> fail: test_bxxc_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> test_bxxc_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> ---------------------------------------------------------------------- </cmt> <cmt> traceback (most recent call last): </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 176, in test_bxxc_gradient </cmt> <cmt> self._variableshapegradient([-1, none, none, -1]) </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 173, in _variableshapegradient </cmt> <cmt> self.assertless(err, 1e-4) </cmt> <cmt> assertionerror: 0.4175793528556824 not less than 0.0001 </cmt> <cmt> ====================================================================== </cmt> <cmt> fail: test_xhwx_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> test_xhwx_gradient (__main__.extractimagepatchesgradtest) </cmt> <cmt> ---------------------------------------------------------------------- </cmt> <cmt> traceback (most recent call last): </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 179, in test_xhwx_gradient </cmt> <cmt> self._variableshapegradient([none, -1, -1, none]) </cmt> <cmt> file ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py"", line 173, in _variableshapegradient </cmt> <cmt> self.assertless(err, 1e-4) </cmt> <cmt> assertionerror: 0.2977283000946045 not less than 0.0001 </cmt> <cmt> ---------------------------------------------------------------------- </cmt> <cmt> ran 7 tests in 406.984s </cmt> <cmt> failed (failures=3, skipped=1) </cmt> <cmt> ================================================================================ </cmt> <cmt>  </cmt> <cmt> adding no_rocm tag to tests which are failing on mi100 with rocm 4.1 </cmt> <cmt> these tests </cmt> <cmt>  </cmt> <cmt> //tensorflow/compiler/xla/tests:convolution_test_1d_gpu_alternative_layout_gpu failed in 3 out of 3 in 16.0s </cmt> <cmt> //tensorflow/compiler/xla/tests:convolution_test_1d_no_vmodule_gpu       failed in 3 out of 3 in 16.1s </cmt> <cmt>  </cmt> <cmt> re-enabling all the tests that will potentially be fixed by jira ticket - 263833 </cmt> <cmt> the following is list of unit-tests from which we are removing the no_rocm tag in this commit, because we suspect/hope that the issue being fixed by jira ticket 263833, will make these tests pass. </cmt> <cmt> all of these tests are passing locally when tested with rocm 4.1rc1, but given the flaky nature of the failure (these tests would only fail on some ci nodes...sometimes), we need to have them pass consistently on all ci nodes, over some periosd of time (couple of weeks) before we can claim victory </cmt> <cmt>  </cmt> <cmt> //tensorflow/python/distribute:cross_device_ops_test_gpu </cmt> <cmt> //tensorflow/python/distribute:distribute_utils_test_gpu </cmt> <cmt> //tensorflow/python/distribute:strategy_common_test_gpu </cmt> <cmt> //tensorflow/python/distribute:strategy_gather_test_gpu </cmt> <cmt> //tensorflow/python/distribute:test_util_test_gpu </cmt> <cmt> //tensorflow/python/distribute:values_test_gpu </cmt> <cmt> //tensorflow/python/distribute:vars_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:custom_training_loop_metrics_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:custom_training_loop_models_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_rnn_model_correctness_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_utils_test_gpu </cmt> <cmt>  </cmt> <cmt> the following two tests fell into the same category as above, but their no_rocm tag ios staying put, because flaku failures were observed for them in local testing with rocm 4.1 </cmt> <cmt>  </cmt> <cmt> //tensorflow/python/keras/distribute:distribute_strategy_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_dnn_correctness_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_embedding_model_correctness_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_image_model_correctness_test_gpu </cmt> <cmt> //tensorflow/python/keras/distribute:keras_save_load_test_gpu </cmt> <cmt>  </cmt> <cmt> also some of the tests take longer than 900s to complete on the rocm platform (no sharding on rocm!)...bumping them up to size large in this commit </cmt> <cmt> adding no_rocm tag to tests that seem to have done flaky with rocm 4.1 </cmt> <cmt> these tests </cmt> <cmt>  </cmt> <cmt> //tensorflow/python/keras/distribute:saved_model_save_load_test_gpu </cmt> <cmt> //tensorflow/python/kernel_tests:tensordot_op_test_gpu </cmt> <cmt>  </cmt> <cmt> see details here - </cmt> <cmt> syncing the contents of the run_gpu_multi.sh script with the rocm fork </cmt> <cmt> fixing errors in ""buildifier check"" </cmt> <cmt> fixing errors in ""bazel query"" </cmt> <cmt> piperorigin-revid: 367580713 </cmt> <cmt> change-id: i5289492260ea8c6fde64848ba895c1ea736019d8 </cmt>",port pr 48187 to r2.5
1749,"<desc> this allows people to avoid having audit messages in the journal at all:  some related cleanups, and adding systemd-journal-audit.socket to documentation. </desc> <cmt> journald: move server_restore_streams out of server_open_stdout_socket </cmt> <cmt> one has little to do with the other, so it's confusing that the second </cmt> <cmt> also calls the first. </cmt> <cmt> journald: make audit socket optional </cmt> <cmt> if we were given some sockets through socket activation, and audit </cmt> <cmt> socket is not among them, do not try to open it. this way, if the </cmt> <cmt> socket unit is disabled, we will not receive audit events. </cmt> <cmt>  </cmt>",make journald audit socket maskable
1750,"<desc> this pr updates links to external pages. it: changes  changes  updates links to other services, where to skip unnecessary redirects. one thing i didn't fix is the link to  what do you think? i'd be happy to squash the commits, or skip some of them if you think this changes too much. </desc> <cmt> [docs] fix link to py-amqp issue tracker </cmt> <cmt> use https for github and wikipedia links </cmt> <cmt> [docs] update external links in readme </cmt>",update and fix links to external pages
1751,<desc> this is a follow-up for this abandoned pull request: #32202 hopefully the code is acceptable and can be merged this time? i would like to use this feature in my current projet. edit: documentation reference (unclear)  source code reference </desc> <cmt> chartjs - missing tooltip axis option </cmt> <cmt> according to </cmt> <cmt> trailing space </cmt> <cmt> updated axis type based on uniqueiniquity's comment. </cmt>,chart.js - missing tooltip axis option
1752,"<desc> removed truncating of text in attachment.text. added attachment.text to be parsed to markdown by default. earlier now closes #20560 #20560 (comment) shows the bug which can be reproduced by using the curl command if you already have a bot with the correct credentials. otherwise you can use this way to reproduce the message, (i have used a bot for that): on the terminal, do git clone  add this bot with these username and password to the list of users. (for reference, you can see this -  now in the terminal where you cloned the repo for the bot, do npm start. you will get a message in the general channel of your running instance. </desc> <cmt> fix: remove truncating of attachment.text </cmt> <cmt> fix: display attachment.text as markdown </cmt> <iss> jira notifications via webhook - layout broken </iss>",default attachments - show full attachment.text with markdown
1753,"<desc> adding my dz60 keymap, and updating my boardwalk keymap my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> updating boardwalk layout, and adding dz60 layout </cmt> <cmt> dz60 config.h </cmt> <cmt> image added to readme </cmt>",niclake - keymap updates - boardwalk updates & dz60 create
1754,<desc> i'm working on font/language support detection and this pr is actually a first bunch of (mostly) obvious fixes. </desc> <cmt> guifontttfdx: prevent crash on unallocated texture or unavailable direct3d device </cmt> <cmt> cguifontttfgl::begin: prevent crash on unallocated texture </cmt>,set of fixes for font processing
1755,"<desc> change the primary motivation of this change was to add new fields for use in the list and upgrade commands; system reference strings that can be used to associate a winget package with software currently installed on a machine.  this required creation of schema 1.1, as well as some refactoring to make inheritance and behavior changes easier between versions. the two types of strings added are packagefamilyname for msix packages, and productcode for packages that register through arp (add/remove programs).  these are added with the option of having multiple of each in the event that a package's installers have unique values.  the values are stored with their casing folded to allow for ordinal comparisons, a performance requirement due to future work on list and upgrade. additional noteworthy changes: changed from implicit indices to explicit ones in 1.1, and drop more of them during preparation for packaging. this should result in a ~35% reduction in page count in the database, with no impact to performance. added a dev debug tool in sqlitewrapper.cpp; set winget_sqlite_explain_query_plan_enabled to 1 to have the query plan for every sqlite prepared statement output to logging. validation the existing tests have been updated to use generate to run the tests not only against all versions, but also with backcompat scenarios. microsoft reviewers: open in codeflow </desc> <cmt> add query plan output for debugging </cmt> <cmt> move header output to remove non-read statements </cmt> <cmt> add index version 1.1 (initial) that uses named indeces throughout and removes more of them when packaging </cmt> <cmt> add new 1:n tables for system reference strings, still requires testing of search </cmt> <cmt> add tests for system reference strings </cmt>",create db 1.1 schema for system reference strings
1756,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: docs to path() increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> [ramda] fix path() return type </cmt> <cmt> add tests </cmt>",fix path() return type according to documentation
1757,"<desc> test sharding appears to have been broken by commit 87cc788. the result being that many tests are simply not run when sharding is enabled. the issue seems to be that the filtering for sharding is happening twice, once in tensorflow/python/platform/googletest.py and then once again in external/absl_py/absl/testing/absltest.py. this commit fixes the issue by removing the shard filtering code in googletest.py. fixes: #25594 </desc> <cmt> fix test sharding </cmt> <cmt> test sharding appears to have been broken by commit 87cc788.  the result </cmt> <cmt> being that many tests are simply not run when sharding is enabled. </cmt> <cmt> the issue seems to be that the filtering for sharding is happening </cmt> <cmt> twice, once in tensorflow/python/platform/googletest.py and then once </cmt> <cmt> again in external/absl_py/absl/testing/absltest.py.  this commit fixes </cmt> <cmt> the issue by removing the shard filtering code in googletest.py. </cmt> <cmt> fixes: </cmt> <cmt> remove unused import of itertools </cmt> <iss> test sharding appears to be broken </iss>",fix test sharding version 2
1758,<desc> for the snap updates caddy to 0.11.0 and updates node.js to 8.11.2 i've already updated the 0.65.1 snap which is live for everyone.  this is just making these changes upstream :) </desc> <cmt> update caddy version </cmt> <cmt> update node.js to 8.11.2 </cmt>,snap update caddy and nodejs
1759,<desc> fix #4620 use click event instead of change event. add test case for #4521 </desc> <cmt> listen to click event for checkbox and radio. </cmt> <cmt> add test cases </cmt> <iss> checkbox :checked is not fully reactive when checkbox is in focus </iss>,use 'click' event for checkbox and radio (fix #4620)
1760,"<desc> the old socket.io guide didn't actually work that well, for the reasons that i've outline in the new guide i wrote. </desc> <cmt> adding feathers to the mix. </cmt> <cmt> adding feathers to the mix. </cmt>",adding feathers to the mix and an updated react native socket.io guide
1761,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> added cordova-plugin-native-keyboard </cmt> <cmt> updated to conform linting checks </cmt> <cmt> onsubmit callback is now optional </cmt> <cmt> pull and conflicts resolved </cmt> <cmt> added possibility to use an array for the property country in geocodercomponentrestrictions </cmt>,possibility to use an array for the property country in geocodercomponentrestrictions class
1762,"<desc> this is used surprisingly often. for example, it is used by a core youtube library called structured page fragments. it allows you to manually dispatch an event with arbitrary data attached to it. the only thing missing from this implementation is the constructor. this is because wrappergenerator is currently missing dictionary capabilities. </desc> <cmt> libweb: add [customvisit] idl interface extended attribute </cmt> <cmt> this custom attribute will be used for objects that hold onto arbitrary </cmt> <cmt> js::value's. this is needed as js::handle can only be constructed for </cmt> <cmt> objects that implement js::cell, which js::value doesn't. </cmt> <cmt> this works by overriding the visit_edges function in the wrapper. </cmt> <cmt> this overridden function calls the base visit_edges and then forwards </cmt> <cmt> it to the underlying implementation. </cmt> <cmt> this will be used for customevent, which must hold onto an arbitrary </cmt> <cmt> js::value for it's entire lifespan. </cmt> <cmt> libweb: add support for the any type in returning and parameters </cmt> <cmt> required for customevent. </cmt>",add initial support for customevent
1763,"<desc> original pull-request #13752 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> range check for h3kring </cmt> <cmt> update test </cmt> <cmt> range check for h3kring </cmt>",cherry pick #13752 to 20.6: range check for h3kring
1764,"<desc> right now formatting of std::byte using compile-time api like so: fmt::format(fmt_compile(""{}""), std::byte{42}) ends up with compilation error, proof on compiler explorer. because there are 2 write functions which satisfy for the passed type std::byte: fmt/include/fmt/format.h lines 2114 to 2120 5a37e18 template <typename char, typename outputit, typename t, fmt_enable_if(std::is_enum<t>::value && !std::is_same<t, char>::value)> fmt_constexpr outputit write(outputit out, t value) { return write<char>( out, static_cast<typename std::underlying_type<t>::type>(value)); fmt/include/fmt/format.h lines 2150 to 2162 5a37e18 template <typename char, typename outputit, typename t> auto write(outputit out, const t& value) -> typename std::enable_if< mapped_type_constant<t, basic_format_context<outputit, char>>::value == type::custom_type, outputit>::type { using context_type = basic_format_context<outputit, char>; using formatter_type = conditional_t<has_formatter<t, context_type>::value, typename context_type::template formatter_type<t>, fallback_formatter<t, char>>; context_type ctx(out, {}, {}); return formatter_type().format(value, ctx); also, i found __cpp_lib_byte feature macro, so all new checks are based on this macro instead of __cplusplus >= 201703l and i changed old checks accordingly. </desc> <cmt> add test for byte formatting with fmt_compile </cmt> <cmt> fix byte formatting with fmt_compile, use __cpp_lib_byte macro </cmt>",fix std::byte formatting with compile-time api
1765,"<desc> removed and renamed several files that do not exist or have been renamed, but the project files had never been updated.  this was causing an issue building with visual studio 2015/2017, with a ""project is out of date"" warning every time the program is run from within the ide. </desc> <cmt> [libcocos2d.vcxproj, libcocos2d.vcxproj.filters] removed entries for non-existent files that were causing ""build is out of date"" issues in visual studio </cmt> <cmt> [project.pbxproj] removed entries for non-existent file </cmt> <cmt> [libcocos2d.vcxproj.filters] renamed ccstencilstatemanager.h extension to .hpp. </cmt> <cmt> [libcocos2d.vcxproj, libcocos2d.vcxproj.filters] removed entry for file ccdownloaderimpl.h which does not exist. </cmt>",vs and xcode project files have non-existent file references
1766,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: luxon#1.20.0 </desc> <cmt> [luxon] add interval#toisodate and interval#toisotime </cmt> <cmt> [luxon] add duration#mapunits </cmt> <cmt> patch version not allowed </cmt>,"add interval#toisodate, interval#toisotime and duration#mapunits"
1767,<desc> fixed an index out of bounds error that occurs when you pass 256 into iskeyjustpressed() on lwjgl3 backend </desc> <cmt> update lwjgl3input </cmt> <cmt> fixed an index out of bounds error that occurs if you pass the value 256 into gdx.input.iskeyjustpressed() </cmt> <cmt> update lwjgl3input </cmt> <cmt> made the iskeyjustpressed method more consistent with lwjgl backend. </cmt>,iskeyjustpressed index out of bounds on lwjgl3
1768,<desc> description: added error handling. the error prompt the user to reboot the sky hub router in case home assistant is not able to fetch data from it. the rebooting has been reported to solve the issue here. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> added error handling in function _get_skyhub_data </cmt> <cmt> error line split for readability </cmt>,improve sky hub error handling
1769,"<desc> setting the 2nd tool's z-offset to a positive value, results in the tool not being able to reach bed level. this is because zmin soft endstop is translated and the new endstop value for the tool becomes its z-offset. since tools in a parking_extruder configuration are all carried on the x-axis, their nozzles' height difference must be compensated by moving the lowest tool lower than zmin, and zmin endstop value for all tools should be 0 (untranslated). this is typically not an issue, since tools are parked outside the hotbed area. if tools are parked within the bed area (in which case useful bed space is consumed, so not a typical configuration), they must be perfectly aligned in height in order to avoid the lowest tool from crashing on the bed. this solution allows both tools reach the bed by skipping the change to the z-min soft endstop value (which typically happens on tool change). all other endstop values are translated accordingly. e0 active: ___________x-axis__________ |||             ||| |||             ||| |||              v ------bed------- e1 active, before the fix: ___________x-axis__________ |||                ||| |||                ||| |||                 v ------bed------- e1 active after the fix: ___________x-axis__________ |||                ||| |||                ||| |||                 v v    ------bed------- 2nd tools with a positive z-offset can work properly. enable parking_extruder, create a 2nd extruder with a positive z-offset value. this is complementary to pull request #20473 </desc> <cmt> fixed broken parking_extruder operation. </cmt> <cmt> fixed configuration files </cmt> <cmt> update solenoid.cpp </cmt> <cmt> update t.cpp </cmt> <cmt> update tool_change.cpp </cmt> <cmt> update tool_change.cpp </cmt> <cmt> update tool_change.cpp </cmt> <cmt> invert </cmt> <cmt> last touch </cmt> <cmt> fix for 2nd tool z-offset operation </cmt>",don't apply hotend_offset.z to z soft endstops
1770,<desc> this is a backport of #54803 for 7.x. this pull request cherry picks the squashed commit from #54803 with the additional commits: 6f50c92 which adjusts master code to 7.x a114549 to mute a failing ilm test (#54818) 48cbca1 and 50186b2 that cleans up and unmutes the previous test aae12bb that adds a missing feature flag (#54861) 6f330e3 that adds missing serialization bits (#54864) bf72c02 that adjust the version in yaml tests a51955f that adds some plumbing for the transport client used in integration tests </desc> <cmt> merge feature/searchable-snapshots branch into master (#54803) </cmt> <cmt> this commit merges the searchable-snapshots feature branch into master. </cmt> <cmt> see #54803 for the complete list of squashed commits. </cmt> <cmt> fix stuff after cherry-picking </cmt> <cmt> mute testdeleteactiondeletessearchablesnapshot (#54818) </cmt>,merge feature/searchable-snapshots branch into 7.x (#54803)
1771,"<desc> when constructing union and intersection types, we eagerly remove duplicate function types that originate in function or method declarations. this eager reduction can be very expensive when resolving the members of unions of a large number of array or tuple types. we used to rely on the eager reduction, but it is no longer necessary because a similar and more efficient reduction happens later (and in a deferred manner) when we compute the signature lists of union and intersection types. with this pr we remove the unnecessary eager reduction. this makes our behavior more consistent since the eager reduction was never done for other types. one example that directly benefits is this code in #26756. when requesting statement completion: function sendcommand<c extends keyof commands>(method: c, ...params: commands[c]['paramstype']) { params.  // statement completion here } we currently spend 5-6 seconds grinding away before bringing up a completion list. with this pr the completion time drops to less than half a second. only one rwc project, fp-ts, is affected by this. upon inspection the new errors in fp-ts look correct, and with the latest code here </desc> <cmt> defer reduction of identical function types in unions and intersections </cmt> <cmt> accept new baselines </cmt>",defer union and intersection type reduction
1772,"<desc> this pr moves .flake8 and .coveragerc into pyproject.toml use pflake8 wrapper use coverage[toml] extra the makefile line ""pip install coverage[toml]"" can be removed once the docker base image has been deployed </desc> <cmt> migrate .flake8 config to pyproject.toml through pflake8 </cmt> <cmt> migrate .coveragerc to pyproject.toml through toml extra </cmt>",consolidate .coveragerc and .flake8 config int pyproject.toml
1773,"<desc> when using tooltip with a delay on show, but not on hide the delay timer is not cancelled. this is now fixed and an unit test is added to the test framework. </desc> <cmt> cancel running timer for tooltips with delayed show, but instant hide. this prevents delayed tooltips from appearing if the mouse leaves the elements before tooltip is showed and the hiding delay is 0. </cmt> <cmt> added unit test to check that tooltips is not showed when leave event is triggered before show delay has expired and the hide delay is set to 0 </cmt>",added fix for bootstrap-tooltip with show-delay but now hide delay.
1774,"<desc> as in the description, it's now fixed. i've removed the signed word since it's implicit. </desc> <cmt> added most of the standard ppc instructions, missing some altivec and complex instructions </cmt> <cmt> fixed rot instructions. </cmt> <cmt> minimal support to ppc[64] emulation </cmt> <cmt> fixed for </cmt> <cmt> flavour </cmt> <cmt> fixed inv_mask[32/64] </cmt> <cmt> fixed parsing of some functions </cmt> <cmt> merge with radare/radare2 repo </cmt>",ppc pseudo bad parse due missing uppercase letters & ppc emu (due mistake)
1775,<desc> fixes #70168 introduced in #69604 which was backported to 2.9.10. this would need to be backported to 2.9 and 2.10. this is another take to get these fixes in after they were reverted in #70272 due to issues with testing the fixes in our ci. lib/ansible/plugins/action/__init__.py </desc> <cmt> fix storing local task_vars facts for the retry (#70171) </cmt> <cmt> * fix storing local task_vars facts for the retry </cmt> <cmt> fixes #70168 </cmt> <cmt> (cherry picked from commit eaf6086eeab3ffc0389694a037c776cd3d6ac0b5) </cmt> <cmt> fix storing delegate_to facts (#70231) </cmt> <cmt> * fix storing delegate_to facts </cmt> <cmt> (cherry picked from commit 88bb76f248833ea0761fc474ba77ef697c62baac) </cmt> <cmt> remove non_local </cmt> <iss> 2.9.10: unboundlocalerror: local variable 'module_style' referenced before assignment </iss>,fix delegate_facts with interpreter not being set
1776,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: this is used in many strategies -  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added passreqtocallback to passport authenticationoptions </cmt> <cmt> added myself to contributors just in case </cmt> <cmt> fixed tabs </cmt> <cmt> actuall fixed tabs </cmt>",passportjs - add passreqtocallback to authenticateoptions
1777,"<desc> hello, i would like to add my project to this amazing library. componofy is a web app that allows users to merge or create their playlists out of many, personal or public, playlists. it also allows users to re-order tracks in playlist with drag and drop and upload custom playlist cover images. please see a 2-minute demo for more details:  it uses material-ui from top to bottom with themes and measurement units applied for each component. for more code details you can see the source code:  i believe this project is great and will be a good asset to your showcase! thanks a lot for this amazing ui library. link: </desc> <cmt> added showcase to readme - componofy </cmt> <cmt> align text </cmt>",add showcase to readme - componofy
1778,"<desc> add tooltips to st.checkbox, st.radio, and st.number_input. pr preview is in e2e/scripts/st_tooltips.py. </desc> <cmt> add help keyword/field to protobufs and api </cmt> <cmt> add tooltip to textinput </cmt> <cmt> remove unnecessary code </cmt> <cmt> fix pylint </cmt> <cmt> fix pylint stuff </cmt> <cmt> fix tests </cmt> <cmt> remove unnecessary change </cmt> <cmt> add e2e test </cmt> <cmt> remove unnecessary change </cmt> <cmt> add tooltips for st.checkbox, st.radio, st.number_input </cmt>",add tooltips to more widgets
1779,<desc> fix #9942. </desc> <cmt> fix sankey edge emphasis not work #9942 </cmt> <cmt> fix opacity not work in edge emphasis which is override by focusnodeadjacency action </cmt> <cmt> fix adjacency node emphasis color not work with focusnodeadj action </cmt> <iss> emphasis line style options do not work on sankey charts </iss>,fix emphasis line style options do not work on sankey charts #9942
1780,"<desc> added trace steps to show addition of nodes and how tree is traversed while adding a new node. this will help in resolving issue #213 in my opinion. please review and let me know your feedback. thanks, raj </desc> <cmt> added trace to construct elements </cmt> <cmt> still work pending in construct and tree code </cmt> <cmt> removed node collection dependecy from consumed app </cmt> <cmt> udpated code to store nodecollection and root with in the construct </cmt> <cmt> tracer </cmt> <cmt> updated layout stratergy to draw nodes </cmt>",tracer to depict addition of nodes in binary search tree
1781,"<desc> closes: #7683 if multiple --config options are provided, crash with serverlesserror example node .\bin\serverless.js --config hello --config world error serverless error --------------------------------------- got 2 config paths: [hello, world].expected single value get support -------------------------------------------- docs:          docs.serverless.com bugs:          github.com/serverless/serverless/issues issues:        forum.serverless.com </desc> <cmt> crash on config multiple cli inputs </cmt> <cmt> add tests </cmt> <iss> serverless cron is not working with type error 'path' </iss>",display error message on duplictate conf path
1782,<desc> fix sentence case requests by sigmavirus24 here:  added myself to authors. </desc> <cmt> added space and sentence case </cmt> <cmt> added space and sentence case as requested by sigmavirus24. </cmt> <cmt>  </cmt> <cmt> adding my name to authors. </cmt> <cmt> adding myself to authors. </cmt> <cmt> adding my name to authors </cmt>,add to authors and fix case
1783,"<desc> a fix motivated by #29785. while i have noted in #44696 (comment) that different requests require different required paramters (overall, implementing the documentation change in that comment is probably the 'final' paramter requirements fix), the op in #29785 appears to be saying that name is required to use the module in the first place. linode ansible version ansible 2.7.0.dev0 (mark-name-required-#29785 f112e314b7) last updated 2018/08/27 00:25:34 (gmt +200) config file = none configured module search path = [u'/home/decentral1se/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/decentral1se/hobby/ansible/lib/ansible executable location = /home/decentral1se/hobby/ansible/bin/ansible python version = 2.7.13 (default, nov 24 2017, 17:33:09) [gcc 6.3.0 20170516] in the running of the test, i can't seem to test against the output but have manually verified: lib/ansible/module_utils/basic.py:2367: systemexit -------------------------------------------------------------- captured stdout call --------------------------------------------------------------- {""msg"": ""missing required arguments: name"", ""failed"": true, ""invocation"": {""module_args"": {""payment_term"": 1, ""displaygroup"": """", ""state"": ""present"", ""wait_timeout"": 300, ""swap"": 512, ""watchdog"": true, ""wait"": true}}} </desc> <cmt> mark 'name' parameter as required. </cmt> <cmt> closes </cmt> <cmt> add the linode-python dependency for unit tests. </cmt>",mark 'name' as required. fixes #29785
1784,"<desc> if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. </desc> <cmt> fix avg time of grpc is not right. </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> fix avg time of grpc is not right. </cmt> <cmt> fix avg time of grpc is not right. </cmt> <iss> the average response time of grpc is not right </iss>",fix the response time of grpc is not right.
1785,<desc> related to #14813 deprecates none in featureunion. two options to do the same thing is undesirable. </desc> <cmt> enh deprecates none in feature union </cmt> <cmt> enh deprecates none in feature union </cmt> <cmt> doc adds todo </cmt> <cmt> doc adds todo </cmt> <cmt> sty </cmt>,dep deprecate none in featureunion
1786,"<desc> there are several variations of alerts in the app: alertmessage .alert (bootstrap) styledwarning this pr aims to unify these as one alert component, as well as introduce a variation of alert that plays well with panels. todo: introduce alert component update alertmessage to use alert introduce panelalert replace styled warning with alert future pr: update all the various uses of bootstrap's .alert to use this component remove .alert and our overrides from sentry.less and shared-components.less introduce grid helper function fix nan value issue in snapshots by wrapping tests with <themeprovider> </desc> <cmt> fix remove org positioning </cmt> <cmt> add panelalert component </cmt> <cmt> add box shadow </cmt>",one alert to rule them all
1787,"<desc> issue: #11371 render iframes with &refid=$refid. pass refid over the channel when emitting events match events to refs first via refid, falling back to postmessage event origin. @tmeasday i removed a least code as possible. i could delete more of the compatibility code dealing with source. </desc> <cmt> add refid to channel-postmessage </cmt> <cmt> de-duplicate the code for switching between handling event from refs vs local iframe </cmt> <cmt> add refid to iframe url </cmt> <cmt> fix typings of channel-postmessage </cmt> <cmt> sourcetype is always external when refid is given </cmt> <cmt> change setstoriespayload to single type </cmt>",change event source to ref
1788,"<desc> went to go play around in the code and add some of my own things, realized things were a little different here. things i changed: 1. pragma once the files that are missing it edit: zvecr says no 2. turn on bootmagic lite. the volcano 660 has a solid bottom so if a user forgets to put on a reset key in their keymap, it's back to dismantling 3. rgblight is enabled.....even though there is no rgb light on this board 4. backlight is enabled.....even though there is no backlight on this board 5. enabled command_enable for extra debugging prowess 6. audio_enable was included twice, once disabling and once enabling. assuming its enabling as why else would you have a speaker? my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fix audio enable repetition </cmt> <cmt> remove rgb led support as this board has no rgb lb leds </cmt> <cmt> use pragma once </cmt> <cmt> this board has no backlight support </cmt> <cmt> enable command_enable </cmt> <cmt> comment cleanups </cmt> <cmt> setting bootmagic to lite as the first board thathat has this pcb has a solid bottom. if someone forgets to put in a reset key on their keymap, they are not going to have fun resetting the board </cmt>",clueboard rev4 updates aka volcano 660
1789,"<desc> also see #3366, #3373. support .msg as file format option in spacy convert (already supported internally by goldcorpus) so training data can be provided as binary messagepack data. support .jsonl in goldcorpus so training data can be provided as jsonl. update spacy convert documentation. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> populate converter argument info automatically </cmt> <cmt> add conversion option for msgpack </cmt> <cmt> update docs </cmt> <cmt> allow reading training data from jsonl </cmt>",improve converters and training data file formats
1790,"<desc> commit ce_aaa_server module new module pull request ce_aaa_server.py ansible version ansible 2.3.0 config file = /etc/ansible/ansible.cfg configured module search path = ['/home/ansible-2.1.1.0/lib/ansible/modules/core/network/cloudengine', '/home/ansible-2.1.1.0/lib/ansible/module_utils', '/home/ansible-2.1.1.0/lib/ansible/modules', '/home/ansible-2.1.1.0', '/home/ansible-2.1.1.0/lib/ansible/utils/'] task [configure accounting scheme] ********************************************* task path: /usr1/code/openness/code/current/kvm/intg/test/testcases/test-ce_aaa_server.yml:58 using module file /usr/local/lib/python2.7/site-packages/ansible-2.3.0-py2.7.egg/ansible/modules/core/network/cloudengine/ce_aaa_server.py <ce_6850> establish local connection for user: root <ce_6850> exec /bin/sh -c '( umask 77 && mkdir -p "" echo $home/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160 "" && echo ansible-tmp-1487042119.19-256857505644160="" echo $home/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160 "" ) && sleep 0' <ce_6850> put /tmp/tmpcgsfja to /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py <ce_6850> exec /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py && sleep 0' <ce_6850> exec /bin/sh -c '/usr/bin/python /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py; rm -rf ""/root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/"" > /dev/null 2>&1 && sleep 0' changed: [ce_6850] => { ""changed"": true, ""end_state"": { ""accounting scheme"": [ [ ""none"", ""default"" ], [ ""radius"", ""test1"" ] ], ""local user group"": [ ""manage-ug"", ""system-ug"", ""monitor-ug"", ""visit-ug"", ""wdz_group"" ], ""radius enable"": [ ""true"" ], ""radius template"": [ ""group1"", ""wdz"", ""w"", ""wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww"", ""test2"" ] }, ""existing"": { ""accounting scheme"": [ [ ""none"", ""default"" ] ], ""local user group"": [ ""manage-ug"", ""system-ug"", ""monitor-ug"", ""visit-ug"" ], ""radius enable"": [ ""true"" ], ""radius template"": [ ""group1"", ""wdz"", ""w"", ""wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww"" ] }, ""invocation"": { ""module_args"": { ""accounting_mode"": ""radius"", ""acct_scheme_name"": ""test1"", ""auth_pass"": null, ""authen_scheme_name"": null, ""author_scheme_name"": null, ""authorize"": false, ""domain_name"": null, ""first_authen_mode"": null, ""first_author_mode"": null, ""host"": ""ce_6850"", ""hwtacas_template"": null, ""local_user_group"": ""wdz_group"", ""password"": ""value_specified_in_no_log_parameter"", ""port"": 12345, ""provider"": null, ""radius_server_group"": ""test2"", ""ssh_keyfile"": null, ""state"": ""present"", ""timeout"": 10, ""transport"": null, ""use_ssl"": false, ""username"": ""rootdc"", ""validate_certs"": true }, ""module_name"": ""ce_aaa_server"" }, ""proposed"": { ""accounting_mode"": ""radius"", ""acct_scheme_name"": ""test1"", ""local_user_group"": ""wdz_group"", ""radius_server_group"": ""test2"", ""state"": ""present"" }, ""updates"": [ [ ""accounting-scheme test1"", ""accounting-mode radius"" ], [ ""radius server group test2"" ], [ ""user-group wdz_group"" ] ] } </desc> <cmt> commit ce_aaa_server module </cmt> <cmt> commit ce_aaa_server module </cmt> <cmt> update ce_aaa_server.py </cmt> <cmt> update ce_aaa_server.py </cmt>",contributing lib/ansible/modules/network/cloudengine/ce_aaa_server.py module to manage huawei data center cloudengine
1791,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> added: initial files, more work needed </cmt> <cmt> fixed: more classes </cmt> <cmt> fixed: some fixes to incorrect types so that gods has no errors </cmt> <cmt> improved: more strick tsconfig </cmt> <cmt> fixed: tslint.json typo in filename </cmt> <cmt> fixed: npm test errors </cmt> <cmt> added: umd global var athenajs </cmt>",added definitions for the athenajs npm package
1792,"<desc> plan is to cut another 2.x release, maybe 2.7182818284? also, bumps agp, compilesdk and targetsdk to latest bumps gradle and robolectric to more recent releases (opted not for latest to minimize build fixes) </desc> <cmt> remove obsolete manifest stuff </cmt> <cmt> gradle 6.1.1 </cmt> <cmt> agp 4.0.1 </cmt> <cmt> compile/targetsdk 30 </cmt> <cmt> robolectric 4.0.1 </cmt> <cmt> migrate to androidx </cmt> <cmt> closes #2175 </cmt>",migrate 2.x branch to androidx
1793,"<desc> previously this caused a crash in parsing. if/when we want to support this syntax, we will need to fix this crash. for now, it's enough to skip the code path and continue parsing in a non-nested fashion. fixes #24389 </desc> <cmt> callback tag:disallow nested-object-param syntax </cmt> <cmt> previously this caused a crash in parsing. if/when we want to support </cmt> <cmt> this syntax, we will need to fix this crash. </cmt> <cmt> update baselines </cmt> <iss> [3.0.0-dev.20180522] tsc crashes on parsing jsdoc with error ""debug failure. false expression"" (in parsetag) </iss>",disallow nested object param syntax in callback tag
1794,"<desc> based on comments from our beta release vote. issue: #1251 #1245 #1246  #1247 i do following adjustments: disclaimer file changed. add release_rc_tag into the release script. also need export this new env. variable. add rc(x) version control mechanism into release process add sha512 contents into vote mail add full urls of skywalking and its submodule projects git commitid fyi @apache/skywalking-committers all committers, to be advised, release doc has just updated. if anyone wants to lead further release vote, please follow this document. </desc> <cmt> adjust release doc and script based on last release vote. </cmt> <cmt> update ui declaimer file. </cmt>",update release doc and related script
1795,"<desc> the current code uses fread (+ byte swapping) / fwrite (without byte swapping) and fread or freadendian/ fwrite for de-serialization and serialization. the resulting file is always written in host endianness, so reading on a host with different endianness requires byte swapping. all functions return the number of elements read or written which must be compared with the intended value. the new code always uses deserialize / serialize methods which return true for success or false for failure, like it is already done with the existing deserialize / serialize methods for a lot of classes. with the new api it will be very easy to switch to a fixed little endian file format as soon as it is used for all serialization code. </desc> <cmt> add helper functions for serialization of simple data types </cmt> <cmt> use tesseract::serialize, tesseract::deserialize </cmt> <cmt> tfile: add helper functions for serialization of simple data types </cmt> <cmt> use tfile::serialize, tfile::deserialize </cmt>",simplify api for serialization and add first users
1796,"<desc> these two patches enable ""--relax"" and ""-fwhole-program"" to the linker and compiler of the marlin firmware.  these optimizations reduce overall code size and should also have an improvement to overall speed. for my printer, the size of the firmware went from 71109 bytes to 69203 bytes after applying these optimizations. </desc> <cmt> use linker ""--relax"" option. </cmt> <cmt> the ""relax"" option enables the linker to convert certain ""call"" </cmt> <cmt> instructions to the smaller ""rcall"" instruction.  this reduces the </cmt> <cmt> size of the resulting binary. </cmt> <cmt> use gcc ""-fwhole-program"" optimization. </cmt> <cmt> use ""whole program"" and ""link time optimization"" features of gcc.  the </cmt> <cmt> whole-program optimization enables the compiler to evaluate the entire </cmt> <cmt> firmware for optimization instead of just one code file at a time. </cmt> <cmt> this leads to better overall optimizations. </cmt>",add additional optimization flags to makefile
1797,"<desc> preparations for #7599 that are useful on their own. </desc> <cmt> logind: simplify one conditional </cmt> <cmt> don't bother with removing the directory if we didn't create it. </cmt> <cmt> logind: fix misleading message </cmt> <cmt> this message would also be emitted at boot for any user with linger </cmt> <cmt> enabled, so ""logged in"" is the wrong term to use. </cmt> <cmt> core: reuse slice_build_parent_slice </cmt> <cmt> tree-wide: use special_root_slice </cmt> <cmt> logind: use free_and_replace in one spot </cmt> <cmt> no functional change. </cmt> <cmt> mount: add option to specify uid= and gid= </cmt> <cmt> the kernel needs two numbers, but for the user it's most convenient to provide the </cmt> <cmt> user name and have that resolved to uid and gid. </cmt> <cmt> right now the primary group of the specified user is always used. that's the most </cmt> <cmt> common case anyway. in the future we can extend the --owner option to allow a group </cmt> <cmt> after a colon. </cmt> <cmt> [i added this before realizing that this will not be enough to be used for user </cmt> <cmt> runtime directory. but this seems useful on its own, so i'm keeping this commit.] </cmt> <cmt> generator: add helper function for writing unit files </cmt> <cmt> it doesn't save too much, but it's a common pattern so i think it's worth </cmt> <cmt> to factor this out. </cmt>",slice cleanups and systemd-mount --owner
1798,<desc> this pr resolves #1747 . an extra hyphen( - )  was appended to the url of contributors badge due to which the url was not correctly routing to all contributors section . this pr deletes the hyphen and fixes the url for all contributors badge. </desc> <cmt> correcting the hyperlink to redirect to correct url. </cmt> <cmt> corresponds to bug #1703 </cmt> <cmt> deleting the extra hyphen(-) that was incorrectly added. </cmt> <iss> issue with all contributors badge in readme.md file </iss>,correcting the url to fix #1747  -  bugfix/1747
1799,<desc> override files. move esp32 env in extra file platformio_tasmota_env32.ini the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core tasmota_core_stage and esp32 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> delete platformio_override_esp32.ini </cmt> <cmt> update platformio.ini </cmt> <cmt> add files via upload </cmt> <cmt> update platformio_override_sample.ini </cmt>,fix esp32 build env in platformio and merge
1800,"<desc> incorporates and closes #5309. fixes #5399 adapts work by @omnipotence456 after #5354. adds note to get_schema_view docs. aside: i note, in passing, that include_docs_urls and the helper functions from documentation.py are essentially undocumented. i'll add an issue for that but want to address it separately. </desc> <cmt> allow custom authentication and permission classes for docs view </cmt> <cmt> document extra parameters to get_schema_view </cmt> <iss> allow `include_docs_urls` to configure schema view authentication </iss>",allow setting custom authentication and permissions on docs view.
1801,<desc> checklist closing issues: #issue i wrote some lines in the radare2book this patch is supposed to add the functionality given by the unix command find . in the future this functionality might enable fetures like recursive copy and remove </desc> <cmt> added a recursive find function r_file_find() </cmt> <cmt> changed lsrf to r_file_find () </cmt> <cmt> don't follow symlinks </cmt> <cmt> changed the name of r_file_find() to r_file_dir_recursive() </cmt>,add recursive list functionality to libr/util/file.c
1802,<desc> fix issue with black failing on master and recent prs. add pre-commit as a required check. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> fix(build): black failing on master </cmt> <cmt> add pre-commit to required checks </cmt>,"black failing on master, add to required checks"
1803,<desc> resolving conflicts from #130 @keon changed modules names math ->  maths string -> strings queue -> queues </desc> <cmt> minor updates in merge_sorted_k_lists.py </cmt> <cmt> q.qsize()>0  ---->   not q.empty()      #  is more verbose and pythonic ;) </cmt> <cmt> refactored module name shadowing builtin modules </cmt> <cmt> minor fix </cmt> <cmt> new changes </cmt> <cmt> new changes </cmt> <cmt> resolving conflicts from patch-1 </cmt>,resolve conflict from refractoring modules.
1804,"<desc> what did you implement: closes #4440. adds ability to specify regional endpoints for api gateway. : # serverless.yml provider: name: aws endpointtype: regional ... how did you implement it: adds the endpointconfiguration attribute when we compile the restapi resource. by default, it sets to edge, which is the default api gw setting. how can we verify it: i used this example: service: endpoint-test # the provider block defines where your service will be deployed provider: name: aws runtime: nodejs6.10 endpointtype: regional functions: helloworld: handler: handler.helloworld events: - http: path: hello-world method: get cors: true then run sls package and check the .serverless/cloudformation-template-update-stack.json file that the restapi resource has the endpointconfiguration defined as desired. todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add endpointtype configuration </cmt> <cmt> add docs on endpointtype configuration </cmt>",add api gateway endpoint configuration
1805,"<desc> r-api for json dump format that was contributed in #1726 bugfix for #1845 bugfix for #1628 json dump example: data(agaricus.train, package='xgboost') bst <- xgboost(data = agaricus.train$data, label = agaricus.train$label, max_depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = ""binary:logistic"") jdump <- xgb.dump(bst, with_stats = true, dump_format='json') cat(jdump) produces: [ { ""nodeid"": 0, ""depth"": 0, ""split"": 28, ""split_condition"": -9.53674e-007, ""yes"": 1, ""no"": 2, ""missing"": 1, ""gain"": 4000.53, ""cover"": 1628.25, ""children"": [ { ""nodeid"": 1, ""depth"": 1, ""split"": 55, ""split_condition"": -9.53674e-007, ""yes"": 3, ""no"": 4, ""missing"": 3, ""gain"": 1158.21, ""cover"": 924.5, ""children"": [ { ""nodeid"": 3, ""leaf"": 1.71218, ""cover"": 812 }, { ""nodeid"": 4, ""leaf"": -1.70044, ""cover"": 112.5 } ]}, { ""nodeid"": 2, ""depth"": 1, ""split"": 108, ""split_condition"": -9.53674e-007, ""yes"": 5, ""no"": 6, ""missing"": 5, ""gain"": 198.174, ""cover"": 703.75, ""children"": [ { ""nodeid"": 5, ""leaf"": -1.94071, ""cover"": 690.5 }, { ""nodeid"": 6, ""leaf"": 1.85965, ""cover"": 13.25 } ]} ]}, { ""nodeid"": 0, ""depth"": 0, ""split"": 59, ""split_condition"": -9.53674e-007, ""yes"": 1, ""no"": 2, ""missing"": 1, ""gain"": 832.545, ""cover"": 788.852, ""children"": [ { ""nodeid"": 1, ""depth"": 1, ""split"": 28, ""split_condition"": -9.53674e-007, ""yes"": 3, ""no"": 4, ""missing"": 3, ""gain"": 569.725, ""cover"": 768.39, ""children"": [ { ""nodeid"": 3, ""leaf"": 0.784718, ""cover"": 458.937 }, { ""nodeid"": 4, ""leaf"": -0.96853, ""cover"": 309.453 } ]}, { ""nodeid"": 2, ""leaf"": -6.23624, ""cover"": 20.4624 } ]} ] and it could be further fed, e.g., into jsonlite: library(jsonlite) jdump %>% fromjson(simplifydataframe = false) %>% tojson(auto_unbox = true) %>% prettify </desc> <cmt> [r-package] json tree dump interface </cmt> <cmt> [r-package] precision bugfix in xgb.attributes </cmt> <cmt> [r-package] bugfix for cb.early.stop called from xgb.cv </cmt> <cmt> [r-package] a bit more clarity on labels checking in xgb.cv </cmt>",json dump format and a couple of bugfixes
1806,<desc> checks an items off #40675 the current mechanics are unstructured and the tests is not future proof (if new attributes are added tests will not pick these up and fail). this pr generalises the construction and future proofs the tests. no user facing cahnge. </desc> <cmt> create a cleaner copy mechanism and future proof tests </cmt> <cmt> add gh number </cmt> <cmt> name chg </cmt>,simplify styler copy mechanics and tests
1807,"<desc> fixes #26279. context: the dockcross/manylinux2014-aarch64 image provides a broken version of libstdc++ that (if statically linked), causes #26279 we need to use a version of dockcross/manylinux2014-aarch64 that has gcc newer than 4.8 (because otherwise we won't be able to build grpc c core, since the compiler would be too old). when a version of dockcross/manylinux2014-aarch64 that has gcc 4.9.4, the resulting wheel won't be manylinux2014 compliant since the libstdc++ is too new (but at the same time we can't statically link libstdc++ since we know that's broken for some reason). the only reasonable solution in short term seems to be to compromise on the level of binary compatibility and publish  manylinux_2_24 compliant wheels instead of manylinux2014 (see  (the armv7l wheels were suffering from the same problem as reported in #26279, so i'm removing static linking of libstdc++ for armv7 as well). </desc> <cmt> workaround #26279 at the expense of binary compatibility </cmt> <cmt> correctly tag aarch64 wheels as manylinux_2_24 </cmt> <iss> free(): invalid pointer crash on specific import order (on arm64 linux) </iss>",workaround #26279 by publishing manylinux_2_24 wheels instead of manylinux2014 on aarch64
1808,"<desc> summary of changes: made _iterate_slices abstract in base class, moved pre-existing definition from base -> series where it was actually being called (dataframe already overrides) made _wrap_transformed_output abstract in base class, as both series and dataframe override this redefined _wrap_applied_output; this was abstract in base class before but its definition was not in sync with how the subclasses actually defined renamed _wrap_output to _wrap_series_output as it is only valid for seriesgroupby renamed _wrap_generic_output to _wrap_frame_output as it is only valid for dataframegroupby renamed _aggregate_generic to _aggregate_frame as it is only valid for dataframegroupby more to come in separate prs </desc> <cmt> more abstractmethoderrors in base class </cmt> <cmt> removed _wrap_applied_output with wrong signature </cmt> <cmt> cleaned up naming conventions </cmt> <cmt> aggregate as abstractmethod </cmt>",clean up abstract and naming definitions for groupby
1809,"<desc> there are a few things to update in this chart. some of them have open prs, but unfortunately, the authors are not signing. bumping versions, not responding to reviews and so on. so this pr is to open the discussion and make drone chart up to date with fixing issues we already know. bump app version to 1.1.0 (a few of us tested it ok). fix grpc  (not in drone 1)  - this is also in #13866 but its incomplete, we need to remove services-grpc also. fix indentation of extracontainers pr: #14284 add drone_agents_enabled = true when it's not kuberentes enabled (agent). #13866 add tolerations #13866 i think set the drone_rpc_host in the server deployment it's important also, the pr  #12864 seems to be attended. by @morriz  - i ve bumped the chart version to  2.0.1 so we can merge this pr with the rc-15 before. dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> master uptodate </cmt> <cmt> bump versions (chart and app) </cmt> <cmt> bump app version </cmt> <cmt> fix drone_rpc_server with no rpc and </cmt> <cmt> if its not k8s enabled set drone_agents_enabled </cmt> <cmt> fix indentation of extracontainers pr:#14284 </cmt> <cmt> no grpc in drone 1.0 </cmt> <cmt> bumb chart version to 2.0.0-rc.15 </cmt> <cmt> add tolerations #13866 </cmt> <cmt> add tolerations documentation #13866 </cmt> <cmt> bump chart version to 2.0.1 </cmt>",bump app version - fix grpc - and other unattended pr's.
1810,"<desc> the general principle here is ""if you're going to show line/column, you want a display filename, not a buffer identifier"". follow-up to #19022; thanks to @davidungar and @codafi for reminding me to go check on other issues. review requests: @anemet for the optimization record change @nkcsgexi for the ide/sourcekit/parse changes @douggregor for the run-time error message change i filed sr-8662 for a case where sourcekit may or may not be doing the wrong thing. there are also still a few suspicious uses of getidentifierforbuffer that i'm not sure about, all of which happen to be in @nkcsgexi's components: swift::writeeditsinjson is using offsets rather than line/column numbers, but i'm not sure what it would want to do for #sourcelocation or the vfs swift::ide::getlocationinfo is also using offsets rather than line/column numbers, but ""location info"" sounds like something that needs to be displayed to the user fixitapplydiagnosticconsumer::handlediagnostic is going to rewrite buffers directly, but it's unclear whether doing that is the right thing for code using #sourcelocation (similar to sr-8662, but for migration). groupnamecollectorfromjson::getgroupnameinternal is only used when building the standard library, but it should probably honor #sourcelocation. i just didn't want to touch it without being sure, and it's not immediately relevant. </desc> <cmt> [ide] honor #sourcelocation in comment-to-xml conversion </cmt> <cmt> [ide] honor #sourcelocation in swift-ide-test's comment printing </cmt> <cmt> [sourcekit] honor #sourcelocation in reporting diagnostics </cmt> <cmt> [silgen] honor #sourcelocation for run-time error messages </cmt> <cmt> we use this when an optional unwrap fails and when a swift-3-style </cmt> <cmt> @objc entry point is used. </cmt> <cmt> [sil] honor #sourcelocation in optimization record yaml files </cmt> <cmt> previously, we were using the physical buffer name but the virtual </cmt> <cmt> line number, which is bogus. </cmt> <cmt> stop using sourcemanager::getbufferidentifierforloc to find buffer ids </cmt> <cmt> the right way is findbuffercontainingloc. getbufferidentifierforloc is </cmt> <cmt> both slower and wrong in the presence of #sourcelocation. </cmt> <cmt> i couldn't come up with a test for the change in ide/utils.cpp because </cmt> <cmt> refactoring still seems to be broken around #sourcelocation. i'll file </cmt> <cmt> bugs for that. </cmt> <cmt> remove sourcemanager::getbufferidentifierforloc </cmt> <cmt> and tidy up doc comments for other methods that do or don't respect </cmt> <cmt> '#sourcelocation'. </cmt> <cmt> 'getbufferidentifierforloc' is no longer useful: it doesn't </cmt> <cmt> consistently return either the name of an actual buffer or the name of </cmt> <cmt> a file suitable for diagnostics. as seen in the previous commit, all </cmt> <cmt> remaining uses of it were wrong anyway. remove it. </cmt>",honor #sourcelocation filenames in several more places
1811,"<desc> with these modifications and the partially masked test, the r package xgboost 0.6 has been submitted to cran. </desc> <cmt> fix cran check </cmt> <cmt> change required r version because of utils::globalvariables </cmt> <cmt> merge back </cmt> <cmt> temporary commit, monotone not working </cmt> <cmt> fix test </cmt> <cmt> fix doc </cmt> <cmt> fix doc </cmt> <cmt> merge back </cmt> <cmt> merge back </cmt> <cmt> fix cran note and warning </cmt> <cmt> improve checks </cmt> <cmt> fix urls </cmt> <cmt> merge back </cmt> <cmt> fix cran check </cmt>",fix for cran submission of xgboost 0.6
1812,"<desc> this depends on #6635 #6655 #6637. the macos sdk path and version was made configurable, so one can overwrite the autodetected values in the case of fail detection and none apple toolchains. with the removal of optional force unwrappings we broke building on macos 10.12, this is fixed before the migration to swift 5/4 the swift 5 migration was tested on various platforms and combinations of toolchains. building works with all apple provided toolchains from 10.12.6/xcode 9.1/swift 4 onwards. in some combinations the swift 5 toolchains from swift.org work too. i tired to keep all compatibility stuff in a separate file. that way it's less intrusive and can easily be removed later when unneeded. success: macos 10.12.6	sdk10.13		xcode 9.2	swift 4.0.3 macos 10.13.6	sdk10.13		xcode 9.4	swift 4.1.2 macos 10.13.6	sdk10.14 (manually)	xcode 9.4	swift 5 (swift.org toolchain) macos 10.13.6	sdk10.14		xcode 10.1	swift 5 (swift.org toolchain) macos 10.14.4	sdk10.14		xcode 10.2	swift 5 fail: macos 10.12.6	sdk10.14 (manually)	xcode 8.3.3	swift 5 (swift.org toolchain) macos 10.12.6	sdk10.14 (manually)	xcode 9.1	swift 5 (swift.org toolchain) macos 10.13.6	sdk10.13		xcode 9.4	swift 5 (swift.org toolchain) the swift.org toolchain can be used like this. sdk path and version might need to be specified depending on your installed xcode version export toolchains=swift macos_sdk=""path/to/sdk10.14.4"" macos_sdk_version=""10.14.4"" ./waf configure no rebase of the existing pr since the changes made afterwards made rebasing a pain, and because a lot of work was put into it to make the build actually work on older setups. the code also got a style improvement. tests are appreciated. </desc> <cmt> build: don't check for swift when disabled </cmt> <cmt> build: add all configure flags as conditional flags to swift compiler </cmt> <cmt> build: add support for swift toolchains not provided by apple </cmt> <cmt> the xcode-select tool only properly works with apple provided toolchains </cmt> <cmt> but not with third party ones from swift.org. in the latter case the </cmt> <cmt> swift compiler executable is found in the proper path but the swift libs </cmt> <cmt> from the xcode or command line tools will be picked. this leads to a </cmt> <cmt> not wanted discrepancy of the swift compiler and libs and possible </cmt> <cmt> errors. </cmt> <cmt> instead of relying on the xcode-select tool search for the libs relative </cmt> <cmt> to the swift executable. that relative path seems to be the same for all </cmt> <cmt> toolchains. if for any reasons a swift executable is not found in the </cmt> <cmt> relative path, fall back to the old xcode-select method. </cmt> <cmt> furthermore, both static and dynamic libs will be searched for but only </cmt> <cmt> the former will be used for now. this is a preparation for the upcoming </cmt> <cmt> swift 5 migration. </cmt> <cmt> build: make swift lib and compiler paths configurable via env vars </cmt> <cmt> build: add swift dynamic linking support </cmt> <cmt> this is in preparation for the upcoming swift 5 transition, where static </cmt> <cmt> linking was replaced by dynamic linking the swift libraries as the </cmt> <cmt> preferred way, by apple. furthermore apple removed the static swift libs </cmt> <cmt> from their dev tools starting with xcode 10.2/swift 5. </cmt> <cmt> because of abi incompatibility dynamic linking for swift versions prior </cmt> <cmt> to 5 doesn't use the system lib path for the dynamic swift libs. </cmt> <cmt> for now static linking is still the default, but that will be changed </cmt> <cmt> when swift 5 support is added and swift 3 support is dropped. </cmt> <cmt> fixes #6232 </cmt> <cmt> osxbundle: print the output of the dylib-unhell call </cmt> <cmt> osxbundle: bundle the dynamic swift std library when needed </cmt> <cmt> build: add check for macos sdk version </cmt> <cmt> this provides an easy way to check for a specific macos sdk version and </cmt> <cmt> with that the availability of features. </cmt> <cmt> cocoa-cb: conditional compilation for dark mode and material features </cmt> <cmt> fixes #6621 </cmt> <cmt> build: make macos sdk path and version configurable via env vars </cmt>",migrate to swift 5 with swift 4 fallback
1813,<desc> this change fixes a race condition in shard group failure callbacks and ensures that we set the correct flag on initial stored responses. relates #49931 closes #53360 </desc> <cmt> fix race condition in shard group failure callback </cmt> <cmt> shard group failure callbacks should be executed before incrementing </cmt> <cmt> the total operations. this is required to ensure that we don't notify </cmt> <cmt> a shard group failure **after** the completion callback. </cmt> <cmt> fix the initial response stored in async search index </cmt> <cmt> this change ensures that we set the isrunning flag to false </cmt> <cmt> when storing the initial response of an async search request. </cmt> <cmt> remove the awaits fix </cmt> <cmt> disable cacheability of blockquerybuilder </cmt> <iss> [ci] asyncsearchactiontests fails unpredictably </iss>,fix sporadic failures in asyncsearchasynctests
1814,<desc> in zipimport.c: add a check whether zlib.decompress() returned a bytes object. in test_zipimport.py: add a test to verify that the assertion failure is no more. </desc> <cmt> init commit </cmt> <cmt> fix news.d item </cmt> <cmt> add @cpython_only </cmt> <cmt> use zip_deflated explicitly in the test </cmt>,fix an assertion failure in zipimporter.get_source() in case of a bad zlib.decompress()
1815,"<desc> there are some reports of zonewindowdrawing instances failing to initialize. this refactoring should make debugging that easier. pr checklist applies to #xxx cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request validation steps performed run fz and make sure it works. </desc> <cmt> separate a big function call to several functions </cmt> <cmt> formatting </cmt>",refactor a function in zonewindowdrawing
1816,"<desc> fixes #6575 microsoft reviewers: open in codeflow </desc> <cmt> use whitespace insensitive compare for indentical override detection </cmt> <cmt> fixes #6575 </cmt> <cmt> change files </cmt> <iss> ""identical override"" detection should be whitespace insensitive instead of line ending insensitive </iss>",use whitespace insensitive compare for identical override detection
1817,"<desc> hi, i am improving the oal based on @arugal 's new pr, . now, i could split the one and only official_analysis.oal into separated files, including core jvm dotnet envoy core is also active due to trace, mesh, or so11y. others are not activated when the receivers are open. </desc> <cmt> split the official_analysis.oal into different parts </cmt> <cmt> add envoy oal define. </cmt>",make oal controlled by the receivers.
1818,<desc> this continues the work on splitting up const_fn into separate feature flags: const_fn_trait_bound for const fn with trait bounds const_fn_unsize for unsizing coercions in const fn (looks like only dyn unsizing is still guarded here) i don't know if there are even any things left that const_fn guards... at least libcore and liballoc do not need it any more. @oli-obk are you currently able to do reviews? </desc> <cmt> move 'trait bounds on const fn' to separate feature gate </cmt> <cmt> separate feature flag for unsizing casts in const fn </cmt>,further split up const_fn feature flag
1819,"<desc> the fieldmapper infrastructure currently has a bunch of shared parameters, many of which are only applicable to a subset of the 41 mapper implementations we ship with.  merging, parsing and serialization of these parameters are spread around the class hierarchy, with much repetitive boilerplate code required.  it would be much easier to reason about these things if we could declare the parameter set of each fieldmapper directly in the implementing class, and share the parsing, merging and serialization logic instead. this commit is a first effort at introducing a declarative parameter style.  it adds a new fieldmapper subclass, parametrizedfieldmapper, and refactors two mappers, boolean and binary, to use it. parameters are declared on builder classes, with the declaration including the parameter name, whether or not it is updateable, a default value, how to parse it from mappings, and how to extract it from another mapper at merge time.  builders have a getparameters method, which returns a list of the declared parameters; this is then used for parsing, merging and serialization. merging is achieved by constructing a new builder from the existing mapper, and merging in values from the merging mapper; conflicts are all caught at this point, and if none exist then a new, merged, mapper can be built from the builder.  this allows all values on the mapper to be final. other mappers can be gradually migrated to this new style, and once they have all been refactored we can merge parametrizedfieldmapper and fieldmapper entirely. </desc> <cmt> first go: need to fix merging with buildercontext </cmt> <cmt> dedicated tests for parametrized mapper </cmt> <cmt> tests </cmt> <cmt> precommit </cmt>",add declarative parameters to fieldmappers
1820,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> types for css-to-react-native </cmt> <cmt> fix test file </cmt> <cmt> fix prettier </cmt> <cmt> fix defs by </cmt>",css to react native types
1821,"<desc> this should be pretty straight forward. my only concern are changes in cguicontrolfactory - is it safe to not set fallback navigation there? we won't do anything if action list is empty. this change is needed to set navigation using replace=false flag (we can't set actions because list isn't empty - fallback navigation is there) </desc> <cmt> don't assign navigation path to itself if <onx> isn't specified </cmt> <cmt> action list will be empty so we won't execute anything anyway </cmt> <cmt> add cguicontrol::setnavigationaction to allow setting single action, add cguiaction(int controlid) ctor to quickly create navigation action </cmt> <cmt> redo applying navigation to grouplist child controls </cmt> <cmt> fixes conditional navigation in grouplist </cmt>",fix conditional navigation in grouplist
1822,"<desc> if keepinview is enabled, a listener for moveend is set to the map: leaflet/src/layer/popup.js line 163 in 3466cbb events.moveend = this._adjustpan; _adjustpan calls panby: leaflet/src/layer/popup.js line 276 in 3466cbb .panby([dx, dy]); and then _resetview is called because the popup latlng/ offset is not in the map size (and animate is not set), in _resetview the moveend event is fired without panning the map and then moveend event ist fired from keepinview and it is starting again. leaflet/src/map/map.js lines 322 to 325 in 3466cbb if (options.animate !== true && !this.getsize().contains(offset)) { this._resetview(this.unproject(this.project(this.getcenter()).add(offset)), this.getzoom()); return this; } to prevent this, we can add to the panby call in _adjustpan the option {animate: true}. this will force that _resetview can't be called and we don't end up in a recursive call. this will only happen if the function _adjustpan is called over the moveend event, so i add animate: true if the event object is set. maybe this is not the best way but would be a solution. fix: #5035 </desc> <cmt> fix keepinview recursion #5035 </cmt> <cmt> fix test </cmt> <iss> calling fitbounds with a keepinview: true popup present can cause leaflet to lock up </iss>",fix popup keepinview if the map needs to panned over a long distance
1823,<desc> this pr removes the margin-top from the dropdown toolbar and sets the height of the list items to 32px so that it is properly centered via flexbox. i additionally centered the restart icon as it was off-center before. before after fixes #51569 </desc> <cmt> vertically center the restart icon </cmt> <cmt> remove top margin and set height for flexbox to vertically align dropdown </cmt> <cmt> clean up svgs </cmt> <iss> dropdown in debug toolbar is not vertically centered </iss>,center dropdown in debug toolbar
1824,"<desc> note: we're experiencing a high volume of prs to this repo and reviews will be delayed. please host your own chart repository and submit your repository to the helm hub instead of this repo to make them discoverable to the community. here is how to submit new chart repositories to the helm hub. fix the issue of wrong typos in 57858d7 (0a8651f) upgrade mysql image version to 5.7.30 (changes in mysql 5.7.30 (2020-04-27, general availability)) upgrade busybox image version to 1.31.1 (25 october 2019 -- busybox 1.31.1 (stable)) upgrade dduportal/bats image version to 1.1.0 (release notes) (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #22253 dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> fix typos in deployment template </cmt> <cmt> mysql to 1.6.4 version </cmt> <iss> [stable/mysql] typo in deployment.yaml </iss>",mysql chart version bump to 1.6.4
1825,"<desc> adds rgb functionality to keymap.  can be compiled against both master and develop branch keymap changes - adds rbg control keys in fn layer similar to glorious core default fn keys encoder changes - fn layer - change rgb idle timeout - holding left shift, change layers - holding right shift, navigate page up/down new led/rgb functionality - rgb idle timeout (default 5 minutes) - can be changed in fn layer with < and > or encoder - setting to zero disables timeout - indicators in fn layer using rgb in fn and number rows to show the timeout in minutes - led address location map as enum definition - led group arrays for arrows, numpad, f row, num row, left and right side leds - default startup in single mode with default colour - capslock, scroll lock, and num lock (not set) indicator on left side led - layer indicator on right side led - fn key light up red when fn layer activate - win key light up red when win lock mode enabled - layer 2 activation lights up numpad area my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add rgb functions; compatible with master/develop </cmt> <cmt> readme update </cmt>",jonavin gmmk pro keymap add rgb functionality
1826,"<desc> in the other classes (pixmappackerio) there is a useindexes flag, but i can't see anything that this could be added to. in pixmappackerio there is parameters that it can be added to, but i'm not seeing an obvious comparison in pixmappacker. alternative idea would be to overload the method, so that the original signature is still available to people, but now it could include the option to pass through useindexes, rather than having it set to true as default. (personally i think it should be true as default, as this doesn't break anything, unless you intentionally call your image files _01.png, _02.png on purpose and don't do that for animations. </desc> <cmt> [pixmap packer io] added index based on file name, so can be used for animations </cmt> <cmt> update pixmappackerio.java </cmt> <cmt> default useindexes to false. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> - added indexes for animations to work in updatetextureatlas </cmt>",added index usage in pixmappacker for updatetextureatlas (currently missing so can't create animations)
1827,"<desc> that seems to have been an old hack. instead, let sbrk/brk handle it themselves, as they otherwise do all the handling of that value. this is also important for pthreads, since sbrk/brk can do this atomically, while if the logic is split into a called function that's much less clean. </desc> <cmt> don't update the sbrk location in emscripten_resize_heap() - leave that to sbrk, which does it anyhow </cmt> <cmt> fix </cmt>",don't set *dynamictop_ptr in memory growth code
1828,<desc> win: implement double-clicked event. win: fix regression caused by #2328 that bounds is always empty. win: pass modifers in clicked events. use the dom's way of telling modifiers. </desc> <cmt> win: implement double-clicked event </cmt> <cmt> docs: don't say things that are expected </cmt> <cmt> win: set guid when getting icon's bounds </cmt> <cmt> win: pass modifers in 'clicked' events </cmt>,fix a few things of tray
1829,"<desc> this fixes the same problem as #3310 but in a slightly different way: instead of maintaining the minimum resources needed by tasks in the ready queue and skipping going over the tasks there, it keeps an index on which resource shape a task is from, which makes it fast to determine which tasks are of a given resource shape. this pr implements the simplest version of this idea and there is a number of refinements that could be applied (avoiding the task copies, implementing a more clever strategy to avoid head-of-line blocking). it has the advantage over #3310 int that the datastructure allows o(1) in determining which tasks to dispatch (although it currently is more expensive than that, but cheaper than in the master, and also cheaper than in the other pr; the strategy there would break down if the ready queue contains zero-resource tasks). it can also facilitate smarter head-of-line blocking avoidance in the future. it has the disadvantage that it doesn't preserve approximate fifo order like the other pr does. closes #3194 closes #3188 </desc> <cmt> put queues outside </cmt> <cmt> working version, still needs to be optimized </cmt> <cmt> implement round robin </cmt> <cmt> proper round robin </cmt> <cmt> fix spillback </cmt> <cmt> update </cmt> <cmt> fix </cmt> <cmt> cleanup </cmt> <cmt> more cleanups </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> add documentation </cmt> <cmt> explanation for hash combiner </cmt> <iss> task submission is extremely slow when many tasks are queued. </iss> <iss> task dispatch iterates over entire task queue even when no resources are left </iss>",ready queue refactor to make dispatching tasks more efficient
1830,"<desc> this breaks a potential deadlock between worker requests for objects (through ray.get or ray.wait) and arguments of queued tasks, when the amount of memory is limited. see #14886 for more details. the fix is to split the request queue in the pullmanager into two queues, one for requests made by a worker and one for arguments of a queued task. the interface is pretty much the same as before, but the implementation is a bit more complicated because requests can now be served out-of-order (e.g., if a worker request is submitted after a task request). closes #14886. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> split queues </cmt> <cmt> regression test </cmt> <cmt> unit tests </cmt> <iss> ray.get fetches not prioritized in pullmanager (can lead to deadlock with pull manager memory capping) </iss>",prioritize worker requests for objects over queued task arguments
1831,"<desc> description: as promised, here is a pr to switch homekit controller over to use config entries, which i'm hoping is ready for 0.94. (if this pr is ready before 0.93 leaves beta, please don't cherry pick it into 0.93. we are waiting for 0.94). i am aware of #23802 and that i'll potentially need to rebase if that is merged first. the config flows themselves were already added a few releases ago, this adds the async_setup_entry handlers and enables the flows, and removes the old configurator code. there is currently no configuration.yaml stuff for homekit controller so we don't try to preserve the old setup_platform entry points. we have pretty high test coverage (on the tip of my dev branch which has a few extras its >98% for all modules) for config flow and the entities in general - we just have to update common and all the tests carry on working with the new code. this doesn't add device registry stuff, but i already have a branch lined up with device registry support ready to go after this. also, after this is merged i can also remove homekit_controller from .coveragerc. @martinhjelmare sorry to tag you directly, but you've had some really good feedback for me before and as this is probably the biggest change i've submitted i was hoping i could trouble you for some here as well checklist: local tests pass with tox. your pr cannot be merged unless tests pass new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> fix user initiated pairing + show more user friendly name </cmt> <cmt> add lock around async_refresh_entity_map </cmt> <cmt> migrate homekit_controller to config entries. </cmt>",adopt config entries for pairing with homekit accessories
1832,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry in testing.pyx we keep a list of numeric dtypes and use that for type checking. but we have functions that do this in tslibs/util.pxd so it's better to use those instead </desc> <cmt> implement is_real_number_object </cmt> <cmt> use is_real_number_object in testing.pyx </cmt> <cmt> rename is_comparable_as_number -> is_comparable_as_real_number </cmt>",de-duplicate numeric type check in _libs/testing
1833,<desc> this pr creates a new system of onboarding for the aws lambda node integration that involves installing an integration instead of setting up the sdk. pre-installation view: post-installation view: </desc> <cmt> adds integration setup </cmt> <cmt> fix </cmt>,adds integration setup to onboarding
1834,"<desc> added the sentraq number pad keyboard kit to qmk in the sentraq vendor directory. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> added qmk config for sentraq number pad keyboard. </cmt> <cmt> sentraq number pad documentation cleanup. </cmt> <cmt> mend </cmt> <cmt> added json for configurator. </cmt> <cmt> small documentation tweaks. </cmt> <cmt> updated the layouts to use the default layouts that match. </cmt> <cmt> uncommended user level functions in keymap, left custom keycode/macro code commented but documented why. </cmt> <cmt> switched to #pragma once from #ifndef structure in header file. </cmt> <cmt> moved sentraq number pad to sentraq creator directory. </cmt> <cmt> renamed sentraq_number_pad to number_pad now that it's nested in the sentraq directory. </cmt> <cmt> updated references inside the files for the keyboard rename and nesting. </cmt>",sentraq number pad rgb diy kit
1835,"<desc> load the docs part of rendering + the docs page/container lazily in webpreview. results for react-ts, this reduced: initial development bundle from 12.6mb -> 11.1mb = 14% saving initial production bundle from 5.5mb -> 4.8mb = 13% saving caveats / questions this adds a dependency on @storybook/addon-docs from @storybook/preview-web. we might want to make it an optional peer dep? changing parameters.docs.container/page to be strings (or maybe symbols?) is technically a breaking change. i'm not sure anyone would look at them directly. we might want to feature flag this? changing parameters.docs.container/page to be getcontainer/page is technically a breaking change. i'm not sure anyone would look at them directly. we might want to feature flag this? i guess it shows up on bundle size tracking somewhere? </desc> <cmt> split docs rendering from previewweb </cmt> <cmt> don't set docs container etc as parameters </cmt> <cmt> so we don't need to import docs in a preview config entry. </cmt>",lazy load docs to reduce bundle size
1836,<desc> this uses the new fuzzaldrin library for core scoring and fuzzy filtering so it can be used in packages freely. refs #950 </desc> <cmt> replace stringscore/fuzzy-filter with fuzzaldrin </cmt> <cmt> upgrade to settings-view@0.29.0 </cmt>,extract string score and fuzzy filter
1837,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fix segmentation fault when the table has skip indices and vertical merge happens. </desc> <cmt> trying to fix vertical merge </cmt> <cmt> remove redundant changes </cmt> <cmt> remove redundant changes </cmt>,fix segmentation fault in vertical merge with skip indices
1838,<desc> related issue #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> fix mypy error for frequent_pattern_graph_miner.py </cmt> <cmt> fix mypy error for markov_chain.py </cmt>,fix type annotations for graphs
1839,<desc> add info.json change keymap to layout change #includes to qmk_keyboard_h added note on how to fix the flickering in switch lighting problems </desc> <cmt> add additional readme notes on how to fix the flickering backlight issue </cmt> <cmt> add qmk configurator support </cmt>,add qmk configurator support for org60
1840,"<desc> this should close #10339 also fixes some coverity issues in canvas.c: if the realloc() inside expand_line fails, instead of freeing the entire canvas, just abort the write, or else all future writes will fail (and from what i understand there were many defects just for this problem) before considering merging, i would like to wait to check if #10339 is really fixed (i was only able to reproduce it in a virtual machine) </desc> <cmt> fix crop utf8 in canvas </cmt> <cmt> fix coverity defects </cmt> <iss> v! glitches when scroll horizontally </iss>",fix panels horizontal scroll glitch + fix some coverity defects
1841,"<desc> addresses tr-356 feature: updated the design of the modal shown when there is a new version of cypress available. added 'copy to clipboard' buttons for upgrade commands. before (project mode) before (global mode) after (project mode) after (global mode) n/a has the original issue been tagged with a release in zenhub? n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? </desc> <cmt> start test server automatically </cmt> <cmt> update footer design </cmt> <cmt> remove update banner </cmt> <cmt> remove more references to update banner </cmt> <cmt> add source param to changelog links </cmt> <cmt> remove padding right on footer </cmt> <cmt> blur footer buttons after clicking </cmt> <cmt> redesign update modal, add copy to clipboard </cmt> <cmt> abstract lifecycle hooks usage </cmt>",redesign desktop gui updates modal
1842,"<desc> what did you implement: closes #2981 how did you implement it: catch the error, then check for specific error message ""no updates to be performed"".  continue execution if it is this message, otherwise throw the error to be caught by the next error handler how can we verify it: re-deploy an already deployed service without any changes and verify that it does not error out with error code 1 service: service provider: name: aws runtime: nodejs4.3 # remove need for functions so that a re-deploy will bring up the error #functions: #  hello: #    handler: handler.hello resources: resources: s3bucket: type: ""aws::s3::bucket"" todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources change ready for review message below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> do no fail when a stack requires no updates </cmt> <cmt> do no fail when a stack requires no updates </cmt> <cmt> resolve(data) </cmt> <cmt> added period to message </cmt> <cmt> new attempt </cmt> <cmt> added comment </cmt> <cmt> updated comment </cmt> <cmt> handle error </cmt> <cmt> fix lint errors </cmt> <cmt> add tests and small refactor </cmt>","fix ""no updates to be performed."" throwing error code 1"
1843,"<desc> update docs branch with #11920 #12890 #12981 #13036 #13050 </desc> <cmt> researching docker hub account linking and automated builds details </cmt> <cmt> (cherry picked from commit a55f8e1ce734035a77cc13d1e2f42dbef41d418e) </cmt> <cmt> update the docker hub account, org and group documentation and images </cmt> <cmt> (cherry picked from commit 5cec69a7b3ea12f9595e017eb27826ff9ad2962b) </cmt> <cmt> spelling fix from marc merlin </cmt> <cmt> (cherry picked from commit bba5fd8caa35d5edf8b68e593eafb277394a6989) </cmt> <cmt> add a userguide to cover the uses of hub before creating new repositories </cmt> <cmt> (cherry picked from commit 9da3a848abea56dff960baa8428dc073b70ec1de) </cmt> <cmt> conflicts: </cmt> <cmt> docs/sources/docker-hub/index.md </cmt> <cmt> docs/sources/docker-hub/repos.md </cmt> <cmt> dhe documentation update </cmt> <cmt> (cherry picked from commit 59bfee2fa4f178660fa4cb2a9d18c924e86595a7) </cmt>",post 1.6.1 docs refresh of hub and dhe docs (on docs branch)
1844,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). add src parameters:  fix invalid argument definitions:  include tests for your changes </desc> <cmt> update apidoc-tests.ts </cmt> <cmt> fix apidoc argument typings </cmt> <cmt> update apidoc-tests.ts </cmt>,fix wrong args + add src param
1845,<desc> edited 3 buttons to tertiary styling. includes db migration (follow approval process in sip-59) </desc> <cmt> changed margin right on warning icon to 8px </cmt> <cmt> fixed to grid units from pixels </cmt> <cmt> changed three buttons styles to tertiary </cmt>,three button styles to tertiary
1846,"<desc> this pr makes the tf longformer-like models compliant with amp. all the slow tests are passing as well for these models. these two models cannot be xla compliant for now, as it seems that tf.where cannot be used in xla if the x and y parameters are none. see the _get_global_attn_indices method which has this case. i have opened an issue on the tf repo in order to ask if it is an expected behavior or a bug. </desc> <cmt> amp </cmt> <cmt> add led </cmt> <cmt> apply style </cmt>",making tf longformer-like models compliant with amp
1847,"<desc> partially fixes #14312 fixes the following items: fastica, [whitening_] the matrix projecting data onto the first principal components. fastica, [mean_] the mean over features nmf, [n_components_] this attribute is same to the n_components parameter if it was set. otherwise, it is same with n_features gaussianrandomprojection, [n_components_] just a typo fixed: n_component_ -> n_components_ sparserandomprojection, [n_components_] just a typo fixed: n_component_ -> n_components_ pca, [n_features_] the number of features in the data matrix the pca transformer was fitted on. pca, [n_samples_] the number of samples in the data matrix the pca transformer was fitted on. </desc> <cmt> update documentation to nmf </cmt> <cmt> describe the n_components_ attribute in addition to n_components parameter. </cmt> <cmt> the will differ it no n_components value given to the constructor. </cmt> <cmt> fix typo in docstring for gaussianrandomprojection </cmt> <cmt> there is an attribute named n_components_, not n_component_ </cmt> <cmt> update docstring for sparserandomprojection </cmt> <cmt> the n_components_ attribute was referred to as n_component_ </cmt> <cmt> update docstring for fastica </cmt> <cmt> document the fastica.mean_ attribute. </cmt> <iss> ensure all attributes are documented </iss>",fix attribute mismatches in documentation strings.
1848,"<desc> you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like searched for similar pull requests what is the purpose of your pull request? description of your pull request and other information an experimental p/invoke based system proxy implementation. main goal is remove all blob in net-core version. </desc> <cmt> backport wininet from shadowsocksrr </cmt> <cmt> migrate to wininet </cmt> <cmt> drop sysproxy </cmt> <cmt> platform and required service check for wininet </cmt> <cmt> toggle menu item enable by wininet state </cmt>",drop sysproxy.exe in net-core version
1849,"<desc> add native support for cpu 128 float.  cupy doesn't have float128, and cuda treats long double as double in device code. convert boolean and float16 in python. the c api for constructing dmatrix from numpy array added in #6998 is renamed from array to dense for consistency. close #6999 . </desc> <cmt> error message. </cmt> <cmt> change c api name. </cmt> <cmt> test for all primitive types from array. </cmt> <cmt> * add native support for cpu 128 float. </cmt> <cmt> * convert boolean and float16 in python. </cmt> <iss> libxgboost.so: undefined symbol: xgboostergetstrfeatureinfo </iss>",support for all primitive types from array.
1850,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. class socket extends eventemitter  client#conn, socket#conn is an instance of engine.socket, including properties ""request"" and ""upgraded"".    increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> class socket extends eventemitter </cmt> <cmt>  </cmt> <cmt> client#conn, socket#conn is an instance of engine.socket, including properties ""request"" and ""upgraded"". </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> add a test. </cmt> <cmt> add my credit. </cmt>","[socket.io]more information of class ""socket"""
1851,"<desc> takes 'churn_rates"" data from rabbitmq api/overview and adds the chart to netdata front end.  the structure of the data parser enables a simple addition of the metrics that are needed to the existing data structures. </desc> <cmt> added chart for churn rates of connections, channels, and queues </cmt> <cmt> clear comments </cmt>",add chart for churn rates
1852,"<desc> set settings.enablebytecodecacheing to true in the reactinit.cpp file to enable this feature. default will be false. helps with reducing boot up time. microsoft reviewers: open in codeflow </desc> <cmt> added basic script store </cmt> <cmt> add basic prepared script store </cmt> <cmt> added code for script store and trygetpreparedscript </cmt> <cmt> added ability to read and write buffer from/to local file </cmt> <cmt> changed code style to match other files in utils folder </cmt> <cmt> made writing bytecode generate appropriately sized file, removed wrappers from bytecode manager </cmt> <cmt> made reading and writing work, removed unneeded wrapper </cmt> <cmt> set default bytecode caching to false </cmt> <cmt> address comments </cmt> <cmt> merge master </cmt> <cmt> use modified date not created </cmt>",implemented uwp scriptstore and preparedscriptstore to allow caching scripts as bytecdoes
1853,<desc> since the are already in tasmota arduino core 2.7.4.1 the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> delete core_esp8266_waveform.cpp </cmt> <cmt> delete core_esp8266_waveform.h </cmt> <cmt> delete core_esp8266_wiring_digital.cpp </cmt> <cmt> delete core_esp8266_wiring_pwm.cpp </cmt>,remove redundant arduino core files from tasmota...
1854,"<desc> renamed outdep to out_dep. added a simple test for .d files generated from -mmd. </desc> <cmt> fixed dependency files not being saved away if using -mmd or similar. </cmt> <cmt> fixed timestamps on object files extracted from archives during link. </cmt> <cmt> this affects builds that use absolute paths to object files when adding to library archives, causing unnecessary archives. </cmt> <cmt> renamed outdep to out_dep. </cmt> <cmt> added test for change for issue #1732. </cmt>",further changes for issue #1732
1855,"<desc> another step towards #3016. fixes #4216. changes in this pr: removes lightgbm-custom pointers to r data (r_real_ptr(), r_int_ptr()) with the standard equivalents from rinternals.h (real(), integer()) converts arguments on the c++ side that are accessed that way from lgbm_se to sexp description r is a dynamically-typed language. you can run code like x <- c(1, 2, 3) without declaring that x is a numeric array, and r will just figure it out. r makes this possible by storing data for an object in a structure called a sexprec. that structure will contain different data based on the r class (integer, character, function, etc.). libraries can reference that data in c code using a type, sexp, provided by rinternals.h. libraries can also get a pointer to a particular type of data within a sexprec using other functions provided by rinternals.h, for example real() to get a pointer to its numeric data. as described in #4216, the internal details of the sexprec struct can change between different versions of r. sexp is the official r api into that struct, and by using it libraries can reliably stay compatible with multiple r versions. this pr's changes fix a bug that currently exists when using {lightgbm} with r 3.6, and protects {lightgbm} from similar bugs in the future. for more details on this, see  notes for reviewers this pr does not depend on #4242 or #4247 </desc> <cmt> real pointer for matrix </cmt> <cmt> remove r_real_ptr </cmt> <cmt> remove r_int_ptr </cmt> <cmt> add test </cmt> <iss> (r) functions that replace r headers are not compatible with all r versions </iss>",use r standard routines to access numeric and integer array data in c++
1856,<desc> first commit is just for debugging. it revealed that something is leaking memory after each compilation and it's unclear what. review with whitespace ignored. this leak leads to #28923 failing size:snapshot. though we can live with the leak for now since azure pipelines have 7gb of ram so we can just increase max-old-space-size to 4gb (up from 2) </desc> <cmt> limit concurrency </cmt> <cmt> increase memory limit </cmt>,increase memory limit for size:snapshot
1857,"<desc> original pull-request #24898 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> allowed s3 key to be empty. </cmt> <cmt> fixed unit tests accoording to the fix. </cmt> <cmt> fix. </cmt>",fixed bug with declaring s3 disk at root of bucket
1858,"<desc> this adds a new conf true/false option to allow the user to draw message lines that begin and end at same place as right angles, rather than curved lines. </desc> <cmt> created option for right angle arrows </cmt> <cmt> make path a bit wider </cmt> <cmt> tweak for lint </cmt>",add option for right angles
1859,<desc> new features apis cherry pick 4 amp related pr into 2.0 branch: 29756 29621 29597 29562 </desc> <cmt> optimizer trans momentum (#29597) </cmt> <cmt> * merge amp related function in momentum from paddle.fluid.contrib.optimizer into paddle.optimizer. </cmt> <cmt> * add unittest for 2.0  momentum api. </cmt> <cmt> * fix some bugs in weight_decay. </cmt> <cmt> add alias for fluid.contrib.mixed_precision (#29562) </cmt> <cmt> * add alias for fluid.contrib.mixed_precision </cmt> <cmt> add static.amp into setup.pu.in (#29621) </cmt> <cmt> * add static.amp into setup.pu.in </cmt> <cmt> * add unittest for api </cmt> <cmt> fix a bug in multi_precision_fp16 unittest. (#29756) </cmt>,amp related pr cherry pick into release/2.0
1860,"<desc> this is just a small change to reduce the time some of the tests take.  it decreases the time around 20-30 seconds depending on run.  small improvement but we have to start somewhere. i'm just going through the tests logs and looking at the longer tests and seeing if they first make sense, if they are duplicated, and what we could change to make them faster without losing functionality. </desc> <cmt> remove build 60 steps </cmt> <cmt> this test is already covered in the individual graph driver tests and it </cmt> <cmt> adds 15s to the test run without adding value.  the original idea was to </cmt> <cmt> test max number of layers, this is fulfilled by the graph drivers. </cmt> <cmt> make network stats version test concurrent </cmt> <cmt> this change makes the test run go down from 10s to 2s </cmt> <cmt> change number of pings to 1 </cmt> <cmt> this cuts the test time down from 6s to 2s </cmt> <cmt> decrease sleep to 2 seconds </cmt>",test improvements to reduce time for long running tests
1861,"<desc> this pull request adds support for core.ignorecase to libgit2. when appropriate, we use strcasecmp to compare strings instead of strcmp. when core.ignorecase is on, the index object for the repository stores entries in strcasecmp order. this means that index iterators yield results in strcasecmp order as well. when core.ignorecase is on, the workdir iterator returns strcasecmp-ordered results, too. the tree iterator (representing committed data) always returns data sorted with strcmp. when merge joining results from two iterators that do not sort their output in the same way, the case-sensitive iterator has its results spooled into memory and then sorted before the merge join can occur, using an iterator type called spoolandsort. this is a performance penalty, of course. when we write out the index, and the data stored in the index is in strcasecmp order, we make sure to re-sort it to strcmp order on the way out to disk. do people think this approach is the way to go, or are there other opinions about how to attack the problem? is there anything obvious or non-obvious that i've missed? </desc> <cmt> support for core.ignorecase </cmt> <cmt> minor fixes for ignorecase support </cmt>",support for the core.ignorecase flag
1862,"<desc> i suggest removing ""fmt/"" prefix in *.h, *.cc files inside fmt directory. consider someone using fmt library as a git submodule or third-party library and has format.h helper file with direct referencing: include ""../../modules/fmt/fmt/format.h"" include ""../../modules/fmt/fmt/ostream.h"" nevertheless i put explicit relative path to format.h and ostream.h i need to add include_directories(""modules/fmt"") anywhere i use my format.h helper, because ostream.h contins the following inside: include ""fmt/format.h"" and i believe it could be easily replaced without any side effects with include ""format.h"" </desc> <cmt> upstream </cmt> <cmt> remove unnecessary ""fmt/"" prefix which should be maintained with additional include_directories() in each project. </cmt>","remove unnecessary ""fmt/"" prefix inside fmt directory"
1863,"<desc> specifically, remove the vector2, vector3, rect2 and color return types, i haven't found any valid use case for these. also update authors.md to contain my full name. </desc> <cmt> remove contrived javascript.eval return types </cmt> <cmt> update my name in authors.md </cmt>",remove contrived javascript.eval() return types
1864,"<desc> update libbpf submodule reference to the latest libbpf master commit. get rid of custom null #defines in libbpf-tools. and also adjust libbpf-tools makefile to use linux uapi headers distributed with libbpf itself.they are always the most recent version. </desc> <cmt> libbpf: update to latest master </cmt> <cmt> update libbpf to the latest upstream commit. </cmt> <cmt> libbpf-tools: remove unecessary custom null definitions </cmt> <cmt> now that libbpf defines null in bpf_helpers.h, there is no need for tools to </cmt> <cmt> re-define null. </cmt> <cmt> libbpf-tools: add libbpf's linux uapi headers to build </cmt> <cmt> do not rely on up-to-date uapi headers on the system. instead use the most </cmt> <cmt> recent ones that are used for libbpf's own build. </cmt>",update libbpf and misc fixes
1865,"<desc> i found there is typo in setting environment github_repository variable for two jobs, however jobs work fine anyway. after short investigation i found info here which says that: the "" github_repository"" is a default environment variable set by github. when you try using the "" env"" key or the "" set-env"" command to change the value of a default environment variable, github will prevent the value from being changed on the system, but this environment variable will be added into the  env context with the new value. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> fix ci workflow typo </cmt> <cmt> fixup! fix ci workflow typo </cmt>",remove unnecessary environment variable from ci workflow
1866,"<desc> original pull-request #33062 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix issue #80: union index out of boundary </cmt> <cmt> addressing review comments </cmt> <cmt> remove the additional white space as per the pipeline build error. </cmt> <cmt> adapt test </cmt> <cmt> whitespaces </cmt> <cmt> merge #33022 </cmt>",cherry pick #33062 to 21.11: merge #33022
1867,"<desc> cherry-pick #20781 #20780 #20912 #20824 </desc> <cmt> [cherry-pick]fix bug in reshape: (#20781) </cmt> <cmt> consider the situation that shape of input can contain more than one -1. </cmt> <cmt> [cherry-pick]support tensor for split and concat, support -1 in num_or_sections, add check num_or_sections (#20780) </cmt> <cmt> * improve split and concat op: </cmt> <cmt> 1. support tensor for argument 'dim' in split op. </cmt> <cmt> 2. support tensor for argument 'axis' in concat op. </cmt> <cmt> * redefine function getdatafromtensor and set unknown output shape to - 1. </cmt> <cmt> * add check: attr(sections) match input(x). </cmt> <cmt> * support tensor for attr(sections) and attr(sections) can contain -1. </cmt> <cmt> * modify error message and fix bug for concat and call resize only when necessary. </cmt> <cmt> test=release/1.6 </cmt>","reshape,concat, split and squeeze"
1868,<desc> i hereby agree to the terms of the cla available at:  fix duplicates after distinct which were possible because of incorrect optimization. fixes #17294. #17296 (li chengxiang) </desc> <cmt> fix #17294: distinct on subquery with group by may return duplicate result </cmt> <cmt> properly check distinct columns. </cmt> <cmt> properly check distinct columns. </cmt> <cmt> update test. </cmt> <iss> distinct on subquery with group by may return duplicate result </iss>,fix incorrect optimization of distinct
1869,"<desc> #27398 introduced some logic to better handle anonymous functions in ios stack traces. however, the logic is only applied if the correct platform is passed into the function. fix </desc> <cmt> test: trim function name logic not working </cmt> <cmt> fix: call trim_function_name with platform </cmt>",call trim_function_name with appropriate platform
1870,"<desc> kube-controller-manager panic when removing a lot of nodes from kubernetes cluster (see #58675). which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #58675 release note: </desc> <cmt> reduce verbose logs </cmt> <cmt> fix possible panic when getting primary ipconfig </cmt> <iss> kube-controller-manager panic with azure vmss </iss>",fix possible panic when getting azure primary ipconfig
1871,<desc> #135 plus style fix and test </desc> <cmt> implements #134 - add a --confirm flag </cmt> <cmt> syle: rename --confirm to --yes </cmt> <cmt> syle: rename --confirm to --yes </cmt> <cmt> style: fix indentation </cmt> <cmt> test: add coverage for auto confirmation </cmt>,--yes flag for auto confirmation
1872,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> update accordionitem. </cmt> <cmt> update checkbox. </cmt> <cmt> update datatable components. </cmt> <cmt> update datepicker. </cmt> <cmt> update menu. </cmt> <cmt> update multiselect. lower specificity of itemtoelement props to jsx.elementconstructor as it is the minimal type signature. </cmt> <cmt> update search. </cmt> <cmt> update tile. </cmt> <cmt> add filterablemultiselect export. </cmt>,update types to match 7.44.0
1873,<desc> fixes #14811. thanks @khodorammar for the repro case. the bug is that we won't pop the portal if it had no children. so we shouldn't push its container either. </desc> <cmt> adds failing test for </cmt> <cmt> fix removechild() crash when removing an empty portal </cmt>,fix crash unmounting an empty portal
1874,"<desc> i had to add new pull patch because they the yara guys introduced another redeclaration bug. i have already filed a pr for this but until the next release comes out, i will have to leave it there. this pr addresses issue #2546. </desc> <cmt> deps: upgrade yara from 3.4.0 to 3.5.0 </cmt> <cmt> deps: update yara bottle hash </cmt>",update yara to version 3.5.0 (#2546)
1875,"<desc> this is more of a collection of loosely related stuff. i added a buffered<t> template that adds buffering to any class that inherits from inputstream or outputstream. i've tried to get the gzip implementation to a state where it can correctly decompress usual files (as opposed to files constructed to test one specific behavior.) i already found and fixed a few bugs but there seems to be a bug buried in deflatedecompressor::decode_distance still. i also accumulated a few unit tests that i wrote to track down errors. it started to become annoying to rebase so i thought i'd merge some of it. </desc> <cmt> libcompress: replace assert_not_reached with set_fatal_error. </cmt> <cmt> we shouldn't assert that the input file is valid. </cmt> <cmt> ak: add log stream operator overload for span. </cmt> <cmt> ak: add buffered<t> which wraps a stream, adding input buffering. </cmt> <cmt> userland: use buffered<t> in gunzip. </cmt> <cmt> libcore: filestream.h: fix infinite loop when trying to read past end-of-file. </cmt> <cmt> deflate: fix deadly typo. </cmt> <cmt> libcompress: add another unit test. </cmt> <cmt> i suspected an error in circularduplexstream::read(bytes, size_t). this </cmt> <cmt> does not appear to be the case, this test case is useful regardless. </cmt> <cmt> the following script was used to generate the test: </cmt> <cmt> import gzip </cmt> <cmt> uncompressed = [] </cmt> <cmt> for _ in range(0x100): </cmt> <cmt> uncompressed.append(1) </cmt> <cmt> for _ in range(0x7e00): </cmt> <cmt> uncompressed.append(0) </cmt> <cmt> for _ in range(0x100): </cmt> <cmt> uncompressed.append(1) </cmt> <cmt> compressed = gzip.compress(bytes(uncompressed)) </cmt> <cmt> compressed = "", "".join(f""0x{byte:02x}"" for byte in compressed) </cmt> <cmt> print(f""""""\ </cmt> <cmt> test_case(gzip_decompress_repeat_around_buffer) </cmt> <cmt> {{ </cmt> <cmt> const u8 compressed[] = {{ </cmt> <cmt> {compressed} </cmt> <cmt> }}; </cmt> <cmt> u8 uncompressed[0x8011]; </cmt> <cmt> bytes{{ uncompressed, sizeof(uncompressed) }}.fill(0); </cmt> <cmt> uncompressed[0x8000] = 1; </cmt> <cmt> const auto decompressed = compress::gzipdecompressor::decompress_all({{ compressed, sizeof(compressed) }}); </cmt> <cmt> expect(compare({{ uncompressed, sizeof(uncompressed) }}, decompressed.bytes())); </cmt> <cmt> }} </cmt> <cmt> """""", end="""") </cmt> <cmt> streams: consistent behaviour when reading from stream with error. </cmt> <cmt> the streaming operator doesn't short-circuit, consider the following </cmt> <cmt> snippet: </cmt> <cmt> void foo(inputstream& stream) { </cmt> <cmt> int a, b; </cmt> <cmt> stream >> a >> b; </cmt> <cmt> } </cmt> <cmt> if the first read fails, the second is called regardless. it should be </cmt> <cmt> well defined what happens in this case: nothing. </cmt> <cmt> libcompress: simplify logic in deflate implementation. </cmt>",add buffered<t> to add buffering to byte streams.
1876,"<desc> this is a public helper method in an api that plugin authors are encouraged to use, so we need to deprecate the method name in 6.x and only remove it in master. </desc> <cmt> correct typo in analysisplugin#requriesanalysissettings </cmt> <cmt> because this is a static method on a public api, and one that we encourage </cmt> <cmt> plugin authors to use, the method with the typo is deprecated in 6.x </cmt> <cmt> rather than just renamed. </cmt> <cmt> migration docs </cmt>",correct spelling of analysisplugin#requriesanalysissettings
1877,<desc> fixed  i am not sure in which section of the project i would have to write a test for this patch but if someone guides me then i will definitely write a test for this patch. </desc> <cmt> remove extra dot in the file name of test db. </cmt>,fixed #32582 -- removed unnecessary dot in names of cloned test databases on sqlite.
1878,"<desc> add some more unit tests to specify the arguments each lifecycle method expects to be passed. with the addition of getderivedstatefromprops, it is important to pass the proper state values into the right parameters. for example, should the next state argument for shouldcomponentupdate get the new state before or after getderivedstatefromprops was called? these tests specify that behavior (answer: after). while not the most useful at this time, i think these tests will be useful if the relevant internals of preact are refactored. </desc> <cmt> add gsbu prevstate test </cmt> <cmt> add prevstate, etc. test for componentdidupdate </cmt> <cmt> add nextstate, etc. test for shouldcomponentupdate </cmt> <cmt> add gdsfp params test </cmt> <cmt> separate testing new props and new state </cmt> <cmt> simplify tests by removing log concept </cmt> <cmt> remove todo </cmt>",specify the arguments for lifecycle methods
1879,"<desc> jquery is throwing when it encounters ""[data-parent=anything.with.a.dot]"". failing fiddle (look in the console to see the error):  the fix is to quote the value for data-parent when finding the elements to hide. pull request contains both a unit test and the fix. </desc> <cmt> failing test for dot in data-parent </cmt> <cmt> use quotes to allow dots in data-parent </cmt>",accordion's data-parent can't contain dots
1880,"<desc> this pr does 2 different things: i removed my attempt to have the unsafe guaranteed builtin take a guaranteed value. it just makes things more complicated than needed. with that in mind, i used ensureplusone to ensure that all values are passed to builtins at plus 1. rdar://34222540 </desc> <cmt> revert ""[+0-all-args] accept guaranteed arguments to unsafe guaranteed."" </cmt> <cmt> this reverts commit 0bc964801bb423e32e6f5236fac82917e4bc19cf. </cmt> <cmt> this turned out to be a bad idea and just add more complication than is </cmt> <cmt> necessary. </cmt> <cmt> [+0-all] use +1 for builtins. </cmt>",pass arguments to builtins at +1
1881,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. official doc increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> fix callback and promise resolve </cmt> <cmt> promise and callback should resolve core.document<model>, not just core.response </cmt> <cmt> update pouchdb-upsert-tests.ts </cmt>",fix callback and promise resolve type
1882,"<desc> adds tryfrom<{int}> for nonzero{int}. it uses the existing nonzero{int}::new() and option::ok_or() functions, meaning the checks are not repeated. i also added tests, i tried to follow the convention i saw in the test file. i also used #[stable(feature = ""nzint_try_from_int_conv"", since = ""1.46.0"")], but i have no idea if the feature/version are correctly named or even correct. </desc> <cmt> added implementations for tryfrom<{int}> for nonzero{int} </cmt> <cmt> added tests for the implementations </cmt>",add tryfrom<{int}> for nonzero{int}
1883,"<desc> added ""mouse move"" support. change ""mouse enter/leave/over/out"" to rely mainly on ""mouse move"" events rather than on uielement.pointerenered/exited. the latter are fired when os decides the pointer enter/left what it thinks is the hit target, but that is wrong in some scenarios like ""box-none"" views overlapping non-related views. the new mechanism basically makes all events consistent with the target resolution offered by the touchhandler.getreactviewtarget. </desc> <cmt> first cut of mouse move/enter/leave fixes </cmt> <cmt> added element bounds checks. </cmt> <cmt> fixed the enter/leave/over/out optimizations </cmt> <cmt> pr feedback </cmt>",added mouse move support and fixes some mouse enter/leave scenarios
1884,"<desc> hi, i just developed a quick menu ui component based vue.js2. i want to share this with other developers. </desc> <cmt> add wheels factory to tutorials </cmt> <cmt> this is a website which is used to share ui components and libraries. it displays many execellent ui componets and this website almost updates every day. it provides searching and find by key words(tag) functionality to help user to find a ui component quickly. for each component, the website shows a concise introduction, such as installation of a component, how to use it and the props table of each component. it also show the demo and github page of each component. </cmt> <cmt> add wheels factory </cmt> <cmt> remove the emply line in tutorials, adding new line in the bottom of apps/websit </cmt> <cmt> add description of wheels factory </cmt> <cmt> adding vue-quick-menu to ui components </cmt>",adding vue-quick-menu to ui components--menu
1885,<desc> this fixes #1121. #2999 should be merged first. </desc> <cmt> modified server ssl certs to allow multiple pairs and force_client_auth flag </cmt> <cmt> fixed tests </cmt> <iss> change the node ssl server credentials api so that a server can have multiple key/cert pairs. </iss>,allow node server credentials to have multiple key/cert pairs
1886,"<desc> ""eslint"": ""^6.8.0"", ""git-rev-sync"": ""^2.0.0"", ""rollup"": ""^0.59.4"", ""rollup-plugin-git-version"": ""^0.3.1"", ""ssri"": ""^8.0.0"", ""uglify-js"": ""^3.9.2"" keep rollup < 0.60.0 for compatibility with ie 8 (see #6647) </desc> <cmt> update rollup-plugin-git-version to ^0.3.1 </cmt> <cmt> update uglify-js to ^3.9.2 </cmt> <cmt> update git-rev-sync to ^2.0.0 </cmt> <cmt> update ssri to ^8.0.0 </cmt> <cmt> update rollup to ^0.59.4 </cmt> <cmt> (latests version with support of ie 8) </cmt> <cmt> remove object.freeze hack, use rollup's output.freeze option instead </cmt>","update dev dependencies, fix most of vulnerabilities"
1887,"<desc> description: fixed a bug caused in creating a dictionary of entities to observe. using dict.fromkeys all entities where observed for each observation since the empty list was added by reference. replaced by dict comprehension. also using this to learn how to commit my work preparing for more substantial changes to this component. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist tox basically takes forever, but it finished in the end. it's not very useful for small pull requests such as this one though, it took more than two hours! have also run all tests manually as mentioned in  (removed all non-applicable checklists) </desc> <cmt> change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list </cmt> <cmt> change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list </cmt> <cmt> use get instead of direct keys for dict </cmt> <cmt> change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list </cmt> <cmt> use get instead of direct keys for dict </cmt>",fix all entities triggering all observations in bayesian sensor
1888,"<desc> makes windows builds extract things that look like warnings and errors from stdout, where msbuild sends all output, and reports them as errors to the logger (essentially making them behave as if they had gone to stderr). this means that native build failures will no longer be completely invisible in non-verbose mode. also fixes an existing warning so that it won't show up in every build: the custom step in the windows template cmake to do the re-entrant flutter step includes a dummy output file to force the step to run every time. this causes a warning from vs. marking it symbolic to indicate that it's not a real output file causes cmake to generate that vs step with the output validation step disabled so that it won't warn. related issues fixes #33583 i added the following tests: tests the regex extraction against sample normal and error lines, and ensures that it properly finds only the latter. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. </desc> <cmt> fix build warning due to phony output </cmt> <cmt> the custom step in the windows template cmake to do the re-entrant </cmt> <cmt> flutter step includes a dummy output file to force the step to run every </cmt> <cmt> time. this causes a warning from vs. marking it symbolic to indicate </cmt> <cmt> that it's not a real output file causes cmake to generate that vs step </cmt> <cmt> with the output validation step disabled so that it won't warn. </cmt> <cmt> add surfacing of errors from stdout </cmt> <iss> improve error surfacing from windows builds </iss>",surface windows build errors in non-verbose mode
1889,"<desc> hi @patrickvonplaten, adding 3 documented notebooks to fine tune transformers to downstream nlp tasks with pytorch: multi-class classification: using distilbert multi-label classification: using bert summarization: using t5 - model tracking with wandb these notebooks are pulled from the git repo: </desc> <cmt> added links to more community notebooks </cmt> <cmt> added links to 3 more community notebooks from the git repo: </cmt> <cmt> different transformers models are fine tuned on dataset using pytorch </cmt> <cmt> update readme.md </cmt>",adding notebooks for fine tuning [community notebook]
1890,"<desc> fixes #2200 this is the data output, going out over stdout. json logging as proposed in #2024 would go out over stderr as usual, so no conflicts there. there is some overlap between info (with --last/--first/--prefix) and list which is more obvious in the json output. the difference is that ""info"" reports more stuff, and takes longer for that, while ""list"" is fast (only looks at the manifest). </desc> <cmt> info: add --json option </cmt> <cmt> create: add --json option </cmt> <cmt> use custom json encoder for repr'ing borg objects consistently </cmt> <cmt> info: --json for archives </cmt> <cmt> list: --json for archive listing </cmt> <cmt> list: --json for archive contents listing </cmt> <iss> --json for create, info, list </iss>",json output for major commands
1891,"<desc> intention of #802 was to have on-the-fly compression using brotli only available to the standalone server, considering the following facts: brotli encoder is written in c++, while we want to keep libh2o as a c library we do not want to bundle libbrotli in libh2o, but having an external dependency against libbrotli might be bothersome to the users of libh2o for the purpose, a macro named h2o_use_brotli was introduced to conditionally enable / disable the calls to lib/handler/compress/brotli.cc. the macro has been turned of when building libh2o. however, we did not stop linking against brotli.cc.  as reported in #940 this has become an issue when trying to use the shared library version of libh2o (or libh2o-evloop). this pr address the issue by stopping linking to brotli.cc when building libh2o.  it also fixes build issues related to how we build and use the library. fixes #940 </desc> <cmt> move lib/handler/compress/brotli.cc to brotli_source_files (since it need not be linked for libh2o) </cmt> <cmt> on osx, libraries being built must link to the dependencies </cmt> <iss> libh2o-evloop 2.0.0 release builds but with unresolved symbols </iss>",fix link error when trying to use libh2o
1892,<desc> this pr adds a makefile so as to have an entry point to understand how to locally generate the website. i had a hard time understanding how to generate it and finally ended up looking in the github actions files. a makefile will make it easier for new users to start contributing. add a requirement.txt file. so we know which libs we need to install. use some best practices for your bash script that generates the docs. </desc> <cmt> chore: add python requirements </cmt> <cmt> feat: better bash scripting </cmt> <cmt> chore: add makefile </cmt>,document build process / add requirements / better bash
1893,"<desc> using a more recent snippet (following their current docs), and adding anonymization of the ip (according to their docs, this should only ""slightly reduce the accuracy of geolocation""). if we do this, should do the same for main website as well. </desc> <cmt> use snippet from google analytics docs </cmt> <cmt> add anonymizeip </cmt>",add anonymizeip for google analytics in docs
1894,<desc> recommend that the defaults in osx/scripts/postinstall-launchd-jenkins be reviewed by a java/osx dev for sanity. </desc> <cmt> add minpermgen and minheapsize settings for defaults(1) which will be used preallocate java's heapsize and permsize. </cmt> <cmt> set defaults for java heap and perms on both i386 and x64_64 architectures. the x64_64 settings work for me. recommend that they be reviewed by a java/osx dev. </cmt>,add more control of java heap and perm sizing on osx and set defaults.
1895,"<desc> use nacosservicemanager  to manage the life cycle of namingservice  and namingmaintainservice when the related configuration is dynamically changed through the configuration center, realize the reconstruction of namingservice  and namingmaintainservice </desc> <cmt> nacos re-register enhance </cmt> <cmt> nacos discovery enhance </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt>",nacos namingservice support dynamic switching
1896,"<desc> added scipy intersphinx inventory to make references clickable (for example in ""see also"" sections in convolve or polyfit). some scipy.stats references also needed updating (such as those in vonmises or zipf; note that to see the effect one needs to rebuild mtrand.so before building the documentation). </desc> <cmt> doc: add scipy inventory for intersphinx. </cmt> <cmt> maint, doc: update some scipy.stats references. </cmt> <cmt> closes #5813. </cmt>",turn scipy references into links.
1897,"<desc> in the dgus_lcd_ui_reloaded code void dgusscreenhandler::setstatusmessage(fstr_p const fmsg, const millis_t duration) but in the function it attempt to use uses the variable msg when it was defined as fmsg updated to use fmsg dgus_lcd_ui_reloaded and all its requirements compiles as expected my test config configuration.zip #23089 </desc> <cmt> use fmsg not msg </cmt> <cmt> remove xtra f </cmt>","fix typo in dgus_lcd_ui_reloaded, dgusscreenhandler::setstatusmessage"
1898,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. (already there?) a quick search for ""fullcalendar"" in the issues ( #16935 #4663 #6893 ) reveals the community needs updated typings for fullcalendar but things are moving slowly. in this pr i'm taking steps towards good typings for fullcalendar@3.5: refactor the definition file such that options consistently map to sections of the doc. add the short description and default values for most options. add missing options and mark where further inspection is necessary to find discrepancies with the doc. i'm not pretending to be able to produce fully compatible typings but this is already far better than what we had before and hopefully someone will be willing to finish the job. i have no idea how the release cycle works in this repo but i was thinking at least publishing those as v3.5.0-preview or something if not just v3.5.0 . lmk what you think. thanks </desc> <cmt> fullcalendar refactoring </cmt> <cmt> add most of v3's features and mark where further checking </cmt> <cmt> is needed to ensure full v3 compatibility. </cmt> <cmt> fix linting </cmt>",fullcalendar refactoring and partial v3 featureset
1899,"<desc> enables the annotationusestyle, avoidnoargumentsuperconstructorcall, and noenumtrailingcomma checkstyle checks and fixes all violations. the motivation is to make the code easier to read by using a consistent style throughout. </desc> <cmt> enable avoidnoargumentsuperconstructorcall checkstyle check </cmt> <cmt> enable annotationusestyle checkstyle check </cmt> <cmt> enable noenumtrailingcomma checkstyle check </cmt>","enable annotationusestyle, avoidnoargumentsuperconstructorcall, and noenumtrailingcomma checkstyle checks"
1900,"<desc> reworks challenge to use argument in function call. i've joined two parts of the original challenge - finding 20 numbers of sequence and first number greater than - into finding 10 numbers, starting from one greater than. limiting required numbers to 10 allows to keep test descriptions cleaner, while not affecting difficulty of challenge. adds two tests. removes unnecessary link. changes tested on local fork. related to #40896. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. </desc> <cmt> fix: rework challenge to use argument in function </cmt> <cmt> fix: remove unnecessary link </cmt>",rework rosetta code harshad or niven series
1901,"<desc> bugfix yes if relevant, link to documentation update: summary fixes #3484 no other information </desc> <cmt> fix(ruleset): allow array of functions returning either string or loader objects </cmt> <cmt> beautify, remove comments, debuggers </cmt> <iss> crash with rule.use as a function returning array </iss>",normalize mixed use array and function
1902,"<desc> label encoder (e.g., scikit-learn's) is a general mechanism of mapping values to integers or vice versa. today, the label encoder in onnx only supports integer-to-string and it's inverse transform. thus, this pr proposes a new signature to fill the gap. </desc> <cmt> add new signature to md file for preview </cmt> <cmt> clarify look-up for floats </cmt> <cmt> update operator-ml.md </cmt>",upgrade label encoder to support more input types
1903,"<desc> this pr doesn't actually add tpu optimization. it restructures the sampling graph to make it compatible with tf.contrib.tpu.rewrite. </desc> <cmt> coconet: cleanup lib_tfsampling and add sampling support to export_saved_model. </cmt> <cmt> uses tf.placeholder_with_default for the scalar params so they can be </cmt> <cmt> left out of the savedmodel signature. </cmt> <cmt> fix import order. </cmt> <cmt> add missing ""lib_saved_model.py"". </cmt>",cleanup and refactor to support tpu inference
1904,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> updated with info,header and footer </cmt> <cmt> formatting </cmt> <cmt> linting </cmt>","updated pdfmake type definition with info,header and footer types"
1905,<desc> fix merge conflict on master-next due to afc8762. </desc> <cmt> [immediate] fix static constructor/destructor calls in runimmediately. </cmt> <cmt> removes a redundant call to lljit::runconstructors and adds a call to </cmt> <cmt> lljit::rundestructors. </cmt> <cmt> [immediate] fix static constructor/destructor calls in runimmediately. </cmt>,fix merge conflict in lib/immediate/immediate.cpp
1906,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. when i went through these challenges on the website, the wording was a bit confusing, so i fixed it. </desc> <cmt> refactor: made instructions incurriculum\challenges\english\01-responsive-web-design\applied-visual-design\use-the-strong-tag-to-make-text-bold.md a little more clear to user </cmt> <cmt> refactor: changed phrasing in instructions in curriculum\challenges\english\01-responsive-web-design\applied-visual-design\use-the-s-tag-to-strikethrough-text.md to make it slightly easier to read and less verbose </cmt> <cmt> refactor: fix phrasing in curriculum/challenges/english/01-responsive-web-design/applied-visual-design/use-the-s-tag-to-strikethrough-text.md </cmt>",change phrasing in challenges to make it easier to read
1907,<desc> fixes #21715 i have followed (at least) the pr section of the contributing guide. description small fix of ripple color for custom switches. </desc> <cmt> fixed ripple color for custom switch </cmt> <cmt> prettier import </cmt> <iss> [switch] wrong custom ripple color </iss>,fix custom switch ripple color
1908,"<desc> achieve the proposal in #421 . dsl ref: w3c spec css device adaptation adding item in config script: <script type=""config""> { ""viewport"": { ""width"": ""device-width"", ... }, ... } </script> maybe we will use <meta> tag as dsl in future. supported properties width: number or ""device-width"" or ""device-height"" height: number or ""device-width"" or ""device-height"" js-native api module: meta method: setviewport args: [viewportobject] (just same as viewport object in config script) </desc> <cmt> * [jsfm] add test case for viewport config </cmt> <cmt> * [jsfm] support vieport configs </cmt>",support to set viewport (achieve #421)
1909,<desc> starts to provide a solution for #18971. thinking i will round this out and also add a prop that allows the user to align the icons as desired. would love feedback from the team if this seems like a good path? @oliviertassinari i have followed (at least) the pr section of the contributing guide. closes #18971. </desc> <cmt> add support for array of customicons </cmt> <cmt> add test for customicons array </cmt> <cmt> revert errant change </cmt> <iss> [rating] allow different icons </iss>,add a demo with different icons
1910,"<desc> this pr updates the .pot file as described in  this pr is marked wip as i want to reread all translations once again . would be great, if a german speaker could review, at least if we agree on important, recurring keywords. to suggest translations for the few remaining fuzzy messages has associated issue: fixes #17441 includes db migration (follow approval process in sip-59) </desc> <cmt> pybabel extract </cmt> <cmt> add and correct de translations </cmt> <iss> german translations missing or wrong </iss>",update german translations (based on master) (#17441)
1911,"<desc> it turns out i had forgotten to include a bunch of files that vagrant-spk was pulling in automatically. the build should be working now, and i've verified that it produces a working spk. </desc> <cmt> add missing meteor-spk files to travis sandstorm build </cmt> <cmt> fix travis sandstorm build </cmt>",fix travis sandstorm spk build
1912,"<desc> @goodmanship i'm creating this draft pr from your branch so we can discuss the code changes. </desc> <cmt> use the constants </cmt> <cmt> return response for kinesis put_records </cmt> <cmt> new kinesis test, bug fix </cmt> <cmt> use boto for this, but needs config </cmt>",inject kinesis throttling errors for testing
1913,<desc> route section: fix to add multiple properties first init the node then add to list. </desc> <cmt> networkd: fix route properties. </cmt> <cmt> we are not able to add multiple properties. </cmt> <cmt> wlp3s0.network: </cmt> <cmt> [match] </cmt> <cmt> name=wlp3s0 </cmt> <cmt> [route] </cmt> <cmt> gateway=10.68.5.26 </cmt> <cmt> metric=10 </cmt> <cmt> sudo ./systemd-networkd </cmt> <cmt> failed to parse file '/usr/lib/systemd/network/wlp3s0.network': file </cmt> <cmt> exists </cmt> <cmt> could not load configuration files: file exists </cmt> <cmt> this patch fixes it. </cmt> <cmt> networkd: address- initialize the node before adding to list. </cmt> <cmt> it make more sense to initalize the node first then </cmt> <cmt> we add to the list. </cmt>,fix address and route conf
1914,"<desc> which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # </desc> <cmt> fixed support for ingress and existingpvc </cmt> <cmt> bumped version </cmt> <cmt> fixed typo </cmt> <cmt> values.nginx.persistence.existingclaim </cmt> <cmt> fixed support for k8s 1.9.6 </cmt>",fixed permission issue for tls secret
1915,"<desc> this relates to #24576, where users were trying to use the upsert method while passing an upsertoptions argument without a returning value.  this was causing compilation to fail.  i have added the test case and made the returning: false option act as the default, as it is in sequelize. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #24576, increase the version number in the header if appropriate. </desc> <cmt> upsert should compile with options that dont include returning </cmt> <cmt> fix parens </cmt> <cmt> bump version for bugfix </cmt>",fix types error with upsertoptions requiring the returning option if they are defined at all
1916,"<desc> original pull-request #27329 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix incorrect row-level filtering </cmt> <cmt> add test. </cmt> <cmt> add test. </cmt> <cmt> update 02002_row_level_filter_bug.sh </cmt> <cmt> add test to parallel skip list. </cmt> <cmt> update skip_list.json </cmt> <cmt> fix spelling. </cmt> <cmt> fix #27179 </cmt>",cherry pick #27329 to 21.6: fix #27179
1917,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: included in commit messages include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> feat(chromecast-caf-receiver): add messagetype enum to system ns </cmt> <cmt> there are two messagetype enums. the one in system namespace was </cmt> <cmt> missing. </cmt> <cmt> 1. </cmt> <cmt> 2. </cmt> <cmt> fix(chromecast-caf-receiver): fix eventhandler for castcontextreceiver </cmt> <cmt> methods in castcontextreceiver accepts eventhandlers with system.event </cmt> <cmt> as arguments and not events.event </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt>",add missing system.messagetype enum and fix eventhandler type mismatch
1918,"<desc> this is a companion pull request for #6227 updating the changelog for activesupport to document the addition of #beginning_of_hour and #end_of_hour core extensions as merged to the 3-2-stable branch in #6170. this pull request contains 2 commits.  the first is the inclusion as outlined above.  the second brings the 3-2-stable changelog up-to-date by adding missing entries for previous releases. / thanks, mark. </desc> <cmt> bring activesupport changelog up-to-date/consistent with master. </cmt> <cmt> add changelog section for unreleased rails 3.2.4; document addition of #beginning_of_hour and #end_of_hour to time and datetime core extensions. </cmt>",updated activesupport changelog [for 3-2-stable]
1919,"<desc> here is an implementation for the get api for system feature upgrades. it is pretty simple. when called, we iterate over all features, resolve all indices, and fetch the version for each index from cluster state index metadata. we then determine the earliest index creation version for each feature to determine whether the features need to be upgraded or not. i've also added a simple bwc test for rolling upgrades to make sure that we are in fact returning the correct index creation versions. </desc> <cmt> implement and test get feature upgrade status api </cmt> <cmt> use version object instead of string versions </cmt> <cmt> refactor for streams </cmt> <cmt> add integration test for feature upgrade endpoint </cmt>",implement get api for system feature upgrades
1920,"<desc> while looking into #497 i realized that the throttle decorator does not work on a per-instance basis but on a per-class basis. class say: @util.throttle(timedelta(seconds=1)) def hello(self): return ""hi"" say().hello() # => ""hi"" say().hello() # => none this was unexpected behavior and this pr fixes this. it also includes some cleanup for the arest sensor which i did while debugging. fixes #497. </desc> <cmt> fix throttle to work on instance-level </cmt> <cmt> cleanup arest </cmt> <iss> arest sensor error </iss>",throttle per instance (fixes arest)
1921,"<desc> what this pr does / why we need it: reverts #4377 to fix the same issue which issue this pr fixes: fixes #4704 special notes for your reviewer: attempted to align with other charts, but behaviour is inconsistent between charts. </desc> <cmt> always set spec.clusterip </cmt> <cmt> version bump </cmt> <iss> [stable/external-dns] invalid value for spec.clusterip on 0.5.3 upgrade </iss>",allow upgrade with empty clusterip
1922,"<desc> there is a bug in cycle_unicode_input_mode() that prevents cycling in reverse. the bug is due to unsigned arithmetic. as a consequence, the uc_rmod keycode does not currently work. this pr changes the uint8_t offset parameter to int8_t and fixes the bug. this pr further allows shift to be used for inverting the direction of the uc_mod, uc_rmod keycodes, similar to how rgb_mod, rgb_rmod work. i've tested uc_rmod and cycling with shift after these changes and can confirm that they work as intended. currently, audio feedback for changing input modes currently only plays for specific uc_m_* keycodes. this pr allows it to play when changing input modes with uc_mod, uc_rmod as well. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> invert uc_mod/uc_rmod direction when shift is held </cmt> <cmt> also use mod_mask_shift in process_rgb.c </cmt> <cmt> allow audio to be played for uc_mod, uc_rmod keycodes as well </cmt> <cmt> fix signedness bug in reverse input mode cycling </cmt> <cmt> misc formatting in process_unicode_common.c </cmt>","fix bug in uc_rmod, add shift and audio support for uc_mod/uc_rmod"
1923,"<desc> there was a dashboard issue where, when a user clicked to view the logs or errors of a given worker, the page would crash. this occurred because the front-end expected a different payload than the backend returned. the pr also adds a test for the new payload. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix bug with worker logs/errors not displaying in the dashboard </cmt> <cmt> add error endpoint test. </cmt>",fix bug in display of worker logs and errors in dashboard
1924,"<desc> going forward, fixed/constrained images will take width and height as parameters, rather than the previous option of maxwidth/maxheight for fluid and constrained images. open question: right now fluid can take width and height. at what level do we want to warn the user to use breakpoints instead? or do we want to cover that in the forthcoming breakpoints pr? (note that the failing tests are based on the plugin helpers, i'm missing something there) readmes outside of gatsby-plugin-image are also not updated as versioning those is not clear. should determine that before merging this pr. </desc> <cmt> in progress </cmt> <cmt> update tests </cmt> <cmt> resolve merge conflict </cmt> <cmt> remove maxheight and maxwidth references </cmt>",update image api to remove maxwidth/maxheight
1925,"<desc> the stdlib has a panic_immediate_abort feature that turns panics into immediate aborts, without any formatting/display logic. this feature was introduced primarily for codesize-constrained situations. unfortunately, this win doesn't quite propagate to result::expect() and result::unwrap(), while the formatting machinery is reduced, expect() and unwrap() both call unwrap_failed(""msg"", &err) which has a signature of fn unwrap_failed(msg: &str, error: &dyn fmt::debug) and is #[inline(never)]. this means that unwrap_failed will unconditionally construct a dyn debug trait object even though the object is never used in the function. constructing a trait object (even if you never call a method on it!) forces rust to include the vtable and any dependencies. this means that in panic_immediate_abort mode, calling expect/unwrap on a result will pull in a whole bunch of formatting code for the error type even if it's completely unused. this pr swaps out the function with one that won't require a trait object such that it won't force the inclusion of vtables in the code. it also gates off #[inline(never)] in a bunch of other places where allowing the inlining of an abort may be useful (this kind of thing is already done elsewhere in the stdlib). i don't know how to write a test for this; we don't really seem to have any tests for panic_immediate_abort anyway so perhaps it's fine as is. </desc> <cmt> inline slice panics on panic_immediate_abort </cmt> <cmt> inline option panics on panic_immediate_abort </cmt> <cmt> add separate impl of unwrap_failed to avoid constructing trait objects </cmt>",make certain panicky stdlib functions behave better under panic_immediate_abort
1926,"<desc> this pr adds the poweredbyheader and webpack fields to the public nextconfig type. related issues linked using fixes #number errors have helpful link attached, see contributing.md related issues linked using fixes #number errors have helpful link attached, see contributing.md </desc> <cmt> chore: add missing poweredbyheader field to nextconfig type </cmt> <cmt> chore: add missing webpack field to nextconfig type </cmt>",add missing fields to nextconfig type
1927,"<desc> currently, deform_conv only works for cuda:0 from ops.dcn.deform_conv import deformconv, deform_conv ## works normally device = ""cuda:0"" out = deform_conv(x, offset, weight, 1, [1, 1], 1, 2, 2) print(out.mean(), out.var()) # tensor(0.1310, device='cuda:0'), tensor(0.1312, device='cuda:0') ## fails to work device = ""cuda:1"" out = deform_conv(x, offset, weight, 1, [1, 1], 1, 2, 2) print(out.mean(), out.var()) # tensor(0., device='cuda:1'), tensor(0., device='cuda:1') the patch aims to fix the issue. </desc> <cmt> update deform_conv_cuda.cpp </cmt> <cmt> update deform_pool_cuda.cpp </cmt>",fix zero outputs when not running on cuda:0
1928,<desc> commit message: count the number of bytes sent to and received from upstream server per request and store them in stream_info for better observability. additional description:na risk level:na testing:will add testing for the new metric. docs changes:add doc for the new metric. release notes:na </desc> <cmt> count bytes </cmt> <cmt> add count byte interface to stream class </cmt> <cmt> add h1 bytes accounting </cmt> <cmt> count byte sent in h1 </cmt> <cmt> log bytes in stream info </cmt> <cmt> clean up </cmt> <cmt> count h2 sent and received bytes </cmt> <cmt> cleam up </cmt> <cmt> clean up </cmt>,count sent and received bytes for http stream
1929,"<desc> chai removing the namespace from their types was a bug, which has been fixed - the correct fix from us would have been pinning our version until a fix was out, but instead we went way overboard and removed the dependency, and i'll be honest, while the assertions are no different when all tests are passing, that's not what there're there for. failure messages like this one: are straight bad compared to what chai gives (a useful comparison of both inputs to equals). object diffs for deep equals are also much worse (or rather, non-extant). we didn't use an assertion library for no reason, we used it to be more productive when debugging. i don't want to need to open a debugger just to see every small discrepancy! and while i could spend hours of effort making our custom assertion library become up-to-par with what i'd expect for a decent debugging experience (and i know @rbuckton already has his own assertion framework, but he's not ready afaik), it's much easy to not have a nih mindset and continue using the tested and featureful assertion library we've been using for years. especially since there's not a single issue with it. </desc> <cmt> revert ""merge pull request #20429 from microsoft/unchai"" </cmt> <cmt> this reverts commit 66ec938164b61a7a9e14214f36bf58edc11c7609, reversing </cmt> <cmt> changes made to 37a40561ac4c4cb1f970ade5fff2389d954593f6. </cmt> <cmt> update lockfile </cmt>",revert merge pull request #20429 (removing chai)
1930,"<desc> this is a continuation of #7479 & #7728, progress towards converging ak::inlinelinkedlist usages with ak::intrusivelist. </desc> <cmt> ak: add intrusivelist::size_slow() to match inlinelinkedlist </cmt> <cmt> the functionality is needed to replace inlinelinkedlist with </cmt> <cmt> intrusivelist in the kernel process class. </cmt> <cmt> kernel: remove unnecessary cast to int during ensure capacity </cmt>",move process inlinelinkedlist usages to intrusivelist
1931,<desc> bug fixes ops this patch fixes onednn-based matmul kernel for cases when both inputs have different number of dimensions. it fixes the issue #30309 for onednn 1.6 (used in the release/2.0 branch). </desc> <cmt> a fix for onednn matmul kernel. fixes issue #30309 (#30723) </cmt> <cmt> a fix for #30309 with onednn 1.6 </cmt>,a fix for onednn matmul kernel. fixes issue #30309 for onednn 1.6
1932,"<desc> to support multiple uris for a job, we need to make the api able to accept multiple uris. right now, protobuf and c++ level is handling multiple uris, but it's not done in python level. this pr fixed it. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix </cmt> <cmt> up </cmt> <cmt> fix lint </cmt> <cmt> fix comment </cmt> <cmt> fix lint </cmt> <cmt> up </cmt> <cmt> up </cmt>",align the interface to use multiple uris for runtime env
1933,"<desc> implements a simple env dynamics learner to be used inside different mbrl algos. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt>",prototype of a dynatrainer (for env dynamics learning in upcoming mbmpo algo).
1934,"<desc> there's a bit of refactoring in here to get this all to work, but mostly it's the last two commits that are the meat of it: factor out all of the code responsible for mutating the output buffer into a discrete set of actions. re-implement those actions with a temporary queue so that queued changes can be reversed without requiring any reads from the output string itself. our old logic constantly referenced the output value, meaning every reference got more expensive as the output for larger, leading to an exponential increase in codegen times. for example, using the example script from istanbuljs/babel-plugin-istanbul#5 (comment) which generates doubling ast array, generation time changes as shown: items: the size of the array being generated time: the time in ms to generate the code length: the number of characters in the output code items: 2 ,  time: 9 ,   length: 239 items: 4 ,  time: 2 ,   length: 465 items: 8 ,  time: 6 ,   length: 917 items: 16 , time: 6 ,   length: 1840 items: 32 , time: 15 ,  length: 3696 items: 64 , time: 25 ,  length: 7408 items: 128 ,    time: 93 ,  length: 14917 items: 256 ,    time: 380 , length: 30149 items: 512 ,    time: 1399 ,    length: 60613 items: 1024 ,   time: 5301 ,    length: 121614 items: 2048 ,   time: 20676 ,   length: 246542 items: 2 ,  time: 7 ,   length: 239 items: 4 ,  time: 5 ,   length: 465 items: 8 ,  time: 5 ,   length: 917 items: 16 , time: 6 ,   length: 1840 items: 32 , time: 11 ,  length: 3696 items: 64 , time: 3 ,   length: 7408 items: 128 ,    time: 13 ,  length: 14917 items: 256 ,    time: 18 ,  length: 30149 items: 512 ,    time: 45 ,  length: 60613 items: 1024 ,   time: 63 ,  length: 121614 items: 2048 ,   time: 117 , length: 246542 items: 4096 ,   time: 266 , length: 496398 items: 8192 ,   time: 460 , length: 996110 items: 16384 ,  time: 980 , length: 2014687 items: 32768 ,  time: 2008 ,    length: 4062687 items: 65536 ,  time: 3819 ,    length: 8158687 items: 131072 , time: 7359 ,    length: 16443904 </desc> <cmt> use the standard newline function. </cmt> <cmt> remove sideeffectful position mutation. </cmt> <cmt> centralize position tracking into buffer. </cmt> <cmt> make the 'catchup' call implicit to source location updates. </cmt> <cmt> drop one usage of removelast. </cmt> <cmt> remove removelast usage. </cmt> <cmt> remove unnecessary passthrough function. </cmt> <cmt> use 'push' for all cases. </cmt>",make the code generator write-only to avoid exponential time generation
1935,"<desc> notes are now fed to stories as parameters. no need to broadcast via channel anymore. run the crna-kitchen-sink app, verify notes are still being displayed. </desc> <cmt> rm unused import </cmt> <cmt> update rn notes addon description </cmt> <cmt> remove dependency on channel to render notes </cmt> <cmt> update readme </cmt> <cmt> update knobs addon structure for consistency with notes and backgrounds </cmt>",remove channel dependency from rn notes addon
1936,"<desc> see for instance #896 -- it's a common problem to need mocked nodes. this solution is probably a bit of a bandaid, as large projects would probably want to set options per-story, this is a lot better than nothing in the meantime. fixes #1085, and to some degree #881 and #876 added a snapshotwithoptions test body, and an example of usage in the test-cra app. run npm test. try removing the test option and it should fail with an undefined access issue. </desc> <cmt> added a snapshotwithoptions test body and example </cmt> <cmt> see for instance </cmt> <cmt> this solution is probably a bit of a bandaid, as large projects would probably want to set options per-story, this is a lot better than nothing in the meantime. </cmt> <cmt> added some docs </cmt>",added snapshotwithoptions to configure storyshots rendering options
1937,"<desc> we retain the worker/object subscribe information and use them to re-subscribe when gcs service restart from failure. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> resubscribe worker/object table info when gcs service restart </cmt> <cmt> remove unnecessary include </cmt>",resubscribe worker table info when gcs service restart
1938,"<desc> cherry-pick of pr against master: #5440 initial pr description: two changes, close relatives. first change enables writing #if swift(>=3.0.1) by contextually inhibiting an early diagnostic in the parser that's currently blocking the initial semi-parse that runs before the version parser kicks in. second change weakens our sense of logical order and logical equality on version structures such that 4 == 4.0 == 4.0.0 (that is, versions are considered to have as many trailing zeroes as necessary). the function evaluating versions you are allowed to pass on the command line is tightened opposite this change, so you still can't say -swift-version 4.0 (only -swift-version 4) but it means that if someone writes #if swift(>=4.0) it'll work, rather than the current behaviour, that thinks 4 < 4.0. resolves sr-2908. </desc> <cmt> support #if swift(subminor-version), rdar://problem/28786959 / sr-2908. </cmt> <cmt> logically compare swift versions as though x == x.0 == x.0.0, etc. </cmt>",rdar 28786959 3.0 branch if swift 3 digit version
1939,"<desc> via #15319 (redid #15399, removed the changes that didn't even belong in it.) so tl;dr this pr - uses a renderer specific object as the value of reactcurrentactingrenderersigil.current checks this value on 'updatecontainer checks this value when setting a state hook's value adds a fixture folder for act() (which is run on ci) this solves 2 specific problems - using the wrong act() shouldn't silence the 'missing act' warning using the wrong act() logs a warning tha you're, er, using the wrong act() (please see  #15399 for the long spiel on the mechanics for this.) </desc> <cmt> warn when using the wrong renderer's act around another renderer's updates </cmt> <cmt> like it says. it uses a real object as the sigil (instead of just a boolean). specifically, it uses a renderer's flushpassiveeffects as the sigil. we also run tests for this separate from our main suite (which doesn't allow loading multiple renderers in a suite), but makes sure to run this in ci as well. </cmt> <cmt> unneeded (and wrong) comment </cmt>",using the wrong renderer's act() should warn
1940,<desc> refs #15791. refs #19602. this pr implements the part that passes information to listener and reads the responses. notes: no-notes </desc> <cmt> implement onbeforesendheaders </cmt> <cmt> pass the request </cmt> <cmt> handle simple listeners </cmt> <cmt> handle response listeners </cmt> <cmt> read responses from listener </cmt>,migrate webrequest module to networkservice (part 6)
1941,"<desc> adds a team selector to the metric alerts page, completing the team alerts frontend work. this pr also includes permission changes similar to #24355 </desc> <cmt> add team selector to metric alerts with proper permissions </cmt> <cmt> woopsie gotta feature flag this </cmt> <cmt> bad at spelling </cmt>",add team alerts support to metric alerts
1942,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. </desc> <cmt> chore: add docs comment </cmt> <cmt> fix: remove rule in tslint.json </cmt> <cmt> chore: add some fix </cmt> <cmt> fix: format tuya-panel-kit </cmt> <cmt> add no-unnecessary-class for globaltoast </cmt> <cmt> fix: remove no-unnecessary-class and fix ther warning </cmt> <cmt> feat: uiidnaveventemitter typed </cmt> <cmt> feat: uiidnaveventemitter typed </cmt> <cmt> fork sync </cmt> <cmt> fix: lint formater </cmt> <cmt> fix: lint formater </cmt>,add some miss props and comment
1943,"<desc> liba52 and libdts haven't been used by default for some time on any platform. ffmpeg is used instead of them. this patch removes them completely from the xbmc source tree and removes the deprecated --enable-libdts and --enable-liba52 configure options. the vs and xcode project files are also updated. build tested on linux and darwin. please test the win32 build to see if i managed to blindly update the vs project files correctly, and maybe provide a fix if that is not the case. also, if someone disagrees about removal of these libraries, now is the time to speak :) </desc> <cmt> removed: use of deprecated liba52 </cmt> <cmt> liba52 hasn't been used by default for a while. remove the use of it </cmt> <cmt> completely in favor of ffmpeg. </cmt> <cmt> removed: internal copy of liba52 </cmt> <cmt> it is no longer used. ac-3 streams are decoded by ffmpeg. </cmt> <cmt> removed: use of deprecated libdts </cmt> <cmt> libdts hasn't been used by default for a while. remove the use of it </cmt> <cmt> completely in favor of ffmpeg. </cmt> <cmt> removed: internal copy of libdts </cmt> <cmt> it is no longer used. dts streams are decoded by ffmpeg. </cmt> <cmt> removed: unused dvdaudiocodecpassthrough.cpp </cmt> <cmt> it has been replaced by dvdaudiocodecpassthroughffmpeg.cpp. </cmt>",remove liba52 and libdts completely
1944,"<desc> this merges the logic for nullbooleanfield, which originally started off as a unique field, with the booleanfield. this reduces the repeated logic and removes the need for additional special cases. this also aligns with the recent changes within django to discourage the use of nullbooleanfield. fixes #6115 closes #6116 </desc> <cmt> make nullbooleanfield subclass booleanfield </cmt> <cmt> this removes a lot of the redundancy that was in place becuase we </cmt> <cmt> were not doing this. this maintains the none initial value that </cmt> <cmt> was previously present, as well as disallowing allow_null to be </cmt> <cmt> passed in. </cmt> <cmt> remove special case for mapping nullbooleanfield </cmt> <cmt> in newer versions of django, the nullbooleanfield is handled the </cmt> <cmt> same way as a booleanfield(null=true). given that we also support </cmt> <cmt> that combination, and that our own nullbooleanfield behaves in the </cmt> <cmt> same manner, it makes sense to remove the special casing that exists </cmt> <cmt> for it. </cmt> <cmt> add test for booleanfield(null=true, choices) </cmt> <cmt> remove special case for nullbooleanfield </cmt> <cmt> adjust mapping tests for nullbooleanfield </cmt> <iss> nullbooleanfield doesn't accept null when choices are defined </iss>",merge nullbooleanfield with booleanfield(allow_null=true)
1945,"<desc> fix sum op. update backward.py: if there is no input grad var in all outputs of previous ops, do not append this op into graph. only apply this stragety when double backward. make some op more standard </desc> <cmt> fix compiling error with cudnn 5.1 </cmt> <cmt> fix sum_op </cmt> <cmt> update backward appedding to support double grad. </cmt> <cmt> test=develop </cmt>",update backward appending stragety to support double backward and fix some bug.
1946,"<desc> remove the -enable-experimental-conditional-conformances flag, enabling the feature all the time (and in all language modes). this allows developers to work around any source-compatibility issues due to the rollout of conditional conformances in the standard library (e.g, the collapsed slice types). to make the limitations of this feature more visible, introduce a runtime warning when a ""conforms to protocol"" check fails dynamically because we have not yet implemented that behavior for conditional conformances. </desc> <cmt> [runtime] warn about dynamically querying conditional conformances. </cmt> <cmt> rather than silently returning ""false"" when we are unable to attempt </cmt> <cmt> to satisfy a conditional conformance at runtime, produce a runtime </cmt> <cmt> warning first, to note to users that this behavior is incorrect and </cmt> <cmt> will change in the future. </cmt> <cmt> revert ""[se-0143] put conditional conformances behind an ""experimental"" flag."" </cmt> <cmt> this reverts commit b59c30c1afe2ae29ee20f14328b3ecb012fc02d6. </cmt> <cmt> eliminate extraneous uses of -enable-experimental-conditional-conformances </cmt>",enable conditional conformances without a flag
1947,"<desc> when we are maximized or fullscreened, check for the presence of the taskbar in auto-hide mode. if the terminal finds the taskbar on any side of the monitor, adjust our window rect by just a little bit, so that the taskbar can still be revealed by the user mousing over that edge. closes #1438 i work here note to future code archeologists: this doesn't seem to work for fullscreen on the primary display. however, testing a bunch of other apps with fullscreen modes and an auto-hiding taskbar has shown that none of them reveal the taskbar from fullscreen mode. this includes edge, firefox, chrome, sublime text, powerpoint - none seemed to support this. this does however work fine for maximized. i'm maximized and fullscreened the terminal a lot in the last two days. </desc> <cmt> i think this _should_ fix #1438 but it instead gets rid of the left, right, bottom borders??? </cmt> <cmt> cleanup for pr </cmt> <cmt> you'd think that the rcwork would just account for an autohide taskbar still... </cmt> <cmt> this actually doesn't work for _any_ fullscreen anymore, weirdly. i could have swore that it did before though.... </cmt> <cmt> turns out i'm crazy and this is expected behavior. </cmt> <iss> cannot access taskbar when terminal is maximized/fullscreen </iss>",reveal the taskbar when the user has the terminal maximized or fullscreen
1948,<desc> the current config object for aws-sdk is missing the majority of the parameters.  i filled it in. </desc> <cmt> filled out the 'config' object for 'aws-sdk'. </cmt> <cmt> aws-sdk: added support for apiversion/apiversions config options. </cmt>,fill in config options for aws-sdk
1949,"<desc> electron's menuitem class has two different signatures for its click-related functions. the first is the menuitem#click instance method which is called by electron when a menu item is clicked and the second is the event handler which consumers provide which is invoked via the click instance method. the instance method takes an event instance, a browserwindow instance and a webcontents instance while the click callback takes a menuitem instance (the item just clicked), a browserwindow instance and an event instance. this pr updates both signatures such that they conform to the current state of affairs in electron. make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. ~~~run npm run lint package-name if a tslint.json is present.~~~ provide a url to documentation or source code which provides context for the suggested changes:  ~~~increase the version number in the header if appropriate.~~~ ~~~if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }.~~~ </desc> <cmt> the click callback accepts an event as its third param </cmt> <cmt> see </cmt> <cmt> fix signature for menu item click instance method </cmt> <cmt> see </cmt> <cmt> add tests to verify new signatures </cmt> <cmt> add myself to the definitions list </cmt>",fix electron's menuitem click signatures
1950,"<desc> this change updates the aggregation script, map script for aggregations, and field scripts to extend docbasedscript to give them access to the new fields api. </desc> <cmt> add fields api to scripted metric aggs and aggregation scripts </cmt> <cmt> add fields api to script fields </cmt>",add fields api to aggregation scripts and field scripts
1951,"<desc> from auto-1016, we have downstream consumers of our ci systems who may not want to push to dockerhub. this pull request allows these downstream consumers who are running our ci code to push to internal registries exclusively. select one: select any that apply: </desc> <cmt> disable docker interactions for security-like repos. </cmt> <cmt> update check string to catch other repo. </cmt>",don't always push to dockerhub
1952,"<desc> lib/ansible/modules/cloud/amazon/lambda.py ansible version ansible 2.3.0 (lambda-add-dead-letter 84c285fcc1) last updated 2017/02/21 09:49:11 (gmt -400) config file = configured module search path = default w/o overrides allows user to set, modify, and delete lambda's deadletterconfig. to delete set dead_letter_arn to an empty string: """". closes #21032. playbook used to test: --- - hosts: localhost tasks: - name: looped creation lambda: name: '{{ name }}' state: present zip_file: '{{ zipfile }}' runtime: 'python2.7' role: '{{ role }}' dead_letter_arn: '{{ sns_arn }}' handler: '{{ handler }}' </desc> <cmt> add dead_letter_arn option for lambda.py </cmt> <cmt> fix logic so deadletterconfig can be deleted </cmt> <iss> add support for deadletterconfig </iss>",add dead letter option for lambda module
1953,"<desc> this fixes #1558 and uses ast_compare=1 on travis tests, so we can make sure those don't break going forward. </desc> <cmt> run yarn to update yarn.lock </cmt> <cmt> upgrade typescript-eslint-parser, use jsxtext instead of literal for strings inside jsxelement </cmt> <cmt>  </cmt> <cmt> so this fixes </cmt> <cmt> see here for more info about the new tsqualifiedname node type: </cmt> <cmt>  </cmt> <cmt> run ast comparison tests on travis </cmt> <iss> (typescript) react literals fail `--debug-check` </iss>","upgrade typescript parser, fix and run ast tests on travis"
1954,"<desc> fixes #13016 overall the changes are made to address how dictionaries are not ordered in python <= 3.5. the major changes are as follows: uses ordereddict in test to make sure the values passed pytest.mark.parametrize has a deterministic order. users sorted on sets for a deterministic order. changes made to sklearn/linear_model/coordinate_descent.py were to ensure that staticmethod path has a deterministic order in their respective classes. only the two classes that uses lasso_path as a staticmethod are affected. the makefile has been updated to take advantage of pytest-xdist. when pytest-xdist spawns processes, the processes independently look through all files in sklearn to test. if the order of discovered test functions are not the same for all processes, pytest-xdist will return an error. travis-ci does not look like it gets that much faster. locally, this pr does speed up running our tests suite. </desc> <cmt> tst: adds pytest-xdist support </cmt> <cmt> tst: add pythonhashseed to command </cmt> <cmt> tst: fix </cmt> <cmt> tst: order pytest parameters </cmt> <cmt> tst: fix for xdist </cmt> <cmt> tst: adjusts dicts for 3.5 ordering </cmt> <cmt> tst: fix </cmt> <cmt> tst: fix </cmt> <cmt> tst: fix </cmt> <cmt> tst: fix </cmt> <cmt> enh: faster </cmt> <cmt> tst: fix </cmt> <cmt> tst: optimize </cmt> <cmt> tst: fix </cmt> <cmt> rfc: minor </cmt> <cmt> rfc: add commands for parallel pytest </cmt> <cmt> rfc </cmt> <iss> parallelize tests again? </iss>",ci uses pytest-xdist to parallelize tests
1955,"<desc> closes #24076 closes #16785 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry additionally, date strings with utc offsets that are using in indexing are now validated by the following: an error is raised if 2 date strings have different utc offsets an error is raised if the date strings have a utc offset and the index is not timezone aware. </desc> <cmt> bug: indexing with utc offset string not longer ignored </cmt> <cmt> add whatsnew </cmt> <iss> err: validate partial string indexing with tz-aware end-points </iss> <iss> slicing datetimeindex should be timezone aware </iss>",indexing with utc offset string no longer ignored
1956,"<desc> closes #26366 tests passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry pandas/core/indexes/timedeltas.py taken care of as well since the errors were the same. </desc> <cmt> fis type annotation </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix some errors and remove the module from mypy.ini </cmt> <cmt> fix linting errors </cmt> <iss> fix type annotations for pandas.core.indexes.datetimes </iss>",fix type annotations in pandas.core.indexes.datetimes
1957,"<desc> adds type hints for controller.py and backend_worker.py i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> add some monkeytype type hints </cmt> <cmt> manually clean up autogenerated type hints for api.py </cmt> <cmt> added optional types </cmt> <cmt> merge from master </cmt> <cmt> travis format </cmt> <cmt> merge from master </cmt> <cmt> travis format </cmt> <cmt> removed binary files </cmt> <cmt> fix minor errors </cmt> <cmt> travis format </cmt> <cmt> removed binary files again </cmt> <cmt> removed last binary file </cmt> <cmt> add type hints for controller, backend_worker </cmt> <cmt> fix type errors on running test_api </cmt> <cmt> travis format </cmt> <cmt> remove annotations import </cmt>",add type hints for controller and backend_worker
1958,<desc> hi there! this pr just renames parameters seed and nthread to random_state and n_jobs respectively in scikit-learn wrapper with keeping backward compatibility. the most pieces of code is for keeping backward compatibility. is it necessary to leave old parameters for a while or should i remove all this stuff and just rename parameters? </desc> <cmt> updated scikit-learn interface </cmt> <cmt> fixed better description </cmt> <cmt> updated set_params() </cmt>,parameters renaming for sklearn naming convention
1959,"<desc> in order to spare the limited build credits we have on travis, i was thinking we could reduce the number of cron builds we do there: we should migrated the icc build to azure but this can be done in a dedicated pr (todo) we can only do nightly linux/arm64 wheel build only for the latest python version to spare resources: people who run scikit-learn bleeding edge builds are more likely to also run the latest python version we can remove the linux/arm64 cron test job that is redundant with the nightly linux/arm64 wheel build. note that the linux/arm64 test fail with scipy 1.6.0 which is handled in the dedicated issue: #19111. </desc> <cmt> maint reduce travis build load </cmt> <cmt> re-add [arm64] for manual arm64 builds in prs </cmt>",ci reduce travis nightly load
1960,"<desc> git has updated xdiff to produce conflict markers that match the eol style in the conflicting files.  this means that if you have checked in cr/lf files into your repository, and perform a merge, you will now get a conflict file that also has cr/lf line endings. update our xdiff to match theirs, to give us this same functionality, and add some unit tests to ensure that it works. </desc> <cmt> xdiff: upgrade to git's included xdiff </cmt> <cmt> upgrade xdiff to git's most recent version, which includes changes to </cmt> <cmt> cr/lf handling.  now cr/lf included in the input files will be detected </cmt> <cmt> and conflict markers will be emitted with cr/lf when appropriate. </cmt> <cmt> merge: test cr/lf conflicts for cr/lf files </cmt> <cmt> ensure that when the files being merged have cr/lf line endings that the </cmt> <cmt> conflict markers produced in the conflict file also have cr/lf line </cmt> <cmt> endings. </cmt>",conflict markers should match eol style in conflicting files
1961,"<desc> calls to threadpool.markthreadexecution() and threadpool.markthreadcompletion() got removed in the 1.3 -> 1.4 rewrite.  this adds them back and gets the unit tests contributed by @nurkiewicz working.  thanks for those, @nurkiewicz! </desc> <cmt> hystrixthreadpoolmetrics.getrollingcountthreadsexecuted() always returns 0 in 1.4.x - failing test case </cmt> <cmt> conflicts: </cmt> <cmt> hystrix-core/src/main/java/com/netflix/hystrix/hystrixthreadpoolmetrics.java </cmt> <cmt> added back calls to threadpool.markthreadexecution() and .markthreadcompletion() in abstractcommand </cmt>",added thread pool metrics back to execution flow
1962,"<desc> it turns out that it's necessary to special case exclusivity builtins and add flags to sil instructions because of a couple circumstances: swift 3 mode exclusivity warnings will continue to be warnings. the standard library will continue building in swift 3 mode (for the foreseeable future). </desc> <cmt> [exclusivity] add a [builtin] flag to begin_[unpaired_]access. </cmt> <cmt> this flag supports promoting keypath access violations to an error in </cmt> <cmt> swift 4+, while building the standard library in swift 3 mode. this is </cmt> <cmt> only necessary as long as the standard library continues to build in </cmt> <cmt> swift 3 mode. once the standard library build migrates, it can all be </cmt> <cmt> ripped out. </cmt> <cmt> <rdar://problem/40115738> [exclusivity] enforce keypath access as an error, not a warning in 4.2. </cmt> <cmt> [exclusivity] make keypath enforcement an error in swift 3 mode. </cmt> <cmt> modify irgen to emit builtin access markers with an error flag in </cmt> <cmt> swift 3 mode. </cmt> <cmt> keypath enforcement is required by user code in swift 4+ mode, but is </cmt> <cmt> implemented within the standard library. a [builtin] flag marks the </cmt> <cmt> special case for access generated by builtins so that they are </cmt> <cmt> always enforced as an error regardless of the language mode. </cmt> <cmt> this is necessary for swift 4.2 because the standard library continues </cmt> <cmt> to build in swift 3 mode. once the standard library build migrates, </cmt> <cmt> this is all irrelevant. </cmt> <cmt> this does not actually affect existing swift 3 code, since the keypath </cmt> <cmt> feature wasn't introduced until swift 4. </cmt> <cmt> <rdar://problem/40115738> [exclusivity] enforce keypath access as an error, not a warning in 4.2. </cmt> <cmt> remove the optimize.sil.preserve_exclusivity attribute. </cmt> <cmt> fix a static exclusivity violation in openclsoverlay.swift. </cmt> <cmt> i noticed this during testing, but it has nothing to do with the other changes </cmt> <cmt> in this pr. this static violation has always been present as a warning and would </cmt> <cmt> continue to be a warning after my changes. </cmt>",enforce keypath exclusivity as error
1963,"<desc> this is to resolve a failure that looks related to a bad install of xcode 8.0 on our build bots and should be reinstated when the infra issue is diagnosed and resolved. instruments worked well when this was originally landed, and on the following commit, but started failing two commits after this originally landed. manual invocation of instruments on the build host currently results in: dyld: library not loaded: @rpath/instrumentsanalysiscore.framework/versions/a/instrumentsanalysiscore referenced from: /applications/xcode8.0.app/contents/developer/usr/bin/instruments reason: image not found abort trap: 6 it appears the /applications/xcode8.0.app/contents/applications directory (which contains instruments) is missing on the host. </desc> <cmt> revert ""make device discovery asynchronous (#10803)"" </cmt> <cmt> this reverts commit 972be9c8b4048e18ecfb8ab582159c8d78abace8. </cmt> <cmt> revert required in order to revert </cmt> <cmt> 37bb5f1300e67fe590c44bb9ecda653b2967e347, which is triggering failures </cmt> <cmt> on the chrome buildbots. </cmt> <cmt> revert ""use xcode instruments to list devices (#10801)"" </cmt> <cmt> this reverts commit 37bb5f1300e67fe590c44bb9ecda653b2967e347. </cmt> <cmt> instruments worked well when this was originally landed, and on the </cmt> <cmt> following commit, but started failing two commits after this originall </cmt> <cmt> landed. manual invocation of instruments on the build host currently </cmt> <cmt> results in: </cmt> <cmt> dyld: library not loaded: @rpath/instrumentsanalysiscore.framework/versions/a/instrumentsanalysiscore </cmt> <cmt> referenced from: /applications/xcode8.0.app/contents/developer/usr/bin/instruments </cmt> <cmt> reason: image not found </cmt> <cmt> abort trap: 6 </cmt> <cmt> it appears the /applications/xcode8.0.app/contents/applications </cmt> <cmt> directory (which contains instruments) is missing on the host. </cmt>",revert use of xcode instruments for device lookup
1964,"<desc> description adds emojis to the categories and adds a horizontal rule between cats. ignore the readme file, couldn't revert it back.. only edited the build.js script. what does your pr belong to? website snippets general / things regarding the repository (like ci integration) types of changes bug fix (non-breaking change which fixes an issue) enhancement (non-breaking improvement of a snippet) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) </desc> <cmt> test readme gen </cmt> <cmt> add emojis </cmt> <cmt> revert readme back </cmt>",add emojis to readme categories
1965,"<desc> when running on a cluster, users need to know which node to use for http requests. this is not a complete solution but at least gives the user some manual control - whichever node they first run serve.init() on will house the http proxy (usually the head node). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> pin http proxy </cmt> <cmt> log </cmt>",pin http proxy to the node that serve.init() is run on
1966,<desc> this allows for a simpler preview loader architecture as node manifests can be requested directly from the deployed frontend of the gatsby site instead of requiring a server to check the filesystem in .cache. </desc> <cmt> move processnodemanifests for inc builds </cmt> <cmt> remove unused import </cmt> <cmt> move node manifests to public dir </cmt>,write node manifests to public dir instead of .cache
1967,"<desc> issue: #7264 #7773 #6803 #7162 rearchitect documentformatting & global css reset port doc blocks to new architecture add syntax highlighting for gfm code blocks now, there are a set of components such as { h1, h2, ... } that are exported from @storybook/components/html. these components are individually styled and can be used to render mdx without any need for global styling. for doc blocks, there is a <resetwrapper> component that can achieve most of what the global reset from theming used to do, but can do it locally within the block. what i need @domyen in addition to major restructuring, the major change here is that the global reset in @storybook/theming also includes styles for some child components, e.g.: '*': { boxsizing: 'border-box', }, 'h1, h2, h3, h4, h5, h6': { fontweight: typography.weight.regular, margin: 0, padding: 0, }, the resetwrapper code does not do any of this: it only does things like setting the font for itself and all descendants. therefore each of the components in documentformatting needs to be updated. since there are styling tweaks that need to be done anyway, i am leaving this to you. both @ndelangen and i are available to help as needed. to properly test this, you need to comment out l36 in examples/official-storybook/config.js: adddecorator(storyfn => ( <themeprovider theme={convert(themes.light)}> {/* <global styles={createreset} /> */} {storyfn()} </themeprovider> )); then: cd examples/official-storybook yarn storybook inspect: doc blocks stories new addons|docs/markdown stories docs for mdx files docspage for stories </desc> <cmt> official-storybook: move addon-docs stories to subdirectory </cmt> <cmt> addon-docs: rearchitect documentformatting, legacy to documentwrapper </cmt> <cmt> addon-docs: restyle doc blocks with new documentformatting </cmt> <cmt> addon-docs: markdown mdx for testing new documentformatting </cmt>",fix css bleed issue in doc blocks
1968,"<desc> context and discussion:  tldr: a few teams have the convention to put hooks under a namespace and the current implementation doesn't catch hooks that are written this way. // is hook usesomething(); // is not hook => doesn't recognize foo.usesomething(); this prevented us from catching the true positives and started to cause issues, like t65929958. we want to extend the definition of ishook so that we can safely catch those that are used: on top level / not in react component or other hooks called in class component being conditionally called we intentionally don't include the namespace that are named in ""camelcase"" because there're a lot of false positive, eg: jest.usefaketimers this change requires us to move a few test cases that are used to be regression tests and were valid to invalid. test plan # under react > yarn test eslintrulesofhooks-test.js </desc> <cmt> extend namespace to pascalcase </cmt> <cmt> add valid case for jest.usefaketimer </cmt>",extend ishook to recognize those under pascalcase's namespace
1969,<desc> this pr also adds integer as a type of value when extracting values from _source. fixes #42858. </desc> <cmt> cover the integer values when extracting field values from _source </cmt> <iss> sql: extracting a single small number from _source fails with error </iss>,cover the integer type when extracting values from _source
1970,"<desc> description: hi there, related to pr #11538, here you find a few more fixes and enhancements. they all work on my installation, will follow up for the automated linting/ci tests. a breaking change is commit 963b34e that changes the entity ids in ha. for this, i appreciate some feedback from @philklei as the original author and @bakedraccoon as the contributor of the above-mentioned pr. related issue (if applicable): pull request in home-assistant.github.io with documentation (if applicable): example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> strip off the rts/io id from the entity id </cmt> <cmt> ignore exception thrown when the device does not provide an active state </cmt> <cmt> send actions with a label for easier identification in the tahoma log </cmt>",fixes and enhancements for the tahoma platform
1971,"<desc> we no longer have a separate powerpc64 and powerpc64le target_arch, and instead use target_endian to select between the two. these patches fix a couple of remaining issues. </desc> <cmt> use target_endian, not target.arch in cabi_powerpc64 </cmt> <cmt> now target_arch is powerpc64 on both big and little endian, we need to </cmt> <cmt> use target_endian when there are differences in the two abis. </cmt> <cmt> target_arch is always powerpc64, remove powerpc64le check </cmt> <cmt> we no longer need to check for powerpc64le, so remove it. </cmt>",powerpc64 fixes after removal of powerpc64le target_arch
1972,<desc> i hereby agree to the terms of the cla available at:  fix rare crash caused by using nullable column in prewhere condition. continuation of #11608 </desc> <cmt> fix header for nullable prewhere column. </cmt> <cmt> update tests. </cmt>,fix nullable prewhere type 2
1973,"<desc> closes #20303 tests added / passed: pytest pandas/tests/reshape/test_qcut.py pandas/tests/reshape/test_cut.py -v passes black pandas passes git diff upstream/master --name-only -- ""*.py"" | xargs flake8 whatsnew entry </desc> <cmt> update whatsnew file </cmt> <cmt> add bool to int coerce </cmt> <cmt> add bool to int coercion tests for cut and qcut </cmt> <cmt> syntax changes </cmt> <cmt> switch np.where condition to check if non nan </cmt> <iss> qcut raising typeerror for boolean series </iss>",coercing bool types to int in qcut
1974,"<desc> related: #18264 the current airflow version (2.x.x) supports custom xcom backends. and it means that the data from xcom could be larger than we think. (e.g. over 100gb) however, pythonoperator and leveldboperator will try to show all of those data from xcom as a log message. this issue can cause web issues such as breaking the web page (due to browser memory issue or rendering speed issue). and it also will make it difficult to see the other log message from the task. this pr suggests changing the loglevel info to debug, because xcom returned value can be treated debug purpose read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> feat: change the loglevel info to debug in pythonoperator </cmt> <cmt> feat: change the loglevel info to debug in leveldboperator </cmt>",change loglevel as debug for xcom returned value message
1975,<desc> i have followed (at least) the pr section of the contributing guide. migrated the following demos to hooks/typescript: components/links/buttonlink.tsx components/links/links.tsx components/transitions/simplecollapse.tsx components/transitions/simplefade.tsx components/transitions/simplegrow.tsx components/transitions/simpleslide.tsx components/transitions/simplezoom.tsx components/typography/typographytheme.tsx customization/components/classesnesting.tsx customization/components/classesshorthand.tsx customization/components/classesstate.tsx </desc> <cmt> [docs] migrate components/typography/typographytheme </cmt> <cmt> [docs] migrate components/transitions </cmt> <cmt> [docs] migrate components/links </cmt> <cmt> migrate some demos in customization/components </cmt>,migrate batch of demos to hooks/typescript
1976,<desc> bug fix (user facing) code base improvement (dev facing) some users don't know how to properly tick the check boxes. so i've modified the issue templates to give an example each. agreement i carefully read the contribution guidelines and agree to them. </desc> <cmt> added checkbox example </cmt> <cmt> added checkbox example </cmt>,added an example of how to use markdown checkbox
1977,<desc> i had to create a new project because spring-all already had a lot of configuration and avoiding conflicts was going to take too much time. besides the reader will have a cleaner and much simpler project to understand. </desc> <cmt> created spring-mvc-web-vs-initializer project </cmt> <cmt> code style check </cmt>,"created project ""spring-mvc-web-vs-initializer"" for the web.xml vs initializer article."
1978,"<desc> fixed a possible segmentation fault when no argument is provided. additionally, made tiny changes to print statements. </desc> <cmt> fixed possible segmentation fault </cmt> <cmt> fixed possible segmentation fault when no arg is supplied </cmt> <cmt> update mean.c </cmt> <cmt> various small changes to print statements. </cmt>",possible segmentation faults in numerical_methods/mean.c
1979,"<desc> this pr fixes #109680. it consists of following major changes: leverage the list view template to reuse the editors. this way we don't keep creating/removing code/diff editors while scrolling limit the editor contributions used the embedded diff editors. avoid unnecessary overview ruler rendering. the diff editor is slower than the native notebook editor, simply because in the diff editor, the amount of monaco editors doubled. the creation and deletion of monaco editors has some cost, even if it's a few miliseconds, rendering 20 monaco editors in a large viewport can cost ~100ms. so the performance of scrolling in the diff editor is definitely slower than scrolling in a notebook editor with the same resource. </desc> <cmt> allow init dimension for the diff editor and left/right side editors. </cmt> <cmt> reuse source code editor </cmt> <cmt> no longer render overview ruler. </cmt> <cmt> fix memory leak </cmt> <cmt> limit editor contribs in notebook diff view </cmt> <cmt> delay cell text model disposing. </cmt> <cmt> revert change to grooming notebook </cmt> <iss> scrolling in a notebook diff editor is sluggish </iss>",notebook diff editor perf improvement
1980,<desc> addresses #20308 this pr ensures polynomialfeatures is compatible with numpydoc: remove polynomialfeatures from docstring_ignore_list. verify that all tests are passing. change docstrings to maintain consistency. </desc> <cmt> remove polynomialfeatures from docstring_ignore_list </cmt> <cmt> fix numpydocs from polynomialfeatures </cmt> <cmt> change docstrings to maintain consistency </cmt>,doc ensures that polynomialfeatures passes numpydoc validation
1981,"<desc> when an application emits a link: rel=preload header, the h2 implementation refers to a push memo to see if it has already pushed the specified resource over the same connection.  if the answer is true, the implementation ignores the header.  if the answer is false, then it pushed the specified resource (if other conditions are met). the memo is implemented as: uses #887 to implement a lru cache of 1,024 entries at maximum hash codes (x31) of urls being pushed are stored in the lru cache implements #896 </desc> <cmt> tiny multi-thread cache implementation </cmt> <cmt> add files to h2o.xcodeproj </cmt> <cmt> add files to cmakelists.txt </cmt> <cmt> simplify the api </cmt> <cmt> make the use of mutex an optional feature </cmt> <cmt> clang-format </cmt> <cmt> early update should be an optional feature as well </cmt> <cmt> return if an entry already existed </cmt> <cmt> add failing test </cmt> <cmt> implement push memo using h2o_cache_t </cmt>",don't push the same resource twice over a single h2 connection
1982,"<desc> this is a fix to issue #19903 . when handle_unknow=""use_encoded_value"", use super()._fit(x, handle_unknow=""ignore"") to avoid raise error during the fit process. </desc> <cmt> fix ordinalencoder fit with unseen category </cmt> <cmt> add test cases </cmt>","fix ordinalencoder.fit should not raise an error  handle_unknown=""use_encoded_value"""
1983,<desc> the dynamic keymap (didn't know at the time) broke the keymap on my zeal boards and with the arrival of the m60-a i finally sat down to figure out why. this pr turns off dynamic keymap for my boards and brings m60-a into the hhkb layout. also brings back some of the backlight commands the broke during the zeal unforking. </desc> <cmt> fix firmware to work with latest wilba changes (i.e. dynamic keymap) and m60a. </cmt> <cmt> get back rgb backlight codes. </cmt>,update keymap to match latest changes to wilba's firmware.
1984,<desc> while reviewing #17062 the line height of the code blocks seemed a little small. this pr makes it slightly bigger: this pr master </desc> <cmt> sty better line height </cmt> <cmt> sty changes lineheight </cmt> <cmt> sty go to 1rem </cmt>,sty adjust line height of code blocks
1985,"<desc> previously: //src/python/grpcio_tests/tests/unit:_server_test //src/python/grpcio_tests/tests/unit:_server_test.python3 //src/python/grpcio_tests/tests/unit:_server_test.python2 now: //src/python/grpcio_tests/tests/unit:_server_test //src/python/grpcio_tests/tests/unit:_server_test.gevent //src/python/grpcio_tests/tests/unit:_server_test.both_pythons //src/python/grpcio_tests/tests/unit:_server_test.python3 //src/python/grpcio_tests/tests/unit:_server_test.python2 this required an update to the rules_python dependency to support the namespace package structure that gevent and zope use. because of a change in behavior in rules_python between our (very old) version and the most recent version, systems without a python3 binary can no longer complete the analysis phase. this breaks windows rbe. i have introduced a patch to make this a soft failure rather than a hard failure. the newer version of rules_python also requires python 3.6+ to be present on the host during the analysis phase. this is a problem for our linux rbe images, which only have python 3.5. i have also turned this into a soft failure. this pr introduced the py_grpc_test rule. this is intended to encapsulate all of the test configurations supported by grpc python which, at the moment, include python 2, python 3, and gevent (under python 3). soon, python 2 will be removed. several tests do not work under gevent. in order to skip them, i have used unittest.skipif. i think this should be the standard way to do this going forward. as you might have guessed based on history, many of these tests are flaky. i have marked them as such so that they will be retried and will therefore not become a blocker for merging prs. </desc> <cmt> wip </cmt> <cmt> add gevent test suite run under bazel. </cmt> <cmt> fix things up </cmt> <cmt> yapf </cmt> <cmt> fix up bazel files </cmt>",create bazel gevent test harness
1986,<desc> this pr changes the error message for two static patterns in a row. for example: class foo { class static func baz() { } // old: 'static' specified twice static class func bar() { } // new: 'class' cannot appear after another 'static' or 'class' pattern } resolves sr-11265. not sure if i have permissions for this: @swift-ci please test </desc> <cmt> fix: error message </cmt> <cmt> fix: error messages </cmt>,fix double static error message
1987,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. this pr would resolve #24346. for information why i think the return type should be bigi see there. hoping i correctly raised this pr. if anything is wrong, please let me know ;) </desc> <cmt> change return type of valueof to bigi </cmt> <cmt> expand tests to cover the previous change </cmt> <iss> @types/bigi: wrong return type for `valueof` </iss>",change return type of valueof to bigi (from number)
1988,"<desc> this pr makes minor modifications to the text about versions in the operator specification files, as well as the change logs. the proposed text is a bit more concise than the existing text, without losing any precision in what it communicates. </desc> <cmt> merge from main onnx repo </cmt> <cmt> changing the string discussing versions in operator specifications. </cmt> <cmt> merge from onnx base repo </cmt> <cmt> merge from master </cmt>",more concise operator versioning text
1989,<desc> tokenizedbuffer (and displaybuffer) now emit a tokenized event once a buffer is fully tokenized. they also emit a tokenized event when the buffer's grammar changes and is re-tokenized. editor uses this event as a trigger to determine if a file should use hard or soft tabs. the tokenization event is needed because comments at the top of a file may contain different tab styles than the code and should not be used to determine the tab state. this information is only available after the buffer is tokenized. closes #2421 </desc> <cmt> add tokenized event to tokenized buffer </cmt> <cmt> use tokenized buffer created by editor </cmt> <cmt> only emit the tokenized event after the first full tokenization </cmt> <cmt> add spec to re-emit the tokenized event when the grammar is changed </cmt> <cmt> determine softtab state after the buffer is tokenized. </cmt> <cmt> reword specs </cmt> <iss> tokenizedline::iscomment returns the wrong value for javascript blockquotes </iss>,use tokenized event to determine tab style
1990,<desc> this removes remained duplicated runs of ci for prs from the original repo and now is in consistency with appveyor and github actions configs. refer to #3096. </desc> <cmt> update .vsts-ci.yml </cmt> <cmt> update .travis.yml </cmt>,run travis and azure pipelines only for master branch
1991,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> fixing doc errors and spacing </cmt> <cmt> tsdoc changes </cmt>,escaping characters to match tsdoc
1992,"<desc> the cmake based packaging system is nice, but not quite production ready. move to the more painful but featureful debuild style. this is one step towards an upstreamable package. also, rename libbpfprog (ugh) to libbcc. split out python-bpf and libbcc-examples into separate packages that depend on libbcc. </desc> <cmt> add proper debian build support </cmt> <cmt> the cmake based build system is nice, but not quite production ready. </cmt> <cmt> move to the more painful but featureful debuild style. this is one step </cmt> <cmt> towards an upstreamable package. </cmt> <cmt> rename libbpfprog (ugh) to libbcc. </cmt> <cmt> split out python-bpf and libbcc-examples into separate packages that </cmt> <cmt> depend on libbcc. </cmt> <cmt> support versioning out of git tree in debuild </cmt> <cmt> this adds support for properly tagging the build when cmake is run not </cmt> <cmt> in a git tree, which is the case when building from src-deb. </cmt>","add proper debian build support, rename libbcc.so"
1993,"<desc> cherry-pick of #29258 into swift-5.2-branch explanation: if dictionary literal aren't well formed, implicit-member completion didn't use to work because it doesn't type check. this patch improves context type analysis for failed dictionary literal elements, so it increases the chance to successfully suggest completion inside dictionary literals. e.g. let dict: [someenum: string] = [.foo: bar, <here>] scope: code completion inside dictionary literals risk: low issue: rdar://problem/57096392 testing: added regression test cases reviewer: ben langmuir (@benlangmuir) </desc> <cmt> [codecompletion] improve context type analysis for dictionary literal </cmt> <cmt> - analyze the type of the literal in the context </cmt> <cmt> - if ':' is missing in the literal, treat the expression as a key </cmt> <cmt> expression </cmt> <cmt> - if the parent expression is tupleexpr, analyze the context type of the </cmt> <cmt> tuple first, then return the element type of the position </cmt> <cmt> rdar://problem/57096392 </cmt> <cmt> (cherry picked from commit 95f12afb7c527338d824bf01377624d462659556) </cmt> <cmt> [codecompletion] use codecompletionexpr as a value of dictionary literal </cmt> <cmt> when a completion happens in a key position and the value expression </cmt> <cmt> is missing. this allows type checker to use typevariable so it increases </cmt> <cmt> the chance to type check them successfully. </cmt> <cmt> (cherry picked from commit 9d44c455db90ddcf7557adada372842f03af1860) </cmt>",improve context type analysis for dictionary literals
1994,<desc> bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) all new and existing tests passed. </desc> <cmt> chore: add missing deps to packages </cmt> <cmt> chore: upgrade to webpack-bundle-analyzer@3 </cmt>,add missing package deps & upgrade to webpack-bundle-analyzer@3
1995,"<desc> as discussed last week, one of ugliest runtime imports in tslibs is of tm for tm.set_locale.  this moves set_locale and a couple of other locale-related functions out of tm. as discussed in #25162, #25203, #25613, this moves the affected functions to a new directory pandas/_config, intended to be strictly ""upstream"" from the rest of pandas (potentially even made actually-upstream as suggested here). following this and #25613, a bunch of other cleanup/simplification becomes feasible. </desc> <cmt> implement _config.localization to avoid runtime import in ccalendar </cmt> <cmt> move a couple more funcs to localization, move test_locale to test_localization </cmt>","move locale code out of tm, into _config"
1996,"<desc> if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. this pr upgraded the configuration center plugin, etcd, to v3.x. i will upgrade it too for the service discovery plugin. we had a discussion on mail list. </desc> <cmt> upgrade etcd to v3 </cmt> <cmt> update changes.md </cmt>",upgrade etcd cluster coordinator and dynamic configuration to v3.x
1997,<desc> #261 fix for invalid characters in dimensions generated by apps.plugin #268 netdataerrorcallback() enhancements </desc> <cmt> enhanced error reporting in netdataerrorcallback() #268 </cmt> <cmt> users and group names are filtered for invalid characters #261 </cmt> <cmt> fixed source files permissions </cmt>,apps.plugin fix for invalid named; netdataerrorcallback enhancements
1998,"<desc> adds a check to the prepare-stable script to prevent experimental builds from being published using stable semver versions. also updates the function that downloads the artifacts to pull from the correct ci job. i think instead of two separate ci workflows, a better approach might be to build stable artifacts to the build directory and the experimental artifacts to a build_experimental directory, and generate both within the same workflow. this would take some work since lots of things assume the output directory is build, but something to consider in the future. test plan ./scripts/release/prepare-stable.js --skiptests --version=0.0.0-experimental-d364d8555 and confirm that it exits with an error message. </desc> <cmt> download correct artifacts for release channel </cmt> <cmt> experimental builds should pull artifacts from the </cmt> <cmt> process_artifacts_experimental job. </cmt> <cmt> i think instead of two separate ci workflows, a better approach might </cmt> <cmt> be to build stable artifacts to the build directory and the </cmt> <cmt> experimental artifacts to a build_experimental directory, and </cmt> <cmt> generate both within the same workflow. this would take some work since </cmt> <cmt> lots of things assume the output directory is build, but something </cmt> <cmt> to consider in the future. </cmt> <cmt> prevent experimental promotion to stable </cmt> <cmt> adds a check to the prepare-stable script to prevent experimental </cmt> <cmt> builds from being published using stable semver versions. </cmt>",update release scripts to support experimental releases
1999,"<desc> the next changes were made: the description of short script form was added. the mention of obsolete config parameter script.default_lang config parameter was removed. the link to ""how to use scripts"" was added to ""update by queue"" docs. @nik9000, please have a look on these changes. i've tested them with gradle and build them too. everything seems ok... </desc> <cmt> adding the description of short script form </cmt> <cmt> a mention of obsolete script.default_lang config param is removed </cmt> <cmt> a link to ""how to use scripts"" is added to ""update by queue"" docs </cmt>",update docs about script parameter
2000,"<desc> this pr proposes to migrate the test_compatible_versions unit test from snapshots to a blocks.log based system.  this removes any dependency on the post-conditions of the methods used to construct blockchains in our tester framework. instead of building a ""new"" chain in a way that was intended to be deterministic but rarely was in practice, the new process will load replay a small blocks.log file to reconstruct the head state of the chain with the latest code.   it will then systematically check that this state is also recoverable from v2, v3 and v4 snapshots of that same chain. this pr also restores the full integrity checksum based check. the blocks.log was created using v1.8.14 so as to have minimal requirements on the reading process.  if the minimum compatible blocks.log version exceeds the version produced by v1.8.14 then this blocks.log may need to be migrated to a newer version. the snapshots were created with the following versions based on this blocks.log: v2 : v1.8.14 tag v3 : v2.0.7 tag v4 :  26e4100 commit (aka head before the new snapshot was added) the unit test now takes an additional program option: --generate-snapshot-log which will attempt to deterministically recreate the blocks.log file prior to running the test.  this will not overwrite the repo version automatically.  there is no guarantee that the resulting chain matches the existing log but this may be useful in the future when a snapshot bump cleans out old versions and we want to start fresh the pre-existing --save-snapshot still works and will be useful as a forward compatible way of generating the future snapshots for this test.  when a new version is created, the author would need to add it to the list of tested versions, run the unit-test with --save-snapshot then copy the file(s) from <build>/unitttests/snapshosts/snap_v*.{bin,json}.gz to the working tree. </desc> <cmt> migrate to log based construction </cmt> <cmt> refactor snapshot test to build state from a blocks.log file instead of a set of tester methods; create v4 snapshots in prep for farming older versions </cmt> <cmt> created a blocks.log compatible with 1.8.x </cmt> <cmt> created v2 snapshots from v1.8.14 tag </cmt> <cmt> created v3 snapshots from v2.0.7 tag </cmt> <cmt> re-created v4 snapshots with the blocks.log that was 1.8.x compatible </cmt>",change to log based snapshot test
2001,"<desc> description: found a bug in pythonegardia package, have fixed it. updating the requirements file and egardia.py file to require that new version (.18). </desc> <cmt> bumping pythonegardia package requirement up to .18 </cmt> <cmt> updating requirements_all to reflect updated pythonegardia package .18 </cmt>",pythonegardia package requirement to .18
2002,"<desc> directly support multiple axes + keepdims in c++. sum_axis, max_axis and min_axis can be depreciated. refer to #2197 . also, the mx.nd.sum(a) will now return a ndarray with shape (1,). the previous sum operator implemented using python will cast it to a float (see </desc> <cmt> add full support of sum (multiple axes + keepdims) </cmt> <cmt> fix style </cmt>",sum with axis full support
2003,"<desc> cleanup 2/3 of style/test_bar.py. parametrises the tests for vmin/vmax clipping and widening, to test with different combinations of align. also adds fixtures for existing tests in the file. </desc> <cmt> renamed a file </cmt>",styler bar tests cleanup 2/3
2004,"<desc> this change shaved 175 kb off of our minified engine javascript. </desc> <cmt> embind doesn't always need the full std::type_info record.  if emscripten_has_unbound_type_names=0, then use a lighter type identifier.  this shaves 175 kb off of our engine's minified javascript. </cmt> <cmt> add a way to opt out of compiler-generated type names for smart pointers and wrapper types. </cmt> <cmt> always require an explicit name for shared_ptr and wrapper type bindings </cmt> <cmt> some compile fixes </cmt>",embind code size reduction by using lightweight rtti record for non-polymorphic types
2005,<desc> catch exceptions won't work with nested workflow. this pr fixed this. closes #18144 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> up </cmt> <cmt> up </cmt> <cmt> format </cmt> <iss> nested workflow with catch exceptions failed </iss>,fix nested workflow with catch exception bug
2006,<desc> remove performance tests of type once. this is needed to run all performance tests in statistical comparison mode (more reliable). </desc> <cmt> remove infinite performance tests </cmt> <cmt> renamed a test </cmt> <cmt> removed outdated info </cmt> <cmt> addition to prev. revision </cmt> <cmt> remove unused features from performance test </cmt>,"remove performance tests of type ""once"", finally."
2007,"<desc> support for stubbing datetime.now with travel_to was added in #18758. it was later backported to 4-2-stable as part of d7ac341, but the tests and changelog entry were not included. the documentation update from #19303 is also included here. </desc> <cmt> change as::testing::timehelpers#travel_to to also stub datetime.now </cmt> <cmt> add datetime.now to list of timehelpers#travel_to stubbing [ci skip] </cmt>","backport tests, changelog and docs for travel_to datetime support to 4-2-stable"
2008,"<desc> this pr fixes the use case where the link is written like this: <a href=""helloworld.htm""><b>hello</b> world</a> with the previous implementation, it returned a link.text set to ""hello"". now, it returns ""hello world"", as expected. </desc> <cmt> basesgmllinkextractor: fixed unknown_endtag() so that it only set current_link=none when the end tag match the opening tag </cmt> <cmt> basesgmllinkextractor: added unit test of a link with an inner tag </cmt> <cmt> basesgmllinkextractor: fixed the missing space when the link has an inner tag </cmt>",fixed link text when there is an inner tag
2009,"<desc> this pr adds features so that namespaces work with the new session builder api. you can now do ray.client().namespace(""hello world"").connect() note: part of this pr is an incidental bug fix where ray.runtime_context().get() was broken in client mode. the fix was necessary to make this pr work so it's included (along with the modification to the test case). closes #15949 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add namespace to client </cmt> <cmt> done? </cmt> <iss> getting namespace from global context doesn't work with ray client </iss>",client builder api namespace support
2010,<desc> this is related to #27260. the elasticsearch-nio jar is supposed to be a library opposed to a framework. currently it internally logs certain exceptions. this commit modifies it to not rely on logging. instead exception handlers are passed by the applications that use the jar. </desc> <cmt> work on remove logging from elasticsearch-nio </cmt> <cmt> accept generic exception handlers </cmt> <cmt> add doc </cmt>,remove logging from elasticsearch-nio jar
2011,"<desc> i haven't removed ak::out yet, because i am expecting merge conflicts. (i mean pretty much everything wants to write to stdout at some point.) since we build with -werror, marking it with [[deprecated]] will produce a helpful error message and we can do the renaming of ak::new_out to ak::out in a week or so. </desc> <cmt> ak: introduce sourcegenerator::fork(). </cmt> <cmt> previously, i abused the copy constructor, this is a lot better. </cmt> <cmt> ak: eradicate the uses of out(). </cmt> <cmt> ak: add [[deprecated]] to out(). </cmt>",eradicate remaining calls to ak::out().
2012,<desc> null grid cells in sql lab's result set were no longer returning their muted styling (italicized and muted gray). this was fixed by applying the null styles through the rendertablecell function instead of rendergridcell. with  less than 50 columns (table) with 50+ columns (grid) go to the sql lab editor make a query that returns a null value observe the corrected styling includes db migration (follow approval process in sip-59) </desc> <cmt> fix null styling in gridcell </cmt> <cmt> removed unnecessary imports </cmt>,null styling in grid cell
2013,<desc> i hereby agree to the terms of the cla available at:  fix possible crash/wrong number of rows in limit n with ties when there are a lot of rows equal to n'th row. detailed description:  leak: </desc> <cmt> fix limit with ties </cmt> <cmt> get rid of sharedchunk </cmt>,fix limit with ties wrong result and memory leak in mergingsortedtransform
2014,"<desc> plus add a compile option to target different versions of windows. needed because for touch events the lowest release is windows 7, but for 2.1 we are targeting vista. this code is donated to godot by adpodnet. (more on this on an upcoming blog post.) </desc> <cmt> implement multitouch on x11 </cmt> <cmt> improve/fix multitouch on windows </cmt> <cmt> - fix logic error. </cmt> <cmt> - track touches to enable defensive handling and releasing on focus out. </cmt> <cmt> - change comment-out by preprocessor #if. </cmt> <cmt> add build param for targeted windows version </cmt> <cmt> remove dead code from windows build script </cmt>",implement multitouch on x11 and improve it on windows (2.1)
2015,<desc> adds framework support for the floating cursor for text editing on ios. it can be triggered by either a force press on the keyboard or (on ios 12) by long pressing the spacebar. fixes #17030 (#5445). </desc> <cmt> initial force cursor </cmt> <cmt> adds force cursor </cmt> <cmt> initial cursor implementation </cmt> <cmt> minor fix </cmt> <cmt> working floating cursor </cmt> <cmt> nits </cmt> <cmt> nits </cmt> <cmt> adds test </cmt> <cmt> nit </cmt> <cmt> nit </cmt> <cmt> nit </cmt> <cmt> final nit </cmt> <cmt> final nit </cmt> <iss> support keyboard cursor move on ios </iss>,adds support for floating cursor
2016,"<desc> added async support: refactored the tasks.py to return the query id and added ability to run the code async. changed the celery_tests to be more end to end (calling run_sql endpoint instead of celery function) added implementation of async run of the hive and presto queries added dependencies required by pyhive implemented progress bar for the async queries added extra fields to the query object to improve traceability: limit_used, select_as_cta_used, executed_sql, select_sql tackles backend of the: #858, #746, #886 implement progress bar for the presto / hive queries implement remote query execution it is a preliminary pr and some more things needed to be done. todo: unit test async queries (presto and hive engines) implement cancel_query endpoint add query_results endpoint </desc> <cmt> refactor the query runner to enable async mode. </cmt> <cmt> refactore the sql calling functions into the queryrunner class. </cmt>",async support for the queries in the sql lab.
2017,<desc> new test: removelistenerwhendispatching customeventtest labelkeyboardeventtest spriteaccelerationeventtest </desc> <cmt> issue #2087: init event::_userdata. </cmt> <cmt> issue #2087: bug fix in eventdispatcher: _isregister fix. </cmt> <cmt> issue #2087: adding new eventdispatcher test. </cmt> <cmt> 1) removelistenerwhendispatching </cmt> <cmt> 2) customeventtest </cmt> <cmt> 3) labelkeyboardeventtest </cmt> <cmt> 4) spriteaccelerationeventtest </cmt> <cmt> issue #2087: enabling acc when testing it. </cmt> <cmt> issue #2087: renaming eventdispatchertest name to eventdispatchertest(new) </cmt>,adding  new event dispatcher test and bug fixes.
2018,<desc> this refactors incident details components to use typescript and adds additional + more accurate typings. </desc> <cmt> rename to tsx </cmt> <cmt> rename organizationincident -> incident </cmt> <cmt> remove old proptypes </cmt> <cmt> change to use await async </cmt> <cmt> rename more files to .tsx </cmt> <cmt> add more types </cmt>,refactor incident details to typescript
2019,"<desc> converts sharp usage based on file paths to file streams, e.g. // before const imgstats = await sharp(file.absolutepath).stats() // after const pipeline = sharp() fs.createreadstream(file.absolutepath).pipe(pipeline) const imgstats = await pipeline.stats() for the writing of files we use sharppipeline.tobuffer() + fs.writefile() for now. we probably will change it to filestream in future pr (will just need to revert 31cfaf3). running the image-processing benchmark didn't show any major speed improvement/degradation </desc> <cmt> copied changes </cmt> <cmt> new changes </cmt>",use file streams instead of file paths
2020,"<desc> issue: n/a this applies the eslint-plugin-storybook to the monorepo, as well as fixes for all of its recommended rules. there are quite a few changes. i added some @todo for discussions. </desc> <cmt> add eslint-plugin-storybook </cmt> <cmt> add temporary lint:storybook command </cmt> <cmt> link eslint-plugin locally </cmt> <cmt> clarify sb extract documentation </cmt> <cmt> upgrade eslint-plugin-storybook to official release </cmt> <cmt> attempt to fix some linting errors </cmt> <cmt> disable default-exports rules for storiesof files </cmt> <cmt> update eslint-plugin-storybook </cmt> <cmt> apply eslint-plugin-storybook to all files </cmt> <cmt> fix/disable eslint rules </cmt> <cmt> apply prefer-camel-case rule to all story files </cmt> <cmt> update eslint plugin and remove unecessary command </cmt>",add eslint-plugin-storybook to the repo
2021,<desc> this fixes a bug where styled components are overriding common container styles for stackedbarchart it also fixes a bug where colors were not working on projectfilterschart </desc> <cmt> increase scoping to override styled component styles for project-filters-chart class </cmt> <cmt> remove width: 100% and height: 100% from figure component because it is overriding traditional width and height styles </cmt>,svg chart excessive height / missing colors
2022,<desc> add associated slides fix typo </desc> <cmt> fix typo in intro to scan in theano notebook. </cmt> <cmt> add link to associated slides to intro to theano notebook. </cmt> <cmt> * feature/theano-update: </cmt> <cmt> add link to associated slides to intro to theano notebook. </cmt> <cmt> fix typo in intro to scan in theano notebook. </cmt>,add slides to theano intro notebook.
2023,<desc> this fixes #149 and #151 </desc> <cmt> properly bundle all files in linux install step </cmt> <cmt> run make install on linux build </cmt> <cmt> use correct default magic database </cmt> <cmt> set default magic db permissions correctly </cmt> <cmt> fixed magic file detection issues </cmt> <cmt> don't install default magic file if none was found </cmt> <cmt> try fix windows packing issues </cmt> <iss> libimhex.so missing from binary download </iss>,properly pack all dependencies into nightlies on all platforms
2024,"<desc> the user can now put {'force_mirroring': 'true'} as attributes to force mirroring of a particular operator. @tqchen i got the following observations, did you observe similar thing when coding up the mirroring feature? some operators (e.g. batchnorm) will crash when mirroring is turned on, with some error like src/symbol/graph_executor.cc:606: check failed: (info.type) != (knotinitialized). the memory consumption is a bit mysterious to measure, for the cifar10 example. although i'm only using pycuda to query the total gpu free memory, which is a very rough estimation, i could see that running the exactly same network training (without touching any mirroring option) could actually lead to quite different reporting of memory consumption. </desc> <cmt> add batch callback parameter to image training examples </cmt> <cmt> script for testing mirroring memory consumption </cmt> <cmt> a convenient interface for getting attr </cmt> <cmt> use attributes to decide whether mirroring is enabled </cmt> <cmt> use attributes to set force_mirroring </cmt> <cmt> some comments on the cifar10-mirroring test case </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",using attributes to enable mirroring for an operator
2025,"<desc> reverts #34097 somehow this was inadvertently merged by ansibot... </desc> <cmt> revert ""adds restart_if_needed argument to nios_zone (#35191)"" </cmt> <cmt> this reverts commit dd5256f3dfe66f34609c016cdf48906ec2e694cb. </cmt> <cmt> revert ""aci: move to 'host' parameter instead of 'hostname' (#35161)"" </cmt> <cmt> this reverts commit d6004852a2504cf3e5ed996c20b45b52d865a1e2. </cmt> <cmt> revert ""win_setup: add product id and product key in facts (#34097)"" </cmt> <cmt> this reverts commit cf1f7b53dfb88f996593ec37fe455c0a2e272758. </cmt>","add product id and product key in facts"""
2026,<desc> i added title case to the article headings on each of the pages for parts 0-5 (though not all parts needed edits). </desc> <cmt> remove title case from the heading to match the sidebar menu </cmt> <cmt> changed all top-level headings to title case </cmt> <cmt> all top-level headings (the main steps) were converted to title case. the sub-headings were left in sentence case. also changed instance of css in all lowercase to uppercase. </cmt> <cmt> change article heading for part-one to title case </cmt> <cmt> change article heading for part-two to title case </cmt> <cmt> change article heading for part-three to title case </cmt> <cmt> update index.md </cmt>,added title case to tutorial page headings parts 0-5
2027,"<desc> as far as netfilter statistics can be obtained with root access rights only, the nfacct plugin was separated from netdata daemon so that it isn't needed anymore to run the daemon as root for collecting netfilter stats. fixes #3749 component name nfacct plugin </desc> <cmt> prepare build configuration </cmt> <cmt> prepare plugin for separating </cmt> <cmt> add command line options </cmt> <cmt> add debug messages </cmt> <cmt> use text api </cmt> <cmt> minor fixes </cmt> <cmt> update the documentation </cmt>",split nfacct plugin into separate process
2028,"<desc> hi. i have a user in canada with a 2019 civic sedan touring that's now working. out of the box, it fingerprinted as 2017 hatchback. only difference i've noticed in this car is a lack of doors_status at 0x405 (still looking for this if it moved). right now, we're using self.standstill and self.door_all_closed like on accord as the only major changes. only remaining complaint is improper reporting of set speed as he uses metric on the eon (to be expected afaik). as both cars will fingerprint as hatchback ex, we could potentially merge these. we have a user with hatchback touring if we want to replace the ex print with that. vehicle weights are obviously slightly different. dbc file is unchanged as it used as-is from the 2017 car. note: early stages of testing on this, but initial impressions are its working fine. </desc> <cmt> fingerprint and new car </cmt> <cmt> you know the drill </cmt> <cmt> fix </cmt> <cmt> mod civic hatch to work for now </cmt> <cmt> try to merge hatch and other bosch </cmt> <cmt> fix </cmt>",merge new 2019 civic and existing 2017-18 civic hatch
2029,"<desc> i have read contributing.md. this pr only changes one algorithm file.  to ease review, please open separate prs for separate algorithms. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> created problem06 in projecteuler </cmt> <cmt> updating directory.md </cmt>",created problem06 in project euler
2030,"<desc> in preparation for being able to parse searchresponse from its rest representation for the java rest client, this adds fromxcontent to searchprofileshardresults and its nested classes. </desc> <cmt> adding parsing to profileresult </cmt> <cmt> adding parsing to aggregationprofileshardresult </cmt> <cmt> add parsing to queryprofileshardresult </cmt> <cmt> add parsing searchprofileshardresults </cmt> <cmt> small test changes concerning parsing time strings in profileresult and collectorresult </cmt>",add parsing from xcontent to searchprofileshardresults and nested classes
2031,"<desc> tc (qos) plugin has been optimized a bit. it also now supports reporting packets and dropped packets. there is more information already parsed by the plugin, per class, like lended traffic, borrowed traffic, etc. if anyone is missing this info, i can easily add it too. applied the last installer fix that protects charts.d config files, to node.d too. </desc> <cmt> prevent overwriting node.d configurations while copying </cmt> <cmt> tc plugin now cleanups properly; added tc packets and dropped packets charts </cmt> <cmt> added tc qos options to control individual charts </cmt>",qos plugin now reports packets and dropped packets; installer now protects node.d config files
2032,"<desc> the dim curve was somehow strangely applied to the saturation and value when setting the hsv. now it correctly applies the lightness adjustment to each color after doing the calculation. previously it would loose a lot of the color range, and the fading between colors in the rainbow mood and rainbow swirl effects were not smooth at all due to this. i also changed the dim curve to use the correct cie 1931 formula (i think it looks slightly better than the original one). it's still not perfect, especially at the low brightness levels. you can easily see jumps there. that's caused by the fact that the ws2812 only take 8 bits values, and many of the brightness values that the eye can see are not representable with only 8 bits per channel. this could be fixed if some high frequency dithering was applied. edit i forgot to say that the overall brightness of the leds might change a bit with this, so you might need to re-adjust the brightness level of you keyboard after applying this pull request. </desc> <cmt> apply the dim curve to the rgb output </cmt> <cmt> just like it's supposed to be used. it now looks much better. </cmt> <cmt> cie 1931 dim curve </cmt>",improve the rgb led effects
2033,"<desc> this currently has a few issues: 1.) this value is the number of tags that have been seen across the entire project -- not just the number of tags that have been seen for this issue -- so it's super confusing on the group tag page when all of the other values are scoped to values seen within the group. this reference was removed for the grouptagvalues react view with gh-4589, presumably because it was confusing there as well. 2.) it's not recorded correctly on the backend (see gh-5554) and is not a high priority to fix in the near future. </desc> <cmt> remove uniquevalues count from tag display ui. </cmt> <cmt> remove unique values from settings/tags/. </cmt>",remove unique tag counts display.
2034,"<desc> newly added groups were always initialising their z index to zero, instead of their position in the parent child list. </desc> <cmt> fixed  new groups incorrectly always adding with a z index of 0 </cmt> <cmt> removed this.z =0, missed from last push </cmt>",groups always had zero z index
2035,"<desc> this pull request will fix the hardcoded paths noted in issue #44, adds a script (not a very good one) that makes the cheatsheets folder and pulls in remote repos to populate it and also updates requirements.txt to add the additional needed requirements. </desc> <cmt> fix srv.bin to work -- listens on 0.0.0.0 </cmt> <cmt> adapter_learnxiny updated to not use hardcoded path </cmt> <cmt> get_answer.py updated to not use hard coded path </cmt> <cmt> replaced hardcoded paths with something kept local to the cheat.sh folder </cmt> <cmt> panela_colors not using hardcoded path </cmt> <cmt> less than ideal script to grab cheatsheets from different repos </cmt> <cmt> added additional requirements </cmt>","remove hardcoded paths, add script to get sheets, fix requirements"
2036,<desc> removing the script and image  element from the previewing svg to avoid loading images or run scripts from unknown resources. in case of script or image element is found an information bar will be shown on the top of the preview. references pr checklist validation steps performed tests passed and validated changes locally. </desc> <cmt> added implementation to remove script and image tag </cmt> <cmt> added unit tests for svgpreviewhandlerhelper </cmt> <cmt> updated unit tests for svgpreviewcontrol </cmt>,remove script and image element from svg
2037,"<desc> explanation: adds support for keypaths that reference computed properties requiring the capture of generic context. scope: completes the support for property references in key paths. the previous restriction here is difficult to explain to users otherwise. issue: rdar://problem/31768590 risk: low. additive improvement to key paths, should be almost no impact on the rest of the compiler. testing: swift ci </desc> <cmt> keypaths: support captured arguments in computed components. </cmt> <cmt> a necessary precursor to supporting subscripts and unspecialized generic accessors in general. give get/set components the ability to have an ""argument"" area that gets instantiated by copying out of the key path pattern arguments at instantiation time, and which holds ""witness"" information for how to copy, destroy, equate, and hash arguments. </cmt> <cmt> irgen: support for computed properties with dependent generic context. </cmt> <cmt> use the keypath implementation's new support for instantiating and dealing with captures to lower the generic context required to dispatch computed accessors with dependent generics. </cmt> <cmt> irgen: builtin.unknownobject should not be hardcoded to use objc refcounting. </cmt> <cmt> it's more appropriate to use unknown refcounting, which we correctly handle in the face of non-objc-interop elsewhere. fixes a problem where the linux standard library would contain an unresolvable reference to objc_release. </cmt>",support keypaths with dependently-generic computed components.
2038,"<desc> #4368 greylisted accounts are not allowed to access extended cpu/net limit in a subjective way. ""cloes get account"" will return the subjective cpu/net limit. if a transaction violates the cpu/net subject limit, it will be rejected by the node immediately. block replay & apply_block will always use the objective cpu/net limit for validation. command line options for producer (can appear multiple times): --greylist-account ""a11111111111"" new api urls: /v1/producer/add_greylist_accounts /v1/producer/get_greylist /v1/producer/remove_greylist_accounts </desc> <cmt> 4368 subjective to disallow account to access extended cpu/net limits </cmt>",subjective extended cpu/net resource access
2039,"<desc> i simply replaced all instances of ""magisk manager"" with ""magisk app"" </desc> <cmt> replace ""magisk manager"" with ""magisk app"" </cmt> <cmt> to stay consistent with the new name </cmt> <cmt> replace ""magisk manager </cmt> <cmt> replace ""magisk manager"" with ""magisk app"" </cmt> <cmt> to stay consistent with the new name </cmt>",update docs to use the magisk manager's revised name
2040,"<desc> update the ergodox / atreus 42 key layouts with cloud 9 ide shortcuts </desc> <cmt> add screen_nav layer for copy/pasting within screen </cmt> <cmt> working readreg/paste macros </cmt> <cmt> working read reg / paste macros </cmt> <cmt> write log and tran patterns, and expand </cmt> <cmt> add ls -la shortcut, add tab on combined layer </cmt> <cmt> put delete word on the right pinky key on shell_nav layer </cmt> <cmt> add tab on the right side, add reset key </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added cloud9 macros </cmt> <cmt> add cloud9 shortcuts to atreus layout </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",update dvorak 42 key layouts
2041,"<desc> for your consideration, this change adds a couple del statements to the teardown method in asynchttptestcase in order to encourage the gc to free up resources passed through application settings. if you are willing to merge this pr, i'd love to also see it applied to the 5.x and 4.x branches. </desc> <cmt> updated asynchttptestcase teardown to release app references </cmt> <cmt> releasing the application and http server references in teardown helps </cmt> <cmt> encourage the gc to clean up resources passed through the application </cmt> <cmt> settings. </cmt> <cmt> empty commit to trigger travis build </cmt> <cmt> switched to double quotes to make black happy. </cmt> <cmt> fixed mypy errors by referring to self correctly. oops. </cmt>",release app references in asynchttptestcase teardown method
2042,"<desc> closes #16939 </desc> <cmt> fix ice in overloaded call with incorrect arity </cmt> <cmt> when an overloaded call expression has parameters but the function </cmt> <cmt> object takes none, construct an array of formal argument types with </cmt> <cmt> the arity of the call expression so that we don't fail by indexing out </cmt> <cmt> of bounds later. </cmt> <cmt> closes #16939 </cmt> <cmt> add regression test for issue #16939 </cmt> <iss> ice calling an unboxed closure with the wrong number of parameters inside another closure </iss>",fix ice when checking overloaded call with wrong arity
2043,"<desc> resolve #4918, fix #5235. the important bits that i gathered from the discussion were: drf should internally encode/decode only strict json, since other modules (eg, postgres's jsonfield) may not be compatible with the extended float values (infinity, nan). incompatible values should raise an exception. users may still want to render/parse extended json. this pr does the following: adds an internal rest_framework.utils.json module that defaults to strict json encoding/decoding. all imports have been changed to rest_framework.utils.json, so they obey the stricter behavior. adds flake8-tidy-imports, which allows us direct users to import the json wrapper module. adds settings.strict_json, which controls the strictness of jsonparser & jsonrenderer. this defaults to true, but users can revert to the old extended behavior by setting this to false </desc> <cmt> add json util wrapper, failing jsonfield test </cmt> <cmt> update json imports </cmt> <cmt> add 'strict_json' api setting. </cmt> <cmt> strict_json controls the renderer & parser behavior on whether or not </cmt> <cmt> to accept non-standard float values (nan, infinity). </cmt> <cmt> add banned imports to prevent standard json import </cmt> <iss> jsonfield: infinity, -inifinity, nan are not compatible with postgres' json field </iss>",use strict float handling in json functions
2044,"<desc> the crash mentioned in the linked issue was happening because we use a single keyboardmanagerstate variable for both of the windows, so when one of the windows is closed there is most likely something getting set to nullptr while a window is still open. the way the code was written was considering only one window open, so the best way to solve this with minimal changes is to ensure only one window can be opened at a time. the pr changes the behavior of the buttons, such that when clicking either of the buttons - if edit keyboard or edit shortcut either of them are open, it will bring that window in focus. earlier if edit keyboard was open and you clicked the same button again, it would just bring that to focus. by this change we ensure that only one window is open at a time, and by bring that in focus the user should also notice the window lying open. this is a first step for #2466 . the pending work for the modal dialog is to prevent the user from being able to access the settings window while this dialog box is up. this also adds a fix where the remap button would stop working if you closed kbm from the taskbar (the runner would not crash though). pr checklist applies to #2469, #2569 cla signed. if not, go over here and sign the cla validation steps performed tried closing and reopening the windows with both the buttons multiple times. </desc> <cmt> bypass xamlbridge window focus handling </cmt> <cmt> constrain only one window can be opened at a time </cmt> <cmt> revert changes on files changed in another pr </cmt>",constrain the buttons such that only one of the windows can be opened
2045,"<desc> this change makes use of the generated protocols for fetchrequest and fetchresponse. the main challenge here was how to allow the transferrable bytes of the record set to be directly sent to the outgoing response without copying into a buffer. the proposed solution is similar to the existing multi-send object used in fetchresponse. however, a new writer class recordswriter was introduced to allow interleaving of bytebuffersend (for headers and other non-record fields) along with recordssend-s which implement the efficient byte transfer. another change introduced here is that fetchrequest and fetchresponse do not maintain their own copies of the fields from the message. instead, they hold a reference to the generated message class (fetchrequestdata and fetchresponsedata). read-only copies of different forms of the message data are created once open construction to allow for efficient access using the existing class methods. for example, in fetchrequest we hold the fetchrequestdata, but also compute and hold: private final fetchrequestdata fetchrequestdata; // these are immutable read-only structures derived from fetchrequestdata private final map<topicpartition, partitiondata> fetchdata; private final list<topicpartition> toforget; private final fetchmetadata metadata; and in fetchresponse, we similarly hold: private final fetchresponsedata fetchresponsedata; private final linkedhashmap<topicpartition, partitiondata<t>> responsedatamap; if we want, we could deprecate all the accessors on fetchrequest/fetchresponse and force callers to use the #data() method. this would eliminate the need for these additional data structures. finally, most of the other changes are fixing up tests that were actually using invalid default values for protocol messages (which are now enforced, thanks to the generated classes) as well as rectifying the json schema to match what the actual defined schemas were (e.g., fetch_response_v11) </desc> <cmt> kafka-10265 use the generated messages for fetchrequest and fetchresponse </cmt> <cmt> fix compile errors and checkstyle </cmt>",kafka-9629 use generated protocol for fetch api
2046,"<desc> if users feed single persistable variable to pe, this variable will be copied n(the number of place) copies, and feed those variable to different place separately. fix #18809 </desc> <cmt> update executor </cmt> <cmt> update executor feed </cmt> <cmt> update executor feed </cmt> <cmt> test=develop </cmt> <iss> cpu_num 10batch_size = 500 </iss>",support feed single persistable variable to pe
2047,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).   if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> refactor(fluent-ffmpeg): update types to match official api specification </cmt> <cmt> refactor(fluent-ffmpeg-tests): add missing semi-colon </cmt> <cmt> refactor: update metadata in definition file </cmt>",update certain methods in ffmpegcommand interface
2048,"<desc> we were allowing the pmrem cubemap size to vary based on the input images, but we had hard coded 256 as the size within the glsl.  this pr makes it clear that we have fixed the size and we also no longer varying the cubemap size based on the input. </desc> <cmt> pick a good default pmremgenerator cube size, and allow it to be overriden. </cmt> <cmt> fix the resolution to what is hard coded in the shaders. </cmt>",fix pmrem cubemap size at 256 for performance reasons
2049,"<desc> the current license file is a source header. i've replaced that with a full apache 2.0 text file, and added a notice file. the notice file will need changing, post migration when the code is fixed to match apache software foundation formats/policies. </desc> <cmt> creating notice. </cmt> <cmt> when code moves to apache, it will need adjusting to the apache format. </cmt> <cmt> replacing source header with full license text </cmt>",fixing license file and adding notice
2050,"<desc> new round of cmake improvements: added lzma, zlib support cmake creates pkg-config file from prepared template files are copied to working copy during build not during configure phase anymore (should be less confusing this way) fixed appending compile definitions this pr bumps the required cmake version to 2.8.9 to support finding lzma library. i think we agreed on sticking to versions < 2.8.12 in earlier iteration, but feel free to correct me. </desc> <cmt> add lzma and zlib support to cmake build system </cmt> <cmt> cmake 2.8.9 needed for findliblzma </cmt> <cmt> copy files during build phase, custom targets instead of commands </cmt> <cmt> previously some files were copied only during configure phase. </cmt> <cmt> custom targets seem nicer. </cmt> <cmt> create and install pkg-config file with cmake </cmt> <cmt> test new cmake branches with circle ci </cmt> <cmt> change all set_target_properties to set_property </cmt> <cmt> set_property function can append to lists, whereas previously used </cmt> <cmt> set_target_properties cannot. </cmt>","add zlib, lzma, pkg-config support to cmake build system"
2051,"<desc> this helps in resolving the react identifier correctly. fixes #11654 </desc> <cmt> add testcase for incorrect emit of jsx </cmt> <cmt> when creating react namespace identifier, set its parent to jsx opening element in the parse tree </cmt> <cmt> this helps in resolving the react identifier correctly and fixes #11654 </cmt>",set parent of reactnamespace identifier to be parse tree node
2052,"<desc> though this might seem in opposition to @tenderlove's #35404  it's made with the same goal of improving how we construct templates and keeping them immutable. previously, when a template without a format (ex. index.erb) was rendered, it was assigned the first format from details. though this was a convenient default, i'd prefer we didn't store it on template, and used that fallback explicitly at a higher level. this way template is only based on the file itself, and the set of locals it is passed. </desc> <cmt> allow format to be nil </cmt> <cmt> create templates with format=nil </cmt> <cmt> remove query_format argument from resolver </cmt>",allow nil format on templates
2053,<desc> added 'setmulticastinterface(netif*)' added a getter for the used 'udp_pcb' -> 'udp_pcb* pcb()' the information about the originating netif is also only available while processing 'onrx'. added the netif to the temp stored data and added a getter for this. </desc> <cmt> addition to udpcontext needed for leamdns2 </cmt> <cmt> addition to udpcontext needed for leamdns2 </cmt>,additions to udpcontext needed for leamdns2
2054,"<desc> this pull request switches the guids for default profiles from being randomly generated to being version 5 uuids. more info in #870. closes #870 requires documentation to be updated (#883) this pull request has a number of changes that seem ancillary, but they're general goodness. let me explain: i've added a whole new types test library with only two tests in since uuidv5 generation requires sha1, we needed to take a dependency on bcrypt i honestly don't think we should have to link bcrypt in conhost, but lto should take care of that i considered adding a new terminal-specific utils/types library, but that seemed like a waste the best way to link bcrypt turned out to be in line with a discussion @miniksa and i had, where we decided we both love apisets and think that the console should link against them exclusively... so i've added onecore_apiset.lib to the front of the link line, where it will deflect the linker away from most of the other libs automagically. startgroup: uuidtests::testv5uuidu8string verify: areequal(uuidexpected, uuidactual) endgroup: uuidtests::testv5uuidu8string [passed] startgroup: uuidtests::testv5uuidu16string verify: areequal(uuidexpected, uuidactual) endgroup: uuidtests::testv5uuidu16string [passed] </desc> <cmt> generate uuidv5s for default profiles </cmt> <cmt> closes #870. </cmt> <cmt> add a comment about using memcpy </cmt> <cmt> clean up </cmt> <cmt> move to types, add tests, finish almost everything </cmt> <iss> feature request: stable uuids for default profiles </iss>",switch to v5 uuids as profile guids for the default profiles
2055,<desc> md-toast now uses textcontent instead of content - content is deprecated </desc> <cmt> update text to textcontent for 1.0.0-rc5 </cmt> <cmt> update content to textcontent for 1.0.0-rc5 </cmt> <cmt> md-toast now uses textcontent instead of content - content is deprecated </cmt>,update md-toast text to textcontent for 1.0.0-rc5
2056,"<desc> the content_type parameter was renamed to response_class in release 0.19.0 tangential question to maintainers: this is the 3rd documentation-related pr i've opened this week. they all fall into different categories, but all have fairly small changes. is this disruptive? would it be better to condense any near-future prs into a single ""documentation"" pr? thanks in advance! </desc> <cmt> fix renamed parameter typo (content_type) </cmt> <cmt> renamed to response_class in release 0.19.0. </cmt> <cmt> specify response_class is a decorator parameter </cmt>",fix renamed parameter content_type typo
2057,"<desc> while i made this pr because we need the constants.getwebviewuseragentasync() in our project; i also noticed that the property installationid was missing. no test were defined so i also added them. see the expo documentation for constants for more info. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added missing properties 'installationid' and 'getwebviewuseragentasync()' to 'constants' declaration </cmt> <cmt> added tests for 'constants' declaration </cmt>",added missing 'installationid' and 'getwebviewuseragentasync()' to 'constants'
2058,"<desc> fixes #14792 closes #14814 the project id is currently used by sanity's image builder, which is used in a react component. @maybac it was faster for me to create a new pr but the credit goes to you, thank you!. </desc> <cmt> use public env for the project id </cmt> <cmt> moved util </cmt> <iss> [cms-sanity] add `next_public_` to readme env variables </iss>",expose the project id to the browser
2059,"<desc> use npx and yarn create to run create-next-app for each example in examples/. this: requires no additional install from the user as these both come with their respective package managers (npx with node ^8.x.x) skips an additional command, reducing the ""getting-started"" friction keeps global install of create-next-app up to date (not sure if npx actually pulls the latest) installs create-<starter-kit-package> globally, or update the package to the latest version if it already exists - yarn docs for those interested, this was done by: removing the npm i -g ... line with: for d in * ( cd $d && sed -i '/npm i -g create-next-app/d' readme.md ) done prepending npx to the execution command with vscode find: create-next-app --example replace: npx create-next-app --example adding the yarn command with: for d in * ( cd $d && sed -i ""/npx create-next-app --example/a # or\nyarn create next-app --example $d $d-app"" readme.md ) done this would have been easier had i learned sed properly prior to step 1. or 2. and just written a single command. interesting nonetheless. </desc> <cmt> remove global npm install of create-next-app </cmt> <cmt> add npx to create-next-app command in examples </cmt> <cmt> add bash to shell snippets </cmt> <cmt> add yarn create to next-app command in examples </cmt> <cmt> fix readmes named with lowercase </cmt> <cmt> change readmes to use uppercase </cmt>",use npx and yarn create to run create-next-app on examples
2060,"<desc> closes #1305 fixed an issue where ""possible eventemitter memory leak detected"" warnings could appear when running multiple specs. increased plugin child ipc listener limit to infinity so the unneeded warning ceases fixed an actual event listener leak in electron downloads code updated process.emitwarning patching to still log warnings in development, but in production, only log warnings to debug log has the original issue or this pr been tagged with a release in zenhub? </desc> <cmt> fix electron eventemitter memory leak in downloads </cmt> <cmt> raise eventemitter limit, suppress warnings in prod </cmt> <iss> do not display maxlistenersexceededwarning ""warning: possible eventemitter memory leak detected."" warning message during cypress run </iss>",suppress eventemitter warnings + other node warnings in prod
2061,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). note: the documentation link below is to the v9 documentation. there is no published documentation for v7; however, the code itself proves this change to be correct. in the v7 definitions, each interface that extends attribute has a getvalue() function. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added getvalue() and setvalue() to xrm v7 xrm.page.attribute. </cmt> <cmt> xrmpageenumattribute - added getvalue and setvalue </cmt> <cmt> revert ""xrmpageenumattribute - added getvalue and setvalue"" </cmt> <cmt> reverted incorrect changes to xrmpageenumattribute </cmt> <cmt> this reverts commit 9a14d6a289e41dcbd6ed8b0ae91c172c701dd756. </cmt>",xrm v7 index- added attribute.getvalue and setvalue
2062,"<desc> this pr makes the following changes: on the edit keyboard screen, key remappings are not applied, so even if the user has orphaned a key, then can still search with it in the drop down menu on the edit shortcuts screen, shortcut remappings are not applied, so even if the user has orphaned a shortcut, then can still use it on that window. this is for consistency with the above behavior. commented out app-specific and togglekeytomodifier handlers in the back-end (even though they wouldn't technically do anything unless they were in the settings). this can be uncommented when we add in the feature to the ui. pr checklist applies to #2551 cla signed. if not, go over here and sign the cla validation steps performed manually verified that even if a key is orphaned you can still use it in edit keyboard you can't use it if you change focus to another app and try typing - to make sure ""apply"" makes sense </desc> <cmt> commented out toggletomod and appspecific function calls </cmt> <cmt> added logic to make sure key remaps don't occur on edit keyboard window </cmt>",change behavior on edit keyboard screen to be physical keys
2063,<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> rename block to columnswithtypeandname. </cmt> <cmt> rename block to columnswithtypeandname. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt> <cmt> rename block to columns. </cmt>,use columnswithtypeandname instead of block for function calls [part 3]
2064,"<desc> added a new site:  fixed few typos and updated few comments to follow pep-8 standards note: few tests failing before the following commits </desc> <cmt> fixed grammar, typos, comments </cmt> <cmt> added new site: 7cups </cmt>",added 7cups site; fixed typos
2065,"<desc> fixes #3272 it seems that only a few backends (including llvm, metal) support struct-for, and i only fix this problem for llvm cuda and cpu backends. not sure whether this works for metal. </desc> <cmt> fix continue in struct for and add a test </cmt> <iss> [ir] continue statement behavior is confusing in struct for </iss>",fix continue statement in struct for and add a related test
2066,<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description ... test plan ... closing issues ... </desc> <cmt> improve mips.cs esil </cmt> <cmt> update </cmt> <cmt> update sign </cmt> <cmt> modify old test </cmt> <cmt> fix mips32 </cmt> <cmt> modify test file </cmt> <cmt> code style </cmt> <cmt> inline </cmt> <cmt> update mthi </cmt> <cmt> upstream </cmt> <cmt> kill warning </cmt>,fix anal_mips_cs some compile warning
2067,"<desc> this is my first rustc code change, inspired by hacking on clippy! the first change is to clear cached typeckresults from latecontext when visiting a nested item. i took a hint from here. clippy has a qpath_res util function to avoid a possible ice in latecontext::qpath_res. but the docs of latecontext::qpath_res promise no ice. so this updates the latecontext method to keep its promises, and removes the util function. related: rust-lang/rust-clippy#4545 </desc> <cmt> reset latecontext enclosing body in nested items </cmt> <cmt> prevents latecontext::maybe_typeck_results() from returning data in a </cmt> <cmt> nested item without a body. consequently, latecontext::qpath_res is less </cmt> <cmt> likely to ice when called in a nested item. would have prevented </cmt> <cmt> rust-lang/rust-clippy#4545, presumably. </cmt> <cmt> query for typeckresults in latecontext::qpath_res </cmt> <cmt> actually fulfills the documented guarantees. </cmt> <cmt> remove qpath_res util function </cmt>",improve safety of latecontext::qpath_res
2068,<desc> this fixes the nll migration mode (which is the default with edition=2018) to inspect all parents of a closure in addition to the closure itself when looking to see if ast-borrowck issues an error for the given code. this should be a candidate for beta backport. fix #55492 </desc> <cmt> borrowck=migrate mode needs to check parent(s) when its given a closure. </cmt> <cmt> regression test for issue 55492. </cmt> <cmt> update compare-mode=nll stderr files to reflect the fix to #55492. </cmt> <iss> nll: migration mistakenly downgrades when ast error is spread across closure and its parent </iss>,borrowck=migrate must look at parents of closures
2069,"<desc> hi all @apache/skywalking-committers according to openjdk website( java 8 (lts). at least may 2026 java 11 (lts). at least oct 2024 we should make the jdk11 compiling passed. that is the primary agenda when i started this work. also, with doing this, i planned to upgrade the grpc too. during the jdk11 compiling fix, the version of powermock was detected as the main block, so, i upgraded it to the 2.x directly. so, you would note, some libraries' versions(such as protobuf, protoc) changed because of grpc or powermock requirements. some tests are deleted because they are not valid in the latest powermock. sorry, i don't have enough time to fix all, because some of them make no sense to me. license updated if you have any concerns, please reply. </desc> <cmt> upgrade dependencies and make the jdk11 compiling passed. </cmt> <cmt> update license and fix license check file. </cmt> <cmt> add ci for jdk11 compiling. </cmt> <cmt> update doc. </cmt>",support jdk 11 compiling and upgrade dependencies
2070,<desc> add missing 'ended' method to the player declaration. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). -ended(): boolean; < </desc> <cmt> makes repository up to date </cmt> <cmt> adds player ended method </cmt> <cmt> fixes  some lint errors. </cmt>,adds missing 'ended' method to the player
2071,"<desc> i think you'll prefer the second simpler version (which i'll think you'll get if you just squash/merge) - but i kept the first, more complex version in so you could see it. for issue #136 </desc> <cmt> stop warning on fgets, complex version </cmt> <cmt> stop warning on fgets, simple version </cmt>","stop warning on fgets, jq_test.c:42"
2072,<desc> this is related to #36652. in 7.0 we plan to deprecate a number of settings that make reference to the concept of a tcp transport. we mostly just have a single transport type now (based on tcp). settings should only reference tcp if they are referring to socket options. this commit updates the settings in the docs. and removes string usages of the old settings. additionally it adds a missing remote compress setting to the docs. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> cleanups </cmt>,update transport docs and settings for changes
2073,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> minio: fixed .listbuckets() method signature </cmt> <cmt> updated minio package version </cmt>","fixed .listbuckets() method signature, bucketitemstate interface"
2074,"<desc> this pr updates the following tests to cover migration till release-1.11 (including release-1.10 and release-1.11): cepmigrationtest bucketingsinkmigrationtest flinkkafkaconsumerbasemigrationtest continuousfileprocessingmigrationtest windowoperatormigrationtest statefuljobsavepointmigrationitcase.scala statefuljobwbroadcaststatemigrationitcase.scala c768117 fixes for cepmigrationtest aaf5040 fixes for bucketingsinkmigrationtest 7d2b7cf fixes for flinkkafkaconsumerbasemigrationtest a1f07bd fixes for continuousfileprocessingmigrationtest 2be0da4 fixes for windowoperatormigrationtest 96e67ee fixes for statefuljobsavepointmigrationitcase f945735 fixes for statefuljobwbroadcaststatemigrationitcase for each test, we creates the corresponding savepoint/checkpoint files by running the corresponding write*snapshots() methods with the corresponding branch. adds 1.10 and 1.11 versions to the migration test version list. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? not applicable </desc> <cmt> [flink-18552][tests] update migration tests of cepmigrationtest to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of bucketingsinkmigrationtest to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of flinkkafkaconsumerbasemigrationtest to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of continuousfileprocessingmigrationtest to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of windowoperatormigrationtest to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of statefuljobsavepointmigrationitcase to cover migration till release-1.11 </cmt> <cmt> [flink-18552][tests] update migration tests of statefuljobwbroadcaststatemigrationitcase to cover migration till release-1.11 </cmt>",update migration tests in master to cover migration till release-1.11
2075,"<desc> this pull request adds a missing closing parenthesis in the insert statement generated for postgresql in upsert mode. added missing parenthesis in generated sql statement the effect of this change was verified against a local postgresql database where the sink was erroring out without the fix. dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (no) the serializers: (no) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (no) </desc> <cmt> added missing closing paren to postgresql on conflict clause </cmt> <cmt> typo </cmt>","correct syntax for postgresql dialect ""upsert"" statement"
2076,<desc> i double checked my bidirectional rnn code and looked closely to the theano scan implementation and i found an error where the return sequences flag is active. (it actually return the reversed sequences that may cause failure in particular where stacking bidirectional layers. here is the fix. </desc> <cmt> up do date 2 </cmt> <cmt> fixed an error in backward computation of recurrent layers on return sequences. </cmt>,fixed error go_backward and return sequences.
2077,"<desc> what kind of change does this pr introduce? (bug fix, feature, docs update, ...) chore. this pr contains changes to the build already on master, and includes fixes and fixes to fixes directly instead of sequentially the commit message follows our guidelines:  tests for the changes have been added (for bug fixes / features) docs have been added / updated (for bug fixes / features) other information: </desc> <cmt> chore(docs-app): load example files based on active deployment </cmt> <cmt> chore(docs-app): only copy relevant assets </cmt> <cmt> this keeps the size of the docs-app build down. </cmt> <cmt> especially needed to keep the size of the generated build .zip </cmt> <cmt> under 10mb, which is the limit for firebase / gcs https function transfers </cmt> <cmt> chore(travis): skip build on deployment job when from pull request </cmt> <cmt> chore(code.angularjs): enable directory listings </cmt> <cmt> chore(code.angularjs): delete old zip files on snapshot </cmt>","update 1.6 with recent travis, fb, docs app changes"
2078,<desc> changes to abi generation to auto populate abi from contract and clause files. please look at issue #2389 comments for more information. </desc> <cmt> starting to add integration to abigen </cmt> <cmt> added clauses generation in abi_generator </cmt> <cmt> finished abi_generator </cmt> <cmt> changed clause decl </cmt> <cmt> removed whitespace changes </cmt>,ricardian misc pr for eos #2389
2079,"<desc> this pulls in #3790, which provides retries in more of the posix emulation functions to be more resilient in the face of files locked by the aggressive locking semantics in win32, and #4073, which allows consumers to configure their own locking strategies so that consumers can ""get out of the way"" of their users a bit more instead of locking files unnecessarily. i refactored these a bit:  this now introduces a do_with_retries macro that will execute the given function up to 10 times, retrying if the error appears to be something like a locked file.  callers can provide a ""cleanup"" function - perhaps to set the file writable - that will be called between invocations of the main function.  this allowed us to clean up some patterns of try / set writable / try again. i introduced the git_retry constant here.  this is internal only and should never be returned to callers. these new retryable functions call the win32 functions directly instead of calling windows' posix emulation functions, which allows us to use the win32 error codes which are more fine-grained.  this allows us to retry only particular failures (ie, error_sharing_violation ) instead of a sharing violation and all the other failures that get mapped to a particular posix errno. this also allows us to bring in the configurable share mode for createfile, in #4073. once p_utimes called a retryable version of p_open, i noticed quickly that it was retrying all the time.  our odb freshening test was freshening an object in a repository that had been copied over from a test harness and - as a result - the objects were all writable.  thus p_utimes would succeed on windows.  but freshening a file that we wrote - and thus marked as read-only - would fail.  oops.  so i made p_utimes deal with read-only files by setting them writable temporarily to update the time. </desc> <cmt> add retries to win32 p_unlink and p_open. </cmt> <cmt> win32: map windows error codes to errno </cmt> <cmt> introduce mapping from windows error codes to errno values.  this </cmt> <cmt> allows us to replace our calls to the windows posix emulation functions </cmt> <cmt> with calls to the win32 apis for more fine-grained control over the </cmt> <cmt> emulation. </cmt> <cmt> these mappings match the windows crt's mappings for its posix emulation </cmt> <cmt> as they were described to me. </cmt> <cmt> win32: introduce do_with_retries macro </cmt> <cmt> provide a macro that will allow us to run a function with posix-like </cmt> <cmt> return values multiple times in a retry loop, with an optional cleanup </cmt> <cmt> function called between invocations. </cmt> <cmt> win32: make p_rename use do_with_retries </cmt> <cmt> win32: teach p_unlink about do_with_retries </cmt> <cmt> win32: teach p_open about do_with_retries </cmt> <cmt> win32: use createfile in p_open </cmt> <cmt> win32: deduplicate code: use p_open in p_creat </cmt> <cmt> allow to configure default file share mode for opening files </cmt> <cmt> this can prevent file_shared_violations when used in tools such as tortoisegit tgitcache and file_share_delete, because files can be opened w/o being locked any more. </cmt> <cmt> win32: do not inherit file descriptors </cmt> <cmt> win32: make posix emulation retries configurable </cmt> <cmt> posix emulation retries should be configurable so that tests can disable </cmt> <cmt> them.  in particular, maniacally threading tests may end up trying to </cmt> <cmt> open locked files and need retries, which will slow continuous </cmt> <cmt> integration tests significantly. </cmt> <cmt> win32: enable p_utimes for readonly files </cmt> <cmt> instead of failing to set the timestamp of a read-only file (like any </cmt> <cmt> object file), set it writable temporarily to update the timestamp. </cmt>",refactor some of the win32 posix emulation
2080,"<desc> xref #24499 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this is part of #24499, will be moving the pages in different prs, so it's easier to discuss. </desc> <cmt> doc: moving user guide to its own directory to help navigation </cmt> <cmt> fixing typo in toctree formatting </cmt> <cmt> merging from master </cmt> <cmt> fixing path to static files </cmt>","creating top-level user guide section, and moving pages inside"
2081,"<desc> backports #18923, #18956, #18971 once we do the split for pr jobs, this will be needed for pr jobs to continue running against v1.20.x </desc> <cmt> split multilang jobs by language </cmt> <cmt> job split followup: increase timeout for macos and windows c/c++ jobs </cmt> <cmt> create build.cfg for split-up pr jobs </cmt> <cmt> remove no-longer-used pr jobs </cmt>",backport kokoro job split to v1.20.x
2082,"<desc> as code.google.com is apparently closing (eventually). gcfg does not yet have a new home, so that godep still exists. </desc> <cmt> move from code.google.com to google.golang.org for google-api-go-client </cmt> <cmt> update mesos-go godep (to eliminate its use of code.google.com) </cmt> <cmt> this helps us remove one more (dying) godep import. </cmt> <cmt> switch from to code.google.com/p/go-uuid/uuid to github.com/pborman/uuid </cmt>",switch godeps away from code.google.com
2083,"<desc> we have a number of tasks that either omit, or incorrectly apply gradle input/output annotations on task properties. in addition to some of these instances resulting in potentially incorrect incremental build behavior, this causes a bunch of noise whenever we build :buildsrc. this pr addresses these reported warnings. </desc> <cmt> fix gradle task validation warnings for test clusters inputs </cmt> <cmt> fix gradle task validation warnings </cmt>",eliminate gradle task input warnings
2084,<desc> ticks off three checkboxes in #8982. the main thing i'm concerned about is the struct returned by parse_temporal_zoned_date_time_string and how it interacts with to_temporal_zoned_date_time (e.g. moving into result and such) as it's currently untested as parse_iso_date_time is not currently implemented. </desc> <cmt> libjs: implement totemporalzoneddatetime and the required aos </cmt> <cmt> libjs: implement temporal.zoneddatetime.from </cmt> <cmt> libjs: implement temporal.zoneddatetime.compare </cmt> <cmt> libjs: implement temporal.zoneddatetime.prototype.equals </cmt>,implement totemporalzoneddatetime and three functions that use it
2085,"<desc> the boost minimum version was bumped from 1.67 to 1.70 solely for rodeos. with rodeos now disabled we can set the minimum back to 1.67. this is somewhat useful for distros like debian 10 which still uses 1.67 out of the box. or, centos 7 & 8 which have 1.69 available via epel (our build scripts still build from scratch though). i completed a build and a ctest -le _tests ctest -l nonparallelizable_tests with 1.67 on this branch. okay okay, this doesn't technically build with 1.67 due to a defect in 1.67 where spsc_queue is missing an include file. however, just about any packager picked up that patch, including debian 10. debian 10:  arch:  homebrew:  as such, i've elected not to introduce a fix for this bug strictly in 1.67 in eosio code since the only likely user (debian 10) already has the fix integrated. needs eosio/fc#175 select one </desc> <cmt> sync fc to get make_strand() replacement </cmt> <cmt> set minimum boost version back to 1.67 </cmt>",restore boost 1.67 as the minimum boost version required
2086,<desc> this is a part of nnie plugin for ncnn. npn will a wip. </desc> <cmt> rename ncnn snapshot png file </cmt> <cmt> add nnie imagewatch plugin and working snapshot </cmt> <cmt> add nnie support to readme.md </cmt> <cmt> fix image path </cmt>,add nnie imagewatch plugin natvis
2087,"<desc> only prepend the language code if it's not there already - otherwise calling package with for instance name=""nl_core_my_pipeline"" would result in an ""nl_nl_core_my_pipeline"" package. nitpicking: add empty newline at the end of the python files that are written. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> add empty lines at the end of python files </cmt> <cmt> only prepend the lang code if it's not there already </cmt>",optionally append lang for packaged model name
2088,<desc> description: this pr implement alexa smart home api native into home-assistant for our cloud support. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> init commit for alexa component </cmt> <cmt> more struct component </cmt> <cmt> add mapping for device/component to alexa action </cmt> <cmt> finish discovery </cmt> <cmt> first version with support on/off/percent </cmt> <cmt> fix spell </cmt> <cmt> first init tests </cmt> <cmt> fix tests & lint </cmt> <cmt> add tests & fix bugs </cmt> <cmt> optimaze tests </cmt> <cmt> more tests </cmt> <cmt> finish tests </cmt>,alexa smart home native support
2089,"<desc> #10861 , #10724 , and #11142 . explanation: tbdgen now includes all the exported symbols encountered while building the standard library and test suite. scope: future users of tbd files, as there's no functionality change outside of it. radar: rdar://problem/32252869 and its subtasks. risk: low: the only changes outside of tbdgen are tightening the linkage of some symbols, which people shouldn't be relying on. testing: ci and local testing with tbd validation turned on by default (which this pr doesn't include, as that could break user's build). </desc> <cmt> [tbdgen] static variables in the main file have accessors. </cmt> <cmt> it is only top-level globals in the main file that do not have </cmt> <cmt> accessors, something like class foo { static var x = 0 } has them no </cmt> <cmt> matter where it is. </cmt> <cmt> fixes rdar://problem/32391290 . </cmt> <cmt> [test] stop a test dumping multiple klocs of sil/ir when it fails. </cmt> <cmt> [tbdgen] include all transparent symbols. </cmt> <cmt> this is a vast overestimate, but is better than missing some. </cmt> <cmt> rdar://problem/32254773 </cmt>",tbd including all files from a full build.
2090,<desc> added persistent metadata to the agent so that on restart a full set of metadata is kept about the charts and dimensions stored in the dbengine. implemented collector metadata logging added persistent guids for charts and dimensions added metadata log replay and automatic compaction added detection of charts with no active collector (archived) added new endpoint to report archived charts via /api/v1/archivedcharts added support for collector metadata update component name database </desc> <cmt> add metadata log files (#9078) </cmt> <cmt> * metadata log initial commit </cmt> <cmt> * add metadata log file write support </cmt> <cmt> * add proof of concept plugins d entrypoints for populating the metadata log files. </cmt> <cmt> global guid lookup (#9092) </cmt> <cmt> implement functions to support a global guid map </cmt> <cmt> generate global random guids (#9120) </cmt> <cmt> generate guids for charts and dimensions for the metadata log and maintain in the global lookup table </cmt> <cmt> initial version of metadata log parsing and replay. (#9195) </cmt> <cmt> * initial version of metadata log parsing and replay. </cmt> <cmt> metadata log compaction (#9252) </cmt> <cmt> * implement metadata log compaction. </cmt> <cmt> * implement metadata log compaction failure recovery logic. </cmt> <cmt> * fix very old bug causing crashes during host shutdown with dbengine memory mode </cmt> <cmt> add support for collectors updating their metadata (#9192) </cmt> <cmt> implemented collector metadata update </cmt>,add support for persistent metadata
2091,"<desc> @mjbvz this pr replaces pr #22918 to address issue #2187. i noticed that @tyriar had essentially created a ""simple find widget"" to use in the terminal which was much simpler to reuse than trying to refactor the full ""find widget"". i refactored that out into a reusable widget (simplefindwidget) and updated the terminal to use it (terminalfindwidget). i then created a webviewfindwidget to be used by the webview to interact with the native webview find api. to respect the layering contract, i had to make the existing webvieweditor into an abstract class and extend it in the correct layer so it could have access to the webview. htmlpreviewpart and releasenoteseditor now extend from that new webvieweditor implementation and therefore both have access to the new find widget. extensioneditor also now leverages the simple find widget to enable searching through readmes and release notes within the extension editor view. finally, i improved the styling of the simple find widget by adding ""overflow: hidden"" to the containers that use it so that it can properly be animated in. caveat: i don't know what htmleditorzone is so i didn't test that. here are gifs of it in action: this is the find working in a markdown preview: this is the find working in release notes this is the find working the same as before in the terminal, but now with animation: this is the find working in the webview sections of the extensioneditor </desc> <cmt> refactored terminalfindwidget into a simplefindwidget and used that to provide find for webviews </cmt> <cmt> refactored webvieweditor into an abstract base and a concrete class to respect 'part' separation </cmt> <cmt> cleaned up css and images that i forgot to delete </cmt> <cmt> reset i18n.js file </cmt>","find in webview based views (html preview, release notes, extension editor)"
2092,"<desc> for gatsby admin, the design calls for us to render a description for each plugin/theme in the ui. this adds a gatsbyplugin.description field, which returns the ""description"" field from the plugin's package.json (using the package.json resource read function!). while i was at it, i also cleaned up the code a bit: instead of manually resolving the node_modules locations of packages, i tried to use require.resolve to fix the tests within the monorepo (they weren't finding the themes in the node_modules, as they aren't there, so no shadowed/able files were returned!). however, require.resolve also doesn't work as it resolves from the __dirname, which is not what we want (particularly in our monorepo). thankfully, the resolve-cwd module by sindre does the exact some thing require.resolve does but from the current working directory instead! instead of duplicating the ""read plugin""-logic in the ""all plugins"" and the ""single plugin"" function (which already lead to mismatches where shadowable/ed files weren't defined when fetching a single plugin), i now use the common read function in the all method. more consistent results and no duplicate code, yay! </desc> <cmt> add description to npm package resource </cmt> <cmt> use require.resolve instead of manually joining node_modules path </cmt> <cmt> use resolve-pkg to safely resolve packages just like require() would do instead of manually joining paths with node_modules </cmt> <cmt> add gatsbyplugin.description to provider </cmt>",add description to gatsby plugin resource
2093,"<desc> currently, commandpalette creates and maintains the switchtotab commands used for the ats. when command goes into the terminalsettingsmodel, the palette won't be able to access command's implementation type, making it difficult for commandpalette to tell command to listen to tab for changes. this pr changes the relationship up so tab now manages its switchtotab command, and commandpalette just plops the command from tab into its list. </desc> <cmt> added command object to tab </cmt> <cmt> working state </cmt> <cmt> more comments </cmt>",give tab ownership of its switchtotab command
2094,"<desc> this allows stuff like: int mycompare(int i, int j) { j - i } ... list.sort(this::mycompare) it is like a manual transmission lambda. the main idea here is allowing pointers to functions in our own class (whether user explicitly wrote them or we wrote them on their behalf). so a few cleanups were needed: allow creating functionref to these (lots of refactoring here) allow dynamic code (def) to access these. we need a runtime whitelist, and we'd like to keep all methods private, avoid reflection/security issues/etc. we add a whitelist to the class itself, a pointer to each function like this: private static final methodhandle handle$mycompare$2; these are initialized in <clinit> with ldc (they are simply constants). we can lookup from this by name and arity exactly, and we have what we need. 3. general cleanup of functions in our asm code (thanks @uschindler). </desc> <cmt> merge master </cmt> <cmt> remove unnecessary semicolon and return </cmt> <cmt> write refs for functions </cmt> <cmt> make this static final </cmt> <cmt> unfuck the methodwriter nesting. all methodwriters should only live separately from each other, no nesting </cmt> <cmt> def case working </cmt> <cmt> fix too long line </cmt> <cmt> more cleanup </cmt> <cmt> test interface default methods </cmt> <cmt> remove some hardcoded strings, fix exception handling (remove rethrow), add some utility methods around the ""handle$"" fields </cmt> <cmt> add comments </cmt> <cmt> need not be public, should not be public </cmt>",method references to user functions
2095,"<desc> fix the remaining /status subresources that return 405 on get and patch which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): ref #63619 release note: apiservices/status and certificatesigningrequests/status now support get and patch </desc> <cmt> add get patch support for two /status: </cmt> <cmt> apiservices/status under apiregistration.k8s.io </cmt> <cmt> certificatesigningrequests/status under certificates.k8s.io </cmt> <cmt> generated </cmt>",apiservices/status and certificatesigningrequests/status support get+update+patch
2096,<desc> since esp32 stage has no core_version.h file we have to disable the include. this is done with setting esp32_stage=true in platformio changed esp32 stage to latest commit f7fb00632e0.... the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.5 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> no core_version.h in esp32 stage </cmt> <cmt> build flag for esp32 stage </cmt>,make esp32 stage compile possible
2097,<desc> recent upgrade of rnw to mux2.6 caused a second shift in button styling. a couple of small tweaks were needed here to match the styling of the xaml button. added border color and width to button. removed workaround in place for winui2.5 buttonbackgroundpointerover brush. added button title color change with change in states. backport #8148 to 0.65. microsoft reviewers: open in codeflow </desc> <cmt> backport winui2.6 button changes </cmt> <cmt> change files </cmt> <cmt> revert comment formatting changes </cmt>,adjust button styling following upgrade to winui2.6
2098,<desc> alternative to #3897 </desc> <cmt> remove threadsafestate </cmt> <cmt> remove threadsafestate completely </cmt> <cmt> clippy </cmt> <cmt> remove loading workers table </cmt> <cmt> reset ci </cmt> <cmt> remove some mutexes from state </cmt> <cmt> remove more mutexes from state </cmt> <cmt> remove mutex from resource table </cmt> <cmt> wrap state in rc and refcell </cmt>,use refcell for mutable state
2099,"<desc> this pr extracts some changes from #23308. the following changes are being made: add classes prop to the sliderunstyled updated buildapi to reflect the definition in the classes for the css section in the api page adds helper tests for the unstyled package removed unnecessary component valuelabelstyled and moved the styles to the valuelabelstyled ""slot"" component. renamed valuelabelunstyled to slidervaluelabelunstyled and reverted back some changes from the original implementation </desc> <cmt> extracted changes </cmt> <cmt> fix </cmt>",general cleanup and add classes prop for unstyled
2100,"<desc> the kernel does the equivalent of the following check before proceeding: if (address + 0x8000000000 < 0x7fffe00000) { return err_invalid_memory_state; } which is essentially what our iskernelvirtualaddress() function does. so we should also be checking for this. the kernel also checks if the given input addresses are 4-byte aligned after the above check, however our mutex::tryacquire() and mutex::release() functions already handle this, so we don't need to add code for this case. </desc> <cmt> kernel/svc: handle error cases for svcarbitratelock() and svcarbitrateunlock() </cmt> <cmt> the kernel does the equivalent of the following check before proceeding: </cmt> <cmt> if (address + 0x8000000000 < 0x7fffe00000) { </cmt> <cmt> return err_invalid_memory_state; </cmt> <cmt> } </cmt> <cmt> which is essentially what our iskernelvirtualaddress() function does. so </cmt> <cmt> we should also be checking for this. </cmt> <cmt> the kernel also checks if the given input addresses are 4-byte aligned, </cmt> <cmt> however our mutex::tryacquire() and mutex::release() functions already </cmt> <cmt> handle this, so we don't need to add code for this case. </cmt> <cmt> kernel/mutex: replace resultcode construction for invalid addresses with the named variant </cmt> <cmt> we already have a resultcode constant for the case of an invalid </cmt> <cmt> address, so we can just use it instead of re-rolling that resultcode </cmt> <cmt> type. </cmt>",handle invalid address cases within svcarbitratelock() and svcarbitrateunlock()
2101,"<desc> currently, asynccheckpointrunnable throws an exception if subtaskcheckpointcoordinatorimpl is closed. however, it should also check its own status as it might be a normal case. the change is covered by existing end-to-end tests which are currently failing. unit testing would involve concurrency which i think would be overkill for essentially a logging problem. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? no </desc> <cmt> [hotfix] refactor subtaskcheckpointcoordinatorimpl.registerasynccheckpointrunnable </cmt> <cmt> [flink-19012][task] check state of asynccheckpointrunnable before throwing an exception </cmt> <cmt> currently, subtaskcheckpointcoordinatorimpl closes all runnables on close. </cmt> <cmt> it doesn't stop the actual threads, however. when closed runnable starts, </cmt> <cmt> it sees its parent is closed and throws an exception. </cmt> <cmt> this causes end-to-end tests failures. </cmt> <cmt> this change adds a check of runnable state. </cmt>",check asynccheckpointrunnable status before throwing an exception
2102,"<desc> added a new define in user config to set the vloume on a secific value 0..30(max). -- very little speakers in a housing (e.g. sonoff sc) can explode by full volume. -- happens to me now two times with white smoke. added version information to the driver file to have some hints what's done. changed two commands -- mp3play 001 to mp3track 001 -- mp3stop is now a real stop and not the pause command as in the original version added some new commands -- mp3play, a real play command. starts at 001.mp3 file on the selected device -- mp3eq, an eq(0/1/2/3/4/5), 0:normal, 1:pop, 2:rock, 3:jazz, 4:classic, 5:bass -- mp3device, specify playback device, usb=1, sd-card=2, default = 2 also after reset or power down/up all is tested parallel (8 h) and works on a sonoff-sv and a wemos d1 (not the mini) as generic device </desc> <cmt> update from original </cmt> <cmt> added mp3_volume to init the mp3 player </cmt> <cmt> added version info and new mp3 player commands </cmt> <cmt> - added the version information to have some little hints what is done. </cmt> <cmt> - added new commands and changed two commands from the first version. </cmt> <cmt> -- intention was to get as less of commands as needed. </cmt> <cmt> -- there will be possible a version with much more function and serial->read. </cmt> <cmt> command list: </cmt> <cmt> - mp3track </cmt> <cmt> -- specify playback of a track, e.g. mp3track 003. </cmt> <cmt> - mp3play </cmt> <cmt> -- play, works as a normal play on a real mp3 player, starts at 001.mp3 file on the selected device. </cmt> <cmt> - mp3pause </cmt> <cmt> -- pause, was original designed as stop, see data sheet. </cmt> <cmt> - mp3stop </cmt> <cmt> -- stop, it's a real stop now, in the original version it was a pause command. </cmt> <cmt> - mp3volume </cmt> <cmt> -- specifies the volume and means a console input as 0..100. </cmt> <cmt> - mp3eq </cmt> <cmt> -- specify the eq(0/1/2/3/4/5), 0:normal, 1:pop, 2:rock, 3:jazz, 4:classic, 5:bass. </cmt> <cmt> - mp3device </cmt> <cmt> -- specify playback device, usb=1, sd-card=2, default is 2 also after reset or power down/up. </cmt>",changed/added mp3 player commands and version information
2103,"<desc> summary created additional documentation for the ""switching from one backend to another"" section of the documentation, including an example of an edited keras.json configuration file. related issues solves issue #11384 pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> update backend.md </cmt> <cmt> added documentation for loading an external backend </cmt> <cmt> added documentation for using an external backend </cmt> <cmt> added documentation for loading external backends </cmt>",fix issue #11384 - explaining how to load external backends in the documentation
2104,"<desc> fixes #17324. @sandy081, you've worked in this area, let me know if this is the right approach. </desc> <cmt> microsoft/vscode#17324 - implement f4 to navigate results </cmt> <cmt> move id/label </cmt> <cmt> expose navigator methods so i can avoid calling selectnext multiple times per action- it has side effects </cmt> <iss> suboptimal hotkey workflow for ""find in files"" </iss>",add f4 shortcut for navigating search results
2105,"<desc> this makes sure we have a valid view staying in the window, so opening devtools won't trigger crashes, and the keyboard events can correctly pass in the window. refs #6704. </desc> <cmt> pass onpaint callback in constructor </cmt> <cmt> this can catch the paint events happened before onload event. </cmt> <cmt> pass skbitmap directly </cmt> <cmt> show dummy view under offscreen mode </cmt> <cmt> also show the text on windows and linux </cmt> <cmt> fix building on linux </cmt>",show a dummy view in the offscreen window
2106,<desc> kip-680: topologytestdriver should not require a properties argument.  jira for the kip: </desc> <cmt> added default constructor without properties in topologytestdriver </cmt> <cmt> using constructor of topologytestdriver without properties parameter </cmt> <cmt> using constructor of topologytestdriver without properties parameter </cmt> <cmt> changed constructor reference to the one without properties </cmt> <cmt> keeping default test props final </cmt> <cmt> fixed merge conflicts </cmt> <cmt> made changes as per style guilde </cmt> <cmt> no need of static default properties </cmt> <cmt> provide randomized dummy app-id if it's not provided </cmt> <cmt> added another constructor with initial clock time parameter </cmt> <cmt> fixed merge conflicts </cmt>,kafka 10629 - topologytestdriver should not require a properties argument
2107,"<desc> what do these changes do? update arrow to apache/arrow#2522 which has glog in plasma. according to arrow's recent change,  n/a </desc> <cmt> update arrow to plasma with glog and update the building process </cmt> <cmt> remove parquetexternalproject.cmake </cmt>",update arrow using plasma with glog
2108,<desc> hold space to mirror handedness of the ergodox.  tap to space.   same works for enter key on right hand. i also moved the modifier keys from default to a layout that is closer to a 108-key board. i use one of that shape at work and want the switch to be as painless as possible. tested this layout and the layer shifting works correctly. no need to spend $600 to get one from matias. </desc> <cmt> started work on halfkeyboard </cmt> <cmt> update to keymap </cmt> <cmt> halfkey layouts complete for dvorak and qwerty </cmt>,halfkeyboard functionality for dvorak and qwerty
2109,"<desc> closes #19643 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fix cdivision error, migrate period_asfreq tests </cmt> <cmt> docstrings, parametrize test </cmt> <cmt> fixup typo </cmt> <iss> period.asfreq issue caused(?) by c division rules </iss>","fix period.asfreq conversion near datetime(1, 1, 1)"
2110,<desc> this pr also adds parallel to elasticnetcv </desc> <cmt> enh: add the ability to set rho by cross-val </cmt> <cmt> enh: store the path for rho in enet </cmt> <cmt> bug: fix tests and reorganize code </cmt> <cmt> enh: draft of parallel cv in elastic net </cmt> <cmt> test: setting rho with elasticnetcv </cmt> <cmt> doc: document elasticnetcv </cmt>,add the option to set rho by cv in elasticnetcv
2111,<desc> this change cuts over from translog to lucene changes history in ccr component. the autogeneratedidtimestamp will be handled in a follow-up. </desc> <cmt> [ccr] use indexsearcher to read operations from lucene index instead </cmt> <cmt> of using the translog </cmt> <cmt> moved ccrindexreader to lucene.java and added a simple test </cmt>,read changes from lucene instead of translog
2112,"<cmt> opencl: fix wrong implementation of function getnumdevicewithemptyscore </cmt> <cmt> gcc report: </cmt> <cmt> opencl_device_selection.h: in function 'ds_status getnumdevicewithemptyscore(ds_profile*, unsigned int*)': </cmt> <cmt> opencl_device_selection.h:589:13: warning: value computed is not used [-wunused-value] </cmt> <cmt> *num++; </cmt> <cmt> ^ </cmt> <cmt> this is caused by a buggy implementation which increases the value of num </cmt> <cmt> instead of *num. </cmt> <cmt> opencl: add missing argument for l_warning </cmt> <cmt> gcc report: </cmt> <cmt> in file included from /usr/include/leptonica/alltypes.h:36:0, </cmt> <cmt> from /usr/include/leptonica/allheaders.h:34, </cmt> <cmt> from openclwrapper.h:2, </cmt> <cmt> from openclwrapper.cpp:11: </cmt> <cmt> openclwrapper.cpp: in static member function 'static pix* opencldevice::pixreadmemtiffcl(const l_uint8*, size_t, l_int32)': </cmt> <cmt> /usr/include/leptonica/environ.h:442:68: warning: format '%d' expects a matching 'int' argument [-wformat=] </cmt> <cmt> (void)fprintf(stderr, ""warning in %s: "" a, __va_args__), \ </cmt> <cmt> ^ </cmt> <cmt> /usr/include/leptonica/environ.h:427:61: note: in definition of macro 'if_sev' </cmt> <cmt> ((l) >= minimum_severity && (l) >= leptmsgseverity ? (t) : (f)) </cmt> <cmt> ^ </cmt> <cmt> opencl/openclwrapper.cpp:1162:3: note: in expansion of macro 'l_warning' </cmt> <cmt> l_warning(""tiff page %d not found"", procname); </cmt> <cmt> ^ </cmt>",fix two small bugs (both found by gcc)
2113,<desc> this does not do it in the spec like way for bytecode but i'm not sure how things like that are supposed to be done in bytecode. </desc> <cmt> spreadsheet: fix that non first sheets could not access global functions </cmt> <cmt> because we declare the functions in runtime.js we need the correct </cmt> <cmt> global object to be setup otherwise they cannot be accessed when </cmt> <cmt> switching to the sheetglobalobject. </cmt> <cmt> libjs: fix that in bytecode mode functions where not created anymore </cmt> <cmt> this is not a proper fix as we should follow the spec here but it gets </cmt> <cmt> us back to a slightly more working state. </cmt>,fix some issues caused by the variable refactor
2114,"<desc> the current codecov only reports the coverage of cpp code. to better integrate with codecov plugin, we should enable coverage report for java and python as well. </desc> <cmt> add coverage report for java </cmt> <cmt> add coverage report for python </cmt>",add coverage report for java and python
2115,"<desc> migrated and fixed the smoke tests over to playwright and execute them on webkit/firefox/chromium as discussed with @rebornix adjusted the github actions, so they run also on a pull requests </desc> <cmt> feat: migrate e2e tests to playwright </cmt> <cmt> fix: os dependency </cmt> <cmt> fix: race condition </cmt>",fix and migrate smoke tests to playwright
2116,"<desc> this cleans up the behavior tests because they were hastily added for the v2 release. the tests themselves were revised for clarity. more work needs to be done documenting how to use and write them, but this is a start. example new test: test('builds in development', async () => { const { fulfilled } = await testsetup.scripts.start({ smoke: true }); expect(fulfilled).tobe(true); }); test('builds in production', async () => { const { fulfilled } = await testsetup.scripts.build(); expect(fulfilled).tobe(true); }); test('formats babel syntax error', async () => { fs.copysync( path.join(__dirname, 'src', 'appbabel.js'), path.join(testsetup.testdirectory, 'src', 'app.js') ); const { stdout, stderr } = await testsetup.scripts.build(); expect({ stdout, stderr }).tomatchsnapshot(); }); </desc> <cmt> speed up installs with pnp </cmt> <cmt> move to a better relative path test </cmt> <cmt> continue work on new test organization </cmt> <cmt> move mjs test to new enhanced tests </cmt> <cmt> move over last legacy test </cmt> <cmt> update behavior e2e script </cmt> <cmt> add first iteration of instructions to test readme </cmt> <cmt> add some more bad instructions </cmt> <cmt> split test command into multiple lines </cmt>",clean up the behavior tests
2117,<desc> #2110 and #2116 </desc> <cmt> english translation update. </cmt> <cmt> some typos are fixed. </cmt> <cmt> mysql.md is not translated yet </cmt> <cmt> some more typos are fixed. </cmt> <cmt> external editions are revised. english translation is actualised from 02.03.2018 version up to 26.03.2018. </cmt>,merged docs from #2110 and #2116
2118,<desc> part of #4401. complements #4431 for assignments instead of declarations. it's another example of a case where better error reporting in isimplicitlyconvertibleto might have been helpful (tracked in #4128). </desc> <cmt> check for matching number of components in tupletype::isimplicitlyconvertibleto instead of the typechecker. </cmt> <cmt> add changelog entry. </cmt> <cmt> update tests. </cmt>,disallow tuple assignment with mismatching number of components.
2119,"<desc> closes #34656 closes #34271 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry behavioural changes .apply() calls  to self._set_group_selection have been replaced with with _group_selection_context(self): for _agg_general, _make_wrapper, and nth. previously these calls to self._set_group_selection created a bug in groupby.apply where calling another method before .apply would change the output of .apply. this bug is now fixed. one new test is added to check that the output of .apply is constant whether another method is called on the same grouper first. two existing tests were actually dependent on the old buggy-behaviour (i.e. they called groupby.sum first and then expected that groupby.apply(sum) would exclude the index columns from the results). all of these tests have been amended in a manner that enforces the new consistent output format while preserving the existing test. both of the copy-pastable examples in the linked bug-reports are fixed. </desc> <cmt> groupby.apply() calls self._reset_group_selection at the start. errant tests updated </cmt> <cmt> gb.apply() now resets group selection so it always returns grouping columns as columns. updated tests that relied on previous behaviour </cmt> <cmt> test uses .drop() instead of selection </cmt> <cmt> wrote new tests </cmt> <cmt> rewrote test </cmt> <cmt> whatsnew </cmt> <cmt> restore if-stat in test_transform </cmt> <cmt> amended test </cmt> <cmt> restored test </cmt> <cmt> restored test </cmt> <cmt> amended test </cmt> <cmt> cleanup </cmt> <iss> bug: same function calls on the same dataframegroupby object give different results </iss> <iss> bug: groupby.min has a side effect on groupby.apply </iss>",groupby.apply() returns different results if a different groupby method is called first
2120,"<desc> i fixed several errors in the manual: bd67bb8 the output of unique_by(length) example was not sorted by length. fix typo: trailing ']'. the output of recurse example were missing . object itself. fdbc91e programs, inputs and outputs were not html-escaped, causing named-capture in regexes to disappear in html. (this also fixes #589) b4a9ea5 fix yaml indentation around the regex section because the generated html were corrupted. a6656ed fix markup, unmatched backquotes. jq output not being represented as a list in yaml were causing ""none""s in generated html. they were commited separately because the indentation fix would have obscured other changes. please squash them if it is more convenient to merge. </desc> <cmt> fix examples in manual </cmt> <cmt> html-escape jq programs in manual </cmt> <cmt> fix indents in manual.yml </cmt> <cmt> fix examples in manual </cmt> <iss> documentation inaccuracy for format strings </iss>",fix several errors in the manual
2121,<desc> updated definition-tester default to tsc v1.1.0-1 some fixes (also by @vvakame) added a version check to runner.js very simple local definition-tester semver check/prompt catches outdated dependency (using npm test or npm run <...>) for #2932 </desc> <cmt> enabled tsc 1.1.0-1 </cmt> <cmt> updated definition-tester to 0.1.x </cmt> <cmt> updated npm run scripts </cmt> <cmt> added basic definition-tester semver check to runner.js </cmt> <cmt> hardened runner.js </cmt> <cmt> first check if definition tester module exists at all </cmt>,switched tester to tsc 1.1.0-1
2122,"<desc> the assertitem failure message pattern in testsubscriber does not match any of the regex patterns defined by intellij to show <click to see difference> link. by changing the ""expected to be"" to ""expected:"", the pattern is recognised by intellij and the helpful link is presented. the original idea from #5249 was to use the ""expected:<> but was:<>"" pattern used in junit, but it is not picked up on its own by intellij. the assertionerror must extend from junit's comparisonfailure, to get it recognised. this however requires dependency on junit. so in the end, the fix is just a very simple change in the message. </desc> <cmt> test intellij formatting fix </cmt> <cmt> fix test subscriber test case </cmt>",1.x use intellij ide friendly assertion failure message
2123,"<desc> a quick solution for allowing those using the master branch to use iob or iob2 formats, and to accept whitespace delimitation on a line other than a pipe. fixes the master branch for #2504 and #2970. fixes for the develop branch are not yet done. i have submitted the spacy contributor agreement. </desc> <cmt> accept non-pipe whitespace as delimiter; allow iob2 filename </cmt> <cmt> added small documentation note for iob2 allowance </cmt>",accept iob2 and allow generic whitespace
2124,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> remove cast as typing stub should now work </cmt> <cmt> fix typing of datejs </cmt>,fix typing for set() and add()
2125,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add via support for bt66tech60 </cmt> <cmt> delete bt66tech60 </cmt> <cmt> add via support bt66tech60 </cmt>",add via keymap support for bt66tech/bt66tech60
2126,"<desc> the following functions/criterions now support double backwards: rrelu, hardshrink, softplus, softshrink, logsigmoid, softmin, glu, mseloss, smoothl1loss, kldivloss, hingeembeddingloss. the following functions are now new-style (once-differentiable): marginrankingloss, cosineembeddingloss also updated the softmin documentation to list the simple formula rather than the stable formula; we did the same for softmax. </desc> <cmt> implement rrelu double backwards. </cmt> <cmt> implement hardshrink double backwards. </cmt> <cmt> implement softplus double backwards. </cmt> <cmt> implement softshrink double backwards. </cmt> <cmt> implement logsigmoid double backwards. </cmt> <cmt> implement softmin double backwards. </cmt> <cmt> implement glu double backwards. </cmt> <cmt> implement mseloss double backward. </cmt> <cmt> implment smoothl1loss double backwards. </cmt> <cmt> implement kldivloss double backwards. </cmt> <cmt> implement hingeembeddingloss double backwards. </cmt> <cmt> marginrankingloss as new style function. </cmt> <cmt> cosineembeddingloss as a new style function. </cmt>",more nn double backwards support
2127,"<desc> description: forks more of the implementations between counters and gauges. counters remain effectively as they were. for gauges, we get to drop the pending_increment_ field which was not used, but to resolve this bug we need to add a mutex, so this saves a little memory. the need for this is mentioned in #7109 but this does not fully resolve that bug. this is wip because i need to verify that it passes 'release' test now, having tweaked the expected memory value, but no way to check it on my system. risk level: medium testing: //test/common/stats/... docs changes: n/a release notes: n/a </desc> <cmt> add a mutex to gauges to avoid an import-mode race. </cmt> <cmt> use absl::mutex directly as it saves 8 bytes per stat relative to thread::mutexbasiclockable and its vptr. </cmt>","remove field from gaugeimpl that was not used, by moving it to the counter-specific section."
2128,"<desc> this removes a dependency on dashboard bootstrap data from the e2e test suite, so that we can change the implementation without breaking tests. this is blocking #13306. decided to open up a separate pr instead of addressing the issue there, for easier review. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> chore(cypress): make the load dashboard test behavior driven </cmt> <cmt> remove bootstrap usage from controls test, + new utils </cmt> <cmt> fix save test to not use bootstrap dat </cmt> <cmt> remove bootstrap usage from the filter test </cmt> <cmt> fix race condition </cmt> <cmt> remove bootstrap from url params test </cmt> <cmt> fix lint </cmt>",make the e2e tests more behavior-driven
2129,"<desc> fixes #9078 currently fixed for archs : x86 arm 64/32 mips gb (it was already fully implemented) todo add support for more archs include this for more op type if needed add test for different arch currently the r_anal_op_mask_all used in many place , have to clean that and change to appropriate mask $ git grep ""r_anal_op_mask_all"" | wc -l 88 </desc> <cmt> intial work on supporting ranalop.dst/src in all archs </cmt> <cmt> fix struct offset for dst operand in ta command </cmt> <iss> struct offset for dst operand </iss>",support ranalop.dst/src in all archs
2130,<desc> i have followed (at least) the pr section of the contributing guide. fixed spelling mistake in the footer of premium themes examples' footer </desc> <cmt> override step props over internal state of stepper </cmt> <cmt> add a unit test </cmt> <cmt> merge upstream with 'master' </cmt> <cmt> fix spelling in premium themes footer </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>,fix spelling mistake in premium themes footer
2131,<desc> fix issues with gif frame disposal modes (fixes file download animation reported in #3291). add support for interlaced gifs (fixes google doodle in #3291). gifloader now uses a single frame buffer to cache the last decoded frame. this drastically reduces memory usage at the small expense of re-decoding frames on each loop. </desc> <cmt> libgfx: correctly handle gif frame disposal modes </cmt> <cmt> restorebackground disposal mode is now a transparent fill to allow </cmt> <cmt> background to show through. </cmt> <cmt> restoreprevious disposal mode now restores the previous frame. </cmt> <cmt> libgfx: add support for interlaced gifs </cmt> <cmt> libgfx: only cache last decoded gif frame </cmt> <cmt> gifloader now uses a single frame buffer to cache the last decoded </cmt> <cmt> frame. this drastically reduces memory usage at the small expense of </cmt> <cmt> re-decoding frames on each loop. </cmt>,gif decoding fixes and improvements
2132,"<desc> this is a major refactoring that moves the type checking code out of the ast classes into its own module (typechecker). furthermore, data added to the ast after the parsing stage (where the ast nodes are actually created) is not added to the ast nodes themselves, but to a class in the ""annotation hierarchy"". this fact will ease the later introduction of templates. to be merged together with ethereum/alethzero#70 and ethereum/mix#82 </desc> <cmt> refactoring: check types outside of ast and recover from some errors. </cmt> <cmt> refactored annotations. </cmt> <cmt> error formatting. </cmt>",support mulitple errors and warnings.
2133,"<desc> add api get method to list the available es versions to be installed. $ awslocal es list-elasticsearch-versions { ""elasticsearchversions"": [ ""7.7.0"", ""7.4.0"", ""7.1.0"", ""6.7.0"" ] } fixes #3439 </desc> <cmt> rebase from master (#1) </cmt> <cmt> rebase 2 (#2) </cmt> <cmt> rebase correctly </cmt> <cmt> fix: list elasticsearch versions </cmt> <iss> how to read data written in elastic search cluster ? </iss>",add list elasticsearch versions api method
2134,"<desc> this patch exposes some of the constants used by probe temperature calibration to the user and solves bugs described in #18227 . in the following code a bug was fixed where 2d point addition was performed to calculate probe_pos_xyz by casting measure_point to an xyz value first. the 0.5f constant is exposed to the user. in addition probe.offset_xy is projected to 2d so that ptc_probe_heating_offset is in reference to the z coordinate frame, not the probe trigger point. probe_pos_xyz = xyz_pos_t(temp_comp.measure_point) + xyz_pos_t({ 0.0f, 0.0f, ptc_probe_heating_offset }), noz_pos_xyz = probe_pos_xyz - xy_pos_t(probe.offset_xy); // nozzle position based on probe position the following fixes a bug where the probe wasn't stowed after each probe, stopping the printer from heating below the trigger point. const float measured_z = probe.probe_at_point(nozpos, probe_pt_stow, 0, false);  // verbose=0, probe_relative=false allows probing on non-genuine pinda v2 probes. #18227 </desc> <cmt> add changes to probe temperature calibration </cmt> <cmt> add values and comments to configuration file </cmt>",extend ptc options and fix probing bugs
2135,"<desc> adds e2e tests for various charsets with and without gzip iso-8859 (latin1) fixes #1543 euc-kr (korean) fixes #3479 shift-jis (japanese) gb2312 (chinese) also adds support for windows-1252 and all other charsets supported by iconv-lite:  auto-detects charset from headers or meta tags ensures that content is injected and sent using the detected content type prevents express from always sending content-type: text/html;charset=utf-8 fixes #3650  if you write a string, it will send it as utf-8 always, had to monkey-patch it out </desc> <cmt> add e2e test that demonstrates encoding issue </cmt> <cmt> fix all sorts of content-type wackiness, infer content-type from html </cmt> <iss> character problems with character encoding of iso-8859-1 sites </iss> <iss> non english characters (korean) encoding is broken </iss> <iss> chrome cypress browser adds ""charset=utf-8"" to the content-type in the response header </iss>",fix a variety of character encoding issues
2136,"<desc> per #2109 , it appears that we were a little deficient when checking out when core.autocrlf=input and the text=auto attribute is specified. this pr ensures that we handle core.autocrlf=input and text=auto when checking out.  this adds tests for the combinations of core.autocrlf of false, true and input along with the text=auto attribute being set and unset, both for writing to the working directory and into the repository. </desc> <cmt> close files on file diff failure </cmt> <cmt> not closing the files on a diff failure ensures that clar </cmt> <cmt> cleanup will fail on win32 because we still have the file open. </cmt> <cmt> tests for core.autocrlf and .gitattributes </cmt> <cmt> tests for crlf filtering into the repository </cmt> <cmt> core.autocrlf=input w/ text=auto attr to workdir </cmt>",handle core.autocrlf=input when checking out
2137,"<desc> description: upgrades existing python-hpilo library to v4.3. existing version does not allow connections to ilo v3 due outdated ssl, upgrade to v4.3 works. checklist: documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> update python-hpilo to 4.3 </cmt> <cmt> update of python-hpilo requirement to 4.3 to resolve outstanding ssl connections for older hp servers (ilo 3) </cmt> <cmt> update requirements_all.txt </cmt> <cmt> update hpilo to 4.3 </cmt>",upgrade hpilo requirement to v4.3
2138,"<desc> this pull requests changes and adds javadoc in some http-related classes it also does some minor internal refactoring to httpcodecutil to make it easier to get the gist of when looking through some methods for the first time sorry about all of these pull requests - i would do more in this package, but i've got enough of a headache to stop for the night and just mindlessly watch tv :) </desc> <cmt> made the documentation in httpmessage a bit easier to understand </cmt> <cmt> make httprequest's documentation easier to read </cmt> <cmt> make httpresponse's javadoc a bit easier to read </cmt> <cmt> documentation and slight internal refactoring of httpcodecutil </cmt> <cmt> documentation redone for cookie </cmt>",even more documentation changes (mainly) - http
2139,"<desc> tuned_examples/regression_tests removed; all tests will be run for both frameworks (use_pytorch will be removed from the yamls and replaced by command line overrides in bazel py_test). also, the regression tests will be run as single, independent py_tests for each algo+env+framework to better be able to catch run errors (hard to track right now). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> conflicts: </cmt> <cmt> rllib/build </cmt> <cmt> rllib/evaluation/worker_set.py </cmt> <cmt> rllib/examples/cartpole_lstm.py </cmt> <cmt> rllib/examples/custom_eval.py </cmt> <cmt> rllib/examples/env/correlated_actions_env.py </cmt> <cmt> rllib/examples/env/env_with_subprocess.py </cmt> <cmt> rllib/examples/env/random_env.py </cmt> <cmt> rllib/examples/env/repeat_initial_obs_env.py </cmt> <cmt> rllib/examples/env/windy_maze_env.py </cmt> <cmt> rllib/examples/nested_action_spaces.py </cmt> <cmt> rllib/examples/parametric_action_cartpole.py </cmt> <cmt> rllib/examples/parametric_actions_cartpole.py </cmt> <cmt> rllib/examples/tensorflow/parametric_actions.py </cmt> <cmt> rllib/tests/test_env_with_subprocess.py </cmt> <cmt> rllib/tests/test_supported_spaces.py </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a2c-microbatch.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a3c-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a3c.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-torch.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/pendulum-ppo-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/pendulum-ppo-torch.yaml </cmt> <cmt> rllib/tuned_examples/pendulum/pendulum-ppo.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/cartpole-a3c.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/cartpole-dqn-tf-param-noise.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ddpg-tf.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ddpg-torch.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ppo.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-td3.yaml </cmt> <cmt> conflicts: </cmt> <cmt> rllib/build </cmt> <cmt> rllib/evaluation/worker_set.py </cmt> <cmt> rllib/examples/cartpole_lstm.py </cmt> <cmt> rllib/examples/custom_eval.py </cmt> <cmt> rllib/examples/env/correlated_actions_env.py </cmt> <cmt> rllib/examples/env/env_with_subprocess.py </cmt> <cmt> rllib/examples/env/random_env.py </cmt> <cmt> rllib/examples/env/repeat_initial_obs_env.py </cmt> <cmt> rllib/examples/env/windy_maze_env.py </cmt> <cmt> rllib/examples/nested_action_spaces.py </cmt> <cmt> rllib/examples/parametric_action_cartpole.py </cmt> <cmt> rllib/examples/parametric_actions_cartpole.py </cmt> <cmt> rllib/examples/tensorflow/parametric_actions.py </cmt> <cmt> rllib/tests/test_env_with_subprocess.py </cmt> <cmt> rllib/tests/test_supported_spaces.py </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a2c-microbatch.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a3c-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-a3c.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-torch.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/cartpole-dqn-param-noise.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/pendulum-ppo-tf.yaml </cmt> <cmt> rllib/tuned_examples/cartpole/pendulum-ppo-torch.yaml </cmt> <cmt> rllib/tuned_examples/pendulum/pendulum-ppo.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/cartpole-a3c.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/cartpole-dqn-tf-param-noise.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ddpg-tf.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ddpg-torch.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-ppo.yaml </cmt> <cmt> rllib/tuned_examples/regression_tests/pendulum-td3.yaml </cmt> <cmt> ddpg stats fix. </cmt> <cmt>  conflicts: </cmt> <cmt> 	.travis.yml </cmt> <cmt> 	rllib/tuned_examples/regression_tests/pendulum-td3.yaml </cmt> <cmt> wip. </cmt>",benchmark and regression test yaml cleanup and restructuring.
2140,<desc> this is needed to get puyo puyo tetris and cave story booting further. also return the correct error code when opening files that don't exist. this supersedes #227 </desc> <cmt> fs: make ensuresavedata create the savedata folder when called for the first time. </cmt> <cmt> fs: stubbed createsavedata. it currently does nothing. </cmt> <cmt> fs: use the correct error code when trying to open files that don't exist. </cmt>,make ensuresavedata create the save data if it doesn't already exist.
2141,<desc> fixes #3729. i suggest this be reviewed commit by commit. </desc> <cmt> use a more accurate test name. </cmt> <cmt> verify builders. </cmt> <cmt> refactor completion code for object literals/bindings and import clauses. </cmt> <cmt> remove builder from import clauses. </cmt> <cmt> added original test case. </cmt>,don't show builders in import clauses
2142,"<desc> added obs_frontend_event_replay_buffer_saved to the frontend api emitted it from the replay buffer save handler in ui updated docs it extends plugin writing capabilities (no drawbacks). arch linux vm, local build, tested with a proof-of-concept plugin with event callback that listens for the event new feature (non-breaking change which adds functionality) documentation (a change to documentation pages) </desc> <cmt> obs-frontend-api: add the event of saving replay buffer </cmt> <cmt> add obs_frontend_event_replay_buffer_saved as given by rfc 33 </cmt> <cmt> ui: emit the replay buffer saved event to the api </cmt> <cmt> send the obs_frontend_event_replay_buffer_saved to api (as in rfc33) </cmt> <cmt> docs/sphinx: add replay buffer saved event </cmt> <cmt> documentation provided for obs_frontend_event_replay_buffer_saved (rfc33) </cmt>",add the replay buffer saved event to the frontend api
2143,<desc> also added a test to app-document suite to make sure we don't regress on this </desc> <cmt> add missing keys for array elements </cmt> <cmt> add test for missing key prop in app-document </cmt>,add missing key prop for array elements in _document
2144,"<desc> the branch in question was merged in #3472 . also updated the comment, which is no longer true. @qlzh727 - for context, these are the files @vishh was using to generate and register a docker image for this repo. </desc> <cmt> remove cd and checkout </cmt> <cmt> updating comment </cmt>",update dockerfile for gpu now that the branch has been merged
2145,"<desc> warnings to encourage people to test reactos in vms until it becomes more stable. </desc> <cmt> update readme.md </cmt> <cmt> added ""alpha"" warnning to readme </cmt> <cmt> this is so people know to test this in vms(p.s sorry for duplicatoion i am new to github(also exuse my spelling i have dislexia)) </cmt>",added a alpha note for new users to the readme
2146,"<desc> this corrects a minor typo made in d2571e5 (#34917). the docs mentioned rescue_with, but the actual method name is rescue_from (with is one of its parameters), as seen in the examples just below these two sentences. i also noticed that we were linking to the rescue_from api docs in the second mention of rescue_from. i think it's conventional to link to an external reference the first time the subject is mentioned, so i moved this link accordingly. </desc> <cmt> change rescue_with -> rescue_from in action cable overview guide </cmt> <cmt> this was a minor typo made in d2571e560c62116f60429c933d0c41a0e249b58b. </cmt> <cmt> the actual method name is rescue_from (with is one of its </cmt> <cmt> parameters), as seen in the examples below these two sentences. </cmt> <cmt> [ci skip] </cmt> <cmt> move the rescue_from api docs link to the first mention of it </cmt> <cmt> in the action cable overview guide </cmt> <cmt> if we want to link to the rescue_from api docs, it makes more sense to </cmt> <cmt> do it the first time we mention rescue_from rather than the second </cmt> <cmt> time. </cmt> <cmt> [ci skip] </cmt>",fix rescue_from documentation in action cable overview guide [ci skip]
2147,"<desc> #1244 didn't supply a test case, so i wrote one for it as a way to get familiarized with the codebase / test system. </desc> <cmt> fixed issue #1241: _scanstring not supporting upper case format specifiers a, e, f, g, x. </cmt> <cmt> add test for capitalized sscanf format specifiers. </cmt> <cmt> add jez ng to authors. </cmt>",add test for uppercase format specifiers in sscanf.
2148,<desc> this change set updates the github.com/stretchr/testify dependency to stretchr/testify@7e4a149. closes mesosphere/kubernetes-mesos#333. ref: #9265 (comment) </desc> <cmt> update github.com/stretchr/testify/... rev to 7ea4a14 </cmt> <cmt> kubelet: use assert.equalvalues instead of assert.equal </cmt> <cmt> the last update to github.com/stretchr/testify makes assert.equal </cmt> <cmt> consider the type of its arguments. this commit makes this test pass </cmt> <cmt> again by only testing for value equality using assert.equalvalues. </cmt>,update github.com/stretchr/testify rev to 7e4a149
2149,<desc> removing trusted-by section from home page and moving it to a new page. this code has been tested on a test web-server. </desc> <cmt> add custom jenkinsfile </cmt> <cmt> move users from home page </cmt> <cmt> test users page </cmt>,move trusted-by section from main page to a new page
2150,"<desc> most network params in dask module is constructed manually based on ips and ports. we need to drop all aliases from params to not confuse lightgbm cpp code with multiple values for the same param. lightgbm/python-package/lightgbm/dask.py lines 125 to 135 in ac706e1 machine_list = ','.join([ '%s:%d' % (urlparse(worker_address).hostname, port) for worker_address, port in worker_address_to_port.items() ]) network_params = { 'machines': machine_list, 'local_listen_port': worker_address_to_port[local_worker_address], 'time_out': time_out, 'num_machines': len(worker_address_to_port) } </desc> <cmt> update dask.py </cmt> <cmt> update basic.py </cmt>",drop aliases of core network parameters
2151,<desc> towards slep009. fixing the __init__s in cross_decomposition. ping @jnothman @ogrisel </desc> <cmt> api make __init__ params in covariance kw-only </cmt> <cmt> api make __init__ params in covariance kw-only </cmt> <cmt> checkout out from master </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> api make __init__ params in cross_decomposition kwonly </cmt>,api make __init__ params in cross_decomposition kw-only
2152,<desc> unified canadian aboriginal syllabics 1400-1488  common indic number forms a830-a839  coverage: </desc> <cmt> base: add common indic number forms to font katica regular 10 </cmt> <cmt> a830-a839 </cmt> <cmt> base: add unified canadian aboriginal syllabics to katica regular 10 </cmt> <cmt> 1400-1488 </cmt>,add unified canadian aboriginal syllabics & common indic number forms to font katica regular 10
2153,"<desc> contains some cleanup of the projectconfig endpoint and generation, along with a fast path for detecting disabled projects based on their visibility attribute. ideally, i would like to merge most of the endpoint's code with the one in the update_config_cache task, but that refactor makes more sense once we're restructuring rate limits. </desc> <cmt> ref(relay): clean up project config generation and add fast-path </cmt> <cmt> ref(relay): remove unused metrics in projectconfig endpoint </cmt>",clean up project config generation and add a fast path
2154,"<desc> add new free course, and sub-categories added a amazing course of codeigniter, a framework php because frameworks promote code productivity it's just free it's a course not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> update free-courses-pt_br.md </cmt> <cmt> update free-courses-pt_br.md </cmt> <cmt> update free-courses-pt_br.md </cmt>","added free codeigniter course, and organizing list by sub-categories"
2155,"<desc> includes #2280, so that should be reviewed first. </desc> <cmt> try harder to return deadline_exceeded when we should </cmt> <cmt> do this by ensuring that the alarm callback has had a chance to run on a </cmt> <cmt> call before returning status to the application. </cmt> <cmt> if we do not do this: </cmt> <cmt> - the server alarm could be scheduled and run </cmt> <cmt> - it will write a rst_stream with a status that loses the deadline </cmt> <cmt> exceededness (because that is unexpressable in http2 error codes) </cmt> <cmt> - it will be received by the client and processed </cmt> <cmt> - the client will return an internal error (the lossy re-encoding of the </cmt> <cmt> server status), and then run its alarm handler to set the status to </cmt> <cmt> something else </cmt> <cmt> delay unregister of fd until freelisted </cmt> <cmt> prevents a race whereby we start deleting the freelist before it's used </cmt> <cmt> don't unregister resolver object until callback complete </cmt> <cmt> prevents tsan races in iomgr shutdown code </cmt>",fix iomgr shutdown tsan races
2156,"<desc> closes #5838 in particle#fire(), an error is thrown if the particle has no texture frame. this prevents an uncaught error later when the particle fails to render. in particleemittermanager#setemitterframes(), console warnings are printed if an invalid texture frame is given or if no texture frames were set. </desc> <cmt> warn for missing texture frames </cmt> <cmt> throw an error for missing particle texture frame </cmt> <iss> please add useful information when a particles emitter has an invalid/null frame </iss>","warn, throw for particle texture frame mistakes"
2157,"<desc> format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> fix service metadata update failed problem. </cmt> <cmt> random connect to server </cmt> <cmt> add some metrics and log for service and client </cmt> <cmt> add some metrics and log for naming task worker </cmt>",add some metrics and logs
2158,<desc> #11035 #10625 </desc> <cmt> make declaration emit test name consistent </cmt> <cmt> update baselines </cmt> <cmt> add tests </cmt> <cmt> update baselines from cherry-pick changes from master </cmt> <cmt> serialize type alias when type alias symbol is not accessible </cmt> <cmt> address pr </cmt>,serialize type alias when type-alias is not accessible and emit generic
2159,"<desc> i updated the german translation to match the english original. as the translated version don't have a subfolder for ""additional material"" i incorporated the subsection into the document. </desc> <cmt> updated the first part of the translation. </cmt> <cmt> update readme.de.md </cmt> <cmt> fixed small typops </cmt> <cmt> translated and added the parts ""additional material"" </cmt> <cmt> # conflicts: </cmt> <cmt> #	translations/readme.de.md </cmt> <cmt> update readme.de.md </cmt> <cmt> clarification </cmt> <cmt> update readme.de.md </cmt> <cmt> read the tutorial again and fixed typos </cmt>",update german translation addresses #96
2160,"<desc> the new release of multi site configurator (msc) will be named multi site orchestrator (mso). since these modules have not been released, we do not offer any backward compatibility. msc </desc> <cmt> msc_tenant: improve docs </cmt> <cmt> rename msc modules to mso </cmt>",rename msc modules to mso nomenclature
2161,"<desc> looks for any /packages/<package>/<path requests and maps those to package:<package>/<path> uris, which are then resolved using normal package uri resolution. related issues dart-lang/webdev#865 i added a unit test to the existing web dev server test. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> support mapping /packages/<package>/<path> requests to package:<package>/<path> uris in the web device file server </cmt> <cmt> add test </cmt>",serve packages uris in flutter_tools dev web server
2162,"<desc> since the days immemorial of the terminal, the termcontrol has auto-focused itself when it finalizes its layout. this has led to the problem that wt ; sp ; sp ; sp... ends up focusing one of these panes at random. this pr fixes this issue by getting rid of the auto-focusing. panes now manually get focused when created. we manually focus the active pane when a commandline is dispatched. since we're internally tracking ""active"" separate from ""focused"", this ends up working as you'd hope. closes #6586 i work here i also had to turn the cursor off by default. most termcontrols would never get the lostfocus event, so their cursors would get left on, and that's not right. i've run the following things a bunch of times to make sure they work: wtd sp ; sp ; sp wtd sp ; sp ; sp ; fp -t 0 newtab splitpane use the command palette to do the above as well where the result used to be random (cases 1 & 2), the result is exactly what you'd expect now. it doesn't work at all for wtd sp ; sp ; sp ; mf left presumably because we can't move-focus directionally during startup. however, that doesn't work today either, so it's not making it worse. just highlights that single scenario doesn't work right. </desc> <cmt> this sorta works to solve #6586 </cmt> <cmt> this works well for </cmt> <cmt>  </cmt> <cmt> wtd sp ; sp ; sp </cmt> <cmt>  </cmt> <cmt> and for </cmt> <cmt>  </cmt> <cmt> wtd sp ; sp ; sp ; fp -t 0 </cmt> <cmt>  </cmt> <cmt> but it doesn't work at all for </cmt> <cmt>  </cmt> <cmt> wtd sp ; sp ; sp ; mf left </cmt> <cmt>  </cmt> <cmt> presumably because we can't move-focus directionally during startup. </cmt> <cmt> this fixes some fallout issues </cmt> <cmt> primarily with splitting not on the commandline. also with using the cmdpal to execute commands </cmt> <cmt> comments, i'm not a barbarian </cmt> <iss> wt split-pane (multiple copies) seems to have occasional focus issues </iss>",only focus the active pane once initialization is complete
2163,"<desc> what do these changes do? ray used to hang in the following scenario: node n1 forwards an actor creation task to node n2. n2 dies. n1 submits an actor task. the location is unknown, so the task gets queued. the actor creation task never gets scheduled, so the task remains queued forever. the job hangs because reconstruction is never triggered for the actor creation task. this pr fixes the issue by notifying the backend that tasks for actors whose locations are unknown depend on the actor creation task. this will trigger reconstruction if the actor creation task failed. this pr does not handle suppression for actor creation, which can happen if task lease or actor table notifications are delayed significantly. </desc> <cmt> add regression test </cmt> <cmt> request actor creation if no actor location found </cmt>",fault tolerance for actor creation
2164,"<desc> fixes  #34500 there are two types of attributes. ""string"" and ""configuration attribute"". we need to get the real ""value"" based on the type. win_iis_website.ps1 ansible version ansible 2.4.2.0 </desc> <cmt> remidate windows debugging </cmt> <cmt> using $complex_args is not working (anymore?). we need to set $params directly. </cmt> <cmt> fixing issue with win_iis_website parameter types </cmt> <cmt> there are two types of attributes. ""string"" and ""configuration attribute"". we need to get the real ""value"" based on the type. </cmt> <cmt> revert ""remidate windows debugging"" </cmt> <cmt> this reverts commit df75d3bb0d152b10c24187ce4c643b4733bae336. </cmt> <iss> win_iis_website always changed with parameter logextfileflags </iss>",fixing issue with win_iis_website parameter types. issue #34500
2165,<desc> see jenkins-36923 follow-up to #2474 @jenkinsci/code-reviewers @reviewbybees also matching pr to be made against bouncycastle-api plugin </desc> <cmt> [fixed jenkins-36922] upgrade to instance-identity-module 2.0 </cmt> <cmt> - we migrate the bcpkix dependency from instance-identity to the war's web-inf/lib so that the net effect is zero and we are still not exposiing the bcpkix as a transitive dependency of jenkins-core </cmt> <cmt> [jenkins-36923] give ownership of bcpkix dependency to bouncycastle-api plugin </cmt>,give ownership of bcpkix dependency to bouncycastle-apl plugin
2166,"<desc> when receiving a header name that is an uncompressed literal, the qpack decoder was using the address of the literal, rather than the literal itself, as the header field name. this pr addresses the issue as well as adding a round-trip test that uses an uncompressed literal. </desc> <cmt> add failing test </cmt> <cmt> deference the buffer, not pointer to the buffer </cmt>",fix error in qpack header decoder
2167,"<desc> result_type must be unsigned:  using a signed type causes an infinite loop working with ms visual studio 2017, targetting: v140, windowstargetplatformversion 10.0.15063.0, debug, x64 simply using uint32_t seems sufficient, since the value of max() is small enough. </desc> <cmt> changes randomnumbergenerator::result_type to be unsigned </cmt> <cmt> changes type of randomnumbergenerator::result_type to be compatible with older compilers as well. </cmt>",randomnumbergenerator::result_type should be unsigned
2168,"<desc> currently, the same class fieldcapabilities is used both to represent the capabilities for one index, and also the merged capabilities across indices. to help clarify the logic, this pr proposes to create a separate class indexfieldcapabilities for the capabilities in one index. the refactor will also help when adding source_path information in #49264, since the merged source path field will have a different structure from the field for a single index. individual changes: add a new class indexfieldcapabilities. remove extra constructor from fieldcapabilities. combine the add and merge methods in fieldcapabilities.builder. </desc> <cmt> add a new class indexfieldcapabilities. </cmt> <cmt> remove extra constructor from fieldcapabilities. </cmt> <cmt> combine the add and merge methods in fieldcapabilities.builder. </cmt>",create a class to hold field capabilities for one index.
2169,"<desc> my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add support for bm65rgb </cmt> <cmt> move bm65rgb to /kprepublic </cmt>","add support for bm65rgb, a revival of #13361"
2170,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: correct import style shown here increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> merged definitions with my own. therefor added some types and made </cmt> <cmt> changed the namespace back to a module. </cmt> <cmt> fixxed lint errors </cmt> <cmt> switched from namespace to module declaration and added type declarations for the string types. </cmt>",improved type definitions for recharts
2171,"<desc> reverted recent change on adding --no-includes to darttest.sh and modified the source generator for dart  to exclude emitting those includes at all. they are not used in any of the tests. ran . src/clang-format-git.sh and fixed two other c++ issues that were recently introduced. tested: tests/darttest.sh with dart 2.8.1 </desc> <cmt> fixed refractoring issue in reflection/generate_code.sh. also, mv deletes the original file, so i don't need to clean it up manually in that case. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixed dart tests by removing code-gen for included files. </cmt>",getting tests/darttest.sh to work on master.
2172,"<desc> this pr adds the same optimization we had in #2044 to messagepack. closes #2196 </desc> <cmt> :bug: serialize 32-bit floating-point numbers as float 32 in messagepack (0xca) #2196 </cmt> <cmt> :white_check_mark: update test suite </cmt> <iss> msgpack serialisation : float is treated as 64bit float, not 32bit float. </iss>",serialize floating-point numbers with 32 bit when possible (messagepack)
2173,<desc> fix the section headers in the ansible docs that do not follow the allowed section header notation. fixes #75685 docs/docsite/rst/dev_guide/style_guide </desc> <cmt> docs: fix section header notation in style_guide/grammar </cmt> <cmt> docs: fix section header notation in style_guide/spelling </cmt> <cmt> docs: fix section header notation in style_guide/tm_resources </cmt> <cmt> docs: fix section header notation in style_guide/voice </cmt> <cmt> docs: fix section header notation in style_guide/why_use </cmt> <iss> docs: update section header notation in style guide </iss>,fix section header notation in style guide
2174,"<desc> cf issue #5181 (which discusses two bugs, so shouldn't be closed just yet) if a training text was empty, gold.ner was none, throwing an error when training the ner pipeline bug fix i have submitted the spacy contributor agreement. </desc> <cmt> set gold fields to empty list instead of keeping them as none </cmt> <cmt> add unit test </cmt>",prevent none in gold fields
2175,"<desc> this is an enhancement or feature. this pr is about changing the heading tag of related posts section from h4 to h2 for seo enhancement. i have implemented the same on my website in pr and working demo with reference to your comment on my post at #3040 (reply in thread) since you have already provided the relevant font size, so any style change may not be required. minimal-mistakes/_sass/minimal-mistakes/_page.scss line 529 3c075fe .page__related-title { </desc> <cmt> update heading tag from h4 to h2 </cmt> <cmt> update heading tag from h4 to h2 </cmt>",change heading tag of related posts section from h4 to h2 for seo enhancement
2176,<desc> updates the openssl static library to be linked into the react windows desktop dll. see introduced  changes: jurocha-ms/openssl@6539cd3...jurocha-ms:bd711e537cc6afab0c295ad81d9728ec7ee6c51d microsoft reviewers: open in codeflow </desc> <cmt> upgrade openssl nuget to 1.1.1-d.3 </cmt> <cmt> change files </cmt>,upgrade openssl nuget to 1.1.1 d.3
2177,"<desc> this is an alternative implementation to #13655. before this patch time travel feature depends on mocha's stub feature. since mocha is not a rails dependency we can't depend on this specific library. we choose to use our own implementation to avoid adding one more dependency to rails. this implementation is using an internal stub implementation instead of minitest to make possible to rspec users use this methods without any problem. fixes #13380. thank you @myronmarston for the help. </desc> <cmt> implement a simple stub feature to use in the time travel helpers </cmt> <cmt> alias the original method first to avoid warnings </cmt> <cmt> use instance method instead of before hook </cmt> <cmt> change the class and method visibility </cmt> <cmt> store the singleton_class in a local variable </cmt> <cmt> use each_value </cmt> <iss> [4.1.0.beta1] time travel helpers don't work ""out of the box"" </iss>",alternative implementation to make time travel not dependent on mocha
2178,"<desc> namely, add iris and userspace eeprom settings </desc> <cmt> fix unicode sample </cmt> <cmt> add irony mark </cmt> <cmt> remove unpretty keymaps </cmt> <cmt> add qmk dfu and conditional music mode </cmt> <cmt> unicode fixes </cmt> <cmt> unicode fixes </cmt> <cmt> make layer indication more modular </cmt> <cmt> finish removing faux click </cmt> <cmt> cleanup of userspace and addition of 'update_tri_layer_state' function </cmt> <cmt> add modifier status indicators to orthodox </cmt> <cmt> remove tri layer function </cmt> <cmt> minor tweaks </cmt> <cmt> remove the orthodox's indicator's reliance on layer_state_set </cmt> <cmt> add custom eeprom settings </cmt> <cmt> make eeprom config more efficient </cmt> <cmt> viterbi config </cmt> <cmt> add iris keyboard layout and userspace cleanup </cmt> <cmt> iris keyboard tweaks </cmt> <cmt> use grave escape on iris </cmt>",update to drashna keymaps and userspace
2179,"<desc> article will be ready in max 24 hours from now. </desc> <cmt> expression-based access control </cmt> <cmt> permitall, hasrole, hasanyrole etc. </cmt> <cmt> i modified classes regards to security </cmt> <cmt> added test cases for spring security expressions </cmt> <cmt> handler interceptor - logging example </cmt> <cmt> test for logger interceptor </cmt> <cmt> removed conflicted part </cmt> <cmt> conflicts: </cmt> <cmt> spring-security-rest-full/src/main/java/org/baeldung/web/interceptor/loggerinterceptor.java </cmt> <cmt> spring-security-rest-full/src/main/resources/websecurityconfig.xml </cmt> <cmt> userinterceptor (adding user information to model) </cmt> <cmt> conflicts: </cmt> <cmt> spring-security-rest-full/src/main/java/org/baeldung/spring/webconfig.java </cmt>",changing spring mvc model parameters
2180,"<desc> your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description this pr implements the following two functions. read the documentation below. /** * is_annotation_reference() - checks if the specified annotation is a reference. * @annotation: pointer to an annotation. * this function recognizes the type of the specified annotation and returns true if its * type is any of the following three: r_code_annotation_type_global_variable, * r_code_annotation_type_constant_variable, r_code_annotation_type_function_name * return: returns true if the specified annotation is a reference. */ r_api bool is_annotation_reference(rcodeannotation *annotation); /** * is_annotation_variable() - checks if the specified annotation is a function variable. * @annotation: pointer to an annotation. * this function recognizes the type of the specified annotation and returns true if its * type is any of the following two: r_code_annotation_type_local_variable, * r_code_annotation_type_function_parameter * return: returns true if the specified annotation is a function variable. */ r_api bool is_annotation_variable(rcodeannotation *annotation); ... test plan check code. fetch and compile cutter pr #2352 after compiling this pr. that pr uses this api. so you can check if it's working correctly or not. ... closing issues ... </desc> <cmt> functions added </cmt> <cmt> formatted </cmt> <cmt> add documentation </cmt>",api for checking if an annotation is a reference or function variable.
2181,"<desc> displayed in internet explorer 11, text placeholder looks same as input text. please check my fiddle with internet explorer 11. (screen capture from my fiddle) this mistake is caused by typo in selecting pseudo class -ms-input-placeholder, so i fixed it. when fixing, i looked this msdn document. and i used !important in some error case because i had to get higher specificity than other style like below. .ui.form .field.error input[type='text'] </desc> <cmt> fix placeholder typo in vendor prefix for ie </cmt> <cmt> add !important to enable placeholder styling in ie </cmt>",fix typo in placeholder styling for the internet explorer
2182,"<desc> i adjusted the oal tool to regenerate all indicators, also change the manual indicators and test mockers. in the parent class, i added the following methods public abstract indicator tohour(); public abstract indicator today(); public abstract indicator tomonth(); by using this, indicator can be transferred to another new indicator in hour/day/month dimensionalities. the high-level dimensionality timer can aggregate indicators in minutes, and save these. </desc> <cmt> add transfer time bucket methods. </cmt> <cmt> prepare to merge </cmt> <cmt> merge commit '1936d38d163998762e66bbd3af8114a267bc1964' into timebucket </cmt> <cmt> # conflicts: </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/generated/all/alldispatcher.java </cmt> <cmt> #	oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/generated/all/allheatmapindicator.java </cmt> <cmt> support to hour, day, month dimensionalities </cmt> <cmt> support time bucket transfer. </cmt>",support time bucket transfer for all indicators.
2183,"<desc> this pr cherry-picks the following prs to stable: #56467: bump stack size to 32mb #56486: propagate all closure requirements to the caller #56519: update edition guide the changes will be included in the final 1.31.0 binary (to avoid a point release). to deploy the build to dev-static the old manifest needs to be removed from the bucket after the pr is merged.  r? @alexcrichton </desc> <cmt> bump stack size to 32mb </cmt> <cmt> propagate all closure requirements to the caller </cmt> <cmt> call methods on the right tcx </cmt> <cmt> there are two tyctxts, one global, one local. methods must be called </cmt> <cmt> on the right one, as they differ by invariant lifetimes. </cmt>",add a few critical fixes to the 1.31.0 release
2184,"<desc> we will be user friendly close #837 </desc> <cmt> cli: if user passed unknown option, show help and exit, close #837 </cmt> <cmt> cli: test unknown option output </cmt> <cmt> linting </cmt> <iss> show cli help when user passed unknown option </iss>",show help on unknown option 837
2185,"<desc> when using kubectl describe <resource> <name> , the events returned for the resource do not use the eventseries.count and eventseries.lastobservedtime this pr adds the logic to compute the age of the event using these fields fixes kubernetes/kubectl#1095 changed kubectl describe to compute age of an event using the count and lastobservedtime fields available in the event series </desc> <cmt> take into account new fields for event </cmt> <cmt> add event with old event fields for test </cmt> <iss> ""kubectl describe <resource>"" doesn't take into account the new fields of core.v1/event </iss>",use fields from event series when computing describe events for a object
2186,<desc> makes the controlled/uncontrolled + derived state pattern more obvious which results in one less create callback (wasteful popper re-creation) and flipplacement call. videos are taken with <popper flip /> and we're about to scroll to a position where the placement needs to be flipped. when this happens we used to get this weird create-update-create-update chain that is now replaced by a continuous update.  pr: and we even got less shipped code. hope that makes the implementation more reasonable. </desc> <cmt> [popper] fix re-creation when placement flips </cmt> <cmt> apply controlled/uncontrolled/derived state pattern </cmt>,refactor to more commonly known react patterns
2187,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. fixes issue #17836 @scissorsneedfoodtoo , #19720 </desc> <cmt> update adjust-the-background-color-property-of-text.english.md </cmt> <cmt> update adjust-the-background-color-property-of-text.english.md </cmt> <cmt> update adjust-the-background-color-property-of-text.english.md </cmt>",fixes issue with background-color and background being interpreted differently
2188,<desc> description: clarifies the drain time command line option is also used by drain listeners via lds. risk level: low testing: n/a docs changes: n/a release notes: n/a </desc> <cmt> clarify draining option docs </cmt>,clarify drain time cli docs
2189,"<desc> in cases where there are lots of tables and/or tables with long names, sql lab can become difficult to use. this adds a couple of affordances for that use case: adds tooltips to items in the table select menu, displaying the full table name widen the autocomplete window. unfortunately i couldn't find a way to make the width dynamic or add a tooltip. but it's now twice as wide as before which should be pretty accommodating. test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> widen the autocomplete menu for table names </cmt> <cmt> display the full table name in a tooltip </cmt>",handle long table names in sql lab
2190,"<desc> adds an extra note as below to explain that a tuple pattern was probably intended. error[e0026]: variant x::y does not have a field named data --> src/main.rs:18:16 | 18 |         x::y { data } => println!(""the data is {}"", data) |                ^^^^ variant x::y does not have field data error[e0027]: pattern does not mention field 0 --> src/main.rs:18:9 | 18 |         x::y { data } => println!(""the data is {}"", data) |         ^^^^^^^^^^^^^ missing field 0 | = note: trying to match a tuple variant with a struct variant pattern fixes #41314. </desc> <cmt> diagnostic note when matching tuple enum with struct pattern </cmt> <cmt> ui unit test for note when matching tuple enum with struct pattern </cmt>",improve diagnostics when attempting to match tuple enum variant with struct pattern
2191,"<desc> this is missing a test of the new cudnn support in convolution2d (here). maybe someone could add that, since i don't have it set up on my machine? </desc> <cmt> add convolutional layer tests </cmt> <cmt> add upsampling layer tests </cmt> <cmt> add tests for border_mode == same </cmt>",add tests for convolutional layers
2192,"<desc> description more updates of #20553 to make the car's indicators more in line with stock, especially on audi.  this also keeps visual indicators online regardless of op enablement state, as we already have the status led for this function. route: 07667b885add75fd|2021-04-13--13-53-11 </desc> <cmt> improve vw hud with laneless and ldw </cmt> <cmt> no longer depend on laneless param </cmt>",vw lane lines visual indicator changes
2193,"<desc> i have added the following new language in the process for starting a new translation section. doc page :-  gujarati french mongolian </desc> <cmt> add gujarati, french, mongolian langulage to new transalation list </cmt>",add new language in transalation list
2194,"<desc> backporting a set of patches from 5.6 that improve allow better parsing of the video= strings from the kernel command line. the base code required the resolution to be specified under all circumstances, whereas with these we can now omit the resolution and only add the overscan margins or rotations. </desc> <cmt> drm/modes: parse_cmdline: fix possible reference past end of string </cmt> <cmt> commit 8582e244e5fe72d2e9ace186fa8f3ed3bb4122e1 upstream. </cmt> <cmt> before this commit, if the last option of a video=... option is for </cmt> <cmt> example ""rotate"" without a ""=<value>"" after it then delim will point to </cmt> <cmt> the terminating 0 of the string, and value which is sets to <delim + 1> </cmt> <cmt> will point one position past the end of the string. </cmt> <cmt> this commit fixes this by enforcing that the contents of delim equals '=' </cmt> <cmt> as it should be for options which take a value, this check is done in a </cmt> <cmt> new drm_mode_parse_cmdline_int helper function which factors out the </cmt> <cmt> common integer parsing code for all the options which take an int. </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: make various char pointers const </cmt> <cmt> commit 83e14ea3a64f00897cc31974d3ae4e27e5a7405b upstream. </cmt> <cmt> we are not supposed to modify the passed in string, make char pointers </cmt> <cmt> used in drm_mode_parse_cmdline_options() const char * where possible. </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: stop parsing extras after bpp / refresh at ', ' </cmt> <cmt> commit c2ed3e941901810ad3d55ce1935fa22c5007fee4 upstream. </cmt> <cmt> before this commit it was impossible to add an extra mode argument after </cmt> <cmt> a bpp or refresh specifier, combined with an option, e.g. </cmt> <cmt> video=hdmi-1:720x480-24e,rotate=180 would not work, either the ""e"" to </cmt> <cmt> force enable would need to be dropped or the "",rotate=180"", otherwise </cmt> <cmt> the mode_option would not be accepted. </cmt> <cmt> this commit fixes this by fixing the length calculation if extras_ptr </cmt> <cmt> is set to stop the extra parsing at the start of the options (stop at the </cmt> <cmt> ',' options_ptr points to). </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: accept extras directly after mode combined with options </cmt> <cmt> commit cfb0881b8f621b656a9e23b31944a5db94cf5842 upstream. </cmt> <cmt> before this commit it was impossible to combine an extra mode argument </cmt> <cmt> specified directly after the resolution with an option, e.g. </cmt> <cmt> video=hdmi-1:720x480e,rotate=180 would not work, either the ""e"" to force </cmt> <cmt> enable would need to be dropped or the "",rotate=180"", otherwise the </cmt> <cmt> mode_option would not be accepted. </cmt> <cmt> this commit fixes this by setting parse_extras to true in this case, so </cmt> <cmt> that drm_mode_parse_cmdline_res_mode() parses the extra arguments directly </cmt> <cmt> after the resolution. </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: rework drm_mode_parse_cmdline_options() </cmt> <cmt> commit 739b200c2edcaaa7a86f37b0c11db57956433dfb upstream. </cmt> <cmt> refactor drm_mode_parse_cmdline_options() so that it takes a pointer </cmt> <cmt> to the first option, rather then a pointer to the ',' before the first </cmt> <cmt> option. </cmt> <cmt> this is a preparation patch for allowing parsing of stand-alone options </cmt> <cmt> without a mode before them, e.g.: video=hdmi-1:margin_right=14,... </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: add freestanding argument to drm_mode_parse_cmdline_options() </cmt> <cmt> commit 99e2716e053734b70434502867be24d20a3e2d84 upstream. </cmt> <cmt> add a freestanding function argument to drm_mode_parse_cmdline_options() </cmt> <cmt> similar to how drm_mode_parse_cmdline_extra() already has this. </cmt> <cmt> this is a preparation patch for allowing parsing of stand-alone options </cmt> <cmt> without a mode before them, e.g.: video=hdmi-1:margin_right=14,... </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: set bpp/refresh_specified after successful parsing </cmt> <cmt> commit 6a2d163756545aa3180d7851d5f8322b865e72be upstream. </cmt> <cmt> drm_connector_get_cmdline_mode() calls </cmt> <cmt> drm_mode_parse_command_line_for_connector() with &connector->cmdline_mode </cmt> <cmt> as mode argument, so anything which we store in the mode arguments gets </cmt> <cmt> kept even if we return false. </cmt> <cmt> avoid storing a possibly false-postive bpp/refresh_specified setting </cmt> <cmt> in connector->cmdline_mode by moving the setting of these to after </cmt> <cmt> successful parsing of the bpp/refresh parts of the video= argument. </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: allow specifying stand-alone options </cmt> <cmt> commit 7b1cce760afe38b40f0989cdf10b2190dccf9815 upstream. </cmt> <cmt> some options which can be specified on the commandline, such as </cmt> <cmt> margin_right=..., margin_left=..., etc. are applied not only to the </cmt> <cmt> specified mode, but to all modes. as such it would be nice if the user </cmt> <cmt> can simply say e.g. </cmt> <cmt> video=hdmi-1:margin_right=14,margin_left=24,margin_bottom=36,margin_top=42 </cmt> <cmt> this commit refactors drm_mode_parse_command_line_for_connector() to </cmt> <cmt> add support for this, and as a nice side effect also cleans up the </cmt> <cmt> function a bit. </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: add support for specifying panel_orientation (v2) </cmt> <cmt> commit 4e7a4a6fbdc669c44e6079f9d5eb25673749455f upstream. </cmt> <cmt> sometimes we want to override a connector's panel_orientation from the </cmt> <cmt> kernel commandline. either for testing and for special cases, e.g. a kiosk </cmt> <cmt> like setup which uses a tv mounted in portrait mode. </cmt> <cmt> users can already specify a ""rotate"" option through a video= kernel cmdline </cmt> <cmt> option. but that only supports 0/180 degrees (see drm_client_modeset todo) </cmt> <cmt> and only works for in kernel modeset clients, not for userspace kms users. </cmt> <cmt> the ""panel-orientation"" connector property otoh does support 90/270 degrees </cmt> <cmt> as it leaves dealing with the rotation up to userspace and this does work </cmt> <cmt> for userspace kms clients (at least those which support this property). </cmt> <cmt> changes in v2: </cmt> <cmt> -add missing ':' after @panel_orientation (reported by kbuild test robot) </cmt> <cmt> buglink: </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: remove some unnecessary code (v2) </cmt> <cmt> commit 5b926617cdef41ce0696e09834991194b1759e28 upstream. </cmt> <cmt> fb_get_options() will return fb_mode_option if no video=<connector-name> </cmt> <cmt> argument is present on the kernel commandline, so there is no need to also </cmt> <cmt> do this in drm_mode_parse_command_line_for_connector() as our only caller </cmt> <cmt> uses fb_get_options() to get the mode_option argument. </cmt> <cmt> changes in v2: </cmt> <cmt> -split out the changes dealing with the initialization of the mode struct </cmt> <cmt> into a separate patch </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt> <cmt> drm/modes: parse_cmdline: explicitly memset the passed in drm_cmdline_mode struct </cmt> <cmt> commit d1fe276b5115f0d581c3cfe6154633b3547e8aab upstream. </cmt> <cmt> instead of only setting mode->specified on false on an early exit and </cmt> <cmt> leaving e.g. mode->bpp_specified and mode->refresh_specified as is, </cmt> <cmt> lets be consistent and just zero out the entire passed in struct at </cmt> <cmt> the top of drm_mode_parse_command_line_for_connector() </cmt> <cmt> changes in v3: </cmt> <cmt> -drop ""mode->specified = false;"" line instead of the ""return false;"" (oops) </cmt> <cmt> this crasher was reported-by: kernel test robot <lkp@intel.com> </cmt> <cmt> acked-by: maxime ripard <mripard@kernel.org> </cmt> <cmt> link: </cmt>","backport a load of cmdline ""video="" token parsing changes"
2195,<desc> early stop callback function with the same logic as in xgboost: stopping after n steps without improvement. </desc> <cmt> adding early stop round function </cmt> <cmt> adding early stop round function correction </cmt> <cmt> adding early stop round function correction 3 </cmt>,add early stop callback function
2196,<desc> i think your repo could really benefit from having my fantastic username displayed among the other completers! </desc> <cmt> added mikesigs to the contributors list </cmt> <cmt> something isn't working </cmt> <cmt> drew a picture </cmt>,add mikesigs to the list of contributors
2197,"<desc> this pr adds code and unit tests that fix issue #1835 and issue #1836. apologies for the changes being together but they were made at the same time. 1836 readable validation messages in error.h define an enum validateerrorcode for a set of kvalidateerrorxxx error codes, one per validation failure type in en.h add getvalidateerror_en() to map error code to a human-readable error message with inserts in schema.h: when creating a validation error, use the error code as the primary indicator, in addition to the error keyword add getinvalidschemacode() to validator to return the error code oneof: split into two errors - 'no match' and 'multiple match' - with error code and message for each allof: create in accordance to  dependencies: make property dependency error look like schema dependency error (bug found - see issue #1805) additionalitems: correct error keyword from items to additionalitems refactor adderrorlocation() in schematest.cpp fix the expected test outputs to include error code in schemavalidator.cpp example, add code to walk the errors and output error messages with inserts 1835 multiple validation failures in schema.h: add validateflag enum and member flags_ to the validator (analogous to parserflag for the reader) provide a flag kvalidatecontinueonerrorflag provide getvalidateflags() and setvalidateflags() for access to flags_ member if kvalidatecontinueonerrorflag set, do not set the valid_ member and thus allow the validator to continue do not change macro rapidjson_invalid_keyword_return - it still always returns false (see note) change isvalid() to return false if kvalidatecontinueonerrorflag set and the error_ object is not empty change getinvalidschemakeyword() and getinvalidschemacode() similarly at various places ensure that internal variables are in a correct state, so that continuing after an error is safe allow sub-validators to inherit the setting of kvalidatecontinueonerrorflag force sub-validators for oneof, anyof, allof, not, dependencies to not inherit kvalidatecontinueonerrorflag add reseterror() to allow errors to be reset (useful for incremental parsing) in schematest.h: add tests to exercise the validator when kvalidatecontinueonerrorflag set add tests to specifically exercise that validator internal variables are correctly set after an error change validate and invalidate macros in bin folder add new unittestschema folder containing new schemas for tests notes: to allow continuing after an error, i considered changing macro rapidjson_invalid_keyword_return so that it did not return false if kvalidatecontinueonerrorflag set, but instead continued. i coded a prototype, but it meant that unnecessary and unsafe processing continued (eg, creating sub-validators when type wrong). the change to allof error reporting. this was also made to aid the user in locating the failure, but is a change in behaviour. we could control this via a validation flag if necessary. </desc> <cmt> pr for commits 2021/01/12 </cmt> <cmt> code and tests </cmt>",fixes for issues #1835 & #1836 - multiple validation failures and readable validation messages
2198,<desc> i hereby agree to the terms of the cla available at:  fix crash in generaterandom with nested types. fixes #10583. </desc> <cmt> try fix header for generaterandom. </cmt> <cmt> added test. </cmt> <iss> column with array type is not represented by columnarray column: fixedstring(size = 100000). </iss>,fix generate random with nested
2199,"<desc> no need to process transactions from accept_transaction next as the transactions are signaled via transaction_ack and processed there. see net_plugin_impl::transaction_ack. no need to update cached transactions block_num if they are expired as they will be purged from the local cache on next cache purge and we should not get them again from the network. add log of accepted connections. when receiving a go_away message, do not attempt to reconnect immediately. this restores old net_plugin behavior for go_away messages. </desc> <cmt> do not reconnect immediately if sent a go_away message. </cmt> <cmt> no need to process accept_transaction next as it comes through transaction_ack </cmt> <cmt> remove commented out uneeded code </cmt> <cmt> add back in correct trx_in_progress_size reduction </cmt> <cmt> change accepted log level to info from debug </cmt>",remove redundant work from net plugin
2200,<desc> this pull request fixes the windows 10 uwp build by adding the missing external/clipper files and removing some obsolete files from the solution.. </desc> <cmt> added missing external/clipper files. removed obsolete files </cmt> <cmt> moved clipper files to external/clipper filter in vs solution </cmt>,fix windows 10 uwp build by adding missing external/clipper files
2201,"<desc> make lightstepsink to send gprc requests to lightstep collectors. not for this iteration 2) right now we make grpc call only when buffer is full, for the first iteration i'd like to keep it this way, but we might need flush thread to flush traces for low rps services </desc> <cmt> replace the json-generated span with a proto </cmt> <cmt> supply the runtime random generator. generate lightste::collector::reportrequest. comments. </cmt> <cmt> fix format for existing code. </cmt> <cmt> make changes. </cmt> <cmt> make existing code to compile with lightstep. </cmt> <cmt> move recorder to header, move ordash to stringutil. </cmt> <cmt> move things around. </cmt> <cmt> temp changes. </cmt> <cmt> add grpc/utility </cmt> <cmt> move to utility class. </cmt> <cmt> conflicts: </cmt> <cmt> source/common/cmakelists.txt </cmt> <cmt> source/common/tracing/http_tracer_impl.cc </cmt> <cmt> async rpc client. </cmt> <cmt> tmp </cmt> <cmt> make envoy built. </cmt> <cmt> few refinements. </cmt>",lightstep gprc generation for tracing
2202,"<desc> we always run that pass when optimizing, but normally do not when not optimizing. in standalone mode, though, an unnecessary import may make the wasm not standalone and so not runnable in wasmer/wasmtime/etc. so in that mode, it's best to run it, to avoid a silly import breaking the wasm. a concrete example of when this is needed is that in hello world with iostreams we end up with unnecessary imports of atexit (we will need to fix that eventually, but it's only needed when exit_runtime is flipped by the user, as the default ignores atexits). </desc> <cmt> st2 </cmt>",always run --remove-unused-module-elements when standalone_wasm
2203,<desc> what do these changes do? currently resource variables go undetected by the tensorflowvariables since they do not use the same ops for reading values. this change should fix this until a more robust solution is implemented. still missing: test to make sure resource variables are found in simple case test to make sure resource variables are found in case with control dependencies to check that the ops names don't differ #4437 </desc> <cmt> adding support for resource variables </cmt> <cmt> currently resource variable go undetected by the tensorflowvariables since they do not use the same ops for reading values. this change should fix this until a more robust solution is implemented. </cmt>,add support for tensorflow resource variables
2204,"<desc> in #10676 we renamed the internal subtopology class that implemented the topologydescription.subtopology interface. by mistake, we also renamed the interface itself, which is a public api. this wasn't really the intended point of that pr, so rather than do a retroactive kip, let's just reverse the renaming. </desc> <cmt> undo renaming </cmt> <cmt> qualify public interface </cmt>",undo renaming of public part of subtopology api
2205,"<desc> issue: #6359 in appcomponent, i used the changed detector ref retrieved from the child component's injector (componentref.injector.get(changedetectorref)), rather than the one available as a property on the component ref object (componentref.changedetectorref), as the latter does not work. after the properties are updated, i mark the child component for checking (childchangedetectorref.markforcheck()), but i call change detection from the appcomponent itself (this.changedetectorref.detectchanges()) to ensure that any properties using @hostbinding are also updated. i don't think so, unless we there is an easy way to produce screenshots after knob interaction. yes, included in this pr. no. </desc> <cmt> merge latest </cmt> <cmt> fix change detection to support onpush </cmt> <cmt> fix issue reference </cmt>",support onpush change detection for class-specified components (to allow use of knobs)
2206,"<desc> dateformatter.parse() timeout because of its o(n^2) time complexity the issue is in  it shows timeout (exceeds 60 secs). this is because dateformatter.parse() is costing o(n^2) time. the original implementation uses ""string.replace"" to generate a new string and to collect specifiers in while(regex_search) loop. however, the new string is completely unnecessary and will never be used after this function call. each iteration in the loop, the regex needs to search for the next matched string from the beginning. this causes it to be o(n^2). my implementation is to loop on suffix. in each iteration, set suffix=matched.suffix() and continue searching from the end of the matched string. so when collecting specifiers, we need to use different indices there to make sure they still point to the same positions in the string after being formatted. after this, the timeout test case passed. the running time of 400 layers cascading which cost 45 seconds in my local machine in the past, now can finish in around 300ms. the failed, timeout(exceeds 61s) test case now can pass in 525ms. besides, i added a new unit test against a long, messy string in utility_test.cc. i also added the timeout test case to the corresponding corpus folder. low passed all the following tests: //test/common/router:header_parser_fuzz_test //test/common/router:header_formatter_test //test/common/common:utility_fuzz_test //test/common/common:utility_test added a new unit test against long, messy string in utility_test.cc. / / </desc> <cmt> added fuzz-test and the corresponding corpus for function getsha256digest() which is in: /source/extensions/common/crypto/utility_impl.cc </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> keep master branch up to date </cmt> <cmt> dateformatter.parse() timeout because of its o(n^2) time complexity </cmt> <cmt> the issue is in </cmt> <cmt>  </cmt> <cmt> it shows timeout (exceeds 60 secs). </cmt> <cmt> this is because dateformatter.parse() is costing o(n^2) time. the original implementation uses ""string.replace"" to generate a new string and to collect specifiers in while(regex_search) loop. </cmt> <cmt> however, the new string is completely unnecessary and will never not used after this function call. each iteration in the loop, the regex needs to search for the next matched string from the beginning. this causes it to be o(n^2). </cmt> <cmt> my implementation is to loop on suffix. in each iteration, set suffix=matched.suffix() and continue searching from the end of the matched string. so when collecting specifiers, we need to use different indices there to make sure they still point to the same positions in the string after being formatted. </cmt> <cmt> after this,  the timeout test case passed. the running time of 400 layers cascading which cost 45 seconds in my local machine in the past, now can finish in around 300ms. the failed, timeout(exceeds 61s) test case now can pass in 525ms. </cmt> <cmt> besides, i added a new unit test against long, messy string in utility_test.cc. </cmt> <cmt> fixed style issues </cmt>",optimized dateformatter.parse() to o(n)
2207,"<desc> @marshallofsound and i are working to wrap up the electron.d.ts effort. the last (known) holdout is the webview-tag doc, which has some unique qualities like its name and the fact that it has attributes. this pr contains fixes to the webview api doc, as well as some fixes for other issues found by the linter along the way. </desc> <cmt> denote webview process so linter will recognize it as an api </cmt> <cmt> fix indentation of app.setloginitemsettings arguments </cmt> <cmt> document arguments for webview methods </cmt>",fix api docs for webview tag
2208,"<desc> two new features for github oauth. based on accounts config pass in allow_signup param on the initial request to prevent sign ups on github side if the user does not have an account already. after data about the user is retrieved get more of it into servicedata so that they are available to the app. we will receive the data anyway, so might as well use it. </desc> <cmt> github save more data retrieved from github </cmt> <cmt> add allow signup option to github oauth </cmt>",github oauth allow_signup & more data returned
2209,<desc> for #6869. </desc> <cmt> refactor mergedencryptcolumnsmergedresulttest </cmt> <cmt> use static import with mockito.mock </cmt> <cmt> use static import with mockito.returns_deep_stubs </cmt> <cmt> use static import with mockito.when </cmt> <cmt> remove useless mock on mergedencryptcolumnsmergedresulttest </cmt> <cmt> add mockeddatasource </cmt> <cmt> use mockeddatasource instead of h2 data source in spring namespace test cases </cmt> <cmt> use mockeddatasource instead of h2 data source in spring namespace test cases </cmt> <cmt> move encrypt spring namespace to encrypt module </cmt> <cmt> refactor encryptspringnamespacetest </cmt> <cmt> move master-slave spring namespace test to current module </cmt> <cmt> remove useless abstractspringjunittest </cmt> <cmt> move shadow spring namespace test to correct module </cmt> <cmt> remove useless xml </cmt> <cmt> move spring sharding test into correct module </cmt> <cmt> revise springnamespacetest </cmt> <cmt> update encryptspringnamespacetest </cmt> <cmt> update masterslavespringnamespacetest </cmt> <cmt> update shadowspringnamespacetest </cmt>,move spring namespace' test cases to correct modules
2210,"<desc> this is a cleanup of the wrappable class, so: there is no getobjecttemplatebuilder, all classes now use buildprototype; developers no longer need to cache the object template themselves; the creation of js object is now in wrappable's constructor, instead of lazily initialized in getwrapper; </desc> <cmt> make wrappable a template class </cmt> <cmt> remove the isolate parameter of getwrapper </cmt> <cmt> remove unneeded cleanup code </cmt>",clean up the wrappable class
2211,"<desc> this is a backport of #12257 and #12279 to swift-4.0-branch to more-accurately gather stats there (in particular: dodge a data-loss issue when writing stats files to deeply-nested directories). rdar://34818636 </desc> <cmt> [stats] fix typo. </cmt> <cmt> [stats] only use input filename, not mangled path, in stats file name. </cmt> <cmt> this was causing cases of very long input pathnames to be mangled into </cmt> <cmt> stats filenames greater than 255 characters long, which in turn meant </cmt> <cmt> stats files were not being written in some cases. </cmt> <cmt> [stats] add a test for long input-path bug (0e5b982d) </cmt>",rdar 34818636 backport pr 12257 stats output dir filename issues to swift 4.0 branch
2212,"<desc> due to ray limitations, we cannot create references to portions of an existing ray object with zero-copy semantics. hence, in dataset we have to store arrow tables as top-level ray objects. this means we have to add a wrapper class to access different block types in a uniform way. after this pr, calls to ds.to_arrow() and ds.from_arrow() are zero copy. possible design alternatives: rename block to something like blockdata (can still do this in the future, but didn't do this in this pr since it changes a lot of code) require all block accesses to be done via static methods (e.g., block.num_rows(block_data). this is a bit clunky and potentially slower since we have check the python type of the data each time. support zero-copy sub-object references in ray. closes #17186 related issue oap-project/raydp#166 </desc> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> wip </cmt> <iss> [data] store pyarrow.table directly as a block instead of wrapping in arrowblock </iss>",enable zero-copy access to underlying arrow tables
2213,"<desc> closes #82956 closes #84659 closes #86530 closes #86535 there is also a random test in here about array repeat expressions that i already had on this branch but it seems to fit the theme of this pr so kept it... r? @lcnr </desc> <cmt> e-not-needs-test </cmt> <cmt> tidy </cmt> <iss> ice using `const_generics` feature </iss> <iss> trait with a lifetime parameter, associated constant, and an associated type can trigger an ice </iss> <iss> const generics panic </iss> <iss> no errors encountered even though `delay_span_bug` issued', compiler/rustc_errors/src/lib.rs:1023:13 </iss>",add tests for some const generics issues
2214,"<desc> see the following links in the node api docs showing the missing optional parameters... crypto.pbkdf2 crypto.pbkdf2sync </desc> <cmt> added optional parameters for the crypto.pbkdf2* functions </cmt> <cmt> fixing typescript optional parameter issue, all tests pass </cmt>",added optional parameters for the node crypto.pbkdf2* functions
2215,"<desc> internal fields model snapshot id, established model memory and job version should not be settable via a request to anomaly_detectors/job_id/_update partial backport of #30512 </desc> <cmt> add jobversion to update </cmt> <cmt> hide internal fields from the rest request parser </cmt> <cmt> change yml tests to not use secret job update settings </cmt> <cmt> use the revert model snapshot api instead </cmt>",hide internal job update options from the rest api
2216,"<desc> don't nack empty updates or those where expected resources are not present.  instead, report an error to watchers for missing resources. implement removing deleted resources from the cache. don't cache cds resources that we didn't ask for. properly unsubscribe from rds resources as required by lds update. when unsubscribing from one resource and then subscribing to another, combine the xds requests. fix a potential crash in the xds lb policy when trying to update a locality whose priority is not in the current update. </desc> <cmt> add test for changing clusters </cmt> <cmt> change logic to send empty response when resources go away </cmt> <cmt> don't nack empty updates. </cmt>","don't nack empty updates, remove deleted resources from cache, and other fixes"
2217,"<desc> upgrade the yubihsm wallet to use libyubihsm2. this brings about two user facing features: support for newly shipping yubihsm 2.1 firmware support for talking to a yubihsm directly through usb instead of through the connector (use yubihsm-url = yhusb://) libyubihsm2 is open source so now we build and statically link to the library internal to the eosio project. this makes using yubihsm for users much easier as they don't have to chase down yubico's installer and dump the .sos in the correct directory (correct can be tricky here). however, this also makes eosio have three new dependencies: libusb, libcurl, and pkg-config. all three of these are pretty standard fare so i don't feel too guilty adding them as dependencies. ci is currently failing because of the inability to have libusb available in the test instance (i link to it dynamically since i consider it much like other system level packages like openssl) </desc> <cmt> upgrade to libyubihsm 2 and link directly with it </cmt> <cmt> add build deps and packages deps for libusb/libcurl/pkgconfig </cmt> <cmt> don't build libyubihsm with lto </cmt> <cmt> lto objects confuse some of the older platforms/compilers we target </cmt> <cmt> handle libusb better in macos build script </cmt> <cmt> something really wonky here; it's like the script tries to unlink everything it installs?? get this working for now with just the libusb that i added </cmt> <cmt> add installation of libyubihsm license </cmt> <cmt> block out libyubihsm's add_test()s </cmt> <cmt> exclude_from_all blocks out all non-dependant targets but this doesn't prevent add_test() from being called on the now non-existant targets. i tried several approaches to remove these tests (without changing upstream cmake) and this approach was the best when factoring in that it's documented and simple </cmt>",libyubihsm2 upgrade & yubihsm 2.1 support
2218,"<desc> this pr adds the capability for async methods in serve actors as well as preliminary support for multiple methods. class mybackend: async __call__(self, flask_request): def other_method(self, _): pass the other_method currently can only be invoked internally by constructing call_method=""other_method"" to the query parameter. it is planned for the future to expose this through serve.route decorator. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> allow task runner to run async method </cmt> <cmt> allow multiple methods endpoint </cmt> <cmt> fix a batching bug </cmt>","add async, multi methods support for serve actors"
2219,"<desc> if a semantic update finishes fast enough, the token snapshot may be identical to the edit snapshot, but because of getbufferforsnapshot consolidating edits into a new buffer, we were not detecting that case properly, and it could cause an assertion failure (or potentially incorrect range shifting in a release build). this would have reproduced very rarely in practice, but i can reproduce it by putting sleep(2) calls right before we read the semantic info in open and edit requests. fix sourcekit-test and unit tests for the (rare) case where an open or edit already has updated semantic info. fix editing test previously disabled so that semantic tokens will be the same regardleess of whether they come from range-shifting or from a full semantic update. </desc> <cmt> [test] fix annotation test to have same behaviour before and after update </cmt> <cmt> the goal of the test is to test the behaviour when the edit is </cmt> <cmt> range-shifted, but in the (rare) case where the document update happens </cmt> <cmt> before the edit finishes, we need the ranges to be the same. in </cmt> <cmt> particular, using separate statements ensures that the tokens not </cmt> <cmt> touched by the edit are not affected by the edit. </cmt> <cmt> re-enable the test disabled on asan, since this seems to be the </cmt> <cmt> underlying issue. </cmt> <cmt> rdar://65934938 </cmt> <cmt> [sourcekitd] fix range shifting ""race"" with a fast semantic update </cmt> <cmt> if a semantic update finishes fast enough, the token snapshot may be </cmt> <cmt> identical to the edit snapshot, but because of getbufferforsnapshot </cmt> <cmt> consolidating edits into a new buffer, we were not detecting that case </cmt> <cmt> properly, and it could cause an assertion failure (or potentially </cmt> <cmt> incorrect range shifting in a release build). this would have reproduced </cmt> <cmt> very rarely in practice, but i can reproduce it by putting sleep(2) </cmt> <cmt> calls right before we read the semantic info in open and edit requests. </cmt> <cmt> incidentally, fix sourcekit-test and unit tests for the (rare) case </cmt> <cmt> where an open or edit already has updated semantic info. </cmt>",fix range shifting vs semantic update timing issues
2220,"<desc> @marcoabreu @kellensunderland @chancebair @gautamkmr @bhavinthaker this pr adds new dockerfiles for python that are currently being used to release docker images to dockerhub after each mxnet release. these dockerfiles are built on the mxnet pip binaries instead of 'build from source' as in the existing dockerfiles. this makes the docker files easier to build and keeps the docker & pip binaries consistent. i have also added a script that can be used to build all 10 different images, run 3 sanity tests and upload them to dockerhub (credentials need to be provided) with one command. please refer to the readme added for more details. docker images are uploaded here:  please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change 4 dockerfiles to build mxnet python for the latest released version. script to automate build, test and release of docker images to dockerhub. a test script that makes sure that the installed version of mxnet matches the requested version. </desc> <cmt> initial commit for docker automation python </cmt> <cmt> fixes </cmt> <cmt> change dir for tests </cmt> <cmt> fix more issues </cmt> <cmt> fix docker tag command </cmt> <cmt> cosmetic changes </cmt> <cmt> update readme </cmt> <cmt> update test to fail on version mismatch </cmt> <cmt> remove debug mode </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme </cmt>",python dockerfiles built on pip binaries and build/release script
2221,"<desc> since most browsers no longer allow making async requests from a page loaded from file://, we now need a proper http server to load the exported html5 game. this should also allow us to get the debugger to work over a websocket connection. includes a small refactor of editorexportplatform/editorrunnative interaction. fix bug where editor theme was not accessible via singleton. closes #16245 . </desc> <cmt> fix editornode.get_editor_theme </cmt> <cmt> editornode was not correctly setting the class memeber when creating the </cmt> <cmt> theme, using a local variable instead. </cmt> <cmt> theme is now created before registering exporters (as they might need it). </cmt> <cmt> improve editorexportplatform interface. </cmt> <cmt> convert all get_device* methods to get_option* and normalize their usage </cmt> <cmt> as icon, label, tooltip. </cmt> <cmt> implement http server for html5 export </cmt> <cmt> since most browsers no longer allow making async requests from a page </cmt> <cmt> loaded from file://, we now need a proper http server to load the </cmt> <cmt> exported html5 game. </cmt> <cmt> this should also allow us to get the debugger to work over a websocket </cmt> <cmt> connection. </cmt> <iss> add simple http server for html5 debugging </iss>","implement http server for html5 ""run"" export"
2222,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  pkg.go.dev:  goreportcard.com:  coverage service link (codecov, coveralls, gocover etc.)  very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> initial commit </cmt> <cmt> change remote url </cmt>","add lets-go, a library with various aws and rest utility packages."
2223,"<desc> this is of course still wrong regarding #5662, but at least brings it in line with the other output formats (and adds a test) import {$679c7b63be557d242f596b1b4cbcc6a9$init} from ""./a.js""; console.log(""b"", $679c7b63be557d242f596b1b4cbcc6a9$$interop$default); after: function $parcel$interopdefault(a) { return a && a.__esmodule ? a.default : a; } import {$679c7b63be557d242f596b1b4cbcc6a9$init} from ""./a.js""; var $679c7b63be557d242f596b1b4cbcc6a9$$interop$default = $parcel$interopdefault($679c7b63be557d242f596b1b4cbcc6a9$init()); console.log(""b"", $679c7b63be557d242f596b1b4cbcc6a9$$interop$default); </desc> <cmt> add test </cmt> <cmt> fix </cmt>",add interop declaration for esm cross bundle imports
2224,<desc> only 567 orgs (<.1% of all sentry's orgs) have more than 50 projects which led to the decision to paginate this settings -> projects page ( before after closes sen-1201 </desc> <cmt> paginated and grid emotion changes </cmt> <cmt> snapshot? </cmt> <cmt> changed to flex </cmt> <cmt> snap </cmt>,change projects settings pagination to 50 items and remove grid emotion
2225,"<desc> what do these changes do? rllib.models.lstm is currently using tf.nn.rnn_cell.basiclstmcell. however, as pointed out in the docs, basiclstmcell will be deprecated from tensorflow 1.13 and should be replaced with tf.nn.rnn_cell.lstmcell. no need to change the signature. tested on cartpolestatelessenv and it works: none linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fixed bug in dirichlet (#4440) </cmt> <cmt> update </cmt> <cmt> replaced deprecated rnn_cell.basiclstmcell with rnn_cell.lstmcell </cmt>",replaced discontinued rnn_cell.basiclstmcell with rnn_cell.lstmcell
2226,<desc> i have created some custom keymaps for the iris and planck keyboard for my personal sets. </desc> <cmt> inital layout </cmt> <cmt> fix the backspace </cmt> <cmt> add a number pad </cmt> <cmt> move the backlight to the adjust layer; move ctrl and delete. </cmt> <cmt> rodhaene/keymap </cmt> <cmt> update from main repo </cmt> <cmt> add initial files for custom keymap </cmt> <cmt> light keymap mod </cmt> <cmt> rodhaene/iris keymap </cmt>,merge in some custom keymaps from forked repository
2227,"<desc> hi, minggo and owen. please review these commits for tizen support. thanks a lot. </desc> <cmt> sync with original branch </cmt> <cmt> support audio interruption and resume callback when change earphone status. </cmt> <cmt> refactor keyevent callback and add makecurrent for compatible with different binary. </cmt> <cmt> enable tizen indicator. </cmt> <cmt> remove the unnecessary evasobject in the window and refactor the function for glview mode. </cmt> <cmt> fix the compatible issue between tizen 2.3 and 2.4. </cmt> <cmt> fix the wrong directory of script resources for helllua template project. </cmt> <cmt> create performance-test project for tizen platform. </cmt>",some bug-fix and quality assurance for tizen support.
2228,"<desc> built on #6070 </desc> <cmt> add a failing test due to a head of line blocking bug in the server </cmt> <cmt> initial interface rework to allow knowing whether to pull payload at registration, not at request time </cmt> <cmt> merge github.com:grpc/grpc into head-of-line-blocking </cmt> <cmt> add missing line </cmt> <cmt> fix registration in test </cmt> <cmt> fix head-of-line blocking in server </cmt> <cmt> fix codegen </cmt> <cmt> introduce machinery to allow tests to register plugins </cmt> <cmt> add test to verify bad behavior </cmt> <cmt> add a test demonstrating forced closure of a stream, and make it work </cmt>","add a test for forced stream closure on the server, and make it work"
2229,"<desc> the encrypted repository is usable to the extent that the feature can greatly benefit from testing as part of snapshot builds on cloud. to get an impression of how to use this feature see the description of the last pr merged in the feature branch  #53352 (comment) . after this pr is merged to the feature branch, my plan is to raise the pr that merges the feature branch to master, without asking for any other reviews. </desc> <cmt> feature flag to register the new encrypted repository type </cmt> <cmt> reverse condition to have a friendlier diff </cmt> <cmt> spotless and invert condition </cmt>",introduce the encrypted repository behind a feature flag
2230,<desc> sil: make adjustfunction type of closures parameterized on whether we use guaranteed closures this is going to go away once we change the default to guaranteed closures. silcombine: fix @callee_guaranteed combine of try_apply i missed another place where we were releasing the context. sr-5441 rdar://33255593 </desc> <cmt> sil: make adjustfunction type of closures parameterized on whether we use </cmt> <cmt> guaranteed closures </cmt> <cmt> this is going to go away once we change the default to guaranteed </cmt> <cmt> closures. </cmt> <cmt> sr-5441 </cmt> <cmt> rdar://33255593 </cmt> <cmt> silcombine: fix @callee_guaranteed combine of try_apply </cmt> <cmt> i missed another place where we were releasing the context. </cmt> <cmt> sr-5441 </cmt> <cmt> rdar://33255593 </cmt>,silcombine and sil adjustfunctiontype fix for @callee_guaranteed
2231,<desc> solve dts==0 bug when demux mpegts if (dts == 0) {dts = pts} solve many aac packed in a large mpegts(2930bytes) demux mpegts and recover the dts. </desc> <cmt> solve dts==0 bugs; solve large aac 2930bytes timestamp bugs </cmt> <cmt> solve dts==0 bugs; solve large aac 2930bytes timestamp bugs </cmt>,solve dts==0 bug and solve many aac packed in a large mpegts(2930bytes)
2232,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. i fixed some english errors and i added more details about video challenges. </desc> <cmt> upade fork </cmt> <cmt> fix some errors </cmt>",fixed some orthographic errors and improvements
2233,"<desc> np.ndarray.dumps and np.ndarray.dump will now let the user specify a pickle protocol. pickling tests now loop over all possible protocols. part of #12011, that implements pickle protocol 5 for numpy arrays (this pr is currently being broken out in multiple shorter prs for simplification and clarity purposes). pinging @ogrisel @mattip </desc> <cmt> added protocol kw to c implementations of array_dump[s] </cmt> <cmt> updated documentation for array_dump[s] </cmt> <cmt> loop over protocol for pickle tests </cmt>",update pickling tests by making them loop over all protocols
2234,"<desc> fixes #12386. often the max_features parameter of a bagging estimator is set as a float, to represent a fraction of the number of features to use. to convert to an integer, this equation is currently used: max_features = int(self.max_features * self.n_features_) however, this often leads to a valueerror if the result is rounded down to zero. this may occur if the number of features is often unknown (for example, due to hyperparameter tuning in an earlier stage). this pr ensures a minimum of one feature is kept in this situation: max_features = max(1, int(self.max_features * self.n_features_) ) would be grateful to check that unit test is implemented in the right place in an appropriate manner. i've tried to be consistent with other tests. i've tried to find the cleanest implementation that still raises a valueerror if max_features is negative, zero, too large, or not an int nor float. </desc> <cmt> added constraint max_features at least one </cmt> <cmt> added non-regression test </cmt> <iss> max_features often rounded down to zero, leading to valueerror </iss>",fix  keep at least one feature when max_features is small fraction
2235,"<desc> fixes #1137 this is not location.reload(), but reload the internal next.js state. </desc> <cmt> add support to reload the page when ask to change the same url. </cmt> <cmt> do not run change() in the initial page load. </cmt> <cmt> add integration tests. </cmt>",reload the page if asked to change the current url
2236,<desc> fixes #15845 alternative to #15885 implements @jnothman's suggestion: #15845 (comment) this pr adds attributes back in as an optional keyword to check_is_fitted. </desc> <cmt> enh adds attributes back to check_is_fitted </cmt> <cmt> doc updates docstring </cmt> <iss> check_is_fitted has false positives on custom subclasses with private attributes </iss>,bug adds attributes back to check_is_fitted
2237,"<desc> convolution2d only has border_mode='full' or 'valid' and the image size changes upon convolution. i added a layer that allows to shrink the image after using convolution2d with border_mode='full' back to the original size (before the convolution2d) example, assume images are 28x28 as in the mnist example model.add(convolution2d(32, 1, 3, 3, border_mode='full'))   # images are now 30x30 model.add(activation('relu')) model.add(cropimage(1))                                     # images are now 28x28 thanks for a great package </desc> <cmt> added cropimage layer. shrinks images in a convolution layer. when </cmt> <cmt> applying a convolution2d with border_mode='full', images will grow in </cmt> <cmt> size, this layer allows to shrink them back to its original size (or any </cmt> <cmt> other size) </cmt>",cropimages to maintain sizes in cnn
2238,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. release url:  beta url: </desc> <cmt> [office-js-preview] (excel) pulling latest type definitions from cdn </cmt> <cmt> [office-js] (excel) pulling latest type definitions from cdn </cmt>,pulling latest excel type definitions from cdn
2239,"<desc> for...of introduces a dependency on symbol and symbol.iterator (and bloated code too, with try / catch in a potentially very hot dev path). we accidentally merged that in #10783. i'm adding this rule so we can be more vigilant. you can ignore it for build and other scripts but please don't ignore it in the source. </desc> <cmt> add no-for-of lint rule </cmt> <cmt> ignore legit use cases of for..of </cmt> <cmt> rewrite for..of in source code </cmt>","disable for...of by default, rewrite cases where it matters"
2240,"<desc> libweb: add pc css unit libgfx+fonteditor+fonts: add ""mean line"" value to all fonts the main inspiration behind this was to have a correct ex css unit. the mean line is based off what it shows in the css values and units level 4 specification, section 6.1.1. </desc> <cmt> libweb: add pc css unit </cmt> <cmt> libgfx+fonteditor+fonts: add ""mean line"" value to all fonts </cmt> <cmt> the main inspiration behind this was to have a correct ex css unit. </cmt> <cmt> the mean line is based off what it shows in the css values and units </cmt> <cmt> level 4 specification, section 6.1.1. </cmt> <cmt>  </cmt>",add pc css unit and get a correct ex unit
2241,"<desc> this change address two issues: #12372 view columns not visible with 'no schema binding' views on redshift connection #12396 dbeaver 21.0.4: not all columns showing in db navigation pane/generated sql - view it address a few aspects, first it will allow the column to display in the navigator and also allow the columns to show in 'generate sql' functions. </desc> <cmt> add datatype aliases for time and timestamp </cmt> <cmt> update check for no binding view to be case insensitive </cmt>",redshift missing columns when view is configured as a non-binding.
2242,"<desc> graylog uses layer 4 loadbalancers for tcp/udp traffic ingress, however there was no way to specify the externaltrafficpolicy in order to preserve the client ip address. my changes allow overrides to local, but default to cluster @kongz  - obligatory mention :) hi! dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> adding the ability to specify externaltrafficpolicy, and thus preserve client ip addresses </cmt> <cmt> updated readme </cmt>",adding the ability to specify externaltrafficpolicy for loadbalancer services
2243,<desc> i added examples that make use of the args form ( i didn't know about this language feature so for me it was quite a search before i found it out. it would be nice to add it to the examples of these modules because you would probably use this language feature faster with these modules than others. </desc> <cmt> added examples to the shell module </cmt> <cmt> added examples to the command module </cmt>,add examples for shell and command modules.
2244,"<desc> kevaa/decompress exports a function with 4 overloads: decompress (input, output, opts) decompress (input, output) decompress (input, opts) decompress (input) prior definition did not support third and fourth overload patterns. this pull request corrects that. line 41 provides for undefined options function extractfile is invoked from decompress on line 95  line 81 allows for decompressoptions sent as second argument instead of third </desc> <cmt> 'output' argument of decompress function is overloaded to support undefined, string, or decompressoptions </cmt> <cmt> updated definitions by tag </cmt> <cmt> added additional tests for output argument overload alternatives </cmt> <cmt> fixed string formatting per lint recommendations </cmt>",decompress function should have four overloads
2245,"<desc> this fixes a pathological-sounding-but-it-happened-to-us scenario that caused incorrect template digests for */* requests that render non-html (json, in our case) templates. the scene looks something like this: an appended view path: append_view_path(rails.root.join(""app/views/api"")) partials in this path with the same logical path as partials in app/views, but for different formats: app/views/api/todos/_todo.json.jbuilder and app/views/todos/_todo.html.erb, both ""logically"" known as todos/todo. both of these partials have cache fragments. a controller action (schedules#show) with a corresponding json template (show.json.jbuilder) that in turn renders a collection of partials: json.todos @todos, partial: 'todos/todo', as: :todo. a client-side fetch requests to this action that doesn't set an accept header so it defaults to */*. the json response is correctly returned, but the template digest it uses for caching is computed using the html templates. altering _todo.json.jbuilder does not invalidate its cache, but altering _todo.html.erb does. we worked around the issue by adding an accept: application/json header. adding a .json format to the url would have worked around it too. here are the new tests failing without the changes to actionview::digestor: $ rake test test=test/template/digestor_test.rb run options: --seed 2948 # running: ........f.............f............... finished in 5.274653s, 7.2043 runs/s, 10.4272 assertions/s. 1) failure: templatedigestortest#test_template_formats_of_nested_deps_with_non_default_rendered_format [/users/javan/projects/rails/actionview/test/template/digestor_test.rb:165]: expected: [:json] actual: [:json, :html] 2) failure: templatedigestortest#test_different_formats_with_same_logical_template_names_results_in_different_digests [/users/javan/projects/rails/actionview/test/template/digestor_test.rb:287]: expected ""18824a8cf013bb976bc39b5809a262c4"" to not be equal to ""18824a8cf013bb976bc39b5809a262c4"". 38 runs, 55 assertions, 2 failures, 0 errors, 0 skips all green with the changes. / </desc> <cmt> fix digesting templates with identical logical names when requesting a format other than the first default </cmt> <cmt> explicity find with the rendered format to handle searching multiple view paths correctly </cmt> <cmt> fix finding templates for digesting for */* requests that render a non-default (html) template </cmt> <cmt> move and rename test </cmt> <cmt> add test for nested html dependencies with same logical name as templates for other formats </cmt>",fix digesting non-html templates with non-unique logical names
2246,"<desc> cherry pick the following fixes to 0.65: i18n.allowrtl should default to true (#7840) better reporting of failures to load the bundle file (#8018) intermittent deadlock when reloading multiple times rapidly (#8026) remove javascriptmainmodulename and debughost (#8027) turbomodules might be kept alive by rnh when instance is shutdown (#8035) fix crash when adding a reactrootview while reloading a reacthost (#8042) microsoft reviewers: open in codeflow </desc> <cmt> i18n.allowrtl should default to true (#7840) </cmt> <cmt> * allowrtl should default to true </cmt> <cmt> * change files </cmt> <cmt> better reporting of failures to load the bundle file (#8018) </cmt> <cmt> * better reporting of failures to load the bundle file </cmt> <cmt> * change files </cmt> <cmt> * remove extra call to abandonjscallqueue, since onerror will do it. </cmt> <cmt> * format </cmt> <cmt> * codereview feedback </cmt> <cmt> intermittent deadlock when reloading multiple times rapidly (#8026) </cmt> <cmt> * intermittent deadlock when reloading multiple times rapidly </cmt> <cmt> * format </cmt> <cmt> remove javascriptmainmodulename and debughost (#8027) </cmt> <cmt> * remove javascriptmainmodulename and debughost </cmt> <cmt> * change files </cmt> <cmt> * update vnext/microsoft.reactnative/reactinstancesettings.idl </cmt> <cmt> turbomodules might be kept alive by rnh when instance is shutdown (#8035) </cmt> <cmt> * turbomodules might be kept alive by rnh when instance is shutdown </cmt> <cmt> * change files </cmt> <cmt> fix crash when adding a reactrootview while reloading a reacthost (#8042) </cmt> <cmt> * fix crash when adding a reactrootview while reloading a reacthost </cmt> <cmt> * change files </cmt> <cmt> * ensure we always reset unloading flag </cmt>",cherry pick various high impact fixes
2247,<desc> adds generic type for relayprops to type variables. adds relayprops interface that can be used to fully abstract relay prop injection. interface iprops extends relay.relayprops<componentrelayvariables> { // everything but no relay. </desc> <cmt> (relay-classic) adds relayprops variables typing </cmt> <cmt> (react-relay) add relayprops interface </cmt> <cmt> (react-relay) fix lint </cmt> <cmt> (react-relay) add maintainer </cmt>,react-relay - improve props and relay variables typing
2248,"<desc> introduce and use new apis to perform lookups of existing pre-specializations in a more light-weight way. don't serialize and don't even try to read bodies of pre-specialized functions. just check if they exist. </desc> <cmt> add apis to check if a function with a given name exists and to invalidate a sil linker entry for a function. </cmt> <cmt> these apis are useful e.g. for quickly finding pre-specialisations by their names. </cmt> <cmt> the existence check is very light-weight and does not try to deserialize bodies of sil functions. </cmt> <cmt> serialize only declarations of pre-specializations. </cmt> <cmt> only declarations of whitelisted pre-specializations from with public linkage need </cmt> <cmt> to be serialized as they will be used by useprespecializations pass during -onone </cmt> <cmt> compilations to check for availability of concrete pre-specializations. </cmt> <cmt> the bodies of these functions are not required as they cannot be used anyways, </cmt> <cmt> because they may refer to symbols with non-public linkage. </cmt> <cmt> simplify a search for an existing generic specialization. </cmt> <cmt> use the new hasfunction api to check for existence of a specialization and clean-up the code. </cmt>",implement a more light-weight approach to perform lookups of existing pre-specializations
2249,"<desc> current behavior: we have a grace period (1s) for transient object store full errors to wait for operations like gc. however if object spilling takes long, we would run out of grace period time and raise oom immediately after spilling is done without waiting for gc. this pr added a test for this scenario, and changed the code such that the oom grace period timer only starts after spilling is done. this is related to #14788 but does not fully resolve it. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix deserializer in metrics.counter </cmt> <cmt> fix restore_spilled_objects() for external object spilling </cmt> <cmt> wip reset oom timer </cmt>",reset oom timer as objects are being spilled
2250,"<desc> checklist closing issues: #issue i wrote some lines in the radare2book the new format is similar to the older one, but all string references are offsets from the start of the string table instead of relative to where the reference lives. this change detects and reacts to this condition. depends on new test bin:  radareorg/radare2-testbins#60 </desc> <cmt> add support for modern coresymbolication elements ##bin </cmt> <cmt> add tests for new coresymbolication elements </cmt>",add support for new coresymbolication element format ##bin
2251,"<desc> this touches some delicate functions to be messing with, so i've split off the underlying logic into a function in common and added an exhaustive test. would welcome review none the less. also, i tried to test for nagative perf. there must something wrong with the test since comparing the commit after just adding a test to the baseline, shows 50% degredation in a bunch of things. as i said, i don't trust this, ideas? timeseries_asof_nan                       23.4131    15.7471 1.4868 datetimeindex_normalize                 1153.1918   774.8010 1.4884 timeseries_asof                           22.3342    14.9964 1.4893 reshape_unstack_simple                     4.8106     3.2289 1.4899 read_table_multiple_date_baseline        980.0920   657.3641 1.4909 timeseries_1min_5min_mean                  0.8087     0.5422 1.4915 timeseries_timestamp_tzinfo_cons           0.0210     0.0141 1.4922 match_strings                              0.5718     0.3817 1.4982 timeseries_large_lookup_value              0.0301     0.0201 1.4998 reindex_fillna_pad                         0.1828     0.1217 1.5018 timeseries_to_datetime_iso8601             5.6048     3.7270 1.5038 read_table_multiple_date                2169.5440  1441.5460 1.5050 reindex_daterange_pad                      0.2608     0.1731 1.5066 timeseries_1min_5min_ohlc                  0.8046     0.5331 1.5092 reindex_daterange_backfill                 0.2466     0.1634 1.5094 period_setitem                          1166.9910   772.4509 1.5108 reindex_fillna_backfill                    0.1790     0.1183 1.5130 timeseries_asof_single                     0.0656     0.0434 1.5136 append_frame_single_mixed                  2.0747     1.3697 1.5147 timeseries_slice_minutely                  0.0762     0.0501 1.5208 columns: test_name | target_duration [ms] | baseline_duration [ms] | ratio (01bc3e0 against 81169f9) - a ratio of 1.30 means the target commit is 30% slower then the baseline. closes #2347 </desc> <cmt> tst: df.pop() of non-unique column </cmt> <cmt> enh: add com.split_ranges util function </cmt> <cmt> tst: add tests for com.split_ranges() </cmt> <cmt> bug: deletion of non-unique column. closes #2347 </cmt> <cmt> tst: split_block_at() after changes </cmt> <cmt> doc: docstring of index.get_loc, clarify return type </cmt> <iss> del df[k] fails for a non-unique key </iss>",del df[k] with non-unique key
2252,<desc> i carefully read the contribution guidelines and agree to them. i created the file strings.xml in values-oc folder to be able to translate to occitan from weblate </desc> <cmt> added initial strings.xml for occitan language </cmt> <cmt> move to values-oc </cmt>,add support for occitan language
2253,"<desc> fixes two regressions that were introduced in swift 5.2: default arguments of local functions inside @inlinable functions were not serialized, which would cause a sil verifier failure if the default argument was referenced there was no enforcement that these default arguments did not reference non-public symbols, which again could cause crashes. fixes rdar://problem/62200974 / </desc> <cmt> ast: diagnose references to non-public declarations from default arguments of inlinable local functions </cmt> <cmt> part of < </cmt> <cmt> sil: serialize default arguments of inlinable local functions </cmt> <cmt> fixes < </cmt>",fix default arguments of inlinable local functions [5.3]
2254,<desc> remove the code that is not useful in the loop </desc> <cmt> remove spaces before and after the properties </cmt> <cmt> update mixall.java </cmt> <cmt> remove spaces before and after the properties </cmt> <cmt> remove spaces before and after the properties </cmt> <cmt> remove spaces before and after the properties </cmt>,[rocketmq-226]remove the code that is not useful in the loop
2255,<desc> add str->int dict in kvstore backend so that module can use the param name to perform update instead of its index @mli @piiswrong </desc> <cmt> update kvstore unit test </cmt> <cmt> update model/module.py </cmt> <cmt> fix lint </cmt>,support str key type in kvstore
2256,"<desc> change points: undo the pr #1033 set the createdependencyreducedpom to true. the code of seata-* has all be packed into the seata-all.jar, and should not be inclueded in the seata-all.pom. modify the all.xml change  the  configs of maven-javadoc-plugin in seata-all.xml </desc> <cmt> undo  pr #1033 </cmt> <cmt> undo  pr #1033 </cmt> <cmt> modify file.conf </cmt>",undo pr 1033 and adjust the maven plugin of seata-all.xml
2257,<desc> i hereby agree to the terms of the cla available at:  fix incorrect behavior when alter table ... drop part 'part_name' query removes all deduplication blocks for the whole partition. fixes #18874. </desc> <cmt> fix deduplication block names parsing </cmt> <cmt> add test </cmt> <iss> dropping of a part breaks deduplication of data blocks </iss>,fix drop part query break deduplication
2258,"<desc> hey @felixxm. this is a backport of adam's #12645. beyond being an improvement, i thought it worth doing, since i imagine it makes our lives easier backporting docs changes in the next few months. but, given the docs conf changes, i wanted to run it passed you so... </desc> <cmt> [3.0.x] prevented (and corrected) single backtick usage in docs. </cmt> <cmt> backport of 1cdfe8d91215eefaa18c398069dd9c6879a9511d from master. </cmt> <cmt> [3.0.x] corrected docs spelling of pgbouncer. </cmt> <cmt> backport of b1f88476dbd738bdcc20466efd5ffcb83ab25093 from master </cmt>",backport of #12645 to stable/3.0.x.
2259,"<desc> mainly gets rid of sign conversions, but also tidies up the surrounding area a little bit. </desc> <cmt> gl_state: get rid of mismatched sign conversions </cmt> <cmt> while we're at it, amend the loop variable type to be the same width as </cmt> <cmt> that returned by the .size() call. </cmt> <cmt> gl_state: make references const where applicable in apply() </cmt>",get rid of mismatched sign conversions in apply()
2260,"<desc> i made a brief documentation for shaders. you can preview it here (before this pr is merged):  currently contains introductory tutorials, documentation for constants.py and custom_default.yml and something about development. i will fill in the rest of the documentation later (about this summer), but i think this document is enough to be used as an introductory guide. this document is built using sphinx, applies furo theme, and is automatically deployed on github pages through github action. if i made some mistakes, please point them out. if there is a grammatical error, please also bring it up (my english is not very good). @3b1b please take a look at this documentation. i will tell you in private about how to deploy this document. </desc> <cmt> update </cmt> <cmt> set up docs </cmt> <cmt> set up action workflow to build up docs </cmt> <cmt> update structure </cmt> <cmt> fix path for sphinx-build </cmt> <cmt> fix action workflow (#5) </cmt> <cmt> set up structure </cmt> <cmt> add manimlib to path </cmt> <cmt> change theme </cmt> <cmt> create manim_example_ext </cmt> <cmt> finish development category and improve style </cmt> <cmt> finished quick start </cmt> <cmt> finish config, structure, constants and custom_default </cmt> <cmt> finish example scenes </cmt> <cmt> fix bugs and update readme </cmt> <cmt> add pycairo to env </cmt> <cmt> add icon </cmt> <cmt> update workflow </cmt>",add documentation for shaders version
2261,<desc> corrected the code style to pep8. a correction that does not affect the operation. before $pycodestyle redash/|wc -l                                                                                                                                                     181 after $pycodestyle redash/|wc -l                                                                                                                                                     111 </desc> <cmt> fix w292 no newline at end of file </cmt> <cmt> fix extra whitespace </cmt> <cmt> fix e305 expected 2 blank lines after class or function definition </cmt> <cmt> fix w391 blank line at end of file </cmt> <cmt> fix e231 missing whitespace after </cmt> <cmt> fix e303 too many blank lines </cmt> <cmt> fix e302 expected 2 blank lines </cmt> <cmt> fix e128 continuation line under-indented for visual indent </cmt>,fix according to pycodestyle format
2262,<desc> addresses #134660 creates a clearer telemetry ui to prevent misconceptions regarding telemetry re-enablement </desc> <cmt> work on improving telemetry setting description </cmt> <cmt> two options </cmt> <cmt> third option </cmt> <cmt> add old crash reporter to gettelemetrylevel </cmt> <cmt> more verbose wording + comments </cmt>,clearer settings ui for new telemetry setting
2263,"<desc> these changes fix/improve: allow to specify expandrowprops.nonexpandable when table key is of type other than number (according to docs, there is no such restriction), better type control for expandrowprops.expanded which previously was of any[] type. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add key type to expandrowprops </cmt> <cmt> add test cases for providing key type </cmt>",add type for table key to use expandrow with correct types
2264,"<desc> fixes #78. this is a resurrection of #130 with test and docs; it seems that effort stalled. i've rebased @lachenmayer's branch on top of latest master and dealt with conflicts, this should merge cleanly. most critically, it does not rely on url embedded identities (aka  thanks to @lachenmayer for the initial effort, and @mzabriskie for the lovely axios. </desc> <cmt> add http basic authentication. </cmt> <cmt> add http basic authentication for node. </cmt> <cmt> documenting the http basic auth request config </cmt> <cmt> abandoning url embedded identities for basic auth </cmt> <cmt> use an authorization header instead, which is a safer choice than url embedded identities (aka </cmt> <cmt> added documentation note about how this will overwrite any existing authorization header that the user may have set. </cmt> <cmt> [chromium128323]: </cmt> <cmt> adding tests for basic auth </cmt> <iss> support for basic authentication on xmlhttprequest.open() ? </iss>",add support for http basic auth via authorization header
2265,"<desc> the c# interpreter requires the seconds parameter to be included, so if one has a raw duration of 13:45, one must append ':00' for the constructor to recognize the duration (input[type=""time""] produces such raw durations). this pr solves that problem. </desc> <cmt> added tests for 24-hour time support. </cmt> <cmt> added 24-hour time support. </cmt> <cmt> converted to spaces </cmt> <cmt> changed tests to test greater than 24 hour timestamps </cmt> <cmt> * feature/24-hour-time: </cmt> <cmt> changed tests to test greater than 24 hour timestamps </cmt> <cmt> converted to spaces </cmt> <cmt> added 24-hour time support. </cmt> <cmt> added tests for 24-hour time support. </cmt>",support constructing durations from timestamps that do not include seconds
2266,"<desc> this pr adds selectedtextstyle and unselectedtextstyle parameters to the bottomnavigationbar class. these parameters provide two main benefits to users of bottomnavigationbar: further customization of the fonts in a bottomnavigationbar. having a generic textstyle allows for more than just fontsize to animate. for example, textstyle.fontweight or textstyle.fontstyle can animate. also, selectedtextstyle and unselectedtextstyle provide a convenient way to customize the fontfamily of the text in a bottom nav. previously, this was only possible by supplying a textstyle directly to all of the individual text widgets passed to bottomnavigationbaritem. selectedtextstyle and unselectedtextstyle parameters will allow for the textstyles to be customized in bottomnavigationbartheme, when it is created. this pr also adds selectedicontheme and unselectedicontheme. these params now make bottom navigation bars much more customizable: related issues n/a i added the following tests: selectedtextstyle and unselectedtextstyle are honored in the bottomnavigationbar. the selectedtextstyle.fontsize and unselectedtextstyle.fontsize take precedence over selectedfontsize and unselectedfontsize. the selectedtextstyle.color and unselectedtextstyle.color take precedence over selecteditemcolor and unselecteditemcolor. the selectedicontheme.color and unselectedicontheme.color take precedence over selecteditemcolor and unselecteditemcolor. the selectedicontheme.size and unselectedicontheme.size take precedence over iconsize. tests for making sure that the padding on the nav bar items is calculated correctly when all labels are shown, just selected labels are shown, and when no labels are shown. alternatives considered since selectedfontsize and unselectedfontsize already exist as parameters, it brings up the question of what to do when both selectedtextstyle.fontsize and selectedfontsize are provided. there are three options i considered: keep both parameters, but prefer selectedtextstyle.fontsize if it is provided, since providing the entire textstyle is more specific. keep both parameters, but throw an assert saying that font size should not be provided on both selectedtextstyle and selectedfontsize. deprecate and remove selectedfontsize, since it is now achievable through selectedfontstyle.fontsize. i opted for option 1, because it is non-breaking and is inline with some existing components. for example, in tabbars, you could provide both indicatorcolor and an indicator with it's own color, and the custom indicators color will be used. if we think that having both will serve as unnecessary complication, or that it will be unclear to users which to use, i can deprecate/remove selectedfontsize and unselectedfontsize in the future. it would require a breaking change, but it may be worth it. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add tests </cmt> <cmt> add tests </cmt> <cmt> remove extra space </cmt>",selected/unselected label styles + icon themes on bottomnavigationbar
2267,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration this is an odd situation where the npm package and the name of the modules consumers import do not align. these types align with the module names create it with dts-gen --dt, not by basing it on an existing project. does not apply in this case tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. cc: @dwickern @jamescdavis @dfreeman @chriskrycho fixes typed-ember/ember-cli-typescript#264 </desc> <cmt> [ember] failing test - relax observermethod property name arg </cmt> <cmt> [ember] relax observermethod property name arg </cmt> <cmt> [ember] @ember/component types refactored into their own package </cmt>",refactor @ember/component types into their own package
2268,"<desc> fix bug/typo in previous pr #9931 add unit test for new feature dropout with axes (variational dropout) passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change dropout operator with axes, unit tests </desc> <cmt> fix bug </cmt> <cmt> add test for dropout with axes </cmt>","fix bug for dropout with axes, also adding unit test"
2269,<desc> upgrade actions/cache to the latest upgrade actions/setup-python disable cache for npm and pip since they don't seem to help much enable parallelization for cypress tests (need to configure record key) here is an example of a successful run when the record key is properly configured. n/a test plan make sure ci passes requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> upgrade cache action and disable cache </cmt> <cmt> always upgrade pip itself </cmt> <cmt> re-cache and clean up </cmt> <cmt> fix hash key; enable parallel for cypress </cmt> <cmt> disable npm and pip cache </cmt> <cmt> export cypress env variables </cmt> <cmt> update build id </cmt> <cmt> reformat and update </cmt> <cmt> longer wait </cmt> <cmt> longer sha </cmt> <cmt> move nonce out </cmt> <cmt> disable parallelization for now </cmt>,optimize github actions for building speed and stability
2270,"<desc> xgboost is a gradient boosting library. it's one of the most popular gb libraries used among kaggle users because it's yielded some of the highest scores. and its also a favorite with some of the champions. here's an example of its use with an otto dataset:  here is a kaggle first place team winner, showing their love for it:  this library is solely for gradient boosting. this resolves issue #821. anyone who agrees with this pull request could vote for it by adding a  to it, and usually, the maintainer will merge it when votes reach 20. </desc> <cmt> resolve issue #821 </cmt> <cmt> added xgboost library </cmt> <cmt> resolved issue #821 </cmt> <cmt> included period at the end </cmt>",xgboost is a kaggle favorite!
2271,"<desc> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add {loadnewmodules, modules} to angular.auto.iinjectorservice </cmt> <cmt> add {loadnewmodules, modules} to angular.auto.iinjectorservice </cmt> <cmt> allow for annotated functions in .loadnewmodules() </cmt>","add types for $injector.{loadnewmodules, modules} to types/angular"
2272,"<desc> an implementation of 3 variants of search function on trie. a simple search determining if the word exists in the trie. a suggestions search which suggests all possible words in trie which share the longest prefix with the search key. and a frequency based suggestions search, which suggests top3 most frequently searched words in trie which shares the longest prefix with search key. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines notes: 3 variants of search explicitly defined, to be performed on trie. explicitly defined so people can refer/use them directly. </desc> <cmt> trie with 3 types of search </cmt> <cmt> trie with 3 types of search and all basic operations </cmt> <cmt> updating directory.md </cmt> <cmt> docs: added main function documentation </cmt>",multiple variants of search on trie
2273,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! add thai java book for students basic java programming with data structure & algorithm book for students. they include all basic data structure & algorithm written in java it's produced by thai university. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> update free-programming-books-th.md </cmt> <cmt> fixed order & added more info </cmt>",update free-programming-books-th.md with java programming book
2274,"<desc> currently when you use the query builder on eloquent models you end up with an instance of the query builder, thus calling find uses the hard-coded id instead of the key defined on the model. see issue #1476. this pr removes the find method from the model itself and instead defines it on the query class. you can now do things like this. $order = order::where('seller_id', '=', $seller_id)->find($order_id); </desc> <cmt> add the find method to the eloquent query class. </cmt> <cmt> find no longer needs to be defined on the model since the query catches it correctly. </cmt>",allow find to be called anywhere on an eloquent model
2275,"<desc> this pr changes the colors of all the elements in the edit keyboard and edit shortcuts windows to default as per the os theme. the theme does not change when the powertoys settings theme is changed. light theme dark theme pr checklist applies to #6 cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments background and foreground properties removed for all the controls. by removing that, the control using the default winui colors, which follow the selected os theme. requesttheme(light) was removed since that will only give colors for the light theme. the two places where we manually set the color had to be adjusted: for the keys in the type key and type shortcut ui, we were using the border xaml control with gray background. this was changes to the systembaselowcolor theme resource (which matches the same color in light theme and had a corresponding dark theme variant as well). this does not get refreshed when the os theme is changed, however the moment another key is clicked the correct color is loaded. for the hold enter to exit animation, we were changing the ok button to dark gray. this was changed to systembasemediumlowcolor. windows::ui::xaml::application::current().resources().lookup(box_value(l""systemcontrolbackgroundbaselowbrush"")).as<windows::ui::xaml::media::solidcolorbrush>() is the code equivalent of {themeresource systemcontrolbackgroundbaselowbrush} in xaml. </desc> <cmt> fixed colors for edit keyboard </cmt> <cmt> fixed colors for edit shortcuts </cmt>",fix colors in kbm ui and add support for light/dark theme
2276,"<desc> a function is added in generator_helpers.h for other wrapped languages. the detached leading comments and leading comments are put together separated by blank lines. the method comments are added to both stubinterface methods and service methods. a test is added, which also illustrated not all things are returned by the protobuf library, namely file level comments are all ignored service trailing comments are taken from one non-blank line below service (methoda1 detached comment) </desc> <cmt> add comments to the generated header file </cmt> <cmt> add a test </cmt>",put proto file comments to generated grpc header file.
2277,"<desc> added the time_series_metric mapping parameter to the unsigned_long and scaled_float field types added the time_series_dimension mapping parameter to the unsigned_long field type fixes #78100 relates to #76766,  #74450 and #74014 </desc> <cmt> added time_series mapping params to unsigned_long </cmt> <cmt> added time_series mapping params to scaled_float </cmt> <iss> can't use `time_series_metric` mapping parameter with `scaled_float` or `unsigned_long` fields </iss>",add time series params to unsigned_long and scaled_float
2278,"<desc> fixes #3726 (""replaced task in chain causes chain to skip to last link""). updates the task.replace() method to copy the replaced task's chain in the correct order. (was copying the chain backwards.) updates integration test of complex chaining to reproduce the issue and pass. </desc> <cmt> add add_replaced test task </cmt> <cmt> make test_complex_chain fail by adding a replaced task </cmt> <cmt> - update expected output </cmt> <cmt> copy replaced task's request chain in reverse </cmt> <cmt> - make t/integration/test_canvas.py::test_chain::test_complex_chain pass </cmt>",fix #3726 - chaining of replaced tasks
2279,"<desc> hi, i added the config.ru for development and thought others may like it. i think the background image (from subtlepatterns.com) makes the page a little easier on the eyes. i thought a print button might be nice, and the print.css was already there. added an email link too. </desc> <cmt> added a config.ru for rack/local dev </cmt> <cmt> added subtle background, added email and print links </cmt>","config.ru for dev, sexy background, print and email links"
2280,"<desc> noticed some typos in the pt-br (brazilian), along with the facts that the slack badge and the last section (self-promotion) are missing. this pr solves both issues. </desc> <cmt> adding slack badge, correcting typos and adding ""self-promote"" section </cmt> <cmt> removing unused text </cmt>",fix and adequate pt-br translation
2281,<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. </desc> <cmt> fix:(curriculum): rename rdbms cert project </cmt> <cmt> fix: some more spots to rename </cmt> <cmt> fix: rename i18n's </cmt>,rename rdbms cert project to proper name
2282,"<desc> fixes the docstring for encode_plus. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case. documentation guidelines, and here are tips on formatting docstrings. @sgugger or anyone really. </desc> <cmt> fix docstring for 'special_tokens_mask' </cmt> <cmt> revert auto formatter changes </cmt> <cmt> revert another auto format </cmt> <cmt> revert another auto format </cmt>",fix 'encode_plus' docstring for 'special_tokens_mask' (0s and 1s were reversed)
2283,"<desc> fa45c44 original pr #43432 </desc> <cmt> update openstack inventory script to keep basic functionality (#43432) </cmt> <cmt> re-applies commit 6667ec447466abf1641787afccf9175369319d1f which </cmt> <cmt> fixed the plugin to the script so that it will work with current </cmt> <cmt> ansible-inventory. </cmt> <cmt> also redirect stdout before dumping the ouptput, because not doing </cmt> <cmt> so will cause json parse errors in some cases. </cmt> <cmt> (cherry picked from commit fa45c44026ed471714d0383fd2731911d16a1271) </cmt> <cmt> fixed the plugin to the script so that it will work with current </cmt>",update openstack inventory script to keep basic functionality backport/2.6/43432
2284,"<desc> non-unique index support clarified #3092 fix assigning a new index to a duplicate index in a dataframe would fail #3468 fix construction of a dataframe with a duplicate index ref_locs support to allow duplicative indices across dtypes, allows iget support to always find the index (even across dtypes) #2194 applymap on a dataframe with a non-unique index now works (removed warning) #2786, and fix #3230 fix to_csv to handle non-unique columns #3495 modification to cache_readonly to allow you to pass an argument (allow_setting), to 'set' this value (useful in order to avoid a computation you know to be true, e.g. is_unique = true for a default index partially fixes #3468 this would previously raise (same dtype assignment to a non-multi dtype frame with dup indicies) in [6]: df = dataframe([[1,2]], columns=['a','a']) in [7]: df.columns = ['a','a.1'] in [8]: df out[8]: a  a.1 0  1    2 construction of a multi-dtype frame with a dup index (#2194) is fixed in [18]: dataframe([[1,2,1.,2.,3.,'foo','bar']], columns=list('aaaaaaa')) out[18]: a  a  a  a  a    a    a 0  1  2  1  2  3  foo  bar this was also previously would raise in [3]: df_float  = dataframe(np.random.randn(10, 3),dtype='float64') in [4]: df_int    = dataframe(np.random.randn(10, 3),dtype='int64') in [5]: df_bool   = dataframe(true,index=df_float.index,columns=df_float.columns) in [6]: df_object = dataframe('foo',index=df_float.index,columns=df_float.columns) in [7]: df_dt     = dataframe(timestamp('20010101'),index=df_float.index,columns=df_float.columns) in [9]: df        = pan.concat([ df_float, df_int, df_bool, df_object, df_dt ], axis=1) in [14]: cols = [] in [15]: for i in range(5): ....:     cols.extend([0,1,2]) ....: in [16]: df.columns = cols in [17]: df out[17]: 0         1         2  0  1  2     0     1     2    0    1    2                   0                   1                   2 0  0.586610  0.369944  1.341337  1  1  1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 1 -1.944284 -0.813987  0.061306  0  0  1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 2 -1.688694  1.644802  0.659083  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 3  1.422893  0.712382  0.749263 -1  0 -1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 4 -0.453802  0.228886 -0.339753  2  0 -2  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 5 -0.189643  1.309407 -0.386121  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 6  0.455658  0.822050 -0.741014  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 7 -0.484678 -1.089146  0.774849  0  1  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 8  0.720365  1.696400 -0.604040 -1  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 9 -0.344480  0.886489  0.274428  1  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 for those of you interested.....here is the new ref_loc indexer for duplicate columns its by necessity a block oriented indexer, returns the column map (by column number) to a tuple of the block and the index in the block, only created when needed (e.g. when trying to get a column via iget and the index is non-unique, and the results are cached), this is #3092 in [1]: df = pd.dataframe(np.random.randn(8,4),columns=['a']*4) in [2]: df._data.blocks out[2]: [floatblock: [a, a, a, a], 4 x 8, dtype float64] in [3]: df._data.blocks[0]._ref_locs in [4]: df._data._set_ref_locs() out[4]: array([(floatblock: [a, a, a, a], 4 x 8, dtype float64, 0), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 1), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 2), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 3)], dtype=object) fixed the #2786, #3230 bug that caused applymap to not work (we temp worked around by raising a valueerror; removed that check) n [3]: in [3]: df = pd.dataframe(np.random.random((3,4))) in [4]: in [4]: cols = pd.index(['a','a','a','a']) in [5]: in [5]: df.columns = cols in [6]: in [6]: df.applymap(str) out[6]: a                a               a               a 0  0.494204195164   0.534601503195  0.471870025143  0.880092879641 1  0.860369768954  0.0472931994392  0.775532754792  0.822046777859 2  0.478775855962   0.623584943227  0.932012693593  0.739502590395 finally, to_csv writing has been fixed to use a single column mapper (which is derived from the ref_locs if the index is non-unique or the column numbering if it is unique) </desc> <cmt> bug: gh3468 fix assigning a new index to a duplicate index in a dataframe would fail </cmt> <cmt> enh: support for having duplicative indices across blocks (dtypes) </cmt> <cmt> bug: fix construction of a dataframe with duplicative indices </cmt> <cmt> bug: enabled applymap to work (and updated internals/convert to use iget) when </cmt> <cmt> using a non-unique index (gh2786 for the warning and gh3230 for applymap) </cmt> <cmt> tst: test for gh2194 (which is fixed) </cmt> <cmt> bug: gh3495 change core/format/csvformatter.save to allow generic way of dealing </cmt> <cmt> with columns duplicate or not </cmt> <iss> enable applymap for dataframes with duplicate columns </iss> <iss> pandas inconsistenly handles identically named columns in csv export and merging </iss>",allow the blockmanager to have a non-unique items (axis 0)
2285,<desc> multi-line comments in typescript aren't aligning properly. they should follow the tslint rule jsdoc-format. this pr adds some failing tests for the issue. i can also try to take a crack at fixing it fixes #648. </desc> <cmt> fix typescript comment snapshot </cmt> <cmt> add failing test for typescript method comments </cmt> <iss> re-indent comments </iss>,fix indentation for jsdoc comments
2286,<desc> generating jsb_cocos2dx_extension_auto.hpp/.cpp. it was separated from original cocos2dx.hpp/cpp.  developer could remove redundant jsbinding native codes now. cocos2dx.hpp/cpp ~> jsb_cocos2dx_auto.hpp/cpp adding jsb_cocos2dx_extension_manual.hpp/cpp </desc> <cmt> fixed #1748: generating jsb_cocos2dx_extension_auto.hpp/.cpp. it was separated from original cocos2dx.hpp/cpp. </cmt> <cmt> developer could remove redundant jsbinding codes now. </cmt> <cmt> updating the submodule of  cocos2d-js-tests. </cmt> <cmt> updating the submodule reference of js tests. </cmt> <cmt> fixed #1748: updating win32 project setting. </cmt>,separating js extension from cocos2dx.hpp/cpp.
2287,"<desc> add default network timeout values to the networking troubleshooting guide. fixes #41826 docs.ansible.com </desc> <cmt> add toc and default timeout values </cmt> <cmt> make options more obvious </cmt> <iss> ansible network automation timeout values for command_timeout, connect_timeout and retry_timeout are not provided in documentation </iss>",add default network timeout values to network troubleshooting guide
2288,"<desc> description: changes for issue #2751 caused that certain code paths were not evaluated during coverage run. this change allows running coverage test with ""trace"" log level and dropping all log messages to avoid cluttering stderr/out. running at ""trace"" level evaluates all code paths. risk level: low. testing: executed several unit tests to check if log level is lowered to trace and logs are dropped. docs changes: no. release notes: no. fixes: #3012 </desc> <cmt> modified test environment setup. if --log-path command line option is </cmt> <cmt> specified a fake file sink is allocated and all logs are dumpoed there. </cmt> <cmt> removed trailing _ from local variables. </cmt> <cmt> removed inaccurate log-level command line arg description. </cmt>",lower log level to trace and drop all logs
2289,"<desc> restoring from a snapshot (which is a particular form of recovery) does not currently take recovery throttling into account (i.e. the indices.recovery.max_bytes_per_sec setting). while restores are subject to their own throttling (repository setting max_restore_bytes_per_sec), this repository setting does not allow for values to be configured differently on a per-node basis. as restores are very similar in nature to peer recoveries (streaming bytes to the node), it makes sense to configure throttling in a single place. the max_restore_bytes_per_sec setting is also changed to default to unlimited now, whereas previously it was set to  40mb, which is the current default of indices.recovery.max_bytes_per_sec). this means that no behavioral change will be observed by clusters where the recovery and restore settings were not adapted. relates #57023 </desc> <cmt> use recovery settings for restore </cmt> <cmt> add docs </cmt> <cmt> default max_restore_bytes_per_sec to unlimited </cmt>",account for recovery throttling when restoring snapshot
2290,<desc> cherry picked from (25f485f) backport for pr #54419 nios </desc> <cmt> update nios_member.py (#54419) </cmt> <cmt> * update nios_member.py </cmt> <cmt> * update api.py </cmt> <cmt> * update nios_member.py </cmt> <cmt> * update nios_member.py </cmt> <cmt> * update api.py </cmt> <cmt> (cherry picked from commit 25f485f79db3aaff53bd649790297452739cef30) </cmt> <cmt> nios_member param fix </cmt>,backport to fix nios member module param bug fix
2291,<desc> resolve #7600 resolve #7601 </desc> <cmt> add python wrapper for matmul_op </cmt> <cmt> add python wrapper for matmul_op and dot_product_attention </cmt> <cmt> add dot_product_attention to nets.__all__ </cmt> <iss> need python wrapper for matmul_op </iss> <iss> need python wrapper for dot-product-attention </iss>,add python wrapper for dot-product-attention
2292,<desc> capture a weak reference to the instance in the websocket resource's callback lambda and bail if it's not available. microsoft reviewers: open in codeflow </desc> <cmt> make ws callbacks capture weak instance instead of strong instance pointer </cmt> <cmt> change files </cmt>,prevent reference cycles between websocketmodule and react instance.
2293,"<desc> followup of #40 and with added localization support the makefile does the .po to .mo part that the shell scripts used to do. </desc> <cmt> much simpler, pure-python packaging </cmt> <cmt> simple building and packaging of i18n </cmt>","much simpler, pure-python packaging + i18n"
2294,"<desc> this adds a link to training t5 in tensoflow 2 community notebook under the notebooks/readme.md community notebook section. this notebook demonstrates how to train t5 for any task using tensorflow 2. trains a question & answer task implemented in tensorflow 2 using squad this pr fixes a typo or improves the docs (you can dimiss the other checks if that's the case). yes did you read the contributor guideline, pull request section? yes was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case. forum link documentation guidelines, and here are tips on formatting docstrings. not applicable did you write any new necessary tests?  not applicable @patrickvonplaten @jplu </desc> <cmt> t5 t5 community notebook added </cmt> <cmt> author link updated </cmt> <cmt> t5 t5 community notebook added </cmt> <cmt> author link updated </cmt>",train t5 in tensoflow 2 community notebook
2295,"<desc> hi everyone, this is a significative pull request in skywalking 6. i propose the new header protocol v2, now it is the time to implement it. if you miss the last one, see v2 protocol. several things you need to pay attention base64 for trace id, segment id, host, entry op name, and parent op name entry op name and parent op name are optional in contextcarrier and contextsnapshot @liuhaoyang .net core @ascrutae nodejs need to follow this protocol, after this is merged. also v1 is still supported in receiving sw3 header, but you need to active v1 header manually in order to let the agent send sw3 header. in default, sw3/sw6 headers could be received, sw6 sent only. </desc> <cmt> add some supports to sw6 header. break many test cases because i turn sw3 default off. for sure, you could open in agent.conf.  fyi @peng-yongsheng @ascrutae </cmt> <cmt> fix ci and make user cases still work under v1 header. </cmt> <cmt> merge commit '513c1b86c6d86b981bf9e5c09c0d041d6c2d624e' into sw6-header </cmt> <cmt> support base64 in v2 header and make entryoperationname and parentoperationname optional in contextcarrier or contextsnapshot </cmt>",new v2 header with header key sw6
2296,"<desc> it was becoming quite annoying to have to open the shell each time i wanted to execute a file, so i did this. this can be made to also run shell scripts and the sort (application/x-shellscript is different from text/x-shellscript), but i'm still not sure about it. a more elegant way of doing this would be to just create a separate plugin which would handle running things from within nnn, and then binding that to a key (like how e is bound to open in editor) or possibly have nuke use it as an opener like it does mocq. </desc> <cmt> added execute fallback to nuke </cmt> <cmt> fixed syntax error </cmt> <cmt> merge local with remote </cmt>",pseudo-ability to run binary files for nuke
2297,"<desc> this adds two trends options to the release's transaction list, trending regressions & trending improvements clicking the transaction name will bring you to the transaction's summary view with the trend display mode already selected this also adds that when clicking on releases in trends, the transactions list will already be on the related list </desc> <cmt> feat(perf): add transactions list to release details </cmt> <cmt> the current release details page does not show any information regarding the </cmt> <cmt> transactions associated with this release. this change adds a transactions list </cmt> <cmt> on to the release details page. this transactions list will show a list of </cmt> <cmt> transactions along with their failure rate, throughput, and p50 duration. </cmt> <cmt> wip: got the table to show trend data </cmt> <cmt> - still have to render percentage correctly </cmt> <cmt> - probably going to refactor the transactions list even more to take </cmt> <cmt> trends more naturally </cmt> <cmt> wip: got it functional with the dropdown </cmt> <cmt> todo still have to get the link working properly </cmt> <cmt> fix: updating link to summary, updating trend queries </cmt>",adding trends to the transaction list
2298,"<desc> relative paths in gradle break when the gradle daemon is used unless user.dir can be changed while the process is running. java 11 disallows this, so we use project paths instead. verified that rat and checkstyle work with java 11 after these </desc> <cmt> rat plugin should not rely on working directory </cmt> <cmt> it breaks when used with the gradle daemon and </cmt> <cmt> java 11. </cmt> <cmt> don't use relative paths in checkstyle config </cmt> <cmt> they break under java 11 </cmt>",fix rat and checkstyle config for java 11 support
2299,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> cytoscape: join layout options declarations </cmt> <cmt> cytoscape: layout events with layouteventobject as parameter </cmt> <cmt> cytoscape: add type to cy property in abstracteventobject </cmt> <cmt> cytoscape: add myself to the 'definitions by' </cmt>,add missing callback parameter and adjust property type
2300,"<desc> currently the run-windows command appears to hang for a long period of time while its building, and its not obvious that anything is happening. this change adds some progress ui to the command so that its easier to see whats going on. microsoft reviewers: open in codeflow </desc> <cmt> improve output of run-windows command </cmt> <cmt> change files </cmt>",improve ui of run-windows command
2301,<desc> shard level request cache is improved to work correctly at all time. also ensure profiling and suggester are properly disabled when not supported. </desc> <cmt> add tests </cmt> <cmt> attempt to fix </cmt> <cmt> fix implementation </cmt> <cmt> fix suggester and profiling </cmt>,improve shard level request cache efficiency (#69505)
2302,<desc> fix #819  the smoke test should no longer hang after this fix #679 this will users debug why the smoke test process could hang we now kill smoketest after 10s using execa's timeout feature print an error message that the command timed out along with stderr (or stdout) review tasks: remove promise cancellation </desc> <cmt> temp 04/29/19 [skip ci] cli verify timeout </cmt> <cmt> add smoke test timeout error and tests </cmt> <iss> add timeout to verify command </iss> <iss> cypress hangs on verify step </iss>,add timeout for cli/verify smoke test
2303,"<desc> fix higher-order array functions (sigsegv for arraycompact/illegal_column for arraydifference/arraycumsumnonnegative) with consts detailed description / documentation draft: ci: </desc> <cmt> fix sigsegv for arraycompact() with consts </cmt> <cmt> arraycompact() implements usedefaultimplementationforconstants() but it </cmt> <cmt> is a no-op for functionarraymapped, fix this. </cmt> <cmt> ci report [1]: </cmt> <cmt> [1]: </cmt> <cmt> fix arraydifference() for consts </cmt> <cmt> fix arraycumsumnonnegative() for consts </cmt>",fix higher-order array functions (arraycompact/arraydifference/arraycumsumnonnegative) with consts
2304,"<desc> fixes #12546. pinging @westy92, @yuit, @vvakame, @bonnici, @codeanimal </desc> <cmt> decomposed 'winston' into a var/namespace/type so it can export a member named 'default'. </cmt> <cmt> fixed 'winston' to expose a member named 'default'. </cmt> <cmt> added a test for the default logger in 'winston'. </cmt>",expose 'default' member on winston
2305,"<desc> this rfc is about how to evolve grammars and syntax themes so that their design goals don't get in each others' way. i am utterly certain that a maximum of four people on earth will care about this, but i'd love to find out i'm wrong. hopefully some discussion can help refine exactly what is being proposed here. rendered version. view rendered docs/rfcs/005-scope-naming.md </desc> <cmt> add rfc about how to evaluate proposed scope additions to grammars. </cmt> <cmt> give the rfc a title. </cmt> <cmt> fix typos. </cmt>",evaluating scope name additions to built-in grammars
2306,"<desc> continues the work in #17535 $ git grep --name-only ""swift-version 3"" | grep -ev 'compatibility/' | wc -l > 238 after $ git grep --name-only ""swift-version 3"" | grep -ev 'compatibility/' | wc -l > 158 </desc> <cmt> migrate some stdlib tests to swift 4 </cmt> <cmt> migrate sil parser tests </cmt> <cmt> migrate serialization tests to swift 4 </cmt> <cmt> migrate sil serialization tests to swift 4 </cmt> <cmt> migrate interpreter tests </cmt> <cmt> migrate parse and namebinding tests </cmt> <cmt> miscellaneous test migrations </cmt>",migrate more tests to swift 4
2307,"<desc> the pr is another solution to fix #11974 .  i believe that it is better than #12127 . what changes were proposed in this pull request? make dimension to be compatible with integer, so [1, dimension(2)] will be casted to [1, 2] automatically. how was this patch tested? add a doctest. add an unit test. pass all unit tests. </desc> <cmt> bug: make dimension compatible with integer </cmt> <cmt> tst: add doctest </cmt> <cmt> bug: resolve circle import </cmt> <iss> tf.reshape does not accept dimension objects for the shape parameter </iss>",make dimension be compatible with integer
2308,<desc> this should fix the warning messages that we get around the usage of strtok_r (). how to use it correctly: see  see  thanks </desc> <cmt> our usage of strtok_r () was not totally correct (but almost) </cmt> <cmt> also double-check input/output of strtok_r () </cmt>,"fix our usage of strtok_r (), it was not 100% correct"
2309,"<desc> cherry-pick of #37380 explanation: with se-0293, closure parameters can use the $ prefix to have a property wrapper type inferred from context. however, when a closure is resolved, the contextual parameter type doesn't always exist. this happens most commonly when the solver is attempting an overload where the contextual type for the closure isn't a function type (e.g. a concrete nominal type, or a type parameter). the implementation was assuming the contextual parameter type always existed, resulting in a crash in the constraint system when attempting to bind to a null type.  the solution is to simply create a type variable for the property wrapper type if the contextual parameter type doesn't exist. scope: this only affects the new $ syntax on closure parameters. risk: very low. testing: added several tests covering a variety of cases where a contextual type for a closure parameter doesn't exist. reviewer: @xedin resolves: rdar://77793820 </desc> <cmt> [constraintsystem] if the contextual parameter type doesn't exist when </cmt> <cmt> resolving a closure, create a new type variable for inferred property </cmt> <cmt> wrapper types. </cmt> <cmt> [diagnostics] always use the parameter name for closure parameter diagnostics, </cmt> <cmt> because the $ prefix does not indicate that the parameter is anonymous. </cmt>",fix a constraint system crash with property wrapper inference using the $ syntax.
2310,"<desc> this patch replaces gui::widget::find_descendant_by_name with core::object::find_descendant_of_type_named. elephant in the room, this patch enables rtti for userspace programs. some quick measurements showed that this is a small binary size increase, on the order of 3% for a class-rich library like libgui.so. this pr is an alternative to #4708, which does the ak::traits thing to do the rtti manually. which, is kind of awkward and really annoying to have to copy paste the ""opt-me-in to rtti"" macro into every header under the sun. i'm not sold on the name of the core::object helper, so lemme know if there's a better one. everyone loves a good naming thread. </desc> <cmt> meta: enable rtti for userspace programs </cmt> <cmt> rtti is still disabled for the kernel, and for the dynamic loader. this </cmt> <cmt> allows for much less awkward navigation of class heirarchies in libcore, </cmt> <cmt> libgui, libweb, and libjs (eventually). measured rootfs size increase </cmt> <cmt> was < 1%, and libgui.so binary size was ~3.3%. the small binary size </cmt> <cmt> increase here seems worth it :^) </cmt> <cmt> libcore: add typed find_child and find_descendant helpers to object </cmt> <cmt> these look a lot like the parallel functionality in gui::widget :). </cmt> <cmt> these use dynamic_cast now, to make use of that rtti we just added. </cmt> <cmt> applications+libgui: convert all gml consumers to use the libcore finder </cmt> <cmt> remove widget::find_child_by_name and widget::find_descendant_by_name, </cmt> <cmt> and convert all users to using the type-safer version in core::object. </cmt>","type safe widget gml usage, with rtti"
2311,<desc> also ensures inferred and auto import projects have name per project service so they are same across any type of runs this is the pr i had started as part of #41004 and is partially done but nothing wrong with merging this without converting many more tests to baselines. that can be done as and when needed. </desc> <cmt> tests to baseline tsserver instead of checking </cmt> <cmt> also ensures inferred and auto import projects have name per project service </cmt> <cmt> log structureisreused value </cmt>,tsserver tests can be baselined
2312,"<desc> fixed #253 and a bunch of related issues. here now common modules loads once using the webpack's commonschunkplugin. still, we use next.js module loading system and ssr features. as a result of this, we don't need to worry about loading the next-bundle and even creating it. </desc> <cmt> add example app which demonstrate the problem. </cmt> <cmt> add the first working version. </cmt> <cmt> fix lint issues. </cmt> <cmt> add readme.md </cmt>",add support for webpack's commonschunkplugin and remove next bundle
2313,<desc> xref #28792 as requested in #32823 creating separate pr. also all descriptions for methods starts with upper case and it looks a little out of place. should it be casted to lowercase perhaps? </desc> <cmt> doc: partial fix sa04 errors in docstrings #28792 </cmt> <cmt> black formatting </cmt>,change doc template to fix sa04 errors in docstrings #28792
2314,"<desc> original pull-request #21533 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> podarray left pad not multiple of element crash fix </cmt> <cmt> updated style check </cmt> <cmt> cleanup podarray </cmt> <cmt> remove unused method </cmt> <cmt> fix error (found by @kitaisreal) </cmt> <cmt> fixed podarray </cmt> <cmt> pod array left pad not multiple of element crash fix </cmt> <cmt> cleanup podarray </cmt>",cherry pick #21533 to 20.8: cleanup podarray
2315,"<desc> re-apply #29289 with a fix for msvc that makes anyrequestbase subclasses be friends with all specializations of it, and defines getrawstorage in the base class to make it accessible to friend top-level functions. </desc> <cmt> revert ""revert ""don't heap allocate for active requests"""" </cmt> <cmt> f8a1ad22e1c5b93d39c6483b0c8ed551a5c7ee17 </cmt> <cmt> [ast] fix friendship with anyrequestbase </cmt> <cmt> this was causing issues with msvc. have subclasses </cmt> <cmt> be friends with all specializations of </cmt> <cmt> anyrequestbase, and define getrawstorage in </cmt> <cmt> the base class to make it accessible to friend </cmt> <cmt> top-level functions. </cmt>","re-apply ""don't heap allocate for active requests"""
2316,"<desc> clojure api docs for the website please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change start of api docs markdown pages for the clojure package minor tweaks to add rm viz example checked in by mistake and other slight wording tweaks the website changes are not linked in so even if the pr is merged it won't be visible yet. </desc> <cmt> rm visualization example output checked in by mistake </cmt> <cmt> add kovas to special thanks </cmt> <cmt> fix up tutorial example with right namespaces </cmt> <cmt> - get rid of getting started since it shows up in codox docs </cmt> <cmt> start on clojure api docs </cmt> <cmt> tweaks in wording </cmt> <cmt> tie in building of clojure docs </cmt>",clojure package api docs for the website
2317,"<desc> the fix for bmfontconfiguration::parseconfigfile reads string file. 'strchr' finds a char until it gets a '\0' or the char to find, if 'contents' self doesn't end with '\0', 'strchr' will search '\n' out of 'contents' 's buffer size, it will trigger potential and random crashes since linelength may bigger than 512 and 'memcpy(line, contents + parsecount, linelength);' will cause stack buffer overflow. const data -> const data& for function argument, performance improvement. removes unused code in material::initwithfile. refactor ccbundle3d, remove wrong use of getdatafromfile. _jsonbuffer is std::string, _binarybuffer is data instance now. spritetest fix image is ref class, please new & release it. don't allocate it on stack. fixes complicated logic of getting string from file. </desc> <cmt> the fix for bmfontconfiguration::parseconfigfile reads string file. </cmt> <cmt> 'strchr' finds a char until it gets a '\0', if 'contents' self doesn't end with '\0', </cmt> <cmt> 'strchr' will search '\n' out of 'contents' 's buffer size, it will trigger potential and random crashes since </cmt> <cmt> linelength may bigger than 512 and 'memcpy(line, contents + parsecount, linelength);' will cause stack buffer overflow. </cmt> <cmt> const data -> const data& for function argument, performance improvement. </cmt> <cmt> removes unused code in material::initwithfile. </cmt> <cmt> refactor ccbundle3d, remove wrong use of getdatafromfile. _jsonbuffer is std::string, _binarybuffer is data instance now. </cmt> <cmt> spritetest fix </cmt> <cmt> * image is ref class, please new & release it. don't allocate it on stack. </cmt> <cmt> * fixes complicated logic of getting string from file. </cmt>","some important fixes for file reading, may cause stack overflow"
2318,<desc> i did more extensive testing on the export and realised that i could not rely on the format used by the original xml export as much as i had hoped since it did locale dependent formating in order to be more human readable. i've added dbunit-compatible formating and verified the corresponding java classes mapping. </desc> <cmt> added missing tag ending </cmt> <cmt> use dbunit output formats </cmt> <cmt> use internal output format for different datatypes instead of relying on </cmt> <cmt> format used by dataexporterxml </cmt>,support for export in dbunit dataset format - improved formating
2319,"<desc> start integration of the first available nightly build before 0.63. this build has some interesting stuff like c++ version stamping, platformcolor, import fixes. fixes #3990 microsoft reviewers: open in codeflow </desc> <cmt> allow override tooling to use nightly builds </cmt> <cmt> fixes #4857 </cmt> <cmt> teach the tooling about the pattern and make sure we can validate against 0.0.0-56cf99a96 (the earliest nightly build). we cannot do a lazy fetch against a shortned commit hash, so we need to get a bit ""creative"" here. </cmt> <cmt> we make a couple other improvements here: </cmt> <cmt> 1. change fetch depth to 1 to pull in less history. this reduces the scratch repo size from 174mb to 34mb when fetching just 0.62.2 (which is already much less than the 500mb for cloning entire remote) </cmt> <cmt> 2. don't add remotes to the scratch git repo and instead fetch using the url. we've seen transient errors where simplegit thinks we don't yet have a repo set up and adds a duplicate remote. this should hopefully fix that. </cmt> <cmt> change files </cmt> <cmt> reduce unneeded fetches </cmt> <cmt> begin integration of 3/22 nightly build </cmt> <cmt> change files </cmt> <cmt> new specs </cmt> <cmt> do auto upgrades (limited success here) </cmt> <cmt> begin manual merging + nativeordynamiccolor deletion </cmt> <iss> remove nativeordynamiccolor related patches when platformcolor is available </iss> <iss> platformconstants cannot determine correct patch and prerelease version </iss> <iss> react patching due to upstream bypassing metro platform checks </iss> <iss> rename rctimage to rctimageview in devmain </iss> <iss> forking of scrollview to prevent crash from duplicate rctscrollview registration </iss> <iss> upgrade to a facebook master build </iss> <iss> image.onload event's source.url is now source.uri </iss>",integrate of 3/22 nightly build
2320,<desc> it is possible and in some cases likely that we will try to sync reversible blocks that we already know about.  this pr is to handle those cases. select one: select any that apply: </desc> <cmt> fix uncaught exception </cmt> <cmt> added handling of duplicate reversible blocks </cmt>,added handling of duplicate reversible blocks.
2321,"<desc> i have followed (at least) the pr section of the contributing guide. closes #14203 before when using the variant prop to change the input of select nothing happens. after now when setting a value for variant like outlined the input will change based on this value, check the code bellow: <select value={values.age} onchange={handlechange} variant=""outlined"" labelwidth={labelwidth} inputprops={{ name: 'age', id: 'outlined-age-simple' }} > output: </desc> <cmt> change variant prop to handle defaultinput </cmt> <cmt> add specs </cmt> <iss> select doesn't support variant=""outlined"" </iss>",changes the default input based on variant prop
2322,"<desc> commit message: fixes oss crash in router fuzz tests due to unimplemented features being tested filteraction filter_action in the route message is not implemented but was being tested, causing an assert to fail in routeentryimplbase::clusterentry risk level: low testing: passed regression test that originally failed on ossfuzz docs changes: n/a release notes: n/a fixes: </desc> <cmt> fix oss issue </cmt> <cmt> style fix </cmt>",fix ossfuzz crash in router tests
2323,<desc> it turns out that np.ma.masked is actually pretty bad at preserving identity or value this pr attempts to fix that. fixes #9328 and #4595 </desc> <cmt> enh: make duplicated masked constants obvious </cmt> <cmt> bug: np.ma.masked does not preserve identity through pickle </cmt> <cmt> it's still possible to create duplicate maskedconstants through .copy() </cmt> <cmt> bug: prevent copies of np.ma.maskedconstant from being created by .view. </cmt> <cmt> this seems to solve the problem everywhere. it's not clear if this works on pypy. </cmt> <cmt> fixes gh-9328 </cmt> <iss> bug: maskedconstant  is mutated despite copying </iss>,fix various problems with the np.ma.masked constant
2324,<desc> this should fix #3275. </desc> <cmt> make scheduling queues removetasks return task states as well. </cmt> <cmt> add test </cmt> <cmt> don't unsubscribe for infeasible tasks when spilling over. </cmt> <cmt> linting </cmt> <iss> test failure in test_object_transfer_dump in runtest.py. </iss>,don't unsubscribe dependencies for infeasible tasks.
2325,"<desc> others docs cherry-pick #pr36554 modify the english document, add warning reminder, only used in cuda11.3 and above </desc> <cmt> fix cusparse compile bug in cuda11.2, test=develop </cmt> <cmt> modify sparse_attention docs, test=document_fix (#36554) </cmt> <cmt> * modify sparse_attention docs, test=develop </cmt> <cmt> * add warning </cmt> <cmt> * add warning ,test=document_fix </cmt>",[cherry-pick]add sparse attention doc warning
2326,"<desc> adds fallback routine for when a font name is missing instead of crashing due to uncaught exception thrown when font cannot be found. closes #550 i'm an employee doesn't need documentation i'm a core contributor for gdi and for directx using the stock layouts and formats, if your chosen font face name isn't found... something else is just picked on your behalf. when i wrote our custom dx code, i instead threw an exception when i couldn't find the chosen font face. that exception was uncaught and led to a crash. i decided to just make the custom code act more like the stock code and attempt to choose a fallback if we cannot find what you've requested. i also improved a bit of the passing around of the chosen font name and added locale name information while i was at it. opened settings set font name to ""arse"" watched as nothing changed from previous consolas selection closed application relaunched didn't crash this time, it just chose consolas instead </desc> <cmt> stop the crash with fonts by trying a few fallback/backup fonts if we can't find what was selected. </cmt> <cmt> create fallback pattern for finding a font. resolve and pass the locale name. retrieve the font name while retrieving the font object. use retrieved data in the _getproposedfont methods instead of re-resolving it. </cmt> <iss> specifying a font to be used in profile that does not exist causes the app the crash </iss>",fixes crash when specifying invalid font
2327,"<desc> grid browser session priority, first cut at working logic with unit tests. there's more code than necessary, and an abusive amount of commentary, but this should correctly prioritize where sessions go based on browser ""rarity"". still need a code review and some unit tests, but i wanted to put this up for review and feedback. there's plenty to optimize, but i think this does the job. by placing an x in the preceding checkbox, i verify that i have signed the contributor license agreement </desc> <cmt> adding distributor test </cmt> <cmt> added first functionality for balancing distributor by browser availability </cmt> <cmt> filling out unit test for ""host priority"", still ignored because the feature isn't implemented </cmt> <cmt> interim commit </cmt> <cmt> adding logs and traces to the distributor code </cmt> <cmt> unit test is passing for distributor optimization by browser </cmt> <cmt> adding comments, slight refactors, and setting up for pr </cmt>","selenium 4.0 grid browser priority, first cut"
2328,"<desc> fixed number of led rgb on rart4x4 and pin matrix on rart45 my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> update config.h </cmt> <cmt> update config.h </cmt>",fix number rgb rart4x4 dan matrix pin rart45
2329,"<desc> setemitzone was rejecting custom objects passed as the source argument because it was checking for the wrong methods. i fixed the checks, but i would actually prefer removing them. </desc> <cmt> correct source checks in setemitzone </cmt> <cmt> correct source types in *zoneconfig definitions </cmt> <cmt> remove source checks in setemitzone </cmt>",fix source checks in particleemitter#setemitzone
2330,"<desc> after #9665, this moves the remaining types in posixmodule to be heap-allocated to make it compatible with pep384 as well as modifying all the type accessors to fully make the type opaque. the original pr that got messed up a rebase: #10854. all the issues in that commit have now been addressed since #11661 got committed. this change also removes any state from the data segment and onto the module state itself.  automerge-triggered-by: @encukou </desc> <cmt> make posixmodule use pytype_fromspec </cmt> <cmt> added news </cmt> <cmt> updated hash </cmt> <cmt> addressed pr issues </cmt> <cmt> rebased </cmt> <cmt> ran argument clinic </cmt> <cmt> added news </cmt> <cmt> remove incref from genericalloc </cmt> <cmt> make posixmodule use pytype_fromspec </cmt> <cmt> added news </cmt> <cmt> updated hash </cmt> <cmt> addressed pr issues </cmt> <cmt> ran argument clinic </cmt> <cmt> added news </cmt> <cmt> merged to master </cmt>",bpo-35381 remove all static state from posixmodule
2331,<desc> i translated readme.md and contributing.md into japanese. saved as readme_jp.md and contributing_jp.md respectively. i hope japanese users will be able to use this project more conveniently. thank you. </desc> <cmt> create contributing_jp.md </cmt> <cmt> create readme_jp.md </cmt>,created readme and contributing files in japanese
2332,"<desc> enables build_test for macos. currently only flutter_gallery has platform directories for the desktop platforms, so this will run only that build, but this will provide an end-to-end build test for macos. once this lands, other example/test projects can be brought online for macos in the future just by adding the macos/ directory to the project. related issues #54295 i added the following tests: build_test for macos before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. </desc> <cmt> enable dev/bots/ build_tests for desktop </cmt> <cmt> enables build_test for windows, macos, and linux. currently only </cmt> <cmt> flutter_gallery has platform directories for the desktop platforms, so </cmt> <cmt> this will run only that build, but this will provide an end-to-end build </cmt> <cmt> test for all three desktop platforms. </cmt> <cmt> once this lands, other example/test projects can be brought online for </cmt> <cmt> desktop platforms in the future just by adding the relevant platform </cmt> <cmt> directories to the project. </cmt> <cmt> add missing awaits </cmt> <cmt> add config enabling </cmt> <cmt> remove linux </cmt> <cmt> remove windows </cmt>",enable dev/bots/ build_tests for macos
2333,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes. the list is: </desc> <cmt> improve typing deprecation for dep0010 and dep0011 </cmt> <cmt> improve typing deprecation for dep0012 </cmt>,"add deprecation messages for dep0010, dep0011 and dep0012"
2334,"<desc> in the process of organizing these, some parametrization opportunities become clear.  didnt do them in this pr to keep this just a moving-around diff </desc> <cmt> more frame method tests </cmt> <cmt> test_count </cmt> <cmt> series cov, count, round methods </cmt>","method-specific tests for cov, corr, corrwith, count, round"
2335,"<desc> fix an issue where arrowvegalitechart react component wasn't being updated after add rows, which caused an unexpected behavior. fix a couple of ""index out of bounds"" issues in arrowvegalitechart component. additional reportnode unit tests. activate metrics for arrow add rows. (totally unrelated, and should have been sent as a separate pr) </desc> <cmt> fix index out of bounds issue in arrowvegalite </cmt> <cmt> update react component after addrows </cmt>",fix add rows on arrowvegalitechart
2336,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> hooks api </cmt> <cmt> added region for hook events </cmt>,definitions and documentation for hooks api
2337,"<desc> in some build modes (certain asyncify flags) we forgot to remove debug info at the very end, if we only needed it in the middle. note that this only affects the names section - function names. we did not have any issues with dwarf, which has explicit stripping code already, and that is heavily tested (as dwarf can be huge) as correct. the fix here is by tracking the reasons why we need interim debug info, and noting when we no longer need it. we can then strip it out at the end, if so. we also stop emitting it as soon as possible, which makes the build slightly more efficient. also, this can avoid running wasm-opt just to strip the debug info if it's already been removed by a previous command, which is potentially a large speedup in a big project in an unoptimized build (as in an optimized one there will be another command that strips it anyhow). to achieve that, this adds tracking of the last command - is there perhaps a nicer way to do it? fixes #14143 </desc> <cmt> fix #14143 </cmt> <cmt> fix </cmt> <cmt> fix flake8 </cmt> <cmt> better </cmt> <cmt> fixes </cmt> <cmt> fix </cmt> <cmt> flake8 </cmt> <cmt> format </cmt> <cmt> comment </cmt> <iss> asyncify, shipping build (o3), code bloat and increased memory usage between emscripten versions </iss>",do not emit intermediate debug info by mistake in the final output
2338,"<desc> heron's formula for area of any (valid) triangle. description adding heronarea.js and adding the corresponding entry in tag_database. more info on heron's formula (and why it works) here:  pr type snippets, tests & tags (new snippets, updated snippets, re-tagging of snippets, added/updated tests) scripts & website & meta (anything related to files in the scripts folder, how the repository's automated procedures work and the website) glossary & secondary features (anything related to the glossary, such as new or updated terms or other secondary features) general, typos, misc. & meta (everything else, typos, general stuff and meta files in the repository - e.g. the issue template) guidelines i have read the guidelines in the contributing document. </desc> <cmt> adding heron's formula for area of a triangle </cmt> <cmt> tagging heron as math, beginner </cmt>",adding heron's formula for area of any triangle
2339,"<desc> this pr completes any previously missing pytorch model counterparts to tfmodels in examples/models. it also makes sure, all example scripts in the rllib/examples folder are tested for both frameworks and learn the given task (this is often currently not checked) using a --as-test flag in connection with a --stop-reward. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fixes and lint. </cmt> <cmt> fix and lint. </cmt> <cmt> fix and lint. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt>  conflicts: </cmt> <cmt> 	rllib/examples/batch_norm_model.py </cmt> <cmt> 	rllib/examples/custom_fast_model.py </cmt> <cmt> 	rllib/examples/hierarchical_training.py </cmt> <cmt> 	rllib/examples/multi_agent_cartpole.py </cmt> <cmt> 	rllib/examples/twostep_game.py </cmt>",examples folder restructuring (model examples; final part).
2340,"<desc> the current nightly test for ray wheel urls is flaky because sometimes mac wheels take a long time to build, see #19331. this pr retries the urls every 10 minutes until all the urls are available, for up to 120 minutes.  the 120 minute figure comes from the fact that mac wheels sometimes take close to 2 hours to show up in the aws bucket, see e.g.  #19331 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> retry urls every 10 min for 90 minutes </cmt> <cmt> increase cluster timeout to 100min </cmt> <cmt> up retries from 90m to 2 hours </cmt>",retry wheel urls for up to 2h to give time for mac wheels to build
2341,"<desc> split out from #68241. this prints the correct effect diff for each line (the before-effect and the after-effect) and makes marginal improvements to the graphviz output for the new dataflow framework including using monospaced font and better line breaking. this will only be useful when #68241 is merged and the graphviz output changes from this: to this: r? @wesleywiser </desc> <cmt> print after effect in default graphviz formatter </cmt> <cmt> now the line for each statement will show the diff resulting from the </cmt> <cmt> combination of before_statement_effect and statement_effect. it's </cmt> <cmt> still possible to observe each in isolation via </cmt> <cmt> borrowck_graphviz_format = ""two_phase"". </cmt> <cmt> add option to dot::render for monospace font </cmt> <cmt> remove unnecessary allows </cmt> <cmt> don't break first line </cmt> <cmt> use nicer alignment when printing state vectors </cmt>",small graphviz improvements for the new dataflow framework
2342,<desc> resolves #8858 resolves #8916 </desc> <cmt> fix cmake param in build eosio for all platforms </cmt> <cmt> add caution message to avoid changing eosio_build_location </cmt> <cmt> fix typo in amazon linux 2 manual build instructions </cmt> <cmt> remove pinned instructions for manual builds </cmt> <cmt> rename unpinned build platform files </cmt> <cmt> update index file for manual build platforms </cmt> <cmt> remove unpinned references in build platform files </cmt>,updates to manual build instructions
2343,<desc> description: follows the general trend of moving things into components with config flow's. related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): weather: - platform: ipma checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> initial version </cmt> <cmt> works </cmt> <cmt> lint </cmt> <cmt> move </cmt>,move weather.ipma into a component
2344,<desc> mostly this was to make sure we're using the final releases of those fbjs versions but looked at other things and cleaned up. </desc> <cmt> remove jsx task & jsx-internal script </cmt> <cmt> these haven't been used in a long time so it's time to get rid of them. </cmt> <cmt> upgrade fbjs </cmt> <cmt> upgrade browserify </cmt>,"upgrade a few package dependencies, remove unused task"
2345,"<desc> backport of #71580 change: fix up wording and do proper backports for porting guide entries. </desc> <cmt> [docs] fix up porting guides for cve revert </cmt> <cmt> change: </cmt> <cmt> - fix up wording and do proper backports for porting guide entries. </cmt> <cmt> (cherry picked from commit ed48a2dd624cb7feb874fddcf49ef538857cd3e6) </cmt> <cmt> remove original, non-backported version </cmt>",fix up porting guides for cve revert [2.9]
2346,"<desc> only works for unoptimized / uncompressed builds. implements a simplistic lexer that makes some assumptions about the lexed source (as described in comments). this should be much faster than running a full parser. i've separated out the addition of the source-map library as a separate commit, so you can review a cleaner diff by looking at the second commit alone. </desc> <cmt> commit the source-map library. </cmt> <cmt> implement basic source maps. closes #1252. </cmt>",implement basic source maps. refs #1252.
2347,"<desc> this pr contains commits that add / update scripts required to setup the rocm community supported build (csb). @gunan , please review the tensorflow/tools/ci_build/linux/rocm/run_csb_tests.sh. it is based on your recommendation of the bazel test command to use, and will be the script we use for our csb. @tatianashp @whchung @parallelo @gunan </desc> <cmt> adding a script for testing the rocm community supported build </cmt> <cmt> updating that parallel_gpu_execute.sh script such that it works as expected for amd gpus </cmt> <cmt> adding rocm support in the build_pip_package script </cmt> <cmt> adding/updating rocm support in the ci_build scripts </cmt>",script updates for the rocm csb build
2348,"<desc> backport of #18618. xref #18601. sub-modules, such as np.linalg, must be explicitly imported in the main namespaces' stub file if one wants to access the sub-module via a getattr operation, i.e. so that one can directly use np.linalg.norm rather than import numpy.linalg; np.linalg.norm. while this was taken care of in the main numpy namespace, the relevant annotations were missing for others such as np.lib.*. this pr fixes aforementioned issue. examples the behavior prior to this pr: >>> import numpy as np >>> x = np.arange(6) >>> out = np.lib.stride_tricks.sliding_window_view(x, 3) mypy output: test.pyi:4:7: error: module has no attribute ""stride_tricks""  [attr-defined] </desc> <cmt> api: formally classify np.lib.stride_tricks as part of the public api </cmt> <cmt> with as_strided, and the newly introduced sliding_window_view function, there are currently 2 public objects that can: </cmt> <cmt> a. only be imported from a private module </cmt> <cmt> b. are publicly documented to-be imported from aforementioned module </cmt> <cmt> both observations are problematic and in need of rectification. </cmt> <cmt> this commit therefore moves np.lib.stride_tricks to the public_modules list. </cmt> <cmt> maint: re-export a number of sub-modules </cmt> <cmt> ensures that type checkers will allow the likes of: </cmt> <cmt> >>> import numpy as np </cmt> <cmt> >>> out = np.lib.stride_tricks.sliding_window_view(...) </cmt> <cmt> api: move polynomial.polyutils to the private_but_present_modules list </cmt> <cmt> aforementioned module was accidently marked as public </cmt>",ensure that re-exported sub-modules are properly annotated
2349,<desc> issue: #9507 removed legacy data and apis from story store. updated getstorybook to use _data (hopefully works the same) added migration notes see tests. try some example storybooks. </desc> <cmt> clean up story store and remove legacy data </cmt> <cmt> fixes #9507 </cmt> <cmt> add migration notes about changes </cmt>,remove legacy data from story store
2350,<desc> restricted to only files just needed you can use assetsmanager within javascript. multiple assetsmanagers support. script package / resource package / promotion package / ... </desc> <cmt> added jsb support for assetsmanager </cmt> <cmt> purgestoragepath added </cmt> <cmt> key with hash to support multiple assetsmanager </cmt> <cmt> delegateprotocol is weak-referenced again </cmt> <cmt> applied cocos2d-x coding style </cmt> <cmt> style edited </cmt>,exposed assetsmanager to javascript and added multiple-assetsmanager support
2351,<desc> this adds a conversion layer from any prior cached results in the database that were created via ptrees to be rapidjson arrays. we do so by setting a database results version flag while processing differentials in query results to ensure we only upgrade result schemas once. this addresses #4206 </desc> <cmt> bug: updating database ptree entires to rapdijson </cmt> <cmt> unit test for database upgrade </cmt> <cmt> fixing up logic to leverage results version flag </cmt>,convert cached ptree entires to rapidjson results
2352,"<desc> addresses #2931, approximately following the suggestions of @gkatsev in the discussion on #3433.  adds named export setformattime  to utils/format-time.js. allows overwriting the standard format-time implementation with a custom function, which will be called with seconds and guide as arguments. also exposes setformattime on videojs. example: videojs.setformattime((seconds, guide) => ${seconds}, ${guide})); change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) </desc> <cmt> add option to override format-time with custom implementation. </cmt> <cmt> added named export setformattime to time-format.js, which replaces the original function with a custom implementation. </cmt> <cmt> addresses issue #2931 </cmt> <cmt> fix lint errors, add jsdoc comments </cmt> <cmt> addresses issue #2931 </cmt> <cmt> add test for setformattime </cmt> <cmt> issue #2931 </cmt>",add an option to override format-time (#2931)
2353,"<desc> small change regarding the default precision, making it 3 (milliseconds will be returned) from previous value of 0. fixes #39288. </desc> <cmt> change the current_timestamp precision from 0 to 3. </cmt> <iss> sql: change the default precision for current_timestamp </iss>",change the default precision for current_timestamp function
2354,"<desc> original pull-request #24898 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> allowed s3 key to be empty. </cmt> <cmt> fixed unit tests accoording to the fix. </cmt> <cmt> fix. </cmt>",fixed bug with declaring s3 disk at root of bucket
2355,"<desc> @jasonbahl this caches introspection queries between builds as well as an md5 of the query response. the hash of the last builds query response is checked against the hash from the current build. if they're different, i recursively regenerate gql queries (to be used in requesting data from wpgql), if they're the same i use cached queries that were generated in the last build. i also store wether or not the schema has changed in redux so that if it has changed i can pull all nodes again later in the plugin, since we don't know if the data shape is the same. if needed, this could later be refactored to track the schema of each individual type and only invalidate cached nodes if their part of the schema changes. for now i'm doing it this way for the mvp </desc> <cmt> add extra safety checks </cmt> <cmt> refactor </cmt> <cmt> update local url </cmt> <cmt> refactor scripts </cmt> <cmt> cache queries and check if the schema has updated </cmt>",cache queries and monitor for schema changes [gatsby-source-wordpress]
2356,"<desc> this pr bumps graphql-js major from v14 to v15 and graphql-compose from v6 to v7 closes #25906 </desc> <cmt> chore: bump graphql major version </cmt> <cmt> fix graphql-compose deprecations </cmt> <cmt> graphql-compose: fix args mapping for directives </cmt> <cmt> graphql-compose: fix incorrect type merging </cmt> <cmt> new version of graphql-compose adds type composers added via createtemp to schemacomposer. so before the upgrade schemacomposer.has(typename) always returned false for temp types, now it returns true (as the temp composer is already added). </cmt> <cmt> graphql-compose: fix merged type assignment </cmt> <cmt> in the new version of graphql-compose the list of actual final types is stored in schemacomposer itself, not typemapper. also the same composer may have multiple keys </cmt> <iss> support new graphql major (15) </iss>",bump graphql and graphql-compose major versions
2357,<desc> addresses #591 </desc> <cmt> upgrade jacoco version to fix the uuid initialization problem #591 </cmt> <cmt> load ee module to make ee classes available on classpath #591 </cmt> <cmt> turn forking on to prevent datanucleus from missing a jdk 9 module #591 </cmt> <cmt> add another jdk 9 module to prevent class not found errors #591 </cmt>,configuration changes needed to run tests on java 9
2358,"<desc> these reverts #7766 it fixes #7630 in a different way and also fixes #7951. </desc> <cmt> add failing spec for window size after restore </cmt> <cmt> revert ""incorrect position when restored from maximize-on-top-drag under windows #7630"" </cmt> <cmt> this reverts commit a2b3abbf47f2adc8f945f3e12ce6f756670d03ca. </cmt> <cmt> fix maximize --> unmaximize positioning issue </cmt> <iss> incorrect position when restored from maximize-on-top-drag under windows </iss> <iss> windows: restore (after minimize) to wrong window size </iss>",fix incorrect window size after restore on windows
2359,<desc> simplification of the spec handling for asyncmock and correction for how spec_set is handled. </desc> <cmt> port tests from original pr </cmt> <cmt> port tests from original pr </cmt> <cmt> minor fixes </cmt> <cmt> remove extraneous tests </cmt> <cmt> remove extraneous test </cmt>,minor fixes to asyncmock spec handling
2360,"<desc> also logs a message when defaulting, and a warning when using a prerelease build of react-dom (e.g. the react 18 alpha) which are not officially supported. note: i've done this in webpack-config.ts instead of the next.js config, as we don't actually want you to be able to opt-out without downgrading back to react 17, and so it ought to be entirely removed from the config eventually. </desc> <cmt> use createroot if detected </cmt>",automatically use createroot for react@>=18
2361,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo: coverage service link (codecov, coveralls, gocover etc.) very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> add dasel to data-structures </cmt> <cmt> add dasel to devops tools </cmt> <cmt> remove dasel from data-structures </cmt> <cmt> update dasel description </cmt>",update dasel description and change category
2362,"<desc> new features others add gen_bkcl_id_op for multi baidu kunlun cards training support fleet api for multi baidu kunlun cards training </desc> <cmt> dygraph supports multi xpu card training </cmt> <cmt> add bkcl_context_test and fix error messages (#1) </cmt> <cmt> fix xpu fill_constant place, to_tensor place </cmt> <cmt> mulit xpu dygraph (#2) </cmt> <cmt> add xpudeviceguard </cmt> <cmt> fix multi xpu dygraph (#3) </cmt> <cmt> * fix some uts' interfaces </cmt> <cmt> * add todos and fix err_messages </cmt> <cmt> fix copy </cmt> <cmt> fix getdeviceid </cmt> <cmt> add gen_bkcl_id_op, test=notest </cmt> <cmt> fix,test=notest </cmt> <cmt> fix,test=notest </cmt> <cmt> fix,test=notest </cmt> <cmt> fix,test=notest </cmt> <cmt> fix </cmt> <cmt> fix test_gen_bkcl_id_op.py </cmt> <cmt> merge upstream/develop </cmt>","add gen_bkcl_id_op, support multi xpu cards training using multiprocess"
2363,<desc> added logic to net_plugin_impl and connection classes to support security group in privacy features. select one: select any that apply: </desc> <cmt> epe-721: add connection management </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> epe-672: add security group to net_plugin </cmt> <cmt> added the security_group_manager class to net_plugin and added logic </cmt> <cmt> to handle connections that are and are not participating in a </cmt> <cmt> security group. </cmt>,add security group participant message handling to net_plugin
2364,<desc> i hereby agree to the terms of the cla available at:  category: doc fixes ('ru'). changes description: adding description of the check table query. ordering miscellaneous queries by alphabet. </desc> <cmt> translation for check table query to russian </cmt> <cmt> fix link to nowhere </cmt>,adding description of the check table query to the 'ru' doc
2365,"<desc> improvement covered both auto bindings and manual bindings all changes follow generational gc style for #12405 </desc> <cmt> improve js template documentation </cmt> <cmt> remove useless manual bindings for menuitems </cmt> <cmt> solve a possible memory leak in httprequest </cmt> <cmt> remove useless manual bindings for addeventlistener functions in ui </cmt> <cmt> use js::persistentrooted instead of js::heap to prevent delegates and wrappers internal js object from gc </cmt> <cmt> more elegant and secured way, potential crashes exists in previous implementation </cmt> <cmt> clean up manual bindings code, remove js_this_object and js_set_rval </cmt>",improved js bindings with more secured memory management
2366,"<desc> this pull request removes the blog feature (and all the other stuff that goes along with it) from the website folder. addresses #5238 </desc> <cmt> update ma' fork </cmt> <cmt> initial setup of docusaurus (#5227) </cmt> <cmt> remove the blog link from the header </cmt> <cmt> remove blog link from the site footer </cmt> <cmt> remove blog translation, as we no longer have a blog </cmt> <cmt> remove all sample blog-content </cmt> <cmt> remove blog info from the website readme </cmt>",5238 removing blog from docusaurus
2367,"<desc> adds generatecontextapispec gradle task that generates whitelist api specs under modules/lang-painless/src/main/generated/whitelist-json. the common classes are in painless-common.json, the specialized classes per context are in painless-$context.json. eg. painless-aggs.json has the specialization for the aggs contexts </desc> <cmt> scripting whitelist api spec: add generatecontextapispec task </cmt> <cmt> scripting whitelist api spec: find common classes </cmt> <cmt> scripting whitelist api spec: generate common.json </cmt> <cmt> scripting whitelist api spec: handle arrays for parameters and return values </cmt> <cmt> scripting whitelist api spec: handle arrays for static methods </cmt> <cmt> scripting whitelist api spec: handle arrays for constructors </cmt> <cmt> scripting whitelist api spec: handle arrays for fields </cmt> <cmt> scripting whitelist api spec: change $ internal names to display names </cmt> <cmt> scripting whitelist api spec: generate rest of the contexts </cmt>",whitelist api spec gradle task
2368,<desc> i'm working on getting these into master (#22580 and #22579) but i'd really like to have them in tensorflow asap because they make the colab autocomplete very crashy. </desc> <cmt> repl completer crash while defining struct </cmt> <cmt> invalid unary ops crash repl completer </cmt>,cherry-pick some autocomplete crasher fixes into tensorflow
2369,"<desc> bpo-33789: test_asyncio: fix resourcewarning (gh-7460) bpo-33789, test_asyncio: hide pendingdeprecationwarning (gh-7461) bpo-32676, test_asyncio: fix warning in test_error_in_call_soon() (gh-7462) </desc> <cmt> bpo-33789: test_asyncio: fix resourcewarning (gh-7460) </cmt> <cmt> * close sockets and streams to fix resourcewarning warnings </cmt> <cmt> * catch also oserror to hide a traceback on an expected handshake </cmt> <cmt> error </cmt> <cmt> (cherry picked from commit 0eba7c39132614a5730cda6b340e18dfb2d30d14) </cmt> <cmt> bpo-33789, test_asyncio: hide pendingdeprecationwarning (gh-7461) </cmt> <cmt> hide pendingdeprecationwarning in test__register_task_3(). </cmt> <cmt> (cherry picked from commit 7ed61e9431ee2c191aeeeb26f86a71bb90ab99fd) </cmt> <cmt> bpo-32676, test_asyncio: fix warning in test_error_in_call_soon() (gh-7462) </cmt> <cmt> fix ""<corowrapper ...> was never yielded from"" warning in </cmt> <cmt> pytask_pyfuture_tests.test_error_in_call_soon() of </cmt> <cmt> test_asyncio.test_tasks. </cmt> <cmt> close manually the coroutine on error. </cmt> <cmt> (cherry picked from commit 9f04f0df6fdb27190690bda949d213893d14e807) </cmt>",backport test_asyncio fixes from master
2370,"<desc> issue raised in dockerode repo: apocas/dockerode#464 when using the run command, to split the stdout and stderr, an array of streams should be passed in as the 3rd parameter of the run command. optionally you can pass in a single stream as well. </desc> <cmt> add array of streams option to run command. </cmt> <cmt> re-add import back in. </cmt>",dockerode - allow passing in array of streams to run command.
2371,"<desc> breaking change: after the discovery of some additional commands, client library now has much better tracking of tv power state. as a result of the client library changes, the standby_connection parameter is no longer needed/present (since the relevant behaviour can be steered automatically by the client library now) description: all standby and suspend modes are currently propagated to home assistant as ""off"", and all other states as ""on"" in order to preserve proper ui behaviour. this also fixes #30999 documentation update in home-assistant/home-assistant.io#11838 </desc> <cmt> upgrade to aiopylgtv 0.3.0 and corresponding simplification and cleanup of webostv state tracking </cmt> <cmt> properly handle case where live tv is not reported in list of apps </cmt> <iss> webos integration now displaying 'live tv' in source list... </iss>",improve state tracking for webostv
2372,<desc> fixes #7145. connect internally strips trailing slash. but we need to also do this during hmr. </desc> <cmt> fix(server): strip trailing slash from middleware </cmt> <cmt> builder: show / for hmr log </cmt> <cmt> chore: remove unreachable condition </cmt> <iss> hmr for servermiddleware fails if sub-app is registered without prefix </iss>,hmr for sub-app servermiddleware without path
2373,"<desc> cherry pick of #104384 #104382 on release-1.21. #104384: fix: skip case sensitivity when checking azure nsg rules #104382: fix: ensure instanceshutdownbyproviderid return false for for details on the cherry pick process, see the cherry pick requests page. fix: skip case sensitivity when checking azure nsg rules fix: ensure instanceshutdownbyproviderid return false for creating azure vms </desc> <cmt> fix: skip case sensitivity when checking azure nsg rules </cmt> <cmt> fix: ensure instanceshutdownbyproviderid return false for creating azure vms </cmt>","fix: skip case sensitivity when checking azure nsg rules
#104382: fix: ensure instanceshutdownbyproviderid return false for"
2374,"<desc> make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, ""[airflow-xxx] my airflow pr""  in case you are fixing a typo in the documentation you can prepend your commit with [airflow-xxx], code changes always need a jira issue. in case you are proposing a fundamental code change, you need to create an airflow improvement proposal (aip). in case you are adding a dependency, check if the license complies with the asf 3rd party license policy. update example dags of emr to context manager and bitshift composition. my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from ""how to write a good git commit message"": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (""add"", not ""adding"") body wraps at 72 characters body explains ""what"" and ""why"", not ""how"" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 </desc> <cmt> [airflow-5398] - update emr example dags to context manager </cmt> <cmt> [airflow - 5398] update emr example dags to context manager </cmt>",update contrib example dags to context manager
2375,"<desc> instead of doing it ourselves use the pflags version.  makes our code smaller, cleaner, more readable, less casting etc. </desc> <cmt> convert for util.ip to just use a net.ip </cmt> <cmt> pflag can handle ip addresses so use the pflag code instead of doing it </cmt> <cmt> ourselves. this means our code just uses net.ip and we don't have all of </cmt> <cmt> the useless casting back and forth! </cmt> <cmt> use pflag ipnet instead of our own helpers </cmt> <cmt> since pflag can handle net.ipnet arguements use that code. this means </cmt> <cmt> that our code no longer has casts back and forth and just natively uses </cmt> <cmt> net.ipnet. </cmt>",use pflags for net.ip and net.ipnet instead of custom flag types
2376,"<desc> right now we're exiting on the very first error. this is not in line with other test-like tasks we have (e.g. yarn lint or yarn test:unit). it also hid a more severe issue #23627. docs: src/pages/components/drawers/persistentdrawerleft.tsx(88,19): error ts2554: expected 1 arguments, but got 0. --  @material-ui/core: ../material-ui-utils/src/deepmerge.ts(2,3): error ts2322: type 'unknown' is not assignable to type 'boolean'. --  closes #23627 </desc> <cmt> [core] don't bail on monorepo typescript task </cmt> <cmt> revert later run with ts 4.1 </cmt> <cmt> [utils] fix deepmerge return type for falsy inputs </cmt> <cmt> [styles] fix usestyles requiring props in ts 4.1 </cmt> <iss> makestyles overload breakage with typescript 4.1 </iss>",add support for typescript 4.1
2377,"<desc> a few changes in src/core/main.c: fix crash when crashchangevt is specified in config. a couple of changes to crash handler behavior. an error message reworded. </desc> <cmt> core: adjust error message about /etc/mtab </cmt> <cmt> since having /etc/mtab as a regular file is now a fatal error, stop </cmt> <cmt> mentioning irrelevant minor consequences. </cmt> <cmt> core: remove spurious assert in parsing crashchangevt= </cmt> <cmt> ""data"" is always null (and unused) in config_parse_crash_chvt(). </cmt> <cmt> core: change how crash_shell and crash_reboot interact </cmt> <cmt> instead of freezing in pid1 and letting the forked child freeze or </cmt> <cmt> reboot when exec(""/bin/sh"") fails, just wait for the child's </cmt> <cmt> exit and then do the freeze_or_reboot in pid1 as usual. </cmt> <cmt> this means that when both crash_shell and crash_reboot are enabled, the </cmt> <cmt> system will reboot after the shell exits. </cmt> <cmt> core: always let the kernel reap zombies when we're about to freeze </cmt> <cmt> regardless of whether we're going to spawn a crash shell or not, let the </cmt> <cmt> kernel reap zombies. it's more consistent this way. </cmt>","crash handler changes, crashchangevt parsing fix"
2378,"<desc> github makes own copies of images referenced in readme, and that fails for large image sizes. the gif has 6mb and so is over the threshold. instead of using an off-github image, use the same image uploaded to user-images.githubusercontent.com. this makes github show the image even when it's very large. this reverses #11170 and finalizes #11158. </desc> <cmt> remove broken image in readme </cmt> <cmt> github makes copies of images referenced in readme, and it fails for large image sizes. the gif has 6mb and so is over the threshold. </cmt> <cmt> this removes the image until i can figure out how to reinsert it so that it shows. </cmt> <cmt> re-add the hot-reload gif animation </cmt> <cmt> instead of using an off-github image, use the same image uploaded to user-images.githubusercontent.com. this makes github show the image even when it's very large (our animation gif is 6mb). </cmt>",fix missing animated gif in readme
2379,"<desc> this pr expands the meaning of include_global_state for snapshots to include system indices. if include_global_state is true on creation, system indices will be included in the snapshot regardless of the contents of the indices field. if include_global_state is true on restoration, system indices will be restored (if included in the snapshot), regardless of the contents of the indices field. index renaming is not applied to system indices, as system indices rely on their names matching certain patterns. if restored system indices are already present, they are automatically deleted prior to restoration from the snapshot to avoid conflicts. this behavior can be overridden to an extent by including a new field in the snapshot creation or restoration call, feature_states, which contains an array of strings indicating the ""feature"" for which system indices should be snapshotted or restored. for example, this call will only restore the watcher and security system indices (in addition to index_1): post /_snapshot/my_repository/snapshot_2/_restore { ""indices"": ""index_1"", ""include_global_state"": true, ""feature_states"": [""watcher"", ""security""] } if feature_states is present, the system indices associated with those features will be snapshotted or restored regardless of the value of include_global_state. all system indices can be omitted by providing a special value of none (""feature_states"": [""none""]), or included by omitting the field or explicitly providing an empty array (""feature_states"": []), similar to the indices field. the list of currently available features can be retrieved via a new ""get snapshottable features"" api: get /_snapshottable_features which returns a response of the form: { ""features"": [ { ""name"": ""tasks"", ""description"": ""manages task results"" }, { ""name"": ""kibana"", ""description"": ""manages kibana configuration and reports"" } } features currently map one-to-one with systemindexplugins, but this should be considered an implementation detail. the get snapshottable features api and snapshot creation rely upon all relevant plugins being installed on the master node. further, the list of feature states included in a given snapshot is exposed by the get snapshot api, which now includes a new field, feature_states, which contains a list of the feature states and their associated system indices which are included in the snapshot. all system indices in feature states are also included in the indices array for backwards compatibility, although explicitly requesting system indices included in a feature state is deprecated. for example, an excerpt from the get snapshot api showing feature_states: ""feature_states"": [ { ""feature_name"": ""tasks"", ""indices"": [ "".tasks"" } ], ""indices"": [ "".tasks"", ""test1"", ""test2"" relates #61657 </desc> <cmt> add plugin name to systemindexplugin </cmt> <cmt> use plugin name for system index descriptor map </cmt> <cmt> add pluginstates to create and restore snapshot requests </cmt> <cmt> plumb system index descriptor map into snapshotsservice </cmt> <cmt> remove unnecessary comment </cmt>","introduce ""feature states"" for managing snapshots of system indices"
2380,"<desc> test and fix for #2420 ensures that the recursive type-checking of new graphql fields added by plugins does not infinitely recur when types contain circular references. the solution used is to simply track the set of types during a traversal, aborting at the first instance of circularity, yet preserving the functionality of input type inference up until that point. </desc> <cmt> add failing test for recursive custom fields </cmt> <cmt> track visited types during field recursion to prevent infinite loop </cmt>",prevent infer input fields infinite recursion
2381,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). docs for net.server.address docs for ws.address cleartextstream was removed 10 major versions ago increase the version number in the header if appropriate. n/a if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. n/a two open questions before this gets merged. one, is it ok to make changes to multiple packages in one pr?  the update to ws is what i actually wanted to make but doing so required exposing the interface from node.  changing the function signature in node broke tests on several other packages, so i fixed those at the same time. i can submit separate prs if need be. two, is there a convention about where to put named interfaces for structures that aren't named in the actual library being described?  node does not actually define an addressinfo type anywhere in its codebase or documentation, but it's an object shape that's used in many places so it makes sense to have one in the typings.  i'm just not sure where it belongs.  i moved it into net because that made sense to me. </desc> <cmt> node: cleartextstream hasn't existed for 3 years </cmt> <cmt> node: move addressinfo to net module; address() can return string </cmt> <cmt> ws: server.address() can return string (same as net.server.address etc) </cmt>",address() method on server and related classes can return a string
2382,"<desc> some assorted stuff i noticed while reviewing #6236. </desc> <cmt> mount: fix potential bad memory access when /proc/self/mountinfo is empty </cmt> <cmt> it's unlikely this can ever be triggered, but let's be safe rather than </cmt> <cmt> sorry, and handle the case where the list of mount points is zero, and </cmt> <cmt> the ""l"" array thus null. let's ensure we allocate at least one entry. </cmt> <cmt> mount: rework find_loop_device() to log about no errors </cmt> <cmt> we should either log about all errors in a function, or about none (and </cmt> <cmt> then leave the logging about it to the caller who we propagate the error </cmt> <cmt> to). given that the callers of find_loop_device() already log about the </cmt> <cmt> returned errors let's hence suppress the log messages in </cmt> <cmt> find_loop_device() itself. </cmt> <cmt> mount: add debug logging for the case when we knowingly ignore an error </cmt> <cmt> mount: change find_loop_device() error code when no loop device is found to enxio </cmt> <cmt> enoent is a bit too likely to be returned for various reasons, for </cmt> <cmt> example if /sys or /proc are not mounted and hence the files we need not </cmt> <cmt> around. hence, let's use enxio instead, which is equally fitting for the </cmt> <cmt> purpose but has the benefit that the underlying calls won't generate </cmt> <cmt> this error on their own, hence any ambiguity is removed. </cmt> <cmt> mount: add missing validation error message </cmt> <cmt> we really should generate exactly one log message for each error, hence </cmt> <cmt> let's do that in this one case too. </cmt>",a bunch of mini fixes for mount-tool.c
2383,"<desc> some random cleanups picked out of pr #49. </desc> <cmt> util: introduce {send,receive}_one_fd() </cmt> <cmt> introduce two new helpers that send/receive a single fd via a unix </cmt> <cmt> transport. also make nspawn use them instead of hard-coding it. </cmt> <cmt> based on a patch by krzesimir nowak. </cmt> <cmt> nspawn: close unneeded sockets in outer child </cmt> <cmt> (david: note, this is just a cleanup and doesn't fix any bugs) </cmt> <cmt> nspawn, machined: fix comments and error messages </cmt> <cmt> a bunch of ""client -> child"" fixes and one barrier-enumerator fix. </cmt> <cmt> (david: rebased on master) </cmt>","util, nspawn, machined: random cleanups"
2384,"<desc> dawn 4.0 changes the code of the existing exceptions and this causes a mismatch with the error advice given by cleos. this causes confusion when understanding the given error advice. this pr rematch the error code with the error advice. at the same time, this pr also changes the reference from account_history_api_plugin in cleos to history_api_plugin since the former is obsolete. #3067 </desc> <cmt> update cleos mismatched error advice </cmt> <cmt> update outdated error advice </cmt> <cmt> change account history api plugin reference in cleos httpc to history api plugin </cmt>",fix mismatch error code with cleos error advice on dawn 4.0
2385,<desc> this commit enables the copydockerfile task to render a dockerfile that sources the elasticsearch binary from artifacts.elastic.co. this is needed for reproducibility and transparency for the official docker images in the docker library. relates #38552 (backport) </desc> <cmt> enable dockerfile from artifacts.elastic.co </cmt> <cmt> this commit enables the copydockerfile task to render a dockerfile that </cmt> <cmt> sources the elasticsearch binary from artifacts.elastic.co. this is </cmt> <cmt> needed for reproducibility and transparency for the official docker </cmt> <cmt> images in the docker library. </cmt> <cmt> add comment </cmt>,enable dockerfile from artifacts.elastic.co 6.7
2386,"<desc> original pull-request #27383 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix </cmt> <cmt> fix flacky test </cmt>",cherry pick #27383 to 21.7: fix flacky test
2387,"<desc> restore iuo bridging behavior on swift-5.0-branch. </desc> <cmt> restore implicitlyunwrappedoptional extension conforming to _objectivecbridgeable. </cmt> <cmt> partial revert of 26f6a751c4dc97383f35bc2d913317df15b54c15. </cmt> <cmt> removing this breaks bridging these values to objective c. once iuos </cmt> <cmt> are removed from the type system and implicitlyunwrappedoptional<t> is </cmt> <cmt> removed from the library, we'll be strictly using optional<t> which </cmt> <cmt> has this conformance as well. </cmt> <cmt> fixes: rdar://problem/36477954, </cmt> <cmt> revert ""iuo: update protocol conformance checking to check iuo attr on decl."" </cmt> <cmt> this reverts commit ec5cebd4d6bcecce2014c88fa4a4afa010a3ddf8. </cmt> <cmt> the way it's implemented is problematic when we still have iuos in the </cmt> <cmt> type system and library. </cmt> <cmt> we end up thinking there are mismatches between requirements and </cmt> <cmt> potential witnesses when there are not. </cmt> <cmt> add runtime tests for bridging optionals and iuos. </cmt>",fix iuo bridging swift 5.0 branch
2388,"<desc> ok, looks like no real changes are needed to support retina devices. we can add an option to iosapplicationconfiguration in the future to allow someone to take full advantage of retina. for now, retina devices simply return the same dimensions (called ""points"" not ""pixels"") as the non-retina displays. on retina devices 1 point = 2 pixels (non retina: 1 point = 1 pixel). here are the changes: getdensity() + getppi() implemented (via help from wikipedia) build-natives.sh fixed (no arm6 anymore!) all convert.xml updated (use env.ivkm_home now) all 3 demo projects updated: 2 of them working, for vectorpinpall i get the following error: ""warning: the referenced library 'gdx-backend-ios.dll' is not used from any code, skipping extraction of content resources. (gdx-vectorpinball-ios)"" - i couldn't figure out what's wrong? iosapplicationconfiguration has now config options for landscape/portrait in any case, that completes your requests for ios :)  i'll look over missing stuff in the ios backend. looks like properties is missing for example. otherwise, i think it's pretty much ready to go besides the build scripts. it's going to be a pain to setup. maybe i look into that? anything special planned for the build scripts to make them easy to use (for others)? </desc> <cmt> shouldautorotatetointerfaceorientation implemented. </cmt> <cmt> removed arm6 (not supported anymore via xcode). path update: ""/developer/usr/bin/xcodebuild"" -> ""xcodebuild"" </cmt> <cmt> iosapplicationconfiguration updated: landscape/portrait update. </cmt> <cmt> convert.xml uses env.ikvm_home now! </cmt> <cmt> all 3 demo projects using ios updated. </cmt> <cmt> note: cannot get vector pinball to work. i get the following error. not sure how to fix!? </cmt> <cmt> ""warning: the referenced library 'gdx-backend-ios.dll' is not used from any code, skipping extraction of content resources. (gdx-vectorpinball-ios)"" </cmt> <cmt> iosgraphics returns density & ppi values now. that ""completes"" the retina update for now. there are actually no changes needed to get apps to work on retina enabled devices. </cmt> <cmt> note: we could add a flag to iosapplicationconfiguration in the future to allow apps to take full advantage of retina. for now all apps will work on both retina and non-retina devices without code changes :) </cmt>",retina support + misc. other changes
2389,"<desc> libweb: expose element.{prefix,localname} libweb: make element::tag_name return the html uppercased qualified name i forgot to change tag_name when this was added. also makes html_uppercased_qualified_name return a const reference. </desc> <cmt> libweb: expose element.{prefix,localname} </cmt> <cmt> libweb: make element::tag_name return the html uppercased qualified name </cmt> <cmt> i forgot to change tag_name when this was added. </cmt> <cmt> also makes html_uppercased_qualified_name return a const reference. </cmt>","expose element.{prefix,localname} and fix element.tagname"
2390,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> morgan: correct morgan function signature </cmt> <cmt> morgan: enable strictnullchecks, add linting </cmt> <cmt> morgan: add definitions author </cmt>","fix function signature, enable strictnullchecks, enable linting"
2391,"<desc> as discussed in #173 summary this pr introduces one command vue build and three options --port --prod/production --local --config outputs to ./dist by default using buble-loader respect user config, you can populate them at ~/.vue/config.js (cli options) and ~/.vue/webpack.config.js (webpack config to merge) check out doc for more. i choose ~/.vue directory instead of file ~/vue.config.js, in a directory you can install loaders and modules there, so that you don't need to install them again in your project what's not ready no auto install, it could be buggy imo still need to add vue build counter.vue magic still need to add some custom css preprocessors for sfc, so that user only need to install relevant loader extract css allow to have project-specific config at project directory, use --config and --webpack to switch, for example --config config.js, and --webpack webpack.config.js tests what do you think? </desc> <cmt> add vue-build </cmt> <cmt> add production mode and custom config </cmt> <cmt> fix lint </cmt>","add vue build command, closed #173"
2392,"<desc> this pr fixes #3629 , and fixes the r package ci to be sure that similar issues don't arise in the future. also fixes #3616 for ci, i'm proposing that instead of having a limit on the number of r cmd check notes, we just ignore very specific notes that we know are not problematic for cran. i think that will be less susceptible to issues like #3629 and give us more confidence that ci is catching problems that would be caught by cran. this is blocking release 3.1.1 (#3611) </desc> <cmt> [ci] [r-package] fix issue with partial argument name matches </cmt> <cmt> fix partial name matches </cmt> <iss> [ci] [r-package] r ci jobs on mac, linux do not always fail if unit tests fail </iss> <iss> [r-package] r cmd check note 'partial argument match' </iss>",fix partial matching of keyword arguments in lgb.cv() (fixes #3629)
2393,"<desc> fix broken link on 3-1 readme files related to #514 issue </desc> <cmt> fix small typo, links and reference fr assignment </cmt> <cmt> fix small typo, links and reference french assignment </cmt> <cmt> fix: add loc param and reference fr assignment </cmt> <cmt> add localization parameter on quizzes links and reference fr assignment </cmt> <cmt> fix localization param </cmt> <cmt> fix localization param </cmt> <cmt> fix broken link on 3-1 readme files </cmt>",suggest broken link fix on 3-1 readme files
2394,"<desc> this pr addresses several issues on windows with paths containing special characters. the source of some of those issues is a slash package which explicitly declares that it only works with ascii paths (see sindresorhus/slash#5). we already have a pr addressing one specific issue in gatsby-source-filesystem (#14372) but many places are affected (including core gatsby package). this pr moves slash util into gatsby-core-utils and replaces slash usages. it also fixes an issue with invalid graphql query names generated from such paths, see #4565 (comment). p.s. not sure what would be the right pr name when it affects multiple packages from monorepo? #4565 #13882 #13865 #14126 #17746 #17746 #19108 </desc> <cmt> generate spec-compliant graphql query names </cmt> <cmt> move slash util from gatsby-source-filesystem to gatsby-core-utils </cmt> <cmt> replace slash package in plugins with a slash util from gatsby-core-utils </cmt> <cmt> refactor: uppercase windows drive letter </cmt>",handle special characters in windows paths
2395,"<desc> back-port of fixes for libavcodec version checks found during #18146 . to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work allow_multiple_commits=1 </desc> <cmt> fix: libavcodec version check for av_codec_flag_global_header </cmt> <cmt> fix: libavcodec version check for avdiscard_nonintra </cmt> <cmt> - avdiscard_nonintra flag is supported only for ffmpeg libraries pack </cmt>",back-port for ffmpeg versions guard fix for av_codec_flag_global_header and avdiscard_nonintra
2396,"<desc> this pr implements directives to tweak the response headers; model after headers directive of apache. it provides following directives: header.add, header.append, header.merge, header.set, header.setifempty, header.unset. see #196 </desc> <cmt> implement h2o_str_stripws </cmt> <cmt> implement the headers module </cmt>",add directives to tweak the headers
2397,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. </desc> <cmt> new typings </cmt> <cmt> updated types into a namespace to allow the default function to be fired </cmt> <cmt> typo on findone </cmt> <cmt> dt tests passed </cmt>",updated bonjour types (were not working on typescript 2.2)
2398,"<desc> cc/ @mit-mit @xster note: this version uses assets that are not in the gallery assets package. once the assets have been added to that package i'll do a conversion to use those. highlights: adds a first time run experience to describe what the gallery is all about adds in the running demo </desc> <cmt> add welcome stub </cmt> <cmt> transplant assets and welcome screen, refactor </cmt> <cmt> finish refactor, keep hardcoded welcome test </cmt> <cmt> transplant and update customize design, add to studies </cmt> <cmt> rename to customized </cmt> <cmt> type annotations </cmt> <cmt> small updates </cmt> <cmt> check for welcome state </cmt> <cmt> remove welcome bg </cmt> <cmt> refactor - wip </cmt> <cmt> add image </cmt> <cmt> welcome implemented </cmt> <cmt> auto progress welcome if no interaction </cmt> <cmt> add limit to pageview </cmt> <cmt> welcome content changes </cmt> <cmt> tweak welcome images on larger screens </cmt> <cmt> clean up </cmt> <cmt> merge master </cmt>",add a welcome screen and a demo from the posse gallery
2399,"<desc> the kernel itself checks whether or not the provided addresses are word aligned before continuing, so we should be doing the same. </desc> <cmt> common: move is4kbaligned() to alignment.h </cmt> <cmt> aligning on 4kb pages isn't a switch-specific thing, so this can be </cmt> <cmt> moved to common so it can be used with other things as well. </cmt> <cmt> common: add function for checking word alignment to alignment.h </cmt> <cmt> this will be used in a following change to svcarbitratelock() and </cmt> <cmt> svcarbitrateunlock() </cmt> <cmt> svc: check for word alignment of addresses within svcarbitratelock/svcarbitrateunlock </cmt> <cmt> the kernel itself checks whether or not the provided addresses are word </cmt> <cmt> aligned before continuing, so we should be doing the same. </cmt>",add missing error checks in svcarbitratelock/svcarbitrateunlock
2400,<desc> fixed  left/right bracket logic when pressing lalt and lctl small changes here and there my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add layer switcher functionality </cmt> <cmt> fixes in left/right bracket functions and other small fixes </cmt>,bugfixes on tapdance logic and small changes in layout
2401,"<desc> this pr fixes a bug when wav2vec2 is trained with batch_size=1 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> correct long to bool </cmt> <cmt> up </cmt>",make sure tensors are always bool for mask_indices
2402,"<desc> please check #10735 for why we are doing this. to solve the issue above, we have merged a pr #10817 and now there is utility functions here to create lodtensor. so this means that we can simplify the book example code using the new api. this pr tries to modify the rnn encoder decoder book example. </desc> <cmt> initial commit </cmt> <cmt> modify rnn_encoder_docoder example </cmt>",modify rnn encoder decoder example using new lodtensor api
2403,<desc> description: fix for timeout error caused by big image icon for notification default image changed to smaller size. added timeout option for connection. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4196 example entry for configuration.yaml (if applicable): notify: - platform: webostv host: 192.168.0.112 name: livingroom_tv filename: webostv.conf checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> use smaller icon </cmt> <cmt> add timeout option </cmt>,notify webos timeout error fix
2404,"<desc> in this pr, i fixed some bugs and add members property to response for the api getroominfo. now an example result of this api is like following: { ""roomid"": ""d2laekjpjwyssxrht"", ""roomname"": ""rocket.chat-experimental-basket-basketball-frvr-xqfx4gsxbn"", ""members"": [ { ""userid"": ""h6vzrjfv2wilf5map"", ""username"": ""kevin"", ""avatarurl"": "" ""status"": ""offline"" }, { ""userid"": ""b8dsjdragwdnj4p9z"", ""username"": ""anakin"", ""avatarurl"": "" ""status"": ""offline"" }, { ""userid"": ""rhwz9jaukm7w6rvnc"", ""username"": ""root"", ""avatarurl"": "" ""status"": ""online"" } ] } </desc> <cmt> [fix] the invalid room name issue </cmt> <cmt> [fix] limit externalcomponent name length </cmt> <cmt> add members property to response </cmt>",fix some bugs and add members property to response
2405,"<desc> this changeset switches the mitigation strategy away from the one taken in pr #1350 (which avoids missing the end-of-input check by restarting the dictionary search with bestlength = 0) to totally avoiding searching the dictionary when we're in that situation, since a precondition to being at risk of running past the end of the input is that we've already found an optimal match. so there's no utility in searching the dictionary. i suspect this will produce a small performance win. notably, this approach to avoiding the issue was already present in the zstd_btopt implementation. not sure how it got missed in zstd_btlazy2 . in making this change, this patch fixes an unfortunate bug. without this change, the zstd_btlazy2 strategy unconditionally selects the best dictionary match (if one is found) over the best input match, even if the dictionary match is worse. furthermore, it then skips trying to match against the input as if it had used the better match into the input that it found and discarded. in the worst case, this can lead to totally failing to compress very repetitive input. this changeset avoids that behavior by returning to only considering matches in the dictionary that are better than the best input match. as a result, this pr fixes issue #1357. </desc> <cmt> remove unused variable </cmt> <cmt> clean up debug log statements </cmt> <cmt> avoid searching dictionary in zstd_btlazy2 when an optimal match is found </cmt> <cmt> bailing here is important to avoid reading past the end of the input buffer. </cmt>",avoid erroneously trampling on match with worse dictionary match
2406,<desc> @nvbn what do you think? please review. any comment is welcome </desc> <cmt> test(shells): add fuck alias to collection of aliases </cmt> <cmt> refact(shells): use an env var tf_alias to keep the name of the alias </cmt> <cmt> this environment variable may be used by any rule to decide whether it </cmt> <cmt> matches or not. </cmt>,use an environment variable that keeps the alias name to avoid looping
2407,"<desc> exp sigmoid tanh 61: [ run      ] jitkernel.vexp 61: i1116 17:31:25.289243 70727 jit_kernel_test.cc:192] vec size 7: refer takes: 0.1193 us, mkl takes: 0.06805 us, tgt takes: 0.04005 61: i1116 17:31:25.292809 70727 jit_kernel_test.cc:192] vec size 8: refer takes: 0.10145 us, mkl takes: 0.0595 us, tgt takes: 0.0142 61: i1116 17:31:25.298521 70727 jit_kernel_test.cc:192] vec size 12: refer takes: 0.19745 us, mkl takes: 0.05865 us, tgt takes: 0.02685 61: i1116 17:31:25.306084 70727 jit_kernel_test.cc:192] vec size 15: refer takes: 0.25365 us, mkl takes: 0.06725 us, tgt takes: 0.05415 61: i1116 17:31:25.313345 70727 jit_kernel_test.cc:192] vec size 16: refer takes: 0.263 us, mkl takes: 0.0668 us, tgt takes: 0.03025 61: i1116 17:31:25.322093 70727 jit_kernel_test.cc:192] vec size 20: refer takes: 0.33465 us, mkl takes: 0.05935 us, tgt takes: 0.04095 61: i1116 17:31:25.332445 70727 jit_kernel_test.cc:192] vec size 30: refer takes: 0.3682 us, mkl takes: 0.07565 us, tgt takes: 0.0708 61: i1116 17:31:25.425176 70727 jit_kernel_test.cc:192] vec size 128: refer takes: 1.54815 us, mkl takes: 2.86435 us, tgt takes: 0.21885 61: [ run      ] jitkernel.vsigmoid 61: i1116 17:31:25.505259 70727 jit_kernel_test.cc:264] vec size 7: refer takes: 0.1178 us, better(jit exp) takes: 0.08285 us, tgt takes: 0.0532 61: i1116 17:31:25.509996 70727 jit_kernel_test.cc:264] vec size 8: refer takes: 0.13415 us, better(jit exp) takes: 0.08 us, tgt takes: 0.02035 61: i1116 17:31:25.517647 70727 jit_kernel_test.cc:264] vec size 15: refer takes: 0.2031 us, better(jit exp) takes: 0.10545 us, tgt takes: 0.0703 61: i1116 17:31:25.524626 70727 jit_kernel_test.cc:264] vec size 16: refer takes: 0.2162 us, better(jit exp) takes: 0.0947 us, tgt takes: 0.0362 61: i1116 17:31:25.537247 70727 jit_kernel_test.cc:264] vec size 30: refer takes: 0.40715 us, better(jit exp) takes: 0.13325 us, tgt takes: 0.08795 61: i1116 17:31:25.549927 70727 jit_kernel_test.cc:264] vec size 32: refer takes: 0.4349 us, better(jit exp) takes: 0.1228 us, tgt takes: 0.0724 61: i1116 17:31:25.574997 70727 jit_kernel_test.cc:264] vec size 64: refer takes: 0.87295 us, better(jit exp) takes: 0.2315 us, tgt takes: 0.14305 61: i1116 17:31:25.613718 70727 jit_kernel_test.cc:264] vec size 100: refer takes: 1.34945 us, better(jit exp) takes: 0.34655 us, tgt takes: 0.2316 61: i1116 17:31:25.662092 70727 jit_kernel_test.cc:264] vec size 128: refer takes: 1.7127 us, better(jit exp) takes: 0.41525 us, tgt takes: 0.2857 61: i1116 17:31:25.758944 70727 jit_kernel_test.cc:264] vec size 256: refer takes: 3.4511 us, better(jit exp) takes: 0.82345 us, tgt takes: 0.5594 61: [       ok ] jitkernel.vsigmoid (258 ms) 61: [ run      ] jitkernel.vtanh 61: i1116 17:31:25.763900 70727 jit_kernel_test.cc:332] vec size 7: refer takes: 0.1219 us, better(jit exp) takes: 0.06585 us, tgt takes: 0.0525 61: i1116 17:31:25.767813 70727 jit_kernel_test.cc:332] vec size 8: refer takes: 0.1395 us, better(jit exp) takes: 0.0354 us, tgt takes: 0.018 61: i1116 17:31:25.776193 70727 jit_kernel_test.cc:332] vec size 15: refer takes: 0.25945 us, better(jit exp) takes: 0.08585 us, tgt takes: 0.07065 61: i1116 17:31:25.783507 70727 jit_kernel_test.cc:332] vec size 16: refer takes: 0.2763 us, better(jit exp) takes: 0.05105 us, tgt takes: 0.0359 61: i1116 17:31:25.797840 70727 jit_kernel_test.cc:332] vec size 30: refer takes: 0.5218 us, better(jit exp) takes: 0.10425 us, tgt takes: 0.0872 61: i1116 17:31:25.812160 70727 jit_kernel_test.cc:332] vec size 32: refer takes: 0.55535 us, better(jit exp) takes: 0.08625 us, tgt takes: 0.0708 61: i1116 17:31:25.840363 70727 jit_kernel_test.cc:332] vec size 64: refer takes: 1.1042 us, better(jit exp) takes: 0.16155 us, tgt takes: 0.14015 61: i1116 17:31:25.884611 70727 jit_kernel_test.cc:332] vec size 100: refer takes: 1.7222 us, better(jit exp) takes: 0.2579 us, tgt takes: 0.2271 61: i1116 17:31:25.941277 70727 jit_kernel_test.cc:332] vec size 128: refer takes: 2.2213 us, better(jit exp) takes: 0.32435 us, tgt takes: 0.2811 61: i1116 17:31:26.054328 70727 jit_kernel_test.cc:332] vec size 256: refer takes: 4.42075 us, better(jit exp) takes: 0.6569 us, tgt takes: 0.56345 </desc> <cmt> exp support all size </cmt> <cmt> refine act and vxx with all size </cmt> <cmt> refine relu and fix addrelu test </cmt> <cmt> refine exp jitcode with all size </cmt> <cmt> test=develop </cmt>",jitcode act support all size
2408,<desc> others others parse rank_to_ip map on cpp side and start message bus </desc> <cmt> add ip parser </cmt> <cmt> adapt singlton </cmt> <cmt> update vlog </cmt> <cmt> modify structure </cmt> <cmt> add isinit interface for message bus </cmt> <cmt> some update </cmt> <cmt> correct typo </cmt>,parse rank_to_ip map on cpp side and start message bus.
2409,<desc> ts 3.7 has been released which supports optional chaining and nullish operator. gastby-plugin-typescript uses babel to transform typescript so two plugin must be added accordingly to support these new feature </desc> <cmt> add plugin </cmt> <cmt> add optional chaining </cmt>,add support for optional chaining and nullish coalescing operator
2410,"<desc> should mitigate the issues found during mcp on #73255. once this is done, we should clean up the queries a bit, since i think mir_drops_elaborated_and_const_checked can be merged back into mir_promoted. fixes #90770.  r? @nikomatsakis (since they reviewed #71824) </desc> <cmt> separate removefalseedges from simplifybranches </cmt> <cmt> otherwise dataflow state will propagate along false edges and cause </cmt> <cmt> things to be marked as maybe init unnecessarily. these should be </cmt> <cmt> separate, since simplifybranches also makes if true {} else {} into </cmt> <cmt> a goto, which means we wouldn't lint anything in the else block. </cmt> <cmt> add ""is"" methods for projections to a given index </cmt> <iss> post-drop elaboration const-checking fails on zsts </iss>",move #![feature(const_precise_live_drops)] checks earlier in the pipeline
2411,"<desc> see issue #3854. we used the mardown syntax to format the coding style page: styled lists; used syntax highlighting; formatted correct and incorrect code as in the solidity style guide; fixed punctuation as for the english rules for bulleted lists; formatted links. there is still room for improvements and small fixes. we could for example remove some numbers in the section titles and lists, remove some lists ... </desc> <cmt> update coding_style.md </cmt> <cmt> use markdown formatting </cmt> <cmt> - never use more than 2 line breaks </cmt> <cmt> - cpp syntax highlighting </cmt> <cmt> - use yes / no instead of right / wrong (as seen in the style guide at </cmt> <cmt> stylizing markdown on this coding_style.md, lists, code </cmt> <cmt> merge </cmt> <cmt> remove punctuation in titles </cmt> <cmt> add list style, links style on coding_style.md </cmt> <cmt> syntax highlighting </cmt> <cmt> merged </cmt> <cmt> punctuation consistency </cmt> <cmt> put correct before incorrect code examples </cmt>",correct the style of coding style (#3854)
2412,"<desc> this pr fixes the behavior raised in #42420. now, the user can create new host record bypassing dns and will also be able to delete existing host_record made via bypassing dns. also, now user can use the feature of dhcp while creating the new host record. nios ansible version 2.7 i have included dhcp support also in this pr, which will help the user to create host_record under dhcp which earlier was not supported and was by default set to false. if the user chooses to create host_record under dhcp, a user will have have to mention the mac address. </desc> <cmt> fixes issue 42420 </cmt> <cmt> fixes issue 42420 </cmt>",allow dns bypass for add/remove of host records with nios_host_record
2413,"<desc> this was the last genericsignature-based operation that relied upon the genericsignaturebuilder. next steps: finish some edge cases with superclass requirements various rewrite system optimizations to recover performance enable the requirement machine by default? start work on using rewrite system to compute minimal and canonical generic signatures nuke the gsb altogether </desc> <cmt> ast: factor out genericsignature::getlocalrequirements() method </cmt> <cmt> this encapsulates genericenvironment's usage of the gsb. </cmt> <cmt> requirementmachine: implement genericsignature::getlocalrequirements() query </cmt> <cmt> ast: don't force requirementmachine creation in getorcreategenericsignaturebuilder() </cmt> <cmt> this was for test coverage before i had any queries ported over, just to </cmt> <cmt> make sure that the completion procedure worked. </cmt> <cmt> now that all the genericsignature queries have been ported over, we don't </cmt> <cmt> need this since  we're going to create all the requirementmachines anyway. </cmt> <cmt> requirementmachine: drop protocols that the superclass conforms to when building an archetype </cmt> <cmt> requirementmachine: tri-state enable flag, and move queries to genericsignaturequeries.cpp </cmt> <cmt> the -enable-requirement-machine and -disable-requirement-machine flags are now </cmt> <cmt> replaced by a new flag -requirement-machine={on,off,verify}. </cmt> <cmt> ast: asert that we don't create genericsignaturebuilders when requirementmachine is enabled </cmt> <cmt> requirementmachine: re-use a single global rewritecontext </cmt>",use requirementmachine to build archetypes when enabled
2414,"<desc> this is in response to #873 essentially, i would like to add a callback function to sla miss handling. in the callback function, i can decide whether to post to slack and to victorops/pagerduty, or some other 3rd party ops solution. email is too limiting. i've added another column to the table to track sla notifications in general. not in this pr is a fix for a general problem which can occur is slas were enabled on a task but no emails or sla alert call back were provided. in this case, the query to return all sla misses would progressively return more and more data, slowing down the scheduler. we need a separate fix to place a window on the max number of sla misses queried. </desc> <cmt> sla miss alert callbacks : allow dags to specify a callback function that can be executed during sla misses. one use-case for this is to allow 3rd party notification on sla misses such as pagerduty and victorops </cmt> <cmt> sla alert callback : supporting the ability to do optional sla alert call backs and emailing </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",allow dags to specify a callback function for sla miss handling
2415,"<desc> description: bump nessclient version to use latest release (0.9.10), with a handful of fixes which should improve the general stability of this component. example entry for configuration.yaml (if applicable): ness_alarm: host: alarm.local port: 2401 zones: - name: garage id: 1 - name: storeroom id: 2 - name: kitchen id: 3 - name: front entrance id: 4 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. </desc> <cmt> ness_alarm: bump nessclient version </cmt> <cmt> update requirements_all.txt </cmt>",bump nessclient version to 0.9.10
2416,"<desc> fix: #9401 note: i added some extra code that checks the operand values which is not strictly necessary, but now the errors are exactly the same as when using mongo shell. </desc> <cmt> add support for  aliasses </cmt> <cmt> styling </cmt>",add support for $type aliasses.
2417,"<desc> closes t-1087 this disables workers of all types from being created with a string literal. it's now required to use new worker(new url('filename.js', import.meta.url), {type: 'module'}). this is because strings passed to the worker constructor are supposed to be resolved relative to the page url, not to the current file. using the url constructor solves this issue so that parcel is more web compatible. this is also how other bundlers like webpack now work. this also makes some formatting improvements to diagnostics, especially when multiple diagnostics are displayed at once. the code frame and hints are now indented underneath each error message so it's clear what it is associated with. in addition, it's now possible to have multiple code frames pointing to different files within the same diagnostic. this way, errors can show context for the error in another file without creating a separate diagnostic which looks like a different error. there's also some other small diagnostic improvements in this pr which you can see in the code. </desc> <cmt> disable workers with string literals </cmt> <cmt> diagnostic improvements </cmt>",disable workers with string literals and improve diagnostics
2418,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): from now on .sql tests can be run isolated by server, in parallel, with random database. it allows to run them faster, add new tests with custom server configurations, and be sure that different tests doesn't affect each other. </desc> <cmt> initial implementation of pytest tests for stateless queries. </cmt> <cmt> run .sql tests with standalone server </cmt> <cmt> try ""fix"" tests </cmt> <cmt> revert ""try ""fix"" tests"" </cmt> <cmt> this reverts commit 52d1042310fa8aef45fc42ae795301f38b3b84b8. </cmt> <cmt> check every test cleans up everything and doesn't hardcode db names </cmt>",run query-tests using pytest framework
2419,"<desc> release a bunch of summarization and translation pseudolabels with reasonably nice documentation. allow make_student(teacher, 'student_000_baseline', 12, 3, d_layers_to_copy=[0,0,0]) for baseline purposes. </desc> <cmt> kwarg layers2copy </cmt> <cmt> allow 000 </cmt> <cmt> links to precomputed pseudolabels </cmt> <cmt> boom boom </cmt>",release pseudolabel links and instructions
2420,"<desc> what do these changes do? clean up the pytorch model api to support rnns, dict / tuple spaces unify qmix rnn model with model catalog i expect we'll have to make more changes (and add more tests) as we implement pytorch support more fully; this is just an initial cleanup to better unify qmix with pytorch a3c. #3365 </desc> <cmt> wip </cmt> <cmt> clean up </cmt> <cmt> wip </cmt> <cmt> add reg </cmt> <cmt> rnn </cmt> <cmt> mask test </cmt>",refactor pytorch custom model support
2421,"<desc> added qwerty and command layers moved modified tap keys to press instead of release added one shot modifiers organizational changes my code follows the code style of this project. i have read the contributing document. </desc> <cmt> added my own keymap </cmt> <cmt> changed thing </cmt> <cmt> updated keymap samuel </cmt> <cmt> updated laypout for better one handed use </cmt> <cmt> updated stuff i want </cmt> <cmt> happy with my lagout </cmt> <cmt> formatting </cmt> <cmt> added new literate config </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> made everything nice </cmt> <cmt> cleaned </cmt> <cmt> fixed spelling and two small bugs in macros </cmt> <cmt> made press and lift function for modifiers </cmt> <cmt> made taps occur on press instead of release </cmt> <cmt> added oneshot keys and chars cant be negative! </cmt> <cmt> removed debug message </cmt> <cmt> added command and qwerty layers </cmt> <cmt> updated </cmt> <cmt> fixed bug with oneshot layer </cmt> <cmt> same bug, different key </cmt>",improvements to samuel's literate keymap
2422,"<desc> continues from #4232,  closes #4153. fixes #2703. fixes #2710. @piscisaureus please review. </desc> <cmt> wip: get better frame info from preparestacktrace </cmt> <cmt> use callsiteeval with fields instead of methods </cmt> <cmt> convert 1-based line/column numbers to 0-based </cmt> <cmt> don't apply source maps twice </cmt> <cmt> fix tests </cmt> <iss> async stack traces </iss> <iss> discrepancy in output between error.stack and thrown error </iss> <iss> don't destructure errors using v8::exception::create_message(), just read error.stack </iss>",get frame data from preparestacktrace()
2423,"<desc> this pull request patches fs.access and fs.accesssync to support paths in asar archives. it also does a little  on the file and uses let/const instead of var. it also supports calling fs apis with a buffer path (instead of a string) which was added in node 6.0.0, nodejs/node#5616 closes #6555 </desc> <cmt> use let/const instead of var </cmt> <cmt> add asar-supported fs.access implementation </cmt> <cmt> add asar-supported fs.accesssync implementation </cmt> <cmt> support paths as buffers </cmt>",add asar implementation of fs.access/accesssync
2424,<desc> backport of #10194 </desc> <cmt> bug: failure to decref in pyufunc_genericreduction. </cmt> <cmt> would lead to a reference leak for the case that an invalid axis </cmt> <cmt> is passed in. </cmt> <cmt> maint: use single failure path in py_ufunc_genericreduction. </cmt> <cmt> this should help avoid reference leaks in future additions. </cmt>,ufunc reduce reference leak (backport)
2425,"<desc> i did not get yaml working on my local machine so i hope it builds from my careful (?) mimicry. it all works now. ready to merge on my end :) </desc> <cmt> added relation prediction, removed from wishlist </cmt> <cmt> relation prediction skeleton </cmt> <cmt> relation prediction results (wn18rr) </cmt> <cmt> described relation prediction </cmt>",new task - relation prediction on wn18rr
2426,"<desc> if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. fyi @lujiajing1126 </desc> <cmt> remove page path in the browser log query condition. </cmt> <cmt> remove endpoint name in the backend log query condition. </cmt> <cmt> fix a code style issue. </cmt> <cmt> fix missing changes. </cmt>",remove endpoint name in backend log and browser log query
2427,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. #30792 </desc> <cmt> fix error in list type </cmt> <cmt> [release] increase prompts version 1.2 </cmt> <cmt> [improve] add boolean as initial message </cmt> <cmt> [improve] add falsy type to skip the question </cmt> <cmt> [fix] remove trail space </cmt> <cmt> [improve] improve type of prompts </cmt> <cmt> fix lint error </cmt>",update a error from #30792
2428,"<desc> save settings file instead of sending ipc message added file watcher to track changes in the settings.json updated ui unit tests what is include in the pr: linked issue: #11077 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> removed ipc messages </cmt> <cmt> added settings utils </cmt> <cmt> replaced mock msg </cmt> <cmt> added asserts </cmt> <cmt> added new tests </cmt> <cmt> file watcher on settings change </cmt> <cmt> update window via message </cmt> <cmt> reverted setconfig </cmt>",drop support for the module interface api to save settings
2429,<desc> rdar://76568032&76567759&76567375&76566897&76566598&76566242&76566029 </desc> <cmt> [test] disabled several autodiff tests for back_deployment_runtime. </cmt> <cmt> rdar://76566029 </cmt> <cmt> [test] disabled casting/casts.swift for back_deployment_runtime. </cmt> <cmt> rdar://76566242 </cmt> <cmt> [test] disabled several concurrency tests for back_deployment_runtime. </cmt> <cmt> rdar://76566598 </cmt> <cmt> [test] disabled interpreter/bridged_casts_folding.swift for back_deployment_runtime. </cmt> <cmt> rdar://76566897 </cmt> <cmt> [test] disabled two playgroundtransform tests for back_deployment_runtime. </cmt> <cmt> rdar://76567375 </cmt> <cmt> [test] disabled several runtime tests for back_deployment_runtime. </cmt> <cmt> rdar://76567759 </cmt> <cmt> [test] disabled several stdlib tests for back_deployment_runtime. </cmt> <cmt> rdar://76568032 </cmt>,disabled several tests for back_deployment_runtime.
2430,"<desc> in #2923 , filespipeline added support for google cloud storage. however, the pr did not implement support for acl. so, this pr add support acl for google cloud storage. (venv) [rhoboro]~/github/scrapy % gcs_project_id=""xxx"" gcs_test_file_uri=""gs://xxx"" tox -- tests/test_pipeline_files.py -v ... =================================================================================================== test session starts ==================================================================================================== platform darwin -- python 2.7.10, pytest-2.9.2, py-1.5.3, pluggy-0.3.1 -- /users/suyamar/github/scrapy/.tox/py27/bin/python cachedir: .cache rootdir: /users/suyamar/github/scrapy, inifile: pytest.ini plugins: twisted-1.7.1, cov-2.2.1 collected 18 items tests/test_pipeline_files.py::filespipelinetestcase::test_file_expired <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed tests/test_pipeline_files.py::filespipelinetestcase::test_file_not_expired <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed tests/test_pipeline_files.py::filespipelinetestcase::test_file_path passed tests/test_pipeline_files.py::filespipelinetestcase::test_fs_store passed tests/test_pipeline_files.py::deprecatedfilespipelinetestcase::test_default_file_key_method passed tests/test_pipeline_files.py::deprecatedfilespipelinetestcase::test_overridden_file_key_method passed tests/test_pipeline_files.py::filespipelinetestcasefields::test_item_fields_default passed tests/test_pipeline_files.py::filespipelinetestcasefields::test_item_fields_override_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_cls_attrs_with_default_prefix passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_custom_settings_and_class_attrs_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_custom_settings_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_different_settings_for_different_instances passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_no_custom_settings_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_subclass_attributes_preserved_if_no_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_subclass_attrs_preserved_custom_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_user_defined_subclass_default_key_names passed tests/test_pipeline_files.py::tests3filesstore::test_persist <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py skipped tests/test_pipeline_files.py::testgcsfilesstore::test_persist <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed =========================================================================================== 17 passed, 1 skipped in 8.53 seconds =========================================================================================== _________________________________________________________________________________________________________ summary __________________________________________________________________________________________________________ py27: commands succeeded congratulations :) </desc> <cmt> add acl support for gcs </cmt> <cmt> added test for gcs policy </cmt> <cmt> update docs for support gcs acl </cmt>",filespipeline supports acl for google cloud storage
2431,"<desc> expand use of xdsresourcetype outside of xdsapi into xdsclient.  this removes a bunch of duplicate data structures and code-paths for different resource types, which makes the xdsclient implementation resource-type-agnostic. the xdsclient api still has a different watcher api for each resource type, which is implemented on top of the new resource-type-agnostic api.  in a subsequent pr, i will remove those resource-type-specific apis and move them to the xdsresourcetype interface. there are two noteworthy structural changes here: i have improved the interface of xdsapi::parseadsresponse().  instead of passing in a bunch of lists of expected resource names for each resource type and then passing out a different map based on the resource type, i have introduced a adsresponseparserinterface api.  the xdsclient provides an implementation of that api, and parseadsresponse() invokes the methods on that object to perform the parsing.  this allows the xdsclient to directly handle each resource as it is parsed, adding it to the cache and notifying watchers as appropriate. i have added a global registry for xds resource types.  the xdsclient code uses this to determine which xdsresourcetype to use for each ads response without hard-coding an ""if/else"" block with options for each resource type. </desc> <cmt> wip </cmt> <cmt> introduce xdsresourcetype api and change listener parsing to use it </cmt> <cmt> converted routeconfig parsing </cmt> <cmt> convert cluster and endpoint parsing </cmt> <cmt> cleanup </cmt> <cmt> clang-format </cmt> <cmt> attempt to work around compiler problems </cmt> <cmt> move xdsresourcetype to its own file, and move endpoint code out of xdsapi </cmt> <cmt> move cluster parsing to its own file </cmt> <cmt> move route config parsing to its own file </cmt> <cmt> move listener parsing to its own file </cmt> <cmt> clang-format </cmt> <cmt> minor cleanup </cmt> <cmt> plumbed xdsresourcetype throughout xdsclient </cmt> <cmt> a bit of cleanup </cmt> <cmt> more cleanup </cmt> <cmt> construct full resource names before calling xdsapi::createadsrequest() </cmt>",use xdsresourcetype abstraction throughout xdsclient
2432,<desc> addresses #20308 this pr ensures linearsvr is compatible with numpydoc. remove linearsvr from docstring_ignore_list. verify that all tests are passing. #dataumbrella sprint </desc> <cmt> remove linearsvr from docstring_ignore_list. </cmt> <cmt> fix numpydocs from linearsvr. </cmt>,doc ensures that linearsvr passes numpydoc validation
2433,"<desc> bug fixes apis this pr fixes several problems in dy2stat for deoldify model in paddlegan. in model, software engineer wrote if x.shape == y.shape, the tenser shape is a tuple in dygraph so the == returns true/false, but in static graph the == becomes element-wise comparison, which is a different behavior. in this pr we reduce the element-wise comparison result. if software engineer write computations which uses parameters in hooks, the static graph can loss the parameter variable because we put param_guard at forward of a layer. in this pr we made param_guard cover pre-hook and post-hook. in paddlegan, software engineer calculated some parameter values in __init__ by running some dygraph code. those code also run during dy2stat. so some variables may be assign as a varbase (tensor) first and then variable, which raised an error. we fixed the bug in this pr by handling the case. todo: we just added testcase for the 1. shape comparison. should add test case for 2. and 3. but since we are chasing 2.0rc, i will do it in the near future pr </desc> <cmt> fix paddlegan deoldify model layer problems, test=develop </cmt> <cmt> code for python/paddle list/variable compare diff, test=develop </cmt>",fix paddlegan deoldify model dy2stat problems
2434,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixes #5990 detailed description (optional): for csv input format: consider unquoted null literal as \n (if setting format_csv_unquoted_null_literal_as_null=1) initialize null fields with default values if data type of this field is not nullable (if setting input_format_null_as_default=1) </desc> <cmt> use default if not nullable </cmt> <cmt> parse unquoted null </cmt> <cmt> add tests </cmt> <iss> load data with csvwithnames or tabseparatedwithnames got error when two columns  continuous  null </iss>,csv unquoted nulls and default values
2435,<desc> closes #39677 ml.get_calendars accepts post requests with a body but in the rest spec body was null which makes the language clients think that is not the case. correct the docs for ml.get_calendars using page parameters in the body. closes #39673 by registering the missing url for delete forecast where the forecast id is not specified. closes #39676 with a doc change in eventresource.asciidoc. </desc> <cmt> forecast id is optional in delete forecast </cmt> <cmt> make get categories with post consistent and update docs </cmt> <cmt> correct docs for scheduled event time format </cmt> <iss> [ml] delete forecast : rest json inconsistency </iss> <iss> [ml] scheduled event resources : inconsistent request parameter types </iss> <iss> [ml] calendars api : inconsistencies in documentation / json spec </iss>,correct small inconsistencies in ml apis spec and docs
2436,<desc> fixes #3493 a copy/paste error meant that the wrong animation was being started for scalex and scaley animations. microsoft reviewers: open in codeflow </desc> <cmt> call startanimatiom on m_scalecombined for scalex / scaley animations </cmt> <cmt> there was a copy-paste error previously that started m_translationcombined instead. </cmt> <cmt> change files </cmt> <iss> animated native driver does not animate scalex or scaley </iss>,call startanimation on m_scalecombined for scalex / scaley animations
2437,"<desc> added ""--sign-with "" or ""--sign-with [ <public key 1>, <public key 2>, ... ]"" option to cleos subcommands that result in one signed transaction being sent to nodeos, skipping the step of requesting nodeos for the keys required for signing the transaction. #8199 the following cleos subcommands will now allow signing with one key (""--sign-with "") or multiple keys ( ""--sign-with [ <public key 1>, <public key 2>, ... ]""): ""set action permission"" ""system regproducer"" ""system unregproducer"" ""vote producer proxy"" ""vote producer prods"" ""vote producer approve"" ""vote producer unapprove"" ""system delegatebw"" ""system undelegatebw"" ""system bidname"" ""system buyram"" ""system sellram"" ""system claimrewards"" ""system regproxy"" ""system unregproxy"" ""system canceldelay"" ""system rex deposit"" ""system rex withdraw"" ""system rex buyrex"" ""system rex lendrex"" ""system rex unstaketorex"" ""system rex sellrex"" ""system rex cancelrexorder"" ""system rex mvtosavings"" ""system rex mvfromsavings"" ""system rex rentcpu"" ""system rex rentnet"" ""system rex fundcpuloan"" ""system rex fundnetloan"" ""system rex defcpuloan"" ""system rex defnetloan"" ""system rex consolidate"" ""system rex updaterex"" ""system rex rexexec"" ""system rex closerex"" ""system rex "" ""set contract"" ""set code"" ""set abi"" ""transfer"" ""push action"" ""push transaction"" ""multisig propose"" ""multisig propose_trx"" ""multisig approve"" ""multisig unapprove"" ""multisig invalidate"" ""multisig cancel"" ""multisig exec"" ""wrap exec"" </desc> <cmt> added ability to provide the keys to sign a transfer transaction with rather than asking nodeos. </cmt> <cmt> added class to handle providing keys to sign transactions with. </cmt> <cmt> added option to sign sub-commands that produce one transaction. </cmt> <cmt> added parameter to allow signing directly for methods that result in cleos creating actions. </cmt> <cmt> refactoring changes to provide accounts instead of account names for methods that can sign. </cmt>",add option to provide transaction signature keys to cleos
2438,"<desc> ucs dns server management new module pull request ucs_dns_server ansible version ansible 2.7.0.dev0 (ucs_dns_server 92f5bf79fb) last updated 2018/10/10 20:36:19 (gmt -400) config file = /users/jomcdono/.ansible.cfg configured module search path = ['/users/jomcdono/documents/src/ucs/ansible/lib/ansible/modules/remote_management/ucs'] ansible python module location = /users/jomcdono/documents/src/ucs/ansible/lib/ansible executable location = /users/jomcdono/documents/src/ucs/ansible/bin/ansible python version = 3.7.0 (default, jun 29 2018, 20:13:13) [clang 9.1.0 (clang-902.0.39.2)] </desc> <cmt> add module for ucs dns server </cmt> <cmt> updates from review </cmt> <cmt> recommit for ansible pr </cmt>",add ucs dns server management module
2439,"<desc> hi @antirez @madolson , now i open this pr to discuss the codes i mentioned in  #6152 , except the original problem, here are other three changes: propagate exec directly in lua script i think we don't need to use also propagate in lua, cause multi is already propagated. flag module client as client_multi if needed in case of nested multi/exec, lua script has the same problem, see details in #5780 propagte brpoplpush as rpoplpush when unblock after the expire problem is fixed, i think it's ok to do that now btw, if this pr is ok, before merge it we should merge #5780 at first to avoid nested mulit/exec when spop with count is called in lua script. </desc> <cmt> propagation: wrap commands in also_propagate array with mulit/exec </cmt> <cmt> random command like spop with count is replicated as </cmt> <cmt> some srem operations, and store them in also_propagate </cmt> <cmt> array to propagate after the call, but this would break </cmt> <cmt> atomicity. </cmt> <cmt> to keep the command's atomicity, wrap also_propagate </cmt> <cmt> array with multi/exec. </cmt> <cmt> propagation: propagate exec directly in lua script </cmt> <cmt> propagation: flag module client as client_multi if needed </cmt> <cmt> in case of nested multi/exec </cmt> <cmt> block: propagate brpoplpush as rpoplpush when unblock </cmt>",wrap also propagate as multi
2440,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> add maxfontsize and minfontsize to series that have it. </cmt> <cmt> update version at top of file. </cmt> <cmt> revert the formatting </cmt>",highcharts - add maxfontsize and minfontsize to series that have it.
2441,"<desc> with this change, github will create and publish a nuget that contains the dll's and headers needed for win32 and uwp. microsoft reviewers: open in codeflow </desc> <cmt> first stab at moving nuget creation to github </cmt> <cmt> fix typo </cmt> <cmt> update copytostaging </cmt> <cmt> update staging bat </cmt> <cmt> more staging update </cmt> <cmt> remove trailing \ from srcroot </cmt> <cmt> typo in artifact name </cmt> <cmt> rework where files were put </cmt> <cmt> remove react-native-windows prefix </cmt> <cmt> missed ship arm </cmt> <cmt> replace original publish yaml </cmt> <cmt> remove accidental whitespace </cmt>",modify publish task to publish nuget
2442,"<desc> others others add flags_call_stack_level to control call stack of error message if flags_call_stack_level == 0, only the error message summary will be shown.  (todo) if flags_call_stack_level == 1, the python stack and  error message summary will be shown. if flags_call_stack_level == 2, the python stack, c++ stack, and error message summary will be shown. currently, default value is 2 (show all call stack), we need to discuss whether to set default to 1 (hide c++ call stack). so the default behavior remains unchaged after this pr before  (flags_call_stack_level=2) traceback (most recent call last): file ""b.py"", line 12, in <module> result = paddle.stack([x1, x2, x3], axis=2) file ""/usr/local/lib/python3.5/dist-packages/paddle/tensor/manipulation.py"", line 361, in stack attrs={'axis': axis}) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py"", line 2794, in append_op kwargs.get(""stop_gradient"", false)) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/dygraph/tracer.py"", line 45, in trace_op not stop_gradient) paddle.fluid.core_avx.enforcenotmet: -------------------------------------- c++ traceback (most recent call last): -------------------------------------- 0   paddle::imperative::tracer::traceop(std::string const&, paddle::imperative::namevarbasemap const&, paddle::imperative::namevarbasemap const&, paddle::framework::attributemap, paddle::platform::place const&, bool) 1   paddle::imperative::preparedop::prepare(paddle::imperative::namevarbasemap const&, paddle::imperative::namevarbasemap const&, paddle::framework::operatorwithkernel const&, paddle::platform::place const&, paddle::framework::attributemap const&) 2   paddle::imperative::preparedop paddle::imperative::prepareopimpl<paddle::imperative::varbase>(paddle::imperative::details::namevarmaptrait<paddle::imperative::varbase>::type const&, paddle::imperative::details::namevarmaptrait<paddle::imperative::varbase>::type const&, paddle::framework::operatorwithkernel const&, paddle::platform::place, paddle::framework::attributemap const&) 3   paddle::framework::operatorwithkernel::getexpectedkerneltype(paddle::framework::executioncontext const&) const 4   paddle::framework::operatorwithkernel::indicatedatatype(paddle::framework::executioncontext const&) const 5   paddle::platform::enforcenotmet::enforcenotmet(std::__exception_ptr::exception_ptr, char const*, int) 6   std::string paddle::platform::gettracebackstring<char const*>(char const*&&, char const*, int) 7   paddle::platform::getcurrenttracebackstring[abi:cxx11]() ---------------------- error message summary: ---------------------- invalidargumenterror: the datatype of stack op's duplicable variable x must be consistent. the current variable type is (double), but the previous variable type is (float). at (/paddle/paddle/paddle/fluid/framework/operator.cc:1307) after (flags_call_stack_level=1) traceback (most recent call last): file ""b.py"", line 12, in <module> result = paddle.stack([x1, x2, x3], axis=2) file ""/usr/local/lib/python3.5/dist-packages/paddle/tensor/manipulation.py"", line 361, in stack attrs={'axis': axis}) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py"", line 2794, in append_op kwargs.get(""stop_gradient"", false)) file ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/dygraph/tracer.py"", line 45, in trace_op not stop_gradient) paddle.fluid.core_avx.enforcenotmet: ---------------------- error message summary: ---------------------- invalidargumenterror: the datatype of stack op's duplicable variable x must be consistent. the current variable type is (double), but the previous variable type is (float). at (/paddle/paddle/paddle/fluid/framework/operator.cc:1307) </desc> <cmt> add flags_call_stack_level </cmt> <cmt> update </cmt>",add flags to control call stack of error message
2443,<desc> this pr cleans up mmdloader and adds document. changes are clean up mmdloader code and apis (more friendly to three.js manner and less polluting three.js objects) separate mmdanimationhelper from mmdloader.js add mmdloader/mmdanimationhelper documents </desc> <cmt> change outlineeffect parameter format for serialization </cmt> <cmt> separating mmdanimationhelper from mmdloader.js </cmt> <cmt> clean up mmdloader </cmt> <cmt> minor update of mmdphysics </cmt> <cmt> update mmd examples </cmt> <cmt> add mmdloader documentation </cmt> <cmt> add mmdanimationhelper documentation </cmt> <cmt> update docs/list.js </cmt>,mmdloader clean up and document
2444,"<desc> bug fixes others 1. support dy2stat error message when call paddle.jit.save before: when call paddle.jit.save(...), if exception is raised in dynamic-to-static, the exception is python native exception and not the optimized dy2stat exception. 2. polish error message 2.1 the original dygraph code is marked with (* user code *) ; 2.2  ""in user code:"" -> ""in transformed code:"" for example: </desc> <cmt> [dynamic-to-static] support dy2stat error message when call jit.save; </cmt> <cmt> add tests for error flags and for disable flags </cmt> <cmt> polish dy2stat error message: (1)add flag (* user code *) for original dygraph code; (2) ""in user code:"" -> ""in transformed code:"" </cmt>",support dy2stat error message when call jit.save and polish error message
2445,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> chore(snowflake-sdk): re-lint type definitions </cmt> <cmt> feat(snowflake-sdk): add snowflakeerror interface, errorcode enum </cmt>","add error interface, error code enum for snowflake-sdk"
2446,"<desc> the transform matrices were all wrong previously. so i split the part where the the dictionary and streams are read and the part where the pattern is calculated. basically the pattern is set right before a fill or stroke. </desc> <cmt> git radial gradients working </cmt> <cmt> changed linear gradients </cmt> <cmt> fixed gradients, need to work on tiling </cmt> <cmt> patterns working </cmt> <cmt> fixed tiling patterns </cmt> <cmt> cleanup, add support for stroking </cmt> <cmt> cleanup </cmt>",fix to gradient and tiling colorspaces
2447,"<desc> basic bsdfs meshstandardmaterial -> roughnessnode, metalnessnode,  normalnode simplification of nodebuilder code generator and depedencies (biggest update of this pr) normalmap support 30+ math functions to mathnode colorspacenode all three.js encoding functions (automatic use in texturenode) temporary variable system: tempnode structnode support new lightcontext ( more generic ) expressionnode for inline code webgpu - selective lights  // physicallightingmodel example // reflectedlight use the same standard native of threejs const glslcode = void ( inout reflectedlight reflectedlight, vec3 lightdirection, vec3 lightcolor ) { re_direct_physical( reflectedlight, lightdirection, lightcolor ); } const physicallightingmodel = new functionnode(  glslcode   ).setincludes( [ re_direct_physical ] ); </desc> <cmt> new nodematerial system updates </cmt> <cmt> update custom lighting model example </cmt>",basic bsdfs of meshstandardmaterial and nodebuilder simplification
2448,<desc> the tests would occasionally fail on slower machines due to the nodes being out of sync. this changes here explicitly validate that the nodes state matches expectation. also refactored the test code into reusable classes. </desc> <cmt> refactored test methods into helper classes for easier reusability. use transaction id validation to make a lot of the api calls more deterministic. </cmt> <cmt> refactor python test code into reusable classes. add additional options to restart script. user can specify kill signal as well as kill count. </cmt> <cmt> revert comment deletion. </cmt> <cmt> add documentation. update run_tests script to output test config and stderr log in error scenario. </cmt>,improve transaction synchronization in tests stat301
2449,"<desc> bug fix (user facing) code base improvement (dev facing) add fast rewind / fast forward in backgroundplayeractivity (activity where you manage videos playing in background) honestly, 9 icons in one row is maybe too much? we could move shuffle and repeat upward. and we could remove (one of) playbackspeedbutton/playbackpitchbutton, since they both do the same. fixes #2722 agreement i carefully read the contribution guidelines and agree to them. </desc> <cmt> add fast-rewind/forward buttons in layout </cmt> <cmt> add listeners in activity </cmt> <iss> fast forward/rewind buttons in background mode </iss>",fast rewind forward in background activity
2450,"<desc> fixed a portion of failing tests after introducing numpy compatible shapes. added a thread-safe switch to turn on/off numpy compatibility. by default, it's off and existing tests should not be affected. @junrushao1994 @szha @eric-haibin-lin @zheng-da @yzhliu </desc> <cmt> fix infer shape rnn </cmt> <cmt> fix boolean mask and custom op unit tests </cmt> <cmt> fix multi proposal </cmt> <cmt> fix diag </cmt> <cmt> add global switch for backward compatibility and fix infer shape bugs </cmt> <cmt> fix slice op infer shape </cmt>",fix unit tests after introducing numpy compatible shapes
2451,"<desc> currently, opening large files takes a long time. most of the time is spent tokenizing the lines and computing the screen lines (accounting for soft-wraps, etc). because of a small logic error, this was all happening twice, every time we opened a file. these flame graphs are for opening an example 2.3mb javascript file (jquery 2.0.3, concatenated 10 times). before opening the file took about 8.2 seconds. the span of time between the two red arrows is unnecessary work. after no more duplicated work. opening the file took about 3.2 seconds. </desc> <cmt> allocate fewer objects for fold attributes in displaybuffer </cmt> <cmt> avoid double computation of screen lines when opening files </cmt> <cmt> previously, instantiating a texteditor would always compute compute </cmt> <cmt> screen lines twice: once when the displaybuffer was instantiated, </cmt> <cmt> and once when the 'invisibles' property was set on the displaybuffer. </cmt>",improve performance of opening files
2452,"<desc> if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #7230 . update the changes log. </desc> <cmt> add some new thread metric and class metric to jvmmetric(#7230) </cmt> <cmt> update protocol (#7230) </cmt> <cmt> update metrics name (#7230) </cmt> <cmt> add benchmark for classmetrics and threadmetrics (#7230) </cmt> <cmt> update scope-definitions.md (#7230) </cmt> <iss> add some new thread metric and class metric to jvmmetric </iss>",add some new thread metric and class metric to jvmmetric (#7230)
2453,"<desc> description this pr migrates the doc's breadcrumbs page to hooks. relates to #15032. this is not ready for merge yet, since i have encountered some difficulties with typescript definitions in customizedbreadcrumbs (lines 12 and 44) and routerbreadcrumbs (lines 29 and 82). i didn't get what should be the type of props, when it does not extend withstyles i have followed (at least) the pr section of the contributing guide. </desc> <cmt> [docs] migrate collapsedbreadcrumbs to hooks </cmt> <cmt> [docs] migrate customseparator to hooks </cmt> <cmt> [docs] migrate customizedbreadcrumbs to hooks </cmt> <cmt> [docs] migrate iconbreadcrumbs to hooks </cmt> <cmt> [docs] migrate routerbreadcrumbs to hooks </cmt> <cmt> [docs] migrate simplebreadcrumbs to hooks </cmt>",migrate docs' breadcrumbs page to hooks
2454,"<desc> since c++17 is supported now in envoy, we can concisely replace the uninformative .first/.second variables with better names to improve readability. this belongs to a more expansive effort referenced here #12354. risk level: low, only cosmetic change is introduced testing: all existing tests passed </desc> <cmt> subject: replacing .first/.second with meaningful names </cmt> <cmt> changed a naming </cmt> <cmt> more name changes </cmt>",replacing .first/.second with meaningful names [envoy/include and miscellanies in envoy/source/common]
2455,<desc> for use in windows shells that are bash-like. closes #4586 </desc> <cmt> add initial windows atom wrapper script </cmt> <cmt> use $0 instead of %~dp0 </cmt> <cmt> add .sh extension </cmt> <cmt> install atom.sh shim </cmt> <iss> include bash launch scripts in /bin/ with the windows installer </iss>,add atom.sh and apm.sh windows scripts
2456,<desc> also updates to react-transform-hmr and handles some issues with it's throwing behavior. closes #643 & addresses comments on #690 </desc> <cmt> update to renamed react-transform-hmr. </cmt> <cmt> switch universal example to webpack-dev-middleware. </cmt> <cmt> better concurrent start script. </cmt>,use webpack-dev-middleware in universal example
2457,"<desc> summary this change adds the material 3 text style names to the texttheme api. it includes renames of all 2018 text styles and the introduction of 2 more styles for a total of 15. the 2018 names will be deprecated later on, once material 3 is fully implemented. part of #89853 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making, or this pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> add m3 text style names to text theme </cmt> <cmt> update typography constructors to use new text style names </cmt> <cmt> update typography tests </cmt> <cmt> update text theme tests </cmt>",update texttheme to have m3 names for styles
2458,"<desc> first, cleans things up by moving all the seen_datetime and seen_integer variables to the tops of their respective blocks. mainly splits the try: block for string_to_dts up into two pieces based on the two lines in that block that could raise and handles errors more specfically. </desc> <cmt> set seen_foo at the top of the inning </cmt> <cmt> catch exceptions in better order </cmt>",order of exceptions in array_to_datetime
2459,<desc> this mostly touches the first section of the docs. i also added some stuff to the rllib training docs to extend the table of contents. </desc> <cmt> fixes </cmt> <cmt> reorder pages </cmt> <cmt> cluster launcher </cmt> <cmt> rename </cmt> <cmt> update </cmt> <cmt> clean up pages </cmt> <cmt> remove outdated internal </cmt> <cmt> some rllib fixes </cmt> <cmt> model </cmt> <cmt> model summary </cmt> <cmt> update </cmt> <cmt> update </cmt>,consolidate and clean up documentation
2460,<desc> this pr changes it so we a) use globalthis to reference the global scope in internal code and b) we define global runtime variables in globals.ts in a more supportable fashion. </desc> <cmt> use globalthis for global scope access. </cmt> <cmt> cleanup defining globalthis properties </cmt>,use globalthis to reference global scope
2461,"<desc> as we're working through more feature detects in #509 we're missing from ringmark, here's another for blobbuilder. this can be updated to use the modernizr.prefixed(""blobbuilder"",window); syntax once #495 lands. </desc> <cmt> adding blobbuilder feature detect test </cmt> <cmt> revision to include support for moz </cmt>",adding feature detect test for blobbuilder
2462,"<desc> closes #39203 tests added / passed ensure all linting tests pass, see here for how to run them i didn't add a whatsnew entry since it's only style fixes. i'll open a new issue regarding @jreback suggestion to ban this with a precommit style rule. i prefer it to be done in a different pr. </desc> <cmt> style: remove use in pd.api.dtype in test_ufunc.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in test_integer.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in doc-string in inference.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in json/array.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in test_floating.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in list/array.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in dtype.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in test_bool.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in reshape.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in arrow/arrays.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype from doc-string and add import in generic.py (#39203) </cmt> <cmt> style: remove use in pd.api.dtype in decimal/array.py (#39203) </cmt> <cmt> style: remove extra line (#39203) </cmt> <cmt> style: run precommit hook to fix import locations (#39203) </cmt> <iss> style: dont' use pd.api.types anywhere in tests </iss>",dont use pd api types in tests
2463,"<desc> fix pie label layout in multiple cases. here are some of the typical cases: a. plain text cannot control wrapping and may be displayed outside of the canvas (left: before; right: after) b. the distances between labelline and labels are not correct due to the width calculation c. the background area of rich text is not correct d. line width of rich text is not correct e. when the text width is explicitly set, rich text area breaks the width constraint. most of the problems relates to text bounding rect calculation and this pr also fixes related logic with pie charts. a full list of changes are listed in the ""view visual test result"" part of this pr. #16023 this pr depends on zrender changes (ecomfe/zrender#847). test/pie-label-alignto-adjust.html please squash the commits into a single one when merge. run visual test of pie charts. </desc> <cmt> fix(pie): label position with rich text #16023 </cmt> <cmt> test(pie): add test case </cmt> <iss> pie chart rich labels overflow </iss>",label layout and text wrapping
2464,"<desc> @rocketchat/core closes #4315 removed unnecessary sizes and removed android icons from meta tags (android icons are requested by manifest.json) </desc> <cmt> normalize favicons, tiles and touchicons </cmt> <cmt> fix browserconfig identation </cmt> <cmt> add favicon svg </cmt> <iss> wrong favicon are shown in some browsers </iss>","fix favicons, tiles and touchicons"
2465,"<desc> @quval requested a cherrypick for 4.2.0 (#13558) to bring in the fixes for the ""test"" exec group inheritance (see #13459 and related commits). commits: 1e258d2 d067669 f1e0d34 8186fbb dcceaa3 68effbe e35aedf b9519f9 52b1b74 627c16e b120d4f 64534e2 9b18d95 762b5d8 a116649 afba8ac 645c42b </desc> <cmt> allow exec groups to inherit from the rule or other exec groups. </cmt> <cmt> work towards #12006. </cmt> <cmt> add a ""test"" exec group for testrunneractions. this will allow users to set {""test.key"", ""value""} inside their exec properties and {""key"", ""value""} will propagate as to just testrunneractions. </cmt> <cmt> this addresses user request #10799 </cmt> <cmt> this is a rollforward of c1ae939e2e27c928dc87ca64280948d93fdb056a, which </cmt> <cmt> was reverted in c266ac966761c4b3d8a408a03e407505c93effdd. </cmt> <cmt> closes #13119. </cmt> <cmt> piperorigin-revid: 360168649 </cmt> <cmt> support execution constraints per exec group </cmt> <cmt> when computing exec properties from the execution platform for an action, take into account only the properties that are relevant to the action's exec groups. in particular, allow setting exec properties for arbitrary exec groups on platforms. previously, any such properties were rejected. </cmt> <cmt> with this change, the following becomes possible: </cmt> <cmt>  </cmt> <cmt> cc_test( </cmt> <cmt> name = ""my_test"", </cmt> <cmt> ..., </cmt> <cmt> exec_properties = { </cmt> <cmt> ""test.key"": ""value"", </cmt> <cmt> }, </cmt> <cmt> ) </cmt> <cmt>  </cmt> <cmt> this will apply {""key"": ""value""} for the test-runner action only (i.e., compilation and linkage won't be affected). the following also becomes possible: </cmt> <cmt>  </cmt> <cmt> platform( </cmt> <cmt> name = ""test_platform"", </cmt> <cmt> constraint_values = ["":test_constraint""], </cmt> <cmt> exec_properties = { </cmt> <cmt> ""test.key"": ""value"", </cmt> <cmt> }, </cmt> <cmt> ) </cmt> <cmt> cc_test( </cmt> <cmt> name = ""my_test"", </cmt> <cmt> ..., </cmt> <cmt> exec_compatible_with = ["":test_constraint""], </cmt> <cmt> ) </cmt> <cmt>  </cmt> <cmt> this achieves the same in a more succinct way. </cmt> <cmt> for related discussion, see pr #12719 by @ulfjack. </cmt> <cmt> closes #13110. </cmt> <cmt> piperorigin-revid: 361167318 </cmt> <cmt> clean up rulecontext to use a table instead of a map of maps. </cmt> <cmt> closes #13164. </cmt> <cmt> piperorigin-revid: 361216667 </cmt> <cmt> documentation for #13110 </cmt> <cmt> closes #13167. </cmt> <cmt> piperorigin-revid: 361885312 </cmt> <cmt> split execgroup into a new target. </cmt> <cmt> piperorigin-revid: 372342357 </cmt> <cmt> create a new interface to allow starlark objects to get a thread when getindex is called. </cmt> <cmt> piperorigin-revid: 367454604 </cmt> <cmt> renamed execgroupcollection to clarify that it is only for starlark usage. </cmt> <cmt> non-starlark usage can go via the toolchaincollection directly. </cmt> <cmt> piperorigin-revid: 367461392 </cmt> <cmt> make starlarkexecgroupcontext use autovalue. </cmt> <cmt> this gives reasonable equals and hashcode behavior. </cmt> <cmt> piperorigin-revid: 367493368 </cmt> <cmt> use a dummy toolchain context for rules that don't have one. </cmt> <cmt> fixes #12610. </cmt> <cmt> closes #13162. </cmt> <cmt> piperorigin-revid: 361545255 </cmt> <cmt> extract a separate starlarktoolchaincontext for starlark-only operations. </cmt> <cmt> also make toolchaincontextapi use starlark threads. </cmt> <cmt> piperorigin-revid: 367515900 </cmt> <cmt> fix toolchains to support type lookup. </cmt> <cmt> fixes #13320. </cmt> <cmt> piperorigin-revid: 367624002 </cmt> <cmt> move default_exec_group_name from toolchaincollection to execgroup. </cmt> <cmt> piperorigin-revid: 372342837 </cmt> <cmt> rename toolchaincollection.getexecgroups to getexecgroupnames. </cmt> <cmt> piperorigin-revid: 372343218 </cmt> <cmt> buildviewfortesting should directly call into configuredtargetfunction. </cmt> <cmt> previously it was trying to replicate the code, but wasn't exact. </cmt> <cmt> piperorigin-revid: 372343711 </cmt> <cmt> move exec group tests out of platforms_test and into integration. </cmt> <cmt> piperorigin-revid: 372383546 </cmt> <cmt> update creating exec groups that explicitly copy from defaults. </cmt> <cmt> also add an execgroupsubject to improve testing. </cmt> <cmt> piperorigin-revid: 372387338 </cmt> <cmt> create a new execgroupcollection container to manage exec group inheritance and exec property parsing. </cmt> <cmt> fixes #13459. </cmt> <cmt> piperorigin-revid: 373388266 </cmt>",cherrypick request for 4.2.0: exec group changes
2466,<desc> merging commits that went to rc but skipped rcbugfix. </desc> <cmt> update readme.md </cmt> <cmt> * description for rc5 </cmt> <cmt> * hint for deprecated arduino versions </cmt> <cmt> update readme.md </cmt> <cmt> oops! at least 1.6.0 </cmt> <cmt> follow-up to commit 200b248(update readme.md) </cmt> <cmt> follow-up to commit 200b2487c2dfb1a5160c0974d2b7c6f2e54719ee </cmt> <cmt> update release date in another place </cmt>,merge rc => rcbugfix changes since rc5
2467,"<desc> this pr improves the registerguest method, allowing to pass the name of a livechat department as parameter, not only the department id. now the department value is checked before saving into guest document, finding for a valid department by both id and name property. </desc> <cmt> improvements on set livechat department by name, </cmt>",set livechat department before register guest
2468,"<desc> #129 this was a refactor to handle adding new 64k pages when existing heaps are used up.  i still have questions for @bytemaster on issue, so to complete this i just added some extra memory to _initial_heap and point to it.  that will be removed when the questions get answered. also, #481 is fixed and at least part of #425 . </desc> <cmt> fixed to correctly find the end of the memory.  fixes bug #481, and is part of #425. </cmt> <cmt> added new tests to verify the logic for adding memory pages. </cmt> <cmt> improved comments to make it easier to identify where errors occur. </cmt> <cmt> refactored existing handling of malloc and realloc to add new pages of memory.  currently, memory pages are fabricated. </cmt> <cmt> added more test cases, better comments, and cleaned up. </cmt>",wasm memory refactor to add more memory
2469,"<desc> i added some code to make the android emulator read glsl files correctly by making the data types constant for uniform variables. if the android emulator cannot read the data types of the variables, it will say opengl error 0x501 or 0x502 gluniform unable to find uniform variable depth. other variables will be affected after depth. with this bugfix, the variables will be read correctly by the android emulator and render your game. i removed too much lines earlier including the original lines for winrt and have placed those back with the bugfix. i needed to remove the earlier pull request to avoid confusion. </desc> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors </cmt> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors changed comment spelling. </cmt> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors correction. </cmt> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors correction in code. </cmt> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors correction in code spacing. </cmt> <cmt> android emulator bugfix for 0x501 and 0x502 opengl errors correction in code spacing. </cmt>",android emulator blank screen 0x501 and 0x502 problem bugfix update
2470,"<desc> this is mostly improving the spec test suite support (with this, the only unimplemented assertion types are ""invalid"" and ""malformed"", which can't be implemented until we have a wast parser). this also fixes some other bugs encountered on the way. </desc> <cmt> tests/libwasm: add support for javascript bigint values </cmt> <cmt> some i64 values will not fit in normal doubles, and these values _are_ </cmt> <cmt> tested by the test suite, this makes the test runtime capable of </cmt> <cmt> handling them correctly. </cmt> <cmt> meta: generate bigints for i64 values in libwasm test suite files </cmt> <cmt> libwasm: implement fx.nearest using nearbyint() instead of round() </cmt> <cmt> this instruction wants roundingmode::toeven, so let's use the correct </cmt> <cmt> function. </cmt> <cmt> tests/libwasm: handle all stream errors in parse_webassembly_module </cmt> <cmt> meta: implement support for the ""unlinkable"" wasm spectest assertion </cmt> <cmt> libwasm: make the truncate operator trap on undefined results </cmt>",yet another bag of fixes
2471,<desc> hopefully this the final fix for #848 @skalot i think i found a way to record all inlined classes. i am not sure if the way i have chosen is what you had in mind. therefore consider this pr as a base for discussion. </desc> <cmt> fix: additionally show smali code of all inlined classes (recursively) </cmt> <cmt> variable name corrected </cmt>,record inlined classes and also generate smali code for them
2472,"<desc> some package repositories which require basic http authentication include the user's credentials in urls returned as part of json responses. because poetry's request authentication system checks for a matching netloc, this ends up breaking basic http authentication for such repositories. this pull request compares by hostname instead of netloc. because hostname doesn't include any extra url authentication information, this fixes access to these repositories. this fixes issue #746. </desc> <cmt> fix authentication failure for some apis </cmt> <cmt> fixes an issue which occurs when apis return authentication information in the urls embedded in json responses. </cmt> <cmt> test authentication on same host with duplicated credentials </cmt> <cmt> add test to ensure that basic authentication credentials in request urls does not break authentication when they credentials match. this test purposefully does not examine program behavior when url credentials and session credentials are different. </cmt>",fix request authentication when credentials are included in urls
2473,"<desc> added a via layout for the frosty flake controller for the coolermaster quickfire rapid. not sure if anyone still has this keyboard, but i had one laying around and i wanted to see if i could port it to via. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> updated my personal layouts </cmt> <cmt> added artix to install script </cmt> <cmt> setting up for pr </cmt> <cmt> added artix to install script </cmt> <cmt> created frosty flake via keymap.c </cmt> <cmt> created the default via keymap.c file for the frosty flake controller </cmt> <cmt> created frosty flake via keymap.c </cmt> <cmt> create rules.mk </cmt> <cmt> add #define dynamic_keymap_layer_count 3 </cmt> <cmt> update keymap.c </cmt> <cmt> delete keyboards/tada68/keymaps/trashcat directory </cmt> <cmt> create keymap.c </cmt> <cmt> create readme.md </cmt> <cmt> create rules.mk </cmt> <cmt> delete keyboards/whitefox/keymaps/trashcat directory </cmt> <cmt> update qmk_install.sh </cmt> <cmt> rename readme.md to readme.md </cmt>",adding frosty flake via keymap
2474,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> adding .d.ts for the tress library </cmt> <cmt> removing dev additions from the package.json </cmt>",type definitions for the tress library
2475,<desc> description: add missing documentation for addon_restart and addon_stdin for hassio integration in services.yaml file. i took the opportunity to reformat all the file in full yaml checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> add services doc </cmt> <cmt> add missing services doc and reformat </cmt>,add missing documentation for some hassio services
2476,"<desc> reference: #20687 added a new section ""data considerations"" in sklearn/datasets/descr/twenty_newsgroups.rst. the previous pr failed due to formatting errors. fixing them too. this is my first contribution to a public repo. please bear with me for the errors. </desc> <cmt> added data considerations for explaining the dataset language </cmt> <cmt> add data considerations section to the descrition of twenty_newsgroups datasets </cmt> <cmt> fix the pull request errors </cmt> <cmt> fix the pull request errors </cmt> <cmt> fix the pull request errors url </cmt>",doc add a note for some data considerations with 20newsgroups dataset
2477,"<desc> fixes #3236. if your type argument inference source is a primitive or a type parameter, we don't use the apparent type to get its structure to dive deeper. this change gets the apparent type for better inference. </desc> <cmt> take the apparent type of the source in type argument inference </cmt> <cmt> add tests </cmt>",take the apparent type of the source during type argument inference
2478,"<desc> @carltongibson it looks like an update to the security release archive was missed. i've checked the release process in case it was missing and something needed amending, but i did find it here as point 3. hope these commits do the trick. they will need backporting as appropriate. </desc> <cmt> added cve-2019-11358 to the security release archive. </cmt> <cmt> added cve-2019-12308 to the security release archive. </cmt>",updated security release archive with missing entries.
2479,"<desc> see #1330 support metaspacesize and maxmetaspacesize  in java8+ in linux and windows i use shell or batch to get java version by java -fullversion, you can see it in commit. in the commit ,you can find i use java_8_version=""180"" to compare java vesion. the reasion is that java version naming rule change in java 9. java -fullversion output example in jdk1.7 -> java full version ""1.7.0_79-b15"" in jdk1.7 -> java full version ""1.8.0_152-b16"" in jdk9 -> java full version ""9.0.4+11"" i find many dos symbol in start.sh, if you run start.sh in linux, it may be a problem. i use dos2unix cmd to format the file. test result in windows jdk9 jdk1.8 jdk1.7 </desc> <cmt> fix [set vm args by different java version] fix #1330 </cmt> <cmt> fix [set vm args by different java version] fix #1330 </cmt> <cmt> fix [set vm args by different java version] fix #1330 </cmt> <cmt> fix [set vm args by different java version] fix #1330 </cmt> <cmt> fix [set vm args by different java version] fix #1330 </cmt>",fix support metaspacesize and maxmetaspacesize vm args in java8+
2480,"<desc> this pull request adjusts the visual testing with storybook documentation to be more accurate and streamlined. it follows up on #31653 that was recently merged. what was done: the documentation was polished to include more accurate instructions on how to set up storybook with gatsby. the example story was updated to a more accurate example. @meganesu, @lekoarts if you could follow up with me on this i'd appreciate it. thanks in advance! stay safe </desc> <cmt> update gatsby fork for further fixing errors on the starter submission </cmt> <cmt> april update gatsby fork </cmt> <cmt> april update fork </cmt> <cmt> august update </cmt> <cmt> updates for the storybook documentation </cmt>",update storybook guide with addon
2481,"<desc> closes #18601. sub-modules, such as np.linalg, must be explicitly imported in the main namespaces' stub file if one wants to access the sub-module via a getattr operation, i.e. so that one can directly use np.linalg.norm rather than import numpy.linalg; np.linalg.norm. while this was taken care of in the main numpy namespace, the relevant annotations were missing for others such as np.lib.*. this pr fixes aforementioned issue. examples the behavior prior to this pr: >>> import numpy as np >>> x = np.arange(6) >>> out = np.lib.stride_tricks.sliding_window_view(x, 3) mypy output: test.pyi:4:7: error: module has no attribute ""stride_tricks""  [attr-defined] </desc> <cmt> api: formally classify np.lib.stride_tricks as part of the public api </cmt> <cmt> with as_strided, and the newly introduced sliding_window_view function, there are currently 2 public objects that can: </cmt> <cmt> a. only be imported from a private module </cmt> <cmt> b. are publicly documented to-be imported from aforementioned module </cmt> <cmt> both observations are problematic and in need of rectification. </cmt> <cmt> this commit therefore moves np.lib.stride_tricks to the public_modules list. </cmt> <cmt> maint: re-export a number of sub-modules </cmt> <cmt> ensures that type checkers will allow the likes of: </cmt> <cmt> >>> import numpy as np </cmt> <cmt> >>> out = np.lib.stride_tricks.sliding_window_view(...) </cmt> <iss> annotations don't import np.lib.* </iss>",ensure that re-exported sub-modules are properly annotated
2482,"<desc> closes #34297 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff @jbrockmendel i added a lenght check as suggested by you. i could not find another method to check the indices (nlevels for example does not work). i'm open to recommendations about adding additional checks before running into the values call. i have added a test, which measures the execution time of both calls to sub. is there a better way to test, if they are equally fast? </desc> <cmt> add additional checks if arrays are equal to avoid costly function call </cmt> <cmt> add test to check performance </cmt> <cmt> run black pandas and delete one check </cmt> <cmt> add list comprehension </cmt> <iss> bug: subsequent calls to df.sub() are much faster than the first call </iss>",34297 sub slow in first call
2483,"<desc> this is the final pr in the stack of #1185, #1169, #1151, and #1117 that modify zstd's compression strategies to allow searching an independent, immutable dictionary context. this pr extends support to the zstd_btopt and zstd_btultra levels. two further work items are planned (in separate prs): improve the heuristic that controls when to attach a dictionary vs when to copy it into the working context. provide a user-accessible override of that heuristic to allow forcing / disallowing attaching the dictionary. </desc> <cmt> attach dicts when using zstd_btopt and zstd_btultra </cmt> <cmt> convert extdict flag to dictmode enum </cmt> <cmt> add _dictmatchstate functions </cmt> <cmt> implement repcode check </cmt> <cmt> switch != zstd_extdict to == zstd_nodict </cmt> <cmt> fix typo </cmt> <cmt> find mls == 3 matches </cmt> <cmt> misc fixes </cmt> <cmt> find proper matches </cmt> <cmt> misc changes </cmt> <cmt> fix compression ratio regression #1 </cmt> <cmt> make sure position 0 gets into the tree </cmt>",support searching the dictionary context in-place
2484,"<desc> the preload attribute specifies a script that will be loaded before other scripts run in the guest page, this script always has access to node apis no matter whether node integration is on in guest page. fixes #776. </desc> <cmt> pass ""preload"" attribute to guestviewmanager </cmt> <cmt> load the ""preload"" script in <webview> </cmt> <cmt> spec: ""preload"" attribute of <webview> </cmt> <cmt> docs: ""preload"" attribute of <webview> </cmt> <iss> webview ipc unavailable without node integration </iss>","add ""preload"" attribute for <webview>"
2485,"<desc> this exposes the torch distributed optimizer settings by adding it as the top level ""ddppo"" trainer. closes #6636 </desc> <cmt> wip </cmt> <cmt> lint </cmt> <cmt> stats </cmt> <cmt> update </cmt> <cmt> doc it </cmt> <iss> any plans to support decentralized distributed ppo? </iss>",add decentralized ddppo trainer and documentation
2486,<desc> i hereby agree to the terms of the cla available at:  fix error output of treeexecutor is not sorted for optimize deduplicate. fixes #11572 </desc> <cmt> remove sortdescription from iblockinputstream. </cmt> <cmt> added test. </cmt> <iss> output of treeexecutor is not sorted after optimize final deduplicate </iss>,remove sort description from streams
2487,"<desc> this pr fixes a bug that made the ordering of nodeids values to be lost. the order in which the node filters are specified is important as it dictates which nodes are being kept and which not in the list for which the metrics are retrieved. fixes #41885. </desc> <cmt> switch to using a list instead of a set for the filters, so that the </cmt> <cmt> order of these filters is kept. </cmt> <iss> nodes types filters order not kept for _nodes api </iss>",prevent order being lost for _nodes api filters
2488,"<desc> implements the community id hash that will allow correlating network connections detected by osquery with other tools that support the standard (zeek, suricata, etc.). add boost endian library refactor core hashing utility to allow base64 encoding (backwards compatible) implement community id thanks to @security-onion-solutions for supporting development of this feature. </desc> <cmt> semi-working, needs ordering </cmt> <cmt> add ordering </cmt> <cmt> working with tests </cmt> <cmt> add docs </cmt> <cmt> remove debug print </cmt> <cmt> format </cmt> <cmt> update doc </cmt>",add community_id_v1 hash function to sqlite
2489,"<desc> doing so unconditionally breaks standalone + autodebug. this has to move some emcc.py code to decide if we need to legalize to an earlier place, so we know that when we do the autodebug stuff as part of the binaryen passes. also_with_impure_standalone_wasm has to use bigint support while doing the ""impure"" part. in that mode we test standalone but not in a wasm vm, rather in a js vm. so we don't legalize, but we do connect to js. without bigint, we would trap on i64s. </desc> <cmt> fix legalization of autodebug with standalone mode [ci skip] </cmt> <cmt> fix + test </cmt>",only legalize as part of autodebug if we should do so
2490,"<desc> add or edit tests to reflect the change. (run with npm test.) run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> feat: react hooks helper types </cmt> <cmt> fix: react hooks helper test </cmt>",types for npm package: react-hooks-helper
2491,"<desc> when searching issues, the snuba backend will use postgres results to filter on message. this pr removes this functionality, and we now use snuba for filtering on messages. </desc> <cmt> removing postgresql query filter on message </cmt> <cmt> first draft of removing message related queries on postgres </cmt>",make message queries use snuba instead of postgres
2492,<desc> this pull request adds a default onfullfilled/onrejection handler to remote promises so that unhandled rejections of remote promises appear in the renderer process instead of the main process. also adds some var -> const/let formatting to rpc-server.js. closes #6113 </desc> <cmt> add failing spec for unhandled main process exception </cmt> <cmt> remove unused return </cmt> <cmt> use let/const instead of var </cmt> <cmt> add spec for unhandled rejection in renderer process </cmt> <cmt> prevent unhandled rejection defaul </cmt> <cmt> use once instead of on </cmt> <cmt> add default fulfilled/rejection handler to promise </cmt>,add default error handler to remote promises
2493,<desc> kafka-12541 introduced a regression for listoffsets requests for non maxtimestamp specs. when communicating with old brokers. this pr addresss this case. tested with new unit test for regression case. </desc> <cmt> kafka-12541 add max_timestamp spec to listoffsets api </cmt> <cmt> kafka-12541 updated replica fetcher to use latest listoffsets request version </cmt> <cmt> kafka-12541 refactor with retry approach in kafkaadminclient </cmt> <cmt> kafka-12541 added logoffsettest tests </cmt> <cmt> kafka-12541 tidy up </cmt> <cmt> kafka-12541 fixes per pr review </cmt> <cmt> kafka-12541 adminclient simplification </cmt> <cmt> kafka-12541 refactor of listoffsets retry per pr review comments </cmt> <cmt> kafka-12541 fixes per pr review </cmt> <cmt> kafka-12541 stopped retries for partitions that cannot use max_timestamp </cmt> <cmt> kafka-12541 roll back changes to requestresponsetest </cmt> <cmt> kafka-12541 fixes per pr review </cmt> <cmt> kafka-12541 fixes per pr review </cmt> <cmt> kafka-12541 fixes per pr review </cmt> <cmt> kafka-13002 fix for immediate downgrade cases for non max timestamp requests </cmt>,listoffsets must downgrade immediately for non max_timestamp specs
2494,"<desc> closes #33562 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry the problem with above issue was with the function non_reducing_slice. it didn't correctly re-format slicing tuples on multiindices when rows or cols also contained a slice(none). an additional check is now done. this method is only used for styler currently. tests added / reformmatted. </desc> <cmt> tst: edited and expanded for latest issue </cmt> <cmt> bug: subset non-reducer </cmt> <cmt> bug: subset non-reducer </cmt> <cmt> bug: subset non-reducer </cmt> <iss> bug: df.style.apply(subset=...) argument only works for explicit slices but not "":"" </iss>",subset slicer on styler failed on multiindex with slice(none)
2495,"<desc> backport of #14360. addresses part of gh-14359 todo / to decide: there's still two namespaces left that look private: numpy.random.entropy (contains random_entropy and seed_by_array, unclear if those need to be public) numpy.random.bit_generator (contains only bitgenerator as a public object i think) </desc> <cmt> doc: fix doc linking, was referencing private submodules. </cmt> <cmt> closes gh-14359 </cmt> <cmt> doc: address last comment on numpy.random doc page fixes pr </cmt>","random: fix doc linking, was referencing private submodules."
2496,"<desc> these enhancements were discussed before at </desc> <cmt> enh: enhance meshgrid to generate 3d grids, sparse grids, matrix indexing. </cmt> <cmt> maint: clean up docstring and some minor items in meshgrid.  remove ndgrid. </cmt> <cmt> bug: meshgrid: raise error on single input. </cmt> <cmt> tst: meshgrid: test expected shapes for cartesian and matrix indexing. </cmt>","meshgrid enhancements (>2-d, sparse grids, matrix indexing)"
2497,"<desc> i started to use the pubnub type definitions, but i needed to call the set of methods i have added. i've had a forked copy of this file in my codebase for a few months, so i wanted to merge it in here so i can remove the file from my code. i was referencing pubnub@4.25.2, which is the latest version. i don't know if there are other things still missing from the types here, but i only focused on adding the ones i needed. provide a url to documentation or source code which provides context for the suggested changes:  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. (i was referencing 4.25.2, but i'm only adding the parts i need and not checking everything.) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add type definitions for channelgroup methods to pubnub type definitions </cmt> <cmt> fix the code formatting after husky configs butchered it </cmt> <cmt> add tests </cmt> <cmt> check in auto-formatted code </cmt>",add channelgroup type definitions to pubnub types
2498,"<desc> checklist add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). reason for changes documentation for ontransitionstart available here. i recognise that on this same page the documentation for ontransitionend does not support my change, but please refer to my issue here as i believe that documentation is incorrect. increase the version number in the header if appropriate. i don't believe it is appropriate if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. changes are minor </desc> <cmt> react-navigation ontransition prop passing </cmt> <cmt> only transition start takes a promise </cmt>",react-navigation ontransition event pass props
2499,"<desc> hi, sorry i am not sure if you are expecting from me to write something into the message or just to be sure to fill everything in my pr from this message.  hope the second one. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> types for osmosis node module </cmt> <cmt> repair linter errors </cmt>",adding new type for osmosis module
2500,"<desc> added some new extension points (also see screenshots): query view and source pages: ability to add extra actions in page header dashboard page: ability to add extra actions in page header query and dashboard list pages: ability to add a toolbar with actions that will be rendered above the table. toolbar component should call onstatechange to notify parent that it's available, in that case page will allow to select items in the table and pass selection to the toolbar component. example of the toolbar component: function extraactionscomponent({ selecteditems, onstatechange }) { useeffect(() => { onstatechange({ isavailable: true }); }, [onstatechange]); return <button disabled={selecteditems.length === 0}>very useful button</button>; } </desc> <cmt> extra actions for query view and query source pages </cmt> <cmt> convert queries list page to functional component </cmt> <cmt> convert dashboards list page to functional component </cmt> <cmt> extra actions for query list page </cmt> <cmt> extra actions for dashboard list page </cmt> <cmt> extra actions for dashboard page </cmt>",extra actions on queries and dashboards pages
2501,<desc> cherrypicked from: ebdf78d backport pr for check point unit tests for the following module from pr #62216: test_cp_mgmt_access_layer.py test_cp_mgmt_access_layer_facts.py test_cp_mgmt_access_role.py test_cp_mgmt_access_role_facts.py test_cp_mgmt_administrator_.py test_cp_mgmt_administrator_facts.py test_cp_mgmt_application_site.py test_cp_mgmt_application_site_facts.py test_cp_mgmt_application_site_catagory.py test_cp_mgmt_application_site_catagory_facts.py test_cp_mgmt_application_group.py test_cp_mgmt_application_group_facts.py test_cp_mgmt_dns_domain.py test_cp_mgmt_dns_domain_facts.py test_cp_mgmt_dynamic_object.py test_cp_mgmt_dynamic_object_facts.py test_cp_mgmt_exception_group.py test_cp_mgmt_exception_group_facts.py unit tests pr check_point </desc> <cmt> changelog </cmt> <cmt> forth pr 18 tests (#62216) </cmt> <cmt> * update test_cp_mgmt_network.py </cmt> <cmt> * 18 tests </cmt> <cmt> (cherry picked from commit ebdf78d6e43fb20e1f70bd0f59f05922bcc19770) </cmt>,backport pr for check point unit tests for the following module from pr 62216
2502,"<desc> currently stat descriptions are single line forcing the scrollbar. so every time we need to read, we need to scroll a lot to get to the full description. this pr adds a css that allows us to split and align lines correctly. risk level: low testing: manual verification of docs docs changes: n/a release notes: n/a </desc> <cmt> fixed server stats docs </cmt> <cmt> fix comment </cmt> <cmt> fix comment </cmt> <cmt> new css added </cmt> <cmt> css folder </cmt> <cmt> multi line changes </cmt> <cmt> resolved conflicts </cmt> <cmt> stats merged </cmt> <cmt> changed cluster and http con mgr stats </cmt>",css to support multiline descriptions in stats
2503,<desc> i have followed (at least) the pr section of the contributing guide. related to #16947 </desc> <cmt> docs: migrate variant anchorplayground demo to emotion </cmt> <cmt> docs: migrate variant basicpopover demo to emotion </cmt> <cmt> docs: migrate variant mousepopover demo to emotion </cmt>,migrate popover demos to emotion
2504,"<desc> adds: a basic, incomplete implementation of array.from() a basic, incomplete implementation of date.tolocalestring(), date.tolocaledatestring(), date.tolocaletimestring() a mostly-working implementation of node.textcontent also slightly simplifies the clock menuapplet. </desc> <cmt> libjs: implement basic functionality of array.from() </cmt> <cmt> the optional 2nd and 3rd arguments are not yet implemented. </cmt> <cmt> this assumes that this is the array constructor and doesn't yet </cmt> <cmt> implement the more general behavior in the es6 spec that allows </cmt> <cmt> transferring this method to other constructors. </cmt> <cmt> libjs: add tolocalestring(), tolocaledatestring(), tolocaletimestring() to date </cmt> <cmt> these just return a ""readable"" implementation of the date for now. </cmt> <cmt> clock menuapplet: use core::datetime to simplify the code </cmt> <cmt> libweb: add node.textcontent </cmt> <cmt> this requires moving remove_all_children() from parentnode to </cmt> <cmt> node, which makes parentnode.cpp empty, so remove it. </cmt> <cmt> it also co-opts the existing node::text_content() method and </cmt> <cmt> tweaks it slightly to fit the semantics of node.textcontent. </cmt>",implement various javascript and dom things.
2505,<desc> closes #13889 </desc> <cmt> tst only report coverage on pylatest_conda </cmt> <cmt> tst only one instance </cmt> <cmt> combine with append </cmt> <cmt> rev enable all tests </cmt> <cmt> rev remove ls </cmt> <iss> coverage on pandas not being reported to codecov </iss>,fixes coverage reporting on pylatest_conda
2506,"<desc> hi, i would like to suggest a ""frequent"" bloggers sections to be added to the list of resources. people interested in staying up-to-date with the latest news and tips&tricks provided by developer blogs can simply add the blogs to their rss readers. a separation could be made between official blogs and community driven blogs (developer blogs). kind regards ruben </desc> <cmt> added frequent bloggers of react native. </cmt> <cmt> added two official react native blogs </cmt>",add bloggers section to list of react native resources
2507,<desc> this updates the alert details page sidebar for the change alerts. if it's a change alert we show comparison scheme in writing and a more descriptive threshold description for other alerts. also added actions for critical and warning thresholds based on the new design. also removed the threshold lines for change alerts. old (same for change/non-change alerts): new (non-change alert): new (change alert): jira: wor-1450 </desc> <cmt> new trigger text style </cmt> <cmt> change alert threshold text </cmt> <cmt> remove threshold lines for change alerts </cmt>,show thresholds for change alerts in the alert details sidebar
2508,"<desc> as suggested by @drashna, i converted the rules.mk for iris to use split_keyboard. had to modify the quantum/split_common/matrix.c to fix a build error. </desc> <cmt> convert iris to split-common </cmt> <cmt> fix build error </cmt>",convert iris to use split_keyboard
2509,"<desc> hi i'm sean, co-founder of magic! this pull request adds an official example of using magic to implement cookie-based, passwordless authentication with email-based magic links. this work is based on the existing with-passport example (following existing layout and styles), removed dependencies on passport and express, and influenced by @emwsc's pull request: #11678 demo: </desc> <cmt> add example with magic and passport.js </cmt> <cmt> tweaked wording on readme </cmt>",add example with magic authentication
2510,<desc> i have followed (at least) the pr section of the contributing guide. migrated popover component's mouse over interaction demo from class components to hooks </desc> <cmt> override step props over internal state of stepper </cmt> <cmt> add a unit test </cmt> <cmt> merge upstream with 'master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> migrate mouseoverpopover demo to use hooks </cmt>,migrate popover demo to hooks
2511,"<desc> this pr manages a second ""feedrate"" applied only to g0 moves. it saves/restores the primary feedrate upon evaluation, and likewise restores/saves g0 feedrate. this increases compatiblity with cnc produced gcode, and can speed up cnc gcode execution where faster g0 is implied. and f is not respecified at each command. would answer to feature request #12047 </desc> <cmt> g0_feedrate </cmt> <cmt> remove default activation </cmt> <cmt> restore unintended suppression of a configuration part </cmt>",option for g0 to have a separate feedrate
2512,<desc> this is a quality of life improvement for typical users. almost all anomaly detection jobs receive their input data through a datafeed. the datafeed config can now be supplied and is available in the datafeed_config field in the job config for creation and getting jobs. backport of: #74265 </desc> <cmt> [ml] add datafeed field to the job config (#74265) </cmt> <cmt> this is a quality of life improvement for typical users. almost all anomaly jobs will receive their data through a datafeed. </cmt> <cmt> the datafeed config can now be supplied and is available in the datafeed field in the job config for creation and getting jobs. </cmt> <cmt> fixing for backport </cmt>,add datafeed_config field to anomaly detection job configs
2513,<desc> breaking change: n/a description: improve log error and debug messages to help understand unexpected errors. related issue (if applicable): fixes partially #25513 **pull request with documentation for home-assistant.io (if applicable): n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> improve log error messages </cmt> <cmt> remove unique_id not ready yet </cmt>,meteofrance improve log error messages
2514,"<desc> bump the android gradle plugins versions to the latest. android studio 4.1+ seems to stop providing editor support for (and recognizing) android libraries when they define an external native build whose root includes the library's directory. as a workaround, i moved the external native build definition into a separate empty android library. this does not affect the project structure since the external native build definition was added in the first place for android studio editor support (the actual native dependencies are handled by scons). </desc> <cmt> update the gradle plugins </cmt> <cmt> add a separate nativesrcsconfigs module to handle android studio constraints for native code editor support. </cmt>",update android gradle plugins versions
2515,"<desc> five new documents: how netdata's metrics collectors work enable or configure a collector collect system metrics with netdata collect container metrics with netdata collect application metrics with netdata see netdata/learn#285 for additional context. this page contains some elements that will only appear on the deployed learn site, so see the deploy preview for this page for the full picture:  some links will not work, as the target docs do not exist yet. for now, these prs will get merged into the docsv2 but not go live on netdata learn. once they're all available, or at least a workable majority, we'll merge them into master and deploy the project as a whole. component name area/docs </desc> <cmt> init files </cmt> <cmt> finish first two collect docs </cmt> <cmt> finish drafts of collect docs </cmt>",add collect docs to the docsv2 project
2516,"<desc> adds unit and integration tests for updating the backend config. this also standardizes the old create_backend codepath and the new deploy codepath on the same underlying call to update a backend config. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> unit tests for backend state </cmt> <cmt> add goals </cmt> <cmt> add explicit goal tests </cmt> <cmt> remove </cmt> <cmt> fix non-detached </cmt> <cmt> small fix </cmt> <cmt> fix version </cmt> <cmt> add cleanup(), include in unit tests </cmt> <cmt> fixes </cmt> <cmt> add exit_actor call </cmt> <cmt> medium for test_handle </cmt> <cmt> refactored unit tests </cmt> <cmt> add tests </cmt> <cmt> add unit tests for updating config </cmt>",add backend_state tests for updating backend config
2517,"<desc> closes #18431 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> doc: add whatsnew note </cmt> <cmt> tst: added test for date_range and datetimeindex with mismatching timezones </cmt> <cmt> bug: fixed exception not being raised if end.tzinfo is none but start.tzinfo is not none </cmt> <cmt> tst: fixed new test failure in test_with_tz to pass in a tzaware end date </cmt> <iss> bug: date_range is inconsistent when given mixed tz aware and tz unaware start/end </iss>",fix tzaware dates mismatch but no exception raised
2518,<desc> description of change this problem is a part of the original problem subset sum in sense that here it will only count those subsets that are continuous arrays. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines </desc> <cmt> create subarray_sum.cpp </cmt> <cmt> updating directory.md </cmt> <cmt> clang-format and clang-tidy fixes for 0a293ece </cmt>,add the subarray sum implementation
2519,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. manual notification for @clmcgrath since bot says ""account can't be detected"". </desc> <cmt> updates flickity definitions for v2 and enables use as a module </cmt> <cmt> adds tslint.json and makes tslint happy </cmt>",updates flickity definitions for version 2 and enables use as a module
2520,<desc> this adds support to the gradle builds for intellij to import the project and have classpaths set correctly. gradle documentation for these changes: </desc> <cmt> fix javadocs - cleanup some warnings </cmt> <cmt> add intellij idea support to gradle build </cmt> <cmt>  </cmt>,support 'provided' dependencies in intellij idea build
2521,"<desc> in this pr: bringing the independent subsystems together via the plugin wiring up the http rpc endpoint wiring up the chain_controller signals adding to nodeos linking temporary fix for ""a+"" mode reads not starting at offset 0 on osx </desc> <cmt> initial http wiring </cmt> <cmt> basic ephemeral store wired into responses </cmt> <cmt> merging http wiring branch </cmt> <cmt> wire in a temporary ephemeral data store implementation to end-to-end test extract and response generation </cmt> <cmt> merge feature/trace-api-plugn @ 3dd66aac1bf103f71587dbc98e84204d6d14c787 </cmt> <cmt> merging feature/trace-api-plugin @ 9f196730fb41fdefd0fd9155ae8103e658568ca8 </cmt> <cmt> fix merges in the night conflict </cmt> <cmt> merging feature/trace-api-plugin @ 0e8978e4d46ca20728a9dab836996414f053eeb6 </cmt> <cmt> integrated with changes to extraction provider constructor </cmt> <cmt> shim to old store api to start working on integration issues </cmt> <cmt> refactored repeated try/catchs </cmt> <cmt> temp fix for osx append read bug </cmt> <cmt> merging feature/trace-api-plugin @ 500ed8e7c4ca41c2299142b47788fd7f7c6974b1 </cmt> <cmt> merging feature/trace-api-plugin @ 51e15ef093c314228b810d280daab076e34aba92 </cmt> <cmt> merging feature/trace-api-plugin @ 6f0832001eff32a975d78732d15a9abbabe88b0d </cmt> <cmt> remove the shim now that the api matches </cmt>",trace api plugin - initial integration
2522,"<desc> this is a significant reorganization of the diff code. i took the old src/diff_output.c that had grown quite large and split it into: src/diff_file.c loads individual files - a patch contains two of these src/diff_patch.c generates patches and can be iterated src/diff_xdiff.c wraps the xdiff dependencies and provides some isolation in the rest of the code src/diff_driver.c is a new file that contains the framework for supporting diff drivers, function context, etc. each of these files is much smaller with a narrower focus. i tried to explain the breakdown of everything in the new docs/diff-internals.md. as part of the new diff drivers work, i added a diff driver cache to the git_repository and removed several unnecessary includes from src/repository.h. after i removed those includes, i had to compensate in a bunch of places around the codebase, but i think it is a good thing because the includes were really overbroad imo. i looked at things in valgrind and there are a bunch of leaks, but most seem related to the new refs stuff and not to this diff code. there is a commit that fixes a few memory leaks that i stuck in just to try to get the valgrind output more readable. reorganize diff into more discrete parts implement diff driver framework implement ""unspecified"" default diff driver that finds last non-blank line (as per core git) implement ""unset"" diff driver that treats file as binary / undiffable implement ""set"" diff driver that forces file to be treated as text [not implemented correctly at the moment] implement ""pattern"" config-based diff drivers with regex matching better isolation for libxdiff code bits add apis to generate git_diff_patch from blobs (or blob and buffer) </desc> <cmt> basic function context header </cmt> <cmt> this implements a basic callback to extract function context for </cmt> <cmt> a diff.  it always uses the same search heuristic right now with </cmt> <cmt> no regular expressions or language-specific variants.  those will </cmt> <cmt> come next, i think. </cmt> <cmt> move some diff helpers into separate file </cmt> <cmt> reorganize diff and add basic diff driver </cmt> <cmt> this is a significant reorganization of the diff code to break it </cmt> <cmt> into a set of more clearly distinct files and to document the new </cmt> <cmt> organization.  hopefully this will make the diff code easier to </cmt> <cmt> understand and to extend. </cmt> <cmt> this adds a new git_diff_driver object that looks of diff driver </cmt> <cmt> information from the attributes and the config so that things like </cmt> <cmt> function content in diff headers can be provided.  the full driver </cmt> <cmt> spec is not implemented in the commit - this is focused on the </cmt> <cmt> reorganization of the code and putting the driver hooks in place. </cmt> <cmt> this also removes a few #includes from src/repository.h that were </cmt> <cmt> overbroad, but as a result required extra #includes in a variety </cmt> <cmt> of places since including src/repository.h no longer results in </cmt> <cmt> pulling in the whole world. </cmt>",diff code reorg plus function context in diff headers
2523,<desc> fix mono export template build errors. fixes #25903 don't print 'cannot find mono in the registry' if bundled with godot. closes #24753 </desc> <cmt> mono: fix export template build errors </cmt> <cmt> fixes #25903 </cmt> <cmt> don't print 'cannot find mono in the registry' if bundled with godot </cmt> <cmt> closes #24753 </cmt>,get rid of irrelevant error and fix export template build errors
2524,"<desc> hide any commandline (cooked read) we have before we begin a resize, and show it again after the resize. i found #5618 while i was working on this. closes #1856 i work here basically, during a resize, we try to restore the viewport position correctly, and part of that checks where the current commandline ends. however, when we do that, the commandline's current state still reflects the old buffer size, so resizing to be smaller can cause us to throw an exception, when we find that the commandline doesn't fit in the new viewport cleanly. by hiding it, then redrawing it, we avoid this problem entirely. we don't need to perform the check on the old commandline contents (since they'll be empty), and we'll redraw it just fine for the new buffer size ran tests checked resizing, snapping in conhost with a cooked read checked resizing, snapping in the terminal with a cooked read </desc> <cmt> this is the test for #1856 </cmt> <cmt> this is the fix for #1856 </cmt> <cmt> add a resizing helper that will force you to do the right thing </cmt> <iss> snapping to smaller screen with a cooked_read crashes conpty </iss>",hide the commandline on a resize to prevent a crash when snapping the window
2525,"<desc> this is another step towards #3016. it proposed using r's standard interface to handle integers passed into the c++ side (for things like array size, buffer size, number of iterations, etc.). changes in this pr: use r builtin sexp type for any arguments passed from r to c++ that should be read-only integers use r builtin rf_asinteger() to convert those sexp objects to ints (replacing lightgbm's r_as_int) fix minor inconsistencies between lightgbm_r.h and lightgbm_r.cpp (e.g. parameter named nrow in the header file and num_row in the implementation) background there is not a scalar integer type in r. when you run some code like x <- 1l, r creates a length-one array (referred to in r as a ""vector""). to treat such data as an integer, instead of an integer array, in c/c++, it's necessary to extract the first element of that array into a new int. r provides a convenience function, rf_asinteger(), for exactly that purpose. see  notes for reviewers this does not rely on #4242 </desc> <cmt> [r-package] replace r_as_int with r built-in </cmt> <cmt> merge master </cmt> <cmt> update header </cmt> <cmt> more changes </cmt>",use r standard routine to access read-only ints passed to c++
2526,"<desc> this pr does 2 things export all types fix references type. previously it was an object of babel.nodepath. however, the docs say it is an object. i've been unable to lint these packages locally because of the following error any advice on how to fix it is appreciated. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> update babel-plugin-macros types to match docs </cmt> <cmt> babel-plugin-macros update version and ts version </cmt>",export all types and fix references type
2527,<desc> without this pr partial function will fail due to missing fields. closes #17800 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> up </cmt> <cmt> up </cmt> <cmt> up </cmt> <iss> error for serialize function object with variable passed in </iss>,allow function without __module__ and __qualname__
2528,"<desc> modifies win_hosts module to use the ansible.basic csharp util instead of the legacy powershell module. also includes an improvement to the diff support. instead of generating a prepared diff, it uses the before, after properties. win_hosts i also updated the documents so that it better matches the development guide. before diff change task [win_hosts : remove aliases from the list] *********** -[192.168.168.1 testhost alias1 alias2 alias3 alias4] +[192.168.168.1 testhost alias1 alias2 ] after diff change task [win_hosts : remove aliases from the list] *********** @@ -19,4 +19,4 @@ # localhost name resolution is handled within dns itself. #      127.0.0.1       localhost #      ::1             localhost -192.168.168.1 testhost alias1 alias2 alias3 alias4 +192.168.168.1 testhost alias1 alias2 </desc> <cmt> switch win_hosts to use csharp util </cmt> <cmt> update win_hosts doc to match doc guide </cmt>",win_hosts to use ansible.basic csharp util and better diff support
2529,"<desc> the tests were still passing because of the relaxed tolerance on particular fundamental matrix calculation methods. reverting that catches the bug; the change suggested in </desc> <cmt> don't relax error level for particular fundamental matrix calculation methods </cmt> <cmt> fix bug #3441, #4072, #4173: 8-point fundamental matrix calculation error </cmt>","8pt fundamental matrix calculation fix - bugs #3441, #4072, #4173, #4186"
2530,"<desc> fixes #5391. we had a bug in removing just some but not all ctors (and lacked a test...). </desc> <cmt> support debug info in the ctor-evaller, and save the files before when in emcc_debug mode for debugging purposes </cmt> <cmt> fix ctor evalling in wasm when just some can be removed #5391 </cmt>",fix partial ctor removal in wasm ctor evalling
2531,"<desc> added lexrange related methods with limit options redis command zrangebylex key min max [limit offset count] </desc> <cmt> sentinelconnectionmanager fails to instantiate </cmt> <cmt> when the redis master has no slave connected, sentinelconnectionmanager </cmt> <cmt> fails to instantiate. </cmt> <cmt> conflicts: </cmt> <cmt> src/main/java/org/redisson/connection/sentinelconnectionmanager.java </cmt> <cmt> merge remote-tracking branch 'mrniko/master' </cmt> <cmt> added lexrange methods with limit options </cmt>",lexrange related methods with limit options and zrangebyscore support
2532,"<desc> description: this pr addresses a todo left behind earlier in guarddog_impl.cc which was bypassing the time-source and working directly with real time. instead we use timers and a dispatcher to run the guard dog. there was a race previously in guarddog_impl_test.cc which had to be resolved to integrate this (inserting a sleep at the current impl: #6239 (comment)), and another race in the interlock mechanism due to a race between the test sleep()ing (moving time forward) and the impl reading time to compute misses and megamisses. this was resolved by incorporating time into the interlock mechanism. note: simulatedtimesystem had threading issues when mutating alarms on one thread while executing them on another. the thread-annotation needed overrides due to the challenges the compiler faces proving that time_system_->alarm_->time_system == time_system, and we want to use a single mutex for the time-system and its alarms. risk level: medium -- guarddog runs all the time. otoh a lot of test iterations show this appears to be robust both in real-time and system-time. testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> rework guarddog_impl.cc using timers rather than condvar timed waits. </cmt> <cmt> working with --runs_per_test=1000 with and without tsan. </cmt> <cmt> cleanup </cmt> <cmt> more cleanup and removal of new simulated-time routines that i didn't wind up using. </cmt>",sim-time thread safety and move guard-dog fully into abstract time.
2533,"<desc> here's a trick with property that @mblondel suggested earlier to make hasattr(clf, ""predict_proba"") work with svc(probability=false) and sgdclassifier(loss=""hinge""): models that define the method, but where it doesn't actually work. this is a bit of a hack, so i don't suggest using it in new code (see comment in svc), but it simplifies other code such as bagging and the smoke tests, i.e. it localizes the problem that these exceptional estimators have instead of spreading it across the codebase. there might be more places where the code can be simplified. the documentation comes out almost right, despite the property: (the ""returns x"" is there in master too, i'll change it in a minute.) ping @jnothman, @gaelvaroquaux, @agramfort, @ogrisel. </desc> <cmt> fix predict_proba status on sgd and svc when disabled </cmt> <cmt> using a property trick suggested by @mblondel. the following now </cmt> <cmt> works: </cmt> <cmt> >>> clf = svc(probability=false) </cmt> <cmt> >>> hasattr(clf, ""predict_proba"") </cmt> <cmt> false </cmt> <cmt> this simplifies the smoke tests. </cmt> <cmt> added a note to svc stating that this should be done in new code. </cmt> <cmt> enh use hasattr ""predict_proba"" in bagging </cmt> <cmt> more robust than catching exceptions. </cmt>","make hasattr(clf, ""predict_proba"") work with probabilities disabled"
2534,"<desc> this adds a new mode to process-stats-dir.py that handles evaluating expressions over specific stats-dir values. also includes mention of a lit.py mode i had to employ today, as per @gottesmm's request. </desc> <cmt> [process-stats-dir] add --evaluate for evaluating specific stat conditions </cmt> <cmt> [process-stats-dir] print diagnostic when --evaluate fails. </cmt> <cmt> [docs] mention lit.py -vv option, helpful for diagnosis. </cmt>",process stats evaluate and lit diagnostics docs
2535,"<desc> original pull-request #27329 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix incorrect row-level filtering </cmt> <cmt> add test. </cmt> <cmt> add test. </cmt> <cmt> update 02002_row_level_filter_bug.sh </cmt> <cmt> add test to parallel skip list. </cmt> <cmt> update skip_list.json </cmt> <cmt> fix spelling. </cmt> <cmt> fix #27179 </cmt>",cherry pick #27329 to 21.8: fix #27179
2536,"<desc> originally reported by @hartmut-co-uk in discord following config makes maximum call stack error: privateruntimeconfig: { api_secret: '${api_secret}' }, it is also reproducible with dotenv-expand itself when using variable as value. since we are using forked version there is this pr but have to also fix for upstream. </desc> <cmt> fix(config): avoid recursion when interpolating </cmt>",avoid recursion when interpolating env
2537,"<desc> these changes address an issue where screen readers may repeatedly and redundantly read texttrackmenuitem's control text on every texttrackchange event in some browsers. the source of the problem is in the handletrackschange() method of texttrackmenuitem and its subclass offtexttrackmenuitem, in which this.selected(true/false) gets called even if the selected state has not changed since its previous invocation. create private isselected_ property for menu items only call .selected(true) in handletrackschange() if !isselected_ </desc> <cmt> wip </cmt> <cmt> more experimentation, logging </cmt> <cmt> remove logging, clean upcomments </cmt> <cmt> remove event arg used for testing </cmt> <cmt> add comment </cmt> <cmt> set value of isselected_ in selected() method </cmt> <cmt> better comment </cmt>",only select texttrackmenuitem if unselected
2538,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #40316 i've left a couple of questions in #40316 about what to do with the pre elements, those are in separate commits, so it can be reverted if needed. </desc> <cmt> added languages to prismjs </cmt> <cmt> added language to code fences for python for everybody </cmt> <iss> code fences should have languages </iss>",adding language to code fences and pre to console logs
2539,"<desc> resolves #6891 move the conversion from fc::variant to json string reponse into the http thread pool to reduce the amount of work done on the application thread. the http_plugin url_response_callback changed from std::function<void(int,std::string)> to std::function<void(int,fc::variant)> -- code calling the url_response_callback is now expected to provide a fc::variant instead of a string. this means the the type must be setup with fc_reflect so it can be converted to variant. this was already the case for all plugins in eos repo, but if external plugins were doing their own json conversion then that will no longer work. </desc> <cmt> move json::to_string processing to http thread pool </cmt> <cmt> move json::to_string to http thread pool </cmt>",move json::to_string response processing to http thread pool
2540,<desc> add dynamic sampling configuration to projects. this configuration is exposed into the project configurations received by relay. </desc> <cmt> added dynamic sampling configuration to projectdetails </cmt> <cmt> put dynamic sampling rules into an object (was a simple array) </cmt> <cmt> added dynamicsampling to relay projectconfigs </cmt>,added dynamic sampling configuration to projects
2541,"<desc> backports #21872 npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fix fuzzy font rendering when hot-plugging displays on macos catalina </desc> <cmt> fix: font rendering with hi-dpi transitions on catalina </cmt> <cmt> backports </cmt> <cmt> chore: update patches </cmt>",font rendering with hi-dpi display transitions on catalina
2542,"<desc> the global ordinals terms aggregator has an option to remap global ordinals to dense ordinal that match the request. this mode is automatically picked when the terms aggregator is a child of another bucket aggregator or when it needs to defer buckets to an aggregation that is used in the ordering of the terms. though when building the final buckets, this aggregator loops over all possible global ordinals rather than using the hash map that was built to remap the ordinals. for fields with high cardinality this is highly inefficient and can lead to slow responses even when the number of terms that match the query is low. this change fixes this performance issue by using the hash table of matching ordinals to perform the pruning of the final buckets for the terms and significant_terms aggregation. i ran a simple benchmark with 1m documents containing 0 to 10 keywords randomly selected among 1m unique terms. this field is used to perform a multi-level terms aggregation using rally to collect the response times. the aggregation below is an example of a two-level terms aggregation that was used to perform the benchmark: ""aggregations"":{ ""1"":{ ""terms"":{ ""field"":""keyword"" }, ""aggregations"":{ ""2"":{ ""terms"":{ ""field"":""keyword"" } } } } } levels of aggregation 50th percentile ms (master) 50th percentile ms (patch) 2 640.41 577.499 3 2239.66 600.154 4 14141.2 703.512 closes #30117 </desc> <cmt> build terms bucket from matching ordinals </cmt> <cmt> the global ordinals terms aggregator has an option to remap global ordinals to </cmt> <cmt> dense ordinal that match the request. this mode is automatically picked when the terms </cmt> <cmt> aggregator is a child of another bucket aggregator or when it needs to defer buckets to an </cmt> <cmt> aggregation that is used in the ordering of the terms. </cmt> <cmt> though when building the final buckets, this aggregator loops over all possible global ordinals </cmt> <cmt> rather than using the hash map that was built to remap the ordinals. </cmt> <cmt> for fields with high cardinality this is highly inefficient and can lead to slow responses even </cmt> <cmt> when the number of terms that match the query is low. </cmt> <cmt> this change fixes this performance issue by using the hash table of matching ordinals to perform </cmt> <cmt> the pruning of the final buckets for the terms and significant_terms aggregation. </cmt> <cmt> i ran a simple benchmark with 1m documents containing 0 to 10 keywords randomly selected among 1m unique terms. </cmt> <cmt> this field is used to perform a multi-level terms aggregation using rally to collect the response times. </cmt> <cmt> the aggregation below is an example of a two-level terms aggregation that was used to perform the benchmark: </cmt> <cmt>  </cmt> <cmt> ""aggregations"":{ </cmt> <cmt> ""1"":{ </cmt> <cmt> ""terms"":{ </cmt> <cmt> ""field"":""keyword"" </cmt> <cmt> }, </cmt> <cmt> ""aggregations"":{ </cmt> <cmt> ""2"":{ </cmt> <cmt> ""terms"":{ </cmt> <cmt> ""field"":""keyword"" </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt> } </cmt> <cmt>  </cmt> <cmt> | levels of aggregation | 50th percentile ms (master) | 50th percentile ms (patch) | </cmt> <cmt> | --- | --- | --- | </cmt> <cmt> | 2 | 640.41ms | 577.499ms | </cmt> <cmt> | 3 | 2239.66ms | 600.154ms | </cmt> <cmt> | 4 | 14141.2ms | 703.512ms | </cmt> <cmt> closes #30117 </cmt> <cmt> unused import </cmt> <iss> string terms is very slow when there are millions of buckets </iss>",build global ordinals terms bucket from matching ordinals
2543,"<desc> updates xcode_backend.sh to use (mostly) assemble apis. this almost completes the migration, though i still need to move the asset unpack step - this is slightly more complicated due to the module format. should have no new external behavior, but does allow us to more easily wire up new features like font-subset, dart-defines, and obfuscation (which was never implemented for ios?) fyi @dnfield fixes #32925 reland: makes the universal framework depend on kernel. due to the behavior of the codegen integration, running them at the same time causes parts of .dart_tool to be deleted and recreated. </desc> <cmt> [flutter_tools] move ios to assemble </cmt> <cmt> fix dependencies and paths </cmt> <cmt> update ios.dart </cmt> <cmt> updates and more tests </cmt> <cmt> update dart tests </cmt> <cmt> fix order of operations </cmt> <iss> re-implement existing ios and android build in terms of --legacy flutter assemble targets </iss>",reland migrate xcode_backend.sh to flutter assemble
2544,"<desc> fix #4856 . set roundcap to be true (default false) for polar bars will have this effect. var option = { angleaxis: { max: 5 }, radiusaxis: { type: 'category', data: ['a', 'b', 'c'], z: 10 }, polar: { }, series: [{ type: 'bar', data: [1, 2, 3], coordinatesystem: 'polar', name: 'a', roundcap: true, color: 'rgba(200, 0, 0, 0.5)', itemstyle: { bordercolor: 'red', borderwidth: 1 } }], legend: { show: true, data: ['a'] }, tooltip: { show: true } }; it may also help to provide an array as polar.radius to make rings more easily. currently, this can be done with empty data in the inner side: this will be improved in future prs. i'll see if i can make it in this milestone. please ignore this feature for now. todo: feat: support polar.radius feat: support bar background </desc> <cmt> feat: add sausage shape </cmt> <cmt> feat(polar): support radius for polar bars </cmt> <cmt> test(polar): add test for polar bars with roundcap </cmt> <iss> [feature] support barborderradius on the polar bar chart </iss>",support round cap for polar bars
2545,"<desc> long overdue, this pr adds a section in the user guide dedicated to the new gbdts. ping @adrinjalali 	@glemaitre 	@amueller 	@thomasjpfan </desc> <cmt> user guide for histogram based gbdts </cmt> <cmt> added backlinks to user guide in classes </cmt>",doc user guide section for histogram-based gbdts
2546,"<desc> struct a; impl drop for a { fn drop(&mut self) {} } const foo: option<a> = none; const bar: () = (foo, ()).1; was erroring with error: any use of this value will cause an error --> src/lib.rs:9:1 | 9 | const bar: () = (foo, ()).1; | ^^^^^^^^^^^^^^^^^^^^^^^^^^-^ |                           | |                           calling non-const function std::ptr::real_drop_in_place::<(std::option::option<a>, ())> - shim(some((std::option::option<a>, ()))) | = note: #[deny(const_err)] on by default error: aborting due to previous error before this pr. according to godbolt this last compiled successfully in 1.27 </desc> <cmt> manually inline a function that was only used once </cmt> <cmt> allow evaluating trivial drop glue in constants </cmt>",fix evaluating trivial drop glue in constants
2547,"<desc> added response checks to all curl and git network calls. </desc> <cmt> ubuntu: added network response checks for curl and git calls, added --connect-timeout 30 to all curl calls </cmt> <cmt> fixed conflicts in amazon build script </cmt>",eosio build ubuntu network response checks
2548,"<desc> currently, we have two im2rec tools. one is python, the other one is c++. there are slightly different in terms of functionality. it helps to solve the #11884  as well. change the data format on example add some notes to tell users the difference and add corresponding to each other. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change @aaronmarkham please let me know how can i make it less confused. </desc> <cmt> update the example data format and link to each others </cmt>",refine the documentation of im2rec
2549,"<desc> update grafana version to the latest (6.1.3) update kiwigrid sidecar version to (0.0.16) (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) @maorfr @rtluckie @zanhsieh dco signed </desc> <cmt> bump grafana version to 6.1.3 </cmt> <cmt> update grafana version on readme </cmt> <cmt> bump kiwigrid version to the latest </cmt> <cmt> update chart properties </cmt> <cmt> update kiwigrid version on readme </cmt>",update grafana version to 6.1.3
2550,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: helmetjs/helmet@fd4931e increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update helmet definitions </cmt> <cmt> helmet ( </cmt> <cmt> update tests for helmet </cmt>",update helmet definitions for 3.13.0
2551,<desc> add typing for bfs and make the code more brief. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> add typing for bfs </cmt> <cmt> add url for bfs </cmt>,add url and typing hint for bfs
2552,"<desc> add some warnings to warn users what they are doing. and use rich to display log, which is more beautiful. n manimlib/logger.py m manimlib/__init__.py: add __version__ m manimlib/__main__.py: print version when start using manim m manimlib/config.py: add cli arg -v and change print to log m ...: change print to log </desc> <cmt> add warning for empty </cmt> <cmt> add tips for interactive mode </cmt> <cmt> add tips for embed mode </cmt> <cmt> add cli flag -v to show version info </cmt> <cmt> use rich to log </cmt> <cmt> print version when start </cmt>",add warnings and use rich to display log
2553,"<desc> rules-tags defaults to [""recommended""], not empty list close #12615 </desc> <cmt> fix(lint): use recommend if config without tags </cmt> <cmt> fix lint </cmt> <iss> bug(cli/lint): all rules are ignored if the config is changed </iss>",use recommended tag if there is no tags in config file or flags
2554,"<desc> you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information fix #23872 by remove non-existing 'ytdl test pl'  change 'ydl_empty_list'  fix incorrect playlist_count for </desc> <cmt> remove non-existant playlist and replace empty playlist test </cmt> <cmt> fix playlist test count </cmt> <iss> testdownload.test_youtubeplaylist broken </iss>",fix playlist tests (fix #23872)
2555,"<desc> *note: moving #2999 over here (based on a lightgbm branch) so we can test readthedocs builds. see #2999 (comment) see comments from @strikerrus #2989 (comment) #2989 (comment) a few of the r examples are broken right now. these weren't caught by tests because one is only a warning, one is a plot that is generated successfully but is incorrect, and one is an issue specific to our readthedocs builds. i think the issue for lgb.cv() is #2715. in that issue we found that data.table 1.11.4 and r 3.6.0 lead to a data.table error ending in column or argument 2 is null. i think this can be fixed by upgrading to the data.table  1.12.1 in conf.py. to fix the lgb.set.categorical() example, i changed file names across several examples to be sure that no two examples write to the same file name. this issue with lgb.plot.interpretation() is because i made a change and forgot to use abs(). new plot: i was not able to reproduce the data.table error in  #2989 (comment). it </desc> <cmt> [r-package] fix r examples and lgb.plot.interpretation </cmt> <cmt> remove space in gitignore </cmt>",fix r examples and lgb.plot.interpretation()
2556,"<desc> this allows both aclk-ng and legacy to coexist together and agent decides at startup which one will be used based on aclk implementation config param of cloud section of netdata.conf this has origin in good idea from @ferroin (asking why can't we have both :d) some of the things can be done nicer... e.g. aclk_stats of ng and legacy could be merged. this is not done as this should be done with minimal amount of effort as legacy will be removed soon (would be lot of wasted effort) + time pressures. component name aclk, aclk-ng </desc> <cmt> ng by default </cmt> <cmt> protobuf not needed yet </cmt> <cmt> ignore --aclk-ng + remove obsolete comment </cmt> <cmt> configure.ac and netdata-installer for dual aclk </cmt> <cmt> fixup config.ac commit </cmt> <cmt> make them coexist </cmt> <cmt> use the legacy version </cmt> <cmt> fixup config.ac </cmt> <cmt> fix disable cloud </cmt> <cmt> ng only fnc back to aclk_util </cmt> <cmt> fix label list on disable cloud </cmt> <cmt> fix disable cloud </cmt> <cmt> update buildinfo </cmt> <cmt> additional fixes </cmt> <cmt> read aclk implementation to be used from cfg file </cmt> <cmt> fix api/v1/info </cmt>",allows aclk ng and legacy to coexist
2557,"<desc> this pr moves the os detection method to common and removes the os-detection dll project. for using the os detection functions in imageresizer, a method was added to powertoysinterop in the commonmanaged class which calls the same method. pr checklist applies to #3579 cla signed. if not, go over here and sign the cla validation steps performed validated with local msi that the correct settings and image resizer settings are loaded in 1909 and 1809. </desc> <cmt> remove os-detection project </cmt> <cmt> removed os-detection project from sln </cmt> <cmt> added os-detection to powertoysinterop </cmt> <cmt> removed references to os-detection and added powertoysinterop.dll to the imageresizer folder </cmt>",move os detection to common and powertoysinterop
2558,"<desc> initial pass at a rocksdb jni cross-platform fat jar. building a cross-platform jar requires: vagrant virtualbox a mac osx machine that can compile rocksdb. once you have these items, run this make command from rocksdb's root source directory: make jclean clean rocksdbjavastaticrelease this command will build rocksdb natively on osx, and will then spin up two vagrant virtualbox ubuntu images to build rocksdb for both 32-bit and 64-bit linux. you can find all native binaries and jars in the java directory upon completion: librocksdbjni-linux32.so librocksdbjni-linux64.so librocksdbjni-osx.jnilib rocksdbjni-all.jar rocksdbjni-linux32.jar rocksdbjni-linux64.jar rocksdbjni-osx.jar </desc> <cmt> update rocksdb's java bindings to support multiple native rocksdb builds in the same jar file. cross build rocksdb for linux32 and linux64 using vagrant. build a cross-platform fat jar that contains osx, linux32, and linux64 rocksdb static builds. </cmt> <cmt> document release.mdgit status </cmt> <cmt> rsync files to vm rather than sync folders, since sync folders was causing clock skew and confusig make. </cmt> <cmt> since we're not sharing folders with the vm, copy built .so files and jars back to host system. </cmt>",build rocksdb jni cross-platform fat jar
2559,"<desc> this adds visit* methods for the astbuilder to convert an antlr tree into a ql tree. i've only scoped this to stateless expressions (no sequence, join, pipes, ancestry). there are a few cases of eql are just shorthand for now, unless we add more optimal/direct support within ql: x in (a, b, c, ...) -> x == a or x == b or x == c or ... x == ""some*wildcard*expr*"" -> wildcard(x, ""some*wildcard*expr*"") functions get turned into unresolvedfunction. i think at some point, we'll need to add ql support for these or have these functions be eql only with a custom registry. i haven't dived much into that yet to see how this works. i'm assuming that this will be done in a separate follow up pr (created issue #51556 for new functions) related issues #49589 #49997 </desc> <cmt> eql: add astbuilder visitors </cmt> <cmt> eql: add tests for wildcards and sets </cmt> <cmt> eql: fix licensing </cmt>",add astbuilder to convert to ql tree
2560,"<desc> fixes microsoft/vscode#51139 further to avoid the unnecessary directory watch triggers in case of amd resolution, say we are trying to resolve module ""fs"" we would go looking for file fs.ts/fs.tsx/etc in each of the ancestor folder. at this point we use to create directory watch in the ancestor folder but to watch it recursively. this lead to the watch being triggered frequently. this fixes that issue since ancestor folders will be watched only for something directly in it. (eg. ancestor/fs.ts) in rest of the scenarios we will watch subdirectory of ancestor folder as shown in #24471 </desc> <cmt> test for amd resolution setting the recursive directory watcher in the parents of root folder </cmt> <cmt> do not watch the parent folders recursively if not needed. </cmt> <cmt> this avoids watching folders like parent folder of the project root just to watch files created in the folder </cmt> <cmt> fixes microsoft/vscode#51139 </cmt> <iss> tsserver consume constant cpu load (~10% or even more) also i am not typing or doing anything in vs code </iss>",do not watch parent folders recursively if not needed
2561,"<desc> this pr solved issue #36381, and a related issue in mathjs repo: josdejong/mathjs#1539 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update mathjs to v6 </cmt> <cmt> [mathjs] fixed test cases to match v6 </cmt> <cmt> [mathjs] added some fixes from eval => evaluate </cmt> <cmt> [mathjs] added test cases for renamed functions </cmt> <cmt> [mathjs] more fixes for renamed functions </cmt> <cmt> added type for factory function </cmt> <cmt> [mathjs] added typing to factory dependencies </cmt>",added typing defs for mathjs-6.0
2562,"<desc> this is mostly done using the gulp lint --fix command, and manual changes in a small number of cases where eslint couldn't determine what to use, in an effort to reduce the number of disabled eslint rules in the core folder and to use modern syntax. </desc> <cmt> enable the no-var linting rule in src/core/metrics.js </cmt> <cmt> enable the no-var linting rule in src/core/unicode.js </cmt> <cmt> enable the no-var linting rule in src/core/ccitt_stream.js </cmt> <cmt> enable the no-var linting rule in src/core/glyphlist.js </cmt> <cmt> enable the no-var linting rule in src/core/primitives.js </cmt>",enable the no-var linting rule in more core files
2563,"<desc> fix link error for ""what can i do"" part add ""related reports"" part for english version see what it looks like here: @996icu </desc> <cmt> fix link error </cmt> <cmt> set up related reports part </cmt>",add related reports part for english version and some set up errors.
2564,"<desc> this extracts logic from computetransformflagsfornode for switch cases that use properties on node subtypes. this allows nodejs (or other hosts) to make deoptimization decisions for each branch rather than for the entire computetransformflagsfornode function which reduces bind time by 10-14% depending on scenario when compared to the ""transforms"" branch. this also manually inlines the updatetransformflags function as it was too polymorphic to be properly inlined. </desc> <cmt> isolate polymorfic code to individual functions to speed up inlining decisions in node. </cmt> <cmt> fix aggregation issue for namespaces </cmt>",performance improvements in the binder.
2565,"<desc> original pull-request #29762 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update minio </cmt> <cmt> update docker_compose_minio.yml </cmt> <cmt> ping tests </cmt> <cmt> may be fix s3 tests </cmt>",cherry pick #29762 to 21.3: may be fix s3 tests
2566,"<desc> i made some work on the issue #533. </desc> <cmt> corrects some words in spanish, and changes others for a better comprehention </cmt> <cmt> corrects some words in spanish, and adds translation </cmt> <cmt> for 2 options not include in es-help.txt but present in help.txt </cmt>",spanish translation corrections and additions
2567,<desc> i added wgsl support and keep glsl until finish nodematerial wgsl code generate. updated the example webgpu_compute and scale parameter behavior.  this contribution is funded by google via igalia. </desc> <cmt> webgpu: hybrid language </cmt> <cmt> webgpu_compute: update of glsl -> wgsl </cmt> <cmt> highlight point color </cmt> <cmt> update screenshot </cmt>,wgsl support and webgpu_compute example updated
2568,"<desc> before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information the rtl.nl extractor does not work with the updated url-scheme anymore. this pull requests fixes the url-pattern. without touching the old regex. a new testcase is added, old ones are still the same. see also #25821 (tried a pull-request before, but #25816 got lost due to a rebase while updating to the most recent code-base). </desc> <cmt> fixed change in rtl.nl url pattern </cmt> <cmt> with old url pattern intact </cmt>",update regex for new urlscheme
2569,<desc> #7939 added support in eosio-blocklog to trim the front of a blocklog and create the version 3 blocklog format added invariant logic for existing version 3 blocklog logic cleanup </desc> <cmt> fixed block reporting to work for trimmed block logs. </cmt> <cmt> moved trim_data into block_log. gh #7939 </cmt> <cmt> adding missed invarients to existing code. gh #7939 </cmt> <cmt> movede trim_blocklog_front logic into block_log and added support for version 3. gh #7939 </cmt> <cmt> added integration tests for trimming front of block log. gh #7939 </cmt>,7939 trim block log v3 support
2570,"<desc> my system has an umask of 027. this means that every file that's created gets the w bit erased for group members, and all of rwx erased for others. it's likely some security measure. this has the effect that the files in base/ don't have rx set for others, but those bits are needed when serenity runs so that e.g. the window user can read /etc/windowserver/windowserver.ini. instead of just copying the on-disk permissions into the image, explicitly set w for group and others, and set x for group and others for files that are x for user (ie executables and directories -- that's what x does). </desc> <cmt> build-root-filesystem: move ""cp -r"" block up. </cmt> <cmt> i want to add a ""chmod -r"" right after the cp command. </cmt> <cmt> this needs to happen before all the other chmods, to not </cmt> <cmt> undo their effect. </cmt> <cmt> build-root-filesystem: explicitly add +rx for group and others to copied files. </cmt> <cmt> this lets serenity boot even when the repository is cloned with a </cmt> <cmt> umask of 027. </cmt>",make serenity boot even if the umask at git clone time was 027.
2571,"<desc> fix double-dash param usage (eg: --help) adds -version parameter sync output of -version and qt aboutdialog merge ui models for aboutdialog and helpmessagedialog </desc> <cmt> remove double-dash parameters from mapargs </cmt> <cmt> should be merged after pull request #4281 </cmt> <cmt> (""add -version option to get just the version #4281""), </cmt> <cmt> because is changed ""--help"" to ""-help"". </cmt> <cmt> checked that grep of 'mapargs.count(""--' returned only </cmt> <cmt> three places that are fixed by pull request #4281. </cmt> <cmt> add -version option to get just the version </cmt> <cmt> adds a -version or --version option to print just the version </cmt> <cmt> of the program for bitcoind, bitcoin-cli and bitcoin-qt. </cmt> <cmt> also make it that -help can be used to display the help (as well as </cmt> <cmt> existing --help). up to now, -help was the only option that didn't </cmt> <cmt> work with either one or two dashes. </cmt> <cmt> util: add function formatparagraph to format paragraph to fixed-width </cmt> <cmt> this is to be used for the -version and -help messages. </cmt> <cmt> add 'about' information to -version output </cmt> <cmt> adds a copyright and attribution message to the -version output </cmt> <cmt> (the same as shown in the about dialog in the gui). </cmt> <cmt> move the message to a function licenseinfo in init.cpp. </cmt>","add -version, fix -help and qt aboutdialog"
2572,"<desc> fixes #10677. i didn't update the docs as i think this is the intended behaviour, but i can do if you think this change would be unexpected. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to it if that's the case. issue #10677. documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> adding required flags to non-default arguments. </cmt> <cmt> make style fix. </cmt> <iss> hf_argparser doesn't set the required flag on non-defaulted enums </iss>",adding required flags to non-default arguments in hf_argparser
2573,"<desc> this adds a command line option to ignore kernel threads in process list, which in my opinion clutter the display. this only applies to unix systems. a nice side effect is that the cpu usage of glances goes down a bit (-0.5 et -1% on my machine, as measured by glances of course). we should also maybe consider making this the default, as the kernel task on mac is already ignored. </desc> <cmt> fix some misspellings </cmt> <cmt> add command line option to ignore kernel threads on unix systems </cmt>",add a command line option to hide kernel threads
2574,"<desc> only show explore and edit buttons for a slice if user has explore or edit access. don't show save buttons on dashboard if user doesn't have save access. also, remove a ""<br>"" in the error message of the savemodal. it displays on screen since the message is not html. </desc> <cmt> hide forbidden ui elements, remove <br> from message </cmt> <cmt> add comma for flake8 </cmt>","hide restricted ui elements, remove <br> from error message"
2575,<desc> i've run the latest black with default args on new code. added a check for black formatting to ensure only formatted code is merged to the master branch. </desc> <cmt> add black format check </cmt> <cmt> this will provide a useful ci check before users can merge. </cmt> <cmt> run black format across all files </cmt>,add black format check to ci
2576,"<desc> adds a visible indicator that a terminal window is elevated. this icon can be disabled with ""showadminshield"" false in the global settings. spec'd in #8455 also in  big picture: #5000 closes #1939 i work here requires documentation to be updated - yea probably </desc> <cmt> add shield to titlebar </cmt> <cmt> move where the shield is hosted, make it actually dependent on elevation state </cmt> <cmt> add a setting too </cmt> <cmt> add a tooltip too </cmt> <iss> ui styling to clearly indicate elevated (admin) window </iss>",add shield to tab row when elevated
2577,"<desc> git gymnastics after #8626 </desc> <cmt> revert ""introduce an 'svc' segment for dns search"" </cmt> <cmt> install specific salt version on aws, based on gce </cmt> <cmt> the latest salt version breaks the container_bridge.py _state function </cmt> <cmt> we can lock to the same version as gce.  this is not a full fix, </cmt> <cmt> because we can't update to the latest salt without breaking gce, </cmt> <cmt> but this at least unbreaks and sync aws with gce. </cmt> <cmt> this isn't a straight copy from gce, because we still use </cmt> <cmt> the salt master on aws (for now) </cmt> <cmt> fixes #8114 </cmt> <cmt> aws: don't use policy-rc.d to prevent starting daemons until we're ready </cmt> <cmt> it isn't required </cmt> <cmt> kubernetes version v0.17.1 </cmt> <cmt> kubernetes version v0.17.1-dev </cmt> <cmt> release 0.17.1 </cmt>",merge release 0.17.1 to master
2578,<desc> description: improve support for 1. gen mill heater checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> improve support for 1. gen mill heater </cmt> <cmt> style </cmt>,improve support for 1. generation mill heater
2579,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #38753 changed the language of the question which was earlier quite complex to understand. also added a new test for better clarification. </desc> <cmt> changed language for project euler problem-2 </cmt> <cmt> changed language for project euler problem-2 </cmt> <iss> poorly worded challenge: project euler: problem 2: even fibonacci numbers </iss>",added a test for project euler problem-2
2580,<desc> just in case someone is too clever with object serialization or tries to be clever by setting private properties. potential bugs are really obscure but better be safe than sorry i.e. only we write the property and no one else. ref: </desc> <cmt> [styles] add stress test for symbol serialization </cmt> <cmt> [styles] fix potential private classname if deserialization is too good </cmt> <cmt> make it more obvious why symbol.for  is dangerous </cmt> <cmt> fix test failing in ie11 </cmt>,fix global classnames being disabled in deserialized themes
2581,"<desc> part of #48366. introduce a new static setting, gateway.auto_import_dangling_indices, which prevents dangling indices from being automatically imported. i've also updated the dangling index docs a little to cover the new setting, and add some scary caveats. </desc> <cmt> add a setting to control dangling index allocation </cmt> <cmt> fix allocate setting and implement its </cmt> <cmt> the new settings didn't work, but now it does, and i've written a couple </cmt> <cmt> of its that create dangling indices and check what affect the setting </cmt> <cmt> has. </cmt> <cmt> i'm still fixing the unit tests though. </cmt> <cmt> finish fixing unit tests </cmt> <cmt> rename the new setting </cmt> <cmt> wip - trying to make new setting static </cmt> <cmt> new setting gateway.auto_import_dangling_indices doesn't need to be </cmt> <cmt> dynamic. unfortunatlely, this has broken one of the its. </cmt> <cmt> add docs for gateway.auto_import_dangling_indices </cmt>",new setting to prevent automatically importing dangling indices
2582,"<desc> adds rbac and pod security policy support for elasticsearch (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr contains starts with chart name e.g. [stable/chart] </desc> <cmt> adds support for rbac and pod security policies for elasticsearch-curator </cmt> <cmt> updated readme to include new psp/rbac options </cmt>",adds rbac and psp support for elasticsearch-curator
2583,<desc> handle the scenario when heritage clause of interface is not entity name expression fixes #12291 handle when type alias's type parameter extends type that wont get emitted in .d.ts fixes #12326 </desc> <cmt> handle the scenario when heritage clause of interface is not entity name expression </cmt> <cmt> fixes #12291 </cmt> <cmt> handle when type alias's type parameter extends type that wont get emitted in .d.ts </cmt> <cmt> fixes #12326 </cmt>,declaration emit when there are errors in the source file
2584,<desc> improves logging overall. </desc> <cmt> shader_bytecode: add encoding for vote.vtg </cmt> <cmt> shader_ir: add error message for exit.fcsm_tr </cmt> <cmt> shader_bytecode: add encoding for bar </cmt> <cmt> shader_bytecode: rename mov_sys to s2r </cmt> <cmt> shader/other: add error message for some s2r registers </cmt>,add some instruction and s2r encodings
2585,<desc> adds a base file downloader class to be used by fragmented media file downloaders (e.g. f4m/m3u8 manifests). rewrites f4mfd and nativehlsfd in terms of fragmentfd. adds generic progress output and resume for nativehlsfd. </desc> <cmt> [fragment] generalize fragmented media file downloader </cmt> <cmt> [f4m] implement f4m fd in terms of fragment fd </cmt> <cmt> [hls] implement hlsnative fd in terms of fragment fd </cmt>,generalized fragmented media file downloader
2586,"<desc> supply unittests for parsing of json value as root element(rfc7159). assert on impossible code paths. for switch-case in reader::transit() function, put all impossible code cases and non-enumerated cases under default:(also with assertions). </desc> <cmt> add unittests for parsing root json value other than array and object. </cmt> <cmt> add unittest for state transition to iterativeparsingmemberkeystate. </cmt> <cmt> use assertion for impossible case(the predict() can ensure the token is colontoken, otherwise it would be marked as error state. so there is no need to check colontoken again). </cmt> <cmt> assert on impossible state transition in transit(); put the last case and all non-enumerated cases(also supply assertion for them) in  for code coverage. </cmt>",improve code coverage for iterative parsing
2587,<desc> using parse/react-native gave error from typescript. quick fix for this. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> add parse/react-native definitions </cmt> <cmt> add description </cmt>,@types/parse add react-native typings to fix warnings.
2588,"<desc> here's a bugfix for functionality which regressed from 1.6 -> 1.7, calling x.fill() with a tuple. should have filed this pr sooner, sorry! >>> import numpy as np >>> np.__version__ '1.6.2' >>> x = np.zeros(2, dtype=[('a', 'f8'), ('b', 'i4')]) >>> x.fill((3.5, -2)) >>> x array([(3.5, -2), (3.5, -2)], dtype=[('a', '<f8'), ('b', '<i4')]) >>> import numpy as np >>> np.__version__ '1.7.1' >>> x = np.zeros(2, dtype=[('a', 'f8'), ('b', 'i4')]) >>> x.fill((3.5, -2)) traceback (most recent call last): file ""<stdin>"", line 1, in <module> valueerror: input object to fillwithscalar is not a scalar </desc> <cmt> tst: test for x.fill(tuple) where x is a struct array </cmt> <cmt> bug: fix to allow x.fill(tuple) where x is a struct array </cmt>",regression when filling struct from tuple
2589,"<desc> i found that when trying to print to pdf, there was a block of code missing from the html, this block is necessary for the pdf layout to be rendered properly and i didn't see it anywhere in the readme so i added it in. </desc> <cmt> update readme.md </cmt> <cmt> update readme.md to include block for pdf printing </cmt>",update to readme.md for pdf printing
2590,"<desc> also, reword the what's new messages: this doesn't change the limited api, it only brings the py_limited_api macro closer to the ideal of only allowing the limited api.  automerge-triggered-by: gh:encukou </desc> <cmt> reword note on removing pymarshal_* with py_limited_api </cmt> <cmt> these items were not part of the limited api, which is defined </cmt> <cmt> in the docs (via misc/stable_abi.txt). </cmt> <cmt> the change brings the py_limited_api macro closer to the ideal </cmt> <cmt> of only allowing things in the limited api. </cmt> <cmt> exclude all of ""marshal.h"" when py_limited_api is defined. </cmt> <cmt> nothing in the file is listed as part of the limited api. </cmt> <cmt> the symbols are not exported in the windows stable abi dlls. </cmt> <cmt> the header is not included from <python.h>. </cmt>",exclude all of marshal.h if py_limited_api is defined
2591,"<desc> this warmup lr can be combinated with other learning rate strategies. for example: decayed_lr = fluid.layers.linear_lr_warmup( fluid.layers.piecewise_decay(boundaries, lr_steps), warmup_steps, start_lr, end_lr) </desc> <cmt> reduce lstm_op kernel size </cmt> <cmt> test=develop </cmt> <cmt> add linear learning warmup method </cmt> <cmt> this warmup lr can be combinated with other learning rate strategies. </cmt> <cmt> for example: </cmt> <cmt> decayed_lr = fluid.layers.linear_lr_warmup( </cmt> <cmt> fluid.layers.piecewise_decay(boundaries, lr_steps), </cmt> <cmt> warmup_steps, start_lr, end_lr) </cmt> <cmt> test=develop </cmt>",add linear learning warmup method in learning rate scheduler.
2592,"<desc> auditd_fim_events table changes added the process uid and gid columns. renamed the path1 column to path. renamed the path2 column to dest_path. socket_events table changes print the saddr event field contents when the parser fails. the original function parsing the field has not been changed (this is straight from master); this may still come in handy when debugging. process_events table changes use decodeauditpathvalues to read path fields from the event records. auditdnetlink changes add support for clearing audit rules when osquery starts ( #3468 ). </desc> <cmt> socket_events: dump the audit_sockaddr saddr field when it can't be parsed. </cmt> <cmt> process_events: use the decodeauditpathvalues helper when reading paths. </cmt> <cmt> auditd_fim_events: change column names. path1 to path, path2 to dest_path. </cmt> <cmt> auditd_fim_events: add process uid and gid. </cmt> <cmt> auditdnetlink: rules can now be cleared on startup using --audit_force_reconfigure. </cmt>","update column names, add process uid/gid, add switch to clear audit config on startup."
2593,<desc> eosio-wat2wasm was really the assemble command from wavm and we used it for the old wasm build environment. it's no longer needed. remove it and other wavm tools from being built as some of these tools don't work as intended due to internal wavm changes we've made. this is being considered for 1.7.x because there are user reported crashes when trying to use these unsupported tools: #6946 </desc> <cmt> don't build wavm tools any longer </cmt> <cmt> some of these don't work as intended due to changes in wavm to support eosio </cmt> <cmt> rename eosio-wat2wasm back to orginal name; don't install </cmt> <cmt> eosio-wat2wasm was really the assemble command from wavm and we used it for the old wasm build enviroment. it's no longer needed. remove the rename and install changes effectively reverting ae9388d restoring this back to upstream </cmt>,remove eosio-wat2wasm and other wavm tools from being built - 1.7
2594,"<desc> related to #31131 per discussion with @mayya-sharipova, this is a breaking change in 6.4 not 6.0 </desc> <cmt> [docs] adds breaking change info for #28344 </cmt> <cmt> [docs] moves breaking change from 6.0 to 6.4 </cmt>",move breaking change info re rejecting regex search if regex string is too long
2595,"<desc> this is a rebased branch based on development per boelle's comments in #971 conditional integration is an adaptive limit on the integral term that prevents accumulation when the proportional or other terms would saturate the heater output. this helps avoid overshoot by not winding up the integral when starting pid control far from the setpoint. discussion in #971, misdirected pull into marlin_v1 in #1246, reverted out of marlin_v1 in #1247. </desc> <cmt> heater.c: limit pid i term with conditional integration. </cmt> <cmt> temperature.cpp:add pid conditional integration on heated bed. </cmt> <cmt> configuration.m: set pid_integral_drive_max from pid_max from bang_max. </cmt> <cmt> current defaults are all 255.  if it makes sense to reduce them, they should come down together, and </cmt> <cmt> be in a  pid_integral_drive_max <= pid_max <- bang_max relationship. </cmt>",add conditional integration to prevent excessive integral windup
2596,"<desc> hi team! a would like to add ""logging"" subsection to microservice security cheat sheet with design recommendation on how to implement logging subsystem in microservice-based systems. -- alexander barabanov advanced software technology lab huawei </desc> <cmt> add ""logging"" section </cmt> <cmt> add logging pattern pic </cmt>","add ""logging"" subsection to the microservice security cheat sheet"
2597,"<desc> see  the downside is that you can't use sudo in the container, but i was able to remove our sudo usages with little effort. </desc> <cmt> let's try running our testsuite without sudo </cmt> <cmt> the de_de(iso-8859-1) locale is not available on ubuntu by default, but there is no reason to require that over the utf-8 one </cmt> <cmt> use another character device in this test as /dev/console seems that it is different for lxc containers </cmt>",change our travis config to use the new container infrastructure
2598,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation problem statement: currently connections to bigquery databases cannot be configured without adding code to superset or adding configuration to its execution environment in the form of google cloud account credentials. solution proposed: add an encrypted field on the dbs table to hold extended connection information. this field can hold json configuration including secrets and add that information on to the database connection object during instantiation. this allows us to configure a service account in google cloud and connect to a bigquery dataset without any code or configuration changes in superset. test plan create a dataset in bigquery in google cloud create a service account in google cloud with access to the dataset download the service account's identity file in json format open the add database screen in superset fill in the sqlalchemy url with bigquery://project-name where project-name is the name of the google cloud project that your bigquery dataset is associated with. add json to the secure extra field with the following structure: { ""credentials_info"": <content from the identity file from google cloud> } click ""test connection"" - it should say the connection is ok. requires db migration. confirm db migration upgrade and downgrade tested. reviewers @mistercrunch @dpgaspar </desc> <cmt> add encrypted_extra to dbs </cmt> <cmt> wip - ui-based bigquery connection configuration </cmt> <cmt> fix 500 bubbling to the surface when adding a database connection </cmt> <cmt> add check for valid json </cmt>",add ui-only database configuration method for extended authorization scenarios
2599,"<desc> while writing the (future) emacs plugin, i had to ensure version of emacs installed was greater than 23. i remembered this script i had worked with during my studies. i have repacked and it here it is: require_tool.sh $ ./require_tool.sh emacs 23 ; echo $? 0 $ ./require_tool.sh emacs 50 >/dev/null ; echo $? emacs 50 or better is required: this is emacs 23.1.1 1 as this might be very helpful to other plugins, i believe $zsh/tools' directory is appropriate. wdyt? by the way, this zsh repo if a very very good idea. thank you all! cheers tristan </desc> <cmt> new plugin git-svn installing git project </cmt> <cmt> git-svn-clone-externals </cmt> <cmt> new tool require_tool.sh </cmt> <cmt> fix version parsing. now working with command $ zsh --version </cmt> <cmt> add new plugin emacs, to take benefit of daemon capabilities of emacs >=23 </cmt> <cmt> removing master stuff </cmt>",new script $zsh/tools/require_tool.sh to ensure version of tool
2600,<desc> building on top of shantur's pr i changed: tuyamcureceived to tuyareceived to keep with established naming scheme (serialsend/serialreceived; tuyasend/tuyareceived) changed topic of tuyareceived from tele/%topic%/result to stat/%topic%/result the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core pre-2.6 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> tuyamcu: implement support for battery powered protocol </cmt> <cmt> tuyamcu: add tuyasend command to communicate with tuya mcu </cmt> <cmt> tuyamcu: add more details to tuyamcureceived </cmt> <cmt> tuyamcu: disable fast reset in low power devices </cmt> <cmt> battery powered devices don't stay up for long which could lead to reset. </cmt> <cmt> tuyamcu : use setoption66 to enable / disable publishing tuyamcureceived over mqtt </cmt> <cmt> tuyasen </cmt> <cmt> tuya_mcu_received </cmt>,aligning tuyamcu code with tasmota naming conventions
2601,"<desc> in kafka streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary. on the other hand, flushing a state store too frequently may have side effects, e.g. rocksdb flushing would gets the memtable into an l0 sstable, leaving many small l0 files to be compacted later, which introduces larger overhead. therefore this pr decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. the checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. this is okay since: a) if eos is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if eos is enabled, then we would never write a checkpoint file until close. here's a more detailed change list of this pr: do not always flush state stores when calling pre-commit; move statemgr.flush into post-commit to couple together with checkpointing. in post-commit, we checkpoint when: a) the state store's snapshot has progressed much further compared to the previous checkpoint, b) when the task is being closed (but as a minor optimization, we would avoid checkpointing on closing if it is exactly the same as the previous one). there are some tricky obstacles that i'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. i've decided to introduce a new api in cachingstatestore to be triggered in pre-commit. </desc> <cmt> first commit </cmt> <cmt> major fixes </cmt> <cmt> flush cache before commit </cmt> <cmt> suppression buffer needs to be flushed too </cmt>",decouple flushing state from commiting
2602,"<desc> features included in this pr: server-side of tls 1.3 key-exchanges: secp256r1 and x25519 resumption zero-rtt sni alpn ocsp stapling todos: correctly handle partial record receives log session ids (no need, since we don't log session tickets for tls 1.2) support for logging secrets (since we cannot do this in openssl 1.0.2) log if the request was early-data it's hard, and we might not need this; let's postpone testing </desc> <cmt> extract </cmt> <cmt> add picotls to xcodeproj </cmt> <cmt> add picotls to cmakefile </cmt> <cmt> change type of the argument to size_t </cmt> <cmt> add picotls support </cmt> <cmt> implement ocsp stapling </cmt>",tls 1.3 support using picotls
2603,"<desc> original pr: #23964 this is a pure tooling update. it doesn't require a release candidate. this pr adds a script to generate language-specific documents and push to github. it relies on docker to consistently produce document pages via various tools. currently supported languages: core/c++/objc/c#/php/python. although this script only generates document, it needs to compile python binaries. it took < 5 minutes to run on my desktop. this script creates a branch with name ""doc-"" followed by current grpc version. it also pushes to github assuming your fork of grpc is named ""/grpc"". take my username as an example: $ tools/distrib/docgen/all_lang_docgen.sh lidizheng ... ================================================================= successfully generated documents for version doc-1.32.0-dev. ================================================================= please check  click  welcome to add generation logic for more languages! </desc> <cmt> add a script to generate all languages doc and push to github </cmt> <cmt> make shellcheck happy </cmt> <cmt> add a link to automatically create a pr </cmt> <cmt> resolve comments </cmt> <cmt> shallow update not allowed (--depth) </cmt>",add a unified doc generation script to 1.32
2604,"<desc> introduce a number of small improvements to our handling of tuple types: when forming a type name from tuple metadata, include the labels (e.g., for dynamic casting failure diagnostics) teach the sil optimizer about casting between tuple types teach the runtime dynamic casting implementation to allow adding/dropping labels there's still a bit more work to do here: we should perform per-element casting in the runtime, and printing of tuples doesn't include the labels. resolves rdar://problem/28121915. </desc> <cmt> [runtime] include tuple labels when printing the runtime name of a type. </cmt> <cmt> when we started recording labels within the metadata for a tuple type, </cmt> <cmt> we failed to print those labels when rendering the type name from </cmt> <cmt> metadata. </cmt> <cmt> [sil optimizer] determine feasibility of dynamic casts between tuple types. </cmt> <cmt> the sil optimizer logic that determined feasability of dynamic casts </cmt> <cmt> completely ignored tuple types, therefore assuming that they would </cmt> <cmt> always fail. check for structural identity, ignoring adding/removing </cmt> <cmt> labels. fixes rdar://problem/28121915. </cmt> <cmt> [runtime] handle tuple/tuple dynamic casts that add/remove labels. </cmt> <cmt> introduce narrow support for tuple/tuple dynamic casts that merely add </cmt> <cmt> or remove labels, but require the element types to match exactly. this </cmt> <cmt> gets us back to allowing the same correct dynamic casts as in swift </cmt> <cmt> 3.0, when labels were completely ignored. </cmt>",improvements to casting/metadata of tuple types
2605,"<desc> identical to #71764 except the rsyncs needed the --links flag: runcommand rsync -av --delete ""${ephemeral_dir}/app.framework"" ""${xcode_frameworks_dir}"" runcommand rsync -av --delete --links ""${ephemeral_dir}/app.framework"" ""${xcode_frameworks_dir}"" macos version of #51453.  see details and discussion there. push linker and embedding logic into the tool so future changes (like distributing as an xcframework, renaming fluttermacos.framework, etc) do not require changes in the user's project. at some point fluttermacos.framework will ship with x86 and arm slices.  with this change, we will be able to introduce thinning (as ios does) in the script without requiring a user project migration. this change would also set us up to stop copying fluttermacos.framework to flutter/ephemeral.  on ios, for example, the framework is copied directly from the artifacts directory to the built_products_dir so there's never a mismatch between a release build and a debug version of flutter. remove app.framework and fluttermacos.framework link step in template build phase. remove app.framework and fluttermacos.framework from the framework embedding build phase. add migrator to do this automatically based on the xcode identifiers.  i confirmed these are the original template identifiers introduced in #40851. build the example and integration test macos apps and see them migrate. remove disable_input_output_paths from the generated podfile, and from the example projects.  now that fluttermacos.framework isn't being technically emitted by a build phase, the #33684 workaround is no longer necessary. future documentation add a macos doc like  add a website note like flutter/website#4019 that disable_input_output_paths can be deleted.  we decided not to automatically migrate this for existing ios projects. related issues fixes #56581 part of #70413 will make #60113 easier. macos_project_migration_test </desc> <cmt> move embedding and linking macos flutter frameworks into the tool (#71764) </cmt> <cmt> --links </cmt> <iss> macos xcode project should move framework linking to tool </iss>",reland move embedding and linking macos flutter frameworks into the tool
2606,"<desc> this may be a good example as the open source code demonstrates how to customize mui components using styled-components and use a theme with overrides. as a side note, in my opinion, the outcome looks fairly attractive :) </desc> <cmt> added typekev to showcase </cmt> <cmt> added an image for the typekev showcase submission </cmt>",add typekev.com to showcase page
2607,"<desc> this adds the audio frame classification (equivalent of token classification) and x-vector (speaker embedding extraction) heads to wav2vec2 and unispeech-sat models. the target tasks for the heads are superb's speaker diarization and speaker verification respectively. these were mainly motivated by unispeech-sat, since the model performs better on those tasks, rather than on asr. sources for the models and weights from the superb's s3prl framework: modelforaudioframeclassification:  modelforxvector:  the heads for both w2v2 and us-sat were finetuned from scratch, since the official checkpoints use custom (better) heads that are incompatible with superb's evaluation protocol. </desc> <cmt> models </cmt> <cmt> squashed commit of the following: </cmt> <cmt> commit 72278e1e931a16d0879acc77f65762f3364833d0 </cmt> <cmt> author: anton-l <aglozhkov@gmail.com> </cmt> <cmt> date:   fri dec 10 21:45:08 2021 +0300 </cmt> <cmt> add unispeech heads </cmt>",add speaker diarization and verification heads
2608,<desc> the version of lobpcg in scipy has recently benefited from some bug fixes. we should update the version that we have in master. </desc> <cmt> ehn update lobpcg </cmt> <cmt> wait for scipy 1.4 </cmt>,ehn update lobpcg from scipy master
2609,"<desc> mojaave.com is mahipat's portfolio, i have developed it using gatsby v2 and bootstrap. </desc> <cmt> updated netlify demo url and description </cmt> <cmt> new demo url - </cmt> <cmt> dummy test </cmt> <cmt> revert ""dummy test"" </cmt> <cmt> this reverts commit d9aab9fa76fed3a1f66dfd73198f2addfeca01a7, reversing </cmt> <cmt> changes made to da850ad8fe47537b1fc08bf095eb98eb41eac994. </cmt> <cmt> merge with origin master branch </cmt> <cmt> adding bootstrap cv starter in the starter list </cmt> <cmt> adding </cmt> <cmt> added source url and made changes in description </cmt> <cmt> added new line at the end of the file </cmt>",add a site(https://mojaave.com) to showcase list
2610,"<desc> keeps the same features but adds flexibility thanks to the new api moves gleed to the core. even though gleed it's windows only, anyone could write a script to convert between formats. i'd be happy to make changes if needed. </desc> <cmt> !a - adds gleed system using new api </cmt> <cmt> !t - consistency pass on map base classes </cmt> <cmt> !d - deletes gleed extension (moves it to core) </cmt> <cmt> !t - updates map, uses sensible texture size and more than 200 objects </cmt> <cmt> !f - adds touch controls to gleed test </cmt> <cmt> !t - better real screen size handling </cmt> <cmt> !t - changes m_mpp for m_units (metres per pixel) </cmt> <cmt> !t - adds gleed map documentation and license headers </cmt>",adapts gleed system to new maps api
2611,"<desc> this replaces the pr #1559 in addition to it: further simplifications and readability improvements. replaced the ""shallow"" directive todo-escape with the native angular ng-keydown. one less reason to complain angular is complex :) </desc> <cmt> angularjs-perf: remove global var todomvc </cmt> <cmt> angularjs-perf: wrap into anonymous functions </cmt> <cmt> angularjs-perf: change to controller as syntax </cmt> <cmt> angularjs-perf: simplified functions </cmt> <cmt> angularjs-perf: removed todo-escaped directive </cmt> <cmt> using the native ng-keydown instead </cmt>","removed globals, readability, simplified or removed components - replace pr #1559"
2612,"<desc> fixes #9347 fixes #45693 fixes #57803 </desc> <cmt> fix a bunch of issues with conpty </cmt> <cmt> add use conpty setting </cmt> <cmt> fix use conpty setting </cmt> <cmt> node-pty@0.7.8-conpty1 </cmt> <cmt> node-pty@0.7.8-conpty2 </cmt> <cmt> flip default to use conpty based on build number </cmt> <cmt> we can revert this before stable if there are bit issues, but the fact that </cmt> <cmt> #57803 goes away is pretty big. </cmt> <cmt> rename experimentaluseconpty to windowsenableconpty </cmt> <cmt> node-pty@0.8.0 </cmt> <iss> integrated terminal: ctrl-c doesn't work in powershell and cmd.exe </iss> <iss> windows terminal issues caused by winpty </iss> <iss> terminal not in a good state initially on windows insider builds </iss>",add terminal conpty support on windows
2613,"<desc> this is a convenience pr fix a littlefs bug: avoid crash at boot when fs size is 0 debug message in fs when implementation cannot start change defaults in arduino ide menus in details, new default options: esp-now is working flash size: 1m for generic board (instead of 512k) fs: maximal not-0 size with maximal size for sketch+ota </desc> <cmt> enable by default latest 2.2.x firmware, including fixed espnow </cmt> <cmt> littlefs: avoid crash when fs size is 0 </cmt> <cmt> serial speed defaults to 921k in menu for all boards (testing, since esptool.py) </cmt> <cmt> flash size defaults: 1m for generic board, not empty fs for all </cmt> <cmt> default fw for platformio too </cmt> <cmt> cosmetics </cmt>","switch default fw to ""2.2.2-dev(38a443e)"" (menu:2.2.1+100)"
2614,"<desc> this should fix issue #5990 serde's #[serde(with = ""serde_bytes"")] field attribute signals that vec<u8> is meant to be binary data and should map to flexbuffer's blob instead of vectoruint. after this pr, i will publish the crate as version 0.1.1. @rw </desc> <cmt> serde with_bytes maps to blob </cmt> <cmt> bump rust flexbuffers minor version number </cmt>",serde with bytes maps to blob
2615,"<desc> detailed list of changes: in lib\profilefunctions.js: added profile.profilefromtime changed: getcurrentprofile to use it activeprofiletotime activeprofiletreatmenttotime in static/report/js/report.js: add loadprofilesrange which loads only the profiles for the day range, and the profile(s) before and after based on the startdate of the profile changed loadprofileswitch to use loadprofilesrange note: loadprofilesrange uses a ajax $.when to chain three sync api calls - this doesn't feel right, but unless the profiles are all loaded the subsequent processing will fail. i also wanted to re-use as much existing code to speed up changes, so didn't implement the code server side existing loadprofiles i think now becomes redundant in lib\report-plugins\daytoday.js: use profile.loaddata to load daily basal profiles (which now has the correct profile range by using loadprofilesrange) this then means the subsequent call to profile.gettempbasal returns the correct value in lib/report_plugins/profiles.js: added a check to make the routine more robust in error conditions in lib/server/profile.js and lib/api/profile/index.js: added the same query model into profiles as the other apis in profile.test.js: added new tests for multi-profile testing </desc> <cmt> pulling latest master </cmt> <cmt> test profile settings </cmt> <cmt> npm version change </cmt> <cmt> use console log </cmt> <cmt> use console log for client </cmt> <cmt> use console log for client.sbx </cmt> <cmt> use console log for client.ddata </cmt> <cmt> use console log for client again </cmt> <cmt> revert </cmt> <cmt> used the new nightscout config </cmt> <cmt> upgrade </cmt> <cmt> resolved minor differences </cmt> <cmt> added multi-profile reporting capabilities </cmt>",fixes #4991 - now selects basal profile based day by day
2616,"<desc> which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #69590 does this pr introduce a user-facing change?: the cabundle and service fields in admission webhook api objects now correctly indicate they are optional </desc> <cmt> fix omitempty/optional indicator on cabundle fields </cmt> <cmt> generated files </cmt> <cmt> add system root unit test </cmt> <iss> cabundle should not be required in webhook clientconfig </iss>",correct optional/omitempty indicator on webhook cabundle
2617,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> add missing type </cmt> <cmt> update test </cmt> <cmt> add name to definitions by </cmt>,add types to allow string array argument for hmset
2618,"<desc> option -p  to specify persistence path save persistence files on sigterm too (not only sigint) </desc> <cmt> stack protection </cmt> <cmt> fix warnings </cmt> <cmt> emulation on host: option -p to change fs persistence location </cmt> <cmt> exit on sigterm too, with sigint </cmt>",option for fs persistence location
2619,"<desc> was trying to run benchmarks, and bumped into some issue (+ the datamatrix, i just removed that as this is now removed from pandas, so not much sense having benchmarks for that) </desc> <cmt> cln: fix params list </cmt> <cmt> fix issue in asv.conf.json for win32+other environment </cmt> <cmt> fix mistaken exclusion of virtualenv or existing:same on win32 in the config. </cmt> <cmt> credits: @pv </cmt> <cmt> cln: remove datamatrix </cmt>",fix some issues in asv benchmark suite
2620,"<desc> this is #18130 rebased. trimstring is an existing alternative. note trimstring uses "" \f\n\r\t\v"" as the pattern, which is consistent with the default behavior of std::isspace. see: </desc> <cmt> replace use of boost::trim use with locale-independent trimstring </cmt> <cmt> replace use of boost::trim_right with locale-independent trimstring </cmt> <cmt> note the only use of readstdin is fed to decodehextx, which fails in </cmt> <cmt> ishex on non-hex characters as recorded in p_util_hexdigit. </cmt> <cmt> tests: add trimstring(...) tests </cmt>",replace uses of boost::trim* with locale-independent alternatives (#18130 rebased)
2621,"<desc> part of #29272 fyi: all changes are generated from a script posted in the issue. tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff fyi: when the remaining prs of this are merged, i'll add another one to add the linting rule - then we can close the issue </desc> <cmt> fixed test util imports in remaining pandas/tests files </cmt> <cmt> replaced 'from pandas.util import testing as tm' with 'import pandas.util.testing as tm' </cmt>",consistent pandas.util.testing imports in remaining test suite
2622,<desc> switched license in repo from lgplv3 to apache2.0 and added a license comment to the minified build. </desc> <cmt> switched license over from lgplv3 to apache2 </cmt> <cmt> added copyright banner to top of distribution video.js </cmt> <cmt> grunt now adds copyright comment to top of video.js </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> added license to readme </cmt>,switched license from lgplv3 to apache2.0
2623,<desc> added mask rcnn 3x multi-scale training config result model box ap mask ap mask_rcnn_r50_fpn_mstrain-poly_3x_coco 40.9 37.1 mask_rcnn_r101_fpn_mstrain-poly_3x_coco 42.7 38.5 mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco 42.9 38.5 mask_rcnn_x101_32x4d_fpn_mstrain-poly_3x_coco 43.6 39.0 mask_rcnn_x101_32x8d_fpn_mstrain-poly_3x_coco 44.3 39.5 mask_rcnn_x101_64x4d_fpn_mstrain-poly_3x_coco 44.5 39.7 mask_rcnn_regnetx-400mf_fpn_mstrain-poly_3x_coco 35.7 37.6 32.8 34.4 mask_rcnn_regnetx-800mf_fpn_mstrain-poly_3x_coco 38.0 39.5 34.7 36.1 mask_rcnn_regnetx-1.6gf_fpn_mstrain-poly_3x_coco 39.5 40.9 36.1 37.5 mask_rcnn_regnetx-4gf_fpn_mstrain-poly_3x_coco 42.2  43.4 38.3 39.2 </desc> <cmt> add mstrain 3x models </cmt> <cmt> fix </cmt> <cmt> fix backbone </cmt> <cmt> caffe norm </cmt>,add mask r-cnn 3x mstrain config
2624,<desc> #470 added support for using the 5-point facial feature extraction model from the face_landmarks() function. these are minor updates to support that: update doc strings add a test update example so it doesn't break if you use the 5-point model fyi @vermeille </desc> <cmt> update doc strings and examples to support 5-point face model </cmt> <cmt> add test for small face model </cmt>,small updates to support #470
2625,"<desc> moves the non-multistream specific state to its own class. this will be necessary to support the multistream variants of opus decoding, given the overall decoder state parameters differ from the regular non-multistreamed version of the decoder. </desc> <cmt> service/audio/hwopus: enclose internals in an anonymous namespace </cmt> <cmt> makes it impossible to violate the odr, as well as providing a place for </cmt> <cmt> future changes. </cmt> <cmt> service/audio/hwopus: move opus packet header out of the ihardwareopusdecodermanager </cmt> <cmt> this will be utilized by more than just that class in the future. this </cmt> <cmt> also renames it from opusheader to opuspacketheader to be more specific </cmt> <cmt> about what kind of header it is. </cmt> <cmt> service/audio/hwopus: provide a name for the second word of opuspacketheader </cmt> <cmt> this indicates the entropy coder's final range. </cmt>",move decoder state to its own class
2626,"<desc> #14890 ## what this pr does / why we need it: to be able to inject custom nginx directive into kong. this is particularly necessary when using kong enterprise with rbac enabled on the kong manager and prometheus plugins is needed. (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/kong] added custom nginx template injection capability via config map </cmt> <cmt> [stable/kong] bump version </cmt>",add nginx custom template feature via config map
2627,"<desc> add direct call mode for normal tasks in java worker. the usedirectcall is now an option of basetaskoptions. due to #5559, the option is not open to users right now. this pr also removes the direct_call test group, since now almost all test cases should be verified under direct call mode, not just the actor tests. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> enable direct call for normal tasks </cmt> <cmt> fix java tests </cmt>",support direct call for normal tasks
2628,"<desc> original pull-request #31528 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> remove partial_merge_join_optimizations </cmt> <cmt> this option is redundant because optimization is controlled by partial_merge_join_left_table_buffer_bytes </cmt> <cmt> disable partial_merge_join_left_table_buffer_bytes due to bug </cmt>",disable partial merge join left table buffer bytes
2629,"<desc> it was suggested in sr-14667 to remove the potentially confusing .dynamictype diagnostic suggesting users to use type(of:  instead. this pr removes that diagnostic and leaves the other diagnostic: ""foo has no value .dynamictype"" resolves sr-14667. link: </desc> <cmt> removes dynamictype diagnostic. fixes sr-14667 </cmt> <cmt> fix test cases related to dynamictype </cmt>",remove dynamic type diagnostic suggesting using type(of: instead
2630,"<desc> replacing the deprecated method ""random.choose"" to ""random.choice"" was technically not part of the original issue. however, it was discussed in the talk page and involved one of the files being moved. i assumed this was too minor to justify the creation of a separate issue. also, i added my name to the contributors list in misc/acks. this will be my third pr to cpython, forgot to do it in the previous ones. </desc> <cmt> replace deprecated method </cmt> <cmt> replaced deprecated method ""random.choose"" with ""random.choice"" ( </cmt> <cmt> added name to contributors list </cmt> <cmt> this will be my third pr to the cpython repository, forgot to add my name in the previous ones. </cmt>","replace deprecated method in ""test_import_pkg.py"""
2631,<desc> the contributor covenant at </desc> <cmt> added to code_of_conduct.md to include link to faq about the code of conduct </cmt> <cmt> added to code_of_conduct.md to include link to faq about the code of conduct </cmt>,add faq to code of conduct
2632,"<desc> two riscv-related improvements: update opcodes from binutils-gdb. update to riscv opcodes from riscv-binutils-gdb git 08219b2. set no_alias=false while disassembling: i'm not sure what the rationale was for setting no_alias to true originally. but setting it to false means that shorter and (usually) better readable aliases for instructions will be shown: before after c.jr ra ret addi a5, zero, 123 li a5, 123 jal zero, 0x101dc j 0x101dc and so on. will submit a test update for this to radare2-regressions: </desc> <cmt> riscv: update opcodes from binutils-gdb </cmt> <cmt> update to riscv opcodes from </cmt> <cmt> [riscv-binutils-gdb]( </cmt> <cmt> git 08219b2. </cmt> <cmt> riscv: set no_alias=false while disassembling </cmt> <cmt> i'm not sure what the rationale was for setting no_alias to true </cmt> <cmt> originally. but setting it to false means that shorter and (usually) </cmt> <cmt> better readable aliases for instructions will be shown: </cmt> <cmt> before               |  after </cmt> <cmt> ---------------------+------------ </cmt> <cmt> c.jr ra            | ret </cmt> <cmt> addi a5, zero, 123 | li a5,123 </cmt> <cmt> jal zero, 0x101dc  | j 0x101dc </cmt> <cmt> and so on. </cmt>",update riscv opcodes for disassembly
2633,<desc> replaces #881.  fixed memory consumption issue by replacing replaysubject with publishsubject and adding an atomicboolean to collapsedrequestobservablefunction to track if a value has been set on the response yet </desc> <cmt> allowing collapsers to return multiple values per request argument.  addresses #865 </cmt> <cmt> modify observablecollapser jmh test to allow multiple response per argument </cmt>,multiple responses per collapser arg
2634,<desc> some application servers speaking http/1.1 is capable of listening to an unix-domain socket (which is often faster and easier to operate than tcp sockets). this pr add to the proxy implementation of h2o the support to connect to such servers. the url of such a server is expressed by  obsoletes #51 </desc> <cmt> accept test mode as command line options </cmt> <cmt> simplify </cmt> <cmt> simplify </cmt> <cmt> it works! </cmt> <cmt> support testing http backends using unix-domain sockets by: perl t/50reverse-proxy/test.pl --unix-socket=1 (note: requires an unreleased version of starlet) </cmt> <cmt> test the behavior when using unix-domain-socket based backend </cmt>,connect to application server via unix-domain socket
2635,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: microsoft/typescript#3626 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> case matters in linux </cmt> <cmt> fix files in tsconfig </cmt> <cmt> fix ol-test </cmt>",change some file names to uppercase because linux is case sensitive.
2636,"<desc> add basic support of tcplisterner for hermitcore revise tcpstream to support peer_addr </desc> <cmt> add tcplistener support for hermitcore </cmt> <cmt> add basic support of tcplisterner for hermitcore. </cmt> <cmt> in addition, revise tcpstream to support peer_addr. </cmt> <cmt> remove unused function </cmt> <cmt> use latest interface to hermitcore </cmt>",extend network support for hermitcore
2637,"<desc> we still need constvalue::scalarpair for match handling (matching slices and strings), but that will never see anything undef. for non-fat-ptr scalarpair, just point to the allocation like larger data structures do. fixes #54387 r? @eddyb </desc> <cmt> do not normalize non-scalar constants to a constvalue::scalarpair </cmt> <cmt> move scalarmaybeundef into the miri engine </cmt>",do not normalize all non-scalar constants to a constvalue::scalarpair
2638,"<desc> issue #2165 1.when brokerid not found and read from slave, use brokerid + 1 as the key 2.add unit test follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. </desc> <cmt> [client] fix slavereadenable=true not work sometimes when cluster deployed on dledger mode </cmt> <cmt> [client] add unit test for findbrokeraddressinsubscribe </cmt> <iss> slavereadenable=true not work when cluster deployed on dledger mode sometimes[followed #2157] </iss>",slave read enable not work sometimes when cluster deployed on dledger mode
2639,"<desc> requirements filling out the template is required. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. all new code requires tests to ensure against regressions description of the change adds a new feature request issue template and uses the current issue template as the bug report issue template to take advantage of the new issue template chooser:  alternate designs could leave things as is but we did find the current issue template is more bug report focused which caused some folks to delete it and leave a 1 or 2 sentence feature request.  also, a separate feature request specific template should hopefully encourage more detailed feature requests. why should this be in core? needs to be so it shows up in the issue template chooser. benefits as mentioned above, a more feature request focused issue template will hopefully encourage people to describe why they want something in addition to encouraging them to look at atom's customizability in case the feature can be satisfied without changes to atom. possible drawbacks it's possible that the extra friction for feature requests might discourage someone from making a feature request, but it's helpful for us to have more information about the what/why/alternatives considered. verification process after merging: create a new issue and make sure the template chooser shows. check that the bug report issue template is the current default issue template. check that the feature request issue template is the one being added here. applicable issues n/a </desc> <cmt> create bug_report.md </cmt> <cmt> create feature_request.md </cmt>",add feature request issue template
2640,"<desc> since wrapping bindings into optional type based on expressiblebynilliteral or adjusting position of any doesn't affect ranking it could be performed by typevarbindingproducer instead. </desc> <cmt> [csstep] don't retain multiple copies of the same bindings just for printing </cmt> <cmt> [constraintsystem] handle binding nullability in producer instead of collector </cmt> <cmt> wrapping bindings into optional type based on presence of </cmt> <cmt> an expressiblebynilliteral conformance requirement should </cmt> <cmt> be done after type variable has been selected for attempting. </cmt> <cmt> otherwise such upfront work would be wasteful since it doesn't </cmt> <cmt> affect binding ranking in any way. </cmt> <cmt> [constraintsystem] make binding producer responsible for attemping any last </cmt> <cmt> instead of doing that while collecting bindings, let's move any </cmt> <cmt> to the end of the list when type variable has been selected to be </cmt> <cmt> attempted next. </cmt> <cmt> [constraintsystem] nfc: extract requiresoptionaladjustment so it could be used for default bindings </cmt>",make binding producer responsible for adjustments to the binding set
2641,"<desc> closes #32806 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this is my first pr against this project, so apologies if i've missed any steps in the process. i'm assuming that i'm supposed to fill in the checklist above myself. this pull request adds the fullmatch regular expression matching mode to the other modes already present under the series.str namespace. for example: >>> s = pd.series([""foo"", ""bar"", ""foobar""]) >>> s.str.fullmatch(""foo"") 0     true 1    false 2    false dtype: bool the fullmatch matching mode restricts matches to those that only match the entire string. note the differences from match: >>> s = pd.series([""foo"", ""bar"", ""foobar""]) >>> s.str.fullmatch(""foo"") 0     true 1    false 2    false dtype: bool >>> s.str.match(""foo"") 0     true 1    false 2     true dtype: bool i've also added regression tests and a ""what's new"" entry. i have also opened issue #32806 to cover this new feature. </desc> <cmt> document new functionality </cmt> <cmt> add fullmatch matching mode to series.str </cmt> <cmt> add tests of series.str.fullmatch </cmt> <cmt> add tests of series.str.fullmatch </cmt> <cmt> fix formatting </cmt> <iss> enh: allow regex matching in `fullmatch` mode </iss>","add ""fullmatch"" matching mode to series.str [#32806]"
2642,"<desc> use shared memory atomics (wherever possible) for building histograms. currently, i tested this on 2m rows of airline dataset, tesla v100, cuda v9.0, depthwise tree grow, max-depth=5, numtrees=100. here are the training numbers with and without shared mem atomics. w/o smem: train_time (s): 44.84 w/ smem: train_time (s): 16.98 current change, at runtime, decides to use shared memory for building histogram, if there's enough shared mem available, else, falls back to global mem atomics. </desc> <cmt> use shared memory atomics for building histograms, whenever possible </cmt> <cmt> fixed shared mem atomics crash issue. </cmt> <cmt> also fixed stray code from a previous incorrect merge. </cmt> <cmt> reverted my accidental checkin of commented python tests. </cmt> <cmt> fixed code styles </cmt>",shared memory atomics while building histogram
2643,"<desc> this is the first in a series of prs that updates the mandatory passes for semantic sil. in this pr, i update capture-promotion and move the ownership model eliminator after it. rdar://29870610 </desc> <cmt> [capture-promotion] refactor out into methods the handling in project_box, partial_apply to helper functions. </cmt> <cmt> [capture-promotion] extract scanning the box for interesting uses into its own helper function and use a higher order function instead of a loop. </cmt> <cmt> [sil] add a new api valuebase::getsingleuser() </cmt> <cmt> this api returns nullptr if the valuebase has more than one user and an </cmt> <cmt> operand * otherwise. </cmt> <cmt> [gardening] use macros and a detail enum to make some code more compact. </cmt>",update capture promotion for semantic sil and move ownership model eliminator after it
2644,<desc> switch to using register_code16() and rename tapdance keys to match the left and right terminology preferred in qmk. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> use register_code16 and relatives for tapdance code </cmt> <cmt> rename tapdance keys to more closely mirror the kc names in qmk </cmt>,use register_code16() and its variants in lieu of separate mod registration
2645,"<desc> @matthiasplappert we (@ndrwmlnk @llach) covered the hand model with 92 touch sensors and extended the handmanipulate{block, egg, pen}-v0 environments to handmanipulate{block, egg, pen}touchsensors-v0. now, an observation additionally contains 92 touch values (0 - no touch, 1 - touch detected). sensory information allows faster and better convergence (preliminary results). test the environments with pre-trained weights (currently in training):  python baselines/her/experiment/play.py handmanipulateblocktouchsensors.pkl python baselines/her/experiment/play.py handmanipulateeggtouchsensors.pkl python baselines/her/experiment/play.py handmanipulatepentouchsensors.pkl touch sensor sites are tailored to physical geoms (robot0:dc_hand), thus may visually overlap with meshes (robot0:d_vizual). active touch sensors are highlighted in red, inactive sensors - in green:  sensors_cube_geoms.mp4 sensors_cube_mesh.mp4 sensors_cube.mp4 sensors.mp4 </desc> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> add touch sensors layout </cmt> <cmt> add touch sensors layout </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> extending robotics shadow hand with touch sensors </cmt> <cmt> add touch sensors layout </cmt>",envs robotics - touch sensors - shadow hand
2646,"<desc> what's in this pull request? explanation: these valuable fixits for adding ( as anyobject) trying to do anyobject calls on an any, and for transforming protocol<...> syntax to use & come from notes and warnings.  as such we need to explicitly enable them in the jsonfixitwriter for migration. scope: aides migration to swift 3.0 risk: low; these are fairly straightforward fixits that should not cause unintentional harm during migration. reviewed by: xi ge testing: regression tests added. resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [fixcode] add ( as anyobject) fixit to the whitelist </cmt> <cmt> this fixit comes from a note, but is very useful for migration of code </cmt> <cmt> that has changed from anyobject to any but wants to do anyobject </cmt> <cmt> dispatch. </cmt> <cmt> rdar://problem/27793389 </cmt> <cmt> [fixcode] enabled protocol<...> fixits </cmt> <cmt> the old syntax is deprecated in swift 3, and these fixits seem quite </cmt> <cmt> safe, so apply them for migration. </cmt> <cmt> rdar://problem/27794981 </cmt>",enable ( as anyobject) and protocol<...> fixits
2647,"<desc> fixes #16723 it's essentially the benchmark suite started here. the main goal is to be able to easily ask for a benchmark when a pr might impact performance. the benchmark suite includes only a subset of the sklearn estimators but we can add new ones after. obviously, adding more estimators make the whole run to take longer and having all estimators would take several hours. right now, the run takes an hour and a half on my laptop, with n_jobs=1, with an empty cache, with the default configuration. with the fastest config and some stuff cached it goes down to 20 min. todo: add documentation ping @rth </desc> <cmt> move asv benchmark suite to scikit-learn </cmt> <cmt> cln </cmt> <cmt> don't track cache </cmt> <cmt> config </cmt> <iss> add benchmarks </iss>",mnt add asv benchmark suite
2648,"<desc> the previous commit dated from the ts 1.6 era and does not compile on ts 2.7+. the ts default lib now includes most of the extensions and such interfaces that are now built-in have been removed from here. breaking: all interface names now use snake_case names like the built-in ones breaking: now requires ts 2.7 or newer add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). this pr changes an existing definition: provide a url to documentation or source code which provides context for the suggested changes: #29897 increase the version number in the header if appropriate. (not there to begin with) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. (already there) fixes #29897 </desc> <cmt> add missing optional attributes parameter for getcontext() and missing context attribute defs, thanks to @ander-nz </cmt> <cmt> name update </cmt> <cmt> add pre-defined attrs and link to spec for webglcontextattributes </cmt> <cmt> merge remote-tracking branch 'definitelytyped/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> remove types from old location </cmt> <cmt> update webgl-ext types to work with ts3 </cmt> <cmt> add ts min version header to webgl-ext </cmt>",update webgl-ext types to work with ts2.7+
2649,"<desc> since we are using gcs client as kv backend, we need to make it auto-reconnect in case of a failure. this pr adds this feature. this pr adds auto_reconnect decorator to gcs-utils and in case of a failure it'll try to reconnect to gcs until it succeeds. this feature right now support redis which should be deleted later once we finished bootstrap since kv will always go to gcs. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> up </cmt> <cmt> up </cmt> <cmt> up </cmt> <cmt> up </cmt>",make gcs client in python able to auto reconnect
2650,"<desc> in addition, prevent capable from reporting itself in the trace. </desc> <cmt> add kernel stack trace option to capable </cmt> <cmt> capable: avoid stack trace overwrite </cmt> <cmt> use 0 in get_stack() to avoid overwriting the stack trace in the </cmt> <cmt> kernel for the same stack_id. </cmt> <cmt> capable: print both tid and pid </cmt> <cmt> add user-space stack trace option to capable </cmt> <cmt> capable: avoid catching itself </cmt> <cmt> capable: drop unused member pid_tgid in struct </cmt> <cmt> capable: report a proper error message when stack trace is missing </cmt> <cmt> print [missed user stack] or [missed kernel stack] when get_stackid() </cmt> <cmt> returns an error. </cmt> <cmt> capable: add missing errno import </cmt>",add user and kernel stack trace options
2651,"<desc> what is this about? this pr fixes some incorrect results and exceptions being thrown by the calculator plugin which might be slowing down pt run. pr checklist applies to #7437 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? the following changes have been made in this pr - following the refactoring of the calculator plugin, the searched which resulted in 0 as the result were not working as there was no difference between a default result returned when the input was not valid and a valid input resulting in 0 as the answer. the validresult field has been added to distinguish a valid result from a default result. null couldn't be returned because calculateresult is a non-nullable type. eg: 1-1. exceptions were being thrown when the user query is not complete, as the queryhelper thinks that the query is valid but the interpreter doesn't. eg: sin, 1+2+ when a string corresponding to a function is the user query an exception is thrown because it is not a valid interpreter input. eg: say hypothetically we're seraching for some app named logo, then on entering log the calculator plugin would be invoked as there is a match with the regex, however, it is not a valid input to the interpreter. there were some functions such as bin2dec, hex2dec, eigval, etc which are not valid inputs to the mages.interpreter function. hence it has been removed. otherwise, the calculator helper would think that these inputs are valid as they match the regex but the mages.interpreter function would throw an exception as they are not valid mathematical oparations according to it. the ideal way to capture a valid input would be using a bnf for a mathematical operation but that cannot be captured in a regex. validation steps performed how does someone test & validate? added tests. manually validated it </desc> <cmt> remove functions which mages cannot interpret and add in functions which mages can </cmt> <cmt> set validresult when the result is explicitly created to differentiate it form an empty calculateresult </cmt> <cmt> add condition to check that the input is not ending with a binary operation </cmt> <cmt> add tests for all the cases </cmt>",fix exceptions and incorrect results within the calculator plugin
2652,"<desc> cherry-picked re-roll of #4156 this is to support the version 2 of the rigidbot motherboard.  it has the same pin-out but has stepper digipots controlled by an mcp4728 dac.  added new board type and updated the dac coding to the current wire library: wire.receive() -> wire.read  wire.send() -> wire.write() major contributor was jayson kelly, who made the first cut at the coding. </desc> <cmt> support for rigidbot v2 </cmt> <cmt> support dac_or_address in printrboard too </cmt>",rigidbot v2 support - has mcp4728 digipot
2653,<desc> this replaces the hand-rolled node version setup with a new feature that was introduced in babel-preset-env@v0.0.7:  changes between 0.0.6 and 0.0.8 should be backwards compatible. </desc> <cmt> update babel-preset-env to 0.0.8 </cmt> <cmt> changes between 0.0.6 and 0.0.8 should be backwards compatible: </cmt> <cmt>  </cmt> <cmt> use node: 'current' as target for babel-preset-env </cmt> <cmt> this replaces the hand-rolled node version setup with a new feature that </cmt> <cmt> was introduced in babel-preset-env@v0.0.7 </cmt> <cmt>  </cmt>,update babel-present-env and use node: 'current' as target
2654,<desc> we are moving test262 and rwc into internal repository.this pr is to update the test262 and rwc path used by the runner </desc> <cmt> update path to test262 and rwc tests files in the runners </cmt>,update rwc and test262 runner
2655,<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: since this pr #19777 got closed i picked it to provide the same fix increase the version number in the header if appropriate. i am not sure this is needed. i can fix it after code review note: i am quite new to typescript </desc> <cmt> fix onchange and onblur parameters </cmt> <cmt> add semicolon </cmt> <cmt> fix definition </cmt>,redux form onchange onblur fix
2656,"<desc> if a function always returns ok(something), we can return something directly and remove the corresponding error handling in the callers. clippy::unnecessary_wraps </desc> <cmt> remove unneccessary wrapping of return value of allow_unstable(), it would always return some(thing) </cmt> <cmt> rustc_parse: remove unneccessary wrapping of return value in fn mk_range() which would always return ok(..) </cmt> <cmt> remove unneccessary wrapping of return value in mk_await_expr() </cmt> <cmt> parser: remove unneccessary wrapping of return value in parse_extern() </cmt> <cmt> remove redundant return value ok(()) of clear_relocations() </cmt> <cmt> rustc_codegen_ssa: remove unneeded wrapping of return type of execute_copy_from_cache_work_item (always returns ok(..)) </cmt> <cmt> rustc_mir: remove redundant wrapping of return type in numeric_intrinsic() </cmt>",remove redundant option/result wrapping of return values
2657,"<desc> i'm using locust as a library for my custom tests scenarios, and i need to identify my test users with authentication tokens that are received from another stress test system. i had some trouble accomplishing that with the current structure, since we can't add extra parameter to user's __init__ when they are spawned. this pr addresses this. let me know if there is a better way to do that. </desc> <cmt> allow extra constructor parameters when building user </cmt> <cmt> adding some documentation </cmt>",return the new users on runner.spawn_users
2658,"<desc> backport of #19756. addresses #18419: hard to navigate docs front page i'm working with @rossbar to implement the following changes: remove html templates remove references of html templates add sphinx-panels as a extension replace index.html/documentation front page with index.rst update the overview page, following this mock-up create the getting started page, which includes brief installation instructions and links to various guides, depending on user profile (absolute beginners, f2p, etc) -> this change will be in a future pr instead </desc> <cmt> delete html templates </cmt> <cmt> delete reference to html files </cmt> <cmt> add sphinx-panels as an extension </cmt> <cmt> add sphinx-panels as requirement </cmt> <cmt> modify template </cmt> <cmt> modify panel styling </cmt> <cmt> add getting started page </cmt> <cmt> add images to index.rst </cmt> <cmt> adjust image size to be consistent </cmt> <cmt> move images to different folder </cmt> <cmt> change file path for images </cmt> <cmt> replace svg with higher resolution </cmt> <cmt> change color of svgs </cmt> <cmt> modify styling of panels </cmt> <cmt> update getting started panel text </cmt> <cmt> change image path for getting started panel </cmt>",update front page of documentation with sphinx-panels
2659,"<desc> output of roi_perspective_transform op  add mask and transform matrix, test=develop </desc> <cmt> track_official_repo </cmt> <cmt> track offical update </cmt> <cmt> track official </cmt> <cmt> track official </cmt> <cmt> track official </cmt> <cmt> track official </cmt> <cmt> modify roi_perspective_transform_op to output mask and transform matrix </cmt> <cmt> modify comment </cmt> <cmt> modify comment </cmt> <cmt> modify api.spec </cmt> <cmt> pull develop before push </cmt>",make roi_perspective_transform op return mask and transform matrix
2660,"<desc> abstract support locales and fix few bugs. this changes are based on recent master of faker. support localization by changing faker.locale see the test. support individual localization packages see the test. fix types for faker.helpers.randomize() if its param is omitted, it should return a string. see the test. fix types for faker.random.objectelement() if its param is omitted, it should return a string. see the test. 5.  fix types for faker.random.arrayelement() if its param is omitted, it should return a string. see the test 6. fix types for faker.helpers.createcard it should contains address.streeta. see the test. </desc> <cmt> check returned values </cmt> <cmt> should support locales </cmt> <cmt> make test pass </cmt>",support locale (and few bug fixes)
2661,<desc> reduces checkstyle errors for patterns: ambassador async-method-invocation balking bridge builder changes involved java docs reordering imports indentations line length issues </desc> <cmt> decreases checkstyle errors for ambassador pattern </cmt> <cmt> reduces checkstyle errors in async-method-invocation </cmt> <cmt> reduces checkstyle errors in balking </cmt> <cmt> reduces checkstyle errors in bridge </cmt> <cmt> reduces checkstyle errors in builder </cmt>,"resolves checkstyle errors for ambassador, async-method-invocation, balking, bridge, builder"
2662,"<desc> changed the warning message to give information about the request generating it as requested in: #2927 tested with spider: import scrapy class quotesspider(scrapy.spider): name = ""test_spider"" custom_settings = { 'download_warnsize': '123', } def start_requests(self): urls = [ ' ] for url in urls: yield scrapy.request(url=url, callback=self.parse) def parse(self, response): page = response.url.split(""/"")[-2] filename = 'test_spider-%s.html' % page with open(filename, 'wb') as f: f.write(response.body) self.log('saved file %s' % filename) which gives the requested warning message: 2017-10-05 15:41:01 [scrapy.core.downloader.handlers.http11] warning: expected response size (606) larger than download warn size (123) in request <get </desc> <cmt> changed the log message to make it more clear. as requested in issue #2927 </cmt> <cmt> changed the log message to make it more clear. as requested in issue #2927 </cmt> <cmt> changed the log message to make it more clear. as requested in issue #2927 </cmt>",changed unhelpful log message from core.downloader.handlers.http11
2663,"<desc> the existing test checks for a single user when trying to fuse a random number generator instruction.   this is because if it is fused but has multiple users, the value may be generated an incorrect number of times.  (multiple users should receive the same random number, not different ones). the test checks for users() length == 1.  this ignores the case there the instruction is the root, where users() length == 0, but there is effectively one user. </desc> <cmt> a root rng instruction has no users, but is still fusable </cmt> <cmt> add comment to explain why zero is ok </cmt>",rng root instruction can be fused as it effectively has one user
2664,"<desc> this pr is doing 3 things. expose metrics_export_port to ray start & ray.init support discovery of metrics export port through ray.nodes() pass metrics_agent_port to core worker instead of getting it from ray_config_def.h. this is important because we don't want to use the same port for all metrics agent in all nodes. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> metrics export port expose done. </cmt> <cmt> support exposing metrics port + metrics agent service discovery through ray.nodes() </cmt> <cmt> formatting. </cmt>",metrics export user interface part 1
2665,"<desc> description: fixes glances startup errors for docker containers that are not running. glances: error on device update! traceback (most recent call last): file ""/usr/src/app/homeassistant/helpers/entity_platform.py"", line 261, in _async_add_entity await entity.async_device_update(warning=false) file ""/usr/src/app/homeassistant/helpers/entity.py"", line 377, in async_device_update await self.async_update() file ""/usr/src/app/homeassistant/components/glances/sensor.py"", line 191, in async_update for container in value['docker']['containers']: keyerror: 'containers' checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> fix unavailable container errors </cmt> <cmt> update to dev </cmt>",fix glances docker container errors
2666,"<desc> this is #49219 up to the point where the bridge is introduced. aside from moving some code around, the largest change is the rewrite of proc_macro::quote to be simpler and do less introspection. i'd like to also extend quote! with ${stmt;...;expr} instead of just $variable (and maybe even $(... $iter ...)*), which seems pretty straight-forward now, but i don't know if/when i should. r? @alexcrichton or @dtolnay </desc> <cmt> proc_macro: don't use diagnosticbuilder for building up diagnostics. </cmt> <cmt> proc_macro: don't try to reflect literals in quasi-quoting. </cmt> <cmt> proc_macro: clean up the implementation of quasi-quoting. </cmt> <cmt> proc_macro: don't expose compiler-internal filename in public api. </cmt>",prepare proc_macro for decoupling it from the rest of the compiler.
2667,<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. add it to notneededpackages.json. see the readme and bundled typing to verify that this typing should be deprecated. </desc> <cmt> add type definitions for koa-send. </cmt> <cmt> merge upstream master to reflect the big types-2.0 upstream merge. </cmt> <cmt> deprecate argon2 typings. they're included in the lib now. </cmt> <cmt> remove unneeded file (big upstream merge mistake). </cmt>,deprecate argon2. the lib has its own typings now.
2668,<desc> use updated fs api fix bug where file.m_file didn't exist in del() if we used file.close() first fs.removetree now removes tree as well as all tree contents (files). this is for a functionality sync between phantomjs and pyphantomjs all tests will now pass successfully </desc> <cmt> use updated fs api </cmt> <cmt> fix bug where file.m_file didn't exist in __del__() if we used file.close() first </cmt> <cmt> fs.removetree now removes tree as well as all tree contents (files). this is for a functionality sync between phantomjs and pyphantomjs </cmt> <cmt> all tests will now pass successfully </cmt> <cmt> regenerate resources </cmt>,update and sync fs api
2669,<desc> backports some prs (linked below) needed for numpy 1.13.0 support in master to 0.18.x. xref: #7946 xref: #8040 xref: #8355 xref: #9010 </desc> <cmt> fix tests on numpy master (#7946) </cmt> <cmt> until now we were in a edge case on assert_array_equal </cmt> <cmt> fix tests on numpy master (#8355) </cmt> <cmt> numpy.apply_along_axis has changed behaviour when the function passed </cmt> <cmt> in returns a 2d array </cmt>,backport numpy 1.13.0 fixes to 0.18.x
2670,"<desc> hi! this pr increases the test coverage by building and testing the library in c++ 98, 03, and 0x mode with travis. the older standards are only tested in release mode to reduce the number of builds. </desc> <cmt> state that sudo is required for ci </cmt> <cmt> this informs travis that the container-based build environment can </cmt> <cmt> not be used. </cmt> <cmt> treat format.cc like a header </cmt> <cmt> given that it is required for header only builds it has to be </cmt> <cmt> installed too. </cmt> <cmt> build and test in c++11 and in c++98 mode </cmt> <cmt> test in c++ 98, 03 and 11 mode </cmt> <cmt> specify c++11 as c++0x for travis </cmt> <cmt> fixed typo in script </cmt>",extend ci tests with older c++ standards
2671,"<desc> closes #38753 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry @snowman2 can you check if this branch returns behavior to what you had before 1.2? </desc> <cmt> wip </cmt> <cmt> bug: precise_xstrtod segfault </cmt> <cmt> fix typo </cmt> <iss> regr: pd.read_csv segfaults with 1.2 (has worked since before pandas 1.0) </iss>",fix precise_xstrtod segfault on long exponent
2672,"<desc> this pr fixes a severe issue for which changes in the properties modal of a dashboard won't be fully saved when the onlyapply prop was used. this pr #17392 enabled the onlyapply tag. later, manual tests have shown that the tag wasn't ready to be used as both the frontend and the backend were not fully implemented for that to work properly. in addition to that, this pr does the following: refactors the propertiesmodal to use typescript refactors the form component to use the functionalities provided by antdesign fixes an issue in the dashboard detail page for which when applying changes and re-opening the properties modal it did not show the latest changes fixes an issue for which changes in the json_metadata for color_namespace, expanded_slices, timed_refresh_immune_slices were not saved fixes an issue for which the dashboard wasn't redirecting back to the original url when the slug was deleted fixes an issue for which changes to native filters would not update the json_metadata immediately, causing potential overwrites changes the endpoint that was used for updating the dashboard (save_dash) with the standard put endpoint. also, it adds the set_dash_metadata function to the update command in the backend. the set_dash_metadata function was only used by the save_dash endpoint before, causing potential discrepancies in the way the json_metatada was handled by the standard put endpoint. removes unnecessary fetch requests open a dashboard edit the properties, including the json metadata apply the changes reopen the modal and make sure the latest changes are there finally, save the changes reload the dashboard and make sure the properties were fully saved includes db migration (follow approval process in sip-59) </desc> <cmt> refactor propertiesmodal </cmt> <cmt> update json_metadata fully </cmt>",save properties after applying changes in dashboard
2673,"<desc> this allows users to take advantage of  (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/spinnaker]: allow kubeconfig to be referenced from encrypted s3 bucket </cmt> <cmt> update readme </cmt> <cmt> remove whitespace </cmt> <cmt> update comments </cmt> <cmt> add newline </cmt>",allow kubeconfig to be referenced in encrypted s3 bucket
2674,"<desc> issue #8636 bug fenced code block closing tags break colorization if they are prefixed with spaces like so: *a* json {}  *b* according to the commonmark spec, up to three spaces are allowed:  update defintion of fenced code block closing tag to support up to three spaces before and any number of spaces after. closes #8636 </desc> <cmt> fix markdown colorization for fenced code blocks when end fence is prefixed by spaces </cmt> <cmt> issue #8636 </cmt> <cmt> **bug** </cmt> <cmt> fenced code block closing tags break colorization if they are prefixed with spaces. according to the commonmark spec, up to three spaces are allowed. </cmt> <cmt> **fix** </cmt> <cmt> update defintion of fenced code block closing tag to support spaces. </cmt> <cmt> closes #8636 </cmt> <cmt> also support any number of spaces after end of closing fenced code block </cmt> <iss> markdown lists containing fenced code blocks with language hints breaks formatting </iss>",fix markdown highlighting for fenced code block close with space prefix
2675,"<desc> fix httpclient connection: close mode (was disconnecting when the server held back responding like when using event stream). closes #25985 . fix httpclient keep alive with chunked encoding. we need to consume the trailer part and final crlf after last chunk as per rfc 7230 section 4.1: chunked-body   = *chunk last-chunk trailer-part crlf we do not return the trailer part, just consume it allowing following requests to work as expected when using keep alive. </desc> <cmt> httpclient read until eof fixes </cmt> <cmt> fix httpclient keep alive with chunked encoding. </cmt> <cmt> we need to consume the trailer part and final crlf after last chunk </cmt> <cmt> as per rfc 7230 section 4.1: </cmt> <cmt>  </cmt> <cmt> chunked-body   = *chunk </cmt> <cmt> last-chunk </cmt> <cmt> trailer-part </cmt> <cmt> crlf </cmt> <cmt>  </cmt> <cmt> we do not return the trailer part, just consume it allowing following </cmt> <cmt> requests to work as expected when using keep alive. </cmt>","httpclient fixes for eof read, chunked transfer encoding"
2676,"<desc> i also refactored the leftnav to make it more type-safe. because runner-ct does not launch an electron process, i changed the code to just launch an external browser via child_process. </desc> <cmt> chore: refactor and improve type safety. support target=blank </cmt> <cmt> chore: refactor navbar </cmt> <cmt> fix: launch docs link in external browser </cmt>",open link in external browser
2677,"<desc> let's use the redundant requirement graph to diagnose these, just like we already do for redundant conformance and layout requirements. also, diagnose conflicts: multiple superclass requirements where neither is a superclass of the other a superclass requirement and a concrete type requirement that is not a subclass a layout requirement and a concrete type requirement that does not satisfy the layout requirement the first two were already being diagnosed, the third is new. here is an example: struct g<t : anyobject> {} extension g where t == int {} we now reject this on account of t not satisfying anyobject. and last but not least, another bug fix. a protocol can constrain an associated type to self: protocol p { associatedtype a : q where a.b == self } protocol q { associatedtype b } and a class might conform to this protocol: class c : p { typealias a = d } class d : q { typealias b = c } the generic signature <self where self : p, self : c> is built during conformance checking. since self : c, we must have that self.a == d; since d.b == c, the requirement a.b == self in protocol p implies that self == c. so the correct minimized signature here is <self where self == c>. this wasn't handled properly before, because of assumptions in removeselfderived() and a couple of other places. fixes rdar://71677712, rdar://76155506, </desc> <cmt> gsb: diagnose redundant superclass requirements using the redundant requirement graph </cmt> <cmt> gsb: diagnose conflicts between concrete-type and anyobject requirements </cmt> <cmt> gsb: factor out updatelayout() from addlayoutrequirementdirect() </cmt> <cmt> gsb: remove unused parameter from lookupconformance() </cmt> <cmt> gsb: remove one of the two overloads of checkconstraintlist() </cmt>",the combination of a superclass and conformance requirement might force a type to be concrete
2678,"<desc> per #3598 , this finally renames the ""recipes"" section to ""using redux"", and starts reorganizing the content: renamed the recipes docs folder to usage fixed up all markdown links added sub-categories for ""setup and organization"", ""code quality"", and ""redux logic and patterns"". they're organizational only - no additional sub-folders in the repo, so all with /usage/ prefixes updated the _redirects file to hopefully catch all old urls and point them to the new ones dropped the ""object spread"" and ""migrating"" pages, which are very outdated at this point </desc> <cmt> rename ""recipes"" folder to ""usage"" </cmt> <cmt> rename ""recipes"" section to ""using redux"" </cmt> <cmt> - renamed the ""recipes"" folder to ""usage"" </cmt> <cmt> - changed the title to ""using redux"" </cmt> <cmt> - updated all links that pointed to ""recipes"" </cmt> <cmt> - updated redirects file to point to new urls </cmt> <cmt> - removed links to pages for ""migrating"" and ""object spread"" . didn't </cmt> <cmt> delete them entirely - some of the material could maybe go </cmt> <cmt> somewhere else </cmt>","rename ""recipes"" category to ""using redux"""
2679,<desc> type: refactor description:  reduced the padding and size of the input elements of the data privacy rules form component before: after: the height of the input fields was 40px and it is 34px </desc> <cmt> ref(ui): decreased fild height and spacing </cmt>,reduced padding and size of the input elements
2680,"<desc> resolves #3283. also this pr renames the ""unconfirmed"" directory to ""reversible"" (accompanied by similar appropriate name changes throughout the code). --hard-replay-blockchain will now attempt to recover and replay as many reversible blocks as possible from the ""reversible"" block database even if it is left in a dirty state. --replay-blockchain will not attempt to recover the reversible blocks by default. if the ""reversible"" block database is in a good state, those reversible blocks will be replayed after the irreversible blocks are first replayed, just as before. if the ""reversible"" block database is in a dirty state, then --replay-blockchain by itself will still fail. however, this pr introduces a --fix-reversible-blocks which if passed along with --replay-blockchain will cause nodeos to first try to recover the ""reversible"" block database before replaying the blocks. it is also possible to pass in --fix-reversible-blocks by itself. in that case, nodeos will only try to recover the ""reversible"" blocks database and then immediately exit. this pr also makes nodeos remove ""forkdb.dat"" after reading the file on startup. this is to avoid the possibility of reading an old ""forkdb.dat"" file after restarting from a crash (even though a crash should theoretically cause the state db to be left in a dirty state and thus require replay anyway). note: this pr does not change the rules about when fork database emits a signal to write out an irreversible block to disk. fork db is still keeping the last irreversible block in memory and delaying the process of writing it to disk until there is a new irreversible block. this essentially results in what appears the be an off-by-one error: the block log does not contain all the blocks deemed irreversible by dpos standards, the remaining irreversible block not in the block log is found in the fork database and the ""reversible"" block database. i would like to fix this quirk of fork db so that the ""reversible"" block database only contains reversible blocks and the block log contains all irreversible blocks as soon as they became irreversible. but that is a bigger change to fork db and so will be left to another pr. </desc> <cmt> add --fix-unconfirmed-blocks #3283 </cmt> <cmt> rename ""unconfirmed"" to ""reversible"" #3283 </cmt> <cmt> --hard-replay by itself should not fail just because the reversible directory is not present #3283 </cmt> <cmt> remove forkdb.dat after reading the file </cmt> <cmt> this is to avoid the possibility of reading an old forkdb.dat file after </cmt> <cmt> restarting from a crash (even though a crash should theoretically cause </cmt> <cmt> the state db to be left in a dirty state and thus require replay </cmt> <cmt> anyway). </cmt> <iss> add --fix-reversible-blocks option </iss>",nodeos option to recover reversible blocks from unclean shutdown
2681,"<desc> @mihaimaruseac this pr adds tf_read_only_memory_region, newreadonlymemoryregionfromfile and stat ( because we need getfilesize ). thank you for doing an import manually with the previous pr. could you please tell me why the it failed the internal import ? </desc> <cmt> add tf_read_only_memory_region </cmt> <cmt> add stat </cmt> <cmt> add path exists and get file size </cmt> <cmt> add newreadonlymemoryregionfromfile </cmt>",s3 read only memory region and stat
2682,"<desc> this directly addresses issue #42157, adding the rls as a non-default component in the mentioned installers. the windows installers appear to have the right functionality added, but i don't have a machine that runs osx, so it would be great if someone could test whether my .pkg commit adds the rls correctly. the final commit also fixes some formatting issues i'd noticed while working on the installers, but i don't know if that's within the scope of this pr, so input would be appreciated. </desc> <cmt> add rls to .exe and .msi installers </cmt> <cmt> add rls to .pkg installer </cmt> <cmt> fix formatting issues in distribution.xml </cmt>","add the rls to .exe, .msi, and .pkg installers"
2683,"<desc> this time, with tests passing on centos 6 and including support for lookup plugins. also squashed it down to two commits for basedir and configuration. </desc> <cmt> look for plugins in the playbook's basedir </cmt> <cmt> load additional plugins from path specified in configuration </cmt>",load plugins from playbook basedir and configured directories
2684,"<desc> move local, cell and free variables, plus the evaluation stack to the thread. cuts down the size of frames to under 100 bytes, and enables further optimizations of python-to-python calls. </desc> <cmt> remove 'zombie' frames. we won't need them once we are allocating fixed-size frames. </cmt> <cmt> add co_nlocalplus field to code object to avoid recomputing size of locals + frees + cells. </cmt> <cmt> move locals, cells and freevars out of frame object into separate memory buffer. </cmt> <cmt> use per-threadstate allocated memory chunks for local variables. dumb and slow implementation. </cmt> <cmt> make per-thread data-stack a contiguous block of memory. </cmt> <cmt> add comments about data stack sizes. </cmt> <cmt> use chunked stack, allows larger stack when needed with reduced memory use most of the time. </cmt> <cmt> delete obsolete comment and debug print statements </cmt> <cmt> move globals and builtins from frame object to per-thread stack. </cmt> <cmt> move (slow) locals frame object to per-thread stack. </cmt> <cmt> add back comment. </cmt> <cmt> fix limit when popping block from data stack. </cmt> <cmt> tidy up frame creation a bit. </cmt> <cmt> improve function name </cmt>",move data stack to thread from frameobject.
2685,<desc> fix apigateway model state fetching add integration tests issue fixed: #3888 apigateway on cloudformation can't find ref on resource </desc> <cmt> add cfn support: kms::alias </cmt> <cmt> fix issues when deploying cfn template with apigateway resources </cmt> <cmt> * fix apigateway model state fetching </cmt> <cmt> * add integration tests </cmt> <cmt> issue fixed: </cmt> <cmt> apigateway on cloudformation can't find ref on resource #3888 </cmt>,fix cfn apigw model resources issues
2686,<desc> this addresses #14578 i created a tutorial for atlassian's sourcetree on macos. a windows one should be made as well but it is similar enough. plus a windows version might be good for someone else to tackle </desc> <cmt> added sourcetree tutorial reference to main readme file </cmt> <cmt> adding sourcetree macos tutorial and assets </cmt> <cmt> commented out link to nonexistant windows tutorial </cmt>,add atlassian sourcetree tutorial cleaned
2687,"<desc> commenting on the cliconf support call for ios-xr modules for ansible 2.9, as the call for support deprecation was added during the early stage of module development and is not relevant currently. iosxr </desc> <cmt> iosxr cliconf support call </cmt> <cmt> iosxr cliconf support call </cmt> <cmt> iosxr cliconf support call </cmt> <cmt> iosxr cliconf support call </cmt> <cmt> iosxr cliconf support call </cmt>",commenting cliconf support call for ios-xr modules for ansible 2.9 version
2688,"<desc> restore alpha support to color picker as a separate property type. this is one of several fixes for the color overlay feature in the color correction filter, which had some questionable math in it. this is technically a breaking change since i'm tweaking the math, but i don't think many noticed the total regression in the first place, so i doubt this feature is widely used. doing a pass to redo the filters in linear space, and noticed this feature must have regressed when alpha was removed from the main color picker. color overlay works again. verified chroma key did not regress. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> ui: support color picker with alpha </cmt> <cmt> libobs: support color picker with alpha </cmt> <cmt> docs/sphinx: add obs_properties_add_color_alpha </cmt>","fix color overlay in correction filter, add color picker with alpha"
2689,"<desc> with this pr, pointerdownevent and pointermoveevent will always set the 0x01 bit on buttons, including for stylus and touch screen (stylus might have other buttons that start from 0x02). for reasoning, check #30454. related issues fixes #30454 pointereventconverter will be moved to embedder by #28972 flutter/engine#8064 and flutter/engine#8088 in gesture_binding_test.dart, tests now check if pointermoveevent and pointerdownevent have correct buttons. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> add kprimarybutton to events with down=true </cmt> <cmt> eof line </cmt> <iss> touching the screen should be represented as 0x01 in buttons </iss>",touching the screen adds 0x01 to buttons
2690,"<desc> and a variety of other patches </desc> <cmt> update coding_style </cmt> <cmt> basic: move two more terminal-related calls into terminal-util.[ch] </cmt> <cmt> core: add support for setting stdin/stdout/stderr for transient services </cmt> <cmt> when starting a transient service, allow setting stdin/stdout/stderr fds </cmt> <cmt> for it, by passing them in via the bus. </cmt> <cmt> this also simplifies some of the serialization code for units. </cmt> <cmt> machined: when opening a shell via machined, pass tty fds in </cmt> <cmt> with this change we'll open the shell's tty right from machined and then </cmt> <cmt> pass it to the transient unit we create. this way we make sure the pty </cmt> <cmt> is opened exactly as long as the transient service is around, and no </cmt> <cmt> longer, and vice versa. this way pty forwarders do not have to deal with </cmt> <cmt> eio problems due to vhangup, as the pty is open all the time from the </cmt> <cmt> point we set things up to the point where the service goes away. </cmt> <cmt> util: do not reset terminal in acquire_terminal() </cmt> <cmt> before, we'd always reset acquired terminals, which is not really </cmt> <cmt> desired, as we expose a setting ttyreset= which is supposed to control </cmt> <cmt> whether the tty is reset or not. previously that setting would only </cmt> <cmt> enable a second resetting of the tty, which is of course pointless... </cmt> <cmt> hence, move the implicit resetting out of acquire_terminal() and make </cmt> <cmt> the callers do it if they need it. </cmt> <cmt> util: minor modernization of vt_disallocate() </cmt> <cmt> shell-completion: add ""machinectl shell"" to bash completion logic </cmt> <cmt> run: various modernizations and smaller fixes </cmt> <cmt> including a fix for properly freeing a calendarspec object after use. </cmt> <cmt> shell-completion: add pseudo machine "".host"" to shell completion </cmt>",allow passing in fds for stdin/stdout/stderr for transient services
2691,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. related to: #39720 boilerplate pr: freecodecamp/boilerplate-advancednode#15 i tried as much as possible to not change unrelated content, but i also took the opportunity to change the instructions with previously discussed versioning additions, and formatting to use github flavoured md. separate issue: husky needs to be configured to not format (search for) changes within backticks. if tests fail, this will be why. also, might be worthwhile (especially once we migrate to mdx) to change the prettier/lint config to do the same. </desc> <cmt> feat(learn): clarify instructions for boilerplate </cmt> <cmt> add how-to-put-a-profile-together </cmt>",migrate instructions from adnode boilerplate
2692,"<desc> see  also i am not 100% sure if i have not introduced leaking of file descriptors somehow (although did run that specific added unittest 10000s of time and everything was legit)... otherwise -- now it passes all old tests and the new one </desc> <cmt> bug: do not ""own"" the fid for gzipfile and file if provided to load already opened (ticket #2178) </cmt> <cmt> also made all assignments of own_file go in pair with assignments to fid to make things clearer </cmt> <cmt> enh: unittest for preceeding commit fixing #2178 </cmt>","""own"" (to close) file handles in load() only if they were not opened before"
2693,<desc> pr  #8764 adds the feature to title plugin in order to use scriptable options. this features wasn't reported in the documentation. this pr adds the scriptable column to options table. </desc> <cmt> fixes typo on padding doc </cmt> <cmt> adds column to the options table for scriptable </cmt> <cmt> fixes table headers </cmt>,adds scriptable column to options table in the title documentation
2694,<desc> this pull request adds the ability to specify a secret which contains the credentials.json used to authenticate against the google cloud dns service for external-dns. </desc> <cmt> the external-dns chart can use a secret containing a credentials.json for google cloud dns </cmt> <cmt> fixed typo in table markup </cmt>,specify google cloud dns credentials.json via kubernetes secret
2695,"<desc> this pull-request slightly adjusts the current error handling code to improve exception safety and enable switching the error handling to user-defined exceptions (by defining rapidjson_parse_error_early_return).  an example of such a user-defined exception can be found in pah/rapidjson-upstream@bc0cca12 (not intended for upstream inclusion). the main changes are: moving parseerrorcode to include/rapidjson/error/error.h clearing document and reader stacks from a destructor adding parseresult class to propagate error code and offset together benchmarking results below, details available at  the third column is just to shows the impact of actually using an exception to propagate an error. linux 64-bit, intel(r) core(tm) i7-3520m cpu @ 2.90ghz compiler baseline exception-support exception-throw gcc 4.4 11826 ms 11896 ms 12029 ms gcc 4.6 12730 ms 13218 ms 12661 ms gcc 4.8 9847 ms 9817 ms 10467 ms gcc 4.9 9833 ms 10067 ms 10285 ms clang 3.5 11172 ms 10867 ms 11165 ms linux 32-bit, intel(r) core(tm) i7-3520m cpu @ 2.90ghz compiler baseline exception-support exception-throw gcc 4.4 14545 ms 14571 ms 14408 ms gcc 4.6 14877 ms 15197 ms 15126 ms gcc 4.8 11341 ms 11378 ms 11971 ms gcc 4.9 11649 ms 11498 ms 12175 ms clang 3.5 12683 ms 13038 ms 12750 ms linux 32-bit, intel(r) core(tm)2 duo cpu e8400 @ 3.00ghz (no sse4.2) compiler baseline exception-support exception-throw gcc 4.4 21160 ms 21199 ms 20627 ms gcc 4.6 20933 ms 21717 ms 22107 ms gcc 4.8 17192 ms 17377 ms 18168 ms gcc 4.9 18510 ms 17703 ms 18364 ms clang 3.5 17565 ms 17575 ms 17477 ms performance details: </desc> <cmt> move parseerrorcode to error/error.h </cmt> <cmt> in order to enable the customization of the error macros </cmt> <cmt> - rapidjson_parse_error_noreturn </cmt> <cmt> - rapidjson_parse_error_early_return </cmt> <cmt> the user may need to have access to the parseerrorcode enum </cmt> <cmt> already.  this requires a separate header location than the </cmt> <cmt> genericreader. </cmt> <cmt> reader.h: prepare ""early return path"" for exception support </cmt> <cmt> in case of a user-defined rapidjson_parse_error_noreturn that throws </cmt> <cmt> an exception instead of using the rapidjson parseerror api, the early </cmt> <cmt> return paths performing the stack unwinding manually can be omitted as </cmt> <cmt> well. </cmt> <cmt> this patch provides a customizable rapidjson_parse_error_early_return </cmt> <cmt> macro to remove these (then unneeded) control paths from the parsing </cmt> <cmt> implementation (with and without a return value). </cmt> <cmt> secondly, clearing the parse stack is moved to a small helper struct </cmt> <cmt> that calls stack_.clear() from its destructor.  this avoids the need </cmt> <cmt> for the 'goto' in the parsestream function and ensures proper cleanup </cmt> <cmt> even if e.g. a user-defined allocator throws an exception. </cmt> <cmt> genericdocument: simplify error handling in parsestream </cmt> <cmt> * unconditionally store error state of reader after parsing </cmt> <cmt> * clear stack after parsing by using a clearstackonexit scope guard </cmt> <cmt> add parseresult </cmt> <cmt> update documentation of parseresult and related functions </cmt>",improve exception safety and add support for swtiching error handling to exceptions
2696,<desc> fix instructions mentioned in #6181 goes with r2r pr radare/radare2-regressions#627 </desc> <cmt> enhance sub op support for thumb arch </cmt> <cmt> generate correct instructions up to 0x100 </cmt> <cmt> improve support for add instruction for thumb arch </cmt>,fix add and sub for arm thumb fix #6181
2697,"<desc> nothing has been turned on yet. an incremental build involving incremental external dependencies behaves as a hybrid between an external dependency and a normal swiftdeps-laden swift file. in the simplest case, we will fall back to the behavior of a plain external dependency today. that is, we will check its timestamp, then schedule all jobs that involve these external dependencies if it is out of date. where things get interesting is when cross-module incremental builds are enabled. in such a case, we know that a previous compiler has already emitted serialized swiftdeps information inside of a swiftmodule file. moreover, we know that that swiftmodule file was loaded by the build of the current swift module. finally, thanks to the previous stack of commits, we now know exactly how to extract this information from the swiftmodule file. to bring this all home, we unpack incremental dependency information from external dependencies, then integrate them into the current dependency graph - as though they were any other swiftdeps file. this neatly extends the single-module incremental logic to the multi-module case. </desc> <cmt> teach the driver to read fine-grained dependency graphs in swiftdeps files </cmt> <cmt> install incremental external dependency integration code </cmt> <cmt> an incremental build involving incremental external dependencies behaves as a hybrid between an external dependency and a normal swiftdeps-laden swift file. </cmt> <cmt> in the simplest case, we will fall back to the behavior of a plain external dependency today. that is, we will check its timestamp, then schedule all jobs that involve these external dependencies if it is out of date. </cmt> <cmt> where things get interesting is when cross-module incremental builds are enabled. in such a case, we know that a previous compiler has already emitted serialized swiftdeps information inside of a swiftmodule file. moreover, we know that that swiftmodule file was loaded by the build of the current swift module. finally, thanks to the previous stack of commits, we now know exactly how to extract this information from the swiftmodule file. to bring this all home, we unpack incremental dependency information from external dependencies, then integrate them into the current dependency graph - as though they were any other swiftdeps file. this neatly extends the single-module incremental logic to the multi-module case. </cmt>",teach the legacy driver to unpack incremental dependency information from swiftmodule files
2698,"<desc> explanation: the actor runtime has some known issues with deadlock when an actor has to give up its thread because it's running lower-priority work. to avoid deadlocks here, disable all of the logic that tries to give up higher-priority threads when only lower-priority work is available, effectively making the actor runtime ignore priorities internally. scope: affects new code using swift's concurrency model. radar/sr issue:  rdar://79378762 risk: low. reviewed by: kavon farvardin, konrad malawski testing: pr testing and ci on main, adding more stress-tests of the actor runtime that previously deadlocked original pr: #38709 </desc> <cmt> [se-0304] clean up handling of task priorities. </cmt> <cmt> fix bit manipulation in activetaskstatus::withescalatedpriority(). </cmt> <cmt> due to a missing ~ when trying to mask in a new priority + the </cmt> <cmt> isescalated flag, we were instead getting an incorrect priority as </cmt> <cmt> well as dropping other useful bits. this led to assertions about the </cmt> <cmt> running state of a task not being set. </cmt> <cmt> ignore task priorities in the actor runtime. </cmt> <cmt> the actor runtime has some known issues with deadlock when an actor has </cmt> <cmt> to give up its thread because it's running lower-priority work. to </cmt> <cmt> avoid deadlocks here, disable all of the logic that tries to give up </cmt> <cmt> higher-priority threads when only lower-priority work is available, or </cmt> <cmt> to escalate work, effectively making the actor runtime ignore </cmt> <cmt> priorities internally. </cmt> <cmt> fixes rdar://79378762. </cmt> <cmt> improve actor-counters test to also test priorities. </cmt> <cmt> re-enable test </cmt>",actor scheduling without priorities 5.5
2699,<desc> cleans up the code in the ft.java to make it more readable and works. added a countchar.java algorithm that counts the characters in a string. </desc> <cmt> count character algo added </cmt> <cmt> clean up floydtriangle (ft.java) </cmt>,clean up ft.java and create countchar.java.
2700,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). isjoi property only exists for validationerror: sideway/joi@cd77ba5  anyschema extends from schemainternals: </desc> <cmt> chore: changes by linter </cmt> <cmt> feat: joi schema has schemainternals </cmt> <cmt> fix: isjoi is removed from joi object </cmt>,anyschema extends schemainternals and isjoi is dropped
2701,<desc> strip 4k from rom for eeprom emulation to save settings with m500 robin e3d can't save settings at all save settings to flash </desc> <cmt> update mks_robin_e3.ld </cmt> <cmt> strip 4k from rom for eeprom emulation to save settings with m500 </cmt> <cmt> update pins_mks_robin_e3d.h </cmt> <cmt> added eeprom emulation to save settings to flash </cmt> <cmt> use 4k flash with emulation to save settings on robin e3d </cmt>,mks robin e3d - enable m500 with eeprom emulation
2702,<desc> closes #9968 </desc> <cmt> fix(challenges): completed marked at render </cmt> <cmt> mark challenge completed using derived data in a selector </cmt> <cmt> instead of manipulating the data on user load </cmt> <cmt> fix(challenge): update user challenge map on challenge complete </cmt>,update user data on challenge complete
2703,"<desc> on both native android and ios attempting to select a space on an uneditable piece of text, will instead select the previous word. this pr brings this functionality to flutter. related issues closes #68226 i added the following tests: selectabletext test for selecting spaces on mobile test for selecting spaces on non-mobile platforms test for double tapping a space on mobile i had to change the following tests: selectabletext long tap still selects after a double tap select i split this test into a macos and ios version because they now differ in behavior when selecting a space, and this particular test taps a space. long press drag moves the cursor under the drag and shows toolbar on lift this test was also split into macos and ios versions because on ios when selecting a word and attempting to drag over a whitespace, it will skip over the whitespace to the next word. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> selecting a space attempts to select the previous word instead on </cmt> <cmt> android if the text is read only/not editable </cmt> <cmt> prefer to use _getpreviousword() over custom solution </cmt> <cmt> use previousword variable </cmt> <cmt> clean up from old solution </cmt> <cmt> update selectable text tests for new space select behavior </cmt> <cmt> * long tap still selects after a double tap select has been split into ios and macos versions as the selecting a space behavior is different on both platforms </cmt> <cmt> * long press drag moves the cursor under the drag and shows toolbar on lift split into ios and macos </cmt> <cmt> selectable text space selection test </cmt> <iss> selecting a space should select previous word in selectabletext on mobile </iss>",selecting spaces on selectabletext (mobile)
2704,"<desc> docs don't mention anything about xpack.security.audit.index.settings when forwarding events to a remote cluster. this is important because in the case when x-pack security is also installed on the remote cluster, the settings there take precedence. jay, do you think we should only register the audit index template if xpack.security.audit.enabled is true ? in this case, when indexing events to a remote with x-pack security installed (but with auditing turned off, by default) index settings from local will be picked up. closes: #30422 </desc> <cmt> [docs] audit indices settings for remote cluster </cmt> <cmt> docs in the guide too </cmt>",clarify audit index settings when indexing to remote
2705,"<desc> with this pr we strongly type this in methods of object literals and provide a facility for controlling the type of this through contextual typing. the new behavior is only enabled in --noimplicitthis mode. the type of the expression this in a method of an object literal is now determined as follows: if the method has an explicitly declared this parameter, this has the type of that parameter. otherwise, if the method is contextually typed by a signature with a this parameter, this has the type of that parameter. otherwise, if --noimplicitthis is enabled and the containing object literal has a contextual type that includes a thistype<t>, this has type t. otherwise, if --noimplicitthis is enabled and the containing object literal has a contextual type that doesn't include a thistype<t>, this has the contextual type. otherwise, if --noimplicitthis is enabled this has the type of the containing object literal. otherwise, this has type any. some examples: // compile with --noimplicitthis type point = { x: number; y: number; moveby(dx: number, dy: number): void; } let p: point = { x: 10, y: 20, moveby(dx, dy) { this.x += dx;  // this has type point this.y += dy;  // this has type point } } let foo = { x: ""hello"", f(n: number) { this;  // { x: string, f(n: number): void } }, } let bar = { x: ""hello"", f(this: { message: string }) { this;  // { message: string } }, } in a similar manner, when --noimplicitthis is enabled and a function expression is assigned to a target of the form obj.xxx or obj[xxx], the contextual type for this in the function expression is obj: // compile with --noimplicitthis obj.f = function(n) { return this.x - n;  // 'this' has same type as 'obj' } obj['f'] = function(n) { return this.x - n;  // 'this' has same type as 'obj' } in cases where an api produces a this value by transforming its arguments, a new thistype<t> marker interface can be used to contextually indicate the transformed type. specifically, when the contextual type for an object literal is thistype<t> or an intersection including thistype<t>, the type of this within methods of the object literal is t. // compile with --noimplicitthis type objectdescriptor<d, m> = { data?: d; methods?: m & thistype<d & m>;  // type of 'this' in methods is d & m } function makeobject<d, m>(desc: objectdescriptor<d, m>): d & m { let data: object = desc.data || {}; let methods: object = desc.methods || {}; return { ...data, ...methods } as d & m; } let obj = makeobject({ data: { x: 0, y: 0 }, methods: { moveby(dx: number, dy: number) { this.x += dx;  // strongly typed this this.y += dy;  // strongly typed this } } }); obj.x = 10; obj.y = 20; obj.moveby(5, 5); in the example above, the methods object in the argument to makeobject has a contextual type that includes thistype<d & m> and therefore the type of this in methods within the methods object is { x: number, y: number } & { moveby(dx: number, dy: number): number }. notice how the type of the methods property simultaneously is an inference target and a source for the this type in methods. the thistype<t> marker interface is simply an empty interface declared in lib.d.ts. beyond being recognized in the contextual type of an object literal, the interface acts like any empty interface. patterns similar to the above are used in several frameworks, including for example vue and ember. using thistype<t> we can now more accurately describe those frameworks. supercedes #8382. we revoked that pr because it always made the type of this in object literal methods be the type of the object literal. we now make that the default behavior, but allow the default to be overridden using a thistype<t> contextual type. </desc> <cmt> use '__this__' property in contextual type to indicate type of 'this' </cmt> <cmt> introduce thistype<t> marker interface </cmt> <cmt> default contextual 'this' type is containing object literal </cmt> <cmt> update tests </cmt> <cmt> accept new baselines </cmt>",typed 'this' in object literal methods
2706,"<desc> small fix to resolve issues caused by using the init container used to install plugins. (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #13482 dco signed title of the pr contains starts with chart name e.g. [stable/chart] </desc> <cmt> modify ingress template to be easier to --set </cmt> <cmt> update readme </cmt> <cmt> updated tls to match new ingress format </cmt> <cmt> fix trailing spaces </cmt> <cmt> additional readme info </cmt> <cmt> modified ingress template to allow path configuration.  bumped major version to reflect incompatible api change. </cmt> <cmt> sync fork </cmt> <cmt> increment chart patch version </cmt> <cmt> merge fix </cmt> <cmt> just use /bin/bash instead of /usr/bin/env bash </cmt> <iss> [stable/sonarqube] `extraenv` not passed to /opt/sonarqube/bin/run.sh when `.values.plugins.install` is truthy </iss>",use #!/bin/bash in ./templates/copy-plugins.yaml instead of #!/bin/sh
2707,"<desc> this is an updated version of #4809. it is rebased to current master and has some new tests added that verify the behavior of the modified securegiturl() function. securegiturl() tries to make sure that we use secure urls. it currently behaves inconsistently, like allowing plain http download without any warnings or raising securityerror if a repository doesn't exist. see #4307 for details. main changes in behavior with this pull request: insecure http: and git: urls are handled consistently: plain http: urls without a commit hash now report a warning. previously they were silently accepted. plain git: urls without a commit hash now no longer raise a securityerror. instead they report a warning. non-existing or otherwise inaccessible repositories now no longer raise securityerror. previously this happend in some cases, leading to very confusing error messages. for more context/rational see #4307 and the test cases in this pull request. </desc> <cmt> allow insecure urls with warnings (#4307) </cmt> <cmt> added test cases for securegiturl() </cmt>",make securegiturl() warn for insecure urls
2708,"<desc> fixes: #19193 </desc> <cmt> fileio: bump limit for read_full_file() and friends to 64m </cmt> <cmt> apparently people use such large key files. specifically, people used 4m </cmt> <cmt> key files, and we lowered the limit from 4m to 4m-1 back in 248. </cmt> <cmt> this raises the limit to 64m for read_full_file() to avoid these </cmt> <cmt> specific issues and give some non-trivial room beyond the 4m files seen </cmt> <cmt> irl. </cmt> <cmt> note that that a 64m allocation in glibc is always immediately done via </cmt> <cmt> mmap(), and is thus a lot slower than shorter allocations. this means </cmt> <cmt> read_virtual_file() becomes ridiculously slow if we'd use the large </cmt> <cmt> limit, since we use it all the time for reading /proc and /sys metadata, </cmt> <cmt> and read_virtual_file() typically allocates the full size with malloc() </cmt> <cmt> in advance.  in fact it becomes so slow, that test-process-util kept </cmt> <cmt> timing out on me all the time, once i blindly raised the limit. </cmt> <cmt> this patch hence introduces two distinct limits for read_full_file() and </cmt> <cmt> read_virtual_file(): the former is much larger than the latter and the </cmt> <cmt> latter remains where it is. this is safe since the former uses an </cmt> <cmt> exponentially growing realloc() loop while the latter uses the </cmt> <cmt> aforementioend ahead-of-time full limit allocation. </cmt> <cmt> fixes: #19193 </cmt> <cmt> cryptsetup: improve error message when key files to load are too large </cmt> <cmt> let's make this easier to grok for users. </cmt> <cmt> prompted-by: #19193 </cmt> <iss> luks key file stopped working after upgrading to 248 </iss>",add back support for large key files to systemd-cryptsetup
2709,"<desc> add a cache in front of lazy member loading that indicates whether the lookup table has a complete accounting of a given base name with respect to the set of all known extensions of the given nominal type.  as a consequence, this cache must be flushed when a new extension with lazy members is installed after we've run any direct lookups. i anticipate this having a non-trivial impact on the performance of lookup.  this is built on #28914 so we can run a shootout and see if the space tradeoff is worth it. </desc> <cmt> [nfc] remove memberlookuptable::clear() </cmt> <cmt> the incremental name lookup cache no longer needs to chuck out the old tables. </cmt> <cmt> [nfc] one-shot name lookup </cmt> <cmt> simplify lookupdirect to attempt one-shot name lookup based on some ideas slava had.  this means we'll try to perform a cache fill up front, then access the table rather than assuming the table is always (relatively) up to date and filling when we miss the first cache access. </cmt> <cmt> this avoids a walk over the deserialized members of an extension that fails named lazy member loading.  instead, we eagerly page the members of the extension into the table and remove it from consideration for lazy member loading entirely. </cmt> <cmt> in the future, we can convince the clang importer to avoid falling off the lazy member loading happy path. </cmt> <cmt> [experiment] stick a cache in front of lazy member loading </cmt> <cmt> add a cache of lazily-imported names so we don't run off and deserialize extensions multiple times.  the cache indicates that the lookup table has a complete understanding of any given base name.  as a consequence, it must be flushed when a new extension with lazy members is added to avoid returning inconsistent results. </cmt> <cmt> this should make lazy member cache misses much, much cheaper. in the best case, we'll avoid repeatedly crawling around on disk.  in the average case, we'll have fallen off the lazy member loading path at some point for some extension and the lazily-complete cache will kick in to keep that one extension from pessimizing the rest.  in the worst case - when an enormous amount of lookups for non-existent members occur - we'll probably balloon memory usage somewhat adding bogus members to the set. </cmt> <cmt> [nfc] update some bounds on lazy member loading tests </cmt> <cmt> not sure when these moved, but tighten them up so we don't regress. </cmt>",one-shot name lookup + lazily-complete base name cache
2710,"<desc> fixes #5989 read and process /sys/class/net/xxxx/duplex and /sys/class/net/xxxx/operstate create custom variables duplex_state and operstate under the bandwidth chart map states to numeric values duplex state (variable duplex_state) 0 = unknown 1 = half duplex 2 = full duplex operstate status map (variable operstate) 0 = unknown 1 = notpresent 2 = down 3 = lowerlayerdown 4 = testing 5 = dormant 6 = up component name </desc> <cmt> - read and process /sys/class/net/xxxx/duplex and /sys/class/net/xxxx/operstate </cmt> <cmt> - create custom variables duplex_state and operstate under the bandwidth chart </cmt> <cmt> - map states to numeric values </cmt> <cmt> duplex state (variable duplex_state) </cmt> <cmt> 0 = unknown </cmt> <cmt> 1 = half duplex </cmt> <cmt> 2 = full duplex </cmt> <cmt> operstate status map (variable operstate) </cmt> <cmt> 0 = unknown </cmt> <cmt> 1 = notpresent </cmt> <cmt> 2 = down </cmt> <cmt> 3 = lowerlayerdown </cmt> <cmt> 4 = testing </cmt> <cmt> 5 = dormant </cmt> <cmt> 6 = up </cmt> <cmt> - fix array size element count! </cmt> <cmt> - return int value </cmt> <cmt> - fix casting warning </cmt> <iss> network interface speed, duplex, operstate </iss>","network interface speed, duplex, operstate #5989"
2711,<desc> adding userspace and keymaps of mine. plus prepping for eventual corne and ergotravel. can move to different name for userspace if y'all want. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add userspace and keymaps </cmt> <cmt> * adding keymaps for zeal60 and iris </cmt> <cmt> * created my own tap dance that toggles rgb mode based on whether i toggled caps lock or not </cmt> <cmt> parent 578ed42a7f8f986147cad040d50d4ae1d24a32e2 </cmt> <cmt> author seth barberee <seth.barberee@gmail.com> 1565065903 -0500 </cmt> <cmt> committer seth barberee <seth.barberee@gmail.com> 1565065903 -0500 </cmt> <cmt> move to userspace </cmt> <cmt> add zeal60 </cmt>,adding my userspace and keymaps
2712,"<desc> fixes #1436 with this, we don't need to wait for the js bundle and page can render directly. this will lead to better page load performance. </desc> <cmt> use a webpack plugin to combine assets. </cmt> <cmt> add comments and make this releseable. </cmt>",load the main js bundle in production with async
2713,<desc> for #3691. standardized routecontext standardized executioncontext move executioncontext to shardingsphere-executor module </desc> <cmt> rename routeunit to executionunit </cmt> <cmt> move executioncontext to shardingsphere-route module </cmt> <cmt> move routeresult to shardingsphere-route module </cmt> <cmt> add result and context package in shardingsphere-route module </cmt> <cmt> remove setter of routeresult </cmt> <cmt> rename routingunit to routeunit </cmt> <cmt> use sqlstatementcontext instead of shardingrouteresult.getsqlstatementcontext() in shardingpaginationparameterrewriter </cmt> <cmt> rename routeresult to routecontext </cmt> <cmt> rename routingresult to routeresult </cmt> <cmt> split shardingsqllogger </cmt> <cmt> move executioncontext to shardingsphere-executor module </cmt> <cmt> move routecontext from result package to route package </cmt>,standardized route and execution's context object
2714,"<desc> if auto fan pins use the pins that regular fans use, init them the same way. always init configured fan pins with set_output (as in marlin 1.0.1) also includes some other fixes and cleanup. reference: #4579 </desc> <cmt> flags for matching auto-fans </cmt> <cmt> update has_fan flags for 4 auto fans </cmt> <cmt> init next_auto_fan_check_ms to zero </cmt> <cmt> loop fan-pins based on array size </cmt> <cmt> init pwm-able auto fan pins with set_output </cmt> <cmt> use matching auto-fan flags </cmt> <cmt> always init configured fan pins </cmt>",init pwm-able auto_fan pins with set_output
2715,"<desc> this function currently always overwrites the underlying error message with a rather useless one. instead let's let the callback set their own error message and only set our own when they fail to do so. this sets a more informative error message for #2797 and fixes #2965 </desc> <cmt> path: don't let direach overwrite the callback's error message </cmt> <cmt> this function deals with functions doing io which means the amount of </cmt> <cmt> errors that can happen is quit large. it does not help if it always </cmt> <cmt> ovewrites the underlying error message with a less understandable </cmt> <cmt> version of ""something went wrong"". </cmt> <cmt> instead, only use this generic message if there was no error set by the </cmt> <cmt> callback. </cmt> <cmt> fileops: set an error message if we fail to link a file </cmt> <cmt> now that git_path_direach lets us specify an error message to report, </cmt> <cmt> set an appropriate error message while linking. </cmt> <iss> cryptic error on disk full </iss>",provide error messages for git_path_direach operations
2716,"<desc> this also fixes python/typing#512 this also fixes python/typing#511 as was discussed in both issues, some typing forms deserve to be treated as immutable by copy and pickle modules, so that: copy(x) is x deepcopy(x) is x loads(dumps(x)) is x  # pickled by reference this pr adds such behaviour to type variables special forms like union, any, classvar unsubscripted generic aliases to containers like list, mapping, iterable this not only resolves inconsistencies mentioned in the issues, but also improves backwards compatibility with previous versions of python (including 3.6). note that this requires some dances with __module__ for type variables (similar to namedtuple) because the class typevar itself is define in typing, while type variables should get module where they were defined. </desc> <cmt> treat type variables and special typing forms as immputable by copy and pickle </cmt> <cmt> add news entry </cmt> <iss> can't pickle generic types </iss> <iss> typevar equality broken? </iss>",treat type variables and special typing forms as immutable by copy and pickle
2717,"<desc> a few pieces of context: when a docker container is started with a mount where the host_path does not currently exist, it will be created with root ownership. when most linux machines are stopped & started the /tmp directory is deleted what is the issue: node reuse is enabled a cluster is started (with file mounts), and eventually shutdown. the ray cluster is restarted and the head node is pulled from the cache. run_init is executed before file mounts are synced a.  this causes /tmp/ray_tmp_mount/, /tmp/ray_tmp_mount/<cluster_name>/ and /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> are all created by docker and with root ownership. b. rsync happens, and tries to copy files to /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> and fails because ubuntu (the default user on the host) cannot edit root-owned files. the solution: flip 4b and 4a to ensure that rsync creates the /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> path closes #17228 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> first pass </cmt> <cmt> delay start up until after file mounts </cmt> <cmt> add test </cmt> <iss> [docker] [autoscaler] failure to setup head node on recycled head </iss>",sync files before starting docker
2718,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  documentation showing that emojiindex.search() returns an array of emoji  source showing that the emojiindex.emojis returns an object of emojidata when multiple skin tones exist. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fix types for emojiindex </cmt> <cmt> run prettier </cmt>",fix types for emoji-mart emojiindex
2719,<desc> removes several unused templates removes team name from title of anything inheriting from the stream base template (possibly only plugins at this point) removes team name from reprocessing script </desc> <cmt> ref(templates): remove unused cannot create teams template </cmt> <cmt> ref(templates): remove unused project and team base templates </cmt> <cmt> ref(templates): remove unused teams template partial </cmt> <cmt> ref(teams): remove team name from stream base template title </cmt> <cmt> ref(reprocessing): remove team name from reprocessing script </cmt>,"remove unused templates, remove team name in a few places"
2720,<desc> this pr runs hack/update-staging-client.sh in kubernetes release-1.5 branch. this helps client-go release-2.0 branch to pick up the bug fixes. i cannot follow the regular cherrypick process because the staging/ folder has been changed too much in the master branch.  fixes kubernetes/client-go#66. </desc> <cmt> fix copy.sh for osx </cmt> <cmt> update staging client </cmt>,update staging in release 1.5
2721,"<desc> while testing #81455 i encountered 2 issues with remote-test-server: it is built with the stage 0 toolchain, which does not support a newly added target. it overwrites ld_library_path instead of appending to it, which prevents the use of a custom sysroot for target libraries. </desc> <cmt> don't build remote-test-server with the stage0 toolchain </cmt> <cmt> newly added targets aren't available on the stage0 toolchain. </cmt> <cmt> preserve existing ld_library_path in remote-test-server </cmt>",make remote-test-server easier to use with new targets
2722,"<desc> sorry for all the commits. still learning git. problem was cr/lf wall-of-pink issues. here is the new router.map in use: resolves issue #454 </desc> <cmt> update to latest </cmt> <cmt> added comments from durandaljs documentation to module and routeinfo </cmt> <cmt> renamed interface irouteinfo from routeinfo </cmt> <cmt> added interface irouteinfoparameters </cmt> <cmt> bugfixed maproute to have two function signatures. </cmt> <cmt> bugfixed map to take single or array of irouteinfoparameters. </cmt> <cmt> revert ""added comments from durandaljs documentation to module and routeinfo"" </cmt> <cmt> this reverts commit 3ab33b847a8b86cb64f0047a229e3e3778531afc. </cmt> <cmt> bugfixed router.map and router.maproute </cmt> <cmt> bugfixed maproute to have two function signatures. </cmt> <cmt> bugfixed map to take single or array of irouteinfoparameters. </cmt> <cmt> renamed interface irouteinfo from routeinfo </cmt> <cmt> added interface irouteinfoparameters </cmt> <cmt> revert ""bugfixed router.map and router.maproute"" </cmt> <cmt> this reverts commit f6d09ab31b41225bda7ea1d2c0ce5ddcc9a37803. </cmt> <cmt> bugfixed router.map and router.maproute </cmt> <cmt> bugfixed maproute to have two function signatures. </cmt> <cmt> bugfixed map to take single or array of irouteinfoparameters. </cmt> <cmt> renamed interface irouteinfo from routeinfo </cmt> <cmt> added interface irouteinfoparameters </cmt> <cmt> fix for router.map et al. </cmt> <cmt> tried to rebase. first time. too late. i had pushed to github. sorry. </cmt>",fix for router.map et al. in durandal.d.ts
2723,<desc> others others move func from kernel_context.h into kernel_context.cc for compile quickly </desc> <cmt> add inplace op adaptation </cmt> <cmt> optimize inplace logic and fix bugs when run kernel that has args of vector<densetensor> </cmt> <cmt> move func in kernel_context.h into kernel_context.cc </cmt> <cmt> refactor logic that transform variable to densetensor </cmt> <cmt> fix bugs when compile </cmt> <cmt> update func name </cmt> <cmt> merge develop </cmt> <cmt> merge develop </cmt>,[pten]move func from kernel_context.h into kernel_context.cc
2724,<desc> adds an option to export detection models with input node that accepts encoded image strings. </desc> <cmt> change define_enum to define_string and delete unused file. </cmt> <cmt> add option to export graph with input node that accepts encoded jpeg or png string </cmt>,add option to export model with input node that accepts jpeg or png strings
2725,"<desc> this module adds support for dns record management via the api of netcup (german hosting provider). new module pull request netcup_dns ansible version ansible 2.7.0.dev0 (netcup_dns 520b744f81) last updated 2018/08/13 11:42:45 (gmt +200) config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/nbw/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/nbw/dev/ansible/lib/ansible executable location = /home/nbw/dev/ansible/bin/ansible python version = 2.7.15 (default, may 16 2018, 17:50:09) [gcc 8.1.1 20180502 (red hat 8.1.1-1)] </desc> <cmt> add support for netcup dns api </cmt> <cmt> documentation on the return values and small fixes </cmt>",add netcup_dns module (manage dns records hosted by netcup)
2726,"<desc> your submissions are formatted according to the guidelines. your additions are ordered alphabetically. your additions are free software, or if not they have been added to non-free. your additions are not already listed at awesome-sysadmin (it infrastructure management), staticgen.com or staticsitegenerators.net (static site generators). any licenses you have added are in our list of licenses. you have searched the repository for any relevant issues or prs. </desc> <cmt> add musikcube and beets under the ""audio"" heading. </cmt> <cmt> this commit also adds the bsd-3-clause license, as that is the license </cmt> <cmt> for musikcube. </cmt> <cmt> revert bsd-2/3-clause/freebsd distinction </cmt> <cmt> all three licenses will be identified as 'bsd' since we have no track record of which entry has which one </cmt> <cmt> user should read the specific license terms of each program for more details </cmt> <cmt> fix link to bsd-2-clause license </cmt>","add musikcube, beets, merge bsd licenses"
2727,"<desc> updating the chart to latest stable version, 1.0.6. adding the functionality to roll the deployment upon config changes. moving clusterip configuration to outside the kubernetes plugin section, since it may be useful to configure even if running without the kubernetes plugin. </desc> <cmt> [stable/coredns] update to latest version 1.0.6 </cmt> <cmt> [stable/coredns] roll deployment on config change </cmt> <cmt> [stable/coredns] move clusterip outside kubernetes plugin </cmt> <cmt> might be useful to configure even if not running with kubernetes plugin. </cmt>",update to 1.0.6 and small improvements
2728,<desc> for #13582 show single table rule is modified to show single table support show single table rule statement </desc> <cmt> show single table rule is modified to show single table </cmt> <cmt> move class </cmt> <cmt> support show single table rule statement. </cmt> <cmt> add document. </cmt> <cmt> # conflicts: </cmt> <cmt> #	shardingsphere-distsql/shardingsphere-distsql-parser/src/main/antlr4/org/apache/shardingsphere/distsql/parser/autogen/commondistsqlstatement.g4 </cmt> <cmt> update document. </cmt>,support show single table rule resource statement
2729,"<desc> some codegen tests didn't seem relevant (e.g. unsupported annotations). the risc-v abi tests were broken by llvm 10, c872dcf fixes that (cc: @msizanoen1) i'm not sure about skipping catch-unwind.rs and included that change here mostly as a request for comment - i can't tell if that's a bug. </desc> <cmt> test: codegen: skip tests inappropriate for riscv64 </cmt> <cmt> test: codegen: riscv64-abi: print value numbers for unnamed func args </cmt> <cmt> llvm 10 includes a009a60a917bc30940422bcef73f8270566d78db which will </cmt> <cmt> print value numbers for unnamed func args. </cmt> <cmt> update these tests to be in line with the referenced clang tests. </cmt> <cmt> test: codegen: add riscv abi llvm intrinsics test </cmt> <cmt> test: codegen: skip catch-unwind on riscv64 </cmt> <cmt> it isn't clear to me if this is a bug or not, hence the fixme </cmt>",fix codegen tests for risc-v
2730,"<desc> closes #20012 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry added center functionality for variablewindowindexer. note - i am unsure if the notimplementederror in lines 1966-1969 in rolling.py still correctly raises an error for offset based windows. finalizes previous pr #36097 </desc> <cmt> update syntax for pandas style </cmt> <cmt> fix syntax error </cmt> <cmt> reintroduce calculate_center_offset as private function </cmt> <iss> center rolling window with date notimplementederror </iss>",center rolling window for time offset
2731,"<desc> related issue = #1905 #2078 #2085 atomic add may crash when adding negative numbers. it is because we didn't partially set the value to memory using mask after we do the addition. adding negative numbers may cause the change of the higher bits. for example: if we pack a (ci3) and b(ci5) in a bit_struct(num=8), and set them all zero at beginning(a is the lower 3-bits, and b is the higher 5-bits). then we add -1 to a, and we will find that b will be changed too. so, a possible solution might be partially setting value to memory with mask in runtime.cpp just like set_partial_bits_b which only affects the bits of a in the former example . </desc> <cmt> quick fix </cmt> <cmt> mod test </cmt>",support atomic add negative numbers for custom types
2732,"<desc> remove the need for extra interfaces in node_provider to support custom node types each node type now gets a custom node_config section, which is merged with the default node configs require specifying the default head/worker node type in multi node type clusters i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> refactor </cmt>",refactor multi node type autoscaler config
2733,"<desc> follow-ups for #20477. </desc> <cmt> ethtool: move function </cmt> <cmt> i'd like to locate all conf parsers at end of file. </cmt> <cmt> udev/net: initialize coalesce tristate variables </cmt> <cmt> otherwise, 99-default.link may introduce something like the </cmt> <cmt> following warnings: </cmt> <cmt> ---- </cmt> <cmt> aug 26 03:23:59 systemd-udevd[519]: wlan0: could not set coalesce settings, ignoring: operation not supported </cmt> <cmt> aug 26 03:24:00 systemd-udevd[547]: wlp59s0: could not set coalesce settings, ignoring: operation not supported </cmt> <cmt> ---- </cmt> <cmt> follow-up for 6c35ea5ef0231d519ff24d43a57a72cebab6a121. </cmt>",follow-ups for coalesce feature support
2734,"<desc> this pr fixes #122365 it seemed like everyone enjoyed the way files.associations worked so i copied that flow. this will read in and be able to handle the old and new format, but will only write to the new format. when i try to handle conversion i get an error saying we can't write to the user setting because there are errors. this is shown due to the fact that the types have changed from array to object, if you have any suggestions let me know. secondly, the biggest downside to this is we lose intellisense. the loss of intellisense does clean up a lot of code since it was dynamic, but that is still something to consider. file associations also doesn't have intellisense and the setting is often set through a picker similar to custom editors. </desc> <cmt> cleanup editor association setting </cmt> <cmt> remove commented out code </cmt> <iss> editor association should have ui piece in settings editor </iss> <iss> editor associations setting is overly verbose </iss>",reduce editor association setting verbosity.
2735,"<desc> this pr also fixed two bugs: in getdeviceandallocator() it didn't set cuda_device_id when device is found in cluster; in the same method if cluster is not available but device name is set in engine, it'll use the tf gpu id from the device name, but the tf_gpu_id->cuda_gpu_id mapping could be unset, in which case it'll failed. e.g. #20780 i've run all available tests and verified that the generated graphdefs are the same as before. </desc> <cmt> fix tf_trt_integration_test.py when running in python3. </cmt> <cmt> use tf_optimizer.optimizegraph() to reimplement create_inference_graph() method, and fix a bug in getdeviceandallocator() where it doesn't set the cuda_device_id even if the device is found. </cmt>",use tf_optimizer.optimizegraph to implement create_inference_graph
2736,"<desc> resolves #6551 renamed onerrorresumenext(source) to onerrorresumewith(source) for observable, maybe, single, and flowable renamed some unit tests and their classes to reflect the method name change changed parameter type of single.onerrorresumewith from single to singlesource updated javadocs for all renamed methods removed redundant casts for unit tests deleted duplicate unit test that arose from no longer needing to cast arguments </desc> <cmt> #6551 renaming observable.onerrorresumenext to observable.onerrorresumewith, removing unnecessary cast from null tests, and updating observable.onerrorresumewith's javadoc to reference correct parameter name, renamed test classes since the distinctions in their names are no longer necessary. </cmt> <cmt> #6551 renaming maybe.onerrorresumenext(maybesource) to maybe.onerrorresumewith(maybesource), renamed some of the affected unit tests, and updated javadoc. </cmt> <cmt> #6551 renaming single.onerrorresumenext(single) to single.onerrorresumewith(single), renamed an affected unit test, updated javadoc, and removed redundant casts. </cmt> <cmt> #6551 changing single.onerrorresumewith parameter from single<? extends t> to singlesource<? extends t> </cmt> <cmt> #6551 renaming flowable.onerrorresumenext(publisher) to flowable.onerrorresumewith(publisher), renaming some affected tests, deleted duplicated unit test that arose from being able to remove redundant casts, updated javadocs. </cmt> <iss> disambiguous some method call sites when calling from kotlin </iss>",3.x rename on error resume next methods to disambiguate when calling from kotlin (#6551)
2737,"<desc> this implements the following: loosens the requirement on localscalar() that the tensor is a scalar; now it only needs to be one element; scalar(...) still has the old requirement because it makes the code simpler (and people probably don't call that constructor directly anymore because we provide nicer conversion functions). implement tocdouble, tocfloat, etc. so that it calls through localscalar() and gets the 1-element property; this is to match the pytorch scalar conversion api and #3839. add a is_nonzero native function which is functionally equivalent to tocbool, which doesn't exist because we don't have bool tensors (it adds a nicer error message as well). uses the above aten changes to implement variable scalar conversions via aten; there is a bit of complication around conversion from double to (python) int, because we want to avoid the aten code path in that case because pylongs don't overflow.  also added a bunch of tests. </desc> <cmt> have localscalar work with all 1 element tensors, not just scalars. </cmt> <cmt> also have tocfloat, etc. call localscalar so 1 element tensors work as well. </cmt> <cmt> implement python number conversions. </cmt> <cmt> implement __bool__, __nonzero__ as aten functions. </cmt> <cmt> remove merge artifacts. </cmt>",implement python scalar conversions via aten; allow localscalar if numel == 1
2738,"<desc> the original author left his own key in there in order to get users started as easily as possible. not only is this a bad idea, but the server key also gives way too many privileges to the user. in essence, people could run their own complete website with that key. i removed the key and provided a script to let them easily upload the schema, create a role and a client key that uses that role. currently that script just lives in scripts/ and is called as yarn setup (defined in package.json) feel free to come up with an alternative but we do need to fix that users see this obscene content as they create a new sample app at this point. </desc> <cmt> let users define their own client token. </cmt> <cmt> make sure users know that graphql schema can also be done via the ui </cmt>",let users define their own database as easily as possible.
2739,<desc> i implemented the binomial and multinomial sampling. i also renamed the previous multinomial implementation to categorical. </desc> <cmt> implement binomial sampling </cmt> <cmt> add correct multinomial implementation </cmt> <cmt> small fix in binomial symbol api doc </cmt> <cmt> change npx_categorical to npx_multinomial </cmt>,add binomial sampling and fix multinomial sampling
2740,<desc> now we don't need to restart the program to apply new disassembly settings. and fix #715 (the disassembly interface is too messy) this change is </desc> <cmt> gui: resolve issue #715 </cmt> <cmt> initialize mwidths with zero </cmt> <cmt> gui: restart is nolonger required </cmt> <cmt> gui: restart is nolonger required </cmt> <cmt> gui: restart is nolonger required </cmt> <cmt> gui: restart is nolonger required </cmt> <cmt> gui: restart is nolonger required </cmt> <cmt> gui: restart is nolonger required </cmt> <iss> the disassembly interface is too messy </iss>,resolve ui bug (#715) and do not require restart on settings change
2741,"<desc> increased the vertical margins between the 3 settings since they are not related to each other. added a release notes link. references #2138 #889 pr checklist applies to #2138 #889 cla signed. if not, go over here and sign the cla </desc> <cmt> added release notes link </cmt> <cmt> minor styling fixes </cmt>",release notes link + minor styling fixes
2742,"<desc> after a post from user ""tann"" on discord #android channel we've realised some inconsistencies on the libgdx default color format (rgb565) and the platform defaults on android (rgb888) and ios (rgba8888). android it is currently set to rgb565 because that was the default of glsurfaceview before but, currently (not sure since when), it's rgb888 ( by default glsurfaceview will create a pixelformat.rgb_888 format surface. i've kept rgb565 as fallback in case the provided color format configuration is not supported by the device. this is the safest approach as, in the rare case a device did not support rgb888 it would fallback to previous default but it's not necessarily the best one. it depends if there are actually devices in the wild (with min sdk 14+) that don't support rgb888, if there aren't, we should default to rgb888. unfortunately i haven't been able to find that information. regarding the changes a couple of comments: the change in the bufferformat on androidgraphics is aesthetic. a new instance with the appropriate configurations is assigned to bufferformat, i'm not sure if instantitating it on declaration is needed at all but i've kept it just in case. something similar happens on glsurfaceview20 init() method changes. even if we set the color format there (either rgb888 or rgba8888) it doesn't matter because we set it manually afterwards in every case later on (check for example androidgraphics.createglsurfaceview()): glsurfaceview20 view = new glsurfaceview20(application.getcontext(), resolutionstrategy, config.usegl30 ? 3 : 2); if (configchooser != null) view.seteglconfigchooser(configchooser); else view.seteglconfigchooser(config.r, config.g, config.b, config.a, config.depth, config.stencil); known issues and tests using rgb565 has some known issues on especific devices such as reported here #5993. i've also personally observed issues when running an opengl gradient on a nexus 7 2013 which displays bad banding and artifacts that get fixed using rgb888. current default rgb565 causes dithering to be applied, especially visible when zooming in on any libgdx game with default settings. @cypherdare says he's been using rgba8888 on his apps for 5 years without any issue. ios on ios the current default is rgba8888 ( ios is weird because the color format seems to be ignored when running on a device (it always looks like rgb888) but it is correctly applied on simulator. i've confirmed this and has been reported on the forums before: </desc> <cmt> set android glsurfaceview texture format to android default rgb888 </cmt> <cmt> set ios default color format to rgba8888 </cmt>",use platform default color bit depth on android and ios
2743,<desc> cherry-picks: dc197e5 5306563 bc2d1d3 df0c097 risk level: low testing: ci part of #10741 </desc> <cmt> release: kick-off 1.14.2-dev </cmt> <cmt> build: refine docker image ci process (#10729) </cmt> <cmt> ci: remove tools from agent for disk (#10775) </cmt> <cmt> ci: update before purge in cleanup (#10938) </cmt>,various build fixes for 1.14.x
2744,<desc> currently this change reports errors only for heritage clause and constraints of type parameters if the name is not public </desc> <cmt> make the symbol writing api on the text writer </cmt> <cmt> checker and emitter changes to report errors on inaccessibility of symbols when writing types in declaration file </cmt> <cmt> report error on class/interface heritage clause if it cant be accessed </cmt> <cmt> fixes #78 and #83 </cmt> <cmt> report errors if the type parameter uses constraint that is using private type/module </cmt> <cmt> fixes #86 </cmt>,report errors for usage of private types when generating declaration file
2745,"<desc> provide two grafana dashboard settings. use skywalking trace-mode dashboard agent. use skywalking mesh-mode dashboard when skywalking is used with service mesh telemetry, including istio, envoy. this is the first version of grafana settings, feel free to improve this. @hanahmily the last step for #2073 fyi @peng-yongsheng </desc> <cmt> change a label name for  sw instance to avoid confict. </cmt> <cmt> fix a wrong metric name. </cmt> <cmt> fix too many counter instances. </cmt> <cmt> set uptime to second. </cmt> <cmt> fix format. </cmt> <cmt> fix format </cmt> <cmt> remove two unnecessary counter. </cmt> <cmt> provide grafana dashboard settings and remove unnecessary metric. </cmt> <cmt> provide a simple ui brief doc. fix #2137 </cmt>",provide grafana settings for telemetry
2746,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. summary of changes reduce examples to only those relevant to the overload and use shorter template for code-only examples. (57202ba / 5d46054 / 861831c / e349a3b / f02ab1e) previously, all examples for all overloads of a method were shown for every overload of that method. now, only relevant examples for each overload are shown. also, code-only examples now use a much shorter template. this should improve the experience for consumers through less noise. these changes also takes index.d.ts back under 1 mb which re-enables github features for it (e.g. syntax highlighting and linking to specific lines). minor changes (a8b6588 / 371a701 / ea00476) these changes are for consistency and should have no impact on existing code. add interface for jquery.fx. add interface for jquery.callbacks. apply consistent ordering. documentation fixes (8686d9f / 8310859) the documentation for jquery.deferred was incorrectly attached to its property instead of its call signature. this pr fixes it so that the correct documentation is displayed when using the call signature. also fixes documentation for an overload of jquery.proxy that had incorrect @since tags and an errant . add jquery.getscript(options). (78fb12a) see jquery/api.jquery.com#1052. accept document, window, and jquery.plainobject for the element parameter of data apis. (cf0be56) see  add jquery.cleandata. (39bfedc) see jquery/api.jquery.com#996. </desc> <cmt> [jquery] introduce interface for jquery.fx. </cmt> <cmt> [jquery] attach jquery.deferred documentation to correct symbol. </cmt> <cmt> [jquery] convert jquery.callbacks to an interface. </cmt> <cmt> this change is purely for consistency with similar properties (e.g. jquery.deferred, jquery.event). </cmt> <cmt> [jquery] for jquery, reduce examples to only those relevant to the overload and use shorter template for code-only examples. </cmt> <cmt> [jquery] for jquerystatic, reduce examples to only those relevant to the overload and use shorter template for code-only examples. </cmt> <cmt> [jquery] for jquery.event, reduce examples to only those relevant to the overload and use shorter template for code-only examples. </cmt> <cmt> [jquery] for jquery.callbacks, reduce examples to only those relevant to the overload and use shorter template for code-only examples. </cmt> <cmt> [jquery] for jquery.promisebase/jquery.deferred, reduce examples to only those relevant to the overload and use shorter template for code-only examples. </cmt> <cmt> [jquery] consistent ordering. </cmt> <cmt> [jquery] add jquery.getscript(options). </cmt> <cmt> see </cmt> <cmt> [jquery] fix documentation for this one overload of jquery.proxy. </cmt> <cmt> [jquery] accept document, window, and jquery.plainobject for the element parameter of data apis. </cmt> <cmt> see </cmt> <cmt> [jquery] add jquery.cleandata. </cmt> <cmt> see </cmt>",documentation improvements. add jquery.cleandata and overloads for jquery.getscript and data apis.
2747,<desc> maxpooling1d and averagepooling2d now passes tests with theano backend also added test cases with different padding modes for average pooling1d </desc> <cmt> added padding test case for averagepooling1d </cmt> <cmt> fixed issues with pool2d </cmt>,fixed issues with conv2d in theano backend
2748,"<desc> when writing pub fn f( /// comment id: u8, ) {} produce a targeted diagnostic error: documentation comments cannot be applied to method arguments --> $dir/fn-arg-doc-comment.rs:2:5 | ll |     /// comment |     ^^^^^^^^^^^ doc comments are not allowed here fix #54801. </desc> <cmt> produce targeted diagnostic when using doc comments on fn args </cmt> <cmt> before parsing argument names and types, try to consume an incorrectly </cmt> <cmt> included doc comment or attribute in order to recover and continue </cmt> <cmt> parsing the rest of the fn definition. </cmt> <cmt> point at match when a parse failure ocurrs inside of it </cmt>",custom diagnostic when trying to doc comment argument
2749,"<desc> this enables underlying compiler support for the proposed exclusivity language feature for testing and evaluation. static enforcement: -onone: static access markers present through irgen -o: all access markers stripped before optimization -onone -enforce-exclusivity=unchecked: diagnostics active, no sil change. -o -enforce-exclusivity=unchecked: diagnostics active, markers stripped before optimization dynamic enforcement: dynamic markers are only present in silgen and throughout sil passes as long as necessary. i.e. once a marker is determined to be dynamic, it is stripped if it's inactive. -onone -enforce-exclusivity=checked: runtime diagnostics active. no changes to the sil other than the access markers themselves except in extreme unexpected cases. -o -enforce-exclusivity=checked: unsupported. output a warning. dynamic markers will be stripped. runtime diagnostics will not be active. </desc> <cmt> [exclusivity] allow accessenforcementselection to run before di. </cmt> <cmt> [exclusivity] handle copy_addr+destroy_addr folding with end_access markers. </cmt> <cmt> [exclusivity] enable access markers for the entire -onone pipeline. </cmt> <cmt> dynamic markers are still conditional on the command line option. </cmt> <cmt> [exclusivity] update tests for access markers. </cmt> <cmt> [exclusivity] access enforcement sil tests. </cmt>","-onone support for access markers, fixes to sil passes, options and pipeline config."
2750,"<desc> description: when user has multiple miflora devices, we can't connect to them during platforms setup, because it takes several seconds to connect to each device and we can't do it concurrently because of locks in btlewrap ( i will remove a code which makes a connection on platform setup. this will lead to 2 problems: first values will appear in 20 minutes (when first update will be called by ha).  we can handle it by triggering async_schedule_update_ha_state() right after ha start. we won't know if everything is ok with device during ha startup. it's impossible to handle this case, we will leave w/o it. related issue (if applicable): fixes #16700 </desc> <cmt> possible fix for startup delay </cmt> <cmt> fixed reported issues </cmt> <iss> platform miflora stoped working on 0.78.0 </iss>",fix miflora connection errors during platform setup
2751,"<desc> adds obs_audio_monitoring_supported() adds audio_monitoring source signal for monitoring type changes updates the advanced audio properties dialog when an input's audio monitoring type changes we allow users to change the monitoring type through obs-websocket, and it wasn't updating the ui when someone would perform a request. i also hate incomplete functionality. os: ubuntu 20.04 build: latest git commit as of posting obs_audio_monitoring_supported() related changes were only tested on ubuntu, but should work the same on all platforms. audio_monitoring signal was tested via obs-websocket advanced audio properties update when setinputaudiomonitortype obs-websocket request is performed bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) code cleanup (non-breaking change which makes code smaller or more readable) documentation (a change to documentation pages) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> libobs: add obs_audio_monitoring_supported() </cmt> <cmt> currently, ifdefs are used to determine if monitoring is supported. </cmt> <cmt> this is difficult to maintain and restricts plugins from knowing if </cmt> <cmt> monitoring is supported by obs. this adds a runtime function to fix </cmt> <cmt> that issue. </cmt> <cmt> libobs/ui: stop using preprocessor directives for monitor </cmt> <cmt> **code cleanup** </cmt> <cmt> stop using preprocessor directives to determine if audio monitoring </cmt> <cmt> is supported. use runtime function instead </cmt> <cmt> libobs: add audio_monitoring source signal </cmt> <cmt> adds a source signal for audio monitoring type changes </cmt> <cmt> ui: update adv audio props on monitoring type change </cmt> <cmt> update the audio monitoring combo box when it is changed via libobs. </cmt> <cmt> required to make obs-websocket requests work well </cmt>",signal when monitoring type is changed and update ui accordingly
2752,"<desc> @steven-sheehy @unguiculus this skips initialization of the replicaset during bootstraping if set to true. this is helpful during a migration phase. you can now add the created nodes to an already existing mongodb replicaset and still install and mange the cluster with the helm chart. you just end up with the defined number of new empty nodes and can implement your own migration path with it. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> start the server with ssl enabled if the client also uses ssl </cmt> <cmt> in retry_until only read the last mongo client line </cmt> <cmt> add a donotinit value that skips the replicaset creation on first start </cmt> <cmt> added test for donotinit flag </cmt> <cmt> bumped chart version, added documentation to readme.md </cmt>",dont initiate replicaset during bootstrapping
2753,"<desc> hi @apache/skywalking-committers and all this pr brings all i talked in #3098, now oal scripts are loaded in bootstrap stage oal is still at compile level. but not by jdk, instead, by oalruntime to generate binary codes. this is the black magic, i have tried my best to keep codes as simple as possible, and keep using freemaker templates for readability. all metrics process flows are the same as before i am going to add metrics name in the remote protocol after this pr merged, to replace the id, because, at bootstrap level, oal scripts may different somehow in different instances. we should use the literal string name in the internal distributed aggregation and print warning log when receiving unexpected metrics name. </desc> <cmt> change oal generator tool to runtime. </cmt> <cmt> step 1. change project structure. api links and maven pom. </cmt> <cmt> part of metrics class generation </cmt> <cmt> metrcis class generated. </cmt> <cmt> set up the basic structure of new oal engine. </cmt> <cmt> finish metrics generation. </cmt> <cmt> support dispatcher generation. </cmt> <cmt> format codes. </cmt> <cmt> generate dispatcher all methods. </cmt> <cmt> implement disable in hardcode. </cmt> <cmt> clear up </cmt> <cmt> merge commit 'c7916d9f2715ff9d3c415f86418d8f81c97a21e7' into rt-oal </cmt> <cmt> # conflicts: </cmt> <cmt> #	oap-server/pom.xml </cmt> <cmt> fix compile startup. </cmt> <cmt> update license and document of new oal engine. </cmt>",all new oal runtime engine
2754,"<desc> android 4.4 added support for basically a slightly more advanced fullscreen feature called 'immersive mode'. this will be beneficial to some games that have support for smaller phones. this fixes #942 </desc> <cmt> added immersive mode option </cmt> <cmt> added android 4.4 kitkat immersive support </cmt> <cmt> fixed accidental typos, sorry. </cmt> <cmt> added actual immersive mode </cmt> <cmt> updated android library to android 4.4 for immersive mode </cmt> <cmt> immersive mode needs a flag that requires the android 4.4 libraries </cmt> <iss> android 4.4 kitkat 'immersive mode' missing </iss>",added immersive mode support for android 4.4 kit-kat devices
2755,<desc> update the tutorial to use the updated version of graphiql with the explorer pane. replace the graphiql-explore.mp4 screen capture with new version. update related screenshots. add new verbiage to introduce the explorer. add new section on field selections with the explorer. none. closes #15806 </desc> <cmt> replace graphiql explore screengrab with version with explorer </cmt> <cmt> add graphiql explorer examples </cmt> <iss> update the tutorial to use the explorer </iss>,update tutorial to use graphiql explorer
2756,<desc> addresses #21350 #dataumbrella this pr ensures metrics.pairwise.euclidean_distances is compatible with numpydoc: remove metrics.pairwise.euclidean_distances from docstring_ignore_list. verify that all tests are passing. partner: @genvalen </desc> <cmt> remove euclidian_distances from function_docstring_ignore_list </cmt> <cmt> ensure that euclidian_distances method passes numpydoc validation </cmt>,doc ensures that metrics.pairwise.euclidean_distances passes numpydoc validation
2757,"<desc> description: this adds support for the homekit battery service - so battery powered homekit accessories can now report their battery percentage, if they are currently charging and if their battery percentage is low. checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: </desc> <cmt> add simple battery sensor </cmt> <cmt> vary icon based on battery state </cmt> <cmt> add test for battery sensory </cmt> <cmt> add test for battery sensor based on a real device </cmt> <cmt> read other battery related states from accessory </cmt> <cmt> add a device class to the battery sensor </cmt> <cmt> respect the low battery flag from the device </cmt>",add support for homekit accessory battery sensors
2758,"<desc> closes #22556 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fix na_position when sort_values by categorical values </cmt> <cmt> move test to test_sort.py and fix index </cmt> <cmt> using pandas.isna to allow categoricalindex calling nargsort </cmt> <cmt> linter fix in test_sorting.py </cmt> <cmt> add to whatsnew </cmt> <iss> df.sort_values() not respecting na_position with categoricals </iss>",df.sort_values() not respecting na_position with categoricals #22556
2759,"<desc> fixes #35226 which is part of #35233. is based on #36208 from @yossi-k. r? @jonathandturner </desc> <cmt> update e0088 to new format, remove e0090 </cmt> <cmt> use span of first unexpected lifetime in e0088. </cmt>",update e0088 to new error format
2760,"<desc> when i do something like this: var handlescroll = _.debounce((e:jqueryeventobject)=>{ //handle the scroll event here }); $el.on(""scroll"", handlescroll); typescript compiler throws error citing parameter mismatch. since these functions return the function with same signature as the functions passed in it is easy to support them via generics. </desc> <cmt> made the functions once, debounce, throttle, after to accept function with generics signature. the function returened from these functions will have signature as the functions passed into them, compiler should be made aware of this. </cmt> <cmt> corrected the auto spacing created by webstorm ide </cmt>","adding generics support for the underscore functions throttle, debounce, once, after"
2761,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> move fingerprintjs types to v1 sub-folder </cmt> <cmt> add types for fingerprintjs2 v2, fix config for v1 </cmt>","add types for fingerprintjs2 v2, move v1 types to subdir"
2762,"<desc> the check_f macros differ slightly (but eventually do the same thing) so the guards allow all the decoder files to be 'amalgamated' into a single file. older gcc needs to fallback on the old-style pragma optimisation flags (the alternative path was verified with gcc4). </desc> <cmt> v1.4.1: merge pull request #1691 from facebook/dev </cmt> <cmt> v1.4.2: merge pull request #1700 from facebook/dev </cmt> <cmt> fix the build on gcc 4.x after 812e8f2a1 </cmt> <cmt> the ancient gcc 4.x doesn't understand the ""optimize"" attribute until 4.4. </cmt> <cmt> fix the build on platforms with gcc 4.x < 4.4 by limiting the dont_vectorize </cmt> <cmt> definition to gcc 5 and greater. </cmt> <cmt> noticed and patch proposed by warner losh <imp@freebsd.org>. </cmt> <cmt> v1.4.3: merge pull request #1730 from facebook/dev </cmt> <cmt> fix the build on gcc 4.x after 812e8f2a1 </cmt> <cmt> tweaks to create a single-file decoder </cmt> <cmt> the check_f macros differ slightly (but eventually do the same thing). older gcc needs to fallback on the old-style pragma optimisation flags. </cmt>",tweaks to create a single-file decompressor
2763,"<desc> performance optimization ops cherry-pick #29187, #29484, #29553 </desc> <cmt> improve performance of elementwise_add grad op (#29187) </cmt> <cmt> * pass stop_gradient for cast op </cmt> <cmt> * improve performance of elementwise_add grad </cmt> <cmt> * use tensor copy async </cmt> <cmt> * dygraph branch </cmt> <cmt> * fix dygraph branch </cmt> <cmt> * add ut </cmt> <cmt> make gelu fp16 computing more robust (#29484) </cmt> <cmt> add fast path for dropout when p == 0  (#29553) </cmt> <cmt> * add fast path for p == 0 in dropout </cmt> <cmt> * add ut </cmt>","some optimizations of elementwise_add, gelu and dropout for amp"
2764,"<desc> this pr adds 2 extra tests for gridlayer zoom-in and zoom-out animation on ""graphical browsers"" (i.e. not phantomjs). they are similar to these already existing 2 tests: gridlayer number of 256px tiles loaded in synchronous animated grid @800x600px loads 32, unloads 16 tiles zooming in 10-11 gridlayer number of 256px tiles loaded in synchronous animated grid @800x600px loads 32, unloads 16 tiles zooming out 11-10 but instead of using clock.tick to accelerate the tests and have to use raf at the appropriate moments, these tests let the animation execute on its own. therefore they should be less prone to breaking when the animation is internally modified. the drawback is that they take slightly longer time to pass (a few hundreds ms). but there are already much longer tests (a few seconds for some of them). hopefully this pr will not conflict once the previous one gets merged (#6199) </desc> <cmt> test(gridlayer): add zoom-in for graph browser </cmt> <cmt> add a new test for ""graphical browsers"" for zoom-in animation, not relying on sinon.usefaketimers so that it lets the animation executing on its own, and is less prone to breaking when the animation process is changed internally. </cmt> <cmt> test(gridlayer): add zoom-out for graph browsers </cmt> <cmt> add a new test for ""graphical browsers"" for zoom-out animation, not relying on sinon.usefaketimers so that it lets the animation executing on its own, and is less prone to breaking when the animation process is changed internally. </cmt>",add 2 new tests for zoom-in/-out in graphical browsers
2765,"<desc> as title. #17702 and #17872 revised same lines in test_gluon_rnn.py. so we need to backport them in one. @ciyongch @taolv @pengzhao-intel also </desc> <cmt> support projection feature for lstm on cpu (only inference) (#17702) </cmt> <cmt> * support projection feature for lstm on cpu </cmt> <cmt> * test solution for -werror=maybe-uninitialized </cmt> <cmt> * check device type when create state </cmt> <cmt> * document the projection feature of lstm for rnn operator </cmt> <cmt> * minor fix </cmt> <cmt> * re-run ci </cmt> <cmt> fix issue of zeros gradients w.r.t. rnn bias when num_layers > 1 (#17872) </cmt> <cmt> * fix issue of zeros gradients w.r.t. rnn bias when num_layers > 1 </cmt> <cmt> * use nd.copy() to initialize parameters of new operator </cmt> <cmt> * add check for output states </cmt> <cmt> * initialize i2h/h2h_weights with zeros for rnn_relu/tanh, and reduce size </cmt> <cmt> * split fused rnn layer test into tests of individual mode </cmt> <cmt> * skip lstm and gru tests on cpu context without dnnl </cmt>",backport #17702 and #17872 to v1.x branch
2766,<desc> what's in this pull request? resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> improve comment and function name. nfc. </cmt> <cmt> add a test case for recent change in functionsignatureopts </cmt>,address gottesmm's and jrose-apple's comments on the partial_apply optimization
2767,"<desc> implement dlpack to paddle tensor conversion, add ""tensorfromdlpack"" function to tensor_util.h, support cpu and gpu. the dlpacktensor class adds the conversion function ""todlmanagedtensor"" to dlmanagedtensor (in order to achieve the connection with cudf and cupy, dlmanagedtensor is required) through pybind11, encapsulate the python interface, pass the dlmanagedtensor pointer through the pycapsule object, and open up with cudf and cupy. added tensor.to_dlpack and fluid.core.from_dlpack interfaces. </desc> <cmt> support convert tensor to cudf depends on dlpack test=release/1.6 </cmt>",support dlpack convert to cudf
2768,"<desc> if we want to support this property, the following patches provides a way of doing so. please refer to the individual commit messages for additional details. fixes #8657. </desc> <cmt> [api-minor] add support for pagemode in the api (issue 8657) </cmt> <cmt> please refer to </cmt> <cmt> refactor reading from the viewhistory in pdfviewerapplication.load </cmt>",add support for pagemode in the api and viewer (issue 8657)
2769,"<desc> this pr introduces a rather big change. the highest-level namespace definition is removed: the whole file represents now the ol namespace. it does not change the way to use the module, still use import * as ol from 'openlayers'. the changes have been tested on a test application based on the draw shapes example. reorganizing the namespaces makes the internal olx namespace available from outside as ol.olx. it fixes #19956. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix no-declare-current-package lint </cmt> <cmt> fix no-internal-module lint </cmt> <cmt> fix no-single-declare-module lint </cmt> <cmt> update tests file using import </cmt> <iss> [openlayers] is there any reason for hiding olx? </iss>",fix the module-related lint issues
2770,"<desc> pulled from some kbfirmware json files after a discord user contacted me about this board. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> [keyboard] neo keys palette g67 hotswap </cmt> <cmt> [keyboard] neo keys palette g67 soldered </cmt>",neo keys palette g67 hotswap & soldered
2771,<desc> this breaks up the serverless-loader into typed handlers to allow for easier maintenance and better type-checking/linting. closes: #19071 </desc> <cmt> migrate api serverless handler to typed handler </cmt> <cmt> migrate api serverless handler to typed handler </cmt> <iss> strongly type next.js' serverless loader </iss>,break up the serverless loader into typed handlers
2772,"<desc> >>> @dataclass(repr=false, eq=false, init=false) ... class x: ...     a: int ...     b: int ...     c: int ... traceback (most recent call last): file ""<stdin>"", line 2, in <module> file ""/home/bucher/src/cpython/lib/dataclasses.py"", line 1042, in wrap return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen) file ""/home/bucher/src/cpython/lib/dataclasses.py"", line 1020, in _process_class cls.__match_args__ = tuple(f.name for f in flds if f.init) unboundlocalerror: local variable 'flds' referenced before assignment </desc> <cmt> add a regression test for bad __match_args__ logic </cmt> <cmt> fix broken __match_args__ logic </cmt> <cmt> blurb add </cmt>",fix __match_args__ generation logic for dataclasses
2773,<desc> closes: #7371 closes: #7726 </desc> <cmt> fix(aws sqs): fix referencing lambdas with provisioned concurrency </cmt> <cmt> fix(aws api gateway): fix referencing provisioned authorizers </cmt> <iss> aws sqs event source does not work with a lambda with provisionedconcurrency </iss> <iss> api gateway custom authorizer not referencing provisioned alias lambda when specifying provisioned concurrency </iss>,fix setup of lambdas with provisioned concurrency
2774,"<desc> this change ensures pseudoterminal-based and local terminals (vscode-file uri as cwd) do not await available profiles as they will not be used: this also ensures we await the createterminal call before returning to the exthost to ensure the terminal id is ready before proceeding. fixes #132519 fixes microsoft/vscode-remote-release#5556 </desc> <cmt> don't await profiles for custom ptys, ensure createterminal returns </cmt> <cmt> fixes #132519 </cmt> <cmt> fixes microsoft/vscode-remote-release#5556 </cmt> <cmt> ensure local terminals can launch before available profiles are ready </cmt> <cmt> fixes #132519 </cmt> <cmt> fixes microsoft/vscode-remote-release#5556 </cmt>",fix launching pseudoterminal-based and local terminals in remote workspaces before the connection is established
2775,"<desc> this is an extended version of #1084, allowing to specify a custom host in the seafdav.conf file, fixing #478. currently, the webdav server binds to localhost if used in fastcgi mode, and to 0.0.0.0 if used in standalone mode. both may be undesired. it is especially annoying if an external web server is used in conjunction with fastcgi. </desc> <cmt> added option to seafile controller to configure host to bind seafdav service to using seafdav.conf </cmt> <cmt> added default host to seafdav.conf </cmt>",custom webdav binding configuration using seafdav.conf
2776,"<desc> this patch simply adds method docs to most of the methods in ml/dmlc/xgboost4j/scala/spark/xgboost.scala and also adds a few style changes to make the code a bit more uniform. i think/hope this will be valuable for developers who need to make changes to the spark package and even for users who wish to understand how xgboost4j-spark parallelizes training within spark. if this is valuable to the community, please let me know if any style changes violate desired conventions, or if any of the docs should be updated/modified. tests no functionality is changed, so existing unit tests should be sufficient. </desc> <cmt> add scala docs to several methods </cmt> <cmt> indentation </cmt> <cmt> license formatting </cmt> <cmt> clarify distributed boosters </cmt>",add some documentation to xgboost4j-spark plus minor style edits
2777,"<desc> changes in this: if the old state was not present or not used, we set flag that says instead of calculating signature for a file (which is dts emit hash) use the version of file as the signature. this makes it so that initial compilation will not calculate the d.ts emit and next file change to the file will be treated as non local change and thats when the signatures for file reference dependency are calculated and it would probably result in emitting more files than necessary but thats the compromise for not having to spend cost for d.ts emit in the initial round. the next change to that file should be able to correctly detect local/non local change as before. 925e70e just updates tests to ensure we are testing the scenarios we intended. dd1cef2 is actual change and may be ideal to look at the changes as part of that commit. 69ebfe3 checks updates to the incremental correctness of the program, essentially signature is same as d.ts emit signature or version of the file. also exported modules map is checked in similar way. 44ba0ec reverts the compileonsave to old behavior of always computing signature this is simplified implementation of work in #42960 by @sokra there are more todos that we can improve on, eg if global file is changed, mark it for lazy signatures etc  but i think that each change should be separate change to be able to evaluate the perf impact and if needed revert it. potential improvements: global file change => resulting in emitting all files so could benefit from using signature as version certain number of new files percentage certain number of changed file percentage </desc> <cmt> extra tests in preparation for lazy signature making sure the original intent of test is maintained </cmt> <cmt> whenver we cant use state delay signature calculation and use source file version as signature </cmt> <cmt> incremental correctness checks </cmt>",do not calculate signatures if old state is not used
2778,"<desc> fixes #757 (v2) replace all wstring from public methods to platform::string also replace std::task by iasyncoperation convert localizationstringutil and appresourceprovider to ""ref classes"" use wstringstream when we concatenate many strings. manually </desc> <cmt> prefer platform::string to wstring in calcviewmodel </cmt> <cmt> merge with upstream/master </cmt> <cmt> fix ""__va_start intrinsic only allowed in varargs"" with x64/arm compilation </cmt> <cmt> take feedback into account </cmt> <cmt> fix string formatting with narrator and bring back cached values </cmt> <iss> prefer platform::string over wstring in calcviewmodel </iss>",replace wstring used in public methods by platform::string in calcviewmodel
2779,"<desc> this simplifies and removes a lot of duplicate code from qwiickeyboard, and should also fix the layer cache to properly work with mt and lt keys. </desc> <cmt> fix missing brackets warning </cmt> <cmt> make the layer cache more efficient </cmt> <cmt> also change the internal representation to a one dimensional array </cmt> <cmt> add a keymatrix_t type </cmt> <cmt> this contains both the matrix number and key position, in preparation </cmt> <cmt> for multi-matrix support </cmt> <cmt> add proper multimatrix support </cmt> <cmt> document some functions </cmt>",add multi-matrix support and make the layer cache more efficient
2780,<desc> description: adds a stat control_plane.connected_state that indicates whether envoy's connected state with management server risk level: low testing: automated tests docs changes: added release notes: added fixes #4449 </desc> <cmt> added stat for connected state of control plane </cmt> <cmt> update docs </cmt>,add control plane connected state stat
2781,"<desc> this pr adds support for the decrqss (request selection or setting) escape sequence, which is a standard vt query for reporting the state of various control functions. this initial implementation only supports queries for the decstbm margins, and the sgr graphic rendition attributes. this can be useful for certain forms of capability detection (#1040). as one example in particular, it can serve as an alternative to the colorterm environment variable for detecting truecolor support (#11057). of the settings that can be queried by decrqss, the only other one that we could be supporting at the moment is decscusr (cursor style). however, that would require passing the query through to the conpty client, which is a lot more complicated, so i thought it best to leave for a future pr. for now this gets the basic framework in place, so we are at least responding to queries, and even just supporting the sgr attributes query is useful in itself. i've added a unit test verifying the reports for the decstbm and sgr settings with a range of different parameters. i've also tested the decstbm and sgr reports manually in vttest, under menu 11.2.5.3.6 (status-string reports). </desc> <cmt> add the basic framework for decrqss. </cmt> <cmt> add a handler for the decstbm setting. </cmt> <cmt> add a handler for the sgr setting. </cmt> <cmt> add some unit tests. </cmt> <cmt> appease the spelling bot. </cmt>",add basic support for the decrqss settings query
2782,"<desc> this is an update to #3751 to provide an error back to the client when database inserts fail. </desc> <cmt> log error on device status insert & don't crash </cmt> <cmt> add error logging to all mongo inserts </cmt> <cmt> return error when role or subject create fails. </cmt> <cmt> return error if insert fails for activity, devicestatus, or food. </cmt>",fix database insert error handling
2783,"<desc> v2 of #2083 </desc> <cmt> basic/virt: add missing includes to compile on ppc64 </cmt> <cmt> tests: turn check if manager cannot be intialized into macro </cmt> <cmt> we need to check the same thing in multiple tests. use a shared </cmt> <cmt> macro to make it easier to update the list of errnos. </cmt> <cmt> change the errno code for ""unitialized cgroup fs"" for enomedium. </cmt> <cmt> exec format error looks like something more serious. </cmt> <cmt> this fixes test-execute invocation in mock. </cmt> <cmt> tests: fix newlines in skip message </cmt> <cmt> lz4: fix size check which had no chance of working on big-endian </cmt>",test fixes to run in ppc64 mock
2784,<desc> ref #98326 /priority important-soon comments for reviewer: might be easier to review commit-by-commit. </desc> <cmt> split gce/gke upgrade mechanics to a separate file </cmt> <cmt> rename functions to eliminate master word </cmt> <cmt> move non-provider specific upgrade tests logic to upgrades package </cmt>,split upgrade tests logic to generic and provider-specific
2785,<desc> description: refresh closest store when menu requested related issue (if applicable): fixes #10929 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> reload closest store on api request </cmt> <cmt> revert change from debugging </cmt> <iss> dominos config error </iss>,reload closest store on api menu request
2786,<desc> to be merged when 1.15 has been released and we've updated our own prettier version. </desc> <cmt> update rationale about multiline object literals for the 1.15 changes </cmt> <cmt> add rationale about decorators for the 1.15 changes </cmt>,update rationale for the 1.15 changes
2787,"<desc> todo: remove print button fix/add print button restyle progress bar re-arrange the zoom options to stephen's specs. add back the browse file button or just remove it? add disabled state for buttons? i think we should change it so the outline button is never disabled, instead it should just say in italic ""no outline available"" or something. clean up the error message dialog a little more out there: scroll the thumbnail view while the user scrolls the main pages. determine the page number based on the center of the screen instead of the top. </desc> <cmt> first mockup, loads tracemonkey pages ok </cmt> <cmt> sidebar toggle working </cmt> <cmt> fixing sidebarview scroll bar overflow </cmt> <cmt> text selection ok, switch outline ok </cmt> <cmt> bug fix (works with intelisa) </cmt> <cmt> outline view </cmt> <cmt> disable user select in outline </cmt> <cmt> page number works (not editable yet) </cmt> <cmt> user-changes to pagenumber are working </cmt> <cmt> loadingicon </cmt>",new ui - work in progress
2788,"<desc> tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry closing a fixme note in the test suite. </desc> <cmt> bug: raise ambiguoustimeerror for date_range with ambiguous start time. </cmt> <cmt> clarify comment </cmt> <cmt> add nonexistent tests </cmt> <cmt> xfail one case after discovered bug </cmt>",fix handling of ambiguous or nonexistent of start and end times in date_range
2789,<desc> fixes #7179 please also review #7932 first as the cleanup to this script. as per title component name area/system none tested several variations of the repro in #7179 and in all cases whether or not netdata is installed in a symlinked location editing configuration eith edit-config works as expected with: enjoy real-time performance and health monitoring... copying '/opt/netdata/usr/lib/netdata/conf.d/apps_groups.conf' to '/opt/netdata/etc/netdata/apps_groups.conf' ... editing '/opt/netdata/etc/netdata/apps_groups.conf' ... </desc> <cmt> re-formated ./system/edit-config.in with shfmt -w -i 2 -ci -sr </cmt> <cmt> fixed and cleaned up ./system/edit-config to work correctly with symlinks </cmt> <iss> edit-config fails due to /opt being a symlink </iss>,fixes support for editing configuration when netdata is installed to a symlinked /opt
2790,"<desc> hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! tryna to transfer cheatsheet links from books to cheatsheets page cheatsheets are smaller and can container good amount of infos you can check it by its link cheatsheets not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> docs: add links for cheatsheets </cmt> <cmt> docs: remove links for cheatsheets from books page </cmt>",transfer links for cheatsheets from books page to new cheatsheets page and add css/js cheatsheets
2791,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration </desc> <cmt> servicenow jakarta api </cmt> <cmt> rename and add add header </cmt> <cmt> fix linting errors </cmt>",new typings for servicenow javascript api reference
2792,"<desc> what is this about? this pr removes the requirement that space is needed after the action keyword. pr checklist applies to #3212. cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? the following changes have been made in this pr - previously, there was only one query being sent to all the plugins. if the first space separated item was an action keyword, then only a non global query would be executed. however, now we have a query being generated for each plugin. we execute global plugins along with the non global plugins as we have removed the space requirement following the action keyword. a few symbols have been added to the search ignore regex of the indexer plugin. the symbols which have been added are >, < and : because when we search for >cmd, the indexer plugin is also executed now and it compared the filenames and returns those which are greated than cmd. this was leading to a delay. also, filenames do not contain these symbols >, < and :. hence queries containing these symbols can be ignored. previously the cancellation token was based on the query, however since we have a unique query for each plugin, the cancellation token is based on the querytext instead which is same for all plugins. validation steps performed how does someone test & validate? added  tests manually validated it </desc> <cmt> returning individual queries for each plugin </cmt> <cmt> changed cancellation token from query type to directly using the rawquery </cmt> <cmt> changed the way we get the plugins for which we execute the query </cmt> <cmt> updated updateresultview to take a string instead of query </cmt> <cmt> changed the way we set a query for each plugin </cmt> <cmt> removed todo comment </cmt> <cmt> global plugins are added as a part of the query builder </cmt> <cmt> merging with master </cmt> <cmt> fix for plugin.json of folder plugin being copied into the shell plugin </cmt> <cmt> >,< and : are not allowed in file paths and indexer creates a query which searches compares if a file name is greater than or lesser than the query </cmt> <cmt> reformatted the regex </cmt> <cmt> catching the exception </cmt> <cmt> fixed merge conflicts </cmt> <cmt> fixed existing tests </cmt> <cmt> modified it so that it works with action keyword as well as action keywords </cmt> <cmt> added unit tests for non global plugins </cmt> <cmt> fixed test </cmt>",to remove the condition that space is needed after the action keyword
2793,"<desc> this bug only occurs if ray.job.resource-path is set. in multi-threading scenario, different raynativeruntime instances holds different functionmanager instances, which means different classloader instances for the same job. if the user code involves any static variables, it may behave strangely. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> fix multiple functionmanager instances lead to unexpected behavior about classloader </cmt> <cmt> use explicit locks instead of synchronized keyword on methods </cmt>",fix multiple functionmanagers creating multiple classloader s
2794,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> update ws for version 3.0.0 ( </cmt> <cmt> update ws for version 3.0.0 </cmt> <cmt> update spdy to avoid redeclaring node types. </cmt> <cmt> put back spaces to avoid pull-request problems </cmt>","avoid re-declaring node types, import instead"
2795,"<desc> fixes #998 the sls variables xxx type commands now support the serverless variable hierarchy (common, stage and region). you can now easily set a variable within the specified scope. </desc> <cmt> issue #998 - variables list shows stage variables </cmt> <cmt> issue #998 - variables set command supports common, stage and region variables now. </cmt> <cmt> removed support for ""all"" regions as it is not needed anymore due to the added hierarchy support. </cmt> <cmt> issue #998 variables unset supports common, stage and region variables. </cmt>",998 variables support stage vars
2796,"<desc> closes #17253 n/a - internal work for multi-domain removes hard-coded domain in multi-domain implementation, so any secondary domain can be visited. n/a has the original issue (or this pr, if no issue exists) been tagged with a release in zenhub? (user-facing changes only) n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? </desc> <cmt> chore: fix rerunning multidomain tests </cmt> <cmt> remove need for anticipatemultidomain </cmt> <cmt> remove anticipatemultidomain from rerun spec </cmt> <cmt> use the domain </cmt> <cmt> use this.debug </cmt> <cmt> create new signal for multidomain that doesn't abuse stability </cmt> <cmt> fix types and tests </cmt> <cmt> fix typo from merge conflict </cmt> <cmt> chore: remove hard-coded domain for multi-domain </cmt>",remove hardcoded domain for multi-domain
2797,"<desc> the interface affects dog/cifar competition chapters. the change also affects utils.py, since the new transform function leaves label as an ndarray object, instead of a scalar. please run ci to make sure this is not breaking anything else. </desc> <cmt> add librsvg2-bin in readme </cmt> <cmt> improve kaggle dog tutorial </cmt> <cmt> fix </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> improve </cmt> <cmt> improve </cmt> <cmt> improve </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> update data aug </cmt> <cmt> add fix to utils for new transform </cmt> <cmt> fix </cmt>",switch to new transform function
2798,<desc> for #6478 . add test case for sqlserver output clause without output table column. add test case for sqlserver output clause without output table. add test case for sqlserver output clause column shorthand. </desc> <cmt> fixes collection empty condition. </cmt> <cmt> add test case for sqlserver output clause without output table column. </cmt> <cmt> add test case for sqlserver output clause without output table. </cmt> <cmt> add test case for sqlserver output clause column shorthand. </cmt>,add sqlserver output clause test case.
2799,"<desc> i am just doing some incremental work towards formalizing store_borrow into an interior pointer and cleaning up a few other things in the process. more specifically: i eliminated some dead code in borrowedvalue's interior pointer finding code. we were always handling open_existential_box, store_borrow earlier since they are interior pointer operands. i changed ome to while lowering rauw store_borrow's result with its dst and added a test. i added interior pointer error tests for store_borrow, open_existential_box, and an interior pointer that is stored into by a store_borrow (we want to in that case treat the store_borrow result's uses as uses of the interior pointer). </desc> <cmt> [ownership] delete dead code that explicitly handles interior pointers open_existental_box, store_borrow. </cmt> <cmt> these both are already classified as interior pointers. thus, we would have </cmt> <cmt> already handled them at the top of the loop where we handle interior pointer </cmt> <cmt> operands. </cmt> <cmt> [ownership] when lowering store_borrow, rauw its result with its input dest. </cmt> <cmt> a store_borrow is a manner to temporarily ""borrow"" a guaranteed value into </cmt> <cmt> memory for purposes like reabstraction. to make this safer in ossa, we treat a </cmt> <cmt> store_borrow's result as an interior pointer into the stored guaranteed value, </cmt> <cmt> causing all uses of that result to be validated as being within the lifetime of </cmt> <cmt> the guaranteed value. </cmt> <cmt> note: this is not the complete store_borrow verification story. we also will </cmt> <cmt> verify that the memory that is being store_borrowed into is not written to while </cmt> <cmt> the store_borrow's result is live. </cmt> <cmt> [ownership] add an interior_pointer error test for store_borrow. </cmt> <cmt> just didn't see one. now we have added to our proof collection a </cmt> <cmt> test case where the store_borrow's result has a use after the end of the source </cmt> <cmt> object's lifetime. </cmt> <cmt> [ownership] when looking at an interior pointer's uses, look through store_borrow. </cmt> <cmt> the store_borrow's result is a sub-interior pointer that ensures that any uses </cmt> <cmt> of the interior pointer are within the lifetime of the borrowed value that is </cmt> <cmt> being stored. but fundamentally this is just embedding lifetime ownership on </cmt> <cmt> def-use edges and once ossa is lowered the result is just the destination </cmt> <cmt> address. so it makes sense to include the uses of the result of the store_borrow </cmt> <cmt> as the dest's uses. </cmt> <cmt> [ownership] add an interior_pointer error test for open_existential_box. </cmt> <cmt> i didn't find one in the file, so i added it. </cmt>",small code improvements around interior pointers
2800,"<desc> apparently that's allowed and the rfc is just unclear about it. some servers seem to zero-pad the chunk size for whatever reason, and previously, we interpreted that as the last chunk. this still does not fix loading github, as the css parser chokes on one of the stylesheets. this sort of infinite loop seems to stem from us handing it something that has invalid data in it, so i am still quite suspicious of transfer-encoding's. </desc> <cmt> libtls: do not call on_tls_finished until the client has read app data </cmt> <cmt> libhttp: handle chunk sizes that start with zeros correctly </cmt> <cmt> apparently that's allowed and the rfc is just unclear about it. </cmt> <cmt> some servers seem to zero-pad the chunk size for whatever reason, and </cmt> <cmt> previously, we interpreted that as the last chunk. </cmt>",handle silly chunked-encoding chunk sizes
2801,"<desc> this pr addresses a few issues with this system test flakiness. this pr is a cherry-picked duplicate of #6041 but for the 2.1 branch, hence i won't repeat the inline comments here. need to grab the monitor before a given operation to observe logs for signal relied too much on a timely rebalance and only sent a handful of messages. i've updated the test and ran it here </desc> <cmt> minor: fixes for making test more stable </cmt> <cmt> minor: cherry pick commits to 2.1 </cmt> <cmt> minor: move restart of kafka node inside grabbing the monitor </cmt> <cmt> minor: more clean up and close up other timing error gaps </cmt> <cmt> minor: clean up messages </cmt>",fixes for broker down test stability 2.1
2802,"<desc> a reopening of #16178. quote from there: theme packages should now be publishable (is that even a word) by lerna note that it wipes out changes from this recent commit: 4793654 (not sure if it makes sense now, needs advice). </desc> <cmt> move theme starters into starters </cmt> <cmt> move themes into packages </cmt> <cmt> remove themes directory </cmt> <cmt> cleaned up the renovate config </cmt> <cmt> cleaned up the lerna config </cmt> <cmt> cleaned up the ci config </cmt> <cmt> exclude theme starters from markdown-magic </cmt> <cmt> cleaned up themes package.json </cmt>",move themes into starters and packages
2803,"<desc> added description of the change added file name matches file name guidelines added tests and example, the test must pass added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines notes: i'll try to fix the merge conflicts in this pr. the reason for this is because i previously worked on this, but i didn't submit the pr the same day i started working on it the merge conflicts are resolved now. </desc> <cmt> [feat/fix/docs]: improvements in the... </cmt> <cmt> ...backtracking folder, and minor fixes in the others/iterative_tree_traversals.cpp and the math/check_prime.cpp files. </cmt> <cmt> clang-format and clang-tidy fixes for 9cc3951d </cmt>",improvements in the backtracking folder
2804,"<desc> now builds static instances correctly. closes #369 as far as i can tell, what essentially happened here is that instances in the designspace were not being renamed, even though the sources were being renamed. as a result, the variable fonts would build correctly, but the static instances were not. the font naming approach has now been changed and is producing reliable results. what's particularly vexing is that for the life of me i can't figure out how the code actually worked before, because as far as i can tell, we've never modified the instance code before. checked tables in ot master </desc> <cmt> update build.py </cmt> <cmt> fixing so static instances build properly. </cmt> <cmt> update build.py </cmt> <cmt> previous commit wasn't quite working. took a different approach. </cmt> <iss> according to fontconfig, familyname no longer contains style name :( </iss>",set the names of the static instances properly
2805,<desc> this pr allows disabling individual rgb matrix effects in userspace. an effect can be disabled by defining disable_[effect_name] in config.h: // to disable alphas mods #define disable_rgb_matrix_alphas_mods </desc> <cmt> allows disabling animations in user space </cmt> <cmt> describe disabling effects in the docs </cmt>,allows disabling rgb effects in userspace
2806,"<desc> to constantly respond to container failures, i add a health check to all integrations. thanks to this, docker is able to detect the problem earlier and restart the container if necessary. information about the state of the containers is also available in docker ps command. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> add health check to integrations </cmt> <cmt> fixup! add health check to integrations </cmt> <cmt> fixup! fixup! add health check to integrations </cmt>",add docker health check to integrations
2807,"<desc> move user-agent: to the new metadata traits system (and away from the old callouts system). this required dealing with slices as data in the new metadata system, which more importantly meant figuring out how to deal with values with ownership semantics (as opposed to the simple integer like values we've been shuffling so far). this also meant needing to fix up a few more places where older api's were utilized. in order to deal with the ownership semantics, i needed a slice type that could express them, so this change also introduces grpc_core::slice and some other associated types. for now it exports some c++-ish accessors, some named constructors, and some unnamed conversion constructors. there's a nice story with this type around mutability, and a better story than we have currently about accelerating operations on some slice types. strategically for slices the objective will be to plug this type family throughout grpc_core, and concurrently remove the managedmemoryslice, unmanagedmemoryslice and other friends that derive from grpc_slice, as this pattern seems remarkably hard to understand and use safely. @drfloob </desc> <cmt> new slice api </cmt> <cmt> storage-classes </cmt>","user-agent metadata trait, also: grpc_core::slice is born"
2808,"<desc> clean up the styles in <indexroute/> component create a separate component for getting started section move the <diagram/> styles to the <diagram/> component replace css to sx setupscrollersobserver & unobservescrollers using useeffect() hook convert indexroute to function component how to test go to the following link mentioned below and scroll down a little bit, the component should work same in both the local and production link, just the implementation of component is now different. local url:  production url: </desc> <cmt> move <diagram/> styles inside <diagram/> component </cmt> <cmt> convert indexroute to function component </cmt> <cmt> add homepagegetstarted component </cmt> <cmt> moved the wrapper styles to object </cmt> <cmt> semantics :3 </cmt>","refactor, tidy and convert gatsby homepage to function component"
2809,"<desc> what types of changes does your pr introduce? put an x in all boxes that apply added dropbox to the list because i used it for some years for screenshotting, it worked great and it wasn't already added in here. </desc> <cmt> update readme.md </cmt> <cmt> i used dropbox for screenshots until 2 years ago and it works very good </cmt> <cmt> update readme.md </cmt>",added dropbox to the list of screenshot softwares
2810,"<desc> this pr contains two changes to swiftlang, the swift layer exposing sourcekit in swift: make each variant keep a strong reference to its sourcekitdresponse context. this is needed because sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was retrieved from (wrapped by sourcekitdresponse) is still alive. expose the new data variant sourcekit apis that were added to support returning the syntax tree in a binary format in swiftlang. </desc> <cmt> [sourcekit] make each variant keep a strong reference to its sourcekitdresponse context </cmt> <cmt> sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was </cmt> <cmt> retrieved from is still alive, so keep a strong reference to sourcekitdresponse </cmt> <cmt> (the swift wrapper of sourcekitd_response_t) in each variant (the swift wrapper </cmt> <cmt> of sourcekitd_variant_t). </cmt> <cmt> [sourcekit] expose the data variant sourcekitd apis in the swiftlang wrapper </cmt> <cmt> these were recently added to support returning the syntaxtree in the bytetree </cmt> <cmt> from sourcekit but were never added in swiftlang (the swift layer wrapping </cmt> <cmt> sourcekit). </cmt>",keep sourcekitd response alive for variant lifetime
2811,"<desc> emit a compile time provided send_string() macro on a new keycode, and assign it to _fl define a new keycode (pstoken) and assign it to a key in the _fl layer. assign reset to _fl at the same time. the associated send_string() macro emits a compile time defined string that we populate in rules.mk. this only works on macos, since it shells out to the macos security utility, which securely fetches a string from the specified service name and account. that avoids storing the string in the source code or in the clear anywhere on the filesystem. it also avoids changing any of qmk's makefiles, keeping the change local to my keymap. since the keymap is macos-specific due to left of spacebar key swaps, i figure the makefile changes being a bit macos specific is ok. i plan to document the change, including how to interact with the security utility on macos, on my blog. i would wrap the rules.mk changes in macos-specific ifdefs, but i don't think the qmk makefile system defines any i can easily check against. i also updated the layout readme with the correct make invocation, and the layout comments in keymap.c while i was at it, to tidy up a bit. none. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> update make command with correct variant </cmt> <cmt> add a custom keycode for a compile-time defined macro and add to _fl </cmt>",add a compile-time provided macro and assign to _fl
2812,"<desc> this contains some small changes that resolve some of the pr06 errors from running ./scripts/validate_docstrings.py --errors=pr06 xref #28724 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> fix pr06 docstring errors in interval.py </cmt> <cmt> fix pr06 docstring errors in spss.py </cmt> <cmt> fix pr06 docstring errors in pytables.py </cmt> <cmt> fix pr06 docstring errors in sql.py </cmt> <cmt> fix pr06 docstring errors in multi.py </cmt> <cmt> fix pr06 docstring errors in groupby.py </cmt>",docstring fixes for pr06 errors
2813,"<desc> in those cases when kubernetes and netdata are manually installed on bare metal, thecgroup-name.sh script cannot get the names of the containers due to empty variables: $kubernetes_service_host $kubernetes_port_443_tcp_port also missing file /var/run/secrets/kubernetes.io/serviceaccount/token my edits add an alternative opportunity to get the name of the container if no variables are set and kubelet is running on the system and kubectl binary is available. by default, /etc/kubernetes/admin.conf is used to access kubectl, if an error occurs during execution, an entry will be added to the log with the warning level, but if you specify the path in the variable $kube_config, then it will be used your custom config. for example, you can use systemd daemon: environment=kube_config=/etc/netdata/kubernetes.conf component name collectors/cgroups.plugin/cgroup-name.sh.in </desc> <cmt> ability to get pod name with kubectl in cgroup </cmt> <cmt> added $kube_config variable </cmt>",added ability to get pod name from cgroup with kubectl in bare metal deployment
2814,<desc> completes @thomaswangio 's set up a netlify cms-managed gatsby site in 5 steps article with the missing netlify auth provider setup. </desc> <cmt> docs: upload screenshot for oauth installation </cmt> <cmt> docs: add auth provider setup section </cmt>,complete blog tutorial with netlify auth setup
2815,"<desc> closes #16979 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> add temp tests to explore different combinations </cmt> <cmt> put tests at the end </cmt> <iss> bug: dataframe.where with category dtype </iss>",add test for df.where() with int dtype
2816,"<desc> in scenarios where the cluster-store configuration is invalid or the store is down during daemon bootup, the get apis in libnetwork were aggressively failing resulting in failing even the local networks and endpoints. there is no reason to be aggressive when the cluster-store is unreachable especially on the get all apis. hence it also helps in solving a bunch of inconsistency issues for the docker0 bridge as well as tracked in moby/libnetwork#651 also solves a part of #17007 . </desc> <cmt> vendoring in libnetwork to fix daemon bootup instabilities </cmt> <cmt> integration test for default bridge init with invalid cluster config </cmt>",fixing bootup inconsistencies due to invalid cluster-store config
2817,"<desc> created a custom keymap for gmmk pro that includes a working volume knob. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> initial commit </cmt> <cmt> add jackkenney keymap </cmt> <cmt> shift around pgup and del </cmt>",jackkenney's keymap for gmmk pro
2818,"<desc> hey there! the contribution guidelines say to ask before submitting a pr, but it doesn't say how to ask. i don't have a lot of experience contributing to oss, so please let me know if i missed something. this pr allows for cra to control tabs on other chromium-based browsers besides google chrome. how the code works: checks if applescript is applicable. logic isn't changed, but i renamed the variable to shouldtryopenchromiumwithapplescript. runs through a list of supported browsers: chrome canary (has to come before chrome because of grep) chrome edge brave vivaldi chromium for each browser, it greps to see if that browser is a process if it finds a match, it passes the browser name to the applescript applescript uses the google chrome dictionary to control the provided browser other than that, the logic is essentially the same. most people shouldn't see a difference in behavior except for those using a browser in the list above that's not chrome; for those people, cra will reuse the existing tab rather than a new tab. i noticed that safari has its own dictionary for applescripts. if it benefits anyone, i could look into implementing similar logic for safari users. unfortunately for firefox users like myself, there seems to be no hope. apologies if i left something out, but i tried my best. let me know what needs to be changed, would be proud to have my code in cra. closes #8264 </desc> <cmt> expands scope of openbrowser tab control </cmt> <cmt> adjust openchrome.applescript to allow manipulation of </cmt> <cmt> other chromium-based browsers (defaulting to chrome). </cmt> <cmt> requires list of compatible browsers to try in openbrowser.js </cmt> <cmt> fix typo </cmt> <cmt> remove safari </cmt> <iss> support for vivaldi & brave browsers for ""openchrome.applescript"" </iss>",wider chromium support for openbrowser
2819,"<desc> i'm open to better names for the new module. with these all in the same place, we can separate out helper functions and de-duplicate a whole bunch of verbose code. </desc> <cmt> ref: collect get_dst_info methods in tslibs.vectorized </cmt>",collect get_dst_info-using functions in tslibs.vectorized
2820,<desc> we'd like to see how many of these flakes are transient and how many involve the device/machine getting temporarily wedged. add a retry with no delay to see if it is possible to add sufficient error handling to startapp/installapp to handle this. </desc> <cmt> [flutter_tools] try to retry app startup to see if reduces flakes </cmt>,retry the driver launch of the application up to 3 times.
2821,<desc> backport of #11431 to 0.19.x that removes the deprecation warning about abc being moved from collections to collections.abc when importing scikit-learn in python 3.7. do not merge while the parent pr is not merged. done as part of #11422 </desc> <cmt> fix collections.abc deprecations with python 3.7 </cmt> <cmt> pep8 </cmt>,fix collections.abc deprecations with python 3.7 (0.19.x backport)
2822,"<desc> previously, the platform_info table on windows did not include the releasedate field. this fix fills in the date column with an iso8601 version of the releasedate. closes #4771 </desc> <cmt> adding getdatetime function to convert a bstr wmi date to filetime </cmt> <cmt> populating date field in platform_info; added function to convert filetime to iso8601 date fmt </cmt> <cmt> formatting changes </cmt>",add releasedate to table for platform_info queries on windows
2823,<desc> this should drastically speed up the test and allow us to collect coverage data. locally this takes about 6 seconds from source. the usage section of the flutter create test takes about 14 seconds at head </desc> <cmt> move usage tests to memory filesystem </cmt> <cmt> fix cirrus </cmt>,move usage flutter create tests into memory filesystem.
2824,<desc> fixes #2592 i choose this solution instead of changing require_admin_or_owner in objectpermissionslistresource since that would effect permissions for multiple operations. </desc> <cmt> pull upstream to my fork </cmt> <cmt> pulling from upstream to sv fork </cmt> <cmt> add error message when non owner tries to add a user to a dashboard </cmt> <cmt> fixes #2592 </cmt> <cmt> redash_feature_show_permissions_control has to equal true for this to be applicable. </cmt> <cmt> operation does throw a 403 forbidden error before this change but it is in the console not shown to the user. </cmt> <iss> a user that is granted permissions to a dashboard cannot grant permissions to others for the dashboard </iss>,throw error when non-owner tries to add a user to dashboard permissions
2825,"<desc> only complete options-name, other case use default complete. because options-value has different type, don't have a standard to complete. use case: </desc> <cmt> merge master </cmt> <cmt> support windows unicode file path. #571 </cmt> <cmt> polish ""support windows unicode file path"" #574 </cmt> <cmt> update doc </cmt> <cmt> add known user (#583) </cmt> <cmt> update contributing.md (#584) </cmt> <cmt> use docker build args </cmt> <cmt> fix typo (#582) </cmt> <cmt> update readme.md </cmt> <cmt> editing pass of document: rewords some sentences for clarity, makes formatting consistent in lists, and corrects some grammar and spelling. </cmt> <cmt> update doc. close #587 </cmt> <cmt> support inject into java process of windows service (#581) </cmt> <cmt> * add as-service.bat to support inject into java process of windows service </cmt> <cmt> * as.bat support telnet/http port args </cmt> <cmt> avoid blocking while start arthas service (#591) </cmt> <cmt> add known user. </cmt> <cmt> packaging as-service.bat (#595) </cmt> <cmt> fix typo (#604) (#606) </cmt> <cmt> fix completionadaptor index out of bounds when the token is empty. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> options command support complete </cmt>",options command support complete options-name
2826,"<desc> this gets rid of lots of unnecessary unsafety. all the atomicu32s were wrapped in unsafecell or unsafecell, and raw pointers were used to get to the atomicu32 inside. this change cleans that up by using atomicu32 directly. also replaces a unsafecell by a safer cell. @rustbot modify labels: +c-cleanup </desc> <cmt> use slice_as_mut_ptr instead of first_ptr_mut. </cmt> <cmt> this function was renamed. </cmt> <cmt> get rid of unsafecell<maybeuninit>s in cloudabi mutex. </cmt> <cmt> get rid of unsafecell in cloudabi rwlock. </cmt> <cmt> get rid of raw pointers and unsafecell in cloudabi condvar. </cmt> <cmt> formatting. </cmt>",cleanup cloudabi mutexes and condvars
2827,"<desc> added a command to manually add a repository given a path to that repository. addresses the request in #46763 to add the ability to manually add repos. this can be done both through the command palette or a button from the git sidebar, as seen below. </desc> <cmt> feature: add support to manually add repositories </cmt>",add option to manually add repos #46763
2828,"<desc> add the labex digicosme logo to the funders list in about.rst @gaelvaroquaux i miss some informations like the period when tom and mathurin have been funded. other than that, is there something else to add ? </desc> <cmt> first modif </cmt> <cmt> add digicosme </cmt>",add a digicosme entry in about us
2829,"<desc> test infrastructure this pr is only tests if relevant, link to documentation update: n/a summary adding some foundational bincases suite for testing bin commands. they will call child_process.exec(), and handler will verify if successfully ran. i am just laying the foundation for the tests. helps make it possible to better cover changes in #3524. from forked branch pr #3643 no other information from forked branch pr #3643 </desc> <cmt> feat(test): add very simple bincases test infra to build off of </cmt> <cmt> reworked the bincases infra. now arguments.json can hold commands </cmt>",add very simple bincases test infra to build off of [fork]
2830,<desc> others others cherry-pick #29885   #30259 </desc> <cmt> reduce the  occupied size  of memory for the fused pattern of elementwise_add op and activation op(relu op for example) (#29885) </cmt> <cmt> register opmaker and infer shape check for fused_elementwise_add (#30259) </cmt>,[cherry-pick]memory optimization for fuse pattern of elemwise_add + act
2831,"<desc> this pr addresses #588, allowing you to do make warn to see all the compiler warnings printed during compilation of c files (really anything that your compiler sent to stderr, which with gcc is nothing unless you have compiler warnings or errors).  it's implemented by sending all stderr output to another file ending with warnings.txt (still printing these warnings immediately after compilation even if you never run make warn) and then concatenating all these warning files into a single summary file afterwards.  if your code successfully compiles without any warnings (i.e. the warning summary file is empty) you should see make happily print make: nothing to be done 'warn' when make warn is run again; otherwise the warnings will be printed every time make warn is run (but without recompiling). in the second commit, i made lint behave in a similar way, producing a per-file lint report and then concatenating the outputs into a summary lint report.  this way lint runs very fast if you run ""make lint"", change just one source file, and then run ""make lint"" again -- this is because it's only invoked for the changed file rather than again for the entire codebase. </desc> <cmt> dump compiler warnings to *.warnings.txt; use ""make warn"" to print them </cmt> <cmt> output a lint report for every source file linted; use to lint </cmt> <cmt> incrementally </cmt>","""make warn"" to print compilation warnings; ""make lint"" runs incrementally"
2832,<desc> this pr provides the marlin support for the (hopefully) upcoming usb composite feature (sd card and cdc usb) in the st stm32 library. the stm32 library changes are in pr 586. the changes needed to support the new feature are: add flags to the platformio.ini environments to enable the usb composite feature add a section to sd2card_sdio_stm32duino.cpp so that when the usb composite feature is enabled that the marlin access of the sd card uses the usb drivers. this has been tested on a steval board and a black stm32f407 board. it has been tested on 16g sd cards. my 4g sd card does not work with the sdio interface.  i need to look into that. </desc> <cmt> add support for composite usb </cmt> <cmt> if composite usb is enabled  then use the composite usb drivers for the onboard sd card. </cmt> <cmt> this is in preparation for usb composite changes to st's stm32 library. </cmt> <cmt> tested on steval board. </cmt> <cmt> platformio.ini changes to support  black stm32f407 </cmt>,add support for composite usb on stm32 sdio boards (experimental)
2833,"<desc> ""bech32"" isn't very user-friendly; used ""native segwit"" as in #11937. you don't spend from addresses. no reason to block off bech32 access with legacy address default. rebased from #12208 </desc> <cmt> gui: rephrase bech32 checkbox text/tooltip </cmt> <cmt> - ""bech32"" isn't very user-friendly </cmt> <cmt> - you don't spend from addresses </cmt> <cmt> gui: allow generating bech32 addresses with a legacy-address default </cmt>","rephrase bech32 checkbox texts, and enable it with legacy address default"
2834,"<desc> upon further coding proceeds, found another unsquashed macos unavailable nproc. decreases travis build time too! fix last pr that uses the wrong command of phy cores instead of logical cores. </desc> <cmt> nproc for ubuntu, hw.logicalcpu for mac </cmt> <cmt> physicalcpu to logicalcpu </cmt> <cmt> non-efficient j1 to hw.logicalcpu </cmt>",changes nproc for mac to hw.logicalcpu where applicable
2835,<desc> description: an exception is thrown to the user if a custom resolver name is specified when using strict or logical dns in the address section of the endpoints. risk level: low testing: //test/... docs changes: this is a behavior change in an error condition. would documenting this change in the proto file be sufficient? release notes: n/a fixes #3553 </desc> <cmt> merge latest master from envoy </cmt> <cmt> merge envoy master </cmt> <cmt> throw exception if custom resolver is specified with strict_dns or logical_dns </cmt> <iss> prevent the use of custom resolvers for dns discovery types </iss>,disallow specifying custom resolver name for strict and logical dns
2836,"<desc> also changes the signature of advance_slice to accept a &mut &mut [ioslice], not returning anything. this will better match the ioslice::advance function. updates #62726. </desc> <cmt> rename ioslice(mut)::advance to advance_slice </cmt> <cmt> to make way for a new ioslice(mut)::advance function that advances a </cmt> <cmt> single slice. </cmt> <cmt> also changes the signature to accept a &mut &mut [ioslice], not </cmt> <cmt> returning anything. this will better match the future ioslice::advance </cmt> <cmt> function. </cmt> <cmt> add ioslice(mut)::advance </cmt> <cmt> advance the internal cursor of a single slice. </cmt>",rename ioslice(mut)::advance to advance_slice and add ioslice(mut)::advance
2837,"<desc> previously, only theme colors could be modified using the themeeditor. now, metric and path properties can also be modified, and the preview shows these changes. :^) preview: inactive window gets a background color instead of being hollow windows get a shadow if they have one specified in the theme window button icons also reflect the theme setting now editing: metrics can be adjusted paths can be modified, with a file picker or manual text editing loading a theme file now updates the ui to show the current values immediately, instead of only when the comboboxes are interacted with i'll have to come back to this later to add support for flagroles which i added in #10609. </desc> <cmt> themeeditor: give both preview windows a background color </cmt> <cmt> the inactive window previously didn't have a background fill, so it </cmt> <cmt> looked odd. </cmt> <cmt> libgfx: make style painters use east const and virtual specifiers </cmt> <cmt> libgfx+windowserver: move shadow-painting code to stylepainter </cmt> <cmt> specifically, this is to make it accessible to themeeditor, but there's </cmt> <cmt> nothing about it that is especially window-specific. </cmt> <cmt> themeeditor: display window shadows in preview :^) </cmt> <cmt> themeeditor: convert layout to gml </cmt> <cmt> libgfx: add to_string() functions for metricrole and pathrole </cmt> <cmt> libgui: add metricrole and pathrole to gui::variant </cmt> <cmt> this is needed for making them editable in the themeeditor, like </cmt> <cmt> colorrole is. </cmt> <cmt> themeeditor: add metricrole editing </cmt> <cmt> the editing ui at the bottom is now split into two groups, one for </cmt> <cmt> colors and one for metrics. </cmt> <cmt> themeeditor: update value edit boxes when loading a theme file </cmt> <cmt> previously, these would continue to show the previously entered values, </cmt> <cmt> until you interacted with the comboboxes. </cmt> <cmt> themeeditor: add pathrole editing </cmt> <cmt> this allows both typing the path, and selecting it with a file-open </cmt> <cmt> dialog. </cmt> <cmt> themeeditor: display the theme's window icons in the preview </cmt> <cmt> if the icons could not be loaded, we fall back to the defaults (which </cmt> <cmt> are the bitmaps that were always used before.) </cmt>","make preview more accurate, and allow editing all properties"
2838,<desc> closes #8439 before after </desc> <cmt> fix setting language previously selected </cmt> <cmt> isolate i18n startup </cmt> <cmt> isolate i18n client startup </cmt> <cmt> wait tapi18n language load when changed in admin settings </cmt> <cmt> fix indentation </cmt> <cmt> change behavior of suggested server language on footer of login page </cmt>,loading and setting fixes for i18n and rtl
2839,"<desc> fixes #4401 fixes #4293 now next.js 6 is on babel 7, remove conflicting babel deps update next server/cloud function .babelrc config update other deps: cloud functions to 1.x.x etc rm install-deps script as it is no longer used on deployment (firebase does not upload node_modules) make scripts consistent in their wrapping of dirs with "" (escaped double quotes) improve readme to clarify config customization and _app.js as per #4401 </desc> <cmt> with-firebase-hosting: update next.js 6, readme about customization </cmt> <cmt> * now next.js 6 is on babel 7, remove conflicting babel deps </cmt> <cmt> * update next server/cloud function .babelrc config </cmt> <cmt> * update other deps: cloud functions to 1.x.x etc </cmt> <cmt> * rm install-deps script as it is no longer used on deployment (firebase does not upload node_modules) </cmt> <cmt> * make scripts consistent in their wrapping of dirs with \"" (escaped double quotes) </cmt> <cmt> with-firebase-hosting: pin next to ""latest"" version </cmt> <iss> with-firebase-hosting example is not working with next 6 </iss> <iss> adding _app.js to 'with-firebase-hosting' causes ""cannot find module '@babel/runtime/regenerator'"" </iss>",update to work with next v6
2840,"<desc> related to (and dependent on) elastic/docs#657 this pr increases the use of attributes for ccr references in the documentation.  it also adds a glossary entry for cross cluster replication, follower indices, and leader indices. </desc> <cmt> [docs] updates ccr hyphenation </cmt> <cmt> [docs] adds ccr-cap attribute </cmt>",replaces ccr terms with attributes
2841,"<desc> also don't attempt to predicate instructions that don't have a predicate field. this is used by smo, splatoon 2, and some other games. </desc> <cmt> gpu/shaders: implemented ssy and sync as a way to modify control flow during shader execution. </cmt> <cmt> ssy sets the target label to jump to when the sync instruction is executed. </cmt> <cmt> gpu/shader: don't predicate instructions that don't have a predicate field (ssy). </cmt>",implemented ssy and sync as a set_target/jump pair.
2842,<desc> changed incorrect home page url for allenai from appenai.org to allenai.org typo fix for website i have submitted the spacy contributor agreement. </desc> <cmt> typo fix for allenai url </cmt> <cmt> changed incorrect home page url for allenai from appenai.org to allenai.org </cmt> <cmt> sign contributor agreement </cmt> <cmt> change date format </cmt>,correct typo for allenai url on homepage
2843,"<desc> this fixes two bugs: the prune setting range was set after loading the current value. if users had a prune of (eg) 200, it would get limited to 99 before the range was raised. this is fixed by setting the range first. the prune setting was limited to <= the chainparams' ""assumed blockchain size"". there's no reason for this limit (the ux is the same either way), and there are use cases it breaks (eg, setting a prune size such that it begins pruning at some future point). therefore, i raised it to the max value. this is a daggy fix, so should cleanly merge to both master and 0.18 branches. </desc> <cmt> gui: options: set the range of pruning size before loading its value </cmt> <cmt> without this, an out-of-default-range value gets limited to the range </cmt> <cmt> gui: options: remove the upper-bound limit from pruning size setting </cmt> <cmt> hypothetically, someone may wish to begin pruning at a future blockchain size, and there's no reason to limit it lower </cmt>","gui: options: initialise prune setting range before loading current value, and remove upper bound limit"
2844,"<desc> add scorer option to components add registered scorers for all components add scorers registry move all scoring methods outside of components as independent functions and register use the registered scoring methods as defaults in configs and inits additional: the scoring methods no longer have access to the full component, so use settings from cfg as default scorer options to handle settings such as labels, threshold, and positive_label the attribute_ruler scoring method no longer has access to the patterns, so all scoring methods are called bug fix: spancat scoring method is updated to set allow_overlap to score overlapping spans correctly enhancement i have submitted the spacy contributor agreement. </desc> <cmt> add scorer option to components </cmt> <cmt> add an optional scorer parameter to all pipeline components. if a </cmt> <cmt> scoring function is provided, it overrides the default scoring method </cmt> <cmt> for that component. </cmt> <cmt> add registered scorers for all components </cmt> <cmt> * add scorers registry </cmt> <cmt> * move all scoring methods outside of components as independent </cmt> <cmt> functions and register </cmt> <cmt> * use the registered scoring methods as defaults in configs and inits </cmt> <cmt> additional: </cmt> <cmt> * the scoring methods no longer have access to the full component, so </cmt> <cmt> use settings from cfg as default scorer options to handle settings </cmt> <cmt> such as labels, threshold, and positive_label </cmt> <cmt> * the attribute_ruler scoring method no longer has access to the </cmt> <cmt> patterns, so all scoring methods are called </cmt> <cmt> * bug fix: spancat scoring method is updated to set allow_overlap to </cmt> <cmt> score overlapping spans correctly </cmt>",refactor scoring methods to use registered functions
2845,"<desc> this pr mutes multiple tests on windows. it does this aggressively to be able to have these passing and make sure we don't cause further breakage on windows. these were found on a local ci setup running with ./gradlew.bat --continue </desc> <cmt> mute failing test </cmt> <cmt> tracked in #44552 </cmt> <cmt> mute evilsecuritytests </cmt> <cmt> tracking in #44558 </cmt> <cmt> fix line endings in esjsonlayouttests </cmt> <cmt> mute failing forecastit  test on windows </cmt> <cmt> tracking in #44609 </cmt> <cmt> mute autofollowit.testconflictingpatterns </cmt> <cmt> tracking in #44610 </cmt> <cmt> mute basicrenormalizationit.testdefaultrenormalization </cmt> <cmt> tracked in #44613 </cmt> <cmt> revert ""mute autofollowit.testconflictingpatterns"" </cmt> <cmt> this reverts commit 012de08f59a26c2216297ffea1589c55d5b6ddc9. </cmt> <cmt> mute x-pack internal cluster test windows </cmt> <cmt> tracking #44610 </cmt> <cmt> mute failure unconfigured node name </cmt> <cmt> fix mute testdefaultrenormalization </cmt> <cmt> increase busywait timeout windows is slow </cmt> <cmt> mute jvmergonomicstests on windows </cmt> <cmt> tracking #44669 </cmt> <cmt> mute sharedclustersnapshotrestoreit testparallelrestoreoperationsfromsinglesnapshot </cmt> <cmt> tracking #44671 </cmt> <cmt> mute nodetests on windows </cmt> <cmt> tracking #44256 </cmt>",mute multiple tests on windows (master)
2846,"<desc> as discussed here. share the ""added"" and ""removed"" events across dispatches in object3d to cut down on allocation when adding and removing objects a lot. the pattern works in this case because no fields are changed on the object between dispatches -- i wonder if there's a way to extend this to cases where event data must change? </desc> <cmt> share event objects </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/core/object3d.js </cmt>","reuse ""added"" and ""removed"" event"
2847,"<desc> enable extra keys to support media keys that are placed on default keymaps. mentioned on boardsource discord. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> extra keys for technik ortho </cmt> <cmt> extra keys for technik staggered </cmt>",enable extra keys for technik ortho and stagger
2848,"<desc> control module updates in a very high rate. a formula is calculated in every frame, whose variables are never changed. so, use a variable to store the result of this formula. after testing on tx2, this could reduce the cpu usage of control by 3%-5%. </desc> <cmt> use a varialbe to store the result of formula to avoid calculating repeatedly </cmt> <cmt> fix code style issues </cmt>",use a variable to store result of formula to avoid calculating repeatedly
2849,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration provide a url to documentation or source code which provides context for the suggested changes: < </desc> <cmt> add fetch to coins in coingecko-api types </cmt>",add coins fetch funcion types
2850,"<desc> follow-up to #38697. see available checks at  i also tried: modernize-deprecated-headers but it breaks the codebase, as we use some code like is_inf, and clang on my distro can't even find cstdint by default. modernize-raw-string-literal is nice, but it breaks our logic to extract strings with ttr(), so editor/translations/extract.py would have to be fixed (and the raw string would have to be re-escaped in python before outputting the pot file for gettext). there's a few more that we may want to evaluate: </desc> <cmt> modernize remaining uses of 0/null instead of nullptr (c++11) </cmt> <cmt> using clang-tidy's modernize-use-nullptr. </cmt> <cmt>  </cmt> <cmt> enforce use of bool literals instead of integers </cmt> <cmt> using clang-tidy's modernize-use-bool-literals. </cmt> <cmt>  </cmt>","apply some modernize-* checks from clang-tidy (nullptr, bool literals, void args)"
2851,"<desc> python sample for #16662 i agree to contribute to the project under opencv (bsd) license. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work force_builders_only=docs </desc> <cmt> add text recognition sample </cmt> <cmt> fix pylint warning </cmt>",add text python recognition sample
2852,"<desc> reverts #38424, and re-applies the non-double-bracket-changes-etcetera </desc> <cmt> revert ""bash scripts; use double brackets, fix bare variables, add quotes"" </cmt> <cmt> this reverts commit 297b30df5ff4deaaedb6ceb17d7bd2e306a580ab. </cmt> <cmt> shell scripts: fix bare variables </cmt> <cmt> this makes my ide a bit more silent :-) </cmt>",remove bashisms and fix bare variables
2853,"<desc> the pr removes the following languages from the docs - fr, de, ja, es, ru. the community has not been able to translate them enough. they are up to date, but in english, so not really helpful. they are also the ones with the less usage. i recommend review per commit. i've also added redirects for the languages that are removed, let me know if i should revert this change. todo: revert bdad428 </desc> <cmt> [docs] remove translation files for fr, de, ja, es, ru </cmt> <cmt> [docs] remove languages from constants </cmt> <cmt> [docs] add redirects for the removed languages </cmt>","remove languages: fr, de, ja, es, ru"
2854,<desc> follow up to #17538 fixes all lint errors in js/shaders. i'll run --fix on the other files in the next pr. </desc> <cmt> fxaashader spaces to tabs </cmt> <cmt> indent updates </cmt> <cmt> volumeshader indents </cmt> <cmt> volumeshader single quotes to double quotes </cmt> <cmt> oceanshader single quotes to double quotes </cmt> <cmt> water refraction shader single quotes to double quotes </cmt> <cmt> single quotes to double quotes </cmt> <cmt> eslint --fix </cmt> <cmt> indents fix to halftoneshader </cmt> <cmt> jsm updaets </cmt>,lint example shaders pr 4
2855,<desc> it is used to generate a all-in-one report file after all the visual test run. usage: npm run test:visual:report it will generate a tmp-report.md file in the test/runtest folder. then you can translate this markdown file to any file you want. like pdf. q: why not integrating it in the dashboard? it has a lot of work(mostly ui) to be integrated. but the most wanted feature is to generate a file which can be shared and achieved for the regression testing before releasing. so i think a cli tool is good enough for this feature. maybe later i can add a button on the dashboard to download the generated markdown report file. </desc> <cmt> test: add report generation script for visual regression testing </cmt> <cmt> test(visual): optimize generated report </cmt>,add a cli script to generate visual test report markdown.
2856,<desc> kubectl currently ignores the local port when creating a port-forward to a service. this pr fixes this and adds unit tests for preventing this behaviour in the future. fixes kubernetes/kubectl#836 builds on #88950 with review comment #88950 (comment) addressed does this pr introduce a user-facing change?: fixes v1.18.0-rc.1 regression in kubectl port-forward when specifying a local and remote port /sig cli /milestone v1.18 /priority important-soon / </desc> <cmt> fix kubectl port-forward for services with explicit local port </cmt> <cmt> simplify dual or single port logic </cmt> <iss> kubectl port-forward for service with explicit local port broken in v1.18.0-beta.1 </iss>,fix kubectl explicit local port for service
2857,<desc> reference to stream changes of braintree search api: </desc> <cmt> [braintree] change search function to use streams </cmt> <cmt> prettier formatting </cmt> <cmt> [braintree] modify tests to reflect the new types </cmt> <cmt> update version in the comments </cmt>,fix search api to be a stream instead of a promise
2858,"<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> update of english version of descriprion of the table function file. </cmt> <cmt> new syntax for replacingmergetree. </cmt> <cmt> some improvements in text. </cmt> <cmt> significantly change article about summingmergetree. </cmt> <cmt> article is restructured, text is changed in many places of the document. new syntax for table creation is described. </cmt> <cmt> descriptions of aggregatefunction and aggregatingmergetree are updated. russian version. </cmt> <cmt> new syntax for new syntax of create table </cmt> <cmt> added english docs on aggregating, replacing and summingmergetree. </cmt> <cmt> collapsingmergetree docs. english version. </cmt> <cmt> 1. update of collapsingmergetree. 2. minor changes in markup </cmt>","updates for aggregating-,collapsing-, replacing- and summingmergetree."
2859,"<desc> related to #39517 this pr enables code snippet testing for the api key examples. it also clarifies that the role_descriptors array is required but can be empty. finally, it wraps some long lines and adds some minor edits. </desc> <cmt> [docs] adds testing to api key examples </cmt> <cmt> [docs] adds testing for api keys </cmt>",enable testing for api key examples
2860,"<desc> no functional changes. </desc> <cmt> shared/install: use _cleanup_free_ </cmt> <cmt> also rewrap some comments so that they don't have a very long line and a very </cmt> <cmt> short line. </cmt> <cmt> tree-wide: use mfree more </cmt> <cmt> tree-wide: introduce free_and_replace helper </cmt> <cmt> it's a common pattern, so add a helper for it. a macro is necessary </cmt> <cmt> because a function that takes a pointer to a pointer would be type specific, </cmt> <cmt> similarly to cleanup functions. seems better to use a macro. </cmt>",use mfree more and add another function to simplify a common set&free pattern
2861,"<desc> closes #24014 xref #10633 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry before this change, when the series.interpolate() method was called with invalid arguments,  exceptions with informative messages would be raised internally, but then caught and suppressed.  an exception with a potentially misleading message would be raised instead. for example, when interpolate is called with method='spline', an order argument must also be supplied.  this is checked internally, but when the order argument was missing, a confusing error would be raised: >>> import pandas as pd >>> s = pd.series([0, 1, pd.np.nan, 3, 4]) >>> s.interpolate(method='spline') traceback (most recent call last): ... valueerror: invalid method 'spline' to interpolate. this problem was reported as issues #10633 and #24014. after this change, a specific and correct exception (previously caught and discarded internally) is raised: >>> import pandas as pd >>> s = pd.series([0, 1, pd.np.nan, 3, 4]) >>> s.interpolate(method='spline') ... valueerror: you must specify the order of the spline or polynomial. in addition, light validation is now performed on the order parameter before it is passed to a scipy class.  previously, pandas would check if order was truthy in the python sense.  if order was non-zero and invalid, a scipy error would propagate to the user: >>> s.interpolate(method='spline', order=-1) traceback (most recent call last): ... dfitpack.error: (1<=k && k<=5) failed for 3rd argument k: fpcurf0:k=-1 after this change, a more understandable exception is raised in this case: >>> s.interpolate(method='spline', order=-1) traceback (most recent call last): ... valueerror: order needs to be specified and greater than 0 </desc> <cmt> bug: raise accurate exception from series.interpolate (#24014) </cmt> <cmt> actually validate order before use in spline </cmt> <iss> unnecessary bare except at class block, function interpolate hides actual error </iss>",fix exceptions when series.interpolate's order parameter is missing or invalid
2862,"<desc> this is what i managed to get done this morning. there's some very real issues fixed in this branch plus a bit of readability. unfortunately i haven't managed to figure out how to tell it to ignore memory leaks in case of oom so it's not the nicest thing to drudge through the issues to find the real ones. </desc> <cmt> merge: actually increment the counts, not the pointers </cmt> <cmt> merge_diff_list_count_candidates() takes pointers to the source and </cmt> <cmt> target counts, but when it comes time to increase them, we're increasing </cmt> <cmt> the pointer, rather than the value it's pointing to. </cmt> <cmt> dereference the value to increase. </cmt> <cmt> pack: use git_buf when building the index name </cmt> <cmt> the way we currently do it depends on the subtlety of strlen vs sizeof </cmt> <cmt> and the fact that .pack is one longer than .idx. let's use a git_buf so </cmt> <cmt> we can express the manipulation we want much more clearly. </cmt> <cmt> object: correct the expected id size in prefix lookup </cmt> <cmt> we take in a possibly partial id by taking a length and working off of </cmt> <cmt> that to figure out whether to just look up the object or ask the </cmt> <cmt> backends for a prefix lookup. </cmt> <cmt> unfortunately we've been checking the size against git_oid_hexsz which </cmt> <cmt> is the size of a *string* containing a full id, whereas we need to check </cmt> <cmt> against the size we can have when it's a 20-byte array. </cmt> <cmt> change the checks and comment to use git_oid_rawsz which is the </cmt> <cmt> correct size of a git_oid to have when full. </cmt> <cmt> filter: close the descriptor in case of error </cmt> <cmt> when we hit an error writing to the next stream from a file, we jump to </cmt> <cmt> 'done' which currently skips over closing the file descriptor. </cmt> <cmt> make sure to close the descriptor if it has been set to a valid value. </cmt>",a few more fixes from coverity
2863,"<desc> this is a hefty patch that takes some first steps towards solidifying our core comms mechanism. highlights include: introduce a @controller.handler decorator that automatically replys() to messages introduce a reply.take() method to take control of a message and prevent automatic reply. this makes the default use case the easy one, and lets us explicitly audit the codebase for places where extra care must be take to ensure that a message is eventually acked. handers are no longer named handle_message. the decorator makes clear what is a handler, so it's just ""message"" now. add an explicit list of permitted messages. this clarifies our mechanisms, and will be the start of better message documentation and more sophisticated handling mechanisms down the track. add a bunch of sanity checks for messages that are acked twice, or never, or are given invalid arguments. use this to catch numerous occurrences throughout the codebase. simplify the class hierarchy in controller by merging master and servermaster. </desc> <cmt> sketch out a more solid core </cmt> <cmt> - decorator for handler methods </cmt> <cmt> - stricter checking for double-acks and non-acks </cmt> <cmt> mandate that all handlers must be wrapped, make tests pass </cmt> <cmt> mitmproxy, mitmdump and mitmweb masters still to be done </cmt> <cmt> sketch out a more solid core </cmt> <cmt> - decorator for handler methods </cmt> <cmt> - stricter checking for double-acks and non-acks </cmt> <cmt> mandate that all handlers must be wrapped, make tests pass </cmt> <cmt> mitmproxy, mitmdump and mitmweb masters still to be done </cmt> <cmt> make @controller.handler inheritance-friendly </cmt> <cmt> use this to adapt mitmweb and mitproxy console </cmt> <cmt> zap stray debugging call </cmt> <cmt> be stricter about the handler call signature </cmt> <cmt> uses this to catch an error in mitmweb </cmt> <cmt> flatten servermaster into master </cmt> <cmt> explicitly list all events </cmt> <cmt> handle_* -> * </cmt> <cmt> now that we have the controller.handler decorator, the _handler prefix </cmt> <cmt> stutters. </cmt> <cmt> adapt examples </cmt>",first steps to solidifying the core
2864,"<desc> it updates vaultingkube version and add labels to metadata following other projects. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # i think test will fail, you can check the initial chart pr for more information. #3902 </desc> <cmt> add labels to metadata </cmt> <cmt> bump app and chart versions </cmt>",update vaultingkube version and add lables to metadata
2865,"<desc> fixes #17535 description of the change prior to this pull request, if a paneitem implemented the ondiddestroy function and the ondidterminatependingstate function, then the pane would make use of both functions. however, if paneitem implemented an ondidterminatependingstate function but did not implement an ondiddestroy function, the pane wrongly ignored the ondidterminatependingstate function. with the changes in this pull request, the ondidterminatependingstate function and ondiddestroy functions are treated independently: if the item only implements ondidterminatependingstate, that's fine: pane will use it if the item only implements ondiddestroy, that's fine, too: pane will use it if the item implements both functions, pane will use both functions if the item implements neither function, that's fine as well verification process verify correct behavior for paneitem that implements ondidterminatependingstate but not ondiddestroy (i.e., perform the ""steps to reproduce"" identified in #17535) implement a new paneitem with an opener. implement ondidterminatependingstate but not ondiddestroy code const {emitter} = require('atom') class somepaneitem { constructor () { this.emitter = new emitter() } getelement () { return document.createelement('div') } terminatependingstate () { this.emitter.emit('did-terminate-pending-state') } ondidterminatependingstate (callback) { return this.emitter.on('did-terminate-pending-state', callback) } gettitle () { return 'some-pane-item' } geturi () { return 'atom://some-pane-item' } } open it as a pending item with a call to atom.workspace.open(item, {pending: true}) double-click on the tab title verify that the item terminates its pending state and becomes a non-pending item verify correct behavior for paneitem that implements ondiddestroy but not ondidterminatependingstate implement a new paneitem with an opener. implement ondiddestroy but not ondidterminatependingstate code const {emitter} = require('atom') class somepaneitem { constructor () { this.emitter = new emitter() } getelement () { return document.createelement('div') } destroy () { this.emitter.emit('did-destroy') } ondiddestroy (callback) { return this.emitter.on('did-destroy', callback) } gettitle () { return 'some-pane-item' } geturi () { return 'atom://some-pane-item' } } call ondiddestroy to register a callback code item.ondiddestroy(() => console.log('destroyed')) open the item with a call to atom.workspace.open(item) destroy the item with a call to item.destroy() verify that the callback is invoked and that the pane item is removed from the workspace </desc> <cmt> add failing test to demonstrate the bug identified in #17535 </cmt> <cmt> fix #17535 </cmt> <cmt> treat ondidterminatependingstate and ondiddestroy as independent </cmt> <cmt> optional functions that a paneitem can implement. a paneitem is free to </cmt> <cmt> implement neither, just one of them, or both of them. </cmt>",teach pane to always look for a pane item's ondidterminatependingstate function
2866,"<desc> use stringtopdfstring to sanitizing bad ""prefix"" entries in page label dictionaries it seems that certain bad pdf generators can create badly encoded ""prefix"" entries for page labels, one example being  unfortunately i didn't come across such a pdf file while adding the api support for page labels, but with them now being used in the viewer i just found this issue. with this patch, we now display the page labels in the same way as adobe reader. add a bit more validation to catalog_readpagelabels, to ensure that the page labels are well formed </desc> <cmt> use stringtopdfstring to sanitizing bad ""prefix"" entries in page label dictionaries </cmt> <cmt> it seems that certain bad pdf generators can create badly encoded ""prefix"" entries for page labels, one example being </cmt> <cmt> unfortunately i didn't come across such a pdf file while adding the api support for page labels, but with them now being used in the viewer i just found this issue. with this patch, we now display the page labels in the same way as adobe reader. </cmt> <cmt> add a bit more validation to catalog_readpagelabels, to ensure that the page labels are well formed </cmt>","use stringtopdfstring to sanitizing bad ""prefix"" entries in page label dictionaries, and add more validation"
2867,"<desc> closes #35719 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> tst: add tests for to_hdf with dropna arg </cmt> <cmt> bug: add missing val handling to hdfstore.put </cmt> <cmt> doc: add whatsnew </cmt> <iss> regr: pd.to_hdf(dropna=true) not dropping all nan rows </iss>","pd.to_hdf(..., dropna=true) not dropping missing rows"
2868,"<desc> travis ci is a free hosted continuous integration platform for open-source projects.  it allows automated testing for github-hosted projects.  i've enabled its use in my (to be obsoleted) fork. after adding the configuration and the additionally required fix, the current master branch build successfully on 64-bit clang and gcc, see </desc> <cmt> prepare for travis-ci.org continuous integration </cmt> <cmt> travis ci is a free hosted continuous integration platform for </cmt> <cmt> open-source projects.  it allows automated testing for github-hosted </cmt> <cmt> projects. </cmt> <cmt> this commit adds a corresponding .travis.yml configuration file. </cmt> <cmt> document.h: define __stdc_constant_macros </cmt> <cmt> the c++ standard does not include the c99 macros used to set the (u)int64 </cmt> <cmt> constants in document.h and reader.h (see adf66292 and ce1fece2). </cmt> <cmt> many implementations include their definition when the </cmt> <cmt> __stdc_constant_macros preprocessor symbol is defined. </cmt> <cmt> see e.g. </cmt> <cmt> needed to successfully build in travis-ci.org's environment. </cmt>","prepare travis-ci.org integration, fix build on ubuntu 12.04 lts"
2869,"<desc> the current isnumeric() function checks if the value is not nan, infinity nor -infinity. this function is only used in one file it has unclear name (infinity and -infinity are usually considered number) it can be easily replaced with native function number.isfinite() number.isfinite(infinity);  // false number.isfinite(nan);       // false number.isfinite(-infinity); // false number.isfinite(0);         // true number.isfinite(2e64);      // true number.isfinite('0');       // false, would've been true with // global isfinite('0') number.isfinite(null);      // false, would've been true with // global isfinite(null) @graceguo-supercat @williaster @conglei @michellethomas </desc> <cmt> remove isnumeric util function and use lodash isfinite instead </cmt> <cmt> use native number.isfinite </cmt>",remove isnumeric util function and use number.isfinite instead
2870,<desc> commit log handwired/reddot: refactor (2fd51a1) reddot.h updated to use #pragma once include guard renamed layout macro keymap to layout refactored arguments to more closely resemble physical layout aligned for readability keymaps/default/keymap.c now uses #include qmk_keyboard_h updated include path for keymap_french.h refactored to use short keycodes aligned for readability handwired/reddot: configurator support (c9f8bee) handwired/reddot: readme update (58f9907) update readme to current qmk template add kle permalink to my best guess at the layout notes arranged the layout based on information in this reddit thread. </desc> <cmt> handwired/reddot: refactor </cmt> <cmt> - reddot.h </cmt> <cmt> - updated to use #pragma once include guard </cmt> <cmt> - renamed layout macro keymap to layout </cmt> <cmt> - refactored arguments to more closely resemble physical layout </cmt> <cmt> - aligned for readability </cmt> <cmt> - keymaps/default/keymap.c </cmt> <cmt> - now uses #include qmk_keyboard_h </cmt> <cmt> - updated include path for keymap_french.h </cmt> <cmt> - refactored to use short keycodes </cmt> <cmt> - aligned for readability </cmt> <cmt> handwired/reddot: configurator support </cmt> <cmt> handwired/reddot: readme update </cmt> <cmt> - update readme to current qmk template </cmt> <cmt> - add kle permalink to my best guess at the layout </cmt>,"handwired/reddot refactor, configurator support and readme update"
2871,"<desc> add the most basic fastapi support, passing the following test. def test_fastapi_function(serve_instance): client = serve_instance app = fastapi() @serve.deployment(app) @app.get(""/{a}"") def func(a: int): return {""result"": a} client.deploy(""f"", func) resp = requests.get(f"" assert resp.json() == {""result"": 100} resp = requests.get(f"" assert resp.status_code == 422  # unprocessable entity assert resp.json()[""detail""][0][""type""] == ""type_error.integer"" i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [wip] fastapi support in ray serve </cmt> <cmt> lint </cmt>",add initial support for fastapi
2872,"<desc> fixes #7299 fixes #7300 </desc> <cmt> fixes #7300, display docsurl as line or content </cmt> <cmt> fixes #7299 display typescript sourcemaps correctly </cmt> <cmt> - adds typescript e2e tests </cmt> <iss> display typescript sourcemaps when using default browserify plugin </iss> <iss> display ""learn more"" docsurl link in interactive mode, otherwise display docsurl as content </iss>","display typescript sourcemaps, display docsurl conditionally"
2873,"<desc> what's in this pull request? more colors in -dump-ast and -dump-parse. when using swift -dump-ast, the astdumper currently produces the following: as you can see, the output is nearly 100% white text. these commits add significantly more color, making it easy to see the distinct elements of the ast: these same benefits apply to -dump-parse. here's the before and after: what's not in this pull request? 100% colorization and test coverage. the screenshots above still contain some white text. these represent parts of astdumper that i haven't modified in this pull request. why? well, the pull request is already large, and i figured i should get some feedback before making it larger. in addition, this pull request doesn't contain test coverage. i do intend on adding test coverage for -color-diagnostics, but that'd take some additional work. i'd prefer to get some feedback on the current color scheme, then add regression tests in a subsequent pull request. should this be merged as-is? i think so. this is a big improvement to -dump-parse and -dump-ast. it could be an ever bigger improvement, it could use a more elegant abstraction than printwithcolorraii, it could have regression tests... but i think those can all come in a future pull request. </desc> <cmt> [astdumper] more colors, compat with print methods </cmt> <cmt> * the clang ast dumper uses a wide variety of colors, including bold </cmt> <cmt> fonts. use a similar scheme in the swift ast dumper, by introducing a </cmt> <cmt> terminalcolor struct that encompasses both a color and whether it </cmt> <cmt> is bold. </cmt> <cmt> * currently the only color swift's astdumper uses is red, for patterns. </cmt> <cmt> add a wider variety of colors, for various purposes. if maintainers </cmt> <cmt> decide to change the color scheme of the output ast, they need only </cmt> <cmt> to modify the color macros. </cmt> <cmt> * many ast methods take an output stream as an argument. when using </cmt> <cmt> printwithcolorraii, these methods could not be used. add a getos() </cmt> <cmt> method to printwithcolorraii, in order to support these methods. </cmt> <cmt> [astdumper] print colors for expr </cmt> <cmt> begin using colors when printing expr. also, move accesssemantics </cmt> <cmt> overload from the output stream << operator to the printwithcolorraii </cmt> <cmt> operator. </cmt> <cmt> [astdumper] use color when printing patterns </cmt> <cmt> print patterns using color, when available. </cmt> <cmt> [astdumper] use color when printing decl </cmt> <cmt> print decl using color, when available. </cmt> <cmt> [astdumper] use color when printing ast nodes </cmt> <cmt> print ast nodes using color, when available. </cmt> <cmt> [astdumper] use color when printing parameters </cmt> <cmt> print parameters using color, when available. </cmt> <cmt> [astdumper] use color when printing stmt </cmt> <cmt> print stmt using color, when available. </cmt> <cmt> [astdumper] use color when printing identifiers </cmt> <cmt> print identifiers using color, when available. </cmt> <cmt> [astdumper] use color when printing typerepr </cmt> <cmt> print typerepr using color, when available. </cmt> <cmt> [astdumper] use color when printing protocols </cmt> <cmt> print protocols using color, when available. also, color many more </cmt> <cmt> parentheses. </cmt>",improve colorization of parse and ast dumps
2874,"<desc> move the deferred limit to the producer plugin which now controls it route all new blocks through producer so it can maintain invariant that there is always a pending block (whether for speculative execution or future signing) re-apply unapplied transactions and apply deferred transactions on a new block (note: this needs proper throttling once subjective failures are handled correctly inside controller). remove spurious calls to start_block in other plugins fixed producer plugin and changed some logic to respect the notion that we ""called our shot"" in start_block and should no longer be concerned with other time slots </desc> <cmt> move the deferred limit to the producer plugin which now controls it; route all new blocks through producer so it can maintain invariant that there is always a pending block (whether for speculative execution or future signing); re-apply unapplied transactions and apply deferred transactions on a new block (note: this needs proper throttling once subjective failures are handled correctly inside controller).  remove spurious calls to start_block in other plugins </cmt> <cmt> fixed producer plugin and changed some logic to respect the notion that we ""called our shot"" in start_block and should no longer be concerned with other time slots </cmt>",route all pushes through producer
2875,"<desc> follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> add it to notneededpackages.json. </desc> <cmt> added files </cmt> <cmt> daily update </cmt> <cmt> added comments </cmt> <cmt> moved directory </cmt> <cmt> passed the dt linter </cmt> <cmt> more linter updates </cmt> <cmt> reverted files </cmt> <cmt> merge </cmt> <cmt> removed redundant dir </cmt> <cmt> changed const enum to enum to fix linter </cmt>",added dsb banking and common type definitions
2876,<desc> update pwm code to the latest version of esp8266/arduino#7231 main benefits: ram: -148 bytes flash: -188 bytes iram: -120 bytes the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.0 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> change pwm updated to the latest version of arduino pr #7231 </cmt> <cmt> change pwm updated to the latest version of arduino pr #7231 </cmt>,update to latest pwm version of arduino #7231
2877,"<desc> adds a url-tvg attribute with a guide from iptv-org/epg if available. languages/bul.m3u #extm3u url-tvg="" ... the attribute can contain multiple guides separated by commas. categories/classic.m3u #extm3u url-tvg="" ... update: the changelog is empty due to an error that occurred while updating the playlist. the full list of changed files can be found here: </desc> <cmt> update playlist.js </cmt> <cmt> install axios package </cmt> <cmt> create epg.js </cmt> <cmt> update db.js </cmt> <cmt> update format.js </cmt> <cmt> update channel.js </cmt> <cmt> update db.js </cmt> <cmt> update generate.js </cmt>",add url-tvg attribute to playlists
2878,"<desc> the functionality provided by #11011 already exists natively in the surefire/failsafe plugins by setting the -dmaven.surefire.debug flag. remove redundant maven profile. also upgrade the surefire/failsafe versions, so they cope better when tests prints to stdout. less stuff in our pom.xml file, and better console output when our tests are printing stuff. </desc> <cmt> revert ""add a profile for debugging tests that run from maven (#11011)"" </cmt> <cmt> this reverts commit 83895f0f </cmt> <cmt> the same functionality is already natively available in surefire, by adding the -dmaven.surefire.debug flag to maven. </cmt> <cmt> update surefire/failsafe version </cmt> <cmt> these new versions copes better when our tests prints to stdout, and disturbs the progress processing that these plugins do. </cmt>",revert test debugging flags and update surefire/failsafe
2879,"<desc> i removed the macro definitions that are no longer needed as keymap_grid is now in the file keymap_common.h. i also fixed an error in the documentation. i added comments showing a blank layout (with ascii art, similar to those found in the other keyboard projects under tmk_keyboard) for each of the supported formats. </desc> <cmt> kc_insert should be kc_ins </cmt> <cmt> the short name was incorrectly set as kc_int when we want kc_ins. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> delete .keymap_nathan.c.swp </cmt> <cmt> update keymap_nathan.c </cmt> <cmt> remove macro for keymap_grid that is in keymap_common.h. </cmt> <cmt> add comments with ascii art for the two layouts in keymap_common.h. </cmt>","housekeeping on keymap_nathan.c, updated documentation"
2880,<desc> it seems that nintendo finally filled that last empty spot in applicationlanguage for a total of 16 supported languages. should fix pt-br language support in mario party superstars </desc> <cmt> ns: language: add brazilianportuguese to applicationlanguage </cmt> <cmt> it seems that nintendo finally filled that last empty spot in applicationlanguage for a total of 16 supported languages. </cmt> <cmt> file_sys: control_metadata: add brazilianportuguese </cmt>,add brazilian portuguese to the list of applicationlanguage
2881,"<desc> this is the pr we discussed in #413 for colortool. there are two bugfixes in this pr (the final two commits). the first two commits are the refactoring. 7daea0a - first refactoring commit, pulls logic out of program.cs and into other files. 05f518d - second refactoring commit, gets rid of mutable fields and mutable statics. b61cb83 - only run the required parser for the colorscheme file. before, all parsers could be run for a single colorscheme file, so we could get error output even if everything imported correctly. 12fff31 - allow the writing of screen/popup background/foreground indices to the registry. before this only worked for the currently running console, now it will save for all consoles. this pr modifies a lot of files, but i've isolated the bulk of the changes in the first commits, so there are no user-facing changes in those commits. </desc> <cmt> pull logic out of program.cs </cmt> <cmt> there aren't any user-facing changes in this commit, just pulling logic out of program.cs. all that remains in program.cs is command line parsing. </cmt> <cmt> - the functions that wrote to the registry, the console, and the virtual terminal (--xterm) are now in their own files, implementing the iconsoletarget interface </cmt> <cmt> - move the utility method uinttocolor into colorscheme, where it can be used as an indexer, e.g. mycolorscheme[i] returns a system.drawing.color </cmt> <cmt> - the ""export to ini"" functionality is now in a ""schemewriters"" namespace; parsers are now in a ""schemeparsers"" namespace </cmt> <cmt> - printing the color table is now in the colortable class. </cmt> <cmt> replace mutable public fields with properties </cmt> <cmt> the properties are made readonly where possible, which is possible in almost all cases. </cmt> <cmt> allow scheme parsers to opt out of attempting to parse a file </cmt> <cmt> this fixes the issue where the ini file parser can throw errors because it's attempting to parse an .itermcolors (xml) file. </cmt> <cmt> add support for writing foreground / background indices to registry </cmt> <cmt> this functionality was implemented for the ""current console"" but was never implemented for writing to the registry, which affects all future consoles. </cmt>","fix colortool parser and registry bugs, and refactor"
2882,"<desc> added support for the hid liberation device, a replacement controller for filco majestouch tlk keyboards. added a default ansi keymap as well as a lightly customized layout. </desc> <cmt> keyboard: added support for hid liberation device </cmt> <cmt> keymap: custom (bakageta) layout for hid liberation device </cmt>",add support for bpiphany's hid liberation device
2883,<desc> added implementation for existing dcompact layout to levinson keyboard dir fixed readme typos for dcompact layouts my code follows the code style of this project. i have read the contributing document. </desc> <cmt> fix whitespace and markdown errors </cmt> <cmt> add dcompact layout implementation for levinson keyboard </cmt>,dcompact layout updates pt. 3
2884,"<desc> free book about operating systems. i've read some chapters of this book when i was taking an operating systems class at college. it helped me to learn the fundamentals and some advance topics as well. so i think anyone can benefit from it. it's very well written and has nice illustrations as well. it's under creative commons attribution-noncommercial-sharealike 3.0 unported license, as we can see in the author's official page. yes, it's a book. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> add index entry for agnostic operating systems topic </cmt> <cmt> add maziero's operating systems book </cmt> <cmt> add under construction indicator </cmt> <cmt> this book is an on going work, it's publish under that link, but things </cmt> <cmt> are changed from time to time in it. </cmt>",add maziero's operating systems book in new index entry for agnostics resources
2885,"<desc> the matrix noah board definition doesn't support a 6.25u space bottom row with layout_iso. added a layout_iso_uk that supports it and a personal map that uses that layout. added a new layout to support iso builds with a 6.25u bottom row. not sure if layout_iso_uk is the right name for it, let me know if not (probably isn't but i wasn't sure if layout_iso_625u or similar was better either). tested on my personal build. n/a. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> 6.25u bottom row iso layout for matrix noah </cmt> <cmt> personal map for matrix noah using new 6.25u bottom row iso </cmt>",matrix noah 6.25u bottom row plus personal keymap using it
2886,<desc> as already mentioned in the other pr we have some osx users which have studio audio equipment which has more then the currently supported 24 channels. it seems common for those audio devices to present all its output channels in one single stream which means ca pulls frames with all the  < numberofchannels > in the render callback. also as far as i can tell all those devices use interleaved audio. the latter makes it really cumbersome to do the padding on my own and atm i don't have any time to even try it. this change here fixes the problem for now and doesn't harm any other implementation. (it just allows for channelmaps with up to 64 unknown channels - so the engine takes care of crafting those huge frames for us...). this also fixes trac ticket </desc> <cmt> [ae] - extend the number of unknown channels from 16 to 64 </cmt> <cmt> [ae/ca/osx] - fillup the stream with up to 64 unknown channels fixes support for studio audio devices with more then 16 unused/unknown channels in one stream - fixes #15874 </cmt>,support devices with up to 72 channels (64 unknown + 8 mapped)
2887,<desc> check vainitialize return value in interop and fix related memleak return value must be checked or vaapi will segfault in vacreatesurfaces if init failed e.g. due to missing driver bug fix (non-breaking change which fixes an issue) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> fix crash when vaapi cannot be initialized </cmt> <cmt> fix memory leak when vaapi cannot be initialized </cmt>,fix crash when vaapi is not available at runtime
2888,"<desc> typically, every libgdx html project has to tweak around with index.html to prevent browser's default behaviour on certain key presses (f1, alt, space, arrow keys and stuff). we already have setcatchkey to prevent system or background app behaviour on key presses, but this is only implemented on android so far. this pr adds the ability to use the setcatchkey methods to prevent browser default behaviour on gwt. additionally, this changes keyforcode from private static to protected. since we now can override the input processing class, it makes sense to have this method overridable as well. </desc> <cmt> gwt input make keyforcode overridable, use setcatchkey to prevent browser's default behaviour </cmt> <cmt> improve setcatchkey javadoc </cmt>",gwt use setcatchkey to prevent browser's default behaviour
2889,"<desc> backport for #16989 copied from original pr: we struggled to investigate flink-23611 due to missing flink logs. it appears that something went wrong with the flink cluster. the stop signal wasn't retrieved by the yarn session cluster thread for some reason which made the test wait forever for the thread to finish. the tests are executed on azureci through tools/ci/test_controller.sh which implements a watchdog mechanism that checks the logs (stdout and mvn-*.log) for new content and kills the test if there's no output for a given amount of time (900s). yarn does produce regular logs, though, through the org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice logger. these log messages are generated every 10 minutes: 22:51:31,785 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 22:51:32,398 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 hence, the test is not killed while waiting for the yarn cluster to finish. the flink logs, as a consequence, are not copied over from the yarn application folder into the build artifact folder as part of the tools/ci/test_controller.sh execution. hotfix: fixes bug in path creation hotfix: improves local log4j configuration for yarn tests disables info logs for org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice in ci log4j configuration dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? not applicable </desc> <cmt> [hotfix][yarn-tests] fixes path definition for local yarn-test working directory artifact collection </cmt> <cmt> [hotfix][yarn-tests] replaces runtime by timestamp </cmt> <cmt> the intend is to improve local debugging matching log events in different log </cmt> <cmt> files (yarn, flink) via the timestamp. </cmt> <cmt> [flink-23611][yarn-tests] disables info log messages coming from yarn's resourcelocalizationservice </cmt> <cmt> we observed regular info log messages being produced by resourcelocalizationservice after the test ran into a timeout: </cmt> <cmt>  </cmt> <cmt> 22:51:31,785 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 </cmt> <cmt> 22:51:32,398 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 </cmt> <cmt>  </cmt> <cmt> these log messages appeared every 10 minutes which prevented the ci/tools/test_controller.sh's watchdog mechanism to </cmt> <cmt> kick in. the watchdog mechanism relies on no output being produced for a given amount of time. this way, the </cmt> <cmt> test_controller script was unable to archive the yarn flink log. </cmt>",disables log message to enable watchdog functionality
2890,"<desc> the adder node can now add float vectors of different lengths by trimming them to the same dimensionality. we can change this behavior in the future, or introduce different nodes (like a ""mix"" node) that address differing vector lengths in different ways. </desc> <cmt> introduce dimensions to expression </cmt> <cmt> rename to setexpressionforslot and add redcomponent function </cmt> <cmt> add expression helpers to aid with differing data widths </cmt> <cmt> add float2constantnode </cmt> <cmt> single-line functions when possible </cmt>",introduce handling for varying dimensionality
2891,"<desc> following are the changes - python implementation - coin_change.py with proper comments cpp code fix - order of table filling was not correct, fixed it and commented the code. cpp code fix 2 - order of top-down memoization is not correct - removed it for now. </desc> <cmt> addition of python implementation and cpp code fix. </cmt>",python implementation of coin_change and cpp code fix
2892,"<desc> description: as discussed with @martinhjelmare in #30309 the def device_state_attributes(self): can be removed, as brightness is already an attribute of light. related pr: #30309 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io n/a the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. n/a new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. n/a untested files have been added to .coveragerc. n/a if the code does not interact with devices: tests have been added to verify that the new code works. n/a </desc> <cmt> remove unnecessary property def </cmt> <cmt> remove unnecessary property def </cmt>",remove unnessecary rfxtrx light property def
2893,<desc> description: fixes xiaomi power strip v1 support fixes chuangmi plug v3 support (syssi/xiaomiplug#11) fixes air conditioning partner (syssi/xiaomi_airconditioningcompanion#21) related issue (if applicable): fixes #13749 </desc> <cmt> bump python-miio version </cmt> <cmt> fix xiaomi power strip v1 support (closes: #13749) </cmt> <iss> xiaomi qmi.powerstrip.v1 gives error </iss>,bump python-miio version (closes: #13749)
2894,<desc> closes  we could only use json and javascript to configure cypress after we can use typescript additionally to js and json i also added cypress.config.ts as a detected default config file </desc> <cmt> feat: allow to use typescritpt in the config file </cmt> <cmt> add end to end test </cmt>,allow to use typescript in the config file
2895,"<desc> according to this issue, we should support python 3.6 and python 3.7 in paddle build scripts </desc> <cmt> add python3.6 and python3.7 support in padde build scripts </cmt> <cmt> test=develop </cmt> <cmt> add support for mac build </cmt> <cmt> test=develop </cmt>",add python 3.6 and python 3.7 support to paddle build
2896,"<desc> adds feature flags (set with defaults to match current behavior) that (a) can escape/display html code, or (b) hide the output of html markup. test plan tested (visually, and in chrome inspector) that html is escaped when escape_markdown_html is enabled, and that html is hidden when display_markdown_html is turned off. requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> utilizing feature flag for html escapement </cmt> <cmt> use src alias </cmt> <cmt> feature flag to allow hiding of html tags </cmt> <cmt> strips js attr </cmt> <cmt> better feature flag naming </cmt> <cmt> simplifying </cmt>",adding feature flags to escape/hide html in markdown
2897,"<desc> currently the work of dispatching semantic events to recognizer callbacks is done by rawgesturedetector. the biggest drawback of this design, among others, is that the involved recognizers are hard coded, therefore custom recognizers are unable to get themselves notified on semantic events. this pr moves this work to recognizers by adding a new method to gesturerecognzier: abstract class gesturerecognzier { semanticshandlerconfiguration get semanticshandlers; } which returns a class that has one optional callback for each kind of semantic event. gesture detector will collect the configuration from all of its recognizers and summarize them into one callback per kind of event, therefore becoming agnostic of actual recognizer type. this pr also renames all callbacks related to semantics to semantics*callback from the current gesturetapcallback, gesturelongpresscallback, etc. they are the same (therefore is non-breaking), but gesture*callbacks are defined by subclasses of gesturerecognizer, which are inappropriate for gesturerecognizer to know. related issues blocks: #32770 i added the following tests: {tap,longpress,horizontaldrag,verticaldrag,pan}gesturerecognizer: its corresponding semantic gesture correctly triggers handlers rawgesturedetector a semantic gesture triggers all handlers of that kind replacing gesture recognizers should update semantic handlers before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> basic functionality </cmt> <cmt> move logic to class and pass tests </cmt> <cmt> rename and comments </cmt>",move declaration of semantic handlers from detectors to recognizers
2898,"<desc> major changes: 1. expose non-self-register extend api for extensions. so extensions like echarts gl which provide multiple charts and components can also have the new minimal import api. an example: // in extension code. class scatter3dchartview extends echarts.chartview { .... } class scatter3dseriesmodel extends echarts.seriesmodel { .... } export function scatter3dchart(registers) { registers.registerchartview(foochartview); } // in users code import {use} from 'echarts/core/'; import {scatter3dchart} from 'echarts-gl/charts'; use([scatter3dchart]); 2. expose several helper methods for extension usage. echarts.helper.createtextstyle echarts.helper.enablehoveremphasis 3. mark as sideeffects in extensions. </desc> <cmt> refact: remove registerwhenextend, add ability for class extend in extension. </cmt> <cmt> refact: adjust exports. </cmt> <cmt> chore: no sourcemap in lib </cmt> <cmt> fix: fix unexpected sideeffects in extension </cmt> <cmt> expose more helper functions to extension </cmt> <cmt> settextstyle, enablehoveremphasis </cmt> <cmt> feat: add state opt in createtextstyle export </cmt>","provide better apis for extensions like echarts gl, wordcloud, liquidfill"
2899,<desc> addresses #20724 #dataumbrella summary of changes to basedecisiontree: add tests to ensure estimator raises proper errors when invalid arguments are passed in. use the helper function check_scalar from sklearn.utils to validate the scalar parameters. test and validation progress: max_depth min_samples_split min_samples_leaf min_weight_fraction_leaf max_features max_leaf_nodes min_impurity_decrease ccp_alpha references check_scalar docs pr #20723 </desc> <cmt> max_depth: add tests </cmt> <cmt> max_depth: add validation </cmt>,maint use check_scalar in basedecisiontree
2900,"<desc> fixes #4667. on master, the tests added in this pr fail and the code below prints info and warning level logs. library(lightgbm) data(""agaricus.train"") dtrain <- lgb.dataset( data = agaricus.train$data , label = agaricus.train$label ) lgb.cv( params = list() , data = dtrain , verbose = -1l , nrounds = 3l , nfold = 2l , obj = ""binary"" ) as of this pr, the tests pass and no logs are produced. </desc> <cmt> fixes </cmt> <cmt> revert debugging code </cmt> <cmt> add test </cmt> <cmt> check for lightgbm explicitly </cmt> <iss> [r-package] `lgb.cv` ignores `verbose` argument </iss>",respect 'verbose' argument in lgb.cv() (fixes #4667)
2901,"<desc> closes #14743 adds proper support for generating commands from select events on multi-selects i had originally overlooked multiple selects in the original implementation - this should add full support. this pr should be merged in after #14788 since it steals some of the test changes that belong to that pr see original issue for a failing example - here's what it looks like now: has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? </desc> <cmt> fix(studio): generate selectors before mouse events on click </cmt> <cmt> set up basics for isolated runner tests </cmt> <cmt> update a ton of studio tests </cmt> <cmt> i didn't like that spacing </cmt> <cmt> add another test for mouse events </cmt> <cmt> fix(studio): properly generate commands for multi select </cmt> <cmt> update other tests for studio select </cmt> <iss> clicking on select option in cypress studio, main window empties - cannot continue testing </iss>",add support for generating multi select commands
2902,"<desc> (whoops branch should've been issue-2117-http-url-not-working...) this pr will resolve issue #2117. it will upgrade an http url to https and see if that works then fallback to using http if it fails. it will test an https url too and verify that the git repos exists fix and rewrite the broken tests the cause of the bug was having a project dependency which itself depended on an http repos. { ""name"": ""yarn-test"", ""version"": ""1.0.0"", ""main"": ""index.js"", ""license"": ""mit"", ""dependencies"": { ""pm2"": ""^1.1.3"" } } running a yarn install on the above would trigger this error error refusing to download the git repo  https is not valid for that domain since they have an invalid certificate chain (refer to #2117 for details). </desc> <cmt> test for https but fallback to http if necessary </cmt> <cmt> add lang key for https </cmt> <cmt> fix broken tests </cmt>",fix bug for #2117 - http url not working
2903,"<desc> fixes #3604 where increase/decrease font size bindings were not working. closes #3604 cla signed. if not, go over here and sign the cla increase and decrease font size works once again! </desc> <cmt> adding fromjson to adjustfontsizeargs </cmt> <cmt> made a legacy function that just allows you to do 1/-1 delta for adjusting font size </cmt> <cmt> adding test case </cmt> <cmt> removing extra quotes </cmt> <cmt> comments lmao </cmt> <iss> `{increase,decrease}fontsize` don't seem to work </iss>",fixing increase + decrease font size
2904,"<desc> it's my refactoring on top of jean's pr 307 feed back welcome </desc> <cmt> added normalize parameter to linearmodel </cmt> <cmt> in fit_intercept, there is now a normalize parameter (default=false) </cmt> <cmt> to normalize data. </cmt> <cmt> added parameter normalize to linearregression </cmt> <cmt> lassolars now uses the normalize parameter </cmt> <cmt> completed the integration of the parameter normalize </cmt> <cmt> implementation of the parameter normalize in bayes.py </cmt> <cmt> added parameter normalize to coordinate_descent </cmt> <cmt> added parameter normalize to ridge.py </cmt> <cmt> added parameter normalize to omp.py </cmt> <cmt> some changes in linear_model </cmt> <cmt> added parameter normalize </cmt> <cmt> added parameter overwrite_x </cmt> <cmt> fixed some errors (mainly docstrings) </cmt> <cmt> conflicts: </cmt> <cmt> scikits/learn/linear_model/omp.py </cmt> <cmt> added a function as_float_array in scikits.learn.utils </cmt> <cmt> this function converts a numpy array to dtype np.float (64 or 32, depending of the original type). </cmt> <cmt> it also takes an optional argument overwrite_x. </cmt> <cmt> thus, _center_data no more takes overwrite_x as an argument, and now modify x inplace. </cmt> <cmt> fix : deleted a forgotten line </cmt> <cmt> i had forgotten a none wanted line in the code, i removed it. </cmt> <cmt> fix : corrected a bug in as_float_array and added a test function </cmt> <cmt> the function was copying x even when overwrite_x was true. </cmt> <cmt> pep8 : replaced tabulations by spaces </cmt> <cmt> fix : if x is already of the good type, we musn't modify it </cmt> <cmt> added a verification in the test </cmt> <cmt> fix : if x.dtype is changed, then a copy of x is returned, even if overwrite_x  is true </cmt> <cmt> the test was updated </cmt> <cmt> test : lasso_lars_vs_lasso_* </cmt> <cmt> added a same test as the existing one, with normalization </cmt> <cmt> conflicts: </cmt> <cmt> scikits/learn/linear_model/bayes.py </cmt> <cmt> scikits/learn/linear_model/least_angle.py </cmt> <cmt> fix : ellipsis in least_angle.py doctests </cmt>",normalize data and refactor of coordinate_descent.py
2905,<desc> this merely log stuff on the console for now. on qemu (without kvm): on hyper-v: ... ... </desc> <cmt> kernel: add support for hypervisor cpuid feature </cmt> <cmt> kernel: detect and display cpuid hypervisor signature </cmt> <cmt> kernel: detect and display cpuid hyper-v data </cmt>,initial hypervisor guest and hyper-v support
2906,"<desc> currently, abstract service classes cause an error during image building. this is reasonable since such services cannot be instantiated. however, since jdk9 there is java.util.serviceloader.stream() which does not force instantiation. thus, we must not fail eagerly. also add test for service with no provider constructor [gr-19958] (#2652). </desc> <cmt> svm: add abstractserviceloadertest [gr-32503] </cmt> <cmt> svm: fail lazily if service loaders cannot be instantiated [gr-32503] </cmt> <cmt> svm: add test for service with no provider constructor [gr-19958] </cmt> <cmt> this adds a test for the work around for </cmt> <cmt> svm: introduce svm_tests_jdk11 </cmt>",native image should fail lazily if service loaders cannot be instantiated.
2907,<desc> this ensures we get a nicer error message from psexec. psexec ansible version v2.6 </desc> <cmt> psexec: handle socket errors (connection timeout) </cmt> <cmt> this ensures we get a nicer error message from psexec. </cmt> <cmt> add changelog fragment </cmt>,handle socket errors (connection timeout) (backport)
2908,"<desc> nearly all of the work required to get aabb vs. aabbs to work in ninja was already present. reportcollisionvsworld already worked, and contained all of the logic required to resolve a collision once the appropriate vectors had been established. reportcollisionvsbody was refactored to use that function (now generically named reportcollision), and now aabbs can collide properly, including bouncing and friction. reportcollisionvsworld is now just a wrapper around reportcollision to maintain compatibility. you can grab a testfile based on the phaser tutorial demo here. all the entities are ninja aabbs. </desc> <cmt> pull from latest dev </cmt> <cmt> dev </cmt> <cmt> implemented ninja aabb vs aabb collisions </cmt> <cmt> removed unused local variables in ninja.aabb.reportcollisionvsbody </cmt>",aabb vs. aabb collision in ninja
2909,<desc> description: move smartthings integraiton library imports to the top of the modules and use library constants in sensor / binary_sensor modules. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: </desc> <cmt> move imports to top </cmt> <cmt> use lib constants </cmt>,move smartthings imports to top
2910,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. this pr relates to this error: </desc> <cmt> added fn type for order </cmt> <cmt> added tests for order with order </cmt> <cmt> updated tests to use s. </cmt> <cmt> increased the version number in the header </cmt>,"updated ""sequelize typings"" to be able to use fn in ""order"" options"
2911,"<desc> this is based on pr #2605 though it does not need to :) </desc> <cmt> add missing headers to build.json </cmt> <cmt> clang-format messed up doxyfile.c++, restored </cmt> <cmt> fix doxyfile for real </cmt> <cmt> only copy stuff when status is ok </cmt>",only copy call details when the status is ok.
2912,"<desc> the fastcgi process spawned by fastcgi.spawn is executed before h2o calls setuid.  so in case the server is spawned with root privileges (is a requirement if it needs to listen to port 80 or 443), the process gets spawned with root privileges. as discussed in  therefore this pr does the following: by default, change the uid (and group privileges) of the spawned process to that specified using the global user directive (in other words, fastcgi processes will be run under the same privileges as the h2o server) optionally accept a mapping as the argument to fastcgi.spawn, and if it contains a user attribute, use spawn the fastcgi process under name of the given user </desc> <cmt> compile and install setuidgid into share/h2o </cmt> <cmt> [refactor] store running username in h2o_globalconf_t </cmt> <cmt> spawn fastcgi process using the specified user </cmt>",setuid the process spawned by fastcgi.spawn
2913,"<desc> remove last places where diagnostics replied on information from constraint system and instead adjust them to use solution associated with a fix where possible. </desc> <cmt> [diagnostics] fix requirementfailure::getconformanceforconditionalreq to use data from solution </cmt> <cmt> [diagnostics] fix missingconformancefailure::diagnoseaserror to use solution to retrieve fixes </cmt> <cmt> [diagnostics] fix contextualfailure to use solution data for hasappliedself </cmt> <cmt> [diagnostics] nfc: move is{array, collection}type helpers into failurediagnostic </cmt> <cmt> [diagnostics] add getrawtype which allows to retrieve type associated with astnode </cmt> <cmt> this is useful when diagnostic needs to check something about type </cmt> <cmt> variables involved in a particular type e.g. whether type variable </cmt> <cmt> has been defaulted. </cmt> <cmt> [diagnostics] avoid direct use of constraint system by missingargumentsfailure::ismisplacedmissingargument </cmt> <cmt> [diagnostics] use solution for verify presence of fix in diagnoseuseofreferenceequalityoperator </cmt> <cmt> [diagnostics] use data from associated solution while diagnosing missing generic arguments </cmt> <cmt> [diagnostics] nfc: add israwrepresentable/conformstoknownprotocol helpers into failurediagnostic </cmt>",audit use of constraint system in diagnostics
2914,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry hi, i wrote this utility which i use in production almost daily at my job, and it's been super helpful for me personally to fill a gap - slow writes from pandas to ms sql. figured i'd suggest it in the pandas ecosystem if it could be useful to others. wasn't sure where to put it, and didn't want to start a new section, so i put it in out-of-core. it appeared to be sorted alphabetically, so i put it in that order. </desc> <cmt> update from master </cmt> <cmt> added bcpandas to ecosystem </cmt>",add bcpandas to ecosystem in docs
2915,"<desc> improve repo (free-programming-books.md) fix incorrect markdown syntax. fix incorrect markdown syntax. none none none not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) </desc> <cmt> add excel-vba ebook repo. </cmt> <cmt> add vba eboob repo. and fix incorrect menu link. </cmt> <cmt> fix wrong format line </cmt> <cmt> fix incorrect markdown syntax. </cmt> <cmt> add excel - vba ebook repo. (#3079) </cmt>",fix incorrect markdown syntax(free-programming-books.md)
2916,<desc> fixes the invariant test for sample weights as mentioned in issue #11316 (refactor tests for sample weights). what is new? this is a generic test for estimators that makes sure the sample weights yield consistent results. the test checks if the output of the estimators are the same for sample_weight = none and sample_weight=np.ones(). pairwise methods are skipped as they require pairwise data. </desc> <cmt> test for none and ones for sample_weight added </cmt> <cmt> test for none and ones for sample_weight added </cmt> <cmt> skip kmeans based estimators </cmt> <cmt> conflict resolved </cmt> <cmt> cleaning </cmt>,add a test for sample weights for estimators
2917,<desc> this pull request fixes the following issues: added missing 3d files to libcocos2d project files implemented missing inet_pton() functions for windows phone </desc> <cmt> added missing inet_pton() for windows phone </cmt> <cmt> fixed check for header already included </cmt> <cmt> added missing inet_pton() for windows phone </cmt> <cmt> added missing files </cmt> <cmt> added missing files </cmt>,wp8 and windows 8.1 universal app fixes
2918,<desc> for #11709 </desc> <cmt> rename clusterpersistrepositoryconfiguration </cmt> <cmt> refactor gov spring namespace </cmt> <cmt> refactor standalone spring name space </cmt> <cmt> refactor cluster spring name space </cmt> <cmt> remove useless codes </cmt> <cmt> move cluster repository.xsd </cmt> <cmt> move standalone repository.xsd </cmt> <cmt> rename test cases </cmt>,refactor gov spring namespace to cluster
2919,"<desc> i hereby agree to the terms of the cla available at:  add materializedpostgresql table engine and database engine. database engine allows to replicate a whole database or any subset of database tables. </desc> <cmt> initial table sync and replication pre-startup </cmt> <cmt> decode replication messages </cmt> <cmt> add stream and buffer classes </cmt> <cmt> initial sync into replacingmergetree table, select via nested table </cmt> <cmt> setup connection in the background, better drop table </cmt> <cmt> replicate insert queries </cmt> <cmt> replicate delete queries </cmt> <cmt> replicate update queries </cmt> <cmt> slightly better </cmt> <cmt> better </cmt> <cmt> read up to max_block_size rows </cmt> <cmt> better slot usage, some fixes </cmt> <cmt> separate replication interface from single storage </cmt> <cmt> add postgresqlreplica database engine </cmt> <cmt> better </cmt> <cmt> fix and test different data types </cmt> <cmt> slightly better </cmt> <cmt> allow to replicate a subset of database tables </cmt> <cmt> better table sync </cmt>",materializepostgresql table engine and database engine
2920,"<desc> this is a minor refactor of the system that deals with previous encryption schemes: it renames #previous_types_including_clean_text -> #previous_types. this private api method is used in other places and invokers are always interested in the ""clean text type"" (when support for unencrypted data is enabled). it makes sense to make that the default behavior. the old internal private method #previous_types is now #previous_types_without_clean_text. this also: adds tests to validate that the system launches decryption errors when all the previous encryption schemes fail to decrypt, and to validate that it returns the ciphertext when support for unencrypted text is enabled. extracts method with common logic for tidying up test of previous encryption schemes. </desc> <cmt> rename previous_types_including_clean_text => previous_types </cmt> <cmt> it's make more sense to revert the naming approach: </cmt> <cmt> - #previous_types, the exposed public method, always include the clean </cmt> <cmt> text type when suport for unencrypted data is enabled </cmt> <cmt> - #previous_types_without_clean_text is a private method used </cmt> <cmt> internally by the type </cmt> <cmt> we want to check previous_types ignoring clean text type here </cmt> <cmt> this wasn't causing any issue because the behavior was virtually the </cmt> <cmt> same (returning the ciphertext), but it was confusing to read. </cmt> <cmt> add missing text for encryption exception raising </cmt> <cmt> extract helper method for common logic across tests </cmt>",internal refactor relative to previous encryption schemes
2921,"<desc> original pull-request #18130 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix remove ttl for column </cmt> <cmt> fix test </cmt> <cmt> fix remove ttl for column </cmt>",cherry pick #18130 to 20.12: fix remove ttl for column
2922,<desc> description: now that zigpy gets the node descriptors for devices and persists them w e no longer have to. this pr removes the node descriptor request that we were making in favor of the one that zigpy does. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> use zigpy node descriptor </cmt> <cmt> cleanup </cmt>,use node descriptor from zigpy for zha
2923,"<desc> category choose one bug fix enhancement (new features, refinement) the js code in the deck.gl examples wasn't working correctly. test plan tested locally reviewers @mistercrunch </desc> <cmt> fix js_data_mutator </cmt> <cmt> remove redundant line change </cmt> <cmt> add missing line changes </cmt>",fix deck.gl sample charts with js
2924,<desc> change interval of update-notifier to 7 days from the current default of 1 day. message updated with yarn instruction: #20061 </desc> <cmt> react-devtools update-notifier interval change to 7 days & msg updated with yarn command </cmt> <cmt> overly eager react-devtools </cmt>,overly eager update-notifier usage in react-devtools
2925,"<desc> when controlling animation progress using animated.value lottie animation was flickering with android. did some investigation and it seems that animationjson was parsed and applied every time any property change would happen. setting animation only once solved that issue. also examples seemed to be broken when imperative api was disabled so fixed progress slider and cleaned up some example code. probably resolves #362 </desc> <cmt> use animated component to update progress slider in examples </cmt> <cmt> load animation json only once. should resolve flickering issues </cmt> <cmt> simplify example picker </cmt> <cmt> fixed progress slider and cleaned up some code </cmt> <iss> animations flicker or won't show after update (android only, ios works perfectly) </iss>",clear animationjson property to resolve android flickering issues
2926,"<desc> closes #45032 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> gh45032 fix iloc._get_setitem_indexer </cmt> <cmt> test for gh45032 </cmt> <cmt> update what's new </cmt> <iss> bug: iloc(axis=1).__setitem__ ignores axis </iss>",fix gh45032 iloc(axis=1).__setitem__ axis argument
2927,"<desc> #2849 the default wrapping used for textblock in rnw is wrapping. when numberoflines is set to 1, we should set wrapping to none, to have proper trimming/ellipsis for single line text. microsoft reviewers: open in codeflow </desc> <cmt> fix single line text trimming issue </cmt> <cmt> reset wrapping when numberoflines property reset </cmt>",fix text trmming issue for single line text
2928,"<desc> to ease cross-development gentoo alows installing only fully qualified toolchains tools: x86_64-pc-linux-gnu-ar and similar. the change allow overriding ranlib variable similar to existing cc, host_cc, ld and friends. </desc> <cmt> mk: allow ranlib override </cmt> <cmt> to ease cross-development gentoo alows installing only fully </cmt> <cmt> qualified toolchains tools: </cmt> <cmt> x86_64-pc-linux-gnu-ranlib </cmt> <cmt> and similar. </cmt> <cmt> the change allow overriding ranlib variable similar </cmt> <cmt> to existing cc, host_cc, ld and friends. </cmt> <cmt> reported-by: agostino sarubbo </cmt> <cmt> bug: </cmt> <cmt> mk: allow objcopy override </cmt> <cmt> to ease cross-development gentoo alows installing only fully </cmt> <cmt> qualified toolchains tools: </cmt> <cmt> x86_64-pc-linux-gnu-objcopy </cmt> <cmt> and similar. </cmt> <cmt> the change allow overriding ranlib variable similar </cmt> <cmt> to existing cc, host_cc, ld and friends. </cmt> <cmt> reported-by: agostino sarubbo </cmt> <cmt> bug: </cmt> <cmt> mk: allow ar override </cmt> <cmt> to ease cross-development gentoo alows installing only fully </cmt> <cmt> qualified toolchains tools: </cmt> <cmt> x86_64-pc-linux-gnu-ar </cmt> <cmt> and similar. </cmt> <cmt> the change allow overriding ranlib variable similar </cmt> <cmt> to existing cc, host_cc, ld and friends. </cmt> <cmt> reported-by: agostino sarubbo </cmt> <cmt> bug: </cmt>","allow ar, objcopy, ranlib overrides"
2929,"<desc> fix hashttpcapability issue with bitbucket shortcut resolver and private repo (#4393) bug with a private repo that used like ""module"": ""bitbucket:team/repo"" fix setrefremote issue with exotic shortcut resolvers and branch/tag/commit bug with a repo that used like ""module"": ""bitbucket:team/repo#tag"" if i have a private dependency like ""activities"": ""bitbucket:openagenda/activities"" in my package.json, and i run yarn install --verbose then i have this error: verbose 0.407 performing ""head"" request to "" verbose 0.867 request "" verbose 0.873 performing ""get"" request to "" verbose 0.98 request "" verbose 0.981 error: error connecting to repository. please, check the url. at /home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:33269:15 at generator.next (<anonymous>) at step (/home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:92:30) at /home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:103:13 at process._tickcallback (internal/process/next_tick.js:109:7) error an unexpected error occurred: ""error connecting to repository. please, check the url."". info if you think this is a bug, please open a bug report with the information provided in ""/home/bertho/openagenda/cibul-node/yarn-error.log"". info visit </desc> <cmt> * fix hashttpcapability issue with bitbucket shortcut resolver and private repo (closes #4393) </cmt> <cmt> * fix setrefremote issue with exotic shortcut resolvers and branch/tag/commit </cmt>",fix bitbucket exotic shortcut resolvers with private repositories
2930,"<desc> so this is my attempt of adding replay and export functions. i first thought on only keeping the last played wav, but then i thought would be nice to let the user choose among the last generated ones for like, comparing and choosing the best. i added a new row on the right side for the 3 new widgets. turned out to be the best placement and  i hope this is fine until the interface cleanup. the interface looks like this now: </desc> <cmt> replay and save last file </cmt> <cmt> store all waves and select on combobox </cmt> <cmt> functional last waves selection combobox </cmt> <cmt> functional last waves selection combobox </cmt>",export and replay generated wav
2931,"<desc> this is for #15749 and #23351 @tyriar the idea is that when storing a backup, callers can now associate metadata with the backup that can be returned when restoring the backup. we can use this metadata to: restore the file properties used for conflict detection (for #15749) restore the file properties used for indicating if a file was deleted on disk or not (for #23351) as you know, we use the first line in the backup for the original file resource already. e.g. file:///users/bpasero/desktop/file.txt contents... with my change, the metadata is being added after the url via json.stringify(): file:///users/bpasero/desktop/file.txt {""etag"":""someetag""} contents... the result will be a uri of file:///users/bpasero/desktop/file.txt with metadata {""etag"":""someetag""}. the space is the actual separator from uri to metadata. i chose it because a uri, when stored as string, will always have spaces escaped. there is one downside with this approach: opening code with a previous version after running with this version causes dirty files to appear twice, once with the correct uri, but once with a uri that contains the metadata. the reason is simple: we change the format of backups and an older version will happily treat the metadata as part of the uri. i think we can tolerate this though because: we do not crash, e.g. startup is still good the dirty file is still there, just twice we typically do not guarantee to be fully forwards compatible, e.g. opening code with an older version on the same directory as a newer code version should not crash, but does not guarantee full data recovery visually it would look like this: </desc> <cmt> hot exit - simplify model creation from backup </cmt> <cmt> hot exit - convert to async/await </cmt> <cmt> hot exit - move tests into node layer </cmt> <cmt> hot exit - implement support for metadata </cmt> <cmt> hot exit - polish </cmt> <cmt> hot exit - use # as separator for better forwards compatibilty </cmt> <cmt> hot exit - back to ' ' as separator </cmt>",hot exit - allow arbitrary metadata with backups
2932,"<desc> fix #13247. r? @alexcrichton  (or anyone else, really). </desc> <cmt> avoid injecting unfulfilled dependence in compiletest on libnative. </cmt> <cmt> two fixes to get make check-stage1 working. </cmt> <cmt> 1. fix a long-standing typo in the makefile: the relevant </cmt> <cmt> ctest_name here is rpass-full (with a dash), not </cmt> <cmt> rpass_full. </cmt> <cmt> 2. the rpass-full tests depend on the complete set of target </cmt> <cmt> libraries.  therefore, the rpass-full tests need to use </cmt> <cmt> the dependencies held in the csreq-prefixed variable, not </cmt> <cmt> the tlibrustc_default-prefixed variable. </cmt> <iss> make check-stage1 is broken </iss>",get make check-stage1 working again
2933,"<desc> remove hacks and wrappers, keep code in sync across our libraries and move spacy a few steps closer to only depending on packages with binary wheels see here:  serialization is hard, especially across python versions and multiple platforms. after dealing with many subtle bugs over the years (encodings, locales, large files) our libraries like spacy and prodigy have steadily grown a number of utility functions to wrap the multiple serialization formats we need to support (especially json, msgpack and pickle). these wrapping functions ended up duplicated across our codebases, so we wanted to put them in one place. at the same time, we noticed that having a lot of small dependencies was making maintainence harder, and making installation slower. to solve this, we've made srsly standalone, by including the component packages directly within it. this way we can provide all the serialization utilities we need in a single binary wheel. srsly currently includes forks of the following packages: ujson msgpack msgpack-numpy cloudpickle enhancement i have submitted the spacy contributor agreement. </desc> <cmt> wip: replace json/ujson with srsly </cmt> <cmt> replace ujson in examples </cmt> <cmt> use regular json instead of srsly to make code easier to read and follow </cmt> <cmt> update requirements </cmt> <cmt> fix imports </cmt> <cmt> fix typos </cmt> <cmt> replace msgpack with srsly </cmt> <cmt> fix warning </cmt>","replace ujson, msgpack and dill/pickle/cloudpickle with srsly"
2934,"<desc> @tomaugspurger as promised, this implements a handful of tests, and a few more can be ported from #23415, but the ea-specific tests haven't been started. the big missing piece is datetimearray._from_sequence, which i'm getting started on now in a new branch. closes #23586 </desc> <cmt> implement most of the rest of ea interface </cmt> <cmt> implement some tests for take, concat_same_type </cmt>",implement _most_ of the ea interface for dta/tda
2935,"<desc> this is a follow up of #109 triggered by twisted merge of #4330 </desc> <cmt> use twisted.web.client.agent for download requests (use of http/1.1) </cmt> <cmt> adds http11.httpdownloadhandler in scrapy.core.downloader.handlers </cmt> <cmt> renamed downloader to http11downloadhandler and some refactoring </cmt> <cmt> only for http, not https </cmt> <cmt> test on expected body length instead of request method (head case) </cmt> <cmt> restore handling of https </cmt> <cmt> http11 cleanup </cmt> <cmt> add http connection pool and custom ssl context factory </cmt> <cmt> enable persistent connections </cmt> <cmt> move ssl context factory to its own module and implement a non-ssl version that warns about pyopenssl support </cmt> <cmt> remove duplicate context factory handling for non-ssl support in http1.0 </cmt> <cmt> close pool connections before finishing tests </cmt> <cmt> empty bodies does not require a body producer </cmt> <cmt> adapt for singletons removals </cmt> <cmt> cleanup http connection pool on engine stop </cmt> <cmt> agents requires an instance of contextfactory </cmt> <cmt> implement download timeouts based on deferred cancellation </cmt> <cmt> add required files to support twisted 11.1 (precise) </cmt>",add http 1.1 download handler
2936,"<desc> the fix for  this pr is a rollback (git revert) of the specific change 8b795ab that caused the problem. i suggest doing this for a perfectly safe 3.9.4 rather than trying to redo the non-critical bugfix under duress as a rush over a significant portion of the worlds holiday.  fixing it properly can wait until a scheduled 3.9.5. </desc> <cmt> bpo-43710: revert ""bpo-42500: fix recursion in or after except (gh-23568) (#24501)"" </cmt> <cmt> this reverts commit 8b795ab5541d8a4e69be4137dfdc207714270b77. </cmt> <cmt> it changed the pythreadstate structure size, breaking the abi in 3.9.3. </cmt> <cmt> news entry </cmt>","rollback the 3.9 bpo-42500 fix, it broke the abi in 3.9.3"
2937,"<desc> additions to types: listeners add definitions to listen/remove listeners from a connection. prettier run prettier as per definetelytyped recommendation. to avoid mixing change and layout, it is split in separate commits. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: apache/tinkerpop@ddf7b98#diff-a974eb4fae74b0556e7ba669da6de50b if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> [@types/gremlin] run prettier </cmt> <cmt> [@types/gremlin] add listener functions to driverremoteconnection </cmt>",add missing methods to driverremoteconnection
2938,<desc> this pr converts the following files to ts: packages/gatsby/src/redux/reducers/nodes.js packages/gatsby/src/redux/tests/nodes.js packages/gatsby/src/redux/reducers/last-action.js packages/gatsby/src/redux/tests/snapshots/nodes.js.snap add new interfaces on: packages/gatsby/src/redux/types.ts and update related imports on: packages/gatsby/src/redux/reducers/index.js related to #21995 </desc> <cmt> change file type from js to ts </cmt> <cmt> change file type from js to ts </cmt> <cmt> update node reducer export method and types </cmt> <cmt> update redux types adding new action interfaces </cmt> <cmt> update redux nodes test adding ts requirements </cmt> <cmt> update nodes snapshot file </cmt> <cmt> update mapobject type </cmt> <cmt> covert last-action reducer to ts and update the related import </cmt>,migrate nodes reducer and last-action reducer to typescript
2939,"<desc> delete by query is a shortcut to search + delete. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. update by query is a shortcut to search + index. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. implementing compositeindicesrequest makes little sense as the indices that the request works against depend entirely on the inner search request. </desc> <cmt> deletebyqueryrequest to implement indicesrequest.replaceable </cmt> <cmt> delete by query is a shortcut to search + delete. deletebyqueryrequest gets serialized on the transport layer only when the transport client is used. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable </cmt> <cmt> updatebyqueryrequest to implement indicesrequest.replaceable rather than compositeindicesrequest </cmt> <cmt> update by query is a shortcut to search + index. updatebyqueryrequest gets serialized on the transport layer only when the transport client is used. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. implementing compositeindicesrequest makes little sense as the indices that the request works against depend entirely on the inner search request. </cmt>",update and delete by query requests to implement indicesrequest.replaceable
2940,"<desc> from epe-486 and auto-311, i was asked to add testing checkboxes to the pull request template for eosio: this benefits blockchain by encouraging developers to consider test cases while writing pull requests and submitting new contributions. this benefits automation by providing a convenient programmatic way to detect, track, notify, or act upon changes to the ci system or test framework(s), like we do with the other check boxes. more broadly, we all stand to benefit from a culture more focused on testing. the new template has been manually pasted into this pull request so you can see what it looks like, but github will not present the new template to users until it is merged to this repository's default branch: you must create templates on the repository's default branch. templates created in other branches are not available for collaborators to use. see the pull request templates heading on the about issue and pull request templates page of github's documentation for more information. see also pull request 9662 -- eos:develop pull request 9663 -- eos:blockvault pull request 9664 -- eos:develop-boxed pull request 9665 -- eos:release/2.0.x pull request 9666 -- eos:release/1.8.x select one: pull request template. select any that apply: none. none. none. none. </desc> <cmt> add ""testing changes"" section to the pull request template </cmt> <cmt> whitespace </cmt> <cmt> add italic emphasis on selection quantity </cmt> <cmt> colon </cmt>","add ""testing changes"" section to pull request template"
2941,"<desc> because getblocktxn requests for unknown blocks would trigger a disconnect, while a getblocktxn for known-old blocks would just be ignored, it should be possible to fingerprint a node by seeing which old, non-main-chain blocks trigger disconnect. the first commit removes the misbehaving score to eliminate this distinction. in the handling of cmpctblock messages, the handling for blocks that are announced that have too little work, or where the block was known but pruned, was busted -- for requested blocks, we would generate a getdata for the block, but for unrequested blocks, we'd fall through and try to process.  in particular, this means that announcing old cmpctblocks could cause a pruning node to redownload old blocks (potentially causing a fill-up-disk dos). the second commit fixes this by aborting processing of cmpctblock messages in this situation. please tag this for consideration in 0.13.0. </desc> <cmt> ignore getblocktxn requests for unknown blocks </cmt> <cmt> don't disconnect peers, or else we leak information that could be </cmt> <cmt> used for fingerprinting. </cmt> <cmt> ignore cmpctblock messages for pruned blocks </cmt> <cmt> also ignores cmpctblock announcements that have too little work.  this is to </cmt> <cmt> prevent disk-exhaustion dos. </cmt>","prevent fingerprinting, disk-dos with compact blocks"
2942,"<desc> test sources have been exempt from the bundled forbiddenapi signatures jdk-system-out that check among others usages of system.out.println and throwable.printstacktrace. with the removal of benchmarks in #15356, there is no need to relax this check for tests anymore. this pr: enables jdk-system-out checks on all sources removes the few remaining usages of println and printstacktrace removes two benchmark classes (probably missed in #15356) </desc> <cmt> remove python and javascript benchmark classes </cmt> <cmt> enable jdk-system-out forbidden api checks on test sources </cmt> <cmt> remove system.out.println and throwable.printstacktrace from tests </cmt>",forbid test sources to use system.out.println and throwable.printstacktrace
2943,<desc> changes based on suggestions on this pr  implemented and more test coverage added </desc> <cmt> repr description added to depends class </cmt> <cmt> repr description added to security subclass </cmt> <cmt> get rid of __repr__ in security since it will inherit from super </cmt> <cmt> make code format consistent with rest </cmt> <cmt> add desc for rest of the classes </cmt> <cmt> update fastapi/params.py </cmt> <cmt> remove trailing whitespace </cmt> <cmt> implement __repr__ </cmt> <cmt> fix formatting </cmt> <cmt> formatting again </cmt> <cmt> ran formatting </cmt> <cmt> added basic testing </cmt> <cmt> get remaining code for params.py </cmt> <cmt> basic tests added to rest of the classes </cmt>,implement changes for __repr__ tests
2944,"<desc> fixes #7070, #7080, and #7260. </desc> <cmt> core: remove compile_read_write_paths() </cmt> <cmt> from 6c47cd7d3bf35c8158a0737f34fe2c5dc95e72d6, runtimedirectory= and </cmt> <cmt> their friends also imply bindpaths=. thus, implying readwritepaths= </cmt> <cmt> is meaningless. </cmt> <cmt> core: readwritepaths= and friends assume '+' prefix when bindpaths= or freinds are set </cmt> <cmt> when at least one of bindpaths=, bindreadonlypaths=, rootimage=, </cmt> <cmt> runtimedirectory= or their friends are set, systemd prepares </cmt> <cmt> a namespace under /run/systemd/unit-root. thus, readwritepaths= </cmt> <cmt> or their friends without '+' prefix is completely meaningless. </cmt> <cmt> so, let's assume '+' prefix when one of them are set. </cmt> <cmt> fixes #7070 and #7080. </cmt> <cmt> test: add test for readonlypaths= with runtimedirectory= </cmt> <cmt> core/execute: runtimedirectory= or friends requires mount namespace </cmt> <cmt> since #6940, runtimedirectory= or their friends imply bindpaths=. </cmt> <cmt> so, if at least one of them are set, mount namespace is required. </cmt> <cmt> core/load-fragment: fix alignment </cmt> <cmt> core/execute: do not create runtimedirectory= under private/ sub-directory </cmt> <cmt> runtimedirectory= often used for sharing files or sockets with other </cmt> <cmt> services. so, if creating them under private/ sub-directory, we cannot </cmt> <cmt> set dynamicuser= to service units which want to share something through </cmt> <cmt> runtimedirectory=. </cmt> <cmt> this makes the directories given by runtimedirectory= are created under </cmt> <cmt> /run/ even if dynamicuser= is set. </cmt> <cmt> fixes #7260. </cmt> <cmt> man: update documents for runtimedirectory= and friends </cmt>","fixes related to runtimedirectory=, readwritepaths= and dynamicuser="
2945,"<desc> when a tabbarview is nested in a page of another tabbarview, there will be particular scenarios that will throw an exception. to reproduce this issue, two conditions must be true: tap on a tab that is adjacent to a tab containing a nested tabbarview the nested tab has to be in between the initial tab and the tab that was tapped on (ie. current index = 0, tap on tab at index 3 when tab at index 2 has nested tabbarview) this happens when the framework tries to build _pageposition, then dispose of it before applyviewportdimension has the chance to be called to set pixels to a non-null value based on the size of the viewport. this fix adds a flag to determine if applyviewportdimension is invoked before dispose. if it hasn't been, then dispose will set pixels to an arbitrary value before attempting to dispose of it. first exception: this is due to the introduction of #29188, which happens because the initial swap that is necessary for warping causes the nested page that is swapped but not shown to be disposed of before applyviewportdimension to be called. second exception: this one is caused by the animation of the page during warp. the last frame does not build before the second setstate is called to swap the children back to their original positions, causing the nested page to be built and disposed of before applyviewportdimension can be called. todo: add an issue to track adding a test to ensure that the warp animation for tabbarview builds its last frame before setstate is called to re-swap the children back to their original locations. #32054 track the potential need for a more robust swapping mechanism that doesn't cause pages that are not shown to be built and immediately disposed of. #32056 related issues fixes #18756 i added the following tests: a regression test to ensure that the exception does throw when a tab adjacent to nested tab is selected. it tests for the first exception case mentioned above. a separate issue will be created to track writing a test for the second exception case. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> (wip) set pixels to 0 at dispose time </cmt> <cmt> add flag to determine if pixels is set by viewport </cmt> <cmt> (wip) attempt at adding nested tabs regression test </cmt> <cmt> added const keywords where needed in test </cmt> <iss> exception while scrolling through tabbar navigation </iss>",fix exception on nested tabbarview disposal
2946,<desc> this pr migrate prometheus bucket to metrics stability framework. the metrics stability framework has provided bucket functionality. (refer: #82583) does this pr introduce a user-facing change?: </desc> <cmt> migrate prometheus bucket functionality to metrics stability framework. </cmt> <cmt> update bazel by hack/update-bazel.sh </cmt>,migrate prometheus bucket functionality to kube-metrics for proxy metrics
2947,"<desc> this change addresses performance issues related to the general behavior of visiteachchild. the current visiteachchild function is highly generic, which make it difficult for hosts to optimize. this change adds individual, more optimized visiteachchildof* functions for the most common nodes in our current test suite. also fixes some issues when compiling processdiagnosticmessages following ""jake clean"". </desc> <cmt> adds streamlined child visitors for frequently visited nodes. </cmt> <cmt> fix compiler issue after merge </cmt> <cmt> fix unresolved merge issue. </cmt> <cmt> remove unused types. </cmt>",optimize frequent paths in visiteachchild.
2948,"<desc> use 128 instead of 64 bits for defpath hashes, like we do for everything else. collision probability is unnecessarily high with 64 bits. also change the representation of ich::fingerprint from fingerprint([u8; 16]) to fingerprint(u64, u64) which is better for hashers like fxhasher. </desc> <cmt> use in-memory representation for fingerprint that is more amenable to hashing. </cmt> <cmt> use 128 instead of 64 bits for defpath hashes </cmt>",use more bits for defpath hashes
2949,"<desc> related pr = #2657 and #2792 in this pr, sparse matrix-vector multiplication and direct linear solvers (llt, ldlt, lu) are supported. </desc> <cmt> sparse matrix multiply with vector and linear solver </cmt> <cmt> add sparse matrix linear solver </cmt> <cmt> add spmv test and linear solver test </cmt>",experimental spmv and direct linear solvers
2950,"<desc> closes #6280 </desc> <cmt> rt: move win32_require out of the rust_kernel type </cmt> <cmt> this is only used on rust_rng, which i am trying to extricate from </cmt> <cmt> the kernel. </cmt> <cmt> rt: eliminate the dependency on rust_kernel from rust_rng </cmt> <cmt> core::rt: add a test that rng works with new tasks </cmt>",make core::rand work with newsched
2951,"<desc> fixes #13393. see also pr #12316 fixes linalgerror when using spectral clustering with the amg solver this pr is derived from the previous pr #12316 submitted by andrew knyazev (lobpcg). in that pr, andrew fixed issue #13393 and also added a new label assignment option 'clusterqr'. it was requested that the pr be split to separate the fix and the new label assignment functionality. this pr contains andrew's fix for the amg bug. </desc> <cmt> change amg tolerance default & laplacian shift (fixes #13393) </cmt> <cmt> add spectral clustering test for amg solver </cmt> <cmt> update docs with edits from andrew knyazev (& some fixed) </cmt> <iss> amg spectral clustering fails just after a few iterations of lobpcg with "" leading minor of the array is not positive definite"" </iss>",fix for spectral clustering error when using 'amg' solver
2952,"<desc> commit message: make server::options available to the ssl handshaker factory this allows the handshaker to detect the run mode (server::options::mode) and use that to bypass checks required for serving but not for validation. risk level: low testing: added and ran unit tests docs changes: n/a release notes: n/a platform specific features: n/a </desc> <cmt> clean up handshakerfactorytest </cmt> <cmt> use using declarations where appropriate, fix local variable naming, </cmt> <cmt> use a named constant for the shared magic string. </cmt> <cmt> add server::options to handshakerfactorycontext </cmt> <cmt> this allows the handshaker to detect the run mode </cmt> <cmt> (server::options::mode) and use that to bypass checks required for </cmt> <cmt> serving but not for validation. </cmt> <cmt> add test for handshakerfactorycontext passing objs </cmt> <cmt> test that the handshakerfactorycontext created by the tls transport </cmt> <cmt> socket impl passes through options from the parent transport socket </cmt> <cmt> factory context. </cmt>",make server options available to the handshaker factory
2953,"<desc> unzip is handled by busybox on android, and it needs the -d param at the end, otherwise it shows the usage options and does not unzip the file. </desc> <cmt> add missing dalvik opcode </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> conflicts: </cmt> <cmt> libr/asm/arch/dalvik/opcode.h </cmt> <cmt> fix unzip param order on android's busybox </cmt>",fix unzip param orders in android's busybox
2954,"<desc> closes #10611 closes #10678. the x-axis for scatter plot and hexbin plot disappears when colorbar is included. this seems to be because colorbar axis is looped through in _handle_shared_axes: pandas/pandas/plotting/_core.py line 426 8a58303 _handle_shared_axes(axarr=all_axes, nplots=len(all_axes), after discussing with @tomaugspurger (issue #10611), we decided to try adding the attribute __is_pandas_colorbar to colorbar axis object and skipping it during handling of shared axes. i've done some tests that seem to fix the issue. but we may need more tests: %matplotlib inline import matplotlib.pylab as pl from mypandas import pandas as pd import numpy as np random_array = np.random.random((1000,3)) df = pd.dataframe(random_array,columns=['a label','b label','c label']) df.plot.scatter('a label','b label',c='c label', patch_mode_flag = false);pl.title('pandas current version'); df.plot.scatter('a label','b label',c='c label', patch_mode_flag = true);pl.title('patch fixing x-axis'); df.plot.hexbin('a label','b label', gridsize=25, patch_mode_flag = false);pl.title('pandas current version'); df.plot.hexbin('a label','b label', gridsize=25, patch_mode_flag = true);pl.title('patch fixing x-axis'); </desc> <cmt> removed colorbars from _handle_shared_axes when called by scatterplot and hexbin </cmt> <cmt> removed colorbars from _handle_shared_axes when called by scatterplot and hexbin </cmt> <cmt> added a debug global variable </cmt> <iss> xticks missing for scatter plots with colors </iss> <iss> hexbin plots does not display x label and xtick labels </iss>",scatter plot and hexbin plot lose x-axis when colorbar is included.
2955,<desc> this pull request enables the build/include_alpha cpplint filter rule for the atom/ directory which checks for alphabetical ordering of #include statements. this was mostly being followed implicitly but now it is explicitly checked for. most files were already  in compliance and a few had minor changes needed. something worth linting for?  / </desc> <cmt> enable alphabetical include order lint filter </cmt> <cmt> sort includes alphabetically </cmt>,enable alphabetical include order cpplint rule
2956,"<desc> if a diagnostic request is actually canceled, we will throw away the type checker as we cannot be certain that it is still in a usable state. i recommend reviewing this with ?w=1 to make the diff easier to understand. </desc> <cmt> make type-checking cancellable. </cmt> <cmt> conflicts: </cmt> <cmt> src/compiler/checker.ts </cmt> <cmt> src/compiler/program.ts </cmt> <cmt> src/compiler/types.ts </cmt> <cmt> src/services/services.ts </cmt>",make it possible to cancel requests to get diagnostics.
2957,"<desc> mainly for ""hygiene""; add comments to remind people to consider keeping these win sync with the vendored package update binary-commit (userland-proxy) for libnetwork:  moby/libnetwork@fcf1c3b...20dd462 update tomlv binary to match vendor, and use mit license: burntsushi/toml@9baf8a8...a368813 ping @vdemeester @akihirosuda ptal </desc> <cmt> add notes about keeping versions in sync </cmt> <cmt> sync version of userland-proxy with libnetwork vendor </cmt> <cmt> update tomlv for mit license </cmt> <cmt> the burntsushi/toml code is now re-licensed as mit. while </cmt> <cmt> the vendored package was already updated, the tomlv binary </cmt> <cmt> used was still using the old license type. </cmt>",sync binary commits with vndr
2958,"<desc> issue: #12531 added functionality to resolved type aliases and extract enum types from the compodoc generated json file added test cases for named enum types yes, there is a new enum example component possibly. i was not able to get the base enum type with auto-incrementing number values to work correctly. it will generate the select input, though switching between the values does not update the component. </desc> <cmt> add miscellaneous property to compodocjson type </cmt> <cmt> correct spelling </cmt> <cmt> add resolution for type aliases from compodoc gen </cmt> <cmt> add test component for enums </cmt> <cmt> add enums check for compodoc types </cmt>",fix type aliases and enum types from angular compodoc json
2959,"<desc> remove a user from a team, or as a regular user, leave the team. the last modal step should be the one in the screenshot. </desc> <cmt> update leave team modal </cmt> <cmt> stories </cmt> <cmt> remove user modal </cmt>",change modals for remove user from team && leave team
2960,"<desc> currently there are two know issues when compiling with intel icc: the operator() in iterator causes warning the use of internal_iterator causes error the first issue can be resolved by replacing the operator() with a converting constructor and assignment. because the existence of the copy constructor may bring ambiguity, i removed it and the copy constructor will be defined implicitly. the second issue is fixed by adding a struct keyword in front of the type name. </desc> <cmt> add converting constructors for iterator </cmt> <cmt> add struct keyword in front of internal_iterator </cmt> <cmt> remove the iter_impl<const basic_json> copy constructor and copy assignment </cmt>",#550 fix iterator related compiling issues for intel icc
2961,"<desc> passing constant values helps opencl to tune instruction paths. for example, unroll loops (#pragma unroll). performance gain is about 2x ~ 3x faster than before (on an amd hd5850m gpu and an a8m apu's gpu). </desc> <cmt> replace create with ensuresizeisenough thus buffer objects can be reused. </cmt> <cmt> optimize bfmatcher by passing macros. </cmt> <cmt> further optimize bfmatcher by passing macros. </cmt> <cmt> fix build error on linux. </cmt> <cmt> rename test case category and code clean up. </cmt> <cmt> capitalize macro namings. </cmt>",optimize bfmatcher by passing macros into build options
2962,"<desc> fix pojoutil realize type convert not support subclasses of 'java.util.date' #2499 the type convert was modified to support the 'java.util.date' subclass org.apache.dubbo.common.utils.compatibletypeutils.java org.apache.dubbo.common.utils.pojoutilstest.java org.apache.dubbo.common.utils.compatibletypeutilstest.java follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskiptests & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. </desc> <cmt> solve time, timestamp, sql. date type conversion problems </cmt> <cmt> add ut </cmt>",[dubbo-2499]fix pojoutil realize type convert not support subclasses of 'java.util.date' #2499
2963,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. this pr includes changes to d3-format and d3-array to bring them up to their latest minor versions (both v1.2). note that the changes to d3-array also include a definitions bug fix: d3.tickstep(...) returns a number value instead of an array of number. closes #15600 . closes #15902 . @gustavderdrache pls review and approve. thx. t </desc> <cmt> update d3-format to v1.2 </cmt> <cmt> * [feature] adds support for optional ""percent"" suffix in locale definition. </cmt> <cmt> * added tslint.json file </cmt> <cmt> [d3-array] update to version 1.2 </cmt> <cmt> * [feature]: add tickincrement(...) </cmt> <cmt> * [fix]: fix incorrect  return type of tickstep(...). the correct return type is number instead of number[] </cmt> <cmt> * [chore]: updated related comments </cmt> <cmt> [d3] update minor version to 4.8 </cmt> <iss> d3-format update definitions to v1.2 </iss> <iss> d3-array update to version 1.2.0 </iss>",d3 update to 4.8.0 (d3-array 1.2 [feature/fix] and d3-format 1.2 [feature])
2964,"<desc> original pull-request #16865 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> test for issue #16862 </cmt> <cmt> blind fix </cmt> <cmt> update 01560_timeseriesgroupsum_segfault.sql </cmt> <cmt> update aggregatefunctiontimeseriesgroupsum.h </cmt> <cmt> fix for issue #16862 </cmt>",cherry pick #16865 to 20.8: fix for issue #16862
2965,"<desc> fixes #5598. background for quite a while, it was the case that when seeking the contextual type of a value, we would always get its apparent type afterwards. this was usually the behavior desired - otherwise, you'd typically run into problems with things like object literals and index signatures. during recent work on string literal types, this turned out to be undesirable because the widened type of a string literal type is the global string type. this was effectively useless because we needed to check whether the contextual type was string literal type or a union with a string literal type, so we separated out the concept of grabbing an expression's contextual type (with getcontextualtype) with grabbing the apparent type of that contextual type (getapparenttypeofcontextualtype). one thing missed in that change was that internally, getcontextualtype was calling getapparenttypeofcontextualtype unnecessarily. this means that if you had a parenthesized string literal, it could never be contextually typed by a string literal type - it would instead get contextually typed by the global string type. the reason the apparent type was necessary in some places is that when ""digging in"" to a type, it's necessary to get the apparent type to recognize its available members, the shape of its type constraint, etc.; however, the apparent type is not needed in simple cases where we simply propagate the type back. </desc> <cmt> added test for parenthesized string literals. </cmt> <cmt> added other tests for string literal types. </cmt> <cmt> accepted baselines. </cmt> <cmt> added tests for string literal types used as generic constraints. </cmt> <cmt> only get the apparent type when necessary. </cmt> <cmt> accepted baselines. </cmt>",only get the apparent type of a contextual type when needed
2966,"<desc> this one should fix #805. </desc> <cmt> refactor condition in printstatementsequence, add new helper function. </cmt> <cmt> add new test cases. </cmt> <iss> two blank lines are inserted between a `case` statement and a comment, except on windows </iss>",fix additional empty line switch case comment
2967,"<desc> issue reference #3172 . i added .md files to the formatting scripts. i'm open to any changes for formatting you think best, as i just used mainly the default options and tab spacing. there are some cases where mutli-line code blocks were condensed to a single line, which may not be best for readability in documentation. </desc> <cmt> add prettier overrides for markdown </cmt> <cmt> add prettier markdown formatting to npm scripts </cmt> <cmt> apply prettier formatting on markdown docs </cmt>",use prettier.js for consistent markdown formatting #3172
2968,"<desc> to safely compile for the web, we need to ensure that unsupported code is not reachable. separately, we would like to explore publishing a packaged version of foundation for external consumption. this pr packages us as much of the platform-specific code into libraries based on io and web so they can be conditionally exported/imported. based on #32952 i added the following tests: existing tests cover io bits, web bits still wip. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> move io and web foundation types into libraries </cmt> <cmt> remove dead documentation and provide basic example of defaulttargetplatform for web </cmt> <cmt> try hiding voidcallback </cmt> <cmt> fix analyzer errors. </cmt> <cmt> update libraries </cmt>",use conditional imports for flutter foundation libraries
2969,<desc> added some of the missing functions from the api reference documentation and fixed a couple things in the time series guide. </desc> <cmt> added series functions to api doc. </cmt> <cmt> adding dataframe methods to api reference. </cmt> <cmt> minor fixes to time series doc. </cmt>,update to api reference documentation.
2970,"<desc> this is a small doc fix that includes bool as part of the types that is supported in mobile, as bool is clearly invoked in the following define (see ln 105 and ln 135) in mobile platform: #define tf_call_bool(m) m(bool) </desc> <cmt> fix doc in tf_call_ when defined(is_mobile_platform) && !defined(__android_types_full__) </cmt> <cmt> this is a small doc fix that includes bool as part of the types </cmt> <cmt> that is supported in mobile (is_mobile_platform && !__android_types_full__), </cmt> <cmt> as bool is clearly invoked in the following define. </cmt> <cmt> also add bool to android full version. </cmt>",fix doc in tf_call_ when invoked in mobile platform
2971,"<desc> description:  checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> upgrade mypy to 0.720 </cmt> <cmt> turn on mypy unreachability warnings, address raised issues </cmt>","upgrade mypy to 0.720, turn on unreachability warnings"
2972,"<desc> clean-up, moving protobuf code to the pb dir moves interop test generated code and supporting library to the pb directory also added proper binaries for the interop client and server; gem install grpc now installs these also removes the minitest dependency (i.e, begins to address the points raised in #2532) adds a test that validates code generation using the health service (does #635 for ruby) </desc> <cmt> update the generated code for the interop service. </cmt> <cmt> - updates the code generated for the interop service </cmt> <cmt> - moves the generated interop service/client from bin to pb </cmt> <cmt> also </cmt> <cmt> - removes an empty file from the health pb directories </cmt> <cmt> reorganize interop test files. </cmt> <cmt> - moves the client/server behaviour to pb/test </cmt> <cmt> - deprecate current bin/interop/interop_{client,server}.rb </cmt> <cmt> - adds executable endpoints to bin </cmt> <cmt> - grpc_ruby_interop_{client, server} </cmt> <cmt> - these will be added to the ruby bin path when the grpc gem </cmt> <cmt> gem is installed, making them easier to execute </cmt> <cmt> removes the dependency on minitest </cmt> <cmt> - replaces it with a simple assertion function </cmt> <cmt> adds a test for ruby code generation. </cmt>",grpc ruby mv interop test to pb
2973,"<desc> these commits should fix all defects detected by coverity. </desc> <cmt> jsonservicedescription: fix cid 719179 and 719180 </cmt> <cmt> jsonrpc: fix cids 1194413, 1194414, 1194415, 1194416, 1213841 and 1213842 </cmt> <cmt> jsonrpc: fix cids 1228813, 1228816, 1228817, 1228818, 1228823 and 1228824 </cmt> <cmt> jsonrpc: fix cid 1273979 </cmt>",fix defects detected by coverity
2974,"<desc> this change will not change the functionality,  it just changes the internal implementation detail. jwkscache holds both config and cache.  currently,  the whole jwkscache object is in the thread local slot, but actually, only the  cache data needs to be in in the thread local. this change will move the thread local data inside jwksdataimpl,  only stores its {jwks, and expire} into thread local. move jwkscache object out of thread local. this change is in preparation to support async fetch of remote_jwks proposed in #14556 (comment). detail changes: created tls for {jwks, expire} inside jwksdataimpl removed tls for jwkscache in filterconfigimpl removed enable_shared_from_this from filterconfigimpl risk level:  low testing:  unit-tested. docs changes: none release notes: none </desc> <cmt> move thread local inside jwksdata </cmt> <cmt> move thread local down to lower level </cmt> <cmt> use make_unique_ptr </cmt>",move threadlocal from jwkscache into jwksdataimpl
2975,"<desc> #2957 </desc> <cmt> allow mixing of args uid and gid </cmt> <cmt> reversed the order of setting uid and gid. when uid is set first, the process doesn't have permission to set the gid. so they've been swapped. </cmt> <cmt> give the user all of its group's rights </cmt> <cmt> when using the option --uid <uid> the process now runs with all of that user's permissions, including its groups. </cmt> <cmt> allow mixing of args uid and gid </cmt>",given --uid add all its gids automatically
2976,<desc> r? @petrochenkov extracted out of a larger pr. </desc> <cmt> ast_validation: comments -> doc comments </cmt> <cmt> syntax::parse::parser: convert unnecessary '&mut self's to '&self'. </cmt> <cmt> parse_bottom_expr: extract common 'return' out. </cmt> <cmt> minor cleanup in parse_assoc_expr_with. </cmt>,assorted cleanup in parser & ast validation
2977,"<desc> added the wallpaper.png (used as a placeholder background) to installer file and set the min/max width of the fz preview control. added fz preview control disabled state: #15165 linked issue: #15165 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> added disabled state </cmt> <cmt> added wallpaper image to installer file </cmt>",added disabled state to fz preview control
2978,"<desc> add missing methods on vectortile class definition add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> + [mapnik] adding methods of the class vectortile as described in </cmt> <cmt> + fix multiple semicolon at definitions </cmt>",+ [mapnik] additional method definitions on the class vectortile
2979,"<desc> fixes #19637, #8710. as suggested in #19641, this pr removed validation from the calibratedclassifiercv predict_proba function and replaced x.shape[0] with _num_samples(x). regression testing has also been added. </desc> <cmt> fix predictions for calibratedclassifiercv with pipeline </cmt> <cmt> fix pep8 warnings </cmt> <iss> calibratedclassifier on pipelines </iss>",fix calibrated classifier cv predictions with pipeline
2980,<desc> redoes #8612 to instead just re-up the existing 2.3.2 tag instead of cutting a new release. update jquery dependencies for bower to avoid some bugs bump to recess 1.1.9 update all links to point to @twbs org and new getbootstrap.com point download urls to the release tag instead of a local zip also bumps some copyright across the project to 2013. </desc> <cmt> component.json -> bower.json; adjust jquery to >=1.8.0 <2.1.0 </cmt> <cmt> bump recess to 1.1.9 </cmt> <cmt> twitter/bootstrap => twbs/bootstrap in links etc. </cmt> <cmt> update urls to account for v3 rc1 soft launch </cmt> <cmt> version bump </cmt> <cmt> add changelog entry </cmt> <cmt> more date changes </cmt> <cmt> point changelog in docs to releases on github </cmt> <cmt> point docs downloads to tag in twbs org </cmt> <cmt> revert to 2.3.2 tag instead </cmt> <cmt> finish bumping copyright </cmt>,bump 2.3.2 dependencies and docs links for v3 rc1
2981,"<desc> although the new lite interface does support float models as well, the current android demo app does only support quantized models. furthermore, it isn't obvious to transfer the code from the quantized version to the floating point model. based on this discussion i integrated the inception-v3 slim model as an alternative to the existing mobilenet. remaining todo: the confidence scores returned by the inception net are not in [0,1] yet. besides that, the inference itself seems to work. so the correct results are listed on top, but the confidence score isn't normalized. maybe the given model doesn't include a softmax layer and ends with the logits? i'm not sure about this. any help is appreciated. </desc> <cmt> make imageclassifier abstract and introduce new concrete subclasses </cmt> <cmt> refactor labelprobarray, because the tensorflow interface doesn't </cmt> <cmt> support boxed data types </cmt> <cmt> bugfix </cmt> <cmt> add todo </cmt> <cmt> reformat </cmt> <cmt> change the readme to reflect the latest changes </cmt>",add support for floating point models as inception-v3
2982,"<desc> this is a follow-up pr to #7612 fixes small part of #7465, so that we won't create file watcher every time on file updating. when running cargo run -- run --watch --unstable foo.js and update the content of foo.js, it seems like i've got results as expected. the integration test run_watch fails locally right now though. i'm looking into it. </desc> <cmt> create single watcher for whole watch process </cmt> <cmt> move wach_path to the top </cmt> <cmt> try fix </cmt> <cmt> remove unwatch </cmt> <cmt> impl simplistic debouncer for watcher </cmt> <cmt> refactor debounce to be awaited, remove select to fix race condition </cmt> <cmt> cleanup and comments </cmt> <cmt> remove unnecessary mutex </cmt> <cmt> use select! to handle debounce events </cmt> <cmt> rename _self -> self_mut </cmt> <cmt> fix poll_next implementation </cmt> <cmt> use std::mpsc instead of tokio's </cmt> <cmt> call wake_by_ref </cmt> <cmt> fix </cmt> <cmt> add sleep </cmt>",create single watcher for whole process
2983,"<desc> completes #12202 fix abandoned by @parul-l. modifications made as per @amueller and @adrinjalali: replaced random data with an image from sklearn image dataset; reformated the output. this completed fix results from reshama shaikh's push to close all prs opened during wimlds's scikit-learn sprint in sep. 2018. yes, reshama is herding cats! cc: @reshamas </desc> <cmt> finalizes fix for #12202 from abandonned pr by @parul-l </cmt> <cmt> completes 12202 fix abandoned by @parul-l </cmt> <cmt> completes 12202 fix abandoned by @parul-l </cmt>",doc adds an example to patchextractor
2984,"<desc> after previous pr #1552, stirngstore not actually does any cleanup. it just erases keys to stale data, not the data itself. now that behavior was fixed and stringstore cleans up correctly. sorry for the inconvenience. it is a bug fix. i have submitted the spacy contributor agreement. </desc> <cmt> stringstore now actually cleaned </cmt> <cmt> do not lose docs in ref tracking </cmt> <cmt> merge github.com:explosion/spacy </cmt> <cmt> swap keys in proper place </cmt> <cmt> remove unnecessary clear of the hits </cmt>",actually reset caches in pipe [wip]
2985,"<desc> some clients are already using protobuf v2 as part of their application and would need a lot of work to move, but tensorflow requires v3. this script patches the protobuf source code after downloading it to put it into a google::protobuf3 namespace, and alters all the necessary tensorflow code to compile with this new namespace. this allows the v3 library to be linked into applications alongside v2 without causing linker errors. </desc> <cmt> added protobuf renaming script </cmt> <cmt> post-process protobuf generated source files to use new namespace </cmt> <cmt> removed backup files </cmt> <cmt> updated protoc scripts for version renaming </cmt>",support a separate namespace for the protobuf library
2986,<desc> fixes #6209 support geturl support getbigdecimal </desc> <cmt> refactor change yamlruleschemametadata same with  ruleschemametadata </cmt> <cmt> change for cr </cmt> <cmt> add test of default constructor </cmt> <cmt> support url and bigdecimal data </cmt> <iss> support more java types for  getobject with type method </iss>,support more java types for getobject
2987,"<desc> dalli 2.2.x was released, so this is safe for merge now / </desc> <cmt> let's run action pack tests with dalli </cmt> <cmt> there is no memcache gem left in repo. </cmt> <cmt> more fixes for action pack tests with dalli. </cmt>",use dalli for memcache session store
2988,"<desc> just like in #9760, we can't actually use the uwp file picker api, because it will absolutely not work at all when the terminal is running elevated. that would prevent the picker from appearing at all. so instead, we'll just use the shell32 one manually. this also gets rid of the confirmation dialog, since the team felt we didn't really need that. we could maybe replace it with a toast (#8592), but meh closes #11356 closes #11358 this is a lot like #9760 introduced in #11062 megathread: #9700 </desc> <cmt> allows the dialog to be opened when elevated. moves some helpers around </cmt> <cmt> make it act like a .txt export, in downloads </cmt> <cmt> comments </cmt> <iss> [1.12] exporting text fails when running elevated (presumably we can't open the file picker elevated) </iss> <iss> [1.12] we can probably just ditch the confirmation dialog when exporting text </iss>",replace the uwp file export with the shell32 one
2989,"<desc> as per issue #969. preview result at johannesmoene/catch. it appears to me that adding some titles could improve the reading experience. for example: tutorial in the tutorial and reference in the reference. regards, martin (joahannes) moene </desc> <cmt> add html anchor 'top' </cmt> <cmt> let toplevel links to .md files link to .md#top </cmt>",link to top of content
2990,"<desc> all compatible conversions with tests. </desc> <cmt> add tests </cmt> <cmt> adapter for batchnorm opset 8 to 9 </cmt> <cmt> adapter for upsample opset 8 to 9 </cmt> <cmt> adapter for scan opset 8 to 9 </cmt> <cmt> update convert.h file </cmt> <cmt> fix syntax error </cmt> <cmt> add type annotations </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> check node type for cast operator </cmt> <cmt> empty commit to rerun checks </cmt> <cmt> add test for min, msx, mean and sum operators </cmt> <cmt> add adapters for min, max and mean operators </cmt>","version conversion of min, max, mean from opset 7 to 8"
2991,"<desc> currently, the decisions regarding which translog generation files to delete are hard coded in the interaction between the internalengine and the translog classes. this pr extracts it to a dedicated class called translogdeletionpolicy, for two main reasons: simplicity - the code is easier to read and understand (no more two phase commit on the translog, the engine can just commit and the translog will respond) preparing for future plans to extend the logic we need - i.e., retain multiple lucene commit and also introduce a size based retention logic, allowing people to always keep a certain amount of translog files around. the latter is useful to increase the chance of an ops based recovery. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> extract interfaces </cmt> <cmt> java doc tweak </cmt> <cmt> wip </cmt> <cmt> translog tests compile </cmt> <cmt> translog tests pass </cmt> <cmt> remove ontranslogrollover as it's not needed for now </cmt> <cmt> simplification and removal of future stuff </cmt> <cmt> update java docs </cmt> <cmt> tell combineddeletionpolicy of open mode so it can be smarter. </cmt> <cmt> introducing indexcommitref </cmt> <cmt> # conflicts: </cmt> <cmt> #	core/src/main/java/org/elasticsearch/index/engine/internalengine.java </cmt> <cmt> #	core/src/main/java/org/elasticsearch/index/shard/indexshard.java </cmt> <cmt> #	core/src/test/java/org/elasticsearch/index/engine/internalenginetests.java </cmt> <cmt> a little test to test translog min reference advance </cmt> <cmt> some java docs </cmt>",introducing a translog deletion policy
2992,"<desc> for the autocomplete feature to work properly (while doing power-rename) we need to handle all previous search and replace items and also keep it as most recently used (mru) list. previously those items were kept in registry, and goal of this pr is to move them to persistent json data file. implemented mru list handler with persistent json storage. migration from registry is supported. support  on the run changes in mru list size. always check if json data file has changed since we loaded it last time, and do reload if needed. enabled flag is also migrated from registry. pr checklist applies to #2011 </desc> <cmt> handle most recently used search/replace strings withing settings. </cmt> <cmt> check for last modified time of json file and reload it if needed. </cmt> <cmt> handle changes in mru search / replace lists size </cmt> <cmt> improve handling of changes in mru list size </cmt>",migrate power rename mru lists from registry to json
2993,"<desc> removed dashcamplayer (the feature is replaced by common/image.js"") improving pnc monitor performance by reducing chart update frequency in pncmonitor, categorizing planning/control plots into different tags. </desc> <cmt> dreamview: using tabs to categorize pnc plots </cmt> <cmt> dreamview: removed dashcamplayer </cmt> <cmt> dreamview: improving pnc monitor performance by reducing chart update frequency </cmt> <cmt> webpack dv </cmt>",add tags to pncmonitor & cleanup
2994,"<desc> fixes #90 . updated the combostyle and progmoderadiobuttonstyle to set istextscalefactorenabled to true so that the text size for these controls will scale according to the system settings. manually tested the text size changes under different scaling percentages. </desc> <cmt> added bug report and feature request issue tempaltes </cmt> <cmt> bug report and feature request templates </cmt> <cmt> copied pull_request_template.md to .github folder </cmt> <cmt> issuetemplates </cmt> <cmt> updated unitconverter comboboxstyle to set istextscalefactorenabled = true </cmt> <cmt> updated the programmer operator button style to set istextscalefactorenabled to true. </cmt> <iss> list items of the combo box in ""currency converter"" window are not adapting under 200 and 300 percent text scaling. </iss>",updated unitconvert combobox and programmer mode radio button styles to enable istextscalefactorenabled
2995,"<desc> part of #29692. </desc> <cmt> particles: properly initialize angular velocity parameter </cmt> <cmt> right now it would take garbage values when loading scenes, </cmt> <cmt> which could end up written to the scene file. </cmt> <cmt> cpuparticles: set linear velocity to 0, like gpu particles </cmt>","fix uninitialized angular velocity, fix inconsistency in linear velocity between cpu and gpu particles"
2996,"<desc> removing the check for user that was added recently (i added it when i added the same check but without a user for the auto resolve message, and now need to remove this) </desc> <cmt> fixing auto resolve logic </cmt> <cmt> fixing test </cmt> <cmt> reverting this logic back to how it was </cmt>",fix(workflow) reverting statusitem logic
2997,"<desc> this allow the filesystem scan thread to get the class_name scripts without loading extra resources. also added a get_dependencies() method to the gdscript resource loader, so now the preloaded resources are also included as dependencies when exporting. also added a function to fileaccess to get the file as a string, since it's not trivial to do. should fix #17513. </desc> <cmt> add function to get string from fileaccess </cmt> <cmt> add a dependency search mode for gdscript parser </cmt> <cmt> - this mode avoids loading any other resource. </cmt> <cmt> - search for class_name now uses this mode, to avoid loading in the scan </cmt> <cmt> thread. </cmt> <cmt> - implement get_dependencies() for gdscript loader, now exporting </cmt> <cmt> dependencies only should include the preloaded resources. </cmt> <iss> resource references from gdscript not followed when exporting w/dependencies </iss>",add a parse mode for gdscript which doesn't load dependencies
2998,<desc> allow void returns in catch/then blocks support union types for catch handlers that really need to return a different type than the original promise allow calling fromnode for a callback that doesn't expect a result parameter </desc> <cmt> allow calls to fromnode without a result parameter in the callback </cmt> <cmt> added better catch definitions that pass through the original promise type or type union of promise|rejection type </cmt> <cmt> promise.then definitions that allow void in the error handler </cmt>,"bluebird catch, then, fromnode improvements"
2999,"<desc> wrapped sections within <section> tags on the /manage page. refactor the layout of the advanced plugin manager page from a table to use <section> tags. also set a margin between sections to add ""breathability"" through vertical spacing. screenshots manage page before manage page after plugins advanced before plugins advanced after n/a ?? i don't think it's worth a changelog entry changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @daniel-beck before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue should exist and be labeled as lts-candidate </desc> <cmt> refactor layout on the plugins/advanced page </cmt> <cmt> - migrate away from a table-based layout, using the <section> html element </cmt> <cmt> - add some space between sections </cmt> <cmt> refactor the sectioning of the /manage page </cmt> <cmt> - use the <section> html elements </cmt> <cmt> - add some spacing between sections to improve readability </cmt>",rework sectioning on /manage and /pluginsmanager/advanced
3000,"<desc> small fixes to a few of the three.js example files to make then work with webgl in ie 11. the main problem was that the examples were overwriting the global window.parent. in ie 11 window.parent is read only so the examples were failing. on other platform browsers window.parent was being changed to a three.object3d. parent = new three.object3d(); i added parent to the following declaration of vars var camera, scene, renderer, parent; this fixes the examples for ie 11. </desc> <cmt> added var parent. parent should not be global. fixes ie 11 </cmt> <cmt> added var parent. parent should not be global. fixes ie 11 </cmt> <cmt> added var parent. parent should not be global. fixes ie 11 </cmt> <cmt> removed return false to fix return error in ie 11 </cmt>",browser interoperability bug fixes for examples in ie 11
3001,"<desc> cherry picks of #47235, #47689 for v1.7.1 note: this will only introduce builds and does not solve for the issues identified in #47776 relates to #45731 </desc> <cmt> .circleci: add python 3.9 to linux binary build matrix (#47235) </cmt> <cmt> summary: </cmt> <cmt> pull request resolved: </cmt> <cmt> depends on </cmt> <cmt> test plan: imported from oss </cmt> <cmt> reviewed by: malfet </cmt> <cmt> differential revision: d24863739 </cmt> <cmt> pulled by: seemethere </cmt> <cmt> fbshipit-source-id: ed78087bb7aae118af7a808d7b5620d6c9b8cb26 </cmt> <cmt> (cherry picked from commit cc337069e0213b00da505c0a9ddf4a2644a39ae4) </cmt> <cmt> .circleci: add python 3.9 builds for macos (#47689) </cmt> <cmt> summary: </cmt> <cmt> pull request resolved: </cmt> <cmt> test plan: imported from oss </cmt> <cmt> reviewed by: janeyx99 </cmt> <cmt> differential revision: d25029226 </cmt> <cmt> pulled by: seemethere </cmt> <cmt> fbshipit-source-id: 1db2b021d3adf243453f4405219d5ce03d03a9c1 </cmt> <cmt> (cherry picked from commit 05dc9821be4c6338702ed17e6f385647604654e6) </cmt>",add python 3.9 support (linux / macos)
3002,"<desc> closes #324. </desc> <cmt> add spec for checking webgl support. </cmt> <cmt> download dirextx sdk dlls. </cmt> <cmt> update libchromiumcontent for libegl.dll. </cmt> <cmt> ship webgl necessary files in distribution. </cmt> <cmt> rename ""frameworks"" to ""external_binaries"". </cmt> <cmt> check for version when downloading external binaries. </cmt> <cmt> only build debug target in cibuild. </cmt> <iss> webgl doesn't work on windows </iss>",fix webgl support on windows
3003,<desc> description: update the androidtv tests to use pytest instead of unittest. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. if the code does not interact with devices: </desc> <cmt> move the patchers to a separate file </cmt> <cmt> got a pytest test working (mostly) </cmt>,bump androidtv to 0.0.26 and update tests
3004,"<desc> fix the error of  #3940 </desc> <cmt> bugfix </cmt> <cmt> supports elasticsearch backend options settings </cmt> <cmt> update document of elasticsearch backend settings </cmt> <cmt> elasticsearch: fix serializing document id. </cmt> <cmt> elasticsearch: fix serializing document id. </cmt> <cmt> revert code </cmt> <cmt> fix es default value and document error,fix code friendly </cmt>",fix the build error of #3940
3005,"<desc> this is related to #31908. in order to use the external version in a reindex from remote request, the search request must be configured to request the version (as it is not returned by default). this commit modifies the search request to request the version. additionally, it modifies our current reindex from remote tests to randomly use the external version_type. </desc> <cmt> reproduce </cmt> <cmt> changes </cmt> <cmt> changes </cmt> <cmt> changes </cmt>",propogate version in reindex from remote search
3006,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. the methods returned on line 319 of loading-bar.js (here) haven't been defined in the interface. i've added their definitions and updated the tests to check that the types of the properties can still be changed, without necessarily touching the method implementations. </desc> <cmt> allow @types/angular-loading-bar to export a string name for angular module inclusion </cmt> <cmt> add in the methods for @types/angular-loading-bar and fix the tests </cmt>",define the methods on the loading bar provider in angular-loading-bar
3007,"<desc> adds support to load layeredfs patches on dlcs. since dlcs have different title ids from the base game, they follow the exact same patch structure except with their title id. adds support for dumping dlc romfs from the game list. if dlcs are found, they will appear in a list with base game for user selection. remove duplicates from dlc list if a dlc is installed twice. when dumping the base game romfs, avoid dumping the patched version (with updates/mods). log a dlc layered fs patch to log for debugging. </desc> <cmt> patch_manager: add support for using layeredfs with data </cmt> <cmt> fsp_srv: apply patches to data storage in opendatastoragebydataid </cmt> <cmt> registered_cache: deduplicate results of listentry and listentryfilter </cmt> <cmt> prevents a entry from appearing in the list twice if the user has it installed in two places (e.g. user nand and sdmc) </cmt>",add support for layeredfs on dlc romfs
3008,<desc> this is a backport of mozilla#327 which fixes mozilla#283. </desc> <cmt> hard overwrite on conflict for query owners (re #283) </cmt> <cmt> use alertdialog instead of custom global function. </cmt> <iss> owners of queries should be able to hard overwrite </iss>,allow query owners to hard-overwrite query content in case of overlap with other user
3009,"<desc> we should support safe c++ worker api according the doc, this pr supports normal task for ray_emote. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> add some functions to serializer </cmt> <cmt> remove response; simplify error handling </cmt> <cmt> invoke with rayobject </cmt> <cmt> add use_ray_remote branch </cmt> <cmt> throw error message </cmt> <cmt> add objectref<void> </cmt> <cmt> support single process normal task </cmt> <cmt> support void normal task </cmt> <cmt> normal task single process </cmt>",ray normal task for ray_remote
3010,"<desc> initial infrastructure code for specializing call_function. also added specialization for calling meth_o  pycfunctions because it's the easiest to implement. along with meth_fastcall. measured up to 20% faster calls for meth_o on microbenchmarks. </desc> <cmt> wip: specialize call_function for builtins </cmt> <cmt> fix some gcc compilation warnings </cmt> <cmt> hopefully fix the segfaults </cmt> <cmt> rename to call_cfunction and generalize to all c functions </cmt> <cmt> fix formatting, remove redundant check </cmt> <cmt> goto fail rather than return -1 </cmt> <cmt> create 2021-06-28-22-23-59.bpo-44525.ssvukg.rst </cmt>",specialize call_function for c function calls
3011,"<desc> this also changes the interactive mode of analyze-sample-code.dart to print the correct line numbers of where the error occurs in the source file (instead of the line numbers in the generated file). unfortunately, it makes the interactive mode a somewhat slower. but having the correct line numbers is more important and helpful. related issues #69123 before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> migrate api doc samples to nnbd </cmt> <cmt> ++ </cmt> <cmt> ++ </cmt> <cmt> ++ </cmt>",migrate the first batch of api samples to null safety
3012,"<desc> stopping pvr manager must follow the strict two-step logic for all (!) of its sub components. stop all sub components (means, stop their worker threads to hold processing) unload all sub components (clearing all data) starting must follow the exact revere logic load all sub components (loading their data from clients and/or database) start all sub components this was not implemented properly for cpvrtimers and cpvrepgcontainer components and should be fixed by this pr. runtime-tested on macos and android, latest kodi master. i had a testcase reproducible on my mac which led to all kind of errors and even crashes. </desc> <cmt> [pvr] fix timers thread start/stop, load/unload races. </cmt> <cmt> [pvr] fix epg container start/stop, load/unload races. </cmt>",fix pvr manager start/stop races
3013,"<desc> a third version of #16306 and #16328 puts the common checks to mark as xfail into the _xfail_test estimator tag. hopefully addresses concerns raised in the two previous implementations. in particular, this would make the workflow identical between scikit-learn and contrib projects. </desc> <cmt> add known failure flag to common tests </cmt> <cmt> better pytest integration </cmt> <cmt> passing request more systematically </cmt> <cmt> more comments </cmt> <cmt> detect pytest session </cmt> <cmt> remove outdated import </cmt> <cmt> add pytest --runxfail to tips </cmt> <cmt> typo </cmt> <cmt> update sklearn/utils/estimator_checks.py </cmt> <cmt> add thomas' comment </cmt> <cmt> simplify signature check </cmt> <cmt> simplify _raise_xfail </cmt> <cmt> remove nb skip tests since its never run </cmt> <cmt> add _xfail_test estimator tags </cmt> <cmt> minor fixes </cmt>",enh xfail in common tests with estimator tags (v3)
3014,"<desc> this is a step toward the long-term goal of making the ""user"" trees nodes immutable. this change isolates the mutable data for expression nodes in the ""user"" tree during the semantic (analysis) phase by moving the mutable data into input and output objects. these objects are created locally during the semantic phase to share information required for semantic checking between parent-child nodes. note that for this change, input and output are still stored in a mutable way on the expression nodes. this will not be the case once the semantic (analysis) phase and ir generation (write) phase are combined in a future change. relates #49869 </desc> <cmt> remove isnull from aexpression </cmt> <cmt> remove explicit cast optimization </cmt> <cmt> remove modification of semantic tree for casting </cmt> <cmt> remove ecast node </cmt> <cmt> start of input/output in expressions </cmt> <cmt> partial change for input and output in expression nodes </cmt> <cmt> add input/output objects for expressions </cmt> <cmt> fix shift bug in ebinary </cmt> <cmt> response to pr comment </cmt>",move aexpression mutable members into isolated input/output objects
3015,<desc> the following deprecated warnings are removed from contrib/timeseries examples the name tf.app.run is deprecated. please use tf.compat.v1.app.run instead. the name tf.session is deprecated. please use tf.compat.v1.session instead. the name tf.train.adamoptimizer is deprecated. please use tf.compat.v1.train.adamoptimizer instead. </desc> <cmt> deprecated tf.app.run removed in known_anomaly.py </cmt> <cmt> deprecated tf.app.run/tf.session/tf.train.adamoptimizer removed in lstm.py </cmt> <cmt> deprecated tf.app.run/tf.session removed in multivariate.py </cmt> <cmt> deprecated tf.app.run removed in predict.py </cmt>,deprecated warning removed from contrib timeseries
3016,"<desc> running pytest in getsentry triggers a bug in firefox_profile.py from the selenium driver. upgrading to version 4 is quite involved. this is a stop-gap to prevent distracting engineers when it happens. this is the output when we patch it: --> installing sentry (for development) we are patching .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py. you will see this message only once. --- .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py	2021-11-09 16:40:20.000000000 -0500 +++ .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py.bak	2021-11-09 16:40:03.000000000 -0500 @@ -207,3 +207,3 @@ def _set_manual_proxy_preference(self, key, setting): -        if setting is none or setting == '': +        if setting is none or setting is '': return </desc> <cmt> wip </cmt> <cmt> patch </cmt>",patch firefox_profile.py from selenium package
3017,"<desc> we add ent_iob as a token pattern key, upon request by #3940 . i also added a tiny addition to the documentation for the new key. enhancement </desc> <cmt> added new field </cmt> <cmt> added exception for iob strings </cmt> <cmt> minor refinement to schema </cmt> <iss> ent_iob as a token pattern key </iss> <iss> suggested documentation improvement: ent_iob in dependencymatcher </iss>",add ent_iob key to matcher
3018,"<desc> fix for #9957 resolves the deprecated function in diagrammer package used in graph.viz. graph nodes are now of fixed size rather than adapting to wrap the whole text, i will check for a solution to this in the next days. </desc> <cmt> fix viz.graph r </cmt> <cmt> fix viz.graph r </cmt>",fix r build crash in ci
3019,"<desc> fixes #4866: minor bug in the dict update when used by minibatchdictionarylearning. i added a test which currently fail on master. _update_dict seems to make smart things to update the residuals incrementally but i found that it's actually much faster (~10x to 20x) to write the function more naively and compute the objective function from scratch at the end. the impact on the time for the whole dict learning is negligible since the bottleneck is the sparse coding but i find version much more readable (and by reading the related issues i'm not the only one). when an atom is not used, the current strategy is to generate a new one from a normal distribution. but it's very likely that it will still not be used. a discussion with @tommoral lead us think that sample a new atom from the data may be a better strategy. below is a plot of the objective function for both strategies. more small adjustments. i explain thoses in dedicated comments </desc> <cmt> several fixes to dict update in dict learning </cmt> <cmt> fix docstrings </cmt> <cmt> avoid noise with 0 std </cmt> <iss> block coordinate descent for dictionary update has a non optimal step </iss>",fix several issues in the dict update
3020,"<desc> this is the second step to bring integration between ebpf and cgroups #11558. this pr is creating shared memory with cgroup plugin. component name cgroup ebpf.plugin 1 - enable flag inside your netdata.conf 2 - compile this branch 3 - take a look in the logs to verify whether shared memory was filled this pr is part of a huge branch that has almost all modifications proposed for #11558 , and it was tested on: manjaro 21.1 (cgroup version 2) centos 7.9 debian 10.10 ubuntu 18.04 </desc> <cmt> cgroup_shm: move preprocessors to header </cmt> <cmt> cgroup_shm: add library to link shared memory </cmt> <cmt> cgroup_shm: add data types </cmt> <cmt> cgroup_shm: initialize shared memory </cmt> <cmt> cgroup_shm: fill header with initial data </cmt> <cmt> cgroup_shm: close shared memory </cmt> <cmt> cgroup_shm: add cgroup to shared memory </cmt>",add shared memory to cgroup
3021,"<desc> this pr along with electron-archive/brightray#157, adds a new api to app: app.allowntlmcredentialsforalldomains(true | false); we are discovering that many domains are incorrectly configured, so that ntlm will not be implicitly passed to a web server because windows (via iinternetsecuritymanager::mapurltozone) will decide it isn't inside the local domain. this pr allows app developers to say, ""don't care about urls, always send ntlm if asked"". if this method is not called, the preexisting behavior will be used we actually set up an in-house domain controller to test this, it appears to be </desc> <cmt> create a new method on app to override url security manager's decisions wrt ntlm </cmt> <cmt> wire it up </cmt> <cmt> linter fixes </cmt> <cmt> rollback submodule change </cmt>",optionally allow ntlm authentication for all domains
3022,"<desc> previously the incremental parser worked in a mode where it would reuse nodes prior to the editedrange, then skip over nodes/tokens in the edited range, then reuse nodes after the edit range.  the reused nodes after the edit range would then have to have their positions fixed up.  i.e. they might move forward/backward depending on what sort of edit it was. this approach resulted in extra complexity as the incremental parser had to keep track of where it was, and how the position it was in the tree related to the position it was at in the text.  this involved keeping track of two different positions in two different sources (the old tree and the text) and keep a relative 'delta' between then to tell if they were in sync. thanks to a suggestion from bill, i've moved things to a simpler model that makes things only slightly more expensive.    specifically, we start the incremental parse with a prepass over the tree.  we skip over all nodes quickly that fall totally before the edit range.  then we mark all nodes and tokens in the edit range as being unusable.  then we move all tokens that fall totally after the change range forward. thanks to this, all nodes/tokens from the old tree that we look at are either marked as unusable, or are located at the same position they would be at in the new text.  this means we no longer need to keep track of relative positions between two sources.  instead, we can simply try move to the node that matches the current text position.  if we find one, we can return it.  otherwise, we know we need to keep rescanning tokens from the new text. </desc> <cmt> simplify incremental parsing by moving old source tree nodes before doing anything. </cmt> <cmt> fix interface. </cmt> <cmt> simplify parser initializer. </cmt> <cmt> simplify incremental code. </cmt> <cmt> always mark nodes and tokens that cross the edited range. </cmt> <cmt> slightly speed up marking by avoiding calling fullstart on so many nodes and tokens. </cmt> <cmt> simplify incremental parser. </cmt> <cmt> speed up incremental parser. </cmt> <cmt> make 'kind' non-enumerable. </cmt> <cmt> remove unused asserts. </cmt>",change how the incremental parser works.
3023,"<desc> this pr merges together several changes: updates to the validation for facebook to handle oldschool /page/id urls changing to always store only the unique username / page name portion of twitter & facebook urls adding new utilities to construct the full urls from the usernames updating structured data etc to use the new utilities to output urls where needed providing 2 new helpers for the theme api which also use the new utilities to output urls where needed all together, these changes should go green in travis! </desc> <cmt> add helpers for facebook & twitter urls </cmt> <cmt> refs #6534 </cmt> <cmt> - this pr assumes that we are now saving usernames only in the database for twitter & facebook </cmt> <cmt> - adds a new social links utility which can generate twitter & facebook urls from the username </cmt> <cmt> - adds a {{twitter_url}} and {{facebook_url}} helper which uses these </cmt> <cmt> - adds a full suite of tests for the helpers & utils </cmt> <cmt> update structured data for fb & twitter usernames </cmt> <cmt> refs #6534 </cmt> <cmt> - twitter & facebook fields are changing to store usernames only </cmt> <cmt> - use the new social url util to generate urls where necessary </cmt> <cmt> - update tests </cmt> <cmt> fixes error in validation </cmt> <cmt> closes #6826 </cmt> <cmt> - refactors the validation of facebook and twitter input field in general.js and user.js controller </cmt> <cmt> - example validations for facebook: </cmt> <cmt> - facebook.com/username will be corrected to the full url </cmt> <cmt> - user will show error your page name is not a valid facebook page name' for general.js and your username is not a valid facebook username for user.js as the username in facebook has to be at least 5 characters long </cmt> <cmt> - twitter.com/username will be autocorrected to the valid facebook url incl. the username </cmt> <cmt> - example validations for twitter: </cmt> <cmt> - twitter.com/user_ will be corrected to the full url </cmt> <cmt> - user:99 will show error your username is not a valid twitter username </cmt> <cmt> - facebook.com/username will be autocorrected to the valid twitter url incl. the username </cmt> <cmt> - updates both acceptance tests </cmt> <cmt> - adds further validation for facebook pages in general settings and user. submitting a url which incl. /page/ or /pages/ will now accept any username followed incl. further /. </cmt> <cmt> - adds a custom transform facebook-url-user which will extract the username (if it's a facebook page, incl. pages/) to store only this in the backend </cmt> <cmt> - uses the twitter-url-user transform now also for user </cmt>",improvements to twitter & facebook handling
3024,"<desc> original pull-request #22594 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> consistent aws timeouts. </cmt> <cmt> consistent aws timeouts </cmt>",cherry pick #22594 to 21.2: consistent aws timeouts
3025,"<desc> hi tf team, would it be possible to fold these tutorial doc updates from master into the r0.10 release branch? thanks, sanders </desc> <cmt> code and data for tf.contrib.learn monitors tutorial. </cmt> <cmt> change: 128588838 </cmt> <cmt> new tutorial on tf.contrib.learn monitors. </cmt> <cmt> change: 128589916 </cmt>",tutorial updates for r0.10 release
3026,<desc> add check to kafkaapis add unit test specific to follower fetch update tool developed with @mimaison </desc> <cmt> minor: added check on handling fetch request from follower </cmt> <cmt> minor: added check on handling fetch request from follower </cmt> <cmt> added unit test specific to follower fetch </cmt> <cmt> updated tool </cmt> <cmt> developed with @mimaison </cmt>,additional check to follower fetch handling
3027,"<desc> this pr cleans the maps in the tokenizer files to make sure each checkpoint has the proper tokenization files. this will allow us to remove custom code that mapped some checkpoints to special files (like bart using roberta vocab files) and take full advantage of the versioning systems for those checkpoints. all checkpoints changed have been properly copied in the corresponding model repos in parallel. for instance, to accomodate the move on the fast bart tokenizers, the following commits have been on the model hub: in facebook/bart-base in facebook/bart-large in facebook/bart-large-mnli in facebook/bart-large-cnn in facebook/bart-large-xsum in yjernite/bart_eli5 in the pr i've also uniformized the way the maps are structured across models, to make it easier to alter (and ultimately remove) them in the future via automatic scripts. </desc> <cmt> move tokenizer files in each repo </cmt> <cmt> fix mbart50 tests </cmt> <cmt> fix mbart tests </cmt> <cmt> fix marian tests </cmt>",copy tokenizer files in each of their repo
3028,"<desc> preview of results: synthetic data | real data </desc> <cmt> modified tweaked tests to use tensor learning rate </cmt> <cmt> temporarily enable tensor lr globally for testing </cmt> <cmt> temporarily change compute_lr_on_cpu to false </cmt> <cmt> revert ""temporarily change compute_lr_on_cpu to false"" </cmt> <cmt> this reverts commit c726775b0e216ddd6822006a8b74ad1d11b21027. </cmt> <cmt> revert ""temporarily enable tensor lr globally for testing"" </cmt> <cmt> this reverts commit 300bc29f593b0744a8d24126b5abf5e2ed36a11f. </cmt>",use lr schedule ops instead of lr callback for tweaked tests
3029,<desc> following-up on the url work from the previous pr built a new library called native-url to address the concerns with the differences in the api between our solution the node-url the library has an exhaustive list of test-cases to ensure it remains api compatible. size difference: current url package - ~5kb gzipped native-url - ~1.6kb gzipped </desc> <cmt> adding native-url package </cmt> <cmt> bumping native-url version </cmt> <cmt> upgrading native-url </cmt>,replace url polyfill with self.url
3030,"<desc> this includes a number of commits for the first round of upgrading to llvm 6. there are still lingering bugs but i believe all of this will nonetheless be necessary! </desc> <cmt> llvm6: codemodel::{jit,}default no longer exists </cmt> <cmt> llvm has since removed the codemodel::default enum value in favor of an </cmt> <cmt> optional implementationg throughout llvm. let's mirror the same change in rust </cmt> <cmt> and update the various bindings we call accordingly. </cmt> <cmt> removed in llvm-mirror/llvm@9aafb854c </cmt> <cmt> llvm6: missing include for llvm 6 in passwrapper.cpp </cmt> <cmt> just bog-standard compile error fixed by adding some new header files </cmt> <cmt> llvm6: tweak fast math intrinsics </cmt> <cmt> looks like they did some refactoring of flags in the backend and this should </cmt> <cmt> catch us up! the ""unsafe algebra"" boolean has been split into a number of </cmt> <cmt> boolean flags for various operations, and this updates to use the setfast </cmt> <cmt> function which should hopefully have the same behavior as before. </cmt> <cmt> this was updated in llvm-mirror/llvm@00e900afd </cmt> <cmt> llvm6: remove mips64 archive variant </cmt> <cmt> it looks like llvm also removed it in llvm-mirror/llvm@f45adc29d in favor of the </cmt> <cmt> name ""gnu64"". this was added in the thought that we'd need such a variant when </cmt> <cmt> adding mips64 support but we ended up not needing it! for now let's just </cmt> <cmt> removing the various support on the rust side of things. </cmt> <cmt> llvm6: different return value for writearchive </cmt> <cmt> updated in llvm-mirror/llvm@203c90ba this function now just returns an error, </cmt> <cmt> so this updates the c++ bindings accordingly </cmt> <cmt> llvm6: don't clone llvm modules on wasm </cmt> <cmt> the comment for why cloning exists doesn't actually apply for wasm today and </cmt> <cmt> apparently cloning is causing subtle bugs in llvm, so let's just avoid it </cmt> <cmt> altogether. more specifically after we emit the assembly for the wasm target we </cmt> <cmt> don't actually use the module again, so there's no need to keep both around. </cmt> <cmt> this seemed to be causing some scary verifier assertions in llvm which seemed to </cmt> <cmt> be uncovered by presumably (?) buggy behavior. let's just avoid it for now and </cmt> <cmt> make the wasm target slightly more lean in the process. </cmt>",first round of llvm 6.0.0 compatibility
3031,"<desc> this issue if related to #5546, where it is claimed that datafeeders will become deprecated. as such, this branch has following changes added _generatorfeedfn class generator_input_fn in generator_io.py support for generator_input_fn in enqueue_data() added unitest in generator_io_test.py refactored code keeping indent spacing to 2. </desc> <cmt> branch to test_tensorflow </cmt> <cmt> using types.generatortype for validation </cmt> <cmt> changed to receving generator function </cmt> <cmt> this allows to run multiple epochs of a finite generator </cmt> <cmt> using placeholders as keys to feed dictionary </cmt> <cmt> added correct counter for the index_placeholder </cmt> <cmt> added corrections to tests </cmt> <cmt> removing extra spaces </cmt>",add support for dict generator input_fn in learn_io
3032,"<desc> fixes #5638 i have added tests for the newly introduced function to check for file and also the default icon src config (with a snapshot test). i was also thinking about testing the promise.reject behavior of onpostbuild, but i got stuck because i don't know if mocking the fs would be a good idea, or should i just leave the fs as is and let it generate files in public directory (which is ignored by git anyway). please suggest. \ </desc> <cmt> throw error if icon does not exist for manifest </cmt> <cmt> gatsby-plugin-manifest will throw an error if the icon defined in </cmt> <cmt> gatsby-config.js does not exist. if it does exist, then console.log </cmt> <cmt> a better message about what is being done. </cmt> <cmt> see gatsbyjs/gatsby#5638 </cmt> <cmt> add tests for gatsby-plugin-manifest </cmt> <cmt> the tests ensure the default icon src configs and behavior of the </cmt> <cmt> newly introduced check for detecting the presense of icon src </cmt> <cmt> mentioned in the gatsby-config.js file. </cmt> <cmt> see gatsbyjs/gatsby#5638 </cmt>",fix gatsby-plugin-manifest cryptic error if file is not present
3033,"<desc> as a result of changing the base docker to ubuntu in #80820, the default shell i.e. /bin/sh changed to dash, rather than bash, which could impact anyone invoking /bin/sh and expecting it to still propagate environment variables with periods in their names. reconfigure the default shell back to bash so that this type of situation works again. </desc> <cmt> change default shell to bash in ubuntu-based images </cmt> <cmt> add a test for what is the default shell </cmt>",change default shell to bash in default docker image
3034,"<desc> fixes for two property-wrapper crashes: move ""has lazy resolver"" check later to handle merge-modules properly (sr-10844 / rdar://problem/51484958) ensure that we fully check the property type vs. wrapper's value type (sr-10899 / rdar://problem/51588022) </desc> <cmt> [se-0258] move ""has lazy resolver"" check later to handle merge-modules properly </cmt> <cmt> the merge-modules phase doesn't have an active type checker, so we were bailing </cmt> <cmt> out of property-wrapper queries before we had a chance to check the cache. </cmt> <cmt> move the check later, to the points where we actually need a type checker. </cmt> <cmt> fixes sr-10844 / rdar://problem/51484958. </cmt> <cmt> [se-0258] ensure that we fully check the property type vs. wrapper's value type </cmt> <cmt> various optimizations / shortcuts in type checking property wrappers meant </cmt> <cmt> that we weren't consistently verifying that a wrapped property type is </cmt> <cmt> identical to the type of the 'value' property of the wrapper. do so. </cmt> <cmt> fixes sr-10899 / rdar://problem/51588022. </cmt>",property wrapper misc fixes 5.1
3035,"<desc> moved the logic to measure elapsed time and cpu load from fio_compressfilename to fio_compressfilename_internal. fio_compressfilename is only used for single file case. if we want to show elapsed time and cpu load for each file in multiple file scenario, the measurement needs to be done in fio_compressfilename_internal, which is called by both single and multiple file scenarios. i could have added the logic to fio_compressfilename_internal, fio_compressfilename_dstfile, or fio_compressfilename_srcfile. i thought fio_compressfilename_internal is a good fit since it already has logic to print stats about compression (compression ratio). i see elapsed time and cpu load as the extension to the stats. </desc> <cmt> zstdcli : exposing cpu load indicator for each file on -vv mode </cmt> <cmt> zstdcli : moving start time and cpu initialization after potential prompt </cmt> <cmt> zstdcli : fixing mixed declarations and code error </cmt> <cmt> zstdcli : moving cpu load calculation from fio_compressfilename_dstfile to fio_compressfilename_internal </cmt> <cmt> zstdcli : trying to fix declaration after statement </cmt> <cmt> zstdcli : remove extra semicolon </cmt> <cmt> zstdcli : align output message with previous message </cmt>",expose cpu load indicator for each file on -vv mode
3036,<desc> some of the multioutput docs contained some errors or were still referring to multilabel. some language issues were fixed on the way. </desc> <cmt> fix a few quirks in the muliclass docs </cmt> <cmt> change references to multioutput </cmt>,doc fix minor quirks in multiclass docs
3037,"<desc> the clojure bert example's infer function accepts a cpu/gpu context, which the command line version of this example exposes as a :cpu/:gpu keyword. previously, these options were ignored and the context was always overridden to the default context (cpu). this pr allows users (both repl and shell) to pass in a gpu context. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (this is a tiny-change pr) to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> clojure bert example: minor code cleanup </cmt> <cmt> * remove unused requires </cmt> <cmt> * remove unused vars & function </cmt> <cmt> * use io alias </cmt> <cmt> clojure bert example: whitespace fix </cmt> <cmt> clojure bert example: allow running with gpu </cmt> <cmt> the infer function accepts a cpu/gpu context, which the command line </cmt> <cmt> version of this example exposes as a :cpu/:gpu </cmt> <cmt> keyword. previously, these options were ignored and the context was </cmt> <cmt> overridden to the default context (cpu). this commit allows </cmt> <cmt> users (both repl and shell) to pass in a gpu context. </cmt>",fix clojure bert example's context argument
3038,"<desc> one more round of deprecations removal. </desc> <cmt> removed deprecated #original_exception in actionview::template::error. </cmt> <cmt> removed deprecated #original_exception in activejob::deserializationerror </cmt> <cmt> removed deprecated support to passing the adapter class to .queue_adapter </cmt> <cmt> removed deprecated methods in activemodel::errors </cmt> <cmt> #get, #set, []=, add_on_empty and add_on_blank. </cmt> <cmt> removed deprecated :tokenizer in the length validator </cmt>","remove deprecations in active model, action view and active job"
3039,"<desc> attempt to fix urgent issue #4072 i'm sorry, no. don't know how to reproduce the test case with unit tests. for the time being you may want to test it against demo project by rguanghui in #4072. previous to the pr it should run into the error described in the related issue. when trying to build it with the fixed version of lib/dependencies/harmonyexportimportedspecifierdependency.js it should print an error message. added unit test which tests on the result of harmonyexportimportedspecifierdependency#gethashcode(importedmodule) when method parameter is null or undefined. don't think so. </desc> <cmt> attempt to fix #4072 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",data must be a string or a buffer (#4072)
3040,"<desc> updates to support qmk-dfu bootloader, and refactor of oled support to utilize built-in i2c and oled drivers. updated existing keymaps to remove extraneous oled code. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> tkc1800: updated to support qmk-dfu bootloader </cmt> <cmt> tkc1800: updated to support qmk-dfu bootloader </cmt> <cmt> tkc1800: updated to utilize common i2c and oled code </cmt>",refactor and updates to tkc1800 code
3041,"<desc> in my fork i have/had to fix the three issues mentioned in the subject. please refer to the (rather extensive) commit messages for more details on my work. the patches so far have been written on a works-for-me basis, so no unittests have been attempted; i'm on a rather tight deadline right now (and i had to get proper error logging from my application). in any case: thanks a lot for making my life a lot easier by writing django-sentry. :) </desc> <cmt> this seems to fix a bug where it was possible for some class, which is not available on the server side (in my particular case a suds soap text object), to be pickled and sent to the server. this caused a bad data response due to an importerror on the server. </cmt>","better error reporting/logging from within sentry, patch for unicode coercion and bug in exception catching"
3042,"<desc> addresses #21034 turns out that moniker ranges break indentation in sub-bullet content when the bullet item isn't included in the versioned content ... therefore, the versioned content must include the bulleted item ... i.e. .... the bullet item must be repeated for each version. </desc> <cmt> patch blazor wasm security layouts </cmt> <cmt> update hosted-with-azure-active-directory.md </cmt>",blazor wasm security versioned content
3043,"<desc> improve documentation readability, and avoid an incorrect debug message. </desc> <cmt> man: systemd.exec: cleanup ""only x will be permitted"" ... ""but x=x+1"" </cmt> <cmt> > only system calls of the *specified* architectures will be permitted to </cmt> <cmt> > processes of this unit. </cmt> <cmt> (my emphasis) </cmt> <cmt> > note that setting this option to a non-empty list implies that </cmt> <cmt> > native is included too. </cmt> <cmt> attempting to use ""implies"" in the later sentence, in a way that </cmt> <cmt> contradicts the very clear meaning of the earlier sentence... it's too </cmt> <cmt> much. </cmt> <cmt> seccomp-util: fix alarming debug message (#8002, #8001) </cmt> <cmt> booting with systemd.log_level=debug and looking in dmesg -u showed </cmt> <cmt> messages like this: </cmt> <cmt> systemd[433]: failed to add rule for system call n/a() / 156, ignoring: </cmt> <cmt> numerical argument out of domain </cmt> <cmt> this commit fixes it to: </cmt> <cmt> systemd[449]: failed to add rule for system call _sysctl() / 156, </cmt> <cmt> ignoring: numerical argument out of domain </cmt> <cmt> some of the messages could be even more misleading, e.g. we were reporting </cmt> <cmt> that utimensat() / 320 was skipped as non-existent on x86, when actually </cmt> <cmt> the syscall number 320 is kexec_file_load() on x86 . </cmt> <cmt> the problem was that syscall nrs are looked up (and correctly passed to </cmt> <cmt> libseccomp) as native syscall nrs.  but we forgot that when we tried to </cmt> <cmt> go back from the syscall nr to the name. </cmt> <cmt> i think the natural way to write this would be </cmt> <cmt> seccomp_syscall_resolve_num(nr), however there is no such function. </cmt> <cmt> i couldn't work out a short comment that would make this clearer.  fwiw </cmt> <cmt> i wrote it up as a ticket for libseccomp instead. </cmt> <cmt>  </cmt>",cosmetic seccomp fixes (#8002/#8001)
3044,"<desc> change all uses of ""master/slave"" terminology to ""parent-child"". component name no functional differences in the code. there are many mentions of master that i have left in place: references to external systems (e.g. the mysql collector and the macos firmware) the use of webmaster anything in urls (e.g. references to git branches) </desc> <cmt> change affected file-names under build_external </cmt> <cmt> update testing scenarios for new filenames </cmt> <cmt> all the other mentions of master-slave netdata instances. </cmt>",change streaming terminology to parent-child in the code
3045,"<desc> merged mkldnn adaptive pooling with traditional pooling implementation, so that the code redundancy is fixed </desc> <cmt> implemented adaptive pooling operator in pooling operator </cmt> <cmt> fix: fixed issues from the review </cmt> <cmt> fix: changes with_workspace var to const </cmt> <cmt> refactor: changed const use_adaptive to more informative use_adaptive_pooling </cmt> <cmt> refactor: changed getmkldnnpoolalgo to more descriptive getmkldnnpoolingalgorithm </cmt>",merge mkldnn adaptive pooling with traditional pooling implementation
3046,"<desc> fix for continued discussion on #1757 btw, i don't expect simd.js to change rapidly, but should we continue manually pull changes into emscripten rather than using git submodules? it'll be helpful in tests/runner.py to print out the js engine that it's running the test with. it'll be helpful in tests/runner.py to print a message telling the user that v8 cannot be used instead of giving a mysterious message saying no available js engines when the user specified v8 in ~/.emscripten. thanks!! </desc> <cmt> updated simd.js to fix nan canonicalization issue for bitcasts </cmt> <cmt> fix accidental rewrite of original url source of simd.js </cmt>",fix nan canoicalization issue for simd bitcasts
3047,"<desc> see related discussion: maxnowack/node-podcast#39 (comment) add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: maxnowack/node-podcast#39 (comment) include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> allow passing a duration in string format </cmt> <cmt> see related discussion: </cmt> <cmt> update version header </cmt>",@types/podcast - allow passing a duration in string format
3048,<desc> description: use collections helpers from #30313 to manage input_text entities. related issue (if applicable): #30494 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> refactor input_text to use config dict. </cmt> <cmt> use collections for input_text. </cmt>,use collection helpers for input_text entities
3049,"<desc> what do these changes do? adds multi-gpu support for multi-agent. previously, this required the simple optimizer that did not support minibatching. also closes #3489 </desc> <cmt> wip </cmt> <cmt> fix </cmt> <iss> error on es when running `python rollout.py` from checkpoint </iss>",multi-gpu support for multi-agent ppo
3050,"<desc> fixes #3453, towards #4222 this is not the most elegant patch, but i need to force resource_table into deno_core::isolate now, and this is the best i can do at the moment. </desc> <cmt> add resource table to core::isolate </cmt> <cmt> wip </cmt> <cmt> compiles </cmt> <cmt> use rc<refcell<resourcetable>> </cmt> <iss> resource table for plugins </iss>",move resource_table from deno::state to deno_core::isolate
3051,<desc> fixes #10055 closes #10081 changed multinomialdeviance from total logloss to average logloss. i fixed stalled pr #10081. the main modification is from #10081. what i did is to merge recently master branch and fix conflicts and flake8 errors. </desc> <cmt> [mrg] fix multinomialdeviance not using average logloss (#10055) </cmt> <cmt> use np.average for handling weighted and unweighted cases </cmt> <cmt> add test for multinomial deviance </cmt> <cmt> extend test of multinomial deviance loss </cmt> <cmt> fix issue with numerical precision in multinomial deviance loss test </cmt> <cmt> split multinomialdeviance tests into several </cmt> <cmt> add test case for unweighted multinomialdeviance </cmt> <cmt> add pytest.mark.parametrize to tests </cmt> <cmt> fix import of assert_raises_regex </cmt> <cmt> conflicts: </cmt> <cmt> sklearn/ensemble/_gb.py </cmt> <cmt> sklearn/ensemble/tests/test_gradient_boosting_loss_functions.py </cmt> <cmt> fix conflicts and follow master branch </cmt> <iss> multinomialdeviance in gradientboostingclassifier should use average logloss instead of total logloss. </iss>,fix fix multinomial deviance by taking the weighted average instead of the sum
3052,<desc> first patch fixes problems with finding suitable frame format when videodevice::findtype() is called with default parameters during video capture object initialization which causes reporting its state as closed after initialization (function isopened() returns false). cv::videocapture cap(cv_cap_msmf); bool state = cap.isopened();  // always false second patch fixes assertion warnings thrown when frames are being grabbed ('atlmfc\include\atlcomcli.h   line:177   expression: p==0'). these warnings occur because smart pointer is not reset at every loop (in imagegrabber::startgrabbing). </desc> <cmt> fixed msmf video capture initialization </cmt> <cmt> fixed assertion warning in msmf frame grabber </cmt>,fixed msmf video capture (camera) issues
3053,"<desc> enforces a minimum width of 460 wide. this allows tabs to always be seen (albeit partially). note: a minimum height was originally added to allow the about menu to be seen. this minimum height was removed from this pr because we don't foresee a circumstance where your terminal is in that state, and you can't just resize it to make the content fit properly. #4990 may be fixed/affected by this? closes #4976 will close issue #5418 upon verification here's some images of what the terminal looks like when it's at its minimum size: 100% scaling 100% scaling: one tab 100% scaling: two tabs 100% scaling: 3 tabs (scrolling enabled) 200% scaling 200% scaling: one tab 200% scaling: two tabs 200% scaling: 3 tabs (scrolling enabled) </desc> <cmt> add minimum size to terminal </cmt> <cmt> 460x380 min size </cmt> <iss> minimize button disappears at minimum size </iss>",add and enforce minimum width
3054,"<desc> accompanying the release of tailwind css v2, @adamwathan recently added detailed instructions for integrating with next to the official tailwind docs. this pr brings the tailwind example in line with those instructions in a minimal way by: creating a new app with create-next-app adding tailwind per the instructions updating index.js to use tailwind for styling (screenshot below) removing other css cruft note: i realize someone has already updated this example to use tailwind v2, but it still deviates in small ways from what you'd get if you followed the tailwind docs verbatim. not a huge deal, but could be confusing to newcomers. </desc> <cmt> remove old stuff </cmt> <cmt> fresh start with create-next-app </cmt> <cmt> add tailwind deps </cmt> <cmt> add tailwind config files </cmt> <cmt> all css -> tailwind </cmt> <cmt> update readme </cmt>",bring tailwind css example in line with official tailwind docs
3055,"<desc> as per #236, rewriting the security questions cheat sheet. this is just a draft - not ready to merge. any comments are very welcome. </desc> <cmt> initial start on improvments to the security questions cs </cmt> <cmt> initial layout for new version </cmt>",rewrite of security questions cs
3056,"<desc> fixes #16723 this pr fixes 2 problems: fusedop did not support boolean input type as its inputs. during testing the fix for the first problem another problem was spotted (which i believe was previously fixed during the process of working on the fusion pr, but i guess some merge undid it) - the fusedop did not recompile the code when there was a change of inputs/outputs number of dimensions, which is wrong. this pr fixes both of those problems and introduces tests for them. @sxjscience please validate the fix. </desc> <cmt> support bool in fusion </cmt> <cmt> added tests </cmt> <iss> [bug] fused_op does not support boolean type </iss>",add support for boolean inputs to fusedop
3057,"<desc> the two commits have the details of the two fixes </desc> <cmt> rustc: fix cfg(not(a, b)) to be not(a && b) </cmt> <cmt> previously, the cfg attribute cfg(not(a, b)) was translated to (!a && !b), </cmt> <cmt> but this isn't very useful because that can already be expressed as </cmt> <cmt> cfg(not(a), not(b)). this commit changes the translation to !(a && b) which </cmt> <cmt> is more symmetrical of the rest of the cfg attribute. </cmt> <cmt> put another way, i would expect cfg(clause) to be the opposite of </cmt> <cmt> cfg(not(clause)), but this is not currently the case with multiple element </cmt> <cmt> clauses. </cmt> <cmt> std: fix backtraces on arm linux </cmt> <cmt> on android, libgcc is missing the _unwind_getip symbol because it's defined as a </cmt> <cmt> macro. this is the same case for arm linux, so this commit adds the necessary </cmt> <cmt> cfgs in place to use the ""expanded macro"" in rust for arm linux. </cmt>","tweak cfg(not(a, b)) and fix building libstd on arm linux"
3058,<desc> this is step 1 as laid out by @nathansobo in #10979. remove texteditors dependency on notificationmanager. </desc> <cmt> don't require notification manager in texteditor </cmt> <cmt> instead expose getcursorscope and let users outside the text editor </cmt> <cmt> show the notification. </cmt> <cmt> don't need to pass in the notification manager anymore. </cmt> <cmt> implement the show cursor scope functionality in the default commands. </cmt> <cmt> update the spec. </cmt>,remove texteditor's dependency on notificationmanager
3059,"<desc> fixes #16356. </desc> <cmt> network: fix indentation </cmt> <cmt> network: decrease indentation level </cmt> <cmt> network: always update acquired prefix route </cmt> <cmt> otherwise, routes become lifetime 0. </cmt> <cmt> fixes #16356. </cmt> <iss> systemd-networkd does not appear to reset the valid/preferred lifetime of delegated ipv6 prefixes when doing a dhcpv6 renew, leading to loss of ipv6 connectivity </iss>",update acquired dhcp6 prefix routes
3060,"<desc> this pr adds support for --checkpoint-at-end to rllib train, which currently ignores this flag. fixes #8919 closes #8919 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> fixes and lint. </cmt> <iss> [rllib] rllib train ... --checkpoint-at-end flag is ignored </iss>",issue 8919 checkpoint at end ignored
3061,<desc> differences between using vue in web and weex using vuex and vue-router </desc> <cmt> + [doc] update <differences between using vue in web and weex> </cmt> <cmt> + [doc] translate the 'using vuex and vue-router' into english </cmt> <cmt> * [doc] finish the difference-with-web doc </cmt>,translate some docs into english
3062,"<desc> currently when you ask for data source options as an admin, it was sending back the full data source configuration, including passwords. in case you have multiple admins in your system or you're using re:dash without https (not recommended), it might be a security concern. this pull request changes this: it will send a placeholder instead of the password (or any other field defined as ""secret""). closes #554. </desc> <cmt> update comment </cmt> <cmt> stop sending passwords to the ui </cmt> <cmt> fix: don't require uploading file again when editing bq/gs data source </cmt>",don't send passwords back to the ui
3063,"<desc> extracted these fixes from #2520 </desc> <cmt> ci: fix a regression in setting up container_name </cmt> <cmt> container_name was just ignored because script(1) does not give env vars to child processes. </cmt> <cmt> in addition, this commit uses '?=' in check.mk to let container_name be overridable by env vars. </cmt> <cmt> ci: fix a regression that step scripts should have -e as the default does </cmt>",fix regressions in gha migration
3064,"<desc> currently there is a clear mechanism to stub sending a request through the transport. however, this is limited to testing exceptions on the sender side. this commit reworks our transport related testing infrastructure to allow stubbing request handling on the receiving side. </desc> <cmt> merge </cmt> <cmt> change </cmt>",introduce mechanism to stub request handling
3065,<desc> this fixes #4235. this is second attempt to support +json content type suffix. the first attempt in #3353 was declined. i applied authors suggestions regarding using should_render method for automatic view selection. </desc> <cmt> [#4235] automatic view based on should_render method instead of content_types property </cmt> <cmt> [#4235] update chengelog </cmt> <iss> recognize `+json` content type suffix </iss>,automatic view mode based on should_render method
3066,"<desc> css: use integer values for font-size in css use correct ordering of @import ""invisible"" isn't a tag - presume its a class ""border-color"" defines the complete border python: use ""not"" instead of == ""[]"" for python prefer triple quoted docstrings prefer static functions where possible prefer modern style classes where possible remove semicolons; global: remove duplicated words words </desc> <cmt> browsers do not consistently handle non-integer values for font-size. </cmt> <cmt> simplify python code </cmt> <cmt> fix order of @import </cmt> <cmt> in css 2.1, any @import rules must precede all other rules (except the </cmt> <cmt> @charset rule, if present). </cmt> <cmt> pep8 prefers triple quoted with double quotes </cmt> <cmt> prefer tuple to array </cmt> <cmt> remove unused code </cmt> <cmt> make functions static where possible </cmt> <cmt> modern style classes </cmt> <cmt> remove useless semicolon from python </cmt> <cmt> duplicate the </cmt> <cmt> add missing semi-colon </cmt> <cmt> border-color > border </cmt> <cmt> invisible isn't a tag </cmt> <cmt> inherit from object </cmt> <cmt> remove duplicate duplicate words </cmt>",fix a variety of minor issues
3067,"<desc> this pr fixes a bunch of callback function signatures so that they align with the signatures expected by windows api. most changes are from __cdecl to __stdcall, which matters on x86, but not on x64 or arm64. cla signed. if not, go over here and sign the cla requires documentation to be updated i find it hard to believe that conhost.exe as shipped in windows would use callback functions with incorrect calling convention. perhaps the version that ships with windows is compiled with /gz (__stdcall-by-default)? but openconsole.sln isn't. all of these functions were found manually, so it's likely that there are more issues like this that i didn't find. it would be great if msvc had a warning similar to gcc's -wcast-function-type. the only one signature incompatibility i found that wasn't eliminated was with fontenumproc (i only fixed the calling convention, which is most important anyway), since a slightly different signature is being used that is similar to enumfontfamproc rather than enumfontfamexproc/fontenumproc, and a slightly more invasive change would be needed. </desc> <cmt> fix signatures of callback functions </cmt> <cmt> fix calling conventions of callback functions </cmt> <cmt> remove now-unnecessary casts of pointers to callback functions </cmt>",fix signatures of some callback functions
3068,<desc> two changes were made: make sure ray cluster is initialized before calling init() if the loop is already running _async_init is scheduled to run in current loop. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> assert ray is initialized </cmt> <cmt> make sure ray is initialized </cmt> <cmt> make sure ray is initialized before asyncio init </cmt> <cmt> use ensure_future to schedule coroutine if loop is running </cmt> <cmt> format code </cmt>,allow async_api to init when loop is running
3069,"<desc> fixes #417. </desc> <cmt> mac: convert from imageskia to nsimage to reserve dpi info. </cmt> <cmt> recognize the ""@2x"" suffix of icon's filename. </cmt> <cmt> fix converting empty v8 dictionary. </cmt> <cmt> use mate::dictionary instead of base::dictionaryvalue for options. </cmt> <cmt> mate::dictionary can represent arbitray type, which matches our use. </cmt> <cmt> dicard uses of base::value in native_window. </cmt> <cmt> support high dpi icon as window icon. </cmt> <cmt> fix compilation error. </cmt> <cmt> :memo: add docs on image support in atom-shell. </cmt> <cmt> wait for crash reporter spec longer. </cmt> <iss> [os x] tray icon for retina display </iss>",add support for high resolution icon
3070,"<desc> sorry, @ogrisel, missed a handful of information commits in the what's new section and feature_extraction.image module (from issue #3167) </desc> <cmt> adding notes section to img_to_graph and grid_to_graph re: np.matrix->np.ndarray </cmt> <cmt> adding what's new item for sklearn.feature_extraction.image np.ndarray changes </cmt>",minor docstring and what's new changes for issue 3167
3071,<desc> allow to generate changelog for tag which doesn't yet exist fixes #4718 component name move changelog generation to be before creating release artifacts fix problem with failing ci system on master branch create only one commit when creating a release exempt issues with stale label from changelog fix rc0 version tag. use next minor release for release candidates </desc> <cmt> consolidate commiting in release pipeline; generate changelog before tagging </cmt> <cmt> fix how rc0 is created </cmt> <iss> use `--future-release` in changelog generation </iss>,better changelog generation when releasing new version
3072,"<desc> this adds console to inner hits, explain, field-stats, request body, scroll docs. relates to #18160 @nik9000 care to take a look? </desc> <cmt> add console to scroll docs </cmt> <cmt> relates to #18160 </cmt> <cmt> add console to inner hits examples. </cmt> <cmt> add console to explain </cmt> <cmt> add console to field-stats docs. </cmt> <cmt> add console annotations to request body docs </cmt>","add console to docs for inner hits, explain, and friends"
3073,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. the exported default function does not return a color object, it returns the hexadecimal string value of the resolved color name. the type definition assumes it is a color object. i encountered this error when attempting to use the library in an existing typescript project using import. in testing this change to the type definition, i did notice that using require did not cause any typescript errors: const gethex = require(""colornames""); but importing the library this way did: import * as gethex from ""colornames""; the changes to the type definition in this pr work with both of the above examples. </desc> <cmt> update colornames types </cmt> <cmt> add name </cmt> <cmt> fix linter errors </cmt>",fix colornames default export type definition
3074,"<desc> fixes #5070 intersectsegmentcircledisplace has been replaced by an overloaded method of intersectsegmentcircle that now accepts a minimumtranslationvector as optional parameter. some design choices justifications use vector2 instead of vector3. this has required creating some static vector2 instances for temporary use similar to vector3 ones. to keep simple naming prefix v2 + letter seems the more compact/readable. these instances can be used by any other method in the class that needs temporary vector2. use vector2 operations when possible for readability use circle as argument (the old one didn't use it as circle class was created later in time) even if the new intersectsegmentcircle that accepts an mtv parameter could also replace the old one, it has been left for backwards compatibility (up for discussion, in my opinion we should remove it) i will squash all the changes when i get confirmation on what to do with the old method + code review. </desc> <cmt> fixed and replaced intersector intersectsegmentcircledisplace </cmt> <cmt> formatting </cmt> <iss> intersectsegmentcircledisplace does not work when the segment is partially inside the circle </iss>",fixes #5070 - fixed and replaced intersector intersectsegmentcircledisplace
3075,<desc> this updates the libcontainer dependency to 5210a236b92a8022a673108f347. its fixes issues where we changed the libcontainer.container struct's name to config.  it also includes the refactoring in libcontainer's dependency chain. </desc> <cmt> update libcontainer to 5210a236b92a8022a673108f347 </cmt> <cmt> docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael) </cmt> <cmt> update libcontainer references </cmt> <cmt> docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael) </cmt> <cmt> rename libcontainer.container to libcontainer.config </cmt> <cmt> docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael) </cmt>,update libcontainer dep to 5210a236b92a8022a673108f347
3076,"<desc> we've added several targets since the introduction of the target tier policy. based on experiences of those adding such targets, and discussions around such additions, clarify the target tier policy to make it easier to follow and work with. none of these changes substantively change the requirements on targets. (in some cases the changes do direct target submitters to follow specific process requirements for the addition of a target, such as how to respond to requirements, where to put target-specific documentation, or what should appear in that documentation. those changes are procedural in nature and document the procedures we already direct people to follow.) clarify how to quote and respond to the target tier policy requirements. several times, people have seemed unclear on how to respond to some of the policy requirements, particularly those that just state things the target developers must not do (e.g. not posting to prs that break the target). add a note that such requirements just need acknowledgement, nothing more. clarify dependency requirements in the face of cross-compilation. i previously phrased this confusingly in terms of ""host tools"", since that is the case where an exception applies (allowing proprietary target libraries commonly used by binaries for the target). rephrase it to apply equally to cross-compilation. this doesn't change the net effect of the requirements, since other requirements already cover the dependencies of the rust toolchain. clarify documentation about running binaries. the requirement for target documentation talks about ""running tests"", but tier 3 targets often don't support running the full testsuite, and in practice the documentation for how to run an individual binary may be more useful. change ""running tests"" to ""running binaries, or running tests"". explain where to place target-specific documentation (a subdirectory of platform-support, with a link from the platform-support entry for the target). add a template for target-specific documentation. </desc> <cmt> clarify how to quote and respond to the target tier policy requirements </cmt> <cmt> several times, people have seemed unclear on how to respond to some of </cmt> <cmt> the policy requirements, particularly those that just state things the </cmt> <cmt> target developers must *not* do (e.g. not posting to prs that break the </cmt> <cmt> target). add a note that such requirements just need acknowledgement, </cmt> <cmt> nothing more. </cmt> <cmt> make quoting and responding a ""must"" rather than an ""is encouraged to"", </cmt> <cmt> since it's easier to review the requirements that way. </cmt> <cmt> clarify dependency requirements in the face of cross-compilation </cmt> <cmt> the requirement on dependencies was phrased in terms of ""host tools"", </cmt> <cmt> but it was also intended to apply equally to targets that only support </cmt> <cmt> cross-compilation. only the exception (for libraries commonly needed for </cmt> <cmt> binaries on the target) was intended to apply to host tools. reword the </cmt> <cmt> requirement to talk about the dependencies required for ""compiling, </cmt> <cmt> linking,and emitting functional binaries, libraries, or other code for </cmt> <cmt> the target"", rather than generically in terms of dependencies for </cmt> <cmt> rustc/cargo. </cmt> <cmt> this doesn't change the net effect of the requirements, since other </cmt> <cmt> requirements already stated that the target can't make the rust </cmt> <cmt> toolchain depend on proprietary libraries. however, this should make the </cmt> <cmt> requirements clearer. </cmt> <cmt> clarify documentation about running binaries </cmt> <cmt> the requirement for target documentation talks about ""running tests"", </cmt> <cmt> but tier 3 targets often don't support running the full testsuite, and </cmt> <cmt> in practice the documentation for how to run an individual binary may be </cmt> <cmt> more useful. change ""running tests"" to ""running binaries, or running </cmt> <cmt> tests"". </cmt> <cmt> point to platform-support/ for target-specific documentation </cmt> <cmt> explain that target-specific documentation should appear in a </cmt> <cmt> subdirectory of platform-support, with a link from the target's entry on </cmt> <cmt> the platform-support page. </cmt> <cmt> add a template for target-specific documentation </cmt>",clarifications in the target tier policy
3077,<desc> fixes #127077 fixes #127078 </desc> <cmt> fix tabs list -> terminal dnd </cmt> <cmt> fix terminal dnd to editor </cmt> <cmt> drag and drop broken from terminal to editor in #125943 because it no longer </cmt> <cmt> accepted the terminal data transfer type and list views changed to drag text instead of </cmt> <cmt> resources. </cmt> <cmt> fixes #127077 </cmt> <iss> terminal tabs list to editor drag and drop stopped working </iss> <iss> terminal drag and hold on a different tab doesn't switch tab anymore </iss>,terminal drag and drop fixes
3078,"<desc> in modules/_datetimemodule.c, the char *timespec and char *specs[] can be made const.  their contents are never modified. in ndarray_get_format in modules/_testbuffer.c, char *fmt can be made const. </desc> <cmt> make specs and timespec be const </cmt> <cmt> make char *fmt be const </cmt>",const strings in modules/_datetimemodule.c and modules/_testbuffer.c
3079,"<desc> currently onnx runtime is doing shape and type inference on both branches of the if operator, regardless of which branch is executing in runtime. this can cause runtime errors in some cases: condition of the if node is based on shape / size of the input then and else branch have different return types this pass is folding an if node and it enables following tests: test_embedding_sequential_1 test_embedding_sequential_2 test_nllloss test_crossentropy test_embedding_bag_1d_per_sample_weights test_embedding_bag_2d_per_sample_weights </desc> <cmt> add pass </cmt> <cmt> add tests </cmt> <cmt> enable tests </cmt> <cmt> merge </cmt> <cmt> update dtype symbolic </cmt> <cmt> update pass </cmt> <cmt> clang format </cmt> <cmt> update utils file </cmt> <cmt> fix clang_tidy errors </cmt> <cmt> update pass </cmt> <cmt> update pass </cmt> <cmt> clang format </cmt> <cmt> update pass </cmt> <cmt> merge </cmt> <cmt> update pass </cmt> <cmt> update pass </cmt> <cmt> update pass </cmt> <cmt> update pass </cmt>",add a post-pass for if folding
3080,"<desc> contribute to lerna by solving an issue where npm is the hard-coded npm client while a user can choose to use yarn issue #1057 ran all the ""yarn test"" options added tests to verify the configuration params i added breaking change (fix or feature that would cause existing functionality to change) - possibly if someone is using yarn as their client but actually they depend on npm running under the hood i have read the contributing document. </desc> <cmt> support some run commands </cmt> <cmt> publish can now use custom npmclient </cmt>",use npmclient instead of hardcoded npm
3081,"<desc> closes #28383 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry the test code is inspired from a similar tests in raiseerror:  valid list_like:  this is my first pull request here and so i have taken all the necessary precautions, also i read the contributing guidelines. not much sure of  black pandas . problem: if columns is not passed a list-like value a substantial decrease in performance was observed. proposed solution: as mentioned in the issue by @willayd that function should raise and hence based on similar situation in the codebase, i have edited the file to raise typeerror. </desc> <cmt> updated reshape.py to validate columns in get_dummies </cmt> <cmt> added validation for the argument passed to columns </cmt> <cmt> added tests for the column validation </cmt> <cmt> the code is inspired from a similar tests in </cmt> <cmt> raiseerror: </cmt> <cmt> valid list_like: </cmt> <cmt> updated test_reshape.py with pep-8 code rec </cmt> <iss> pandas get_dummies validate ""columns"" input </iss>",pandas get_dummies validate columns input
3082,<desc> take care of mocks breaking the recent version of pytest. fixes #52347 tests n/a </desc> <cmt> fix invalid os.stat mock in tests </cmt> <cmt> fix leaking mock patch in tests </cmt> <cmt> closes #52347 </cmt> <iss> some unit tests crash on python 2.7 using pytest 4.2.1 </iss>,bugfix/ fix mocker patch in tests
3083,"<desc> #1987 was merged in before i could update the other pytorch examples. this should also close #1960 once it's merged in. </desc> <cmt> update run_glue to save optimizer and scheduler states, then resume training from a checkpoint </cmt> <cmt> update run_squad to save optimizer and scheduler states, then resume training from a checkpoint </cmt> <cmt> update run_ner to save optimizer and scheduler states, then resume training from a checkpoint </cmt> <cmt> update run_xnli to save optimizer and scheduler states, then resume training from a checkpoint </cmt> <iss> improving model saving and resuming </iss>",closes #1960 add saving and resuming functionality for remaining examples
3084,<desc> add norman layout under the minidox keyboard add keymap_extra def for norman layout re-org'ed the modifiers as explained in the readme corrected colour legend for kle that the readme links to my code follows the code style of this project. i have read the contributing document. </desc> <cmt> norman layout with lower and raise layers working </cmt> <cmt> * add keymap_extra def for norman layout </cmt> <cmt> * re-org'ed the modifiers as explained in the readme </cmt> <cmt> * corrected colour legend for kle that the readme links to </cmt> <cmt> use #pragma once in header file </cmt>,norman layout for the minidox keyboard
3085,<desc> this redirects stderr to /dev/null when the --help or --version arguments are used. it also shortens the help text so it fits within 80 chars. </desc> <cmt> shorten the spec-directory description </cmt> <cmt> redirect help and version stderr to /dev/null </cmt> <cmt> closes #1580 based on @zcbenz's suggestion. </cmt>,don't show error messages for version and help cli options
3086,<desc> defers some eager ctypes imports to allow most other functionality to work when ctypes is missing. closes #16331. </desc> <cmt> defer ctypes imports in _dtypes_ctypes module </cmt> <cmt> defer ctypes import in generated _distributor_init.py </cmt> <iss> make ctypes completely optional on windows </iss>,make ctypes optional on windows
3087,"<desc> as part of #76147, we're no longer going to skip injecting a migrateactions based on properties an associated allocateaction in the same phase. there are still other circumstances when we would not inject a migrateaction (e.g. when the user has already defined one), though. commit by commit is best, imho, but there's not a ton of diff here. </desc> <cmt> remove this extraneous migrateaction </cmt> <cmt> combine these tests </cmt> <cmt> imho the details don't matter much, and randomness captures the </cmt> <cmt> ""doesn't matter / either way"" components just fine. </cmt> <cmt> reorganize these just a little bit </cmt> <cmt> it reads more clearly to me this way </cmt> <cmt> ignore the allocate action when injecting migrate </cmt> <cmt> get these tests passing </cmt> <cmt> one last round of test cleanup </cmt>",inject migrate action regardless of allocate action
3088,"<desc> (my) tests are flaky--this pull request adds a missing dependency. the cli throws an error if /src/images/ doesn't exist (i.e., after running this recipe in an empty hello-world project.) is this okay? </desc> <cmt> feat(gatsby-recipes): add mdx images recipe </cmt> <cmt> recipes(fix): add gatsby-transformer-remark package to mdx-images recipe </cmt>",remove gatsby-transformer-remark package from mdx-images recipe
3089,"<desc> description: this uses a centralized method to update the plex media_player and sensor platforms, reducing calls to the server and refreshing both platforms in sync. done to prepare for a future improvement to the update mechanism. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist </desc> <cmt> update plex platforms together </cmt> <cmt> remove unnecessary methods </cmt>",central update for plex platforms
3090,"<desc> currently, not even the docs home page will load in ie9/10. some have had luck with polyfills, but accessing props in state initialization is an anti-pattern anyways, it should be set in componentwillmount which is a cleaner solution than polyfills or constructors. this issue is also affecting some other components as mentioned by @hhaidar in #4593. i haven't done a full scan yet to take a look. @hhaidar want to follow my lead here and get the rest shored up? pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: ""[component] fix leaky abstraction"". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( </desc> <cmt> [listitem] move props access for state initialization into componentwillmount, fixes #4042 </cmt> <cmt> [radiobuttongroup] move props access to componentwillmount for setting state, fixes #4223 </cmt>",fix error with props access in state assignment for ie9/10
3091,"<desc> this renames the n* and n*_ref tuple getters to val* and ref* respectively, and adds mut* getters. it also removes the cloneabletuple and immutabletuple traits. </desc> <cmt> implement show for 1-12 element tuples </cmt> <cmt> delegate tostr implementation to show for tuples </cmt>",implement show for 1-12 element tuples and improve the std::tuple api
3092,<desc> i hereby agree to the terms of the cla available at:  other add clickhouse-keeper-converter tool which allows converting zookeeper logs and snapshots into clickhouse-keeper snapshot format. </desc> <cmt> some code for snapshot deserialization </cmt> <cmt> add some functions for data conversion </cmt> <cmt> better </cmt> <cmt> remove unused flag </cmt>,tool for conversion of zookeeper data into clickhouse-keeper snapshot
3093,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. named export  function signature of seq/sequence </desc> <cmt> the factory variable can be imported as named import. </cmt> <cmt>  </cmt> <cmt> add override definitions for seq and sequence. </cmt> <cmt>  </cmt>,make factory can be used named import / add override definitions for seq and sequence
3094,"<desc> no functional change. </desc> <cmt> clarify event_free() documentation regarding pending/active events </cmt> <cmt> currently it's not clear as to whether ""first make it non-pending and </cmt> <cmt> non-active"" sentence requires user to take some action (e.g. call event_del(), </cmt> <cmt> which event_free() already does internally) or just describes what this </cmt> <cmt> function does from the developer point of view. </cmt> <cmt> fix a few trivial documentation typos </cmt>",clarify event_free() documentation + fix a few typos
3095,"<desc> get things in a state where the stdlib build passes as well as tests, but do not actually enable constraint propagation yet. </desc> <cmt> [constraint solver] disabling the shrink() pass results in new ambiguities. </cmt> <cmt> one expression in this test becomes ambiguous when the shrink() pass is </cmt> <cmt> disabled. enabling the constraint propagation pass disables the shrink </cmt> <cmt> pass. </cmt> <cmt> for now we'll run this with -propagate-constraints explicitly enabled </cmt> <cmt> and with the expected output changed. this is a regression that will </cmt> <cmt> need to be investigated and fixed in the solver. </cmt> <cmt> [constraint solver] tweak test based on using a bit more memory for -propagate-constraints. </cmt> <cmt> this test is trying to confirm that memory usage is independent and that </cmt> <cmt> follow-on expressions do not fail just because of the first failure, and </cmt> <cmt> now we naturally fail on another expression because of the additional </cmt> <cmt> memory used for -propagate-constraints. </cmt> <cmt> tweak the test to bump up the threshold and swap the order of </cmt> <cmt> expressions so that the now-failing expression is first. </cmt> <cmt> [constraint solver] fix memory corruption issue. </cmt> <cmt> we use simplifyconstraint() to activate other constraints, and then </cmt> <cmt> examine those constraints to find related disjunctions. in examining </cmt> <cmt> those active constraints, we were simplifying them in case they </cmt> <cmt> failed (which would allow us to bail out earlier). in doing so, we could </cmt> <cmt> potentially generate new disjunctions when we simplify an unresolved </cmt> <cmt> value member constraint. if we do that, we end up collecting these new </cmt> <cmt> disjunctions as part of the set of related disjunctions, but that's </cmt> <cmt> problematic because as part of exiting the solver scope to roll back </cmt> <cmt> changes we delete these disjunctions from the system. </cmt> <cmt> instead of actually simplifying the active constraints, just collect the </cmt> <cmt> disjunctions and move the active constraints back to the inactive list. </cmt> <cmt> with this change we can build the stdlib. </cmt>",fixup some issues with constraint propagation
3096,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> add portconfig type for detect port first argument </cmt> <cmt> update detect-port version </cmt>",add portconfig type for first argument from default function
3097,"<desc> this pr is bringing instruction per cycle for netdata using perf.plugin. component name perf.plugin 1 - set your /etc/netdata/netdata.conf as : perf = yes update every = 1 command options = cycles instructions emulation l1i 2 - compile this branch and take a look at  perf counters section. 3 - access  { ""plugin"": ""perf.plugin"", ""module"": ""hardware"" }, { ""plugin"": ""perf.plugin"", ""module"": ""cache"" }, { ""plugin"": ""perf.plugin"", ""module"": ""software"" }, </desc> <cmt> ipc_through_perf: add counter for perf.plugin </cmt> <cmt> ipc_through_perf: add new variable used to create charts </cmt> <cmt> ipc_through_perf: add new chart </cmt> <cmt> ipc_through_perf: fix chart name </cmt> <cmt> ipc_through_perf: update title </cmt>",update perf.events and add new charts
3098,"<desc> add open_wesocket_close_frame option to swlistenport websocket close frame code in $frame->code websocket close frame reason in $frame->reason use $server->set(array(""open_websocket_close_frame""=>true)) to enable the receiving of close frame in websocket server onmessage callback add test for flag open_websocket_close_frame </desc> <cmt> sync upstream </cmt> <cmt> add ""open_websocket_close_frame"" option for server </cmt> <cmt> add check for ""open_websocket_close_frame"" </cmt> <cmt> set initial value of zreason </cmt> <cmt> sync with unit-test </cmt> <cmt> add test for flag open_websocket_close_frame </cmt> <cmt> change test with new flag and new frame </cmt> <cmt> fix test </cmt> <cmt> unit test </cmt>","add open_websocket_close_frame flag, fix code and reason in websocket frame"
3099,"<desc> nano v3, gtr or skr pro boards this pr add support for native usb flash drive, using otg and usb host. stm32duino didn't merge my usb host pr yet, so i created new envs pointing to my stm32duino pr. native usb flash drive for marlin. #define usb_flash_drive_support #define use_otg_usb_host #20299 </desc> <cmt> add usb flash drive support for native usb host otg </cmt> <cmt> add support for gtr and skr pro </cmt> <cmt> not yet </cmt>",usb flash drive support using native usb host + msc
3100,"<desc> the following has always been an error because we require a common supertype to exist among the candidate inferences for a particular type parameter: declare function choose<t>(x: t, y: t): t; let a = choose(10, ""abc"");  // error, type '""abc""' not assignable to type '10' however, because we currently infer union types when instantiating a generic function type in the context of a non-generic function type, we don't report an error on the following: declare function foo<t>(cb: (x: number, y: string) => t, x: t, y: t): t; let b = foo(choose, ""abc"", 10);  // not an error, but should be with this pr we stop inferring union types in cases such as the above. this is a breaking change. all errors uncovered in the test baselines seem reasonable, but we'll have to see what results from the rwc tests. worst case we can tighten the rules only in --strictfunctiontypes mode. fixes #16107. </desc> <cmt> stop inferring unions for disjoint callback parameter inferences </cmt> <cmt> update tests </cmt> <cmt> accept new baselines </cmt>",don't infer unions for disjoint callback parameter candidates
3101,"<desc> this pr is the first in a series designed to remove painless type completely in favor of java class.  since we aren't supporting generic types, painless type is completely extraneous.  the goal here is to simply the painless code long term and remove anything unnecessary. the def 'marker' class has been added.  any def type in painless will use this marker class instead of object to denote the type is dynamic.  the marker class will be converted to object when byte code is written.  this does not add more code as the painless type currently must be checked to see if it's dynamic anyway.  by using java class consistent comparisons can be made during casting instead of checking for dynamic then checking against class.  this is simpler. this first step replaces painless type with java class for any casting done during compilation.  there should be no behavioural change. </desc> <cmt> painless: only allow painless type names to be the same as the </cmt> <cmt> equivalent java class or the imported version of the java class. </cmt> <cmt> fix doc error. </cmt> <cmt> add static methods to make creating painless casts obvious as to what is </cmt> <cmt> being boxed/unboxed. </cmt> <cmt> add a marker class for the def type to be used during type analysis. </cmt> <cmt> replace painless type with java class for casting. </cmt> <cmt> remove use of painless type in favor of java class in casting. </cmt>",replace painless type with java class during casts
3102,"<desc> trans: when coercing to box<trait> or box<[t]>, leave datum in it's original l-/r-value state. this fixes a subtle issue where temporaries were being allocated (but not necessarily initialized) to the (parent) terminating scope of a match expression; in particular, the code to zero out the temporary emitted by datum.store_to is only attached to the particular match-arm for that temporary, but when going down other arms of the match expression, the temporary may falsely appear to have been initialized, depending on what the stack held at that location, and thus may have its destructor erroneously run at the end of the terminating scope. fix #20055. (there may be a latent bug still remaining in fn into_fat_ptr, but i am so annoyed by the test/run-pass/coerce_match.rs failures that i want to land this now.) </desc> <cmt> trans: when coercing to box<trait> or box<[t]>, leave datum in its original l-/r-value state. </cmt> <cmt> this fixes a subtle issue where temporaries were being allocated (but </cmt> <cmt> not necessarily initialized) to the (parent) terminating scope of a </cmt> <cmt> match expression; in particular, the code to zero out the temporary </cmt> <cmt> emitted by datum.store_to is only attached to the particular </cmt> <cmt> match-arm for that temporary, but when going down other arms of the </cmt> <cmt> match expression, the temporary may falsely appear to have been </cmt> <cmt> initialized, depending on what the stack held at that location, and </cmt> <cmt> thus may have its destructor erroneously run at the end of the </cmt> <cmt> terminating scope. </cmt> <cmt> test cases to appear in a follow-up commit. </cmt> <cmt> fix #20055 </cmt> <cmt> test cases for issue #20055. </cmt> <cmt> note that i have not yet managed to expose any bug in </cmt> <cmt> trans::expr::into_fat_ptr; it would be good to try to do so (or show </cmt> <cmt> that the use of .to_lvalue_datum there is sound). </cmt> <iss> panic during unit tests (coerce_match) </iss>",fix trans coercions of box<[t]> and box<trait> in match arms
3103,<desc> fixes errors in typescript 3.9-beta reported in test_types_next we were previously relying on implicit children types (from functioncomponent and forwardrefcomponent) and the false assumption that every transition component implements the same children type. now that our ts types follow closely our (runtime) proptypes the issue was more obvious but typescript < 3.9 did not catch these. </desc> <cmt> [core] fix incorrect typings regarding transition components and children </cmt> <cmt> revert: use stable ts </cmt>,fix incorrect typings regarding transition components and chilren
3104,"<desc> adding nuspec for the package updating update-binver.ps1 to allow passing in the major/minor version instead of getting from release tag creating new build pipeline which takes a major/minor version as a parameter, updates the version in source and builds and signs, generates a nuget package and signs that, then publishes it i haven't tested the actual push command yet, as i'd like to get pr approval before doing so microsoft reviewers: open in codeflow </desc> <cmt> testing nuget build pipeline </cmt> <cmt> deleting </cmt> <cmt> set up ci with azure pipelines </cmt> <cmt> [skip ci] </cmt> <cmt> signing </cmt> <cmt> build.sourcesdirectory </cmt> <cmt> changing pattern </cmt> <cmt> exact path </cmt> <cmt> sign nuget </cmt> <cmt> x86 </cmt> <cmt> minimatch </cmt> <cmt> 230012 </cmt> <cmt> ready for nuget push </cmt> <cmt> adding push step </cmt> <cmt> updating package name </cmt>",azure pipeline to generate and publish microsoft.windowspackagemanager.utils nuget package
3105,<desc> added five new sites built by bejamas: mambu avenues multicoin capital argent meet flo changed bejamas creator cover. </desc> <cmt> chore(sites): add new sites built by bejamas </cmt> <cmt> chore(creators): update bejamas cover </cmt>,add new sites built by bejamas to showcase; change bejamas creator cover
3106,<desc> types of changes bug fix fix language.from_disk overwrites the meta.json file. bug fix fix trailing whitespace on morphology features. </desc> <cmt> fix language.from_disk overwrites the meta.json file. </cmt> <cmt> fix trailing whitespace on morphology features </cmt>,fix trailing whitespace and language.from_disk overwrites
3107,"<desc> adds the aws_profile environment variable to the command prompt for the agnoster theme. setting the aws_profile to anything containing production or ending in -prod will set the colour to yellow on red, otherwise it will be black on green </desc> <cmt> add aws_profile to prompt </cmt> <cmt> remove errant newline </cmt> <cmt> add aws: prefix to segment </cmt>",add aws_profile env var to prompt for agnoster theme
3108,"<desc> this pr is mainly to fix the conhost.exe not using the application manifest correctly and the operating system version cannot be detected correctly. related documents can be viewed #2053. this update also brings support for longpath to conhost.exe. closes #2053 cla signed. if not, go over here and sign the cla requires documentation to be updated when directwrite rendering is turned on with usedx, this application cannot display emoji on windows 10 before applying this pr. after applying this pr, it can be displayed normally. </desc> <cmt> fix conhost detect os version </cmt> <cmt> fix conhost.exe.manifest </cmt> <iss> usedx option no longer works in conhost </iss>",fix conhost.exe detect os version
3109,"<desc> laser_feature add two menu items under the laser control submenu when laser_feature is defined to fire a laser test pulse. item 1 sets the adjustable fire time from 1 to 999 milli-seconds and the second menu item fires the trigger. a beep will occur if use_buzzer is defined. if pwm is supported it will fire at the power pwm setting that was previously set, if not set it defaults to 80%. no pwm results in full power with the set time duration. supports alignment, testing and calibration of more powerful laser rigs. #define laser_feature #define reprap_discount_smart_controller none </desc> <cmt> laser percent power </cmt> <cmt> ""adding laser test fire function"" </cmt>","""add laser test fire function"""
3110,<desc> continuation #8807 closes #8807 </desc> <cmt> improved docstring for the solver parameter of logisticregression </cmt> <cmt> further improve docstring on n_jobs and solver </cmt> <cmt> added warning when self.solver == 'liblinear' & self.n_jobs != -1 </cmt> <cmt> in logisticregression </cmt> <cmt> corrected typo: warning => warnings </cmt> <cmt> tst/doc reverse doc and add test </cmt>,improved docstring for the n_jobs parameter of logisticregression
3111,"<desc> as people are asking (#3142) how to use the new rnn symbol in mxnet, we provide this simple example as a demo. more importantly, this allow us to identify the use cases and issues we need to address. currently we only have a wrapper to cudnn rnn cell, so it is not available for cpu mode. also we are working to stabilize the interfaces, as you can see from the comments of the demo, there are still many workarounds need to be applied to be able to work nicely with the rest of the mxnet high level apis. @sbodenstein @antinucleon one important issue i need to mention is that currently the lstm cell takes all the parameters as a concatenated big vector. this is not compatible with our initializer architecture. i only verified it is able to run and the perplexity is decreasing. but i did not compare with our old lstm implementation results. </desc> <cmt> rnn-cell demo (push to server for testing) </cmt> <cmt> a running example with cudnn rnn cell </cmt>",rnn cell demo with ptb lstm language model
3112,"<desc> fixes: #21441 </desc> <cmt> homectl: also acquire ""cheap"" passwords for homectl update/passwd </cmt> <cmt> in 57bb9bcba5563c040ee0c41f58e3730a006a8de2 support was added to read </cmt> <cmt> ""cheap"" passwords from env vars and stuff before issuing the first </cmt> <cmt> operation, instead of waiting for it until the first operation failed. </cmt> <cmt> this was added for most verbs of ""homectl"", but two were left out: </cmt> <cmt> update + passwd. add it there too. </cmt> <cmt> homework: fix message typo </cmt> <cmt> homework: don't try to shift uidmap for already activated home areas </cmt> <cmt> when we want to operate on an already activated home area we so far </cmt> <cmt> tried to reapply the uidmapping logic. we shouldn't do that, it's </cmt> <cmt> already applied after all. </cmt> <cmt> we only want to apply this for newly activated home areas. hence check </cmt> <cmt> for the right homesetupflags flag for it home_setup_already_activated. </cmt> <cmt> the patch is actually in theory a two-liner. except that so far we don#t </cmt> <cmt> pass the homesetupflags flags down all necessary functions where the </cmt> <cmt> uidmap stuff will eventually run. hence this larger than intended </cmt> <cmt> commit. </cmt> <cmt> homework: also apply uid shifting when changing passwords/resizing/updating home areas </cmt> <cmt> this adds uidmap shifting also when resizing/updating/changing </cmt> <cmt> passwords. prviously i thought we didn't have to, because the user is </cmt> <cmt> not going to access the uidmap if we only quickly activate the home </cmt> <cmt> area. but this thinking is wrong, because the three operations will </cmt> <cmt> result in an update ~/.identity fie to be written, and we should do that </cmt> <cmt> with uidmap applied, so that its ownership maps down to nobody below as </cmt> <cmt> intended. </cmt> <cmt> fixes: #21441 </cmt> <cmt> homework: fix a bad error propagation </cmt> <cmt> homework: add debug log message whenever we applied a uidmap to a mount </cmt> <iss> spurious fails in test-46-homed </iss>",homed uidmap (and other) fixes
3113,<desc> combine prs #10200 #10206 #10209 #10212 #10215 #10217 to 2.1 minor edits to the reference of various cleos commands select one: select any that apply: </desc> <cmt> applied new command reference template </cmt> <cmt> applied revised reference template </cmt> <cmt> applied command ref template </cmt> <cmt> applied new reference template </cmt> <cmt> applied reference template </cmt> <cmt> applied reference template </cmt> <cmt> fix broken link and other edits on cleos create account ref :doc </cmt> <cmt> minor edits on cleos create key ref :doc </cmt> <cmt> minor edits on cleos create account ref :doc </cmt> <cmt> minor edits on cleos get transaction ref :doc </cmt> <cmt> minor edits on cleos wallet import ref :doc </cmt> <cmt> minor edits on cleos wallet keys ref :doc </cmt> <cmt> minor edits on cleos net connect ref :doc </cmt> <cmt> minor edits on cleos net disconnect ref :doc </cmt> <cmt> minor edits on cleos net peers ref :doc </cmt> <cmt> minor edits on cleos net status ref :doc </cmt>,update reference for various cleos commands - 2.1
3114,"<desc> current way of running testlightgbm.exe on windows doesn't return actual status code. take a look at the logs in master: ...  proposed call in this pr makes master windows job red. looks like appleclang doesn't have leak sanitizer. so set sanitizers to only ""address;undefined"" for macos. -- the c compiler identification is appleclang 12.0.0.12000032 -- the cxx compiler identification is appleclang 12.0.0.12000032 ... clang: error: unsupported option '-fsanitize=leak' for target 'x86_64-apple-darwin19.6.0' it seems that the clang/llvm shipped by apple does not have -fsanitize=leak support.   msvc is just about getting support of asan    current support is limited to x86 and x64 on windows 10. send us feedback on what you'd like to see in future releases. your feedback helps us prioritize other sanitizers for the future, such as /fsanitize=thread, /fsanitize=leak, /fsanitize=memory, /fsanitize=undefined, or /fsanitize=hwaddress. you can report bugs here if you run into issues.  ... cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\_deps\googletest-build\googletest\gtest.vcxproj] gtest-all.cc cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\_deps\googletest-build\googletest\gtest.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\_deps\googletest-build\googletest\gtest.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\_deps\googletest-build\googletest\gtest.vcxproj] gtest.vcxproj -> d:\a\1\s\build\lib\debug\gtestd.lib building custom rule d:/a/1/s/cmakelists.txt cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] test_chunked_array.cpp cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\testlightgbm.vcxproj] test_common.cpp cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] test_main.cpp cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\a\1\s\build\testlightgbm.vcxproj] ... i had to remove the following test because it fails with many setups os + compiler 2^971 * (2^53 - 1 + 1/2) : the smallest number resolving to inf @cyfdecyf could you please take a look at this? for example, it fails on windows + msvc 19.16.27045.0; ubuntu focal + clang 10.0.0. tested with swapped compilers: everything is ok. tested thread sanitizer: linux is ok, macos fails - issue created #4331. </desc> <cmt> run cpp tests with sanitizers </cmt> <cmt> re-trigger ci </cmt> <cmt> continue </cmt>",run cpp tests with sanitizers on linux and macos
3115,<desc> #1913 into 1.1 branch </desc> <cmt> fix link extractor tests for non-ascii characters from latin1 document </cmt> <cmt> url path component should use utf-8 before percent-encoding (that's what </cmt> <cmt> browsers do when you open scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html </cmt> <cmt> and follow the links) </cmt> <cmt> this matches current w3lib v1.14.1 </cmt> <cmt> add link extractor test for non-ascii characters in query part of url </cmt>,fix link extractor tests for non-ascii characters from latin1 document (pr #1913)
3116,<desc> this is a 10x improvement for searching for characters. this also contains the patches from #46713 . feel free to land both separately or together.  r? @bluss fixes #46693 </desc> <cmt> move rust memchr impl to libcore </cmt> <cmt> use memchr in [u8]::contains </cmt> <cmt> support 16 bit platforms </cmt> <cmt> remove the unused ascii_only field in chareqsearcher </cmt> <cmt> split out char searcher from multicharsearcher </cmt> <cmt> move charsearcher to its own section in the file </cmt> <cmt> fill in forward searcher impl for char </cmt> <iss> str::find(char) is slower than it ought ot be </iss>,use memchr for str::find(char)
3117,<desc> /area kubeadm /sig cluster-lifecycle milestone 1.23 kubernetes/kubeadm#2537 follow up of #103063 part of kubernetes/kubeadm#2046 action required: kubeadm: remove the deprecated flag --experimental-patches for the init|join|upgrade commands. the flag --patches is no longer allowed in a mixture with the flag --config. please use the kubeadm configuration for setting patches for a node using {init|join}configuration.patches. </desc> <cmt> kubeadm: remove deprecated --experimental-patches </cmt> <cmt> kubeadm: disallow the mixture of --config and --patches </cmt>,disallow the mixture of --config and --patches & remove deprecated --experimental-patches
3118,"<desc> continues and closes #14337. addresses comments in #14337: add parameter to affinitypropagation class, add test, add what's new entry. this is the last open pr from the 2019 scipy sprint. </desc> <cmt> added value checks and random state parameter to method </cmt> <cmt> changed default parameter to none instead of 0 </cmt> <cmt> added numpy randomstate to the check </cmt> <cmt> replaced inline validation with check_random_state from utils and pointed at glossery </cmt> <cmt> needed a different default parameter to pass the default way this has been working in the past </cmt> <cmt> updated to conform with flake8 stds </cmt> <cmt> sync with upstream. </cmt> <cmt> add random_state to affinitypropagation class. </cmt> <cmt> add test. </cmt> <cmt> add what's new entry and versionadded directive. </cmt>",add random_state parameter to affinitypropagation
3119,<desc> also upgraded to the latest version of the pivot table library. closes #772 and #334. </desc> <cmt> close #772: upgrade to latest pivottable.js lib </cmt> <cmt> feature: pivots are now regular visualizations that can be *saved*. </cmt>,pivot tables are now regular visualizations that can be saved
3120,"<desc> not much to say that's not already contained in the title. pr checklist applies to #1972 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request added members and methods to support this operation. the shortcut keys, variable and method names and code readability may require some feedback. validation steps performed tested with a large grid layout. unit tests passed. </desc> <cmt> added an alt key hook </cmt> <cmt> refactor a block of code into a method </cmt> <cmt> again refactored existing code </cmt> <cmt> apparently win+alt does not reach fancyzones </cmt> <cmt> using ctrl+alt instead of win+alt for now </cmt> <cmt> it works </cmt> <cmt> fixed vd change </cmt> <cmt> remove unused member </cmt> <cmt> fix compilation error </cmt> <cmt> enable shrinking </cmt>",use ctrl+win+alt+arrows to expand/shrink windows to adjacent zones
3121,"<desc> please point out the problem, i'll fix it as soon as possible </desc> <cmt> fix bug stop stopspan when not createspan </cmt> <cmt> fix bug stop stopspan when not createspan </cmt> <cmt> change the agent log level to millisecond </cmt> <cmt> add the function of the specified-agent-config </cmt> <cmt> merge skywalking master to mine </cmt>",add the function of the specified agent config
3122,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. add it to notneededpackages.json. </desc> <cmt> feat(theme-ui): remove theme-ui package </cmt> <cmt> theme-ui provides its own types as of v0.6.0 </cmt> <cmt> ( </cmt> <cmt> feat(theme-ui__components): remove theme-ui__components package </cmt> <cmt> @theme-ui/components provides its own types as of v0.6.0 </cmt> <cmt> ( </cmt>,remove theme-ui and theme-ui__components typings (no longer needed)
3123,"<desc> just some improvements i made in the course of my retroplayer work. the bug fixes here don't affect krypton, so they don't need to be backported. for when master is branched for v18 development. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) </desc> <cmt> caddonsdirectory: improve code clarity in getscriptsandplugins() </cmt> <cmt> caddondirectory: don't clear existing items from item list parameter </cmt> <cmt> binaryaddoncache: add function to get add-on by id and type </cmt> <cmt> binaryaddoncache: optimize update() function </cmt> <cmt> dvdcodecutils: fix conversion to av_malloc missed by 09acfb8 </cmt> <cmt> dvdcodecutils: fix buffer overflow if height is odd </cmt> <cmt> stringutils: template-ize join() to support more container types </cmt> <cmt> playmedia() builtin: don't clear video playlist if item is not video </cmt>",fixes and code improvements from game branch
3124,"<desc> previously, invalid attributes were silently accepted and ignored. </desc> <cmt> [parse/sema] diagnose invalid attributes for paramdecl </cmt> <cmt> previously, invalid attributes were silently accepted and ignored. </cmt> <cmt>  </cmt> <cmt> [parse/sema] diagnose invalid attributes for generictypeparamdecl </cmt> <cmt> previously, invalid attributes were silently accepted and ignored. </cmt> <cmt>  </cmt>",diagnose invalid attributes for paramdecl and generictypeparamdecl
3125,"<desc> fixes #17618 padding is only added to the ""left"" and ""bottom"" sides to bring total area to 48 by 48.  this is done prior to the rotation so it works for both rtl and ltr. </desc> <cmt> increase total area of text selection handle to 48 by 48 </cmt> <cmt> remove extra param </cmt> <iss> selection handle touch target is too small in textfields. </iss>",increase text handle size to 48 by 48
3126,"<desc> solves #2544. unfortunately, coretemp sysctls are quite heavy calls. </desc> <cmt> add intel cpu temperature chart to freebsd plugin </cmt> <cmt> correct cycle for rrddim in cpu temperature chart </cmt> <cmt> fix data type and mib for coretemp sysctl in freebsd plugin </cmt> <cmt> limit sprintf usage in coretemp module in freebsd plugin </cmt>",add cpu temperature chart to freebsd plugin
3127,"<desc> added a new job in the alignments tool which tells you which faces are in the faces folder, but aren't found in the alignments file. this is useful for me because my alignments file is saved every 10 frames it goes through. and if it gets stopped, i want to delete the pngs it made that aren't saved in the alignments file. </desc> <cmt> add cli option </cmt> <cmt> add logic </cmt>",remove leftover faces alignments job
3128,"<desc> update prometheus to 2.13.1 update prometheus operator to 0.34.0 remove prometheusoperator.crdapigroup. this experimental arg was briefly available and has not been working since 0.26.0. it is no longer available on the prometheus-operator container. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> update core components </cmt> <cmt> remove unsupported crdapigroup param </cmt> <cmt> this parameter already does not work and has not for many versions of </cmt> <cmt> the operator, thus removing it is not a breaking change </cmt>","up versions of operator, prometheus"
3129,<desc> replaced assert_raises and assert_raises_regex with pytest.raises context manager. related to #14216 </desc> <cmt> fix assert_raises and assert_raises_regex in test_locally_linear.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_spectral_embedding.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_mds.py </cmt> <cmt> fix assert_raises and assert_raises_regex in test_t_sne.py </cmt>,maint:fix assert raises in sklearn/manifold/tests/
3130,"<desc> when possible i simply cherry-picked fixes from the master branch, but sometimes i had to redo them manually. here i started with activesupport, i'm not sure i eliminated them all yet because the test suite is segfaulting on my machine. this is still a work in progress, but opening a pr give me a ci run which is helpful. </desc> <cmt> :warning: calling uri.open via kernel#open is deprecated, call uri.open directly </cmt> <cmt> introduce keyword arguments for some as::cache methods </cmt> <cmt> since rediscachestore#write_entry takes kwargs, we needed to kwargsify all these methods </cmt> <cmt> in order to eliminate ruby 2.7 warnings. </cmt> <cmt> it's a little bit bigger patch than i expected, but it doesn't warn on ruby 3, </cmt> <cmt> and it doesn't introduce any incompatibility on loder rubies, so it may not be a bad thing anyway. </cmt> <cmt> :number is not a keyword argument </cmt> <cmt> i18n.translate takes kwargs options </cmt>",fix many ruby 2.7 warnings for the 6.0 stable branch
3131,"<desc> parse ': class' in a protocol inheritance clause identically to ': anyobject'. this allows us to simplify some code. it also results in cleaner printing of generated interfaces. fixes </desc> <cmt> parse: simpler handling of 'class' in protocol inheritance list </cmt> <cmt> instead of treating this as its own thing, just parse it as if </cmt> <cmt> the user wrote 'anyobject'. </cmt> <cmt> astprinter: don't print redundant 'where self : anyobject' </cmt>",fix printing of class-constrained protocols
3132,"<desc> a board can now define the following linker symbols to configure its flash storage layout: _micropy_hw_internal_flash_storage_start _micropy_hw_internal_flash_storage_end _micropy_hw_internal_flash_storage_ram_cache_start _micropy_hw_internal_flash_storage_ram_cache_end and optionally have a second flash segment by configuring micropy_hw_enable_internal_flash_storage_segment2 to 1 and defining: _micropy_hw_internal_flash_storage2_start _micropy_hw_internal_flash_storage2_end f413, f439, h743, l4xx and wb55 have been converted to this new scheme. </desc> <cmt> stm32/flashbdev: support generic flash storage config via link symbols. </cmt> <cmt> a board can now define the following linker symbols to configure its flash </cmt> <cmt> storage layout: </cmt> <cmt> _micropy_hw_internal_flash_storage_start </cmt> <cmt> _micropy_hw_internal_flash_storage_end </cmt> <cmt> _micropy_hw_internal_flash_storage_ram_cache_start </cmt> <cmt> _micropy_hw_internal_flash_storage_ram_cache_end </cmt> <cmt> and optionally have a second flash segment by configuring </cmt> <cmt> micropy_hw_enable_internal_flash_storage_segment2 to 1 and defining: </cmt> <cmt> _micropy_hw_internal_flash_storage2_start </cmt> <cmt> _micropy_hw_internal_flash_storage2_end </cmt> <cmt> stm32/boards: convert f413,f439,h743,l4xx,wb55 to new flash fs config. </cmt>",support generic flash storage config via linker symbols
3133,"<desc> the core issue seems to be with skip_child. the skip_child function makes some assumption regarding the state you are in. in particular, it seems that you cannot be right before a key so that the first step of skip_child is to bring you to a key. that's never a problem when the key you are searching for is found. when the key you are searching found is not found, then it is possible that you may end up just before a key. by convention, keys are at the level of the object, so the code in the main branch and in the 0.9.x is wrong in such cases because skip_child will encounter a key, it will decrement the depth and conclude that it is back in the parent. this is bad. this is not the nicest fix in the world and it may have small negative impact on performance but i am preoccupied by patching 0.9.x as soon as possible. a better solution might be to ensure that when a key is not found, we are never right before a key. i had implemented that (it is not hard), but it is more invasive. this patch here is very small. fixes  #1521 </desc> <cmt> reduction of the missing-key bug. </cmt> <cmt> adding the other test cases. </cmt> <cmt> really simple fix for 1529 </cmt> <cmt> nicer code. </cmt> <iss> simdjson 0.9.x ondemand parser fails on dynamic document (possible regression) [fixed in 0.9.3, unfixed in main branch] </iss>",my third attempt at fixing issue 1521 (not being merged due to performance concerns)
3134,"<desc> a previous commit fixed the runtime code, this pr fixes the compatibility issues for the unit tests. </desc> <cmt> make tests compatible with python 3 </cmt> <cmt> * change dictionnaries iteritems() to items() </cmt> <cmt> remove six dependency for dictionnaries iterators </cmt>",make object_detection dictionaries compatible with python3
3135,"<desc> set a weekly ci running every sunday night to all models from onnx model zoo with latest onnx.checker and onnx.shape_inference motiviation to enhance the robustness of onnx, add more tests. </desc> <cmt> add test_model_zoo and weekly ci </cmt> <cmt> change to use windows </cmt> <cmt> fix syntax error </cmt>",test all models from onnx model zoo with latest onnx.checker
3136,<desc> @mourner @danzel simplified version of my previous guide update. publishing plugins on npm now has its own section and the amd/commonjs section is trimmed down quite heavily and focuses around a single piece of sample code. </desc> <cmt> seperate npm and module loader info. condense module loader section </cmt> <cmt> fix merge conflict </cmt> <cmt> fix spelling </cmt>,module loaders + publishing on npm
3137,"<desc> as per request in #4934, new option addition in settings under texturepacker to specify the array of interpolation modes per scale factor. no breaking changes in the api, and fully backwards-compatible assuming bicubic (which was the default) in case nothing is being specified. contributor agreement has been signed and emailed. </desc> <cmt> fix #4934: add texturepacker interpolation option to settings </cmt> <cmt> document texturepacker settings change in changes </cmt>",option in texturepacker.settings to specify the interpolationmode when scaling
3138,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. the full diff is messy as i reorganized the types to match the order of </desc> <cmt> updated react-slider types to 1.1 </cmt> <cmt> reorganized types to match react-slider doc </cmt>",update react-slider types to 1.1
3139,<desc> unit tests are always killed because out of memory. this pr reduces memory footprint and skips some heavy tests. also support pytorch1.9 and python3.9 in this pr. skip tests of building all configs. reduce base_channels of resnet in most of the tests. reduce the input size. delete some redundant tests. </desc> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt> <cmt> fix ci </cmt>,fix ci out of memory & add pytorch1.9 python3.9 unit tests
3140,"<desc> i tried to use prophetnet with seq2seqtrainer, but it failed. the error message told me: this is because the collator uses prepare_seq2seq_batch() in _encode(), but prepare_seq2seq_batch() is not implemented in prophetnet tokenizer. i've gotten kind advices in the huggingface forum, and implemented the function.  the modifications are as below: add prepare_seq2seq_batch() in /src/transformers/tokenization_prophetnet.py. to use .view in loss computation in seq2seqtrainer, i add a part where it is confirmed that logits is contiguous in /src/transformers/modeling_prophetnet.py. i've checked it works on cpu and gpu as below: !python finetune_trainer.py \ --learning_rate=3e-5 \ --do_train --do_eval --evaluate_during_training \ --max_source_length 511 \ --per_device_train_batch_size 2 \ --predict_with_generate \ --n_train 300 \ --n_val 100 \ --model_name_or_path microsoft/prophetnet-large-uncased \ --data_dir $xsum_dir \ --output_dir tmp_gpu \ --overwrite_output_dir although the pretrained_positional_embeddings_sizes is 512,  if --max_source_lenght is set to 512, cuda error occurs. i'm sorry, but i have not been able to identify the cause of this. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case.  documentation guidelines, and here are tips on formatting docstrings.  i'm sorry, i misunderstood what is being asked here.  now i understood that the ./tests/  code is needed. i'm working on this, but i'm getting errors in formatting etc. and using black won't fix it. i added related content to the test_tokenization_prophetnet.py. i changed the environment and made it work again according to the instructions, and it seems that formatting with black works appropriately. @sshleifer thank you for kindly answering my questions in the forum! </desc> <cmt> simply insert t5tokenizer's prepare_seq2seq_batch </cmt> <cmt> update/add some 'import' </cmt> <cmt> fix runtimeerror caused by '.view' </cmt> <cmt> moves .view related error avoidance from seq2seq_trainer to inside prophetnet </cmt>",adding the prepare_seq2seq_batch function to prophetnet
3141,<desc> this pr adds alerts permission group with alerts:read and alerts:write. these scopes are added to all roles within the app except owners and also added to the relevant issue alert and metric alert endpoints. eventually we will have a setting to turn on alerts:write for owners there are also some frontend changes to enable buttons which were previously behind projects:write </desc> <cmt> members can now edit alerts </cmt> <cmt> members can now edit alerts </cmt> <cmt> small change to project scopes </cmt>,add new scopes for editing/viewing alert rules
3142,"<desc> what did you implement: closes #3142 the aws::lambda::eventsourcemapping resource was being created with wrong the dependson attribute if custom roles were defined using a string to reference a logical role name elsewhere defined in the serverless.yml.  the eventsourcemapping resource was previously only checking for roles defined via a direct arn or the fn::getatt syntax.  it did not support referencing a role's name directly (i.e.. role: mydefaultrole as documented here) the result of this is that the eventsourcemapping resource would set the dependson to the default iamrolelambdaexecution role.  if custom roles were used for all functions then the iamrolelambdaexecution role would not exist in the compiled cloud formation and the deploy would fail with template format error: unresolved resource dependencies [iampolicylambdaexecution] in the resources block of the template how did you implement it: this builds upon #3083 as it enables the custom role to be referenced directly without using the fn::getatt syntax. how can we verify it: deploy any serverless.yml with an event stream using only functions with custom roles (e.g. the sample in #3142 ) todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> add failing test </cmt> <cmt> fix failing test </cmt> <cmt> add additional test for custom role at provider </cmt> <cmt> add type check for a string </cmt> <cmt> fix lint issues </cmt> <iss> serverless fails to deploy service with a kinesis stream event: unresolved resource dependencies [iampolicylambdaexecution] in the resources block of the template </iss>",fix event streams when functions have direct reference to custom roles
3143,"<desc> two patches that improve the c code quality. the first is important, as it fixes a few calls through function pointers of the wrong type (which cause undefined behavior). the second just shuts up the build by introducing a few casts and removing some unused variables. </desc> <cmt> fix: wrong function types in ufunc_object.c </cmt> <cmt> assign_reduce_identity_{zero,one} were treated as </cmt> <cmt> pyarray_assignreduceidentityfunc, but that type has </cmt> <cmt> an extra void* argument. added the argument. </cmt> <cmt> fix: remove unused variables and add casts </cmt> <cmt> makes the build complete with fewer warnings. </cmt>",call through wrong function pointer type + minor stuff
3144,<desc> fixes #91290 </desc> <cmt> scaffold out link provider proposed api </cmt> <cmt> part of #91290 </cmt> <cmt> get link providers passing all the way through to the renderer </cmt> <cmt> register via link manager </cmt> <cmt> handle link on exthost </cmt> <cmt> update </cmt> <iss> allow extensions to contribute links to the terminal (aka link providers) </iss>,proposed terminal link provider api
3145,<desc> lots of changes here but i wanted to get gles closer to gl. i hope we can all test this and shove it in asap :) i've tested on gbm be aware that to use clinuxrenderergles you need to use sw decoding/rendering or use vaapi this brings all the goodies present with #13428 #13481 #13507 #13968 #13973 #14295 android amlogic ios vaapi </desc> <cmt> [gles] videoplayer: rewrite yuv - rgb conversion </cmt> <cmt> linuxrenderergles: cleanup confusing log messages </cmt>,"yuv2rgb rework, tonemapping, and other cleanup"
3146,"<desc> relands #47616, but as an opt-in change to allow developers to migrate to the fixed version. the original pr caused golden tests to fail since the snackbar's offset was updated. before fix after fix set all instances of scaffold.shouldsnackbarignorefabrect to true after this pr is merged. fix all failing tests. there are likely two main types: a) fix all golden tests to expect the new change. b) fix any widget tests that expect the snackbar to appear higher than it should. the difference should simply be the size of the floating action button's rect. once scaffold.shouldsnackbarignorefabrect is set to true by default (in a subsequent pr), remove the parameter from all instances of scaffold. related issues addresses #47202 addresses #43716 i added the following tests: same tests as original pr, but with the shouldsnackbarignorefabrect flag turned on. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc and migration guide: </desc> <cmt> renamed some tests in snack_bar_test.dart </cmt> <cmt> improved one test from snack_bar_test.dart </cmt> <cmt> now the test checks certain position y of fab </cmt> <cmt> fixed issue where snack bar was higher then should be </cmt> <cmt> added tests for testing height of snackbar. </cmt> <cmt> moved test 'floating snackbar is positioned above floatingactionbutton' to group 'snackbar position' </cmt> <cmt> improved test by removing padding details, and renaming. </cmt> <cmt> moved test ""snackbar bottom padding is not consumed by viewinsets"" to group ""snackbar position"" </cmt> <cmt> and improved test for testing with universal behavior </cmt> <cmt> add soft breaking change flag </cmt>",snackbarbehavior.floating offset fix - soft breaking change
3147,"<desc> this is an alternative fix for #12180. </desc> <cmt> tty-ask-password: copy argv[] before forking child </cmt> <cmt> another fix in style of bd169c2be0fbdaf6eb2ea7951e650d5e5983fbf6. </cmt> <cmt> let's also avoid strjoina() in a loop (i.e. stack allocation). while in </cmt> <cmt> this specific caseone could get away with it (since we'd immediately </cmt> <cmt> afterwards leave the loop) it's still ugly, and every static checker </cmt> <cmt> would be totally within its rights to complain. </cmt> <cmt> also, let's simplify things by not relying on argc, since it's redundant </cmt> <cmt> anyway, and it's nicer to just treat things as null terminated strv </cmt> <cmt> array. </cmt> <cmt> fixes: #12180 </cmt> <cmt> tty-ask-password: drop redundant local variable </cmt> <cmt> tty-ask-password: no need to initialize something already nul initialized to nul </cmt> <cmt> tty-ask-password: simplify signal handler installation </cmt> <cmt> tty-ask-password: re-break comment </cmt>",let's copy argv[] before forking
3148,"<desc> fixes  #66304 r? @gilescope shows both the actual as well as the expected panic value when a test with should_panic(expected=...) fails. this makes should_panic more consistent with assert_eq. i am not sure whether printing the any::type_id() is useful, is there something better that we could print for non-string panic values? </desc> <cmt> print a more useful error message on should_panic mismatch </cmt> <cmt> replace some asserts with assert_eq for better error readability </cmt> <iss> better error messages for #[should_panic] tests with expected strings </iss>",more useful test error messages on should_panic(expected=...) mismatch
3149,<desc> ondidchangeselectionrange and ondidchangecursorposition passed different data to their call backs. this makes them consistent. </desc> <cmt> add cursor to ondidchangecursorposition event object </cmt> <cmt> only pass event to the editor </cmt> <cmt> add cursor to the docs </cmt> <cmt> ondidchangeselectionrange emits object with ranges + selection </cmt> <cmt> update ondidchangeselectionrange doc string </cmt> <cmt> update doc string in selection::ondidchangerange </cmt> <cmt> update cursor::ondidchangeposition doc string </cmt>,make cursor / selection events consistent
3150,"<desc> here are the changes again with the revisions added in. </desc> <cmt> playing catchup </cmt> <cmt> adding sections, and fixing grammar: </cmt> <cmt> added bodhi linux, as well as a how does a person contribute section. </cmt> <cmt> also ran through and fixed grammar. </cmt> <cmt> fixing ordering. </cmt> <cmt> didn't fix ordering the first time. also forgot to mention in previous commit that i added a few github links to previously listed software, since they weren't listed. </cmt> <cmt> i also previously fixed the wording on some of the softwares from ""best"" to an actual description of what they do. </cmt> <cmt> capitalization and official client utilities section </cmt> <cmt> added pea utilities and pea extractor and pihole </cmt> <cmt> also added more open source repositories for programs. </cmt> <cmt> fixing personal language, </cmt> <cmt> and adding more in-depth descriptions. </cmt> <cmt> grammar is hard </cmt> <cmt> grammar </cmt> <cmt> added how to contribute to toc </cmt> <cmt> added to table of contents </cmt> <cmt> grammar and toc change </cmt> <cmt> fixing linking </cmt> <cmt> table of contents links didn't function, now they do. </cmt> <cmt> added nomacs image viewer </cmt> <cmt> adding suggested changes: </cmt> <cmt> cleaned up from before. </cmt> <cmt> aligning to master: </cmt>","more grammar, more programs 2:"
3151,"<desc> caches vectors in the class and uses a new helper to opportunistically shrink/grow as viewport sizes change in order to save performance on alloc/free of commonly used vectors. scratches a perf itch. i work here. wil tests added no add'l doc. am core contributor. two fixes: for outputting lots of text, the base renderer class spent a lot of time allocating and freeing and reallocating the cluster vector that adapts the text buffer information into render clusters. i've now cached this vector in the base render class itself and i shrink/grow it based on the viewport update that happens at the top of every frame. to prevent too much thrashing in the downward/shrink direction, i wrote the til::manage_vector helper that contains a threshold to only shrink if it asks for small enough of a size relative to the existing one. i used 80% of the existing size as the threshold for this one. for outputting lots of changing colors, the vt graphics output engine spent a bunch of time allocating and reallocating the vector for graphicsoptions. this one doesn't really have a predictable size, but i never expect it to get extremely big. so i just held it in the base class. ran the til unit test checked render cluster vector time before/after against big.txt from #1064 checked vt graphics output vector time before/after against cacafire case before after big.txt cacafire </desc> <cmt> cache the vector for clusters and manage its size based on the viewport to save a ton of alloc/dealloc work. </cmt> <cmt> hold vt graphics options vector in class to save alloc/realloc/free time. </cmt>",improve perf by avoiding vector reallocation in renderer clusters and vt output graphics options
3152,"<desc> most pager, by default, does not support control characters. so, the idea is to add a test after the set of pager to change it to less -r so control chars can be interpreted first, test for pager, than bat, than change. </desc> <cmt> added support of most </cmt> <cmt> only test if bat exists </cmt> <cmt> faster this way </cmt>",adding support for most pager
3153,"<desc> this adds getclassloader permission for ingest-attachment and mapper-attachments plugins. i will backport the mapper attachment fix to 2.3. closes #16864 </desc> <cmt> can not extract text from office documents (.docx extension) </cmt> <cmt> add rest test for: </cmt> <cmt> * .doc </cmt> <cmt> * .docx </cmt> <cmt> the later fails with: </cmt> <cmt>  </cmt> <cmt> ==> test info: seed=db93397128b876d4; jvm=1; suite=1 </cmt> <cmt> suite: org.elasticsearch.ingest.attachment.ingestattachmentrestit </cmt> <cmt> 2> reproduce with: gradle :plugins:ingest-attachment:integtest -dtests.seed=db93397128b876d4 -dtests.class=org.elasticsearch.ingest.attachment.ingestattachmentrestit -dtests.method=""test {yaml=ingest_attachment/30_files_supported/test ingest attachment processor with .docx file}"" -des.logger.level=warn -dtests.security.manager=true -dtests.locale=bg -dtests.timezone=europe/athens </cmt> <cmt> failure 4.53s | ingestattachmentrestit.test {yaml=ingest_attachment/30_files_supported/test ingest attachment processor with .docx file} <<< failures! </cmt> <cmt> > throwable #1: java.lang.assertionerror: expected [2xx] status code but api [index] returned [400 bad request] [{""error"":{""root_cause"":[{""type"":""parse_exception"",""reason"":""error parsing document in field [field1]""}],""type"":""parse_exception"",""reason"":""error parsing document in field [field1]"",""caused_by"":{""type"":""tika_exception"",""reason"":""unexpected runtimeexception from org.apache.tika.parser.microsoft.ooxml.ooxmlparser@7f85baa5"",""caused_by"":{""type"":""illegal_state_exception"",""reason"":""access denied (\""java.lang.runtimepermission\"" \""getclassloader\"")"",""caused_by"":{""type"":""access_control_exception"",""reason"":""access denied (\""java.lang.runtimepermission\"" \""getclassloader\"")""}}}},""status"":400}] </cmt> <cmt> >    at __randomizedtesting.seedinfo.seed([db93397128b876d4:53c706ab86441b2c]:0) </cmt> <cmt> >    at org.elasticsearch.test.rest.section.dosection.execute(dosection.java:107) </cmt> <cmt> >    at org.elasticsearch.test.rest.esresttestcase.test(esresttestcase.java:395) </cmt> <cmt> >    at java.lang.thread.run(thread.java:745) </cmt> <cmt>  </cmt> <cmt> related to #16864 </cmt> <cmt> add getclassloader perm for tika in ingest </cmt> <cmt> add doc and docx rest test to mapper attachment along with </cmt> <cmt> getclassloader permission </cmt> <iss> can not extract text from office documents (`.docx` extension) </iss>",fix attachments plugins with docx
3154,"<desc> currently, when an agent takes a new omnichannel request(manual selection routing method), the agent is redirected from the room preview to home template, which makes a bad user experience. to fix this wrong behavior, an agent will be redirected to the home template just in case they are no longer allowed to access the room, for instance, when another agent takes the chat. </desc> <cmt> fix the ux when an agent takes a new chat. </cmt> <cmt> remove unnecessary parentheses. </cmt>",keeps the agent in the room after accepting a new omnichannel request
3155,<desc> fix the bug of simple_test with proposals remove the redundant codes in fast_rcnn </desc> <cmt> fix wrong keyword argument 'nms_cfg' in htc </cmt> <cmt> fix wrong keyword argument 'nms_cfg' in htc </cmt> <cmt> fix the bug of simple_test with proposals </cmt> <cmt> remove the redundant codes in fast_rcnn </cmt>,fix bug of simple_test with proposals
3156,"<desc> part 8. we have an in-house rule to compare explicitly against false instead of using the logical not operator (!). however, this hasn't historically been enforced, meaning that there are many violations in the source at present. we now have a checkstyle rule that can detect these cases, but before we can turn it on, we need to fix the existing violations. this is being done over a series of prs, since there are a lot to fix. </desc> <cmt> more fixes in libs/ </cmt> <cmt> fixes in x-pack/plugin/sql </cmt> <cmt> fixes in server action/admin/indices </cmt> <cmt> fixes in client and server </cmt> <cmt> fixes in server </cmt> <cmt> fixes in server </cmt> <cmt> fixes in server </cmt> <cmt> fixes in server </cmt> <cmt> fixes in server </cmt> <cmt> fixes in server </cmt> <cmt> more fixes </cmt>",replace not operator with explicit false check - part 8
3157,"<desc> cherry pick #36587, #36662, #36908, and #36917 into stable-2.5 tower_credential.py ansible version 2.5 </desc> <cmt> fix credentials for tower api v2 </cmt> <cmt> (cherry picked from commit 640749d54f727c1408512f064564056735484b6b) </cmt> <cmt> tower cred: implement credential /api/v1/ kind compatability </cmt> <cmt> (cherry picked from commit 9cb4b70e279e25231a8770b817112b744893b125) </cmt> <cmt> tower cred: filter user name lookup by the proper key </cmt> <cmt> (cherry picked from commit cd6855275e42a564201d93810b89ba7e885d1e06) </cmt> <cmt> tower cred: update kind options in documentation </cmt> <cmt> (cherry picked from commit 8a41233202e01700459735a8dd67502e512261d5) </cmt> <cmt> tower cred: support credential kind/type for /api/v1/ and /api/v2/ (#36662) </cmt> <cmt> older versions of tower (3.1) don't have a concept of credentialtypes </cmt> <cmt> (this was introduced in tower 3.2).  this change detects older versions </cmt> <cmt> of pre-3.2 tower-cli that *only* support the deprecated kind </cmt> <cmt> attribute. </cmt> <cmt> (cherry picked from commit 641f8b4ef6a706f8e45a317445b30eadf3e3f5ba) </cmt> <cmt> add changelog fragment </cmt>",cherry pick tower credential fixes to stable-2.5
3158,"<desc> pyenv related docs - macos big sur pyenv issue can be fixed by adding commands into ~/.zshrc file having airflow_home and source code in ${home} can lead to disastrous effect of deleting all the file in the airflow folder. added a warning message to prevent deletion read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> breeze setup-autocomplete zshrc reload </cmt> <cmt> pyenv issue fix -macos big sur </cmt> <cmt> warning message about airflow_home and source code in same path -- initialize-local-virtualenv command </cmt> <cmt> pyenv issue fix -macos big sur </cmt> <cmt> warning message about airflow_home and source code in same path -- initialize-local-virtualenv command </cmt>","pyenv related docs added, warning message in breeze initialize-local-virtualenv command"
3159,"<desc> also, deprecate getoccurrences and replace it with an appropriate getdocumenthighlights api that matches the roslyn api and properly handles highlights across multiple files. </desc> <cmt> extract code for getting syntactic document highlights into its own function. </cmt> <cmt> get semantic document highlights as well through the new api. </cmt> <cmt> no need to tweak spans in syntactic highlights. </cmt> <cmt> use the filename that is in scope. </cmt>",ensure that getoccurrences not return items not in the file asked for.
3160,"<desc> fixes #12181 mimics native behaviour. android unaffected. </desc> <cmt> add a minimum distance that needs breaking on ios each time scrolls stopped. </cmt> <cmt> testing and tests </cmt> <cmt> tweak docs </cmt> <iss> after drag and stop, finger lift can still cause a small position shift </iss>",let ios have a minimum scroll movement threshold to break before motion starts
3161,"<cmt> meta: add lagom_unsupported helper function to serenity.sh </cmt> <cmt> meta: don't depend on toolchain for lagom target in serenity.sh </cmt> <cmt> - only call ensure_toolchain for non-lagom targets </cmt> <cmt> - use host addr2line, we can't expect the i686 toolchain's addr2line to </cmt> <cmt> support the host's binary executable format </cmt> <cmt> - don't export serenity_arch and toolchain_dir, don't need them anymore </cmt> <cmt> meta: make 'serenity.sh run lagom' run lagom executables </cmt> <cmt> running the tests will be moved to a separate test command which can </cmt> <cmt> then leverage the availability of different targets and run either unit </cmt> <cmt> tests on the host or the image in qemu in self-test mode. :^) </cmt>",serenity.sh tweaks and better lagom support
3162,<desc> docstring lint errors fixed. </desc> <cmt> update model.py </cmt> <cmt> fixed lint error: one-line docstring summary should be followed by a blank line </cmt> <cmt> fixed lint errors </cmt> <cmt> one-line docstring summary should be followed by a blank line </cmt> <cmt> and 2 spaces for inline comments </cmt> <cmt> update model.py </cmt> <cmt> fixed further lint errors </cmt> <cmt> update utils.py </cmt> <cmt> fixed further lint errors </cmt> <cmt> update utils.py </cmt> <cmt> update model.py </cmt>,fixed lint errors for docstring affecting sketch_rnn
3163,"<desc> issue: #10167 exposed sketchpickerprops.presetcolors for the color control component. stop click event propagation at the popup level, to give user the chance to click on the hex input box and edit the color value this way. one side-effect of this change is that now the user will have to click on the color control button to close the color picker, instead of closing it automatically per mouse click. is this testable with jest or chromatic screenshots? no. does this need a new example in the kitchen sink apps? no. does this need an update to the documentation? yes, included in this pr. </desc> <cmt> expose sketchpickerprops.presetcolors for the color control component </cmt> <cmt> of addon:controls. </cmt> <cmt> add onkeydown and onblur handler for the color picker. </cmt> <cmt> add documentation for  option of color control. </cmt>",expose presetcolors for the color control
3164,"<desc> i've hit cases where pbuf_alloc() returns a nullptr.  in the original code, it would happily try to dereference this, and i'd get ""exception 28"".  i've updated udpcontext to check for this condition, and pass along that something has gone wrong.  in the case of send(), that means returning false, and for append(), return that 0 bytes were actually appended. </desc> <cmt> check that pbuf_alloc doesn't return nullptr </cmt>",udpcontext - check after pbuf_alloc for errors
3165,<desc> implemented playback controls for offline usage updated sources of getting modules/hardware status based on the new changes in hmi </desc> <cmt> dreamview: implemented playback controls for offline usage </cmt> <cmt> dreamview: reflected hmi proto changes </cmt>,implemented replay controls for offline usage & reflected hmi proto changes
3166,"<desc> fixes #12067 in cases where the same (embedded) texture is being loaded into multiple map slots, a separate videonode is created for each slot but only one has a .content entry containing the actual image data, presumably to save space. there appears to be no data in the fbxtree.connections about these duplicate images though, so i track them via absolute paths (all embedded images still keep a track of the original absolute path to the image on the computer the file was made on), and then loop over possible duplicates after all the images are parsed, and for duplicate pairs where only one has an entry in the image map, create a corresponding entry for the other. also fixed a bug  in ascii format where the videonode.content is an empty string so an entry consisting of just data:jpeg;base64, was being created in the imagemap. this was making it seem like this error was only coming up for binary format files while in fact ascii format was just creating blank textures for these duplicates. </desc> <cmt> fbxloader correctly parse duplicate maps </cmt> <cmt> typo </cmt> <iss> fbxloader: some textures on mixamo model fail to load </iss>",fbxloader correctly parse duplicate embedded textures
3167,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see latest flow config here and new api documentation for connectroutes here increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update redux-first-router typings with api changes as of v1.9.8 </cmt> <cmt> scrub trailing commas </cmt> <cmt> fix style of author declarations </cmt>",update type definitions to v1.9
3168,<desc> use configuration::getinstance()->supportsshareablevao() in place of cc_texture_atlas_use_vao. and fix gl_ext_discard_framebuffer always disable in eaglview.mm. </desc> <cmt> use configuration::getinstance()->supportsshareablevao() in place of cc_texture_atlas_use_vao; </cmt> <cmt> fix gl_ext_discard_framebuffer always disable in eaglview.mm; </cmt> <cmt> fix gl_ext_discard_framebuffer always disable in eaglview.mm (fix compile fail on early ios sdk 4.0); </cmt>,configuration of vao in runtime
3169,"<desc> while looking into #38307, i noticed some confusing wording in the asset pipeline guide: rails/guides/source/asset_pipeline.md lines 36 to 45 aeac447 rails automatically adds the sass-rails gem to your gemfile, which is used by sprockets for asset compression: ruby gem 'sass-rails'  using the --skip-sprockets option will prevent rails from adding them to your gemfile, so if you later want to enable the asset pipeline you will have to add those gems to your gemfile. also, specifically adding them to your gemfile add those gems is confusing because the preceding paragraph only mentions one gem (sass-rails). i discovered that this is a result of removing mentions of uglifier and coffee-rails from that paragraph in #35994. so i've opened this pr as a follow-up to #35994 to clean up the confusing wording that was left in the guide. while i was in there, i also clarified the purpose of the sass-rails gem and added links to </desc> <cmt> clean up leftover plural references in asset pipeline guide </cmt> <cmt> prior to ab123a33d2460dcdc5c36001cef5316eadc75fb3, this guide mentioned </cmt> <cmt> that three gems (sass-rails, uglifier, and coffee-rails) would be added </cmt> <cmt> to the gemfile by default, unless the --skip-sprockets option was </cmt> <cmt> used when generating the application. </cmt> <cmt> however, ab123a33d2460dcdc5c36001cef5316eadc75fb3 removed uglifier and </cmt> <cmt> coffee-rails from the guide (to reflect the switch to webpacker for </cmt> <cmt> managing javascript in rails 6). now that only sass-rails is left, the </cmt> <cmt> guide should say ""adding this to your gemfile"" instead of ""adding them </cmt> <cmt> to your gemfile"" and ""add that gem"" instead of ""add those gems"". </cmt> <cmt> [ci skip] </cmt> <cmt> clarify what sass-rails is used for in asset pipeline guide </cmt> <cmt> the original text ""used by sprockets for asset compression"" was written </cmt> <cmt> when this sentence was summarizing the purpose of three gems: </cmt> <cmt> sass-rails, uglifier, and coffee-rails. </cmt> <cmt> however, ab123a33d2460dcdc5c36001cef5316eadc75fb3 removed uglifier and </cmt> <cmt> coffee-rails from this sentence. now that only sass-rails is left, we </cmt> <cmt> can be more specific about what it is used for: compiling sass </cmt> <cmt> stylesheets. </cmt> <cmt> [ci skip] </cmt> <cmt> link to the sass-rails repo and sass-lang.com in asset pipeline guide </cmt> <cmt> we link to the sprockets-rails repository in the preceding paragraph, </cmt> <cmt> so it seems appropriate to also link to the sass-rails repository in </cmt> <cmt> this paragraph. and since readers of this guide may not know what sass </cmt> <cmt> is, it also seems appropriate to link to the sass-lang.com website. </cmt> <cmt> [ci skip] </cmt>",fix confusing wording in asset pipeline guide [ci skip]
3170,<desc> remove support file update from create-cypress-tests wizard and update vue instructions. test it right now by typing in terminal (inside npm project) yarn create cypress-tests-beta </desc> <cmt> v0.0.590 </cmt> <cmt> v0.0.591 </cmt> <cmt> update vue plugins </cmt> <cmt> remove support file injection from wizard </cmt> <cmt> v0.0.592 </cmt> <cmt> revert package.json </cmt>,update plugins and remove support
3171,"<desc> this pull request is to provide a kafka source/sink pair to simulate a kafkashuffle that can: read topics that are already partitioned by key and process them without partitioning them again (avoid shuffles); and use this to decompose the job into smaller jobs and independent pipelined regions that failover independently. extend datastream api to allow user-defined sinkfunction to manipulate watermark kafka shuffle producer change write timestamp and watermark information together with a record in kafka use keygrouprangeassignment to assign records to different kafka partitions kafka shuffle consumer change, kafka fechter change each consumer read partitions equal to the key group indices that it got assigned. for now, the number of partitions is enforced to equal to the number of consumer parallelism. kafkashufflefechter encapsulates the logic of record emitting and watermark emitting. this change added tests: end-2-end tests partition assignment tests some other tests are missing: specific watermark tests failover tests dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (yes) the serializers: (don't know) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (yes) if yes, how is the feature documented? (javadocs) </desc> <cmt> [flink-15670][core] provide a utility function to flatten a recursive properties to a first level property hashtable </cmt> <cmt> in some cases, kafkaproducer#propstomap for example, properties is used purely as a hashtable without considering its default properties. </cmt> <cmt> [flink-15670][connector] adds the producer for kafkashuffle. </cmt> <cmt> kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected. </cmt> <cmt> [flink-15670][connector] adds the consumer for kafkashuffle. </cmt> <cmt> kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected. </cmt> <cmt> [flink-15670][connector] kafka shuffle api part </cmt> <cmt> kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected. </cmt> <cmt> [flink-15670] kafka shuffle test case + add log4j2 file </cmt> <cmt> kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected. </cmt>",provide a kafka source/sink pair as kafkashuffle
3172,"<desc> @ahtn, just wanna make sure it's cool for me to merge this into qmk - it looks like you did most of the hard stuff with this :) if you want any attribution, let me know, or open a pr to the lets-split-support branch here, and we'll merge that in before this goes to master. @climbalima, if you want your keymap added to this as well, feel free to open a pr as well! (now or at any point in the future) todo make an actual default keymap write up more about the tech/keyboard in the readme work pm_reset into native reset with pro_micro flag </desc> <cmt> one half working </cmt> <cmt> i2c working </cmt> <cmt> images, docks, clean-up [skip ci] </cmt> <cmt> add options to config.h </cmt> <cmt> remove uno_slave for now, even though it's freakin cool </cmt>",add let's split support
3173,<desc> removes a bit of unnecessary headers and gets rid of some direct dependencies on other headers. reduces the amount of rebuilding necessary if certain headers change in the future. </desc> <cmt> yuzu/configuration/configure_system: remove unused header inclusions </cmt> <cmt> yuzu/configuration/configure_debug: remove unused header inclusions </cmt> <cmt> yuzu/configuration/configure_per_general: remove unused header inclusions </cmt> <cmt> yuzu/configuration/configure_touchscreen_advanced: remove unnecessary header inclusions </cmt> <cmt> yuzu/configuration/configure_input_player: forward declare types where applicable </cmt> <cmt> allows removing the inclusion of the main input common header from the </cmt> <cmt> ui config header. </cmt>,remove unnecessary inclusions where applicable
3174,"<desc> fix cmake generate ios project, default arch config run fail on ios11 device cmake cmd: cmake .. -gxcode -dcmake_toolchain_file=../cmake/ios.toolchain.cmake </desc> <cmt> arch_dir only useful for search linux prebuilt libs </cmt> <cmt> add ios app target only_active_arch property </cmt> <cmt> set xcode property for application, include all depend target </cmt>",correct ios project config when using cmake -gxcode generate (3.17 round 2 test)
3175,"<desc> fixes #4358 ignores some as they seem out of scope for the repository. (more like a challenge or ""codethrough"" than an educational resource or tutorial.) build a discord clone with react js for beginners build a youtube clone with react js for beginners the 5-day react javascript challenge membuat clone aplikasi terkenal dengan react js efek animasi dengan javascript as this is not really a collection of videos for a course or series. it's an accumulation for random videos. ignores challenge 5 hari ngoding react js as this link appears twice in this pr. moves django untuk pemula from id.md to en.md since the tutorial is in english and renamed it to python django tutorial 2018 for beginners to match the source title. everything i ignored was reviewed subjective, could be nice to give them a peek and comment if anyone disagrees with an ignored resource. read our contributing guidelines put lists  in alphabetical order, correct spacing. followup check the output of travis-ci for linter errors! </desc> <cmt> fixes #4358 </cmt> <cmt> update title to match source </cmt>","adds ""python django tutorial 2018 for beginners"" and ""belajar es6 - javacsript gaya baru"""
3176,"<desc> this pr adds the implementation of nep-35's like= argument, allowing dispatch of array creation functions with __array_function__ based on a reference array. there are two ways to dispatch, details below. the first is via python api (as demonstrated by np.ones and np.full), where array_function_dispatch is used, but differently than the existing dispatch for compute functions, where it's dispatched usually on the first argument, this is dispatched on the like= keyword argument, returning (like,). we also check if like is not none as a performance optimization, see #16935 (comment) . the second dispatch occurs via c through splitting array_implement_array_function in two functions. the first function remains very similar to how it was originally implemented (array_implement_array_function) but adds a step to remove like= argument before calling downstream libraries -- downstream libraries shall not add like= to their signatures. the second function (array_implement_c_array_function) will also remove the like= argument, but it will also extract the reference array from it and will gather the public_api python function by doing an import on np.function_name, where function_name shall be passed by the calling function. the usage of the c dispatch is very straightforward and optimized for the case where like=none, adding minimal overhead to such functions. the necessary work will thus be only done when a reference array is passed, such as importing the numpy python function -- this can still be improved by using a lookup mechanism to avoid reimporting for each subsequent call but it was decided not to do that in this pr. the caller function will still need to add a like argument to its keyword list and parse that, but it will not be used anywhere other than the dispatcher function, it will also need to call the c dispatcher and check for its return value, if it returns py_notimplemented it will continue with numpy's implementation, otherwise return that value (from downstream library) immediately. </desc> <cmt> enh: add like= kwarg via __array_function__ dispatcher to asarray </cmt> <cmt> enh: add new function for __array_function__ dispatching from c </cmt> <cmt> this new function allows dispatching from c directly, while also </cmt> <cmt> implementing the new like= argument, requiring only minimal </cmt> <cmt> changes to existing array creation functions that need to add </cmt> <cmt> support for that argument. </cmt> <cmt> enh: add like= support to numpy.array </cmt> <cmt> the implementation uses array_implement_c_array_function, thus </cmt> <cmt> introducing minimal complexity to the original _array_fromobject </cmt> <cmt> code. </cmt> <cmt> bug: fix like= dispatcher for np.full </cmt> <cmt> enh: remove np.asarray like= dispatcher via python </cmt> <cmt> np.asarray can rely on np.array's c dispatcher instead. </cmt> <cmt> tst: add some tests for like= argument </cmt> <cmt> tests comprise some of the functions that have been implemented already: </cmt> <cmt> * np.array (c dispatcher) </cmt> <cmt> * np.asarray (indirect c dispatcher via np.array) </cmt> <cmt> * np.full (python dispatcher) </cmt> <cmt> * np.ones (python dispatcher) </cmt> <cmt> enh: remove like= argument during array_implement_array_function </cmt> <cmt> enh: add like= kwarg to ones and full </cmt> <cmt> bug: prevent duplicate removal of like= argument </cmt>",implement nep-35's like= argument
3177,"<desc> these test were very slow on pypy and flaky on windows because they relied on refcount semantics to close the underlying mmap object when calling __del__. this pr refactors them to use flush instead, which is sufficient to prove the point of the tests. also update documentation to prefer flush to __del__, and point out the shortfalls of __del__ use a pytest fixture to get a temporary directory rather than a local solution. </desc> <cmt> tst: avoid refcount semantics, speed up tests </cmt> <cmt> doc: update documentation of numpy.memmap </cmt>",avoid refcount semantics in using numpy.memmap
3178,"<desc> this adds a phantom template that can be used to add additional type information to other types, which allows for stronger typing between types represented by the same type. applies this to priorityload and priorityavailability, both of which are represented by a std::vector<uint32_t>. risk level: low testing: uts for phantom, everything else is compile time docs changes: n/a release notes: n/a fixes #5570 </desc> <cmt> upstream: use phantom types for load/availability </cmt> <cmt> uses a phantom type that allows embedding additional type information </cmt> <cmt> into a simple type to add type safety to usages of priorityload and </cmt> <cmt> priorityavailability. </cmt> <cmt> this ensures compile time safety when passing around these types, </cmt> <cmt> ensuring that they are not used interchangeably. </cmt> <cmt> expose default ctor </cmt> <cmt> always include default ctor </cmt> <cmt> add types file </cmt> <cmt> format </cmt> <cmt> document weird case </cmt>",add phantom types to load/availability
3179,"<desc> fixes #15473 minor text+sample change: in 3.x, the microsoft.aspnetcore.diagnostics.healthchecks package is implicit from the shared framework. the 2.x text is fine as it is. the microsoft.extensions.diagnostics.healthchecks package comes in transitively via the microsoft.aspnetcore.diagnostics.healthchecks package, so there's no need for the app to reference it. thanks @lol768! </desc> <cmt> health checks topic package reference update </cmt> <cmt> package is transitively referenced </cmt> <cmt> package is transitively referenced </cmt> <iss> is this up to date with asp.net core 3.0? </iss>",health checks package reference updates
3180,<desc> this migrates all of our unit tests that were previously suffixed with .unit.test.js to a single test/unit folder removing the redundant suffix. a root tsconfig.json has also been added to enable type checking the newly converted tests to help prevent test errors from incorrect usage. </desc> <cmt> move unit tests to one folder </cmt> <cmt> migrate unit tests to typescript </cmt>,move unit tests to one folder and migrate them to typescript
3181,"<desc> original pull-request #21533 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> podarray left pad not multiple of element crash fix </cmt> <cmt> updated style check </cmt> <cmt> cleanup podarray </cmt> <cmt> remove unused method </cmt> <cmt> fix error (found by @kitaisreal) </cmt> <cmt> fixed podarray </cmt> <cmt> pod array left pad not multiple of element crash fix </cmt> <cmt> cleanup podarray </cmt>",cherry pick #21533 to 21.1: cleanup podarray
3182,<desc> trigger the change event on the next tick. this means that multiple changes to a track's mode will only result in a single change event on its associated texttracklist rather than 3 events as it may be currently. fixes #5159. </desc> <cmt> add helper to event target to queue events </cmt> <cmt> queuetrigger change events </cmt> <cmt> lint error </cmt>,async change events in texttracklist with eventtarget#queuetrigger
3183,"<desc> this allows user a way to specify directories and/or files to ignore: 869abb1 adds parsing of new watchoptions: excludefiles and excludedirectories in tsconfig as well as command line 9cd3e93 adds a way to create noopwatcher for files and directories that are being watched. dddd906 adds a way to exclude invoking callback for excluded things from sys itself. this means no invoke for excluded path if its invoked from recursive directory watching or not watching directories that are excluded on os that don't support recursive watching (like linux) 0a8d84f handles the server host configuration and external/inferred projects watch options with ignore. 496939d reloading projects, reloads project from scratch cd18da8 file updates when reloading are reflected this provides a way on systems where watching can be expensive and letting user refresh things if something changes rather than us having to poll or rely on events fixes #33335, #36035, #36243, #36394 </desc> <cmt> parse excludedirectories and excludefiles </cmt> <cmt> use watch factory in typings installer </cmt> <cmt> some refactoring for watchfactory </cmt> <cmt> create noop watcher if file or directory being watched is excluded </cmt> <cmt> baselines without using exclude watch options </cmt> <cmt> baselines including exclude option </cmt> <cmt> handle exclude options in the system watches </cmt> <cmt> add test without exclude option for recursive directory watching </cmt> <cmt> test baselines with exclude option </cmt> <cmt> always set syslog </cmt> <iss> initializing js/ts features is extremely slow with wsl and node_modules </iss> <iss> add a way to exclude file or directory watching </iss> <iss> typescript server won't start on wsl </iss> <iss> tsserver.js/typingsinstaller.js is watching ignored directories (causing cpu load) </iss>",add way to exclude files and directories to watch
3184,"<desc> after upgrading to latest, i have begun to have issues with url-loader being able to resolve file-loader, and .cache/app.js being able to resolve socket.io-client.  this is likely because i am using pnpm in my particular repository. url-loader uses a fallback of file-loader, but it only provides a simple string.  url-loader also doesn't provide file-loader as a production dependency, nor does it list it as a peer dependency, so it would need to get it from somewhere else. i'm not sure why this only started breaking now, but this is the error i get: error #98123  webpack generating javascript bundles failed cannot find module 'file-loader' require stack: - <require stack leading to url-loader> file: /path/to/node_modules/typeface-poppins/files/poppins-latin-600.woff what i've done here is simply resolved that to a fully qualified path, relative to gatsby. additionally, i have added an alias for socket.io-client, because .cache/app.js now imports it, but webpack cannot find it because the project i am working on doesn't have it installed in its dependencies.  that's to fix this error: error #98124  webpack generating development javascript bundle failed can't resolve 'socket.io-client' in '/path/to/project/.cache' if you're trying to use a package make sure that 'socket.io-client' is installed. if you're trying to use a local file make sure that the path is correct. file: .cache/app.js both of these fixes work great in my testing.  the only thing i can't be sure of is if the fallback for url-loader will have unintended side effects. additionally, because socket.io-client is used directly by gatsby, it should be installed as a production dependency.  if not, then yarn 2 will break, because it won't be able to retrieve it from socket.io. </desc> <cmt> provide fully qualified path for url-loader's fallback </cmt> <cmt> create resolution for socket.io-client, for import in .cache/app.js </cmt> <cmt> include socket.io-client as dependency </cmt>",add explicit dependency on socket.io-client and explicitly set url-loader fallback
3185,<desc> on formidablelabs/victory-chart#527 a new prop was added to victoryaxisprops - invertaxis. updating the definition of victoryaxisprops with the new prop </desc> <cmt> update victoryaxisprops with invertaxis prop </cmt> <cmt> update victoryaxisprops with invertaxis prop </cmt>,"adding ""invertaxis"" to ""victoryaxisprops"" definition"
3186,"<desc> fixes #10051 added an optional argument for_partial_fit=false to _validate_params which bypasses warnings about max_iter and tol added for_partial_fit=true to _validate_params calls in partial_fit methods for both sgdclassifer and sgdregressor i appreciate that this could have been done through the use of set_max_iter=false but it seemed clearer to me to have a dedicated flag. first contribution to this project, so i apologize if i've done something horrifically wrong </desc> <cmt> partial fit warnings disabled </cmt> <cmt> partial fit warnings disabled for regressor </cmt> <cmt> style improved </cmt> <cmt> tests added </cmt> <cmt> pycodestyle passing </cmt> <cmt> rejiggered format </cmt>",fix for erroneous max_iter and tol warnings for sgdclassifier when using partial_fit
3187,"<desc> add 'not null' option to alert if... input when selected, disable value input fix validator_config field to send operator when selected and not null only when corresponding option is selected update usesingleviewresource hook to add error handling on updateresource/createresource methods update error handling on edit/create so modal does not close test plan requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> add not null condition option + related logic </cmt> <cmt> fix error handling </cmt> <cmt> add error handling on create </cmt>",add 'not null' condition option to modal
3188,"<desc> also change a bug! to delay_span_bug closes #74018 </desc> <cmt> delay bug for non-universal regions in member constraints </cmt> <cmt> call type_of for opaque types later in compilation </cmt> <cmt> this ensures that various wf checks have already been done before we </cmt> <cmt> typeck item bodies. </cmt> <iss> ice when playing around with existential types, impl trait </iss>",compute underlying type of impl trait types later in compilation
3189,"<desc> commits compilations of : toggle menu for psu from lcd pannel from the prepare menu, accessible when is not printing, you have the possibility to turn off the psu when is on et vice versa. from the host, you can turn off or turn on the psu then the menu is updated accordingly. from the lcd message, the printer status is reported ready or off respectively when the psu is on or off. turn off power supply off-load disable the high current outputs and wait a little before to turn off the psu, because the interrupting capacity of the psu is unknown. could be a function if needed by other. no bed config for ramps the motherboard 35 is a config without bed with this pins setting : d8 extruder d9 fan d10 controller fan nicolas. </desc> <cmt> toggle menu for psu from lcd pannel </cmt> <cmt> from the prepare menu, accessible when is not printing, you have the </cmt> <cmt> possibility to turn off the psu when is on et vice versa. </cmt> <cmt> from the host, you can turn off or turn on the psu then the menu is </cmt> <cmt> updated accordingly. </cmt> <cmt> from the lcd message, the printer status is reported ready or off </cmt> <cmt> respectively when the psu is on or off. </cmt> <cmt> turn off power supply off-load </cmt> <cmt> disable the high current output and wait a little before to turn off, </cmt> <cmt> because the interrupting capacity of the psu is unknown. </cmt> <cmt> could be a function if needed by other. </cmt> <cmt> no bed config for ramps </cmt> <cmt> the motherboard 35 is a config without bed with this pins setting : </cmt> <cmt> d8 extruder </cmt> <cmt> d9 fan </cmt> <cmt> d10 controller fan </cmt>","lcd toggle for psu, current tripping and no bed config"
3190,"<desc> i messed up the rebase to next, so this pr is this one, but based into next branch, sorry :-/ #14523 i have followed (at least) the pr section of the contributing guide. today i found an issue with the slider inside an scrollable area (a dialog) the more to the right the thum was, the more scroll area that would be shown in the dialog, such as here: apparently the issue is that the thumb uses a width/height of 100% + a transform, which would transform it to be outside of the track area. the fix i applied was setting the width and height to 0, while using the top and left properties to position the thumb wrapper, therefore it never exceeds the track area. i tried the dev docs example page and it seems to work ok. ps: i tried playing with overflow hidden, but it did not help. fixes #13455 </desc> <cmt> [labs][slider] fix for slider thumb wrapper size </cmt> <cmt> [slider] alternate fix </cmt> <cmt> move padding and margin fix to container instead of root </cmt> <cmt> vertical slider example fix </cmt> <cmt> update slider.js </cmt> <iss> slider overflows element width </iss>",fix thumb creating scroll overflow
3191,<desc> db2foreignkeyconfigurator db2indexconfigurator db2schemaconfigurator db2sequenceconfigurator db2uniquekeyconfigurator in org.jkiss.dbeaver.ext.db2.ui based on org.jkiss.dbeaver.ext.db2 managers of the same name created </desc> <cmt> #8562 part (configurators) of ui-part from plugins/org.jkiss.dbeaver.ext.db2 moved in org.jkiss.dbeaver.ext.db2.ui </cmt> <cmt> #8562 wrong path in plugin.xml fixed </cmt>,#8562 configurators from ext.db2 moved in ext.db2.ui
3192,"<desc> following the release of mistral-v1, we are pushing a draft pr with the stability fixes we made for training gpt-2 models directly to the base gpt-2 class definition (ensuring backwards compatibility). this is in line with the following issues: stanford-crfm/mistral#86: enabling sharing mistral checkpoints via hf hub (@osanseviero) #13463: upcasting scaled dot-product attention + layerwise scaling for stability (@lvwerra) concretely we implement: weight initialization from the original gpt-2 paper (by default, shouldn't affect folks unless they are training gpt-2 models from scratch) layer-wise scaling in scaled dot-product attention (optional flag; necessary for running/loading mistral gpt-2 models) scaled dot-product attention reordering (scale before dot-product) & fp32 upcasting when training in mixed precision (optional flag; only necessary for training new mistral/other gpt-2 models). this is a draft pr to aid in @lvwerra and @thomwolf's work training gpt-2 models stably; we plan on implementing tests (please let us know potential pain points), adding documentation, and will act on any other feedback you have . cc mistral team: @lorr1, @j38, @santhnm2 cc others at hf + gpt-2 model reviewers: @stas00, @patrickvonplaten, @lysandrejik resolves #13463 </desc> <cmt> add layer-wise scaling </cmt> <cmt> add reorder & upcasting argument </cmt> <cmt> add layer scaling & upcast/reordering flags + functionality </cmt> <cmt> add openai gpt-2 weight initialization scheme </cmt> <cmt> openai gpt-2 initialization </cmt> <iss> upcasting of attention computation for reliable pretraining of gpt-2 models </iss>",add mistral gpt-2 stability tweaks
3193,<desc> i changed the problematic regex pattern that i critized earlier in #4072 </desc> <cmt> update app.py </cmt> <cmt> fixed the dns rebind protection for secure handling of ipv6 addresses </cmt> <cmt> update changelog </cmt> <cmt> fixed the dns rebind protection for secure support of ipv6 addresses (@tunnelpr0) </cmt>,secure fix for the dns rebind protection issue from #4072
3194,<desc> fixes #6568 fixes #6587 review url </desc> <cmt> pull from main </cmt> <cmt> merge from docs </cmt> <cmt> merge from docs </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> added first draft of asp.net core 2.1 release notes </cmt> <cmt> wip: what's new in 2.1 </cmt>,what's new in asp.net core 2.1
3195,"<desc> estuary includes support for several addons, a number of them have not been updated to python 3: script.maps.browser plugin.program.autocompletion script.extendedinfo i couldn't find any sign someone is working on it to get them ported to py3, so we'll drop support for those. support can be re-added in case py3 compatible versions of those addons are submitted to our addon repo. </desc> <cmt> [estuary] remove support for script.maps.browser </cmt> <cmt> [estuary] remove support for plugin.program.autocompletion </cmt> <cmt> [estuary] remove support for script.extendedinfo </cmt>",remove support for addons that have not been updated to py3
3196,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation piking up from @mistercrunch work on #7716 this feature implements async computation of dashboards and charts, includes: rest api endpoint to fetch cached thumbnails or trigger async computation cli utilities to compute thumbnails using a config user (defaults to admin). able to override method to authenticate users on sellenium thumbnails are stored on a extra caching backend get list endpoints for charts and dashboards have a new field with the api endpoint to fetch to corresponding item thumbnail. the retrieved endpoint includes a digest used to avoid browser caching when the chart changed. async jobs are triggered by sqlalchemy events on insert and update of charts and dashboards, to keep cached thumbnails up to date. note: this feature is behind 2 feature flags, one for the api other for sqla event listeners (it's done this way because of tests) tests are running with the feature flag off. there is a specific tox env var to run thumbnails tests similar to cypress-sqllab-backend-persist imho celery tests should be refactored, one possible path would be to introduce superset docker build (nice one to test also) and then run the worker, making it available for tests. short description of the 2 main flows: flow 1 (thumbnail exists on cache): 1 - frontend requests a thumbnail from the api 2 - backend requests the thumbnail from cache 3 - thumbnail exists on cache 4 - thumbnail is retrieved to the client flow 2 (thumbnail does not exist on cache) 1 - frontend requests a thumbnail from the api 2 - backend requests the thumbnail from cache 3 - thumbnails does not exist on cache 4 - async task to celery to compute the thumbnail 5 - http 202 is sent to client (client can render a default thumb) 6,7 - sellenium requests to the frontend a dashboard/chart visualization page, takes a screenshot, resizes and caches the result requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> [thumbnails] new, thumbnail computation for charts and dashboards </cmt> <cmt> [thumbnails] initial working api with cache </cmt>",thumbnails for dashboards and charts
3197,"<desc> this adds a test to aggregatortestcase that allows us to programmatically verify that an aggregator supports or does not support all available field types.  it fetches the list of registered field type parsers, creates a mappedfieldtype from the parser and then attempts to run  a basic agg against the field. a supplied list of supported vstypes are then compared against the output (success or exception) and suceeds or fails the test accordingly. still a wip, need to tidy up, add javadocs, add another ""main"" agg or two (histo, etc).  putting it up in case folks want to have a look before i spend more time on it. note: to make this work, the pr cherry-picks over the getvaluessourcetype() component of #51503.  this will be added in eventually from the vs refactor branch, but is technically ""unused"" code outside of the tests until then. note 2: does not support field types added from a module at the moment. </desc> <cmt> put values source types on fields (#51503) </cmt> <cmt> comprehensively test supported/unsupported field type:aggs combinations </cmt> <cmt> this adds a test to aggregatortestcase that allows us to programmatically </cmt> <cmt> verify that an aggregator supports or does not support a particular </cmt> <cmt> field type.  it fetches the list of registered field type parsers, </cmt> <cmt> creates a mappedfieldtype from the parser and then attempts to run </cmt> <cmt> a basic agg against the field. </cmt> <cmt> a supplied list of supported vstypes are then compared against the </cmt> <cmt> output (success or exception) and suceeds or fails the test accordingly. </cmt>",comprehensively test supported/unsupported field type:agg combinations
3198,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> fix syntax and lexical errors </cmt> <cmt> fix syntax and lexical errors </cmt> <cmt> fix syntax errors  in create an export fallback </cmt> <cmt> fix syntax errors  in create an export fallback </cmt> <cmt> fix syntax and lexical errors in template literals </cmt> <cmt> fix syntax and lexical errors in template literals </cmt> <cmt> fix syntax and lexical errors in es6 const declare </cmt> <cmt> fix syntax and lexical errors in es6 const declare </cmt>",fix syntax and lexical errors in es6 1-4 les
3199,"<desc> first gen creality boards didnt have an sd detect pin, so allow setting to -1 in config file to prevent issues. </desc> <cmt> suggested message change </cmt> <cmt> allow override for old creality boards </cmt>",allow override for creality old boards
3200,<desc> fixes #12800 does not convert pandas dataframe into a dense array if all its columns are sparse arrays. since we have pandas sparse support on our minds: </desc> <cmt> enh adds pandas sparse support for check_array </cmt> <cmt> enh adds pandas sparse support for check_array </cmt> <cmt> rev remove comments </cmt> <cmt> tst improves test </cmt> <cmt> tst improves test </cmt> <iss> roadmap: pandas sparsedataframe may be deprecated </iss>,enh adds support for pandas dataframe with only sparse arrays
3201,"<desc> this includes various test fixes, and switches wasm from using js versions of compiler-rt routines to just compiling them with the rest of compiler-rt. </desc> <cmt> check the complete output of this test. </cmt> <cmt> fix double-to-int conversion overflow. </cmt> <cmt> fix missing #include. </cmt> <cmt> for wasm, compile compiler_rt i64 routines rather than providing them via js. </cmt> <cmt> update to the latest upstream compiler-rt files. </cmt> <cmt> this includes an aapcs attribute fix which is not relevant to </cmt> <cmt> emscripten (upstream r266891), and a fix to avoid undefined behavior </cmt> <cmt> in udivmoddi4.c (upstream r204193). </cmt>","compiler-rt, sqlite, and tests fixes"
3202,"<desc> closes #20664 i might be unavailable for the next few hours, so i'm just putting this up here, even though it includes changes from #20814 in the first commit. once that is merged, this can be merged on top of master and it'll just have the categorical changes. </desc> <cmt> squashed commit of the following: </cmt> <cmt> commit ec0cecd292947aa4d8416991e9f8920a4cd9a831 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   fri apr 27 06:02:48 2018 -0500 </cmt> <cmt> updates </cmt> <cmt> commit 6858409f3394035483e327c6e0fca05c1a6285ff </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   fri apr 27 05:48:59 2018 -0500 </cmt> <cmt> added note </cmt> <cmt> commit eb43fa4159c2affaf57ad686c260b2d1899eeacd </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 20:47:35 2018 -0500 </cmt> <cmt> really truly fix it hopefully. </cmt> <cmt> commit 7c4f625fdab30865e23570bf9e0a5450cf3e648e </cmt> <cmt> merge: 9a6c7d44c 6cacdde56 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 20:40:15 2018 -0500 </cmt> <cmt> commit 9a6c7d44ce9f474acb68d7b62efc138aedc3a100 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 20:04:17 2018 -0500 </cmt> <cmt> doc updates </cmt> <cmt> commit eecd632b16d475a5bbdca2013839298904056997 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 15:00:00 2018 -0500 </cmt> <cmt> skip categorical take tests </cmt> <cmt> commit f3b91ca70ce9caacae29f3ecd80cd121f5ee1a33 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 13:43:26 2018 -0500 </cmt> <cmt> doc fixup </cmt> <cmt> commit fbc4425a09bb973fefae90b3da2e1a205129658e </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 13:37:45 2018 -0500 </cmt> <cmt> updates </cmt> <cmt> * indexer -> indices </cmt> <cmt> * doc user-facing vs physical </cmt> <cmt> * assert na_cmps </cmt> <cmt> * test reindex w/ non-na fill_value </cmt> <cmt> commit 741f284f1c320ef6bbbf8ddadc871322cf703909 </cmt> <cmt> merge: 5db66248f 630ef1649 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 07:18:32 2018 -0500 </cmt> <cmt> commit 5db66248f2c40d5de6ffe9a2c308830c4128079a </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   thu apr 26 07:17:30 2018 -0500 </cmt> <cmt> doc and move tests </cmt> <cmt> commit 74b2c09bfc410be7190bbf6c69cb2c19fee6fbdd </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 21:40:18 2018 -0500 </cmt> <cmt> added verisonadded </cmt> <cmt> commit fc729d6dea77dee0d89148cdda738c0e9d8ab7c5 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 15:51:27 2018 -0500 </cmt> <cmt> fixed editor </cmt> <cmt> commit 1a4d9873629bb28e19a124e40b063879fc5e3ad0 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 15:50:48 2018 -0500 </cmt> <cmt> pass an array </cmt> <cmt> commit bbcbf19a560efed894670b0bc495a80283e003fc </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 15:07:28 2018 -0500 </cmt> <cmt> cleanup </cmt> <cmt> commit d5470a0f9f4d2f3937f0e63256f0750a50276586 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 15:02:26 2018 -0500 </cmt> <cmt> fixed reorder </cmt> <cmt> commit 82cad8b1f369db80851c13fe856a30bdb8bd154c </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 15:00:43 2018 -0500 </cmt> <cmt> stale comment </cmt> <cmt> commit c449afd2208451d67ce9c71c4b9d94448665c534 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 14:48:33 2018 -0500 </cmt> <cmt> bounds checking </cmt> <cmt> commit 449983b3686710886da78e2c2b77ce59be9a93d3 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 12:55:31 2018 -0500 </cmt> <cmt> linting </cmt> <cmt> commit 69e7fe76b540807bb973496ee5a2e3e636b90287 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 12:40:20 2018 -0500 </cmt> <cmt> updates </cmt> <cmt> 1. reversed order of take keywords </cmt> <cmt> 2. added to extensions api </cmt> <cmt> 3. removed default implementation </cmt> <cmt> commit 05d884498a1b15f876e5166bc5208afd804b63c7 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 09:59:33 2018 -0500 </cmt> <cmt> updated docs </cmt> <cmt> commit 31cd304e2f61fad841f6d56135fd6bbb202c606f </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 09:43:45 2018 -0500 </cmt> <cmt> pep8 </cmt> <cmt> commit 338566faf627e1fabd638a65055f1804948dd021 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 09:42:28 2018 -0500 </cmt> <cmt> upcasting </cmt> <cmt> commit b7ae0bc2cadd821d97f21fc2eac99b321d9473e5 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 09:06:59 2018 -0500 </cmt> <cmt> revert combine change </cmt> <cmt> commit 125ca0b7cf5796b806e76c2c38d780e55ea12176 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 08:37:07 2018 -0500 </cmt> <cmt> simplify </cmt> <cmt> upcasting is still broken </cmt> <cmt> commit c721915114c5dd39cd7aec6c9dec762ca28abcac </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 07:50:54 2018 -0500 </cmt> <cmt> removed default_fill_value </cmt> <cmt> commit 37915e9f31652904a3a3c9d91e2d4e394aecc14f </cmt> <cmt> merge: 67ba9ddb0 60fe82c8a </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 07:44:15 2018 -0500 </cmt> <cmt> commit 67ba9ddb0c8dec7f88a7ce14387898b552afe355 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 07:42:54 2018 -0500 </cmt> <cmt> more with default fill value </cmt> <cmt> commit eba137f8c7ae45288200566aebbf32229c69720c </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 05:59:58 2018 -0500 </cmt> <cmt> more internals hacking </cmt> <cmt> commit 08f24790daa8bbade46dca86dd2fb9ff0353118c </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   wed apr 25 05:59:17 2018 -0500 </cmt> <cmt> fixup json take </cmt> <cmt> commit 0be9ec6593f38b698af6475c668ecf4c709bbe20 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   tue apr 24 18:02:13 2018 -0500 </cmt> <cmt> non-internals changes </cmt> <cmt> commit dacd98e5f8ed0947bb2646499ac2e3cfd94e6177 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   tue apr 24 14:45:36 2018 -0500 </cmt> <cmt> moves </cmt> <cmt> commit fb3c2343c88be05ff1db5ca0ddef274eb0fda6b3 </cmt> <cmt> author: tom augspurger <tom.w.augspurger@gmail.com> </cmt> <cmt> date:   tue apr 24 13:59:51 2018 -0500 </cmt> <cmt> [wip]: extensionarray.take default implementation </cmt> <cmt> implements a take interface that's compatible with numpy and optionally pandas' </cmt> <cmt> na semantics. </cmt> <cmt> python </cmt> <cmt> in [1]: import pandas as pd </cmt> <cmt> in [2]: from pandas.tests.extension.decimal.array import * </cmt> <cmt> in [3]: arr = decimalarray(['1.1', '1.2', '1.3']) </cmt> <cmt> in [4]: arr.take([0, 1, -1]) </cmt> <cmt> out[4]: decimalarray(array(['1.1', '1.2', '1.3'], dtype=object)) </cmt> <cmt> in [5]: arr.take([0, 1, -1], fill_value=float('nan')) </cmt> <cmt> out[5]: decimalarray(array(['1.1', '1.2', decimal('nan')], dtype=object)) </cmt> <cmt>  </cmt> <cmt> closes </cmt> <cmt> bug/api: futurewarning from categorical.take indices </cmt> <cmt> we're changing how categorical.take handles negative indices to be in </cmt> <cmt> line with series and other eas. </cmt> <iss> bug: categorical.take and series([categorical]).take is inconsistent with other dtypes </iss>",deprecate categorical take default behaviour + fix series[categorical].take
3203,<desc> this affects gatsbyplugin atm as it requires a npmpackage to be installed. </desc> <cmt> validate plans that any inter-resource dependencies are satisfied in the plan </cmt> <cmt> pause execution of resource with dependencies while installing until its dependency is ready </cmt> <cmt> fix lint problem </cmt>,let resources declare dependencies & validate recipes & ensure dependencies installed first
3204,"<desc> fixes and improvements for the following: because of some changes, we were unable to send utf-8 characters with sendinputevent the cursor-changed event was missing some data needed for custom cursors (hotspot + size of cursor) to be able to draw the cursor easily, i introduced a tobuffer to nativeimage that retrieves the image in a raw representation into a nodebuffer </desc> <cmt> update as upstream </cmt> <cmt> fixes not being able to send utf8 characters anymore </cmt> <cmt> adds option to get raw data from nativeimage </cmt> <cmt> send some more data with the cursor-changed event </cmt>",a minor fix for sendinputevent and improvements related to cursor-changed event
3205,"<desc> i've run the latest black with default args on new code. i have added test_box.py with additional box.py tests and i have added a basic test for console.input() in test_console.py for issue #37. unfortunately, the total coverage didn't change from 94% but hope it helps in the long run. let me know if i should change anything. thanks! </desc> <cmt> add basic console.input() test </cmt> <cmt> add box tests </cmt>",add input and box tests
3206,"<desc> this pull request contains 4 patches. increasingly, data is colliding between jquery internal data and user data. this patch cleanly separates the two. it also changes the way the data functions work on plain js objects as a result. users can still access internal data if they need to, but uses jquery.expando as a key, so it is nearly impossible for collision to occur with any key that a user would reasonably use. this patch includes changes to the unit testing framework that check and report any time a unit test leaks data in any of the jquery globals. it also cleans up all of the tests that had been leaking. dommanip was leaking an element when appending to a list of multiple elements by never using the first element and always cloning. this patch fixes this issue. jquery.dequeue was not properly cleaning up and removing empty queues. this patch fixes this issue. </desc> <cmt> change the way jquery.data works so that there is no longer a chance of collision between user data and internal data. fixes #6968. </cmt> <cmt> fix dommanip leaks the first element when appending elements to multiple other elements. </cmt> <cmt> fix jquery.queue leaks empty queues. </cmt> <cmt> update unit tests with a leak detection mechanism for the various jquery globals and fix all leaks in the tests. </cmt>",data collision mitigation & unit test leaks patch (bug #6968)
3207,"<desc> this pr ensures that the results are displayed along with the warning when enhanced mode is disabled. references pr checklist applies to #2041 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx detailed description of the pull request / additional comments the following changes have been made in this pr - these lines ( modified the tests to reflect the change in code accordingly. the ui behaves as follows - if the enhanced mode is disabled then the first indexer result is this warning, followed by the other results if the enhanced mode is enabled or if the warning is disabled from the settings then the warning is not shown. validation steps performed manually validated it all tests pass (had to modify the test to reflect the change in logic) </desc> <cmt> show results always and conditionally show warning </cmt> <cmt> changed test logic to show warning when expected </cmt>",drive detection indexer warning refinement
3208,"<desc> #3549 #3488 #3661 rnw implementation of viewpanel sometimes create outer border instead of using the inner border, for example when round corner border is requested. this is causing noticeable layout issue especially when border size is large. rn's yoga layout sets the top/left for each children, but yoga has no notion of outer border(in its view, border is always part of the view instead of parent of view), and its placement logic includes the border size. so we need to compensate the outer border size when viewpanel is arranging its children, by deducting the border size from the top and left. when testing, i also found children clipping issue when outer border is present, so fix that too. microsoft reviewers: open in codeflow </desc> <cmt> format </cmt> <cmt> change files </cmt>",fix viewpanel layout issue when outer border exists
3209,"<desc> enables apps to run tasks without the need for manually scheduling them. by passing a config object with the job processor definition (startupsetting), the job will be scheduled to run right after being registered. this is what makes it possible for apps to schedule jobs within the ""initialization"" phase, without the need for user input. it wasn't previously possible due to the fact that a modifier was required to schedule jobs, but no modifiers are allowed in the ""initialization"" phase (it can be potentially problematic in ha setups). how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> make the apps scheduler run jobs after defining them </cmt> <cmt> ensure onetime jobs won't have duplicates at startup </cmt>",allow apps to schedule jobs along with processor register
3210,<desc> adds more debug info. adds information about why object chunks failed to be received. also adds plasma store debug dumps once capacity is reached. plasma store will periodically dump information if asio stats are turned on (should probably rename this config parameter at some point). i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> debug </cmt> <cmt> todo </cmt> <cmt> periodic dump </cmt>,add object store debug information
3211,"<desc> added trimesh fixed convexpolyhedron constructor - faces is a number[][] added trimesh to shape.types added geometryid to shape added axisa, axisb to hingeconstraint added setmotorspeed to hingeconstraint added target to icollisionevent this type def is used to validate the typescript on these pages </desc> <cmt> added trimesh </cmt> <cmt> fixed convexpolyhedron constructor - faces is a number[][] </cmt> <cmt> added trimesh to shape.types </cmt> <cmt> added geometryid to shape </cmt> <cmt> added axisa, axisb to hingeconstraint </cmt> <cmt> added setmotorspeed to hingeconstraint </cmt> <cmt> added target to icollisionevent </cmt> <cmt> this type def was used to validate the typescript that generated these examples </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt>  </cmt> <cmt> added author to comment </cmt>","updates for cannonjs types. added trimesh, added hingeconstraint properties, added shape properties, fixed convexpolyhedron constructor"
3212,<desc> resolves: #2744 added tests for changed code. updated documentation for changed code. </desc> <cmt> fix #2744 </cmt> <cmt> add test for #2744 </cmt> <iss> 1.1.0b2 causes envcommanderror (non-posix paths with file:// protocol on windows) </iss> <iss> poetry 1.1.0b2 fails to install zipp when trying to install poetry-core </iss>,fix non-posix paths with file:// protocol on windows
3213,<desc> the pi's gpu only used to support advanced deinterlace for sd video. we've improved the firmware to allow advanced deinterlace at 1080i so we can remove this limit. also allow deinterlace with software decode. pi 2 can handle software decode + deinterlace for dvds. </desc> <cmt> [rbp] enable qpu based deinterlace and remove resolution limit </cmt> <cmt> [mmalrenderer] allow deinterlace with software decode </cmt>,support advanced deinterlace for 1080i
3214,"<desc> bump go.d.plugin version to v0.22.0 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.21.0 </desc> <cmt> packaging: bump go.d.plugin version to v0.22.0 </cmt> <cmt> packaging: update go.d.plugin checksums </cmt>",update go.d.plugin version to v0.22.0
3215,<desc> http client move buffer (1460 byte) from stack to heap. only malloc needed ram if we know the response size and its less then 1460 </desc> <cmt> http client move buffer (1460 byte) from stack to heap. </cmt> <cmt> only malloc needed ram if we know the response size and its less then 1460 </cmt>,http client move stream buffer the heap
3216,"<desc> what did you implement added a link to the aws documentation that describes the differences between rest apis and http apis. closes #xxxxx how can we verify it todos useful scripts npm run test:ci --> run all validation checks on proposed changes npm run lint:updated --> lint all the updated files npm run lint:fix --> automatically fix lint problems (if possible) npm run prettier-check:updated --> check if updated files adhere to prettier config npm run prettify:updated --> prettify all the updated files write and run all tests write documentation enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> rest apis vs. http apis </cmt> <cmt> link clean up </cmt>",rest api vs. http api
3217,<desc> ubl and eeprom with host program such as octoprint in settings.cpp some debugging statements where not correctly disabled. this is causing issues with host programs such as octoprint. in particular ubl.echo_name() was being called and printing out a string without a newline. ok was then appended to that line and octoprint then never sees the ok its waiting for and times out. debugging is correctly disabled and octoprint no longer gives misleading serial errors. configuration.zip #20417 </desc> <cmt> fix debug messages </cmt> <cmt> correct missing character </cmt>,"fix debug messages, causing octoprint serial issues."
3218,"<desc> emit information to ipc processes about routes, redirects, rewrites, and headers </desc> <cmt> ipc emit all pages as ssr </cmt> <cmt> ipc emit all pages as ssr </cmt> <cmt> ipc emit all pages as ssr </cmt> <cmt> ipc emit all pages as ssr </cmt> <cmt> more logging </cmt> <cmt> make log action </cmt> <cmt> change string value for pages </cmt> <cmt> edit routes in canary </cmt> <cmt> new canary </cmt> <cmt> change route emission </cmt> <cmt> page data </cmt> <cmt> add tests for sending log_routes </cmt> <cmt> merge master </cmt> <cmt> merge master </cmt> <cmt> adjust tests </cmt> <cmt> commit for canary change </cmt> <cmt> comments </cmt> <cmt> ipc emit redirects and rewrites </cmt> <cmt> add tests for ipc emits </cmt>","ipc events for routes, redirects, rewrites, and headers"
3219,<desc> fixes #3914. mysqlvisitor lacks of visitor for ddlstatement.g4. it is necessary to add ddlstatement.g4 antlr visitor. mysqlvisitor adds ddlstatement.g4 antlr visitor. </desc> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <cmt> mysql ddlstatement visitor </cmt> <iss> optimization for sharing parser with antlr visitor for mysql </iss>,add mysql ddlstatement antlr visitor
3220,"<desc> in several places in main.cpp, synchronized data structures are accessed without cs_main being held. </desc> <cmt> lock cs_main for state/misbehaving </cmt> <cmt> processmessage calls state(...) and misbehaving(...) without holding the </cmt> <cmt> required lock; add lock(cs_main) blocks. </cmt> <cmt> lock cs_main for chainactive </cmt> <cmt> activatebestchain uses chainactive after releasing the lock; reorder operations </cmt> <cmt> to move all access to synchronized object into existing lock(cs_main) block. </cmt>",locking for misbehave() and other cs_main locking fixes
3221,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> add @dhis2/ui-constants package </cmt> <cmt> fix lint warnings </cmt>",add types for the @dhis2/ui-constants package
3222,<desc> fixes #642 . focused the textblock element when the event source is the textblock itself. this fixes the resultant number not gaining focus when a right-click is performed. tested manually </desc> <cmt> fixed issue with focus when right-clicking result </cmt> <iss> right-click on numbers fails to highlight after 'selecting all' from context menu </iss>,fix the focus when right-clicking calculationresult's textblock
3223,"<desc> what's this pr do? this pr fixes the use of cursorpoller in stream so that it's updated with the current active filters. previously, the poller locked in whatever filters were present on page load. this fixes ""switching the active filter does not prevent old results from loading"" on issue #1585. change summary: streammanager: don't add items unless they have an id stream: sync state with url on mount cursorpoller: add setendpoint method to update internal url unmount react components after each test where should the reviewer start? src/sentry/static/sentry/app/views/stream.jsx src/sentry/static/sentry/app/utils/cursorpoller.jsx how should this be manually tested? run make test-js you can also start the sentry server, navigate to the stream page, and select one of the filters (i.e., ""bookmarks"", ""assigned"") before the poller has a chance to complete its first poll. if the filtered data remains the same after the first poll has completed then the changes have fixed the issue. any background context you want to provide? this pr builds upon #1602. what gif best describes this pr or how it makes you feel? </desc> <cmt> fix polling with filters </cmt> <cmt> previously, the stream poller would not respect filters selected after page </cmt> <cmt> load. this caused subsequent polls to request data using the old filters. a </cmt> <cmt> change was made to update the poll url upon changing filters. </cmt> <cmt> update react component tests </cmt> <cmt> tests were not unmounting react components after running, which could cause </cmt> <cmt> memory leaks or unexpected behavior from ""watched"" stores or actions. tests now </cmt> <cmt> unmount the tested component. </cmt>",poll with current active filters
3224,"<desc> this pr makes classic ui (upscaled dogm) to work with the native display resolution for touch. before that, the code had a lot of fixed magic numbers and weird calculations to translate the touch from the native resolution to an independent resolution of 320x240. the reason for this pr is simple: it allow classic ui use the same xpt calibration values of the color ui and lvgl ui, allowing us to create a generic touch calibration screen. one unique xpt calibration values for all ui. less complex code. it will allow us to create a generic touch calibration screen. it better integrate touchbuttons with the classicui. any board with tft_classic_ui. </desc> <cmt> make dogm use the real screen resolution for touch and drawing, instead of fixed 320x240 coordinate space. buttons positions now are calculated </cmt> <cmt> we dont need any more xpt values specific for classic ui on 480x320 screens! </cmt>",make classic ui use the screen resolution for touch (not fixed 320x240)
3225,"<desc> from #5704. </desc> <cmt> cgtop: check cgroups after parsing options </cmt> <cmt> we would try to determine controllers even if not necessary: </cmt> <cmt> <mock-chroot><mock-chroot> sh-4.4# ./systemd-cgtop --help </cmt> <cmt> failed to determine supported controllers: no medium found </cmt> <cmt> <mock-chroot><mock-chroot> sh-4.4# ./systemd-cgtop --version </cmt> <cmt> failed to determine supported controllers: no medium found </cmt> <cmt> this broke check-help-systemd-cgtop under mock, but even apart </cmt> <cmt> from that, the program should be able to print --version in any </cmt> <cmt> circumstances. </cmt> <cmt> nspawn: check cgroups after parsing options </cmt> <cmt> same justification as in previous commit. </cmt>","make sure --version, --help always work"
3226,"<desc> closes #299. in tree view, the recurse_nodes function travels down every possible path, leading to exploding complexity with certain recombining graphs. we can implement a very fast dfs traversal, but then we lose the nice expand/collapse functionality. unfortunately i don't know an easy way to compute the number of paths in a graph (i think there's a big prize for that), so i'm solving this the old fashioned way: try the complicated method, and if it takes too long, fall back on the quick one. here's what happens: the default timeout is 1 second (i thought that was a reasonable wait for most graphs) we try to run the full recursion. if it finishes in less than 1 second, the resulting tree view has full expand/collapse functionality but if the full recursion times out, then it falls back on a quick dfs recursion that will display a full tree, but can't be dynamically expanded if a url parameter force_expand is passed, then the timeout is removed and the system will compute the full recursion no matter how long it takes. </desc> <cmt> add timeout/fallback to tree traversal </cmt> <cmt> expand_all -> force_expand for clarity </cmt>",add timeout/fallback algorithm for building tree view
3227,"<desc> the pr moves the cmsis framework and other lpc176x specific code into an external repository, implementing a custom platformio platform and arduino framework aiming to be be mostly arduino api compatible (only the public api tricks used by libraries will still cause many problems as it does with due etc). this is still a work in progress but there are so many bugfixes and improvements at this point that i can't really wait any longer to merge, (too many issues coming up that are fixed). clean up the platforms directory to include only hal related items clean up the build system, enforcing order of inclusion updates to the usb system (mostly @gloomyandy's work) addresses various timeout issues usb will now always reconnect on board reset fixes cdc serial transmission errors can use onboard sd card for gcode while sharing it with host as usb drive, needs unmounted on marlin to access with host, marlin takes priority default to using flash eeprom emulation as it is more reliable pwm is now compatible with all 6 hardware channels on any compatible pin with transparent fallback onto the 20 interrupt driven channels, if hardware channel is busy or not available. all the things i've forgotten about this is a major overhaul of the platform and how it builds, it more than likely fixed things i don't know about and broke other things that i will soon know about. i've added a near duplication of the lpc1768 pio build environment for the lpc1769, though i may rethink it if people deem it unnecessary, marlin code assume f_cpu is a constant and that any calculation it is used in (there are lots) with be optimised away, if f_cpu has to assigned at run-time these calculations (maybe in isrs) are not optimised. </desc> <cmt> [hal][lpc176x] pull out framework into separate repository </cmt> <cmt> framework and build platform now located at </cmt> <cmt> fix mkssbase leds </cmt> <cmt> move hardware serial </cmt> <cmt> remove hardware/software serial </cmt> <cmt> hardware serial extraction </cmt> <cmt> hardwareserial isrs </cmt> <cmt> fix disabled serial2 causing serial object to link </cmt> <cmt> move usb devices out to framework </cmt> <cmt> separate out adc/pwm peripheral function from hal.cpp </cmt> <cmt> fix includes </cmt> <cmt> remove unused pwm init </cmt> <cmt> move adc </cmt> <cmt> hal header update </cmt> <cmt> templated filtered adc </cmt> <cmt> lpc1769 platform </cmt> <cmt> usb and sdcard sharing improvements </cmt> <cmt> * add traceback after watchdog timeout </cmt> <cmt> add the cpability to perform a traceback following a watchdog timeout. </cmt> <cmt> * enhanced hardware spi </cmt> <cmt> allow use of either ssp0 or ssp1. </cmt> <cmt> ensure that no data is left in i/o buffers after calls to enable sharing of ssp hardware. </cmt> <cmt> * make flash emulation of eeprom the default </cmt> <cmt> make use of flash for eeprom storage the default. this means that usage of eeprom will not cause usb drive mount/unmount operations. </cmt> <cmt> * allow sharing of sd card </cmt> <cmt> sd card i/o operations from the usb stack take place in idle loop, rather than at interrupt time. allowing sharing of the spi bus. </cmt> <cmt> new configuration options to allow usage of the sd card to be specified. </cmt> <cmt> * fix problem with hardware spi pins </cmt> <cmt> servo update </cmt> <cmt> update lpc builds to use platformios ldf limited to strict mode </cmt> <cmt> need to identify why incompatible libraries are still included without specifically disallowing them </cmt> <cmt> update the sdcard usb sharing config and apply to re-arm </cmt> <cmt> remove debug output from flash persistent store implementation </cmt>","pull out framework, improve build, fix things"
3228,"<desc> inside pro.h, the keys that are normally ""ralt"" and ""fn"" were swapped, causing confusion in making keymaps, since fn needed to be left of ralt in the keymap when the physical key is to the right. my personal keymap is also included, which i adjusted alongside my fix for these two keys being swapped. default keymap is already correct and does not need to be changed for this (although rgui is used instead of fn. maybe good use of fn couldn't be made here?) added via support. json made by me is being submitted to via repo. config.h has been changed to have bootmagic row/column defined for this board to use esc instead of lshift for bootmagic. firmwares in question have been compiled and flashed to my board with my keymap & tested. first pr, always open to feedback on how to do things better. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added wholesomeducky keymap for gmmk pro </cmt> <cmt> finalized keymap & added 1000hz polling for gmmk pro </cmt> <cmt> corrected for ralt and fn being swapped </cmt> <cmt> fixed ralt and fn being swapped in the layout definition. updated personal keymap to reflect fixed layout. </cmt> <cmt> removed an old comment from personal keymap for gmmk pro </cmt>",fixed bootmagic lite support; added personal keymap and via support
3229,"<desc> this pr fixes the issue that crashed and abnormal sessions are also counted as errored in release health as an example, even though we only have crashed sessions in this example and the total adoption is an accurate measure of how many sessions have been captured which are 7 sessions, the graph shows double that amount as errored sessions. changes: subtract crashed and abnormal from errored session count added test </desc> <cmt> added node14js support for lambda integration </cmt> <cmt> subtracted crashed from errored to avoid duplication of data </cmt> <cmt> added extra checks to ensure that errored now excludes abnormal and crashed </cmt>",discount crashed and abnormal sessions from errored sessions
3230,"<desc> fixes #11441, continues and closes #14463 add comments to clarify spectral clustering algorithm as asked by @gaelvaroquaux. @glemaitre not sure your comments have been addressed. </desc> <cmt> update comments in spectral.py </cmt> <cmt> clarified what variable maps corresponds to. </cmt> <cmt> update comments in spectral_embedding_.py </cmt> <cmt> update comments in spectral_embedding_.py to clarify laplacian normalization and use of initial approximation of eigenvectors for lobpcg. </cmt> <cmt> update comments in spectral.py </cmt> <cmt> added comment to clarify exact eigenproblem that is solved. </cmt> <cmt> fix formatting spectral.py </cmt> <cmt> deleted line break. </cmt> <cmt> update spectral.py </cmt> <cmt> remove trailing whitespace </cmt> <cmt> update spectral_embedding_.py </cmt> <cmt> removed trailing whitespaces </cmt> <cmt> remove comment describing csgraph_laplacian </cmt> <cmt> remove comment describing csgraph_laplacian return variables when norm_laplacian=true </cmt> <cmt> merge with upstream </cmt> <iss> spectral clustering algorithm documentation clarification </iss>",add comments to clarify spectral clustering and spectral_embedding
3231,<desc> hi there this pr adds the ability to add annotations to traefik dashboard's service. this is useful when using tools like external-dns. thank you! jh </desc> <cmt> update readme.md </cmt> <cmt> add service annotation to configuration table </cmt> <cmt> add annotations to traefik dashboard's service </cmt> <cmt> this commit allows for annotations to be added to traefik dashboard's service. this is useful when using tools like [external-dns]( </cmt>,add annotations to the traefik dashboard service
3232,"<desc> related to #2182 this force the user to have an unlocked wallet before he is able to send a transaction. since every transaction is required to have at least one authorizer now, i feel that this behaviour makes sense. </desc> <cmt> add locked wallet assertion </cmt> <cmt> separate wallet not available and not existent exception </cmt>",make cleos complains about locked wallet
3233,<desc> an initial implementation of gatsby functions. learn more at the rfc at #27667 post feedback at #30735 test this by installing gatsby@functions-next & adding functions: true to your flags in your gatsby-config.js. </desc> <cmt> add new plugin </cmt> <cmt> add functions plugin by default </cmt> <cmt> add stub </cmt> <cmt> bump up package.json </cmt> <cmt> wip </cmt> <cmt> compile all functions found in build </cmt> <cmt> add plugin by default only if gatsby_experiment_functions is set </cmt> <cmt> move to public for now </cmt> <cmt> move to functions dir </cmt> <cmt> run a dev server for functions </cmt> <cmt> wip </cmt> <cmt> move to onprebootstrap </cmt> <cmt> add target node </cmt> <cmt> bump up package.json </cmt> <cmt> bump up package.json </cmt> <cmt> add support for env vars </cmt> <cmt> publish 0.1.0-4 </cmt> <cmt> bump up peerdependencies </cmt>,add the ability to run functions locally and on gatsby cloud
3234,"<desc> the e0397 explanation, as i've written it, isn't really an explanation, but i'm not sure what to put here. i will happily take suggestions. partially addresses #25851 </desc> <cmt> update e0015 explanation, fix e0053. </cmt> <cmt> add error explanations for e0040, e0087, e0378, e0379, e0394. </cmt> <cmt> convert mutable statics error to have error code and add explanation. </cmt> <cmt> also changes 'owned pointers' => 'boxes' in the error message. </cmt>",add 5 more error explanations. update e0015's explanation. add an error code.
3235,"<desc> this is a naive implementation of what has been working for us internally. </desc> <cmt> bpo-35022: add support for __fspath__ to magicmock </cmt> <cmt> the magicmock class supports many magic methods, but not __fspath__. to ease </cmt> <cmt> testing with modules such as os.path, this function is now supported by default. </cmt> <cmt> add test </cmt> <cmt> documentation </cmt>",add __fspath__ support to unittest.mock.magicmock
3236,"<desc> match header to inbox header, fix mobile styles. fix margin from footer on bottom of page  before mobile new mobile </desc> <cmt> fix(ui): remove margin from footer on alerts </cmt> <cmt> fix(ui): match alerts to inbox headers </cmt>","adjust alerts header to match inbox, mobile fixes"
3237,"<desc> breaking change: this change breaks existing service call references to the media_player.epson_select_cmode services by changing the service calls to be epson.select_cmode. my understanding is that because this is not a service provided by the base media_player component, it should live in the domain of the epson component instead. if that's the case, then it also makes sense to update the service name. description: update the domain and service name for epson.select_cmode. see this comment for context: #28890 (comment) related issue (if applicable): related to #27289 pull request with documentation for home-assistant.io (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. </desc> <cmt> update .coveragerc, move epson constants to const.py, move epson cutsom service to epson domain </cmt> <cmt> newline in services.yaml </cmt>",update service domain for epson from 'media_player' to 'epson'
3238,"<desc> libdebug now supports walking the chain of dw_tag_inlined_subroutine entries in dwarf to get the list of source positions in the inline chain for a given address in the program. this pr also contains various requirements for implementing this, a bugfix (5ef0fb4) and some refactoring in libdebug. example backtrace of crash -r: backtraces should now be easier to understand, for example here we can see the location in the code of crash (crash.cpp:282) that caused the refptr assertion failure. thanks @gunnarbeutner for suggesting to implement this </desc> <cmt> libdebug: fix typo in debuginfo::get_source_position </cmt> <cmt> libdebug: remove unused debuginfo::for_each_source_position </cmt> <cmt> libdebug: move get_die_at_offset to dwarf::compilationunit </cmt> <cmt> libdebug: move dwarf::attributevalue to a separate file </cmt> <cmt> libdebug: store libdebug objects on the heap & make them non-copyable </cmt> <cmt> this fixes an issue were some libdebug objects (for example, </cmt> <cmt> dwarf::compilationunit) held a reference to their parent </cmt> <cmt> dwarf::dwarfinfo object, which was constructed on the stack and later </cmt> <cmt> moved to the heap. </cmt> <cmt> libdebug: move dwarf::lineprogram into dwarf::compilationunit </cmt> <cmt> previously, the lineprogram objects were short-lived, and only created </cmt> <cmt> inside debuginfo::prepare_lines() to create a vector of sorted lineinfo </cmt> <cmt> data. </cmt> <cmt> however, dwarf::lineprogram also contains other useful data, such as </cmt> <cmt> index-to-string mapping of source directories and filenames. </cmt> <cmt> this commit makes each dwarf::compilationunit own its </cmt> <cmt> dwarf::lineprogram. </cmt> <cmt> debuginfo::prepare_lines() then iterates over the compilation units to </cmt> <cmt> prepare its sorted vector of lines. </cmt> <cmt> libdebug: add lineprogram::get_directory_and_file(size_t) </cmt> <cmt> this function returns the directory path & filename for a given file </cmt> <cmt> index. </cmt> <cmt> ak: add redblacktree::find_largest_not_above_iterator </cmt> <cmt> it's a version of find_largest_not_above that returns an iterator. </cmt>",show inlined functions in backtraces
3239,"<desc> the internal nfacct plugin: is now synced with the current development of netdata can collect connection tracker metrics too; fixes #161 the plugin still requires netdata to be running as root. the next step is to move it away from the netdata daemon to an external plugin, that will be setuid to root. but in order to do this, it has to be merged with the internal netfilter plugin, so that only one method of netfilter data collection will be used at any time. so, if netlink is available it should be used, otherwise the proc filesystem should be used, but if even this is not available the plugin should stop and exit. </desc> <cmt> update nfacct plugin to match current netdata development </cmt> <cmt> nfacct plugin with static dimension pointers </cmt> <cmt> properly initialize global structures </cmt> <cmt> properly initialize the just allocated global structures </cmt> <cmt> convert nfacct to linked-list instead of array </cmt> <cmt> added connection tracking information via netlink </cmt> <cmt> netfilter plugin - final touch before moving it outside netdata </cmt> <iss> netdata uses obsolete procfs for conntrack data - netfilter.plugin </iss>",data collection of netfilter connection tracker metrics using netlink (libmnl)
3240,"<desc> changed makefile and forced mac os x using either gcc-5 or clang-omp, since the -lopenmp flag fails the default xcode compiler and causes confusions when linking. added pippack subroutine in makefile for packaging for pip installation changed manifest.in, the most important part, by adding refactored code plus exclusion to .a files which can fail linux build-on-the-fly changed setup.py and setup_pip.py, added prep_pip.sh for supporting updated pip install and, submitted 0.6a2 tag to pypi, tested with mac os x 10.10, ubuntu 14/16 and centos 7 with no problem </desc> <cmt> force gcc-5 or clang-omp for mac os, prepare for pip pack </cmt> <cmt> add sklearn dep, make -j4 </cmt> <cmt> finalize pypi submission </cmt>",pypi (pip installation) setup for 0.6 code
3241,"<desc> context we need to support multiple pages and layouts in the app. this pr enables us to have routing, pages, and layouts. it adds a basic sidebar navigation component. closes unify-308 naive navbar ui note currently, the schema stitching @tgriesser added is preventing the component tests from compiling. features and bonuses we have a router, with url-based navigation + back/forward support we have layouts and pages. pages can have metadata (like a human-readable name) declared in <route> blocks we have a 404 page :-) new ui sidebarnavigation sidebarnavigationrow how to test yarn dev --project packages/launchpad from the workspace root launch a browser navigate to the /vite/ app path see the router, layouts, etc and click through them to see the pages change </desc> <cmt> feat: adding navigation to the frontend app </cmt> <cmt> cleaning up markup </cmt> <cmt> adding layout and navigation and pages </cmt> <cmt> setimmediate fix </cmt>","adding navigation, pages, router, and layout"
3242,"<desc> this pr moves the data-oriented parts of feature gating into its own crate, rustc_feature. the parts consist of some data types as well as accepted, active, removed, and builtin_attrs. feature gate checking itself remains in syntax::feature_gate::check. the parts which define how to emit feature gate errors could probably be moved to rustc_errors or to the new rustc_session crate introduced in #66878. the visitor itself could probably be moved as a pass in rustc_passes depending on how the dependency edges work out. the pr also contains some drive-by cleanup of feature gate checking. as such, the pr probably best read commit-by-commit. r? @oli-obk </desc> <cmt> introduce crate rustc_feature and move active, accepted, and removed to it </cmt> <cmt> move stability to rustc_feature </cmt> <cmt> move attributetemplate to builtin_attrs </cmt> <cmt> simplify gated cfgs logic </cmt> <cmt> builtin_attrs: inline some strings </cmt> <cmt> move is_builtin_attr to syntax::attr </cmt> <cmt> builtin_attrs.rs -> rustc_feature </cmt> <cmt> inline two explanation constants </cmt> <cmt> move unstablefeatures -> rustc_feature </cmt> <cmt> check.rs: inline a constant </cmt> <cmt> tidy: adjust feature gating path </cmt> <cmt> update rustc_feature crate docs </cmt> <cmt> move gateissue to rustc_feature & simplify emit_feature_err </cmt> <cmt> derive(default) for features </cmt>",feature gating declarations => new crate rustc_feature
3243,"<desc> this contains @ethomson's failing test that checkout was incorrectly recreating a deleted file even in safe checkout mode, plus it has the fix for the problem and some extra new checkout test helpers that make it easier to look at exactly what checkout is doing. </desc> <cmt> test asserting checkout should not recreate deleted files </cmt> <cmt> fix checkout of modified file when missing from wd </cmt> <cmt> this fixes the checkout case when a file is modified between the </cmt> <cmt> baseline and the target and yet missing in the working directory. </cmt> <cmt> the logic for that case appears to have been wrong. </cmt> <cmt> this also adds a useful checkout notify callback to the checkout </cmt> <cmt> test helpers that will count notifications and also has a debug </cmt> <cmt> mode to visualize what checkout thinks that it's doing. </cmt>",checkout should not recreate deleted files - with fix
3244,"<desc> fixes #12336 part 3. add datasourcepreparer and environmentchecker for opengauss implement opengaussdatasourcepreparer close un-used data sources part of unit test </desc> <cmt> add datasourcepreparer abd environmentchecker for opengauss </cmt> <cmt> get first actual data node and related data source of all logic tables </cmt> <cmt> close un-used data sources </cmt> <cmt> impl opengaussdatasourcepreparer </cmt> <cmt> refactor, prepare for index name rewrite </cmt> <cmt> get create logic table sqls </cmt> <cmt> unit test </cmt> <iss> create sharding tables automatically in target data sources before scaling task starting </iss>",scaling prepare tables part 3 : implement opengauss dialect
3245,"<desc> with this pr, when comparing two object types we first check that the source type contains all properties required by the target type. only when that is the case do we then proceed to compare the types of the properties. previously we'd do both of these things in the same pass which could cause us to needlessly drill into the (possibly deep) types of matching properties only to later discover that other properties are missing (meaning that the types are not related). as can be seen from the baseline differences, we now bail out quicker when types are not related. this reduces noise in error messages and should also help performance. </desc> <cmt> check all properties are present before checking types in relationships </cmt> <cmt> accept new baselines </cmt>",compare shapes of objects before comparing contained types
3246,<desc> related issue (if applicable): fixes # the code change is tested and works with tasmota core esp32 v.1.0.7 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> update xdrv_54_lvgl.ino </cmt> <cmt> fix compile error with lvgl define and without use_berry defined </cmt> <cmt> update xdrv_54_lvgl.ino </cmt> <cmt> fix compile error without berry define. </cmt>,fix compile error with berry defined.
3247,"<desc> fixes #16691 the reason for the bug is typeof document.all that it returns undefined. indeed this behavior is called ""willful violation"" based on this site "" warning i can't write tests because jsdom hasn't implemented document.all yet. jsdom/jsdom#3028 but if you have any suggestions for writing them down. i'd be happy to write them down. test plan correct typeof document.all error </desc> <cmt> add html_all_collection type to correct typeof document.all </cmt> <iss> devtools: failed to execute 'postmessage' on 'window': #<htmlallcollection> could not be cloned. </iss>",fix devtools crash when inspecting document.all
3248,"<desc> adds contributing to flutter: getting started to the contributing.md related issues none no code changes. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. </desc> <cmt> adds contributing to flutter artcile link </cmt> <cmt> updates article title </cmt>",adds contributing to flutter article link
3249,"<desc> adds another field (""request.method"") to the structured logfile audit. this field is present for all events associated with a rest request (not a transport request) and the value is one of get, post, put, delete, options, head, patch, trace and connect. closes #29765 </desc> <cmt> walk in the park </cmt> <cmt> tabs are evil </cmt>",security audit includes http method for requests
3250,"<desc> this is a continuation of pr #13362 started by @ptrendx titled ""add nhwc layout support to pooling (cudnn only)"".  we're in agreement that i'm the best one to push this work forward to a point of final acceptance. based on reviewer comments, i've expanded the support of the newly introduced 'layout' parameter to include cpu and cuda implementations, not just cudnn.  also 3d support in cudnn and graceful fallback for mkldnn.  i've re-enabled and expanded the testing of test_operator_gpu.py:test_pooling_versions.  i understand and avoid the earlier flakiness of that test, which was due to inclusion of the pooling_v1 operator in some problem domains where its definition differs.  the initial commit here is identical to the last one made by @ptrendx for pr #13362.  follow-up commits will add this new functionality and additional description. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> adds layout support: mx.sym.pooling(..., layout='nhwc',...) with tests. </cmt> <cmt> docs changes </cmt> <cmt> trigger </cmt> <cmt> skip nhwc pooling tests on non-cudnn platforms </cmt> <cmt> fix pylint nhwc pooling </cmt> <cmt> fixes from review </cmt>","add nhwc layout support to pooling (cpu, gpu cuda, gpu cudnn)"
3251,"<desc> hi @potiuk, this pr fix gcs copy operation without wildcard and rename destination object according to source file name. related: #9803 </desc> <cmt> fix bug in gcs copy operation </cmt> <cmt> change test copy operation with different_delimiter_and_destination_object </cmt>",#9803 fix bug in copy operation without wildcard
3252,"<desc> addresses issue #1174 </desc> <cmt> new method getsupportedcallingcodes() (java) </cmt> <cmt> cpp code: not yet tested because of santa :/ </cmt> <cmt> fixing cpp build issues </cmt> <cmt> - adding pending_code_changes.txt </cmt> <cmt> - removed the ""using std::"" statements in the .h file and fixing the c++ </cmt> <cmt> and test code accordingly </cmt> <cmt> removed redundant code, ported to js, compiled. </cmt> <cmt> modified jars. </cmt>",added new api for getsupportedcallingcodes
3253,<desc> commit message: this proposes an email template for announcing the security fix of the main branch. risk level: n/a testing: n/a docs changes: this provides supporting information release notes: n/a </desc> <cmt> templates: add an emlai template for announcing security fix of main branch </cmt> <cmt> restructure </cmt>,add an email template for announcing security fix of main branch
3254,<desc> fixes eos_logging idempotency issue when trying to set both logging destination and facility. (#31862) added fix for the idempotency issue added new integration tests added fix in changelog.md eos_logging.py ansible version stable-2.4 </desc> <cmt> fixes eos_logging idempotence issue #31862 (#40604) </cmt> <cmt> * eos_logging idempotence fix </cmt> <cmt> * fixed eos_logging idempotence issue </cmt> <cmt> * fixed pylint and pep8 errors </cmt> <cmt> * added tests for eos_logging & minor fix </cmt> <cmt> * removed q statements </cmt> <cmt> (cherry picked from commit b9ea6468398d23c4b9c39f0c91cd79bf0b61af5d) </cmt> <cmt> added eos_logging fix in changelog </cmt>,fix eos_logging idempotency issue cp into 2.4
3255,<desc> cleanups made while working on other prs. addresses some glitches in the matrix. </desc> <cmt> whitespace clean </cmt> <cmt> fix m503 s parameter </cmt> <cmt> move temperature reporting to temperature class </cmt> <cmt> general ubl/g26 code cleanup </cmt> <cmt> standardize lcd interface code for ubl a little </cmt> <cmt> allow buffer clean without release command </cmt> <cmt> changes for parity with 2.0.x </cmt>,"cleanup, bugfixes, parity with 2.0.x"
3256,<desc> continuation of #9304 </desc> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> more strict aliasing </cmt> <cmt> strict aliasing in c++20 </cmt> <cmt> build fix </cmt> <cmt> update types.h </cmt>,strict aliasing via c++20's char8_t (merged with master)
3257,"<desc> closes #57554, closes #43459 this is my first contribution to the open source world! write tests for setting make tests use different settings </desc> <cmt> add tabclosingorder, set default mru and use setting to focus next tab </cmt> <cmt> change domaction name </cmt> <iss> make closing tab to open next/previous tab instead of mru </iss> <iss> allow to close tabs from left to right rather than in order of most recently focused </iss>",add setting for tab closing order
3258,"<desc> we mention in the contributing docs that we expect the airbnb style guide for javascript, but this wasn't actually enforced in our eslintrc. this pr adds the base airbnb style rules, with some exceptions for the ones that we're currently violating and might require some discussion. also note that this doesn't yet include the airbnb react style rules </desc> <cmt> require airbnb style guide (without react) </cmt> <cmt> automatic style fixes (from eslint --fix) </cmt> <cmt> manual style fixes, and disable often-violated rules </cmt> <cmt> enable no-underscore-dangle rule </cmt> <cmt> enable class-methods-use-this (mark methods as static) </cmt>",enforce airbnb style guide rules
3259,"<desc> add t5 model convert to transformers-cli did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. @patrickvonplaten @sgugger @lysandrejik members/contributors which may be interested in your pr. </desc> <cmt> update run_mlm.py </cmt> <cmt> add t5 model to transformers-cli convert </cmt> <cmt> update rum_mlm.py same as master </cmt> <cmt> update converting model docs </cmt> <cmt> update converting model docs </cmt>",add t5 convert to transformers-cli
3260,<desc> this pr does the following changes: the default model class to benchmark is the one that can be found under config.architectures improve plotting file </desc> <cmt> add benchmark for all kinds of models </cmt> <cmt> improved import </cmt>,extend benchmark to all model type extensions
3261,<desc> summary we can now test the sequence api on python3. this pr aims at enabling those tests on travis. related issues pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> split sequence test from generator tests </cmt> <cmt> use_spawn check for windows </cmt> <cmt> do not copy use_spawn </cmt>,split generators tests from sequence tests
3262,"<desc> this pr adds two new optional arguments to draggablescrollablesheet called snap and snapsizes. if snap is false (default value), the widget's behavior remains unchanged. if snap is true, the widget will snap to snapsizes when the user's finger leaves the screen during a drag. see for details: #34111 (comment). this is achieved by replacing (if a snap should occur) the sheet's ballistic simulation in _draggablescrollablesheetextent.goballistic with one that snaps to targets instead of moving forward until velocity is dissipated. fixes: #34111 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> hijack helloworld </cmt> <cmt> added snap points and snaping behavior </cmt> <cmt> working in basic scenario </cmt> <iss> add drag length parameter to draggablescrollablesheet </iss>",add snapping behavior to draggablescrollablesheet
3263,<desc> description: we need a way to run the deprecated field check on the routeconfiguration. today the schema check tool validates the bootstrap config. this change will help achieve similar functionality on routes served from rds. risk level: low testing: manual testing docs changes: included release notes: included </desc> <cmt> deprecated check </cmt> <cmt> docs </cmt> <cmt> docs </cmt>,deprecated field check in route checker tool
3264,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> directly give the bbox property to all objects </cmt> <cmt> add unions along side existing types </cmt> <cmt> add iteration example </cmt>",add discriminated unions for geojson types
3265,"<desc> every use of apply_mark in a built-in or procedural macro is supposed to look like this location.with_ctxt(syntaxcontext::root().apply_mark(ecx.current_expansion.id)) where syntaxcontext::root() means that the built-in/procedural macro is defined directly, rather than expanded from some other macro. however, few people understood what apply_mark does, so we had a lot of copy-pasted uses of it looking e.g. like span = span.apply_mark(ecx.current_expansion.id); , which doesn't really make sense for procedural macros, but at the same time is not too harmful, if the macros use the traditional macro_rules hygiene. so, to fight this, we stop using apply_mark directly in built-in macro implementations, and follow the example of regular proc macros instead and use analogues of span::def_site() and span::call_site(), which are much more intuitive and less error-prone. ecx.with_def_site_ctxt(span) takes the span's location and combines it with a def-site context. ecx.with_call_site_ctxt(span) takes the span's location and combines it with a call-site context. even if called multiple times (which sometimes happens due to some historical messiness of the built-in macro code) these functions will produce the same result, unlike apply_mark which will grow  the mark chain further in this case. after apply_marks in built-in macros are eliminated, the remaining apply_marks are very few in number, so we can start passing the previously implicit transparency argument to them explicitly, thus eliminating the need in default_transparency fields in hygiene structures and #[rustc_macro_transparency] annotations on built-in macros. so, the task of making built-in macros opaque can now be formulated as ""eliminate with_legacy_ctxt in favor of with_def_site_ctxt"" rather than ""replace #[rustc_macro_transparency = ""semitransparent""] with #[rustc_macro_transparency = ""opaque""]"". r? @matthewjasper </desc> <cmt> audit uses of apply_mark in built-in macros </cmt> <cmt> replace them with equivalents of span::{def_site,call_site} from proc macro api. </cmt> <cmt> the new api is much less error prone and doesn't rely on macros having default transparency. </cmt> <cmt> resolve: do not rely on default transparency when detecting proc macro derives </cmt> <cmt> incremental: do not rely on default transparency when decoding syntax contexts </cmt> <cmt> using expnids default transparency here instead of the mark's real transparency was actually incorrect. </cmt> <cmt> hygiene: require passing transparency explicitly to apply_mark </cmt> <cmt> remove default macro transparencies </cmt> <cmt> all transparancies are passed explicitly now. </cmt> <cmt> also remove #[rustc_macro_transparency] annotations from built-in macros, they are no longer used. </cmt> <cmt> #[rustc_macro_transparency] only makes sense for declarative macros now. </cmt>",audit uses of apply_mark in built-in macros + remove default macro transparencies
3266,"<desc> update vulkan loader and headers to sdk-1.2.131.2 (headers are actually sdk-1.2.131.1, they did not get a re-release.) also synced vma 2.3.0 again, fixing unwanted clang-formatting of thirdparty code. glslang: sync with upstream 4fc7a33 for vulkan sdk 1.2.131 1231c2e fixes #36888. @bruvzg could you check if the glslang patch is still needed for macports mingw builds? (for the reference, previous discussion about it: #29993 (comment)) @faless fyi, this glslang version adds some emscripten components that we might want to integrate in our buildsystem eventually: $ ls thirdparty/glslang/glslang/osdependent/web/ glslang.after.js  glslang.js.cpp  glslang.pre.js </desc> <cmt> update vulkan loader and headers to sdk-1.2.131.2 </cmt> <cmt> (headers are actually sdk-1.2.131.1, they did not get a re-release.) </cmt> <cmt> also synced vma 2.3.0 again, fixing unwanted clang-formatting of </cmt> <cmt> thirdparty code. </cmt> <cmt> glslang: sync with upstream 4fc7a33 for vulkan sdk 1.2.131 </cmt> <cmt> fixes #36888. </cmt> <iss> clang 10 failure with glslang </iss>",update vulkan sdk to 1.2.131.2 and matching glslang version
3267,<desc> this pr stringify the secretsmanager response to mirror ssm behaviour when getting a parameter that references a secret. 3496 </desc> <cmt> stringfy secret reference value </cmt> <cmt> adds test checking for sourceresult data type </cmt> <cmt> fixes indentation </cmt> <cmt> fixes indentation </cmt> <cmt> fixes indentation </cmt> <cmt> stringify secretsresponse </cmt>,ssm wrong output when referencing secretsmanager
3268,"<desc> this pr adds another github action that runs type checks (using the mypy toxenv) and reports the current status to  example: in the above example, the selenium.common package is fully typed (green color & 100% coverage), while selenium.webdriver.chrome.options module is not - more details can be found in tox_mypy job log, where mypy will report an error for the line. in this example: selenium/webdriver/chrome/options.py:25: error: implicit generic ""any"". use ""typing.dict"" and specify generic parameters selenium/webdriver/chrome/options.py:28: error: function is missing a type annotation (relevant spot in the job log for reference) this way, one should be able to easily track the typing errors. this is a proposal to address the discussion in #9482. it is added for @automatedtester for an evaluation! also, once merged into master, codecov should start tracking the changes in upcoming prs, comparing typing coverage against the current master (an example on how it will look like, although this comment actually reports code coverage difference). once all typing errors are resolved (thus a 100% typing coverage achieved for the complete python codebase), we can stop reporting the typing coverage and just run tox -c py/tox.ini in tox_mypy job. it will then simply fail on new typing errors. i have read the contributing document. </desc> <cmt> [py] add github action for type checking </cmt> <cmt> temporarily enable running ci from ci/branchname </cmt> <cmt> ignore mypy exit code </cmt> <cmt> allow passing arguments in mypy toxenv, add lxml dependency for cobertura reports </cmt> <cmt> record and upload cobertura report in mypy gh action </cmt> <cmt> don't write inline comments for dependencies </cmt> <cmt> use correct coverage report path to upload to codecov </cmt> <cmt> revert running actions on ci/branchname </cmt>",run type checks in ci and report typing coverage to codecov
3269,"<desc> related ticket: #1208 this pull request adds support for max_retries as an argument to requests.request. i think that since we already support timeout as a top-level argument then it makes sense to support max_retries too. i've added a unit test, but this is a very difficult thing to test for. i can't see any easy way to simulate an unreliable connection. please let me know what you think. </desc> <cmt> [kennethreitz/requests#1208] adding a max_retries argument </cmt> <cmt> [kennethreitz/requests#1208] adding unit test for max_retries </cmt>",adding max_retries as an argument
3270,"<desc> i noticed the current types for react-redux-toastr were for version 3.6 and mostly outdated. i ended up essentially rewriting the types from ground up. at least one place where i'm not sure if the types are correct: i've written types for the redux action creators explicitly instead of using actioncreator<actions>. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> react-redux-toastr: unify code style </cmt> <cmt> react-redux-toastr: change react.component types to use state and props </cmt> <cmt> react-redux-toastr: change to named imports </cmt> <cmt> react-redux-toastr: remove module declaration </cmt> <cmt> react-redux-toastr: add union types for known strings </cmt> <cmt> react-redux-toastr: rename toastrconfirmoptions to confirmtoastroptions for unified style, refine properties </cmt> <cmt> react-redux-toastr: add interfaces for all of the toastr option objects </cmt> <cmt> react-redux-toastr: refactor some variables to alphabetical order </cmt> <cmt> react-redux-toastr: add interfaces to toastrs in reducer state, add toastr action payload, toastr reducer state </cmt> <cmt> react-redux-toastr: rename toastoptions to toastroptions to unify style </cmt> <cmt> react-redux-toastr: rename toastroptions to reduxtoastrprops and rewrite properties </cmt> <cmt> react-redux-toastr: slight refactor of reduxtoastrprops </cmt> <cmt> react-redux-toastr: remove confirmoptions interface </cmt> <cmt> react-redux-toastr: remove duplicate confirmtoastroptions interface </cmt> <cmt> react-redux-toastr: rewrite toastremitter, modify tests to comply with version 7.0.0 </cmt> <cmt> react-redux-toastr: rewrite action creators, start using toastrstate </cmt> <cmt> react-redux-toastr: slight refactor, alphabetize stuff </cmt> <cmt> react-redux-toastr: remove unused component state and props </cmt>",rewrite types for package v7.0.0 and typescript 2.4
3271,"<desc> there is lots of code in core.internals inside try/except blocks, in particular calls to _try_coerce_args.  it is tough to reason about these because it is often unclear what the raising cases are.  this simplifies that problem by separating values, args = self._try_coerce_args(values, args) into values = self._coerce_values(values) and args = self._try_coerce_args(args)  (note the former doesnt have a ""try"" in the name because it never raises). also: removed a never-used ndim kwarg from block.make_block and removed a now-redundant datetimetzblock.copy method. </desc> <cmt> separate coerce_values from coerce_args </cmt> <cmt> remove redundant method, move non-raising outside try </cmt> <cmt> remove ndim kwarg from make_block </cmt> <cmt> small cleanup </cmt>",separate raising from non-raising parts of method
3272,<desc> in pull_requests.md description: config dump risk level: small? testing: unit test docs changes: n/a(is config_dump auto gen doc enough?) release notes: config_dump handler prints out secret discovery service information </desc> <cmt> sds config dump single cmt due to dco... </cmt> <cmt> spelling check. </cmt>,config dump for secret discovery service.
3273,"<desc> not sure if we want to fix it like this, but i think this is a problem that we are going to keep having. related #6621 fixes: #5937 issue originally found and explained by @meikidd, see: #5937 (comment) this pr fixes a regression introduced in 7.7.0 by this pr: #6155 this pr is based on the fix by @dispatchcommit in #6621 but with a bit more ""magic"" closes: #6621 </desc> <cmt> feat: add a named request animation frame function </cmt> <cmt> implement </cmt> <iss> high cpu usage after the player stays in background for a while </iss>",add named requestanimationframe to prevent performance issues
3274,"<desc> hi andreas, here a few small improvements i found during implementing the json schema validator. i know the double printing could be improved a lot with the ""%x.yf"" notion, but today i have only a limited version that has %.6f implemented ;-) </desc> <cmt> ak: print double numbers with printf </cmt> <cmt> this patchset allows double numbers to be printed with the printf function. </cmt> <cmt> the fraction will always be printed as 6 digit number. this can be improved :^) </cmt> <cmt> ak: a few json improvements </cmt> <cmt> * add double number to object serializer </cmt> <cmt> * handle negative double numbers correctly </cmt> <cmt> * handle \r and \n in quoted strings independently </cmt> <cmt> this improves the situation when keys contain \r or \n that currently </cmt> <cmt> has the effect that ""a\rkey"" and ""a\nkey"" in an json object are the </cmt> <cmt> same key value. </cmt>",print double numbers with printf & a few json improvements
3275,"<desc> small refactorring of serbian language abbreviation. changed from ""rs"" -> ""sr"" i have submitted the spacy contributor agreement. </desc> <cmt> serbian stopwords added. (cyrillic alphabet) </cmt> <cmt> spacy contribution agreement included. </cmt> <cmt> test initialize updated </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> serbian language code update. --bugfix </cmt>","serbian language code update ""rs"" -> ""sr"""
3276,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr is a continuation of the work @gitkrystan did in #46278, now that @jamescdavis's refactorings to have qunit expose es module declarations on its own have landed. big thanks to both of them for making this easy to pull over the finish line! note: dt recently had a prettierrc added, and my editor was pretty insistent about applying formatting updates, so the first commit here is just me pre-applying that before actually changing anything. the latter two contain the actual content of this change. </desc> <cmt> apply dt's prettier formatting before i actually touch anything </cmt> <cmt> annotate this for nested hooks with ember-qunit </cmt> <cmt> add test coverage for this in nested hooks </cmt>",provide this type for module nestedhooks
3277,"<desc> this pr addresses a long-standing issue where h2o uses the certificate on the disk when fetching ocsp response for stapling. the problem has been that if the certificate on the disk gets changed (e.g., by an acme client) but h2o is not restarted, the certificate being used and the ocsp response being stapled become inconsistent. this inconsistency leads to tls handshake failures. this pr addresses the issue by using the certificate chain being loaded at boot time for stapling. builds on top of #2879. to be merged after #2879. </desc> <cmt> [xcode] set file format </cmt> <cmt> [fetch-ocsp-response] load file from stdin, if not specified </cmt> <cmt> [h2o] retain certificate chain in pem format, supply that to fetch-ocsp-response </cmt>",use loaded cert rather than what's on the disk
3278,"<desc> issues solved: when metrics is not valid in query(), the error message gives 'nonetype' has no attribute sqla_col, which is not very descriptive count_distinct was transfered to count_distinct(col) expression in sqllab_viz todo: refactor all metrics_creation pr to a consistent place needs-review @mistercrunch @bkyryliuk </desc> <cmt> return error message when metrics are not valid </cmt> <cmt> fix bug with count distinct expression </cmt>",fix sql expression bug with count distinct metrics
3279,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> </desc> <cmt> heading/text align props update, </cmt> <cmt> flex prop overflow removed </cmt> <cmt> button color, header accblty level, tab props tab </cmt> <cmt> video couple onhandlers </cmt>","updated header/text, video element,  removed flexprop overflow and minor changes"
3280,"<desc> last of #3625 on top of implementing the new parameterized way of using addons for info, i also added made changes regarding how the options and parameters were processed with respect to each other, #3625 (comment). before, the addon parameters would be the ones that were the latest set (global -> local -> story), replacing the previous ones entirely. now, it only replaces the addon properties per key, #3625 (comment). i don't think my solution in lib/core/src/client/preview/client_api.js is the cleanest one, so if anyone else has a better idea, happy to hear! i tried some stuff with reduce but that only made more of a mess. i applied similar logic to the handling of options and parameters. core tests 2 snapshot tests failed in 1 test suite, both output: - snapshot + received ... - <component> + <deprecated> this seems unrelated to my changes, or am i mistaken? </desc> <cmt> implement params for info + merge the options and params </cmt> <cmt> add examples of the param implementation </cmt> <cmt> update the documentation with the new possibilities </cmt>",use parameters for info addon
3281,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. run tsc without errors. include the required files and header. base these on the readme, not on an existing project. </desc> <cmt> adding type definition for </cmt> <cmt> adding lint and fixing issues reported by it </cmt> <cmt> fixig issues </cmt>",adds type definition for koa-jwt (https://github.com/koajs/jwt)
3282,"<desc> i successfully installed pipenv with pip and tried to run for the first time only to encounter this error: traceback (most recent call last): file ""/library/frameworks/python.framework/versions/3.4/bin/pipenv"", line 11, in <module> load_entry_point('pipenv==3.2.4', 'console_scripts', 'pipenv')() file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py"", line 560, in load_entry_point return get_distribution(dist).load_entry_point(group, name) file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py"", line 2642, in load_entry_point return ep.load() file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py"", line 2296, in load return self.resolve() file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py"", line 2302, in resolve module = __import__(self.module_name, fromlist=['__name__'], level=0) file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pipenv/__init__.py"", line 1, in <module> from .cli import cli file ""/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pipenv/cli.py"", line 17, in <module> from requests.packages.urllib3.exceptions import insecurerequestwarning importerror: cannot import name 'insecurerequestwarning' this was due to my installed version of requests being 2.3.0.  upon upgrading requests to 2.4.0 and above, pipenv runs fine. as such, i've qualified the version requirement in setup.py </desc> <cmt> qualified version of requests to >2.3.0 </cmt> <cmt> updated requests version required to >=2.4.0 </cmt> <cmt> updated requests version required to >=2.4.0 </cmt>",qualfied version of requests required to >2.3.0
3283,"<desc> adds a ""sync"" label to translation sync prs checks if any existing prs have that label before creating a new one. motivation this lets us run the sync script in bulk and not have to worry whether duplicates will be created. </desc> <cmt> do not create a new pull request if a label exists </cmt> <cmt> add the labels to the created prs </cmt>",(scripts/i18n) check if an existing sync pr exists before creating a new one.
3284,"<desc> the step pulse widths are longer than expected for the lpc1768, due & teensy35_36.  this is because the stepper_timer_prescale macro was wrong. here are the before and after numbers for lpc1768 & due all numbers are in microseconds minimum_stepper_pulse is the setting in configuration_adv.h minimum_stepper_pulse  0    1    2    3    4    8 lpc1768 previous               0.6  6.1  9.5  13.0 18.5 corrected              0.6  1.1  2.1  3.1  4.0  8.2 due     previous               1.1  6.0  6.0  8.6  11.3 18.6 corrected              1.1  1.4  2.0  3.1  4.0  7.8 we may want to drop the teeny35_36 change because i don't have one to verify against. if i read the code correctly the teeny35_36 step pulse is infinite.  i have a hard time believing that so i expect someone will step up with a different explanation. the current macros end up with pulse_timer_prescale being zero because of the following defines: #define stepper_timer_prescale   0 // not defined anywhere else! #define pulse_timer_prescale    stepper_timer_prescale the following defines the width of the x, y & z step pulses.  since pulse_timer_prescale is zero the while loop will never terminate. while (extra_cycles_xyze > (uint32_t)(hal_timer_get_count(pulse_timer_num) - pulse_start) * (pulse_timer_prescale)) { /* nada */ } </desc> <cmt> correct pulse_timer_prescale macro </cmt> <cmt> switch to stepper_timer_prescale </cmt>","correct step pulse width on lpc1768, due & teensy35_36"
3285,<desc> @rocketchat/core closes #9873 this pr allows to customize the message that will be displayed at the end of the conversation in livechat widget. </desc> <cmt> message of the conversation finished has been added. </cmt> <cmt> new setting added to display a message when the livechat conversation has ended. </cmt>,livechat setting to customize ended conversation message
3286,"<desc> the updated scripts need new binding generators. on windows use .bat linux and mac use .sh </desc> <cmt> issue #3781, update genbinding script to fit new bindings-generator. </cmt> <cmt> issue #3781: fix the variable name. </cmt> <cmt> issue #3781, add windows bat script. </cmt> <cmt> issue #3781, js not generate cocos2dx physics now. </cmt> <cmt> issue #3781, undefine the __mingw32__ macro to fix the script error on windows </cmt>",issue#3781 update script for each platform bindings generating.
3287,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> :bust_in_silhouette: adjust username </cmt> <cmt> :label: add definition for constructor and method 'endpdf' with buffer </cmt> <cmt> :white_check_mark: add test for constructor and method 'endpdf' with buffer </cmt> <cmt> :rotating_light: remove linter error 'prefer-const' </cmt>,adjust username; add definition and test for for constructor and method 'endpdf' with buffer
3288,"<desc> our telemetry-sourced bugs have a ton of call stacks like this, where it isn't obvious which refactor triggered it (tons of them have a dochange function) and it isn't obvious which assert failed without checking out very specific versions of tsserver.js and digging into the line numbers: error: debug failure. false expression. at dochange (tsserver.js:116689:22) at unknown (tsserver.js:116680:96) at function.changetracker.with (tsserver.js:111861:17) at object.getcodeactions (tsserver.js:116680:64) at unknown (tsserver.js:112847:121) at object.flatmap (tsserver.js:573:25) at object.getfixes (tsserver.js:112847:23) at unknown (tsserver.js:122423:35) at object.flatmap (tsserver.js:573:25) at object.getcodefixesatposition (tsserver.js:122421:23) at suppressed_frame() at suppressed_frame() at iosession.session.getcodefixes (tsserver.js:131477:64) this pr adds messages to all the assert* family calls in these two folders. as a follow-up we could also do the same for cast as that has a few ambiguous stacks as well. in most cases i tried to make the assert messages globally unique rather than making them consistent, since this will make looking them up later easier. </desc> <cmt> add comments to assert calls </cmt> <cmt> add comments to assert calls in codefixes </cmt>",add assert comments in codefixes and refactors
3289,"<desc> as an alternative to #1287 this implements the core git rules for config section and key validation with new code that is based on what already existed in libgit2. the rules, for reference, that are implemented are: the top-level section name (i.e. before the first period) and the trailing key name (i.e. after the last period) must consist entirely of alphanumeric characters and dashes, the first character cannot be a dash, and all the letters will be mapped to lower case. also, these parts cannot be missing. any middle section name, if it exists, must not contain newlines. these rules are enforced both when you go to set a value in a config file and when you attempt to rename a section of config file. this pr includes a new test that @nulltoken wrote which i copy-pasted from the above mentioned pr. </desc> <cmt> test buf join with null behavior explicitly </cmt> <cmt> implement config key validation rules </cmt> <cmt> this is a new implementation of core git's config key checking </cmt> <cmt> rules that prevents non-alphanumeric characters (and '-') for </cmt> <cmt> the top-level section and key names inside of config files. </cmt> <cmt> this also validates the target section name when renaming </cmt> <cmt> sections. </cmt> <cmt> test config name validation </cmt> <cmt> this is @nulltoken's work to test various invalid config section </cmt> <cmt> and key names and make sure we are validating properly. </cmt>",stricter config entry name validation
3290,"<desc> this pr contains sources for a new 'devexpress-web' types version: add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). asp.net controls and mvc extensions -> client api reference asp.net bootstrap controls -> client api reference dashboard -> asp.net client api reference reporting -> client api reference (webforms & mvc) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> added new major version 191.5 </cmt> <cmt> recovered old tslint config </cmt> <cmt> upgraded to 19.1.6 </cmt> <cmt> added new major version 192.3 </cmt>",added new devexpress-web major version 192.3
3291,"<desc> this cleans up the code and avoids potentially significant js overhead in the common case. </desc> <cmt> demangle fserror stacks only in assertions, and not all the time; and only do the workaround for node.js 4 in legacy_vm_support, to avoid stack trace overhead </cmt> <cmt> fix </cmt> <cmt> better </cmt>","improve fserror stacks only in assertions, and not all the time"
3292,"<desc> what's this pr do? this pr mitigates memory leaks on the stream. there are still many more to be fixed, but it's a start. this intended to address ""streammanager does not remove items from groupstore (memory leak)"" in #1585, but none of the leaks we saw were actually related to groupstore. where should the reviewer start? src/sentry/static/sentry/app/components/dropdownlink.jsx how should this be manually tested? using the chrome debugging tools, you can profile the memory use of the stream before and after the changes in this branch. what gif best describes this pr or how it makes you feel? </desc> <cmt> refactors and bootstrap tooltip delegation </cmt> <cmt> bootstrap tooltips were being added to every column of the barchart. now a </cmt> <cmt> single tooltip is delegated to the barchart component. also, the chart columns </cmt> <cmt> are no longer rendered asynchronously. </cmt> <cmt> there was also some general method extraction refactoring. </cmt> <cmt> fix memory leaks on stream </cmt> <cmt> fixed some memory leaks on the stream caused by several factors including bound </cmt> <cmt> dom events that were never released. there are still leaks, but many fewer. </cmt> <cmt> some components of streamactions were refactored into components for </cmt> <cmt> clarity. </cmt> <cmt> the datepicker was a large source of memory leaks and was non-functional, so we </cmt> <cmt> commented it out. </cmt> <cmt> * redesign/react: (29 commits) </cmt> <cmt> minor fixes to standardize embed </cmt> <cmt> lint </cmt> <cmt> fill userreport.group_id on save </cmt> <cmt> index userreport(project_id, event_id) </cmt> <cmt> format issuetrackingplugin labels with format_html </cmt> <cmt> fix default project query </cmt> <cmt> correct checking of request.sentry </cmt> <cmt> various additions to error embed </cmt> <cmt> support name/email initial data params </cmt> <cmt> ignore embed js </cmt> <cmt> remove some unused bits </cmt> <cmt> basic functional submission and error handling </cmt> <cmt> various responsive fixes </cmt> <cmt> add close action </cmt> <cmt> various responsive features for modal </cmt> <cmt> various stylistic tweaks to modal </cmt> <cmt> add embeddable error feedback </cmt> <cmt> fix tag handling from url params </cmt> <cmt> use entirety of parsed query in stream search </cmt> <cmt> changes for 7.6.2 </cmt> <cmt> ... </cmt>",fix memory leaks in stream
3293,"<desc> improve code coverage about 1 percent. fix #6193 fix #6192 perfect test cases in dubbo-common perfect test cases in dubbo-remote add runnablewrapper to manage exception in threadlessexecutor fix empty check in statustelnethandler </desc> <cmt> feat(test): perfect test cases in urlstrparser </cmt> <cmt> feat(test): perfect test cases in baseservicemetadata </cmt> <cmt> feat(test): perfect test cases in hashedwheeltimertest </cmt> <cmt> feat(test): perfect test cases in executorrepository </cmt> <cmt> feat(threadpool): use runnablewrapper to manage exception </cmt> <cmt> feat(test): perfect test cases in threadlessexecutor </cmt> <cmt> feat(test): perfect test cases in common.utils </cmt> <cmt> feat(test): perfect test cases in transporters </cmt> <cmt> feat(test): perfect test cases in remoting.utils </cmt> <cmt> feat(test): perfect test cases in exchangers </cmt> <cmt> feat+fix(telnet, test): perfect test cases in telnet, fix miss check health when get status without parameter </cmt> <cmt> fix(test):fix executor url </cmt> <cmt> fix(test):fix executor url </cmt> <cmt> fix(test):fix executor pool size in jdk 11 </cmt> <cmt> fix(format):fix file format in statustelnethandler </cmt> <iss> [bugfix] telnet unable get proper health when execute 'status' without parameter </iss> <iss> [enhancement] threadlessexecutor unable to handle all exceptions </iss>",improve code coverage and fix some code
3294,"<desc> i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. </desc> <cmt> expand infosec & qa article </cmt> <cmt> expand the information security & quality assurance root article. </cmt> <cmt> fixing capitalization in infosec title. </cmt>",expand certifications/information security and quality assurance article stub
3295,"<desc> i have an ergodox ez with the left led hack in place ( would like to add back in support in erogodox_ez.c for this hack. currently it's implemented using #define left_leds (as it was done previously), but i'm totally flexible. the current implementation just cycles the lights on boot; keymap specific code is required to do anything useful on layer switch, etc. (you can see a trivial example here: </desc> <cmt> add initial support for left leds on an ergodox ez </cmt> <cmt> update left led support </cmt> <cmt> implement ergodox_left_leds_update in ergodox_ez </cmt> <cmt> previously, this code was implemented in keymap.c, but i'm unaware of </cmt> <cmt> someone with a different implementation of this particular hack. [if </cmt> <cmt> someone has it, we can add another #ifdef in the future.] </cmt> <cmt> document how to define left_leds and how that hack is done </cmt>",ergodox ez left leds support
3296,<desc> this pull request adds support for named amd modules and addresses the pain point of using typescript-generated amd modules when anonymous modules and out-of-the-box bundlers (like r.js) are not an option. this feature was previously discussed at </desc> <cmt> initial support for named amd modules. </cmt> <cmt> added a compiler test for named amd modules. </cmt>,adding support for named amd modules.
3297,"<desc> closes #12800 changing to streams will make it lighter on both client and server. the first batch of online/away users will come from a rest request (thus will not flood websocket) and only further changes on status will come though ddp. update presence package to include a change on clients to not call connect anymore presence package process instance removals on each instance, which generates lots of duplicate status changes if an instance goes down/updates test without upm </desc> <cmt> change users publications for rest calls </cmt> <cmt> get active users on startup and listen for changes </cmt> <cmt> better handling reconnections </cmt> <cmt> support streamcast </cmt> <cmt> change full user subscription to no use users collection </cmt>",change user presence events to meteor streams
3298,<desc> per issue #1124 </desc> <cmt> initial commit for adding support for amazon linux 2015.03 </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> base rhel/amazon/centos detection on system-release and ubuntu on lsb-release </cmt> <cmt> remove unnecessary conditionals from amazon.sh </cmt>,add support for amazon linux 2015.03
3299,<desc> fixes #11387 </desc> <cmt> :lipstick: </cmt> <cmt> renames </cmt> <cmt> :lipstick: let -> const </cmt> <cmt> small refactorings </cmt> <cmt> pass in actual editors </cmt> <cmt> be aware of line mapping when rendering diff view zones and diff overview decorations </cmt> <cmt> push view zones to accomodate equal but differently wrapped lines </cmt> <cmt> add iviewmodel.createlinebreakscomputer() </cmt> <cmt> do not store the original content in the diff information for inline diff margin actions </cmt> <cmt> render inline diff view zones in batch </cmt> <cmt> improve rendering of view zones with changed or deleted text (inline diff editor) </cmt> <iss> support word wrap in the diff editor </iss>,add support for word wrap in diff editor
3300,<desc> add api on adding recent documents add api for user tasks of jumplist set application dock menu add a guide on desktop environment integration fixes #746. </desc> <cmt> override => override in browser.h </cmt> <cmt> cocoa: enable modifying initialized menu </cmt> <cmt> cocoa: enable creating empty menu </cmt> <cmt> fix displaying context menu for devtools </cmt> <cmt> override => override in atom_api_app.h </cmt> <cmt> add app.dock.setmenu api </cmt> <iss> add support for taskbar extensions </iss>,add api for windows jump list and mac application dock menu
3301,<desc> centralize all options at the root for easier discovery. renaming all_the_debug_macros  ->  enable_all_the_debug_macros for consistency with the rest of the options. making this enable_all_the_debug_macros an option makes it visible to users and tooling and formalize the type of the argument. making this build_lagoms an option makes it visible to users and tooling and formalize the type of the argument. </desc> <cmt> cmake: consolidate all options to the root of the project </cmt> <cmt> cmake: remove some trailing whitespace from a few cmakelists.txt files </cmt>,consolidate and document all options to the root of the project
3302,"<desc> this change makes rodeos be able to get the rabbits stream addresses for queues or exchanges from environment variables. --stream-rabbits arg                  addresses of rabbitmq queues to stream to. format: amqp://user:password@addres s:port/queue[/streaming_route, ...]. multiple queue addresses can be specified with ::: as the delimiter, such as ""amqp://u1:p1@amqp1:5672/queue1 :::amqp://u2:p2@amqp2:5672/queue2"".if this option is not specified, the value from the environment variable eosio_stream_rabbits will be used. --stream-rabbits-exchange arg         addresses of rabbitmq exchanges to stream to. amqp://user:password@address :port/exchange[::exchange_type][/stream ing_route, ...]. multiple queue addresses can be specified with ::: as the delimiter, such as ""amqp://u1:p1@amqp1:5672/exchange1:::am qp://u2:p2@amqp2:5672/exchange2"".if this option is not specified, the value from the environment variable eosio_stream_rabbits_exchange will be used. this pr is done for rodeos following the changes for amqp_trx_plugin in nodeos and for cleos - #10829 . select one: select any that apply: </desc> <cmt> epe-1577 rodeos accept rabbits queue or exchange from environment variables </cmt> <cmt> epe-1577 improved help message </cmt>",epe-1577 rodeos getting stream addresses for queues or exchanges from environment variables
3303,<desc> fixes #4643 formula for decayed adagrad operator: moment_out = decay * moment + (1 - decay) * grad * grad param_out = param - learning_rate * grad / (sqrt(moment_out) + epsilon) </desc> <cmt> implementing the decayedadagrad optimizer step operator </cmt> <cmt> implementing decayedadagrad operator </cmt> <cmt> remove file </cmt>,implementing the decayed adagrad optimizer operator
3304,"<desc> the new registry asset spacy.emptykb.v1 creates an empty kb with a configurable entity length. this is used with a default length in case the user doesn't specify anything in their config for the entity_linking component. the kb constructor does not take a vocab argument anymore - this can be set (kb.initialize) when the el pipe is created. this now generates a new el component with custom length - without going through the hassle of calling the knowledgebase constructor etc: nlp.add_pipe(""entity_linker"", config={""kb"": {""entity_vector_length"": 35}}) if ok, i'll document this separately on the nightly docs branch. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> el field documentation </cmt> <cmt> documentation consistent with docs </cmt> <cmt> default empty kb, initialize vocab separately </cmt> <cmt> formatting </cmt>",default empty kb in el component
3305,<desc> absence of this tag was causing morphology.pyx to fail when assigning tag ids. types of changes bug fix (non-breaking change fixing an issue) new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. </desc> <cmt> fix(model): fix tag map for fixing issues with tag space </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix(model): add space to es tag_map. fixing error in morphology.pyx when sp tag is missing </cmt>,add space to es tag map
3306,"<desc> adds a golden test for a few material icons (first, last, and variants). this will help validate upcoming icon font updates will look something like: </desc> <cmt> create icons golden test </cmt> <cmt> update icons_test.dart </cmt>",add material icons golden test
3307,"<desc> this pr is exactly the same as #7688 with updates to the build file to make tests pass so that we can merge the changes in. closes #7134 and #7688 @eronwright : not sure if you saw updates to #7688 asking for tweaks to the pr to make the tests pass. if you want to update that pr instead, i'm happy to abandon this one. otherwise, will merge this one in and abandon the other. </desc> <cmt> [java] [feature] load from savedmodel </cmt> <cmt> - add savedmodelbundle class </cmt> <cmt> [java] [feature] load from savedmodel </cmt> <cmt> - incorporate feedback </cmt> <cmt> [java] [feature] load from savedmodel </cmt> <cmt> - incorporate feedback (2) </cmt> <cmt> [java] [feature] load from savedmodel </cmt> <cmt> - update build file to new location for junit </cmt> <cmt> [java] [feature] load savedmodel </cmt> <cmt> - format files using google-java-format </cmt> <cmt> (see </cmt>",ability to load from savedmodel
3308,"<desc> tldr: reduces the time it takes to get from flutter run to an interactive debugging session. locally this reduces the startup time for a dirty application from ~40 seconds in the flutter gallery to about ~12 seconds. the default behavior of flutter run is to build the platform binary (apk, ipa) as necessary and update it on the device before starting a debug session. this artifact is almost always invalidated whenever the user restarts a debugging session, because it depends on all dart sources, assets, and native dependencies. depending on the speed of the user's workstation, this can take anywhere from several seconds to several minutes to rebuild. both dart code and flutter assets can be loaded at runtime from the devfs instead of from the apk - this is how hot restart works. if the dart source code and assets are removed as inputs from the apk, then invalidations will only occur on flutter version updates or plugin changes, which will be significantly less frequent than source code changes. instead of building the user's application in the initial apk, we build the empty ""splash"" application which looks like so: after syncing files, the tool performs a silent hot restart to begin the debugging session. known issues: ides are not supported because we cannot hot restart into a paused state #45424 </desc> <cmt> example of fast start functionality </cmt> <cmt> add splash application </cmt>",support --fast-start for android applications (as an opt-in)
3309,"<desc> this pr will add flexibility and allow more configuration for nextcloud deployments: allow to put extra php configs put all default configuration if custom configurations are set for this particular case, if one extra config is set, the rsync exclude will prevent the first copy of all default configurations files. allow to have annotations on pvc cronjob follow redirect for cases like having https but not managed by the ingress controller (aws elb for example) image, affinity, tolerations and resources can be changed just for cronjob instead of using nextcloud deployment one change mount path to allow the creation of a tmp directory in volume instead of using the /tmp which is on kubernetes nodes (large files upload can be in trouble when using the /tmp) use the fs group of www-data (33) for mounted files (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> [stable/nextcloud] allow to inject custom php configuration files </cmt> <cmt> [stable/nextcloud] add annotations and labels on pvc </cmt> <cmt> [stable/nextcloud] add fs group of www-data for mounted files </cmt> <cmt> [stable/nextcloud] change mount path of pvc </cmt> <cmt> [stable/nextcloud] add tmp directory in volume </cmt> <cmt> this directory can be used for uploads as temporary directory </cmt> <cmt> [stable/nextcloud] fix cronjob job template labels for new helm spec </cmt> <cmt> [stable/nextcloud] allow change of cronjob image and add pull secrets </cmt> <cmt> [stable/nextcloud] allow change cronjob resources,tolerations,affinity </cmt> <cmt> [stable/nextcloud] cronjob (curl) follow redirect </cmt> <cmt> [stable/nextcloud] add default values for persistence annotations </cmt> <cmt> [stable/nextcloud] add all default nextcloud configurations </cmt> <cmt> [stable/nextcloud] update documentation with new values and indent </cmt> <cmt> [stable/nextcloud] upgrade chart version </cmt>",add flexibility and more configurations
3310,"<desc> since #5702 coldwhite and warmwhite channels were inverted. now channels are back to rbbcw (and not rgbwc) **related issue (if applicable): #5761 the pull request is done against the latest dev branch only relevant files were touched (also remember to update changelog.ino file) only one feature/fix was added per pr. the code change is tested and works. the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> fixed: wc/ww were inverted, back to rgbcw </cmt> <cmt> fixed: wc/ww were inverted, back to rgbcw </cmt>","coldwhite/warmwhite channels were inverted, back to rgbcw"
3311,"<desc> modify travis-ci: use python 3.6.5 instead of the latest python 3.8. it seems that travis-ci is failing (mac with python3) in recent prs. originally brew upgrade python used python 3.7. it changes to use 3.8 recently and mypy type check fails in python 3.8. error log is here: clang -wno-unused-result -wsign-compare -wunreachable-code -fno-common -dynamic -dndebug -g -fwrapv -o3 -wall -iast27/include -i/usr/local/cellar/python@3.8/3.8.3_2/frameworks/python.framework/versions/3.8/include/python3.8 -c ast27/parser/acceler.c -o build/temp.macosx-10.13-x86_64-3.8/ast27/parser/acceler.o ast27/parser/acceler.c:13:10: fatal error: 'pgenheaders.h' file not found #include ""pgenheaders.h"" ^~~~~~~~~~~~~~~ 1 error generated. error: command 'clang' failed with exit status 1 ---------------------------------------- error: failed building wheel for typed-ast running setup.py clean for typed-ast failed to build typed-ast installing collected packages: typed-ast, mypy, onnx running setup.py install for typed-ast ... error error: command errored out with exit status 1: </desc> <cmt> merged </cmt> <cmt> update from upstream </cmt> <cmt> merged </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",fix travis-ci on mac with python3 and circleci with stable vision
3312,<desc> fixes color range when dxva processor is used for rendering. fixes a possible segfault in video drivers when driver supports only fl9.1/9.2 re-factoring: see commit details. </desc> <cmt> [dxva] fix dxva renderer color range. </cmt> <cmt> [winvideofilter] lower feature level for test shader. this fixes segfault in video drivers which support only fl9.1/9.2. </cmt>,a set of fixes for directx.
3313,"<desc> the cmakelists that i tested worked on linux but not on win32. i made small fixes to get it to work on win32 platform. this probably needs more thorough testing, to make sure nothing is broken on other platforms where it is supposed to work but that i couldnt test on. </desc> <cmt> adding headers in src files so they appear in ide </cmt> <cmt> basic fixes for win32 builds </cmt> <cmt> fixed network link library curl in win32 case : libcurl_imp </cmt>",fixing cmake project for win32
3314,"<desc> this is a bug introduced in #26694 . the issue comes from the attempt to share code that commits the new history uuid and/or a new translog uuid. this goes wrong an existing 5.6 index that is recovered from store: a new history uuid is generated as it doesn't exist in the index the translog is opened and it's uuid doesn't change. the committing the new history uuid used the standard commitindexwriter method. the latter asks the translog for the oldest file generation that is required to recover from the local checkpoint + 1 the local checkpoint on old indices is -1 (until something is indexed) and the translog is asked to recover from position 0. that excludes any operations the translog that do not have a seq no assigned, causing the fullclusterrestart bwc tests to fail. to bypass this pr moves away from the attempt to share the committing code between a new translog uuid and a new history uuid. instead we do what we did before and open the translog with a potential commit. afterwards we commit the history uuid if needed. this comes with the expense of opening up the method to commit an index writer in the engine. this pr is opened against 6.x . we have the option to leave the code on master as is. let me know which you prefer for the long term. i can go either way. </desc> <cmt> roll back combined history/translog commit </cmt> <cmt> move back to a follow history uuid commit, so not to confuse people that expect a commit to have translog info </cmt> <cmt> relax assertions </cmt> <cmt> name </cmt>",generating and committing a history_uuid on existing old indices destroys translog recovery info
3315,"<desc> close #3488 depend on  deno.cachedir() deno.configdir() deno.datadir() deno.datalocaldir() deno.audiodir() deno.desktopdir() deno.documentdir() deno.downloaddir() deno.fontdir() deno.picturedir() deno.publicdir() deno.templatedir() deno.videodir() if the directory does not exist, an exception is thrown e.g. deno.downloaddir() not every linux has a download directory todo: test case </desc> <cmt> merger upstream </cmt> <iss> want: more dir api for system </iss>",add more dir api for deno
3316,"<desc> i've fixed a few minor errors in the windows and wsl building documentation; specifically an incorrect link title (windows.md), an unclear article title (windowssubsystemforlinux.md) and an outdated link to msdn (windowssubsystemforlinux.md). </desc> <cmt> update windowssubsystemforlinux.md </cmt> <cmt> clarified article title, updated msdn link </cmt> <cmt> clarify wsl article link </cmt>",clarified and corrected wsl/windows documentation
3317,<desc> this is a followup to #31886. after that commit the transportconnectionlistener had to be propogated to both the transport and the connectionmanager. this commit moves that listener to completely live in the connectionmanager. the request and response related methods are moved to a transportmessagelistener. that listener continues to live in the transport class. </desc> <cmt> wip </cmt> <cmt> remove connection listener from transport </cmt> <cmt> add methods </cmt> <cmt> fix checkstyle </cmt>,move connection listener to connectionmanager
3318,<desc> fixes: #4117 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> f-string update rsa_cipher.py </cmt> <cmt> f-string update rsa_key_generator.py </cmt> <cmt> f-string update burrows_wheeler.py </cmt> <cmt> f-string update non_recursive_segment_tree.py </cmt> <cmt> f-string update red_black_tree.py </cmt> <cmt> f-string update deque_doubly.py </cmt> <cmt> f-string update climbing_stairs.py </cmt> <cmt> f-string update iterating_through_submasks.py </cmt> <cmt> f-string update knn_sklearn.py </cmt> <cmt> f-string update 3n_plus_1.py </cmt> <cmt> f-string update quadratic_equations_complex_numbers.py </cmt> <cmt> f-string update nth_fibonacci_using_matrix_exponentiation.py </cmt> <cmt> f-string update sherman_morrison.py </cmt> <cmt> f-string update levenshtein_distance.py </cmt> <cmt> fix lines that were too long </cmt> <iss> refactor: use f-strings instead of str format </iss>,changes occurences of str.format to f-strings
3319,"<desc> original pull-request #33065 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> out of bounds column index </cmt> <cmt> add a test </cmt> <cmt> merge #33050 </cmt>",cherry pick #33065 to 21.12: merge #33050
3320,"<desc> fixes #8978 during testing of docker with device mapper backend, i often noticed bunch of warnings on console and often thought that if something is wrong with my docker setup. it turned out that docker does not keep track of already used device ids.  this patch series should make docker little bit smarter about it. more details are in issue and patches. please review and pull. thanks vivek </desc> <cmt> devmapper: move file write and rename functionality in a separate function </cmt> <cmt> currently we save device metadata and have a helper function savemetadata() </cmt> <cmt> which converts data in json format as well as saves it to file. for </cmt> <cmt> converting data in json format, one needs to know what is being saved. </cmt> <cmt> break this function down in two functions. one function only has file </cmt> <cmt> write capability and takes in argument about byte array of json data. </cmt> <cmt> now this function does not have to know what data is being saved. it </cmt> <cmt> only knows about a stream of json data is being saved to a file. </cmt> <cmt> this allows me to reuse this function to save a different type of </cmt> <cmt> metadata. in this case i am planning to save nextdeviceid so that </cmt> <cmt> docker can use this device id upon next restart. otherwise docker </cmt> <cmt> starts from 0 which is suboptimal. </cmt> <cmt> devmapper: export nextdeviceid so that json.marshal() can operate on it </cmt> <cmt> i was trying to save nextdeviceid to a file but it would not work and </cmt> <cmt> json.marshal() will do nothing. then some search showed that i need to </cmt> <cmt> make first letter of struct field capital, exporting this field and </cmt> <cmt> now json.marshal() works. </cmt> <cmt> this is a preparatory patch for the next one. </cmt> <cmt> devmapper: save and restore nextdeviceid in a file </cmt> <cmt> the way thin-pool right now is designed, user space is supposed to keep </cmt> <cmt> track of what device ids have already been used. if user space tries to </cmt> <cmt> create a new thin/snap device and device id has already been used, thin </cmt> <cmt> pool retuns -eexist. </cmt> <cmt> upon receiving -eexist, current docker implementation simply tries the </cmt> <cmt> nextdeviceid++ and keeps on doing this till it finds a free device id. </cmt> <cmt> this approach has two issues. </cmt> <cmt> - it is little suboptimal. </cmt> <cmt> - if device id already exists, current kenrel implementation spits out </cmt> <cmt> a messsage on console. </cmt> <cmt> [17991.140135] device-mapper: thin: creation of new snapshot 33 of device 3 failed. </cmt> <cmt> here kenrel is trying to tell user that device id 33 has already been used. </cmt> <cmt> and this shows up for every device id docker tries till it reaches a point </cmt> <cmt> where device ids are not used. so if there are thousands of container and </cmt> <cmt> one is trying to create a new container after fresh docker start, expect </cmt> <cmt> thousands of such warnings to flood console. </cmt> <cmt> this patch saves the nextdeviceid in a file in </cmt> <cmt> /var/lib/docker/devmapper/metadata/deviceset-metadata and reads it back </cmt> <cmt> when docker starts. this way we don't retry lots of device ids which </cmt> <cmt> have already been used. </cmt> <cmt> there might be some device ids which are free but we will get back to them </cmt> <cmt> once device numbers wrap around (24bit limit on device ids). </cmt> <cmt> this patch should cut down on number of kernel warnings. </cmt> <cmt> notice that i am creating a deviceset metadata file which is a global file </cmt> <cmt> for this pool. so down the line if we need to save more data we should be </cmt> <cmt> able to do that. </cmt> <iss> snapshot creation failure warnings on console </iss>",save restore device id: issue #8978
3321,"<desc> renamed the folders and projects as per powerrename. there are 3 folders under imageresizer: dll : contains the imageresizerext project (previously shellextensions) ui : contains the imageresizerui project (previously imageresizer) tests : contains the imageresizeruitest project (previously imageresizer.test) all files and references of shellextensions has been replaced by imageresizerext. added an empty readme.md file for imageresizer. pr checklist applies to #53 cla signed. if not, go over here and sign the cla tests passed validation steps performed build/install/run debug/release x64 all test cases pass </desc> <cmt> created empty readme file </cmt> <cmt> renamed dll project </cmt> <cmt> removed shellextensions references in src </cmt> <cmt> fixed imageresizerui assembly name and added changes to msi </cmt>",refactor imageresizer code base naming to match powerrename
3322,"<desc> related issue = #3775 #2489 problem: with the introduction of pretty exception mechanism, the ""excepthook"" and ""_taichi_skip_traceback"" are no longer needed. therefore i removed all occurrences and  make respective changes to documents. briefing of changes: remove all occurrences of ""excepthook"" and ""_taichi_skip_traceback"" change descriptions of pretty traceback messages rename ""misc/demo_excepthook.py"" to ""misc/demo_traceback.py"" </desc> <cmt> deprecate excepthook and cleanup all _taichi_skip_traceback. </cmt>",deprecate excepthook and completely remove _taichi_skip_traceback
3323,"<desc> this pr takes care of correcting a series of crashes and incorrections on async gpu & vulkan. resume of changes: remove cpu query cache invalidation on async gpu, as async gpu always flushes and invalidates them. on async gpu, shader & pipeline invalidations from the cpu will no longer be instant and instead use the sync interface. corrected an issue in vulkan's pipeline cache where if a shader had an invalid address, it wouldn't use a null shader instead of trying to decompile it. </desc> <cmt> videocore: use syncguestmemory mechanism for shader/pipeline cache invalidation. </cmt> <cmt> vkpipelinecache: use a null shader on invalid address. </cmt>",correct a series of crashes and intructions on async gpu and vulkan pipeline
3324,"<desc> currently when a user with talkback active begins to type in a text field, the hint is immediately hidden triggering a secondary read of the nodes semantic info.  to avoid this, we always include the hint semantics in the semantics tree, regardless of whether it is hidden by text. additionally, we remove the label from the semantics tree when focused, as it moves up and away and is de-emphasized. fixes #16673 work towards #15187 </desc> <cmt> correct order of text field semantics </cmt> <cmt> undo extra change to text field </cmt> <cmt> merge </cmt> <cmt> change semantic visitor order for text field </cmt> <cmt> update test to reflect current order </cmt> <iss> android a11y: hint is not read out when textfield is toggled to edit mode </iss>",toggle whether label or hint contribute to text field semantics when unfocused/focused
3325,"<desc> improvements to the g-code parser. add parser shorthand functions to get a parameter (or default value). use parser.seenval for cases where a value is required. patch some spacing, comments </desc> <cmt> apply const, spacing, etc. </cmt> <cmt> cleanups to gcode.h, use seenval() </cmt>","use parser.seenval, add shorthand functions"
3326,"<desc> note: before submitting this pull request, please review our contributing guidelines. sometimes when publishing a chord with a large header a race condition occurs when the group result isn't saved before one of the tasks of the header completes. this regression was introduced in #4443 when the saving of the group result was moved after publishing the chord's header. even after rearranging the code so that header_result.save() would come first there was a problem since the code that freezes the group didn't use the same task_id as the one that the group was published with. this is now also fixed. </desc> <cmt> added a test case which artificially introduces a delay to group.save(). </cmt> <cmt> fix race condition by delaying the task only after saving the group. </cmt>",fix a race condition when publishing a very large chord header
3327,"<desc> hi there, this is my first pull request to rust :-) i started implementing some specializations for doubleendediterator::nth_back() and these are the first two. the problem has been discussed in #54054 and nth_back() is tracked in #56995. i'm stuck with the next implementation so i though i do a pr for the ones i'm confident with to get some feedback. </desc> <cmt> implement nth_back for box </cmt> <cmt> implement nth_back for windows </cmt>",implement specialized nth_back() for box and windows.
3328,"<desc> what's in this pull request? dynamic casts to anyobject should succeed for an arbitrary source type because we can always make a swiftvalue. resolved bug number: (sr-2420) resolved bug number: radar #26268575 before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> perform collection force-casts by force-casting the elements </cmt> <cmt> instead of forcing conditional casts of the elements. </cmt> <cmt> this should produce better and more compact code, allow more </cmt> <cmt> efficient runtime behavior, and generate much better runtime </cmt> <cmt> diagnostics if the cast fails. </cmt> <cmt> dynamic casts to anyobject should succeed for an arbitrary source </cmt> <cmt> type because we can always make a swiftvalue. </cmt> <cmt> rdar://26268575 </cmt>",dynamic casts to anyobject should succeed for all types via swiftvalue
3329,"<desc> overview this change includes the basics of the sqlite index; namely the metadata table and schema versioning.  it also adds the overarching class that will be used to contain the sqlite index for the consumers above.  finally, the versioning scheme for creating new schemas is begun and detailed below. design the object stack is as such: sqliteindex :: houses the database connection and the proper interface with which to interact with it isqliteindex :: interface that creates a uniform model to use against all schemas schema::v*::interface :: actual implementation of isqliteindex for specific schema version the code that needs to interact with an index will create a sqliteindex object.  that in turn will open the database, determine the schema version, then create the appropriate isqliteindex providing object.  all queries and changes to the index will go through the sqliteindex object. when a change to the schema is needed, a new schema directory should be created.  this can pull code from the schemas before it, only updating the specific table(s) that are needed.  then version code should be updated to create the new interface as appropriate.  any new methods needed on isqliteindex should be added, and sqliteindexbase to implement them in terms of the older functions.  only the new schema should need to implement the new functions.   once shipped, one should never need to update code within an existing schema, save for bug fixes. testing tests are added for creating a new sqlindex, and reopening it with the various dispositions. tests were also added for the new savepoint sqlite wrapper class. </desc> <cmt> begin index code </cmt> <cmt> checkpoint </cmt> <cmt> forgotten project files </cmt> <cmt> checkpoint </cmt> <cmt> checkpoint </cmt> <cmt> checkpoint </cmt> <cmt> finished baseline code for index with metadata.  needs more complete testing. </cmt>",add the basis for the sqlite index
3330,"<desc> some changes needed to install libraries and headers and small addition in testing lib to read wasm and abi files directly. </desc> <cmt> install libs and headers </cmt> <cmt> updated tester to read wasm and abi files, and updated submodules </cmt>",install libs and support for eosio.system repo
3331,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> add chayns typings version 0.14.0 </cmt> <cmt> fixes for tslint </cmt>",add typings for chayns version 0.14.0
3332,<desc> this adds the feature #8852 requested </desc> <cmt> add overwrite directory feature to savedmodelbuilder </cmt> <cmt> make indenting consistent to the rest of the code </cmt> <cmt> change assertion error's message to reflect new parameter </cmt>,allow savedmodelbuilder to overwrite existing folders
3333,<desc> this pr adds unit tests for the top-level develop state machine. the child machines will follow. </desc> <cmt> feat(gatsby): add top-level error handling to state machine </cmt> <cmt> add initial tests </cmt> <cmt> add tests for top-level machine </cmt> <cmt> test error handling </cmt>,add unit tests for develop state machine
3334,"<desc> a small cleanup / code consistency pr. no change in functionality. the wart that prompted this pr is the prior code called ::getenv() to sniff the electron_trash environment variable, then immediately used base::environment to sniff the desktop environment. this pr constructs the base::environment first so that it can be used in both places. also removes an unnecessary function wrapper and makes the trash argv builder easier to read. npm test passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> chore: use base::environment in moveitemtotrash() linux impl </cmt> <cmt> chore: remove unnecessary local function xdgutil() </cmt> <cmt> chore: tweak code comment </cmt>",use base::environment in linux moveitemtotrash()
3335,"<desc> and then add a warning for using -print-stats in such a build, to make it easier to triage these issues in the future. rdar://problem/30386242 </desc> <cmt> [test] disable -print-stats tests for no-asserts builds. </cmt> <cmt> rdar://problem/30386242 </cmt> <cmt> warn when using -print-stats on a release build. </cmt> <cmt> this should make it easier to catch issues like the previous commit </cmt> <cmt> in the future. </cmt>",disable -print-stats serialization tests for no-asserts builds
3336,"<desc> fix multiple values for keyword argument error in modelaverageoptimizer and elasticaverageoptimz. for detailed error, please look at here </desc> <cmt> fix multiple values for keyword argument error </cmt> <cmt> fix multiple values for keyword argument for easgd </cmt> <cmt> place easgd in ea_coustom_getter scope </cmt> <cmt> place ma_opt in ma_coustom_getter scope </cmt>",fix multiple values for keyword argument error in modelaverageoptimizer and elasticaverageoptimizer
3337,"<desc> the changes made possible to make custom handler on mouse wheel events in qt and gtk for linux opencv build. reopened pr #6725 due merge checking problem </desc> <cmt> highgui module: implemented qt and gtk mouse wheel callback support in linux </cmt> <cmt> pull highgui mouse wheel changes linux into master </cmt> <cmt> highgui module: removed unused type_mouse_event mouse_wheel </cmt> <cmt> compilate switch-case with gtk_scroll_smooth since gtk>=3.4 </cmt> <cmt> highgui: window_gtk.cpp directive boolean operations or/and replaced by ||/&& to keep compatible with older systems </cmt> <cmt> highgui module: a bit readable onmouse flags mapping </cmt> <cmt> highgui module: using event->scroll.delta_{x,y} instead parsing direction and added widget event mask gdk_smooth_scroll_mask for gtk>=3.4 </cmt> <cmt> highgui module: mouse wheel - modification keys fixed, wheel event value is cv_event_mousewheel or cv_event_mousehwheel </cmt> <cmt> highgui module: window_qt mouse wheel reuse variable delta instead call evnt->delta() </cmt>",implemented mouse wheel callback support for linux
3338,"<desc> pr to fix #1776 added test_start and test_stop events to the base runner class' start() and stop() method, respectively added/updated relevant tests and documentation. </desc> <cmt> toggled test condition and fixed broken event handler </cmt> <cmt> added event to base runner.start() method </cmt> <cmt> added dedicated tests for worker event changes </cmt> <cmt> updated test_stop event </cmt> <cmt> updated documentation </cmt> <iss> restore locust_start_hatching functionality </iss>",fire test_start and test_stop events on worker nodes
3339,"<desc> helps with #75080. @rustbot modify labels: t-doc, a-intra-doc-links, t-rustdoc known issues: the following f32 and f64 primitive methods cannot be resolved: f32/f64::powi f32/f64::sqrt f32/f64::sin f32/f64::cos f32/f64::powf f32/f64::exp f32/f64::exp2 f32/f64::ln f32/f64::log2 f32/f64::log10 f32/f64::mul_add f32/f64::abs f32/f64::copysign f32/f64::floor f32/f64::ceil f32/f64::trunc f32/f64::round links from core to std: links with anchors? i provided a separate commit that replaced links with anchors by intra-doc links. here the anchor location information gets lost, so its questionable whether to actually replace those links. </desc> <cmt> use intra-doc links for ordering::* </cmt> <cmt> use intra-doc links for atomicbool::* </cmt> <cmt> use intra-doc links for atomicisize::* </cmt> <cmt> use intra-doc links for atomici32::* </cmt> <cmt> use intra-doc links for atomicu32::* </cmt> <cmt> use intra-doc links for u32::* </cmt> <cmt> use intra-doc links for f32::* and f64::* </cmt> <cmt> use intra-doc links for sync::* </cmt> <cmt> use intra-doc links for mem::* </cmt> <cmt> use intra-doc links for ptr::* </cmt> <cmt> use intra-doc linkks </cmt> <cmt> use intra-doc links for compare_exchange and compare_exchange_weak </cmt> <cmt> use intra-doc links for links with anchors </cmt>",move to intra-doc links for /library/core/src/intrinsics.rs
3340,"<desc> some minor followups for that pr: add module integration code in shell.js, to avoid writing the js in emcc.py (which is at its maximum size this early in the compilation process, possibly hundreds of mb) just to add it, which is a little slower (a few %). do not force -o2 in test_modularize_closure_pre: while we won't have closure if -o0 or -o1, it's useful to see that the situation in that test passes in those modes as well fix an existing regression bug with debugging stuff like this, improper use of 'final' in emcc, which led to incorrect logging of temp files (if a method calls save_intermediate(), it must modify the global 'final' var, as that method reads it). in particular we logged the modularize temp file incorrectly. </desc> <cmt> add module integration code in shell.js, to avoid writing the js in emcc.py (which is at its maximum size this early in the compilation process, possibly hundreds of mb) just to add it, which is a little slower (a few %) </cmt> <cmt> do not force -o2 in test_modularize_closure_pre: while we won't have closure if -o0 or -o1, it's useful to see that the situation in that test passes in those modes as well </cmt> <cmt> fix improper use of 'final' in emcc, which led to incorrect logging of temp files (if a method calls save_intermediate(), it must modify the global 'final' var, as that method reads it) </cmt>",followups for eval-removal 1 (#5751)
3341,"<desc> fix #2923 for the npe add replaymethodsinvocation  for encryptpreparedstatement: replay  the cache properties such ad querytimeout </desc> <cmt> sync from apache </cmt> <cmt> fix for #2923 </cmt> <cmt> add the protected  querytimeout properties </cmt> <cmt> fix for #2923 </cmt> <cmt> if null == preparedstatement, return the empty statement list </cmt> <cmt> fix #2923 </cmt> <cmt> re add the querytimeout,set it zero when clear paramaters </cmt> <cmt> add @sneakythrows </cmt> <cmt> sync from apache </cmt> <cmt> fix #2923 </cmt> <iss> when using encryptpreparedstatement to savebatch occours error </iss>",fix #2923 add replaymethodsinvocation  for encryptpreparedstatement
3342,"<desc> remove useless initilization for tw and th code </desc> <cmt> emitter.start should setting quantity not adding </cmt> <cmt> i think emitter.start should setting quantity not adding, maybe ""+="" is a mistake? </cmt> <cmt> remove useless initilization for tw and th code </cmt> <cmt> tw and th have been initialized twice, the first time is useless. </cmt>",remove tw and th init
3343,"<desc> closes #31507 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> remove \n from docstring </cmt> <cmt> fix conflicts </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix issue 17038 </cmt> <cmt> revert change </cmt> <cmt> revert change </cmt> <cmt> fix uo </cmt> <iss> json_normalize in 1.0.0 with meta path specified - expects iterable </iss>",non-iterable value in meta raise error in json_normalize
3344,"<desc> fix #1149 </desc> <cmt> fix room model's removebytypecontainingusername.  usernames field missing trailing 's' </cmt> <cmt> deletes direct message subscription for users conversing with user being deleted. </cmt> <cmt> fixes #1149 where ""other"" user's subscription for non-deleted, direct message, was not deleted.  this led to duplicate key error if a new user, with the same username as the deleted user, is created and tries to direct message the ""other"" user. </cmt>",remove direct message subscription for both users when one is deleted
3345,"<desc> these commits partially revert my recent pr #10545, in favor of an implementation that uses the importscanner to compile any js modules that were not already compiled by compiler plugins, including modules found in .npm/package/node_modules directories. revert using _findsources to scan .npm/package/node_modules after much thought, i believe this implementation (#10545) would have caused severe compatibility problems when using packages published with earlier versions of meteor in a meteor 1.8.2 app, or when publishing packages with meteor 1.8.2 for use with earlier meteor versions. specifically, this implementation relied on writing the additional .npm/package/node_modules resources found by _findsources into the unibuild json file(s), and there just wasn't any good way to make sure the new json format could be safely consumed by previous meteor versions. even if we found a way to hide the new resources from older versions of meteor, perhaps by putting them in a new/different property of the unibuild json file, packages published with older meteor versions might try to load an npm package with a ""module"" field without realizing the code must be compiled, which would likely cause a syntax error in meteor 1.8.2, since the ""module"" field always gets preference over the ""main"" field of package.json (in meteor 1.8.2). backstop esm module compilation with reify in the importscanner instead of compiling esm syntax in node_modules using compiler plugins, the importscanner can provide ""native"" support for esm syntax by using reify to quickly compile just the import/export syntax in any imported modules that were not already handled by compiler plugins. since this code runs every time the app is built, it should not matter which version of meteor was used to publish a package. compared to the previous implementation (#10545), this implementation should have far fewer compatibility concerns, as well as being faster thanks to not processing or compiling modules until the importscanner determines that they are actually imported. the number of files that get compiled by this system should be relatively small for now, but to maintain good performance, the results of the compilation are cached on disk and in memory. </desc> <cmt> revert using _findsources to scan .npm/package/node_modules. </cmt> <cmt> after much thought, i believe this implementation (#10545) would have </cmt> <cmt> caused severe compatibility problems when using packages published with </cmt> <cmt> earlier versions of meteor in a meteor 1.8.2 app, or when publishing </cmt> <cmt> packages with meteor 1.8.2 for use with earlier meteor versions. </cmt> <cmt> specifically, this implementation relied on writing the additional </cmt> <cmt> .npm/package/node_modules resources found by _findsources into the </cmt> <cmt> unibuild json file(s), and there just wasn't any good way to make sure the </cmt> <cmt> new json format could be safely consumed by previous meteor versions. </cmt> <cmt> even if we found a way to hide the new resources from older versions of </cmt> <cmt> meteor, perhaps by putting them in a new/different property of the </cmt> <cmt> unibuild json file, packages published with older meteor versions might </cmt> <cmt> try to load an npm package with a ""module"" field without realizing the </cmt> <cmt> code must be compiled, which would likely cause a syntax error in meteor </cmt> <cmt> 1.8.2, since the ""module"" field always gets preference over the ""main"" </cmt> <cmt> field of package.json (in meteor 1.8.2). </cmt> <cmt> backstop esm module compilation with reify in the importscanner. </cmt> <cmt> instead of compiling esm syntax in node_modules using compiler plugins, </cmt> <cmt> the importscanner can provide ""native"" support for esm syntax by using </cmt> <cmt> reify to quickly compile just the import/export syntax in any imported </cmt> <cmt> modules that were not already handled by compiler plugins. </cmt> <cmt> since this code runs every time the app is built, it should not matter </cmt> <cmt> which version of meteor was used to publish a package. compared to the </cmt> <cmt> previous implementation based on packagesource#_findsources and unibuild </cmt> <cmt> json files (#10545), this implementation should have far fewer </cmt> <cmt> compatibility concerns, as well as being faster thanks to not processing </cmt> <cmt> or compiling modules until the importscanner determines that they are </cmt> <cmt> actually imported. </cmt> <cmt> though the number of files that get compiled by this system should be </cmt> <cmt> relatively small for now, to maintain good performance, the results of the </cmt> <cmt> compilation are cached on disk and in memory. </cmt>","support module syntax in importscanner, rather than using packagesource#_findsources."
3346,"<desc> fix ""too many connections of zookeeper datasource"" related to #612 save zkclient in a global map and reuse it 5 rules enabled echo cons | nc zookeeper.host 2181 check if there only exists one connection to zkserver </desc> <cmt> com.alibaba.csp.sentinel.node.statisticnode#curthreadnum </cmt> <cmt> using the longadder rather than atomicinteger to provides better performance </cmt> <cmt> reformat the code according to alibaba java coding guideline </cmt> <cmt> reformat the code according to alibaba java coding guideline </cmt> <cmt> fix issue#612: too many connection of zookeeper datasource </cmt> <cmt> reformat code </cmt>",fix too many connection of zookeeper datasource
3347,<desc> add some update statements ansible/modules/network/cloudengine/ce_bgp_neighbor_af.py </desc> <cmt> update ce_bgp_neighbor_af modified information </cmt> <cmt> update ce_bgp_neighbor_af to fix bugs (#60937) </cmt> <cmt> * update ce_bgp_neighbor_af to fix bugs </cmt> <cmt> * update ce_bgp_neighbor_af to fix bugs </cmt> <cmt> * update ce_bgp_neighbor_af to fix bugs </cmt> <cmt> (cherry picked from commit a2602090981a65652199423a185e3c2bd8b2c356) </cmt>,[backport/2.8/60937]update ce_bgp_neighbor_af to fix bugs
3348,"<cmt> make sure the global asyncio event loop policy isn't changed. </cmt> <cmt> by default there is no default event loop policy, so typically this is simply making sure it isn't set. </cmt> <cmt> update tests to not leave an event loop policy behind </cmt> <cmt> add a news entry </cmt>",check the global asyncio event loop policy isn't set after any tests
3349,"<desc> try to implement keyboard shortcuts in the browse folder dialog by importing wine code jira issue: core-14332 import the wine commit which implement the shortcuts - import shellfolder.h to have isfhelper definition (that maybe let us get rid of some #ifdef reactos) now at least renaming via f2 key works, but not delete via del key get del also working (help or tips appreciated) </desc> <cmt> [shell32] add shortcut to rename folders with the f2 key. </cmt> <cmt> sync wine commit 2e25a43f3fb6230460447bae6fb5db2edbd4a42f by fabian maurer </cmt> <cmt> [shell32] add shortcut to delete folders with the delete key. </cmt> <cmt> sync wine commit 43f44ffb3779ff23c863d9b3297f92720e7e3733 by fabian maurer </cmt>",sync brsfolder.c with keyboard shortcut code from wine
3350,"<desc> currently, kafkalog4jappender does not support linger.ms or batch.size. in some situations, those two parameters are good to tune the performance. </desc> <cmt> kafka-10407: have kafkalog4jappender batch.size and linger.ms </cmt> <cmt>  </cmt> <cmt> currently, kafkalog4jappender does not support batch.size or linger.ms which would otherwise be beneficial in some situations. </cmt> <cmt> removed import * </cmt>",have kafkalog4jappender support linger.ms and batch.size
3351,<desc> unify the terms and interface used for logging in to 1password  between the facts module and lookup plugins. onepassword.py onepassword_raw.py onepassword_facts.py ansible version 2.7 </desc> <cmt> unify login behavior between 1password lookup plugins and module </cmt> <cmt> - use the same names for all credential aspects </cmt> <cmt> - only require the minimal amount of information for each </cmt> <cmt> - add more examples </cmt> <cmt> change parameter terms </cmt> <cmt> - use terms in line with 1password documentation. </cmt> <cmt> - update examples </cmt> <cmt> - update tests </cmt>,unify terms and ui between 1password lookups and facts module
3352,<desc> another pr for #4475. refactor tracers config: move interface to include/ introduce factorybase to reduce boiler plate use config::utility to convert opaque config risk level: low testing: ci docs changes: n/a release notes: n/a </desc> <cmt> move tracer config to its own file </cmt> <cmt> introduce factory base </cmt> <cmt> change interface to use opaque config only </cmt>,refactor tracers to use config::utility
3353,"<desc> fixes #5668 for the entity linker training example, according to the first comment by @adrianeboyd . i have submitted the spacy contributor agreement. i ran the tests, and all new and existing tests passed. --> i tested the modified example code. </desc> <cmt> entity linker training example: model loading changed according to issue 5668 ( </cmt> <cmt> contributor agreement </cmt>",fixed vocabulary in the entity linker training example
3354,<desc> fixes #2112 updated to vs2017 project format added description of how types are disposed i didn't update the actual code samples to include cover disposability; i just added an inline code section. perhaps @davidfowl could review. </desc> <cmt> upgrade to vs2017 project format. </cmt> <cmt> updated to describe how services container handles disposing of idisposable instances </cmt>,di disposing and project format upgrade
3355,<desc> apply #pragma once instead of using bracketing defines. clean up some formatting. remove some extraneous header includes. </desc> <cmt> adjust some thermistors formatting </cmt> <cmt> apply #pragma once in headers </cmt> <cmt> misc cleanup and formatting </cmt>,"apply #pragma once, misc cleanup"
3356,"<desc> before this pr, files are delivered by cloud pickle which can't deliver the independent modules. in this pr, a new api is introduced job_config = ray.job_config.jobconfig( runtime_env = { 'working_dir': '/mnt/data/test' } ) ray.init(address='auto', _redis_password='5241590000000000', job_config=job_config, logging_level=logging.debug) for the driver: it'll create a package and push it, if it doesn't exist for worker: it'll fetch the package if it doesn't exist. some implementation details here: filelock is used to avoid concurrent downloading package is uploaded to redis when the driver starts package is downloaded when the worker starts file size limit is added to avoid uploading too big files. some work to be done: adding gc to remove non-using pkg better delivering and caching logic ray client support closes #14527 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> prototype support </cmt> <cmt> move downloading to other place </cmt> <cmt> make it work </cmt> <cmt> format </cmt> <iss> basic support for shipping code with working_dir and py_modules </iss>",minimal support for runtime env
3357,"<desc> attempt to detect and repair situations where optional unwrap is missing from operator/call arguments. don't suggest default value fix-it if effected argument belongs to inout operator parameter or enclosed in explicit address-of. resolves: rdar://problem/47776586 </desc> <cmt> [cssimplify] detect missing optional unwraps in operator/call arguments </cmt> <cmt> [diagnostics] refactor missing optional unwrap diagnostic </cmt> <cmt> instead of passing all of the information available in the diagnostic </cmt> <cmt> to static functions, let's bring ""default value"" and ""force unwrap"" </cmt> <cmt> fix-it logic under ""missing optional unwrap diagnostic"" umbrella. </cmt> <cmt> [diagnostics] don't suggest unwrap with default value if type is not materializable </cmt> <cmt> [typechecker] nfc: add a test-case for rdar://problem/47776586 </cmt>",detect and diagnose missing optional unwrap in arguments
3358,<desc> this is better for editing the colors (you only need to change the style.css file) </desc> <cmt> readme update for bin files </cmt> <cmt> note for the esptool (nodmcu-flasher alternative) </cmt> <cmt> all css in 1 file </cmt>,all css in one file
3359,"<desc> r? @guillaumegomez </desc> <cmt> remove unnecessary crate_name parameter to after_krate </cmt> <cmt> it's always tcx.crate_name(local_crate), it doesn't need to be passed </cmt> <cmt> in separately. </cmt> <cmt> remove unnecessary diag parameter to after_krate </cmt> <cmt> remove unnecessary edition parameter to renderer </cmt> <cmt> remove unnecessary edition field on sharedcontext </cmt>",remove unnecessary fields and parameters in rustdoc
3360,<desc> deleted typography.js which unnecessarily complicates the example for styled-components moved createglobalstyle to a separate file with good practise </desc> <cmt> delete typography.js which shouldn't be in the styled-components example </cmt> <cmt> moved globalstyle to external file with good practise </cmt>,delete typography.js and move createglobalstyle to separate file for styled-components example
3361,"<desc> general idea is to show using easily understood tools and metrics how to compare your site's performance, and to use these ideas to show rather than tell that gatsby v2 improves performance over gatsby v1. </desc> <cmt> blog: start working on gatsby-perf blog post </cmt> <cmt> blog: keep writing post </cmt> <cmt> chore: keep working </cmt> <cmt> blog: some more tweaks </cmt> <cmt> chore: add source </cmt>",add web perf 102 blog post relating to gatsby v2
3362,<desc> fix rss icon too large in rss settings dialog remove trailing spaces fix download & upload icon too large on statusbar in webui </desc> <cmt> fix rss icon too large in rss settings dialog </cmt> <cmt> give a name to the rss icon (in .ui file) </cmt> <cmt> add helper function: utils::misc::largeiconsize() </cmt> <cmt> group functions under the same #ifdef </cmt> <cmt> remove trailing spaces </cmt> <cmt> fix download & upload icon too large on statusbar in webui </cmt>,fix new icons too large
3363,<desc> flags certain test cases in scheduler using package:test tags in order to facilitate landing support for running all framework tests in a browser. requires: #33349 </desc> <cmt> changes to scheduler to faciliate web testing </cmt> <cmt> remove extra skips </cmt>,compatibility pass on flutter/scheduler tests for javascript compilation. (2)
3364,"<desc> i hereby agree to the terms of the cla available at:  detailed description / documentation draft: converted raw github issues / pulls url links to #ddddd format fixed typos added more detailed descriptions (copy-pasting from other versions of the same pr/issus) wrapped some queries and setting parts as code blocks typo: materialize *d* mysql -> materializemysql (although materialize d sounds natural...) </desc> <cmt> docs: fix broken changelog link </cmt> <cmt> docs: fix raw link to #ddddd </cmt> <cmt> fix: typo and code blocks, missing explanations </cmt>","changelog issue/pr raw urls to #ddddd links, with some typo fixes"
3365,"<desc> back when for-loop iteration variables were just de-sugared into let bindings, debuginfo for them was created like for any other let binding. when the implementation approach for for-loops changed, we ceased having debuginfo for the iteration variable. this pr fixes this omission and adds a more prominent test case for it. also contains some minor, general cleanup of the debuginfo module. fixes #19732 </desc> <cmt> debuginfo: create debuginfo for for-loop variables again. </cmt> <cmt> debuginfo: clean the debuginfo module up a bit. </cmt> <cmt> debuginfo: add test case for destructured for-loop variable. </cmt> <iss> debuginfo: ""lexical-scope-in-for-loop"" auto-test fails </iss>",fix regression in for-loop variable debuginfo
3366,<desc> fixes r2d2 (torch) multi-gpu issues with lstm and attention nets. the following yaml file would cause an error for r2d2: stateless-cartpole-r2d2: env: ray.rllib.examples.env.stateless_cartpole.statelesscartpole run: r2d2 stop: episode_reward_mean: 150 timesteps_total: 1000000 config: # works for both torch and tf. framework: tf num_workers: 0 # r2d2 settings. burn_in: 20 zero_init_states: true #dueling: false lr: 0.0005 # give some more time to explore. exploration_config: epsilon_timesteps: 50000 # wrap with an lstm and use a very simple base-model. model: fcnet_hiddens: [64] fcnet_activation: linear #use_lstm: true use_lstm: true lstm_cell_size: 64 max_seq_len: 20 # fake 2 gpus. num_gpus: 2 _fake_gpus: true same for using an attention net instead of the lstm. this pr fixes both issues. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip. </cmt> <cmt> wip </cmt>,fix r2d2 (torch) multi-gpu issue.
3367,"<desc> i hereby agree to the terms of the cla available at:  added postgresql table engine (both select/insert, with support for multidimensional arrays), also as table function. added postgresql dictionary source. added postgresql database engine. </desc> <cmt> add libpq and libpqxx </cmt> <cmt> add storage postgresql with read support </cmt> <cmt> better </cmt> <cmt> support insert into table </cmt> <cmt> add table function </cmt> <cmt> better </cmt> <cmt> add tests for storage </cmt> <cmt> add postgres dictionary source </cmt> <cmt> better </cmt> <cmt> update libraries </cmt> <cmt> add postgresql database engine </cmt> <cmt> update libpq </cmt> <cmt> add table cache, better drop table </cmt>","add postgresql table function, dictionary source, database engine"
3368,<desc> adds a field to docs frontmatter to link to an issue on github if this field is present it will generate a link to the issue on github updates documentation on removing the link to issue when a stub is converted to a doc closes #11342 not sure the style of the link is the best way to display this. happy to have someone provide contribution to this. </desc> <cmt> added issue frontmatter to docs field </cmt> <cmt> added conditional for render of github link </cmt> <cmt> typo </cmt> <cmt> updated contribution docs re removing issue </cmt> <cmt> update gatsby node to fetch frontmatter for issue </cmt>,link stub to github issue
3369,"<desc> also, added exposing webpack to the next.config.js webpack function fixes: #6353 </desc> <cmt> add using circleci env var for max workers </cmt> <cmt> and expose webpack to config </cmt> <cmt> expose experimental cpu config </cmt> <iss> build failing with `spawn enomem` / `spawn e2big` </iss>",add experimental cpus config and use circleci env var
3370,"<desc> adding in triage needed by default what is include in the pr: the templates with the tag we merge in and check.  does not touch any source linked issue: #9136 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> update translation_issue.md </cmt> <cmt> update bug_report.md </cmt> <cmt> update feature_request.md </cmt> <cmt> update documentation-issue.md </cmt>",default add triage to issues
3371,"<desc> commit 1 fixes ""error c2678: binary '!=': no operator found which takes a left-hand operand of type 'serialized' (or there is no acceptable conversion)"" there is an acceptable conversion, msvc!  #include <iostream> class decl { }; // has to be a subclass - using decl works. class valuedecl : public decl { }; class serialized { public: /*implicit*/ operator decl *() const { return nullptr; } }; // has to be const. void execute(const valuedecl *parent) { serialized serialized; if (serialized != parent) { std::cout << ""hello, world""; } // replacing the if block with the following is the workaround. /* decl *converted = serialized; if (converted != parent) { std::cout << ""hello, world""; }*/ } int main() { execute(nullptr); } commit 2 fixes warnings ""not all control paths return a value"" all control paths are covered, msvc! </desc> <cmt> work around msvc bug for equality check of implicit operator conversion of class to base-class pointer with const subclass pointer </cmt> <cmt> add some llvm_unreachable annotations for recently introduced msvc control path warnings </cmt>",get swift compiling with msvc again
3372,<desc> category documentation added wp-semantix to list of companies using apache superset in readme.md file before: list of companies using apache superset from the readme.md file: after: list of companies using apache superset from the readme.md file: test plan none needed requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> latest apache superset (rc 0.33) </cmt> <cmt> latest changes from apache-superset </cmt> <cmt> added wpsemantix to list of companies using apache superset in readme.md file </cmt>,added wpsemantix to list of companies using apache superset in readme file
3373,"<desc> this pr upgrades elastalert to 0.1.30, which includes the changes described in the master yelp/elastalert repository: yelp/elastalert@87119b8 which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # no kubernetes related fixes. </desc> <cmt> upgrade to new docker image 0.1.30 </cmt> <cmt> upgrade to new docker image 0.1.30 </cmt>",upgrade to 0.1.30 of elastalert docker image
3374,<desc> i hereby agree to the terms of the cla available at:  add parallel quorum inserts. this closes #15601. detailed description / documentation draft: to use parallel quorum insert set the value insert_quorum >= 2 and insert_quorum_parallel = 1 these inserts can be non-linearizable and can't run in parallel with non-parallel inserts. they also can't be used with sequential_consistency </desc> <cmt> first part </cmt> <cmt> working copy (with some debug info) </cmt> <cmt> remove debug things </cmt> <cmt> add question in comments </cmt> <cmt> quorum inserts 2 </cmt> <cmt> quorum inserts 2 </cmt>,improvement of quorum inserts in clickhouse
3375,"<desc> this pr adds a new provider to airflow for executing sql queries against an apache drill instance.  this is useful because, while its primary use case is interactive analysis that often avoids the need for etl, drill's ctas statements and support for querying a large variety of data sources also make it a very capable etl tool.  what is lacking to use drill this way is worklow management, and that gap is one that airflow fills perfectly. </desc> <cmt> add apache drill provider. </cmt> <cmt> add docs skeletons. </cmt>",airflow-5529 add apache drill provider.
3376,"<desc> issue: #15172 this adds a new shortcuts query param for the manager. when set to false it will set ui.enableshortcuts: false, so that keyboard shortcuts will be disabled. this is particularly useful when embedding stories on a page, where keyboard shortcuts might conflict. additionally, i've taken the opportunity to support true and false as alternative to 0 or 1, add a table of supported params to the docs, and properly deprecate some legacy params. is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? yes, added </desc> <cmt> implement shortcuts=0 url param to disable keyboard shortcuts </cmt> <cmt> support true/false as url param value, document and properly deprecate layout url params </cmt>",add shortcuts url param to disable keyboard shortcuts
3377,"<desc> this pr fixes three small issues: iprofilingblockinputstream checked limits after reading a block (which would be committed, but not used) limits were applied on the unionblockinputstream instead of kafka streams, which could cause an extra block to be read storagekafka: make commit message only if messages are consumed (this is not an issue, but optimization) refs #1690 </desc> <cmt> iprofilingblockinputstream: check limits before reading block </cmt> <cmt> this makes one pointless check before the first block is read, but </cmt> <cmt> is necessary to prevent reading blocks from storages like kafka where </cmt> <cmt> messages are read only once. </cmt> <cmt> storagekafka: make commit message only if messages are consumed </cmt> <cmt> storagekafka: move limits to individual kafka streams instead of unionblockinputstream </cmt> <cmt> the unionblockinputstream might read an extra block from the asynchronous child streams otherwise, </cmt> <cmt> which will never be used, but offsets for this block would be committed, which would result in </cmt> <cmt> lost messages. </cmt>",fix missing messages in kafka materialized views
3378,"<desc> per @oliviertassinari's suggestion at codesandbox/codesandbox-client#2284 (comment), i've added post-updates to each of the container sandbox example package.json files so they run on codesandbox without issue. i have followed (at least) the pr section of the contributing guide. </desc> <cmt> add post-update for yarn </cmt> <cmt> importing this example to codesandbox doesn't work, but it does with this. </cmt> <cmt> add post-update for yarn </cmt> <cmt> importing this example to codesandbox doesn't work, but it does with this. </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> editing post-update for codesandbox </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> editing post-update for codesandbox </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> adding post-update for codesandbox </cmt> <cmt> adding link to sandbox </cmt> <cmt> removing post-update </cmt> <cmt> added in error - not required as it's a client sandbox, not container. </cmt> <cmt> removing post-update </cmt> <cmt> added in error - not required as it's a client sandbox, not container. </cmt>",add post-update to examples so they run on codesandbox
3379,"<desc> part of work for #2958 builds cypress binary for mac platform on circleci (instead of buildkite), all jobs can now run on both linux and mac via executor parameter, both binaries are built. blocked from completing this because cannot sign the mac app using fastlane (does not support mac apps). see issue itself for links about the blocking issue. would like to land the work so far, even with mac workflow disabled for now, since it makes the jobs more robust </desc> <cmt> use arch when caching dependencies on circle </cmt> <cmt> add mac job </cmt> <cmt> hmm, mac name </cmt> <cmt> executor name </cmt> <cmt> use circle v2.1 </cmt> <cmt> circle 2.1 cannot have job names start with a digit </cmt> <cmt> hmm, separate mac workflow </cmt> <cmt> shared build job via executor </cmt> <cmt> allow node version mismatch on circleci mac build </cmt> <cmt> correct workflow names per os </cmt> <cmt> do not check term on darwin platform </cmt>",build osx on circle 2958
3380,"<desc> chromium introduced metrics to measure unload performance in:  which would cause some dchecks to assert in electron in some cases: #27717. and it would result in failing tests, because it caused the main process to crash: crashreporter module should send minidump when sandboxed renderer crashes api-crash-reporter-spec.ts 643 ms error message: ptype: expected 'browser' to equal 'renderer' error stack trace: assertionerror: ptype: expected 'browser' to equal 'renderer' at checkcrash (electron\spec-main\api-crash-reporter-spec.ts:39:35) at context.<anonymous> (electron\spec-main\api-crash-reporter-spec.ts:154:7) at runmicrotasks (<anonymous>) at processticksandrejections (internal/process/task_queues.js:93:5) this patch temporarily disables the metrics so we can have green ci, before finding out a real fix. note that this pr also replaced uses of deprecated crashed events to avoid running into the crash in #27730. npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none </desc> <cmt> patch </cmt> <cmt> use render-process-gone instead of crashed </cmt> <cmt> update patches </cmt>",disable unload metrics to fix ci failure
3381,<desc> after talking with @jdipierro i'm taking over this initiative. however i can't actually interact with the old pr so this is being created. his original work has been rebased onto latest master. referencing #849 adds a basic dockerfile with a base of python:3.7-alpine putting final image size at 291mb. i believe most if not all of the changes requested by @mbeacom have been addressed in this as well. </desc> <cmt> dockerfile and startup script </cmt> <cmt> docker compose example </cmt> <cmt> first pass at docker docs </cmt> <cmt> attempt to add docker build to travis matrix </cmt> <cmt> remove docker compose docs </cmt> <cmt> i've found it easier to run locust locally in standalone mode while developing the locustfile. </cmt> <cmt> the example docker-compose file still exists though. </cmt> <cmt> update dockerfile to slim down created image and tweak behaviors. </cmt> <cmt> change base image from py3.6 to py3.7-alpine. this shrinks the image size by about 600mb so that's nice. </cmt> <cmt> addition of the apk call is required for pip to actually build and of the dependencies for locust. </cmt> <cmt> removal of docker_start portion is based on comments by mbeacom. technically this makes the base image unusable without a consumer </cmt> <cmt> adding their own dockerfile with a copy/add call or another entrypoint. </cmt> <cmt> add py37 environment to tox and travis.yml </cmt>,official docker image and documentation v2
3382,"<desc> only position is not enough to decide where to show custom view, fixes #1500. </desc> <cmt> docs: pass bounds in clicked event of tray </cmt> <cmt> win: mouse position is not notify icon's position </cmt> <cmt> pass bounds in clicked event of tray </cmt> <iss> get tray icon position </iss>","pass bounds instead of position in ""clicked"" event of ""tray"""
3383,<desc> previously rustdoc would render this struct declaration: pub struct foo<const n: usize = 10>; as: pub struct foo<const n: usize>; this pr changes it to render correctly </desc> <cmt> rustdoc- show defaults on const generics </cmt> <cmt> add test </cmt>,display defaults on const params- rustdoc
3384,<desc> i hereby agree to the terms of the cla available at:  detailed description / documentation draft: #12508 (comment) </desc> <cmt> issues-4006 fix race condition in integeration test </cmt> <cmt> issues-4006 try fix bad integration test </cmt>,issues-4006 try fix materialize mysql database integration test
3385,<desc> this pr tweaks our inference logic to only check type parameter constraints in the final phase of type argument inference (and specifically not in the phase where contextually sensitive arguments are excluded). checks prior to the final phase otherwise can cause inferences to become fixed when constraints are self-referential. fixes #29520. </desc> <cmt> only check constraints after type argument inference is complete </cmt> <cmt> accept new baselines </cmt> <cmt> add regression test </cmt> <cmt> accept new baselines </cmt> <iss> arrow functions treated differently than functions and methods </iss>,only check constraints in final phase of type inference
3386,"<desc> namedtemporaryfile files can't be reopened on windows. but as nobody knows how windows filesystems work also just skip the test. we are using the 64 byte api so it should work. cleaned up version of gh-4927 </desc> <cmt> bug: avoid namedtemporaryfile for large file test </cmt> <cmt> namedtemporaryfile files can't be reopened on windows. </cmt> <cmt> tst: skip large file test on windows </cmt> <cmt> nobody knows if it supports sparse filesystems, so just skip it. </cmt>",use tempdir for large file
3387,"<desc> moving the new connection pool to its final destination. no code changes. this is a copied file with include fix-ups, and two changed comments (removing the ""move this code"" todo and adding the ""fix void*"" todo promised in #11689) risk level: low (code move) testing: n/a docs changes: n/a release notes: n/a </desc> <cmt> move </cmt> <cmt> fixing move todo </cmt>",cleaning up a file move todo
3388,<desc> introduces a new superset update_api_docs cli command to regenerate docs/src/resources/openapi.json based on the current openapi spec for the /api/v1 namespace. test plan ensure the superset update_api_docs command runs successfully validate the docs render the /docs/rest-api page correctly requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> update_api_docs cli command for regenerating openapi.json </cmt> <cmt> fix /api/v1/async_events spec </cmt> <cmt> regenerate openapi.json (docs) </cmt>,script to generate api docs (openapi.json)
3389,"<desc> i'd like to expose ports commonly used by etcd in the etcd docker image. it does not affect kubernetes in any way but it would make it more convenient to use the image for other purposes, outside of kubernetes. i also merged the two copy lines to reduce the number of layers. </desc> <cmt> expose old and new etcd client and server ports </cmt> <cmt> merge copy lines in etcd dockerfile </cmt>",expose commonly used ports in the etcd image
3390,"<desc> add a new locator path element ""condition"" to represent condition expression of if expression and ternary operator. while generating constraints switch to use if as a anchor for conditional expression conversion to bool. use contextual mismatch diagnostics we already have for while, guard etc. to diagnose if/ternary conditional mismatches. resolves: rdar://problem/56559847 </desc> <cmt> [constraintsystem] add a new ""condition"" locator path element </cmt> <cmt> ""condition"" path element is used to represent a condition expression </cmt> <cmt> associated with if expression or ternary operator ? :. </cmt> <cmt> locator has been changed in the way that it's now anchored from if </cmt> <cmt> itself which simplifies down to condition expression it needed. </cmt> <cmt> [constraintsystem] use new condition element in constraint generation/diagnostics </cmt> <cmt> [diagnostics] nfc: adjust all of the improved if/ternary test-cases </cmt>",improve if/ternary condition expression diagnostics
3391,<desc> fixes #5644 add postgres to optional reqs add postgres fields mapping tests add importable hstorefield ensure hstorefield accepts null values by default </desc> <cmt> test postgres field mapping </cmt> <cmt> add hstorefield </cmt> <cmt> ensure 'hstorefield' child is a 'charfield' </cmt> <cmt> add hstorefield docs </cmt>,"add hstorefield, postgres fields tests"
3392,"<desc> removing stl headers from the filamesh reader. not sure that the jsbindings were amended correctly. also still has <functional> from the cstring header using it for std::hash specialisation, maybe that could be moved to another header to be included only by internal source files, as std::hash should only be used by stl headers anyway? (i think). </desc> <cmt> removed stl headers from filameshio/meshreader.h modified the samples to work the same, and made an effort to remedy the jsbindings although i'm not experienced with them. </cmt> <cmt> fixed assignment operators for materialregistry </cmt>",removing stl headers from filameshio
3393,"<desc> now it looks something like this: in redmond 2000: i thin'k now it looks pretty neat :) closes #1987 </desc> <cmt> libgui: paint texteditor background same as widget's if it's not enabled </cmt> <cmt> now texteditor draws it's background as a colour that does not make the </cmt> <cmt> user think it can be writed into. this also affects textbox. </cmt> <cmt> filemanager: disable propertiesdialog custom rename disabling logic </cmt> <cmt> textbox already handles well its disabled state so it's no use to have a </cmt> <cmt> way to prevent it from propertiesdialog, too. </cmt> <iss> libgui: texteditor+textbox don't respect is_enabled(). </iss>",improve painting and managing of disabled widgets: checkbox & textbox
3394,<desc> cherry-pick of xds interop tests: make header/path matching fail properly failover test based on lrs regex path matching test more header matcher tests present/range/regex increase path and header matching timeout case insensitive path matching </desc> <cmt> xds testing: make header matching and path matching fail properly </cmt> <cmt> xds testing: add failover test based on load </cmt> <cmt> xds testing: add regex path matching test </cmt>,cherry-pick of xds interop tests to v1.35.x
3395,"<desc> fixes #17239 code is well-documented: to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change modified:   cmake/modules/findnccl.cmake tested with following command cmake -gninja -duse_cuda=on -dcmake_cuda_compiler_launcher=ccache -dcmake_c_compiler_launcher=ccache -dcmake_cxx_compiler_launcher=ccache -dcmake_build_type=release -duse_cudnn=on -duse_nccl=on .. without this branch, it failed with nccl not found could not find nccl (missing: nccl_include_dirs nccl_libraries) cmake warning at cmakelists.txt:636 (message): could not find nccl libraries with this pr, it passes. </desc> <cmt> update findnccl.cmake </cmt> <cmt> if cuda root dir is not specified, search for the symlinked unix default </cmt> <cmt> update findnccl.cmake </cmt> <cmt> fix the cmake variable name </cmt> <cmt> findcudatoolkit exposes result variables (cmake variables). use those. </cmt> <cmt>  </cmt> <cmt> search for library in /usr/local/cuda </cmt> <cmt> comment if </cmt> <iss> cmake with nccl flag does not work. </iss>",fix nccl cmake autodetect issue
3396,"<desc> fixing some issues found by using @mui/styled-engine-sc directly in the @mui/system. inspired by #29036. the changes from #29036 are also included here. the purpose is to battle test how well the integration with styled-components is really working. fixes #28905 fixes #27167 list of problems found: ts is broken - all styled-component's utils should be compatible with mui's styled() if @mui/styled-engine-sc is used issues found:  unstyled demos are broken - fixed by b7807f3 created #29048 cssbaseline is broken tests failing. false alarm, it was because the styles were tested with jsdom. everything is fine when using browser, so i just disabled jsdom for them: 75e92d7 styled() tests are broken -  the issues (not blocking) that i could not resolve are:  rtl fixtures are broken - fixed by 22afcab one is still broke - it is related to styled-components/stylis-plugin-rtl#22. it was fixed by styled-components/stylis-plugin-rtl#21, but styled-components v5 is not compatible with the v2 of the plugin, so nothing we can do about it at this point. </desc> <cmt> [styled-engine] extract types for styled() </cmt> <cmt> [styled-engine-sc] fix mixins, styled options, normalize style args </cmt> <cmt> [mui-material] export css & keyframes </cmt> <cmt> small fix </cmt> <cmt> revert me: test ci using @mui/styled-engine-sc </cmt> <iss> `css` helper from `styled-engine-sc` produces incompatible type. </iss> <iss> [v5] no documented way of importing css or keyframes for styled-components </iss>",fix various issues reported by using @mui/styled-engine-sc
3397,"<desc> this is a big refactor of win_find that does; moves towards the ansible.basic wrapper for better option validation and module invocation reporting streamlined the file information collection to only get the metadata of each file once and not multiple times try to optimise the checks that occur against each file to improve performance the return values are more closely aligned to win_stat with the ultimate goal to share that information in 1 location. in terms of performance here is the difference when running the following task - win_find: paths: c:\windows\system32 recurse: yes patterns: '*.exe' get_checksum: no # devel play [2019] ********************************************************************************************* task [win_find] ***************************************************************************************** ok: [2019] play recap ********************************************************************************************** 2019                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 real    1m3.178s user    0m3.918s sys     0m0.272s # win_find-perf play [2019] ******************************************************************************************************************************************************************************************************* task [win_find] *************************************************************************************************************************************************************************************************** ok: [2019] play recap ******************************************************************************************************************************************************************************************************** 2019                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 real    0m9.127s user    0m1.565s sys     0m0.126s that's a saving of around 1 minute for scanning *.exe in the system32 directory. nothing will ever match the raw performance you can get with get-childitem or some other binary due to the overhead added by powershell itself and the extra information that we collect then serialize. fixes #42696 - win_find vs find behaviour fixes #50569 - performance, path types and win_find vs find behaviour fixes #56712 - performance (somewhat) fixes #63018 - performance supersedes #53148 win_find </desc> <cmt> win_find - refactor to make more performance and use newer style </cmt> <cmt> win_find - refactor for performance improvements and alignment to find </cmt> <cmt> more path alignment to find </cmt> <iss> module win_find fails tasks and stops play on non-existing directories </iss> <iss> win_find: exits if it can't access a file and will crash if the path it hits has ps centric wildcard characters </iss> <iss> win_find partially unknown folder performance (2.4.2->2.8.0 regression) </iss> <iss> improve win_find performance </iss>",win_find - refactor for better performance and alignment to find
3398,"<desc> summary see #11665 in this pr, batch_dot uses tf.matmul to avoid memory allocation that happens when doing an elem-wise multiplication, if enough shape information is available. if required shape information is not available, we fall back to old elem-wise mul+tf.reduce_sum based implementation. pr overview </desc> <cmt> add matmul impl for batch_dot </cmt> <cmt> no shape info tests </cmt> <cmt> pep8 </cmt>",fix memory issue in tensorflow backend's batch_dot
3399,"<desc> cherry pick of #78958 #79966 #81390 #81489 on release-1.14. #78958: update to go 1.12.6 #79966: update to go 1.12.7 #81390: update to go 1.12.8 #81489: update go to 1.12.9 update to use go 1.12.9 </desc> <cmt> update to go 1.12.6 </cmt> <cmt> update to go 1.12.7 </cmt> <cmt> update to go 1.12.8 </cmt> <cmt> fix up failing boilerplate test </cmt> <cmt> fix malformed port in vsphere cloud provider test </cmt> <cmt> the port name previously didn't matter on these tests, but is now </cmt> <cmt> actively being checked in go1.12.8 and higher. </cmt> <cmt>  </cmt> <cmt> update go to 1.12.9 </cmt>",update release-1.14 to go 1.12.9
3400,<desc> adds the feature requested in #10440 ability to fetch a menu items by passing in menuitems and an id. called like: const fsc = menu.getmenuitembyid('fullscreen'); </desc> <cmt> add first pass at getmenuitembyid </cmt> <cmt> conform to linter standard </cmt>,add getmenuitembyid to menu api
3401,"<desc> if deleteonexithook is in the open state and the program runs for a long time, the deleteonexithook file keeps increasing. this results in a cause memory leak see #10351 i re-customized a deleteonexithook hook. if deleteonexithook is turned on, this hook will be added when creating a temporary file. after the request ends and the corresponding resources are released, the current file will be removed from this hook, so that it will not increase all the time. fixes #10351. </desc> <cmt> fix </cmt> <cmt> fix </cmt> <cmt> fix </cmt>",fix deleteonexithook cause memory leak
3402,<desc> added programs for displaying adjacency matrix and adjacency list for a graph whose inputs we get from user in python </desc> <cmt> add files via upload </cmt> <cmt> update adj list.py </cmt> <cmt> update adj mat.py </cmt>,added programs for displaying adjacency matrix and adjacency list in python
3403,"<desc> this removes the auto redirect on the report user page for people that aren't signed in. before: after: there was also a tiny bit of margin on this page causing the horizontal scroll bar to show up that i removed... i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. </desc> <cmt> fix: dont auto redirect after reporting a user </cmt> <cmt> fix(client): remove annoying redirect on report user page </cmt> <cmt> fix: remove unused code </cmt>",remove auto redirect on report user page
3404,"<desc> i implemented m300 before i realized it was already done, oops! but of course i didn't use interrupts so ddrboxman's is better. but s0 should be silent, so i fixed that. define custom_mendel_name makes it easier to change the printer name as it appears in the lcd ""mendel ready."" message. added code to support up to 10 levels of depth in the sd folder hierarchy. english spelling and grammar corrections here and there. </desc> <cmt> added custom_mendel_name option to configuration.h and language.h </cmt> <cmt> also cosmetic comment changes and spelling corrections in printed </cmt> <cmt> messages </cmt> <cmt> make m303 silent when ""s0"" is sent </cmt> <cmt> if s is left out perhaps it should be silent, but check the spec for </cmt> <cmt> this m code. </cmt>","m300 bug, custom_mendel_name, sd dir depth, grammar"
3405,"<desc> this closes probtorch#87. math checked and approved by @fritzo cc: @apaszke </desc> <cmt> init f distribution </cmt> <cmt> rename f to fishersnedecor, add tests and docs </cmt> <cmt> remove other samplers, fix shape error and add new kl for dirichlet </cmt> <cmt> update entropy function in fisher-snedecor </cmt> <cmt> add comment regarding f-distribution entropy test </cmt> <cmt> remove entropy and revert changes in kl.py </cmt> <iss> implement f-distribution </iss>",implementation of the fisher-snedecor distribution
3406,"<desc> #19800 (comment) - i investigated the performance issues with test_basic_3.py::test_worker_startup_count. i traced the slow code and figured out that this block is the most consuming one in each worker. for example, if one worker consumes ~4s then this block contributes the maximum towards these ~4s. rest, i will confirm the specific slow line right after the meeting. so, it seems like the issue is with the usage of sleep_for. the documentation says, it blocks the execution for at least the time duration specified. so, we are passing 10 microseconds, that means it would be at least 10 microseconds and it can be more than that too. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> initial support for absl::bitgen </cmt> <cmt> unskipped tests </cmt> <cmt> applied linting </cmt>",replace time based seed generation with absl::bitgen and absl::uniform
3407,"<desc> #1966, #1939 add a timeout-handle to stop the auto restart. </desc> <cmt> add a new props :""proc.pm2_env.restart_task"" to solve the problem : ""process still restart after it be stop or delete."" </cmt> <cmt> fix the ""restart_task"" enumerable problem. </cmt>","""process still restart after it has be stop or delete"""
3408,"<desc> we produced a new split keyboard. and these are keymap and config about this keyboard. we want to add it to qmk configurator. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> add files via upload </cmt>",[keyboard]add new split keyboard: momoka ergo
3409,"<desc> smart open is stateless, so we should pass the session directly. otherwise, it will create a new connection with s3 whenever it spills/restores objects (which caused 100% cpu issue). this indicates the smart open impl is just for s3 now. #13757 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> in progress. </cmt> <cmt> formatting. </cmt> <cmt> formatting. </cmt>",share the same s3 session for smart_open spilling.
3410,<desc> fatal notifications created during package load/activation/etc. now contain additional package name metadata for use in the notifications package. required for atom/notifications#100. / </desc> <cmt> include package name metadata when creating errors </cmt> <cmt> add specs </cmt>,add package name metadata for load errors
3411,"<desc> this removes a bunch of dead code from sentry.utils.javascript that i encountered when i was researching where we are going to need to support environment parameters for tsdb, and the code that was only used by code that was deleted (and so on.) </desc> <cmt> delete groups/public_details.html template. </cmt> <cmt> this was (presumably) replaced by the sharedgroupdetailsendpoint et al. </cmt> <cmt> the last reference to this file was removed with </cmt> <cmt> 559fc2c9c834a69cf675cfd1cb60e834c8c60b85. </cmt> <cmt> remove users/details.html template. </cmt> <cmt> the last reference to this file was with </cmt> <cmt> 3d815aed3a0ea259e82f317a4fc7582ee426f4b8. </cmt> <cmt> remove handle_before_events template tag. </cmt> <cmt> remove unused transformer abstraction and related code. </cmt> <cmt> remove {event,group}.has_two_part_message. </cmt> <cmt> this isn't used in our supported plugins at all, which is the only </cmt> <cmt> reason i could think that it'd be around other than referenced in a file </cmt> <cmt> deleted in this patch. </cmt> <cmt> remove unused events_per_page constant. </cmt> <cmt> remove sentry_activity template tag library. </cmt>",delete assorted dead and orphaned code
3412,<desc> change all #include s60*** to #include qmk_keyboard_h add info.json for both default and rgb edit layout to remove that extra key on zxcv row propogate above changes to keymap.c files </desc> <cmt> change to qmk_keyboard_h </cmt> <cmt> add info.json for qmk configurator support </cmt>,qmk configurator support for sentraq s60-x
3413,"<desc> just cooked this up on the flight san diego - toronto ;-) extracts scripts logic into a script helper scripts now accept variables to be passed in when turned on via service. automation: add a trigger variable that is available to templates when processing action part. automation: allow using script sequence syntax for action alexa: allow script syntax for action and expose intent slots as variables script - breaking: no longer allow config delay workaround by @jaharkes because it confused the code. (now using config validation to convert all to timedeltas) automation: trigger: platform: mqtt topic: some/notify/topic action: service: notify.notify data_template: message: {{ trigger.payload }} automation 2: trigger: platform: state entity_id: light.hue action: service: notify.notify data_template: message: {{ trigger.to_state.name }} is now {{ trigger.to_state.state }} available trigger data per platform: 'trigger': { 'platform': 'event', 'event': event, } 'trigger': { 'platform': 'mqtt', 'topic': msg_topic, 'payload': msg_payload, 'qos': qos, } 'trigger': { 'platform': 'numeric_state', 'entity_id': entity_id, 'below': below, 'above': above, 'from_state': from_state, 'from_value': from_value, 'to_state': to_state, 'to_value': to_value, } 'trigger': { 'platform': 'state', 'entity_id': entity, 'from_state': from_s, 'to_state': to_s, 'for': time_delta, } 'trigger': { 'platform': 'sun', 'event': event, 'offset': offset, } 'trigger': { 'platform': 'template', 'entity_id': entity_id, 'from_state': from_s, 'to_state': to_s, } 'trigger': { 'platform': 'time', 'now': now, } 'trigger': { 'platform': 'zone', 'entity_id': entity, 'from_state': from_s, 'to_state': to_s, 'zone': zone_state, } </desc> <cmt> allow variables in service.call_from_config </cmt> <cmt> alexa: expose intent variables to service calls </cmt> <cmt> automation: add trigger context and expose to action </cmt>",trigger variables in automation actions
3414,"<desc> you can already implement this today with a stateful callable class, but it can be more intuitive to write a function instead. @michaelzhiluo you might want to try this out for your maml implementation. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> update </cmt> <cmt> debug </cmt> <cmt> doc </cmt>",add .transform() function for arbitrary generator transforms
3415,"<desc> i am changing how escape keys works in listwidget. currently, the focus gets trapped inside the component when an escape key is pressed. my proposed change unselects all the items on first escape (current logic) and then it lets the default behavior take over. </desc> <cmt> updating forked vscode 11/16/20 </cmt> <cmt> fixing how escape key works in listwidget </cmt>",fixing listwidget escape button behavior
3416,<desc> description: some fixes to huawei lte device tracker. related issue (if applicable): fixes #29354 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> include mac address in device state attributes for absent devices too </cmt> <cmt> use mac address as default name whether device is connected or not </cmt> <cmt> fix initialization of known entities </cmt> <cmt> closes </cmt> <iss> huawei_lte device_tracker unavailable after reboot </iss>,huawei lte device tracker fixes
3417,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add types for package 'fluxible' </cmt> <cmt> add fluxible router types </cmt> <cmt> fix tests </cmt> <cmt> fixed annotation </cmt> <cmt> add missing types </cmt> <cmt> # conflicts: </cmt> <cmt> #	types/fluxible-router/index.d.ts </cmt> <cmt> #	types/fluxible/index.d.ts </cmt>",add missing types and functions to fluxible
3418,<desc> this pr closes #528 and we can improve ui/ux should the need arise. </desc> <cmt> added tabbar button for listing files uploaded to room. </cmt> <cmt> using (other) local collection for sync </cmt> <cmt> adding limit to publication. </cmt>,including tab for listing room uploaded files
3419,"<desc> fixes #19103. this is similar to #19105 and what was discussed in the comments, except that it covers another case (anonymous volumes with permissions) which wasn't covered in the original discussion. this seems to work fine, and doesn't seem to restart existing containers - except if the user specified volumes: strict (or implicitly via wildcard) in comparisons. therefore, i think this pr should not be backported to stable-2.9. docker_container </desc> <cmt> simplify code. </cmt> <cmt> only pass anonymous volumes. </cmt> <iss> docker_container sends volume to docker api erroneously </iss>",pass volumes only for anonymous volumes
3420,<desc> related #7159 </desc> <cmt> add videocapture / videowriter avfoundation implementation for mac </cmt> <cmt> add support for cap_prop_mode </cmt> <cmt> support setting cap_prop_mode to capture grayscale or yuv frames much </cmt> <cmt> faster from cv_cap_avfoundation_mac. </cmt> <cmt> fix buffer release issue </cmt> <cmt> cvvideowriter_avfoundation_mac had a serious buffer release bug. </cmt> <cmt> also made writeframe() block until isreadyformoremediadata rather than </cmt> <cmt> return an error. </cmt> <cmt> videoio: refactor avfoundation code integration </cmt>,updated pr #7159 (osx avfoundation support)
3421,"<desc> remove simplejson. remove utf encoding guessing, which the built-in module handles now. simplify htmlsafe_dumps to use str.translate instead of multiple str.replace. issue deprecation warning if encoding is passed to dumps, dump, loads, or load. this was deprecated in the built-in module back in 3.1. the only valid encodings for json are utf-8 (with/without bom), utf-16 (be/le), and utf-32 (be/le). json.loads accepts bytes and json.loads accepts binary files in these encodings without any special handling on our part. dumps can be encoded after calling, and dump can be passed a binary file wrapped with io.textiowrapper. rewrite docs for consistency. fix imports and references of markup to be from markupsafe instead of flask or jinja. see the individual commits for easier diffs. closes #3555 </desc> <cmt> remove simplejson </cmt> <cmt> - remove encoding detection backport, json.loads supports it directly </cmt> <cmt> - use str.translate instead of multiple str.replace </cmt> <cmt> deprecate json encoding options </cmt> <cmt> make consistent with built-in json module </cmt> <iss> remove simplejson </iss>",remove simplejson and deprecate encoding options
3422,"<desc> lldb builds a python module in the form of a c shared library.  this is used in some swift tests. since python module format changed between python 2 and python 3, these tests must be run with the same python version that was used when lldb built it. of course, in a system with multiple python versions installed, this may or may not be the same version used by the rest of the swift build. this adds some logic to lit.cfg to figure out the version of python used by lldb and expose that as %{lldb-python} for use in tests that need to access the lldb module. </desc> <cmt> use the correct python executable to match lldb </cmt> <cmt> the linux-fatal-backtrace script needs to run with an lldb </cmt> <cmt> module loaded into python.  this in turn requires that the </cmt> <cmt> test be run with the exact same python version as was used </cmt> <cmt> by lldb (not just the same python module directory).  this </cmt> <cmt> can get confused on systems with multiple versions of python </cmt> <cmt> installed. </cmt> <cmt> this replaces lldb-python-path (the python module directory path) </cmt> <cmt> with lldb-python (which is the correct python version run with </cmt> <cmt> the lldb path).  this should ensure that this test is always </cmt> <cmt> run with the same python version and module that lldb used. </cmt> <cmt> use consistent braces for the lldb-python substitution </cmt>",use correct python version for lldb-related tests
3423,"<desc> closes #6231 we're collecting more environment variables when running cypress with gitlab ci. one of my projects required this to correctly create a commit url. i'm not able to debug this on the cypress dashboard, however, i suspect that the commit link for gitlab may be incorrect. </desc> <cmt> #6231 use more ci information from gitlab </cmt> <cmt> issue-6231 fix spec provider tests </cmt> <iss> missing ci information from gitlab </iss>",issue 6231 use more information from gitlab
3424,"<desc> this pr introduces a script that automates creating a release source archive and handles some licensing issues by removing some files that were identified to be non-compliant, and introducing a apache rat license check in the source generation process to ensure all apache mxnet code is compliant. </desc> <cmt> fix command for running rat check in v1.x branch. </cmt> <cmt> add script for creating source archives. </cmt>",create tool for building source archives
3425,"<desc> before this change, pressing enter in firefox 55 would insert a line break into the description field and then save it. this change prevents the line break from being inserted before saving. there's no change to chrome's behaviour from this change. </desc> <cmt> update redirected link in readme </cmt> <cmt> remove magic numbers from editinplace() </cmt> <cmt> this makes it a lot easier to read and figure out what's going on. </cmt> <cmt> use event.preventdefault() on editinplace textarea </cmt> <cmt> before this change, pressing enter in firefox 55 would insert a line </cmt> <cmt> break into the description field and then save it. </cmt> <cmt> this change prevents the line break from being inserted before saving. </cmt> <cmt> there's no change to chrome's behaviour from this change. </cmt>",prevent line breaks in editinplace description when using firefox
3426,<desc> i hereby agree to the terms of the cla available at:  fix wrong thread estimation for right subquery join in some cases. close #24075 </desc> <cmt> fix max parallel stream for joined pipeline </cmt> <cmt> add tests/performance/join_max_streams.xml </cmt> <iss> version 21.6 is much slower than 21.4 </iss>,fix max parallel streams for joined pipelines
3427,<cmt> bpo-30455: generate tokens related c code and docs from token.py. </cmt> <cmt> generate regexpes from exact_token_types. </cmt> <cmt> fix generating the documentation. </cmt> <cmt> add shebangs and executable bits. </cmt> <cmt> add generated file parser/token_names.h. </cmt> <cmt> misc other fixes and enhancements. </cmt> <cmt> move symbol.py generating code into a separate file. </cmt> <cmt> fix dependencies for pgen. </cmt> <cmt> add a hack for '<>'. </cmt> <cmt> make _pyparser_tokennames a const array. </cmt> <cmt> fix tests. </cmt> <cmt> remove async and await. </cmt> <cmt> generate all token related files from grammar/tokens. </cmt>,generate all token related code and docs from grammar/tokens.
3428,"<desc> currently only support one overall gauge and i still need to test it, but it should be good for initial review. </desc> <cmt> add c# stress test client </cmt> <cmt> add metrics.proto generated files to c# project </cmt> <cmt> add generated proto files </cmt>",initial draft of c# stress test client
3429,"<desc> addresses this issue #3575 run logs from this branch -> </desc> <cmt> supress wandb images size mismatch warning </cmt> <cmt> supress wandb images size mismatch warning </cmt> <iss> warning: ""images sizes do not match"" when w&b logging enabled </iss>",suppress wandb images size mismatch warning
3430,"<desc> this is a preliminary patch to add chamber heat pid control. it introduces a new m309 command for adjusting the pid of the chamber (e.g. ""m309 p37.04 i1.04 d655.17"") and also expands m303 to support auto-tuning pid for an index of -2 to accommodate the chamber heater_id (e.g. ""m303 e-2 c5 s42"") this does not yet add an entry to the onboard printer menu to adjust the pid, as i was in a hurry to get my print running again (now that my temps are stable!), but i will continue adding that support after my current run when i have somewhere to test on again. mostly, i wanted to get this merge request started, in case there are any objections to my just inventing an m309 command for this, and if you guys had a better approach you'd prefer to see here. also, currently using pidtempchamber will preclude the use of chamber_fan and chamber_vent as the previous implementation of those features relies on a check every x ms loop that interferes with pid operation. again, this will also be resolved shortly, but with only one printer it's hard to use and develop on it at the same time. required heated chamber wired in a manner that is safe/sane to use with pwm. my build is a lasko ""myheat"" 100, with a fotek ssr-10da wired between the voltage source and the heating element. the heater fan is wired to run constantly when the printer is powered to avoid heat-soaking the ceramic element under partial current conditions. chamber heat pid control. this is currently operating as expected on a skr 1.4 turbo using my config as archived in my primary git fork here:  resolves: #16316 </desc> <cmt> chamber pid control, basic support. </cmt>",pid for chamber (resolves feature request #16316)
3431,<desc> quick fix to change this nightly test to install pip packages using pre-release. a different task should add coverage for other packages later. </desc> <cmt> enable test for pip-mkl </cmt> <cmt> add --pre flag to test pre-releases </cmt> <cmt> merge </cmt> <cmt> fix conflicts </cmt>,test installation of pip --pre
3432,<desc> this pr is based on #4445 please do not review it before #4445 is merged. this pr is part of #4076 </desc> <cmt> split registry to separate classes </cmt> <cmt> fixes for windows build </cmt> <cmt> reorganized includes to improve compile time (pr#4076 for reference) </cmt> <cmt> # conflicts: </cmt> <cmt> #	include/osquery/registry_interface.h </cmt> <cmt> #	osquery/registry/registry_interface.cpp </cmt> <cmt> fixed code generation </cmt> <cmt> reorganized includes to improve compile time (pr#4076 for reference) </cmt> <cmt> fixed tests </cmt> <cmt> fixed tests + removed some includes </cmt>,reorganized includes to improve compile time 2
3433,<desc> description: this implements the transparency feature for google calendars. if for example an all-day event is present but it is set to 'free' ha now skips those events and shows the next. this can be turned on/off per calendar. ignore_availablilty is optional and defaults to false. it enables/disables whether to respect/ignore the transparency tag which can be opaque (busy) or transparent (free). related issue (if applicable): fixes #6076 (only partial) pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#5101 example entry for configuration.yaml (if applicable): - cal_id: calendar@googlemail.com entities: - device_id: calendar name: calendar track: true ignore_availablilty: true checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> remove len call. </cmt> <cmt> add transparency feature for google calendars. </cmt> <cmt> remove double default value assignment. </cmt> <cmt> change keyword to be more explicit. </cmt> <iss> google calendar - all-day events block scheduled events that day from being displayed </iss>,add option to ignore availability in google calendar events
3434,"<desc> in urllib3/urllib3#186 i proposed to add a .stream() generator to the urllib3 response object. this avoids some of the nasty problems with the .read() method on that object (apparent zero-sized reads when there's still data, all sorts of stuff). it's also a much more natural way to stream data. this pr would update urllib3 to include that pr, and updates our streaming methods to use it where possible. @michaelhelmick: do you want to try this branch with your twitter issue? use one-byte chunk sizes. </desc> <cmt> update urllib3 to cffbd6b317 </cmt> <cmt> use the new urllib3 stream generator. </cmt>",use new urllib3 'stream' parameter.
3435,<desc> before a maximum 25 of channels was able to be displayed in the teams' channels list. 2021-04-21.15-37-22.mp4 fixes #21707 related to this bug already merged #21518 </desc> <cmt> updating the code </cmt> <cmt> updating the code </cmt> <cmt> updating the fork </cmt> <cmt> update main branch </cmt> <cmt> updating the branch </cmt> <cmt> update fork </cmt> <cmt> upating the fork </cmt> <cmt> updating fork </cmt> <cmt> updating fork </cmt> <cmt> updating fork </cmt> <cmt> correcting the channel list for teams </cmt> <iss> maximum 25 channels can be displayed in the teams' channels list </iss>,maximum 25 channels can be loaded in the teams' channels list
3436,"<desc> the short version: this pr implements the currentcolor identifier, which acts somewhat like a pointer to the color property. it's useful for say, setting an underline to always match the text color, and it's the initial-value for several properties. making it actually work exposed a few bugs in other things, so this also fixes: ""0"" failing to parse as a css number several incorrect initial values in properties.json and i made a few places use the generated property_initial_value() function instead of hard-coding things. it's not perfect. for example, border: 2px solid; correctly uses the default of currentcolor, but border-width: 2px; border-style: solid; doesn't. but i couldn't figure out why, and that's an edge case, and i've been on enough tangents with this, so i'm leaving it for now. :^) </desc> <cmt> libweb: make stylevalue::to_color() take a node instead of the document </cmt> <cmt> this is in preparation for the currentcolor value, which needs to know </cmt> <cmt> what node it's on so it can check the color. </cmt> <cmt> libweb: implement currentcolor special value </cmt> <cmt> the currentcolor identifier represents the current value of the </cmt> <cmt> color property. this is the default value for border-color and </cmt> <cmt> text-decoration-color, and is generally useful to have. :^) </cmt> <cmt> libweb: persuade css parser that idents like currentcolor are colors </cmt> <cmt> shorthand properties were only checking for colorstylevalues, which </cmt> <cmt> excludes identifier colors. now they accept them too, including the </cmt> <cmt> various -libweb-foo colors. :^) </cmt> <cmt> libweb: make ""currentcolor"" lowercase in properties.json </cmt> <cmt> it's technically case-insensitive, but the spec always defines it as </cmt> <cmt> ""currentcolor"" so it feels wrong to capitalise it differently there. </cmt> <cmt> libweb: stop treating eof as a valid part of an identifier </cmt> <cmt> this was specifically causing the string ""0"" to be parsed as an invalid </cmt> <cmt> dimension token with no units, instead of as a number. that then caused </cmt> <cmt> out generated property_initial_value() function to fail for those </cmt> <cmt> values. </cmt> <cmt> libweb: generate shorthand initial values after their longhands </cmt> <cmt> when parsing shorthand values, we'd like to use </cmt> <cmt> property_initial_value() to get their longhand property values, </cmt> <cmt> instead of hard-coding them as we currently do. that involves </cmt> <cmt> recursively calling that function while the initial_values map is </cmt> <cmt> being initialized, which causes problems because the shorthands appear </cmt> <cmt> alphabetically before their longhand components, so the longhands aren't </cmt> <cmt> initialized yet! </cmt> <cmt> the solution here is to perform 2 passes when generating the code, </cmt> <cmt> outputting properties without ""longhands"" first, and the rest after. </cmt> <cmt> this could potentially cause issues when shorthands have multiple </cmt> <cmt> levels, in particular border -> border-color -> border-left-color. </cmt> <cmt> but, we do not currently define a default value for border, and </cmt> <cmt> border-color takes only a single value, so it's fine for now. :^) </cmt> <cmt> libweb: add some more css identifiers </cmt> <cmt> these are used by the ""initial"" values in properties.json </cmt> <cmt> libweb: correct some initial values and add missing ones </cmt> <cmt> - the text-decoration-foo values now match the spec. </cmt> <cmt> - added values for border-foo since those are needed soon. </cmt> <cmt> - make color's initial value be -libweb-palette-base-text. </cmt> <cmt> libweb: use initial values from properties.json inside css parser </cmt> <cmt> this replaces several hard-coded initial values, with use of </cmt> <cmt> property_initial_value(). </cmt> <cmt> libweb: replace hard-coded defaults in node::apply_style() </cmt> <cmt> this now uses the values in initialvalues, which is not ideal, but </cmt> <cmt> it's better to have our defaults defined in two places, than in 3. </cmt> <cmt> the default for border-colors is currentcolor, so we shortcut that </cmt> <cmt> here and just grab the value of the color property. as noted, this is </cmt> <cmt> not perfect, but it's somewhat better. </cmt>","implement the currentcolor css special value, with bonus yaks"
3437,"<desc> closes #19653 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff </desc> <cmt> clarified fill_value parameter in arithmetic ops </cmt> <cmt> add fill_value change to df </cmt> <cmt> add fill_value example to df </cmt> <iss> doc: clarifiy fill_value behavior in arithmetic ops </iss>",clarify and add fill_value example in arithmetic ops
3438,"<desc> ipv4interface and ipv6interface did not has netmask and hostmask attributes when its argument is bytes or int. this commit extracts method for constructors of network and interface, and ensure interface class always provides them. </desc> <cmt> bpo-36392: ipaddress: add test for missing attributes </cmt> <cmt> network class did not have .netmask and .hostmask </cmt> <cmt> attributes on some cases. </cmt> <cmt> bpo-36392: add missing attributes to network </cmt>",ipaddress: fix interface missed some attributes
3439,"<desc> wip if there are other parts of the api that break please respond to this issue with the package and the api it relies on. editorview scrollview outlet is missing. geteditor getfirstvisiblescreenrow getfontfamily getfontsize getlastvisiblescreenrow getpagerows ignoring this method, i couldn't find it used anywhere getpane highlightfoldscontainingbufferrange (could probably be removed from the api but it needs to be replaced in selectionview) isscreenrowvisible  (could probably be removed from the api) pagedown pageup pixelpositionforbufferposition pixelpositionforscreenposition redraw scrolltobottom scrolltobufferposition scrolltocursorposition scrolltopixelposition scrolltoscreenposition setfontfamily setfontsize setinvisibles (i think we could ignore this one, its not used and can be set via config) setlineheight setplaceholdertext (this is only used by mini-editors and we are going to wait on implementing it) setshowindentguide setshowinvisibles setsoftwrap splitdown splitleft splitright splitup togglesofttabs togglesoftwrap based on feedback from @abe33 and @smashwilson and anything i've run into personally. closes #2428 </desc> <cmt> add append shim </cmt> <cmt> add overlayer shim </cmt> <iss> missing api on reacteditorview </iss>",add shims to the react view editor
3440,<desc> ci: lgplv2+ify dependapot config and codeql action ci: tighten codeql and labeler even more by moving the read permissions to the top level and granting additional permissions to the specific jobs. it should help to prevent new jobs that could be added there eventually from having write access to resources they most likely would never need. @mrc0mmand could you take a look? </desc> <cmt> ci: lgplv2+ify dependapot config and codeql action </cmt> <cmt> ci: tighten codeql and labeler even more </cmt> <cmt> by moving the read permissions to the top level and </cmt> <cmt> granting additional permissions to the specific jobs. </cmt> <cmt> it should help to prevent new jobs that could be added </cmt> <cmt> there eventually from having write access to resources they </cmt> <cmt> most likely would never need. </cmt>,lgplv2+ify dependapot config and codeql action and tighten codeql and labeler even more
3441,<desc> cherry pick of #65882 #65986 #65985 #66076 on release-1.11. #65882: add script to verify generated files #65986: verify-generated-files: ensure git tree is clean #65985: re-add pkg/generated/bindata.go #66076: don't delete pkg/generated/bindata.go in make clean re-adds pkg/generated/bindata.go to the repository to allow some parts of k8s.io/kubernetes to be go-vendorable. fixes #65968. </desc> <cmt> add script to verify generated files </cmt> <cmt> verify-generated-files: ensure git tree is clean </cmt> <cmt> don't gitignore pkg/generated/bindata.go </cmt> <cmt> generate pkg/generated/bindata.go for release-1.11 </cmt>,add script to verify generated files #65986: verify-generated-files: ensure git tree is clean #65985: don't gitignore pkg/generated/bindata.go
3442,"<desc> http3-idle-timeout works exactly like http2-idle-timeout, with the exception that it applies to http/3. note that the default is 30 seconds, as we do not expect nat entries to survive longer than that. </desc> <cmt> add knob for tuning idle timeout </cmt> <cmt> test h3 server idle timeout and client reconnecting </cmt>",add knob to configure h3-idle-timeout
3443,<desc> this fixes 2 crashes on windows. originally part of  #5279 </desc> <cmt> use port::aligned_free() to free allocations from port::aligned_alloc(). </cmt> <cmt> this was resulting in memory corruptions on windows. </cmt> <cmt> windows doesn't use ld_library_path so don't print it. </cmt> <cmt> it was actually crashing instead of printing the error message since getenv() returns null. </cmt>,fixes a memory corruption on windows/gpu
3444,"<desc> we've been slowly improving batch support in clusterservice so service won't need to implement this tricky logic themselves. these good changes are blessed but our logging infra didn't catch up and we now log things like: depending on the source string this can get quite ugly (mostly in the zendiscovery area). this pr adds some infra to improve logging, keeping the non-batched task the same. as result the above line looks like: zendiscovery waiting on join moved from: as a bonus, i removed all zen-disco prefixes to sources from that area. </desc> <cmt> wip </cmt> <cmt> improve and apply to all batchers </cmt> <cmt> line length </cmt>",improve logging for batched cluster state updates
3445,"<desc> fix a bunch of things on et_rel elf: when a section symbol is found, get the name of the section, instead of just print empty stuff like readelf does do not print warning messages (e.g. no program headers, no dyn segment, etc.) when the type is et_rel, because it's a regular thing for that kind of files to not have those things fix relocation patching for type r_x86_64_plt32 (there are still some weird stuff there, wrt to that fake .got.r2 section) </desc> <cmt> get the section name for section/local elf symbols </cmt> <cmt> do not print warning messages if elf is et_rel </cmt> <cmt> in that case, it's a normal thing that dynamic sections and program </cmt> <cmt> headers are not present. </cmt> <cmt> fix the address of the fake plt table </cmt>",fix relocations in et_rel elf
3446,"<desc> string normalizer is found in the following frameworks: stopwordsremovertransform in ml.net countervectorizer/tfidfvectorizer in scikit-learn stringnormalization performs string operations for basic cleaning. this operator has only one input (denoted by x) and only one output (denoted by y). this operator first examines the elements in the x, and remove elements specified in ""stopwords"" attribute. note that an implementation should sequentially remove ""stopwords[0],"" then ""stopwords[1],"" and so on. after removing stop words, the intermediate result can be further lowercased, uppercased, or just returned depending the ""casechangeaction"" attribute. </desc> <cmt> add stringnormalizer </cmt> <cmt> update typeandshapeinference function. </cmt> <cmt> add test output, coverage and docs. </cmt> <cmt> add two dim test, add data. adjust numpy_helper for multi-dim </cmt> <cmt> string array. </cmt> <cmt> update docs </cmt>",add stringnormalizer operator to onnx
3447,"<desc> fixes #1093 allow function wrapping methods like ensureasync, that internally use initialparams, to have a context bound to the function they have wrapped. this allows something like this to work: var async = require('async'); var foo = function(one) { console.log(this); }; foo = async.ensureasync(foo); foo = foo.bind({bar: true}); foo(); // prints {bar: true} </desc> <cmt> explicitly bind 'this', curried by lodash's rest method, to the wrapped method before invoking </cmt> <cmt> add unit test for context curring when using initialparams </cmt> <cmt> update initialparams import to match project style </cmt>",bind context to functions wrapped by initialparams
3448,"<desc> with extremely long queries, share query link would break as it exceeds maximal number of characters permitted in a url solution: adding a new key-value store model for us to store text associated with ids store query string in key-value store, use id in search params in url make asynchronous call to get query string after tabbedsqleditors is mounted added tests needs-review @ascott @mistercrunch @bkyryliuk </desc> <cmt> add keyvalue model for storing id-value pairs </cmt> <cmt> use it for storing shared queries </cmt> <cmt> change string to text and added test </cmt> <cmt> put getquerylink in one place </cmt>",use a key-value store model for sharing long queries
3449,<desc> updates to dart sdk 1.22.0-dev.5.0 migrates flutter analysis code to new analyzer apis works around analyzer futureor type resolution problem (dart-lang/sdk#28285) note that we'll want to time landing this w/ @cbracken's updates to the coverage package.  fyi: @cbracken </desc> <cmt> bump dart sdk to 1.22.0-dev.5.0. </cmt> <cmt> suppress spurious futureor type warning. </cmt> <cmt> # conflicts: </cmt> <cmt> #	packages/flutter_tools/pubspec.yaml </cmt> <cmt> fixed linter dep post merge. </cmt>,bump to dart sdk 1.22.0-dev.5.0
3450,"<desc> add marks property to text per documentation at  add return type to editor.withoutsaving and editor.withoutmerging per  add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).   if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add marks property missing from text </cmt> <cmt> add return type to editor.withoutsaving and editor.withoutmerging per </cmt> <cmt>  </cmt> <cmt> lint fixes </cmt> <cmt> tests </cmt> <cmt> formatting </cmt>",update definitions for slate - text and editor
3451,"<desc> we took care of an unnecessary loop that was occurring when an overlay was present in #15894. however, resizes of the overlay were still taking longer than needed because they were invoking .updatesync on the text editor component. in this pr, we take the approach of only updating the dimensions of the overlay element and invoking a render on just the overlay component when a resize occurs. the amount of time spent in the overlay observer callback is greatly reduced which means less time spent scripting on keystrokes. this is important because any scripting that occurs as a result of a new keystroke needs to finish well ahead of the next keystroke to avoid holding up its handling. in the above image, the time spent in the resize observer callback is reduced from 2.36ms to 0.32ms, and the time to handle this frame goes from 11.75ms down to 9.10ms. / </desc> <cmt> update overlay itself instead of text editor when resize occurs </cmt> <cmt> fix failing test </cmt>",only update overlay instead of text editor when resize occurs
3452,<desc> #18077 - reuse c-api int8 unit test application #18111 - unify fp32 vs. int8 comparison tests output </desc> <cmt> unify fp32 vs. int8 comparison tests output (#18111) </cmt> <cmt> test=release/1.5 </cmt> <cmt> reuse c-api int8 unit test application (#18077) </cmt> <cmt> test=release/1.5 </cmt>,cherry pick or  #18077 and  #18111
3453,"<desc> resolves #45210 in this pull request we introduce the ensure query/function. ensure has the semantics and type of the function q1 below: fn q1::ensure(k){ q(k); } further, ensure avoids the need to load the result from disk (or execute the provider, if we are not storing the results of q to disk). @nikomatsakis </desc> <cmt> implement query ensure </cmt> <cmt> $query::ensure() guarantees that one of two things is true after it returns: </cmt> <cmt> - the query has all green inputs. </cmt> <cmt> - the query has been executed. </cmt> <cmt> and counts as a read from the source query </cmt> <cmt> ensure typeck_tables_of from typck_item_bodies </cmt> <cmt> this should make typecktables lazier. </cmt>",introduce ensure and ensure typeck_tables_of
3454,"<desc> fixes ""should call the provided event handlers when respective events are fired:"" in react 18 (  the problem was that updates are only flushed when exiting the outermost act call. so in concurrent react act(() => { updatea(); act(() => { updateb(); }); // updateb assertions }) the updateb assertions would not match all updates. so we should either avoid the nested act() or move the assertions outside of any act call (generally good advise unless you know what you're doing and then you should explain the intention in code comments). i also noticed that the test was basically repeating the same mistakes as our enzyme tests: dispatching mocked events. the problem is that they not only not really test anything meaningful but also are brittle because you need to know what fields react needs. we can just dispatch synthetic dom events which decouples the event dispatching from react entirely (e.g. no need to know that nativeevent is a thing in react's synthetic events) and properly ensures integration of the component under test. general advise: don't try to write as little as possible in tests. optimize for readability (in tests even more than you should already be doing) and isolation (i.e. how well can i reason about this test while ignoring all the other code in the test file?). the rest of the changes are type related changes that avoid type casting (apart from the non-null assertion which is dangerous because it's not true in nested act calls). </desc> <cmt> revert later run with react 18 </cmt> <cmt> [test] use dom events instead of synthetic, partial events </cmt>","use dom events instead of mocked, partial events"
3455,"<desc> this pr modifies essinglenodetestcase and esintegtestcase and several concrete test classes to use node names when bootstrapping the cluster. today clusterbootstrapservice.initial_master_node_count_setting setting is used to bootstrap clusters in tests. instead, we want to use clusterbootrstapservice.initial_master_nodes_setting and get rid of the former setting eventually. there were two main problems when refactoring internaltestcluster: nodes are created one-by-one in buildnode method. and node.name is created in this method as well. it's not suitable for bootstrapping, because we need to have the names of all master eligible nodes in advance, before creating the node with bootstrapping configuration set. we address this issue by separating buildnode into two methods: getnodesettings and buildnode. we first iterate over all nodes to get nodes settings, then change the setting for the bootstrapping node and then proceed with building the node. if automanageminmasternodes = false, there is no way for the test to set the list of bootstrapping nodes because node names are not known in advance. this problem is solved by adding updatenodessettings method to nodeconfigurationsource and esintegtestcase (which could be overridden by concrete integration test class) . once we have the list of settings for all nodes, the integration test class is allowed to update it. in our case, we update the clusterbootrstapservice.initial_master_nodes_setting setting. </desc> <cmt> essinglenodetestcase fix </cmt> <cmt> esintegtestcase fix </cmt> <cmt> fix tests that use autominmasternodes = false </cmt>",change unsafe bootstrap nodes count to nodes list in tests
3456,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> types for the datatables.net scroller extension </cmt> <cmt> reformatted for dtslint </cmt> <cmt> neu erstellt mit dts-gen </cmt> <cmt> another dtslint fix. </cmt>",types for datatables.net scroller extension
3457,"<desc> this change enables portions of the ingest consumer to be run concurrently. in particular, this allows saving the event to the processing store to be performed concurrently, while other operations remain on the main thread, avoiding thread safety concerns or introducing new connections to shared resources (i.e. postgres.) the motivation for this change is due to the move to bigtable, as set operations against the bigtable storage are marginally slower than the redis storage by roughly 25%. since this is such a frequently hit path, those serially executed blocking operations back up, limiting overall throughput without increasing the consumer count. testing shadow operations with a small thread pool (4 threads per consumer) enabled the bigtable storage to maintain similar quality of service to the existing redis backend. other details of note: individual messages are no longer guaranteed to be processed in fifo order. batches as a whole are still guaranteed to be processed in fifo order, and the committed offset still moves monotonically. the threadpoolexecutor is not backed by a bounded queue, but the queue is implicitly bounded by the batch size and/or time by virtue of being used with the batching consumer. even though the queue has some upper bound, it is still possible that this could lead to the memory required to hold all of the in-flight messages leading to an oom condition (these objects were previously eligible for garbage collection much more frequently since only one message was processed at a time), particularly since the callback itself contains references to large objects. (this backlog should not accumulate to the extent of what we were previously seeing with consumer ooms due to the secondary backend backing up prior to getsentry/getsentry#5545.) </desc> <cmt> support returning future from processing functions </cmt> <cmt> add return value annotation to processing functions </cmt> <cmt> annotate ""other messages"" </cmt> <cmt> add optional executor for event processing </cmt> <cmt> changes to control flow to enable concurrent event storage </cmt> <cmt> support asynchronous work in consumer </cmt> <cmt> add async process path </cmt> <cmt> callback return value is ignored so don't overspecify </cmt> <cmt> enable in tests </cmt> <cmt> add back to cli </cmt> <cmt> handle early return </cmt> <cmt> misc cleanup </cmt>",enable concurrent execution of event processing store insertion
3458,"<desc> same as pull request #1050. this facilitates playbook decision-making that are package manager based.  it also allows simple package installation across distributions in a single statement: -name: install wget action: $ansible_pkg_mgr name=wget state=present now implemented with a list of dicts to identify the package manager in use. </desc> <cmt> add pkg_mgr fact to setup </cmt> <cmt> this should help facilitate playbook decision making that are not </cmt> <cmt> strictly distribution specific, but more package manager. </cmt> <cmt> update package manager fact innards to a list of dicts </cmt>",add pkg_mgr fact to setup (take 2)
3459,"<desc> i encounter the same problem as #1800 when using infinite loop with slidespergroup, some slides will repeat if the number of slides doesn't fit the group. for example, if there are 10 slides with following settings: slidesperview: 4, slidespergroup: 4, loop: true, it becomes: page 1: 1, 2, 3, 4 page 2: 5, 6, 7, 8 page 3: 9, 10, 1, 2 page 1: 1, 2, 3, 4 1 and 2 are repeated in page 3. thus, this pr adds the feature to fit the last page with blank slide(s) when the new parameter fitslidegroupwithblank is set to true. then page 3 will become: 9, 10, (empty), (empty) </desc> <cmt> add blank slides </cmt> <cmt> add demo .html </cmt>",add blank slides to fit slides per group
3460,"<desc> trt 5.1.2 added new functions to itensor. we have to define them for simpleitensor to prevent compiler errors. according to trt team, users are not meant to inherit from itensor, so we should modify our code at some point to avoid having these issues every time the definition changes. </desc> <cmt> fix itensor virtual functions for 5.1.2+ </cmt> <cmt> remove unnecesarry checks </cmt>",override new 5.1.2 itensor pure virtual functions
3461,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation the toast presenter is missing from the welcome app, so toasts are never displayed. i noticed this while investigating another problem. i also improved the error message when the dashboard endpoint returns a 401. now: test plan tested locally. requires db migration. confirm db migration upgrade and downgrade tested. reviewers @khtruong @nytai </desc> <cmt> add toast presenter </cmt> <cmt> improve message when unauthenticated </cmt> <cmt> lint </cmt>",add toast presenter to welcome app
3462,"<desc> this pr improves type inference for multiple object literals occurring in the same context. when multiple object literal types contribute to a union type, we now normalize the object literal types such that all properties are present in each constituent of the union type. for example: const obj = test ? { text: ""hello"" } : {};  // { text: string } | { text?: undefined } const s = obj.text;  // string | undefined previously we inferred type {} for obj and the second line subsequently caused an error because obj would appear to have no properties. that obviously wasn't ideal. the key insight behind this pr is that for object literal types we know that unspecified properties always have the value undefined. this is unlike regular object types where unspecified properties might have any value. based on this fact we implement the following new rules: when checking a type relationship between a source type s and a target type t, if t is an object literal type, any excess properties in s are required to have type undefined (normally such excess properties are permitted to have any type). when widening a union type, we normalize all constituent types originating in object literals by adding optional properties of type undefined to each constituent as appropriate such that all constituents have the same set of property names. when inferring multiple object literal types for a type parameter, the object literal types are normalized into a single inferred union type. an example of object literal normalization: // let obj: { a: number, b: number } | //     { a: string, b?: undefined } | //     { a?: undefined, b?: undefined } let obj = [{ a: 1, b: 2 }, { a: ""abc"" }, {}][0]; obj.a;  // string | number | undefined obj.b;  // number | undefined nested object literals are likewise normalized: // let obj: { kind: string, pos: { x: number, y: number, a?: undefined, b?: undefined } } | //     { kind: string, pos: { a: string, x?: undefined, y?: undefined, b?: undefined } | { b: number, x?: undefined, y?: undefined, a?: undefined } } let obj = [{ kind: 'a', pos: { x: 0, y: 0 } }, { kind: 'b', pos: test ? { a: ""x"" } : { b: 0 } }][0]; obj.kind;   // string obj.pos;    // { x: number, y: number, a?: undefined, b?: undefined } | { a: string, x?: undefined, y?: undefined, b?: undefined } | { b: number, x?: undefined, y?: undefined, a?: undefined } obj.pos.x;  // number | undefined obj.pos.y;  // number | undefined obj.pos.a;  // string | undefined obj.pos.b;  // number | undefined multiple object literal type inferences for the same type parameter are collapsed into a single normalized union type: declare function f<t>(...items: t[]): t; // let obj: { a: number, b: number } | //     { a: string, b?: undefined } | //     { a?: undefined, b?: undefined } let obj = f({ a: 1, b: 2 }, { a: ""abc"" }, {}); obj.a;  // string | number | undefined obj.b;  // number | undefined fixes #19236. </desc> <cmt> missing properties in fresh object literals are known to be undefined </cmt> <cmt> normalize object literals in widened union types </cmt> <cmt> normalize nested object literals </cmt> <cmt> use a single union type for all inferred object literal types </cmt> <cmt> accept api changes </cmt> <cmt> accept new baselines </cmt> <cmt> ensure void return in foreachtype </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt> <cmt> add missing semicolon </cmt>",improved type inference for object literals
3463,"<desc> the ruby dsl for defining a protobuf schema has always been implemented in c. originally this was necessary, because upb could not consume descriptors directly. however for several years now the ultimate output of the dsl is just a protobuf (filedescriptorproto), so the dsl could just as easily be implemented in ruby. this pr removes 1,352 lines of code from c and reimplements them as ~400 lines of ruby. this will have the following benefits: reduces our overall c footprint, reducing the chance of sigsegv bugs (such as #8842 which is a recent segv crash bug in the dsl). reduces our overall line count and maintenance burden. makes it possible to share the dsl code between mri and jruby. it is possible that this pr will have some amount of performance regression in the startup time required to load generated foo_pb.rb files, since the dsl is evaluated using ruby instead of c. however, the dsl was already calling back and forth between c and ruby a lot, so hopefully the impact will not be too large. in any case, there are ways of mitigating this if it becomes an issue (see below). this change requires us to add a new method descriptorpool#add_serialized_file, which allows for defining messages using a serialized descriptor proto instead of the dsl. this is necessary to bootstrap google/protobuf/descriptor_pb.rb, which cannot use the dsl as these protos are used to implement the dsl. future directions in the future we may want to change the code generator to use descriptorpool#add_serialized_file for all generated files, instead of the dsl. this would have the following benefits: performance: loading from a serialized descriptor will avoid the cpu cost of evaluating the dsl. for large schemas with many proto files, this could have a noticeable impact on app startup time. correctness/completeness: as we continue to implement missing features in ruby protobuf, particularly custom options, the dsl will become more and more of a hindrance. custom options have some very difficult edge cases that would be nearly impossible to accommodate in the dsl unless we resort to serialized descriptors at some level. using binary descriptors avoids all of this complication. there are various options for how we could keep the generated code readable, even if we move to binary descriptors. for example, we could do something like: if false # code for ides and human readers. class foomessage attr_accessor :bar_field, attr_accessor :baz_field end else # code that is actually executed, implements semantics equivalent to the above. google::protobuf::descriptorpool.generated_pool.add_serialized_file(""<unreadable binary data>"") foomessage = google::protobuf::descriptorpool.generated_pool.lookup(""foomessage"").msgclass end since this will require some input and dialogue about what is the best fit for the ruby community, i'm leaving this out of the current pr. the dsl will continue to be available no matter what, since we've exposed it already as a public api. </desc> <cmt> some preliminary work towards a ruby builder. </cmt> <cmt> pure-ruby dsl is passing all tests! </cmt> <cmt> put the raw descriptor data after __end__ in the ruby source. </cmt>",move dsl implementation from c to pure ruby
3464,"<desc> this is a follow up to #18561 it adds more test cases and includes a fix to safari since safari adds another stack frame for the construct call. polyfills might do something similar so this tries to be resilient by skipping over those. results from fixtures at lazy at component ( at div at suspense at babelclasswithfields ( at babelclass ( at frozenclass ( at nativeclass ( at suspenselist at custom name ( at errorboundary ( at example ( firefox: lazy component@ div suspense babelclasswithfields@ babelclass@ frozenclass@ nativeclass@ suspenselist displayname@ errorboundary@ example@ note: firefox doesn't respect displayname in stack traces. safari: lazy component@ div suspense babelclasswithfields@ babelclass@ frozenclass@ nativeclass suspenselist custom name@ errorboundary example@ note: safari doesn't give us a line number for native classes without an explicit constructor. </desc> <cmt> add more edge cases to fixture </cmt> <cmt> also adjust some expectations. i think the column should ideally be 1 but varies. </cmt> <cmt> the example row is one line off because it throws on the hook but should ideally be the component. </cmt> <cmt> similarly class components with constructors may have the line in the constructor. </cmt> <cmt> account for the construct call taking a stack frame </cmt> <cmt> we do this by first searching for the first different frame, then find </cmt> <cmt> the same frames and then find the first different frame again. </cmt>",fix component stacks for ie and native classes in safari
3465,"<desc> mainly opening this pr to get a full ci run before merging, as it's mostly a port of #27386 to the 6.x branch. the changes to versionutils#resolvereleasedversions() and associated tests deserve attention, and ultimately backporting to 6.0 too. i'd wait for ci to pass before looking at this too hard. </desc> <cmt> prepare for bump to 6.0.1 on the 6.0 branch (#27386) </cmt> <cmt> an attempt to bump to 6.0.1 on the 6.0 branch exposed up a handful of issues that this commit fixes. one of those fixes is a terrible hack that will be fixed more thoroughly in #27397, and another is a back port of d5e56c55553291682932d7e9e8dc7068f59e618b which is related to #27251. </cmt> <cmt> bump version to 6.0.1 </cmt> <cmt> remove big horrible hack </cmt> <cmt> version.current.minimumcompatibilityversion() is now version.v_5_6_0 anyway. </cmt> <cmt> fix assertion message </cmt> <cmt> the preceding line modifies versions so versions.get(versions.size() - 1) </cmt> <cmt> no longer contains the highest version. </cmt> <cmt> rewrite the guts of versionutils.resolvereleasedversions() </cmt> <cmt> the policy for which version constants are unreleased changed at 5.6 - we now </cmt> <cmt> plan to keep an unreleased 'marker' version at the end of each minor branch, </cmt> <cmt> whereas prior to 5.6 the unreleased marker version was removed during the </cmt> <cmt> version bumping. </cmt> <cmt> this commit simplifies the logic a bit and also makes it clear which bits can </cmt> <cmt> be removed once 5.x versions are no longer relevant. </cmt> <cmt> orly </cmt> <cmt> improve comments </cmt>",bump version to 6.0.1 on the 6.x branch
3466,"<desc> adds the offset field to the indexsymbol struct. this lets code using swift::index functions skip any line/column -> offset reverse calculation if the specific byte offset location is desired. </desc> <cmt> make swift indexing code capture symbol start/end offset within the current source file. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> make symbol info only store symbol occurrence offset, not start/end offset. the rest can be determined from the source manager by finding the token's sourceloc. </cmt> <cmt> merge remote-tracking branch 'apple/master' </cmt> <cmt> remove unnecessary lexer.h include. </cmt>",store symbol byte offset in indexsymbol
3467,"<desc> this removes most uses of fgets() from our codebase, replacing them with read_line(), which is a lot more careful with overly long lines. </desc> <cmt> clock-util: excorcise fgets() </cmt> <cmt> terminal-util: excorcise fgets() </cmt> <cmt> terminal-util: use fgetc() carefully instead of fread() </cmt> <cmt> binfmt: validate rule file name before using it </cmt> <cmt> binfmt: fgets() excorcism </cmt> <cmt> also, let's not claim we ignored errors when we don't. </cmt> <cmt> cgtop: fgets() excorcism </cmt> <cmt> cryptsetup-generator: fgets() excorcism </cmt> <cmt> catalog: fgets() excorcism </cmt> <cmt> hwdb: fgets() excorcism </cmt> <cmt> keymap-util: fgets() excorcism </cmt> <cmt> modules-load: fgets() excorcism </cmt> <cmt> reply-password: fgets() excorcism </cmt> <cmt> condition: fgets() excorcism </cmt> <cmt> udev-rules: fgets() excorcism </cmt>",let's get rid of fgets()
3468,<desc> netdata-installer.sh: improve message about updater installation packaging/installer/functions.sh: get_crondir fails if crondir is not found packaging/installer/functions.sh: mark get_crondir and check_crondir_permissions functions as private component name netdata-installer.sh some follow-up corrections to netdata-installer.sh based on review comments in #7060 </desc> <cmt> netdata-installer.sh: improve message about updater installation </cmt> <cmt> packaging/installer/functions.sh: get_crondir() fails if crondir is not found </cmt> <cmt> packaging/installer/functions.sh: mark get_crondir and check_crondir_permissions functions as private </cmt>,netdata-installer.sh follow-up based on #7060 review
3469,"<desc> somewhat ironically, bind_to_port isn't currently flagged as deprecated but use_original_dst was, so manually extended its lifetime per discussion on #5355. it wasn't clear to me if the tcp_proxy deprecated_v1 fields were also part of #5355 so tagging piotr as a reviewer. i'll envoy-announce once we've nailed down the fields and gotten approval from all. risk level: high (first time using this process - it will likely cause problems for someone) testing: tests pass. docs changes: n/a release notes: should we relnote these?  they're already in deprecated.md </desc> <cmt> release: flipping deprecated features to be fatal-by-default </cmt> <cmt> manually reverting fields from #5355 </cmt>",flipping deprecated features to fatal-by-default
3470,"<desc> after reading a bunch of changelogs, this upgrades pytest and friends to a good set of versions for increased harmony with the upcoming django 2.2 and python 3.8. not too well-versed in pytest, but most of the few new features over these versions didn't seem really interesting to me. mostly bugfixes and improvements. after pytest 6+ we're able to consolidate configuration into pyproject.toml which is preferable, i went ahead and did that and also cleaned up some old configuration that doesn't apply / isn't useful anymore. --strict-markers is good. i also tried to use the new --import-mode=importlib but that became a todo. i'll follow up with fixing all the warnings and then forbidding warnings with some filters, there's a lot. (there has been a lot even before this.) </desc> <cmt> upgrade pytest and friends to good versions, consolidate configuration into pyproject.toml </cmt> <cmt> this marker isn't being used </cmt> <cmt> add todo about --import-mode=importlib </cmt>","upgrade pytest and friends, cleanup configuration"
3471,<desc> leaving the pad or the invalid_entry aba_ctr uninitialized causes valgrind to complain since part of the atm read is still uninitialized. possibly consider doing this under ndebug? </desc> <cmt> stop upsetting valgrind with uninitialized shorts </cmt> <cmt> add explicit comments about purpose of writing to pad </cmt>,write to dummy pads and invalid entries in lock-free stack to prevent valgrind complaints
3472,"<desc> issue: #10799 update mdx compiler to support .bind() idiom (split into #11198) addon-controls examples for angular, ember, html, svelte, vue, web-components minor cleanup see updated snapshots </desc> <cmt> mdx: support function.bind({}) syntax </cmt> <cmt> addon-controls: update readme with .bind({}) idiom </cmt> <cmt> addon-controls: angular example </cmt> <cmt> addon-controls: ember example </cmt> <cmt> ember-cli cleanup </cmt> <cmt> addon-controls: html example </cmt> <cmt> official-storybook: use bind idiom for args mdx </cmt> <cmt> addon-controls: svelte example </cmt> <cmt> addon-controls: vue example </cmt> <cmt> addon-controls: vue mdx example </cmt> <cmt> addon-controls: web-components example </cmt> <cmt> argstable stories cleanup </cmt>","add examples to angular, ember, html, svelte, vue, web-components"
3473,<desc> cherrypicked from commit (3fdc4ba) backport for pr #56292 ios </desc> <cmt> to fix ios static route ci failure (#56292) </cmt> <cmt> * ios static failure </cmt> <cmt> * fix ci failure </cmt> <cmt> (cherry picked from commit 3fdc4ba6b4d4ad28e9bdb21d2019975e520e265a) </cmt> <cmt> adding bp changelog </cmt>,backport pr for fixing ios static route tc ci failure
3474,"<desc> commit message:add transport failure reason to body additional description: adds transport failure reason to response body . this is specially useful to detect tls related failures when the client does not use envoy. otherwise cert expiration related errors just come as connection failure and it takes some digging to figure out the reason. risk level: low, but changes the existing response body. testing: updated docs changes: n/a release notes: updated </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> correct test case </cmt> <cmt> add release notes </cmt> <cmt> correct version history </cmt>",add transport failure reason to response body
3475,"<desc> modified app.now to correctly return the  timezone-aware current date/time, according to the configured timezone or utc. added unit tests for the changed/added methods. optimize tests by reducing wait time for some test cases due to default polling interval value. fixes #3753. </desc> <cmt> fix wrong task eta when using timezone setting </cmt> <cmt> optimization: reduce polling interval in test cases </cmt> <cmt> test cases for app.now, app.uses_utc_timezone </cmt>",fix task eta issues when timezone is defined in configuration
3476,<desc> small fixes in the readme conform to the current version of the boilerplate. updated jquery to version 3.1.1 and updated some dependencies to their latest versions. </desc> <cmt> fixed small grammar error </cmt> <cmt> replaced .jade with .pug </cmt> <cmt> small changes conform to the current version of the app </cmt> <cmt> small changes conform to the current version of the app </cmt> <cmt> updated jquery to version 3.1.1 </cmt> <cmt> updated jquery to version 3.1.1 </cmt> <cmt> updated some dependencies </cmt>,update readme conform to current version & other small updates
3477,"<desc> closes: #1196 closes: #5085 closes: #2759 closes: #11710 closes: #5252 closes: #4735 closes: #5086 this commit allows servers admins to set which ldap groups they want to synchronize with rocket user roles. automatically assign ldap groups to rocket.chat roles admins can choose to automatically remove users from a role if their ldap group is removed. role automatically added role automatically removed example setting the new ""user data group map"" to the following will allow users in ldap under the group ""rocket-admins"" to be assigned the rocket.chat ""admin"" role. { ""rocket-admin"": ""admin"", ""devops"": ""devops"" } here's what the group looks like: automatically add / remove users in channels based on ldap groups for a preview, see: #14278 (comment) tested and working with openldap. </desc> <cmt> init commit of ldap user role / group synchronization </cmt> <cmt> * 'develop' of </cmt> <cmt> regression: active room was not being marked (#14276) </cmt> <cmt> rename cloud to connectivity services & split apps in apps and marketplace (#14211) </cmt> <cmt> lingohub based on develop (#14178) </cmt> <cmt> [improve] replace livechat inquiry dialog with preview room (#13986) </cmt> <cmt> bump version to 0.74.3 </cmt> <cmt> room loading improvements (#13471) </cmt> <cmt> [fix] invalid condition on getting next livechat agent over rest api endpoint (#13360) </cmt> <cmt> [improve] open rooms quicker (#13417) </cmt> <cmt> [fix] ""test desktop notifications"" not triggering a notification (#13457) </cmt> <cmt> [fix] translated and incorrect i18n variables (#13463) </cmt> <cmt> regression: remove console.log on email translations (#13456) </cmt> <cmt> [fix] properly escape custom emoji names for pattern matching (#13408) </cmt> <cmt> [fix] not translated emails (#13452) </cmt> <cmt> added missing package dependency (#13437) </cmt> <cmt> update russian localization (#13244) </cmt> <cmt> [improve] allow configure prometheus port per process via env var (#13436) </cmt> <cmt> [improve] add api option ""permissionsrequired"" (#13430) </cmt> <cmt> [fix] several problems on hipchat importer (#13336) </cmt> <cmt> add the missing uniqueid to the push notifications (#13423) </cmt> <cmt> [fix] notify private settings changes even on public settings changed (#13369) </cmt> <cmt> ... </cmt> <iss> admins from ldap group </iss> <iss> room/channel/group membership based on ldap group membership </iss> <iss> ldap put users in different permission roles based on group </iss> <iss> ldap - add ability to map ldap groups to roles </iss> <iss> ldap - add ability to configure an ""auto join"" for users with a specific group </iss> <iss> mapping user in channels based on ldap groups? </iss> <iss> automatically add to channel or private room through ldap filters </iss>","ldap user groups, roles, and channel synchronization"
3478,"<desc> fixes #16958 alternative to and closes #16963 alternative to and closes #17219 same as #17219 , but raises a warning when a check is skipped. </desc> <cmt> ignore xfail_checks in check_estimator </cmt> <cmt> avoid ignoring in parametrize... </cmt> <cmt> raise warning </cmt> <iss> xfail_checks tag only works with parametrize_with_checks </iss>","mnt ignore xfail_checks tag in check_estimator, with warning"
3479,<desc> this is a followup for #6206 as @jarfa is afk for 2 weeks. i has already been reviewed there. i just want to make sure that the changes i made to address my last comment do not break ci. </desc> <cmt> much faster isotonic regression prediction (involved re-setting interpolation to linear) </cmt> <cmt> change to test_isotonic_regression_ties_min </cmt>,fix isotonic performance issue at prediction time
3480,"<desc> db intrinsics are ""keyed"" off of scope, table, and a primary key.  this is how all objects are stored.  it also allows for a secondary key for each type. in chainbase, the secondary keys are ordered by the order of that secondary key, and then by the order of the primary key that is stored with it. db_key_value_format is a class designed to provide the formatting for creating composite keys to store in rocksdb for primary and secondary keys. unit tests verify key construction and deconstruction, ordering and error handling. also, threw in an empty place holder for db_context_rocksdb.cpp. select one </desc> <cmt> all composite key construction and destruction working. </cmt> <cmt> fixed key256_t and float*_t and cleaned up debug statements. </cmt> <cmt> fixed types after rebasing off integration branch. </cmt> <cmt> fixing more type issues after rebasing to integration branch. </cmt> <cmt> fixed tests for new extra primary key. </cmt>",rocksdb composite key construction for db intrinsic primary and secondary keys
3481,<desc> i hereby agree to the terms of the cla available at:  fixed very rare deadlock at shutdown detailed description / documentation draft: fixes #18891. </desc> <cmt> revert previous fix </cmt> <cmt> fix rare deadlock on shutdown of backgroundschedulepool </cmt> <iss> clickhouse-local cannot shutdown correctly. </iss>,fix rare deadlock at shutdown of backgroundschedulepool
3482,"<desc> as mentioned in the bpo, there are some instances where notimplemented is used when notimplementederror was meant to be. this is the example i found after running rg -e notimplemented[^e] doc/, all other usages looked correct. i have updated the doc/library/winreg.rst file, and then noticed that the clinic comments for pc/winreg.c were also incorrect. i updated these and ran python3 tools/clinic/clinic.py pc/winreg.c to generate the new output. this is my first time fixing the docs here so if i have missed a step </desc> <cmt> fixed wrong use of notimplemented, should be notimplementederror </cmt> <cmt> updated the clinic input in winreg.c and ran clini on it </cmt>",fix usage of notimplemented instead of notimplementederror in docs
3483,<desc> collects latency & count measurements on get and list operations to gce cloud. release note: </desc> <cmt> add metric capture on gets </cmt> <cmt> undo capture of list clusters </cmt> <cmt> add missing underscore </cmt> <cmt> missed a file </cmt>,collect latency metric on get/list calls
3484,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> added new valid cookie option for client-sessions </cmt> <cmt> modified test case for change in index file </cmt> <cmt> new valid option for cookie in @types/client-sessiosn </cmt>,added valid option for cookie in @types/client-sessions
3485,"<desc> #927 - fixes this issue. tested in ie10 and ie11. bug was due to me blindly following an out-of-date mozilla dev guide:  #1131 - fixes this issue. bug was due to autoplay being detected on load, but if the option was changed during the lifetime of the slider then the tab-switch never checked this and would carry on with whatever the initial value was at initialization. now it will check the autoplay option every time the page changes visiblity. </desc> <cmt> fix ie10/11 visibility bug </cmt> <cmt> fixes #1131 - need to check autoplay during event, in case it was changed during lifetime </cmt>",page visibility fixes for 2 bugs.
3486,"<desc> #111 with limit by clause you can select only n elements from each chosen group. for example, if you have table t like this (num: 1 1 3 3 3 4 4 5 7 7 7 7), the query select num from t limit 2 by num will give you the following result: (num: 1 1 3 3 4 4 5 7 7) </desc> <cmt> style of constructor init list </cmt> <cmt> parse limit by [#metr-23881] </cmt> <cmt> ignore qt-creator file </cmt> <cmt> first dirty implementation of limit by clause [#metr-23881] </cmt> <cmt> clone and format limit_by asts [#metr-23881] </cmt> <cmt> getaliasorcolumnname instead of getcolumnname [#metr-23881] </cmt> <cmt> organize code [#metr-23881] </cmt> <cmt> disable some optimization related to limit clause if limit by clause is present [#metr-23881] </cmt>",limit by clause was implemented
3487,<desc> we're skipping build script checks for these libraries temporarily until we make a decision on dart:io support on the web. reland of rolled back pr due to missing video_player. edit: in turns out i needed to land the refactor of goldens to not rely on platform specific code too ... includes some fixes from #38773 fixes #34858 </desc> <cmt> add comment explaining skip </cmt> <cmt> more specific </cmt> <iss> [web] dartev compile error http module </iss>,update the supported library set for flutter for web
3488,<desc> commit message: adds guidance on envoy_bug per #14190 risk level: low docs changes: updates to style.md part of #14190 todos (part of issue): add macro for internal class invariants </desc> <cmt> draft </cmt> <cmt> fix markdown format </cmt> <cmt> markdown style </cmt> <cmt> fix indent </cmt> <cmt> fix wording </cmt>,add guidance on envoy_bug in style.md
3489,"<desc> @rocketchat/core should close #6902 and #7412 i say should because i have not been able to deploy this remotely and have only tested the rc fixes locally. i was getting several ""this.somefunction is undefined"" errors after enabling the irc plugin via the admin panel in chrome 61. i fixed these context errors by binding this to the functions that were giving the undefined message in the constructor. also, there are several regexp's that were declared such that the functions they were made to trigger were not being triggered. i changed the declarations and now i am seeing messages. </desc> <cmt> bind context so we don't get a call to undefined. </cmt> <cmt> fix bindings. </cmt> <cmt> create regexp's properly. preferring old style over es6 syntax. </cmt> <cmt> try to get a stable docker build working with fix. </cmt> <cmt> revert dockerfile changes. </cmt> <cmt> fix version number. </cmt>",contextual errors for this and regexp declarations in irc module
3490,"<desc> what do these changes do? some points in this pr: (1) shorten the length of jobid to 4 bytes. (2) the job_id is generated by gcs for uniqueness. (3) embed job_id to driver id.  the first 4 bytes of a driver id is the job_id bits, and rest 16bits must be filled with 0xff. refer this doc for more details of id refactor. linter i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> add jobid test </cmt> <cmt> fix </cmt> <cmt> add python part </cmt> <cmt> fix </cmt> <cmt> fix tes </cmt> <cmt> remove todos </cmt> <cmt> fix c++ tests </cmt> <cmt> lint </cmt>",shorten the length of  jobid to 4 bytes
3491,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  #2479  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dslint/dt.json"" }. already there </desc> <cmt> add additional type defs for rsvp </cmt> <cmt> satisfy linting </cmt>",ember - add additional type defs for rsvp namespace
3492,"<desc> fixes #5016. this adds support for importing the same specifier in multiple ways within the same file. for example, a static and dynamic import, or a url import. previously this was not possible because we used the specifier as the key of an object in the dev packager. now, the specifier is replaced with a hash of the original specifier and the import kind. in addition, some bundler bugs were fixed so that assets/dependencies with different bundlebehavior settings are not merged. </desc> <cmt> support for multiple types of dependency with the same specifier in the same file </cmt> <cmt> add bundle behavior to bundle id hash and prevent inline/isolated bundles from being merged </cmt> <cmt> fix bugs with wrapped exported symbols in esm output format </cmt> <cmt> add tests for multiple dep types </cmt> <iss> dynamic import causes static import to resolve to a promise </iss>",support multiple dependency types on the same specifier in the same file
3493,<desc> parameter pool was not getting passed to the base operator it was using default_pool. added it to the options_to_remove list so that it gets passed as it is. </desc> <cmt> update forked repo </cmt> <cmt> update qubole_hook filter do not remove pool as an arg for qubole operator </cmt>,update qubole_hook do not remove pool as an arg for qubole operator
3494,"<desc> a layout with split left shift, vim arrow keys & iso setup. keymap based on macbooks with iso uk/english international keyboard layouts. i also switched around the parameters in the layout_iso macro so that when editing layers, kc_ent is the last key on the second row, and kc_bsls on the third (as one would expect for the iso layout). </desc> <cmt> added iso layout </cmt> <cmt> iso dz60 layout: jkbone </cmt>",iso keymap & layout for dz60
3495,"<desc> this is a cherry-picks of stack of 2 prs: #52349 and #52350 into release/1.8 branch fixed how type casting is handled in mixed precision onnx export. </desc> <cmt> [onnx] update fuselogsoftmaxnllloss function to handle autocasting (#51729) </cmt> <cmt> adds a check for patterns for cases with autocasting enabled in which a cast node is inserted before the negativeloglikelihoodloss </cmt> <cmt> node and causing these patterns below not to be recognizable by peephole pass function </cmt> <cmt> [onnx] update layernorm symbolic to handle autocasting (#52199) </cmt> <cmt> when onnx export creates a 0-dim tensor of constant type, this action overrides the type promotion logic as quoted in #9515. in order to prevent this from happening this pr adds the following functionality. </cmt> <cmt> if the data type is a floating point type, it is converted to a 0-dim double tensor, else it is converted to a 0-dim tensor of its original type </cmt>",fix onnx mixed precision export for layernorm & fuselogsoftmaxnllloss
3496,"<desc> one of the places where we ask whether a type's metadata should be obtained via its mangled name was missing the newer, more robust checking for minimum deployment target. this pr also re-enables a test that was suppose to be enabled after a fix, but was missed. resolves rdar://83104637 </desc> <cmt> [irgen][backdeploy] fix infinite recursion in metadata queries </cmt> <cmt> one of the places where we ask whether a type's metadata should </cmt> <cmt> be obtained via its mangled name was missing the newer, more </cmt> <cmt> robust checking for minimum deployment target. </cmt> <cmt> re-enable test that was mistakenly not re-enabled after being fixed </cmt>",fix infinite recursion in determining the mangling kind for a backdeployed feature.
3497,"<desc> if we set trainer.config[""horizon""] to e.g. 2000 (e.g. cartpole), the env should also use that limit (and not stop after 200 steps). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> fix. </cmt> <cmt> rollback. </cmt> <cmt> wip. </cmt>","if trainer config horizon is provided, should try to increase env steps to that value."
3498,"<desc> this pull request is in support of wtu. i initially added support for a new flag, pseudoconsole_undocked_prefer_inbox_conhost, which i liked because it was more explicit. you can see that approach in commit cae3289. consider this an open discussion. should we automatically fall back? or should we allow a developer to opt for fallback? automatic fallback pros it's easier on the consumer we can eventually expand it to support $arch/openconsole.exe cons packaging the project wrong will result in a working-but-somewhat-broken experience (old conhost) implicit behavior may be bad manual selection pros consumer gets explicit control cons consumer must explicitly opt in. in the case of wtu, that means pushing a configuration down into terminalconnection all the way from terminalapp to say ""use the inbox one, dummy"" </desc> <cmt> winconpty: add prefer_inbox_conhost </cmt> <cmt> this flag makes the out-of-box build of winconpty prefer the inbox </cmt> <cmt> console host (conhost.exe). </cmt> <cmt> squash! winconpty: add prefer_inbox_conhost </cmt>",fall back to conhost if openconsole is missing
3499,<desc> the directory structure for icc's installation had changed so it couldn't find he setvars.sh it needed. i now just reference the compiler path for the latest icc directly which shouldn't change. </desc> <cmt> adding icc to actions </cmt> <cmt> removing icc from travis </cmt>,removing broken icc test from travis and adding working version to actions
3500,"<desc> these changes: add support to identify a number of audio stream types via the descriptor tag in mpegts modify (fix?) the way eac3 sync frame format was parsed the following is the set of descriptor tags used by ffmpeg: static const streamtype desc_types[] = { { 0x6a, avmedia_type_audio,    av_codec_id_ac3          }, /* ac-3 descriptor */ { 0x7a, avmedia_type_audio,    av_codec_id_eac3         }, /* e-ac-3 descriptor */ { 0x7b, avmedia_type_audio,    av_codec_id_dts          }, { 0x56, avmedia_type_subtitle, av_codec_id_dvb_teletext }, { 0x59, avmedia_type_subtitle, av_codec_id_dvb_subtitle }, /* subtitling descriptor */ { 0 }, }; after i made the change to handle the descriptor tags, i found that exoplayer still didn't like the eac3 mpegts files output by ffmpeg. upon investigation, we found that exoplayer wasn't skipping the substream id field and therefore the parsing was misaligned. we are under the impression that the field is mandatory so not sure how this worked originally? </desc> <cmt> add support to identify (e)ac3 streams via ts descriptor tag </cmt> <cmt> skip substream id field when parsing eac3 sync frame format </cmt>",improve identification of (e)ac3 content in mpegts and tweak eac3 parsing
3501,"<desc> fixes #4122 there seems to be an issue with the v142 compiler bits which causes the code generated around compactvalue.isundefined to not always return the correct value. using fp:strict within yoga.cpp works around the issue. an alternative would be to fork compactvalue, and add pragma's to enable strict just around that. -- or wait for a compiler fix. we should look at disabling this change on compiler updates to see if the compiler issue has been fixed. microsoft reviewers: open in codeflow </desc> <cmt> fix issue with yoga layout in x64 release </cmt> <cmt> change files </cmt> <iss> e2etest failure: padding doesn't work for views on vs 2019, v142 tools, release x64 </iss>",fix issue with yoga in x64 release builds
3502,<desc> fix #13566 : the code was not clear enough in the connectivity-constrained clustering part of the tutorial. i replace the code example and i add some comments to explain what we are doing. </desc> <cmt> add context to tutorial example </cmt> <cmt> merge </cmt> <cmt> try to keep line length under 80 characters </cmt> <iss> tutorial example code lacking context </iss>,fix tutorial example code lacking context #13566
3503,"<desc> implement #1949: profiles.json has been given a setting for background images labeled as shown below, with the following valid values. this allows background images to be anchored to different corners/sides of the console to fit that background image's intended use-case and focus. ""backgroundimagealignment"": ""center"" | ""left"" | ""top"" | ""right"" | ""bottom"" | ""topleft"" | ""topright"" | ""bottomleft"" | ""bottomright"" when left, top, right, or bottom is specified, the other axis is implied to be centered, as that is the default behavior. i went in favor of labeling the default value as center instead of none as ""none"" does not clearly list the alignment behavior. alternative setting the branch dev/trigger/background-image-align-two-settings implements the exact same functionality, but by splitting the profiles.json setting into separate horizontal and vertical settings. i am happy to submit it as a pr if the two-setting approach is preferred. there seems to be no other issues or pull requests relevant to background image alignment. closes #1949 cla signed. if not, go over here and sign the cla requires documentation to be updated (settingsschema.md, usingjsonsettings.md (optional)) i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #1949 the profile class defines methods for parsing and serializing the combined horizontalalignment and verticalalignment enums to and from json. an std::tuple<horizontalalignment, verticalalignment> field _backgroundimagealignment has been added  for storing the profile setting in one place, as it logically makes sense that both alignments to be in use together. terminalsettings and icontrolsettings have been given backgroundimagehorizontalalignment and backgroundimageverticalalignment properties. the combination of std::tuple<horizontalalignment, verticalalignment> is gone once we leave the profile class. combining the two enums is only relevant to how they are stored in profiles.json. terminalsettings defines the default values of both alignment properties as center. the termcontrol class changes the image setup in termcontrol::_initializebackgroundbrush() to assign the _bgimagelayer's (background image control's) alignments to that of the specified alignment settings. the alignments assignments have also been moved from within the image source assignment block, to the bottom of the additional images settings definitions (stretch and opacity). additional fixes the line below for the constant definition has a lowercase i at the beginning of the word ""image"". the i has been capitalized to follow proper uppercamelcase. the two references to this backgroundimagestretchmodekey constant have been updated to reflect the new name. terminal/src/cascadia/terminalapp/profile.cpp line 43 fad7638 static constexpr std::string_view backgroundimagestretchmodekey{ ""backgroundimagestretchmode"" }; (this change was performed in its own commit, so it can be reverted if needed.) test and observe all 9 possible alignment values, invalid input, and not specifying the setting at all. for each image stretch mode. for when a background image is defined or not. confirm alignment names match up. for each alignment value, confirm they are re-serialized correctly when opening windows terminal. confirm default setting results in a centered background image. test and observe if alignment settings are properly applied when first opening the windows terminal or opening a new profile tab. preview example alignments below are examples of the alignments bottom (left) and bottomright (right) in use. figure a (left) shows the use of bottom alignment with uniformtofill stretch mode. the waves will always be at the bottom and stay centered horizontally. figure b (right) shows the use of bottomright alignment with none stretch mode. the image will always remain in the bottom right corner and remain the same size. </desc> <cmt> implement base background image alignment settings </cmt> <cmt> terminalsettings now has two new properties: </cmt> <cmt> * backgroundimagehorizontalalignment </cmt> <cmt> * backgroundimageverticalalignment </cmt> <cmt> these properties are used in termcontrol::_initializebackgroundbrush to specify the alignment for termcontrol::_bgimagelayer. </cmt> <cmt> this is a base commit that will split into two possible branches: </cmt> <cmt> * use one setting in profiles.json: ""backgroundimagealignment"" </cmt> <cmt> * use two settings in profiles.json: ""backgroundimagehorizontal/verticalalignment"" </cmt> <cmt> implement background image alignment profile setting </cmt> <cmt> implement background image alignment as one profile setting. </cmt> <cmt> * this has the benefit of acting as a single setting when the user would likely want to change both horizontal and vertical alignment. </cmt> <cmt> * horizontalalignment and verticalalignment are still stored as a tuple in profile because they are an optional field. and thus, it would not make sense for one of the alignments to be left unused while the other is not. </cmt> <cmt> * cons are that the tuple signature is quite long, but it is only used in a small number of locations. the serialize method is also a little mishapen with the nested switch statements. empty lines have been added between base-level cases to improve readability. </cmt> <cmt> fix capitalization typo for backgroundimagestretchmodekey </cmt> <cmt> in profiles.cpp, the key for the image stretch mode json property had a lowercase 'i' in ""backgroundimage"", not following proper uppercamelcase. </cmt> <cmt> the ""i"" has been capitalized and the two usages of the constant have been updated as well. </cmt> <iss> feature request: background image alignment </iss>",implement #1949 background image align (as one setting)
3504,"<desc> it is because the building process can't find the needed header files. and this already introduced building errors on the branches of 5.2.y and 5.3.y for rpi4, and i guess all branches need these two fixes, it is safe to merge these two patches to base branch then it will apply to all branches automatically? </desc> <cmt> rtl8192cu: let it support to build in the non-src folder </cmt> <cmt> if we build the kernel with ""-o=$non-src-folder"", this driver will </cmt> <cmt> introdcue a building error because of the header's location. </cmt> <cmt> vc_sm: let it support to build in the non-src folder </cmt> <cmt> if we build the kernel with ""-o=$non-src-folder"", this driver will </cmt> <cmt> introdcue a building error because of the header's location. </cmt>",fix two building errors when we build the kernel in the non-src folder
3505,"<desc> this adds support for both signed/unsigned 'long long's. (see:  most the work was already there, so this was straightforward. fixes #8896. </desc> <cmt> add support for 'long long' and 'unsigned long long' types </cmt> <cmt> add long long test </cmt> <cmt> long long test (native side) </cmt> <cmt> update doco for long long type </cmt> <iss> [webidl] 'long long' datatype doesn't appear to be supported </iss>",add support for 'long long' datatype
3506,<desc> ports #20735 and #21651 to release-2.7 // </desc> <cmt> --emitdeclarationsonly flag to enable declarations only output (#20735) </cmt> <cmt> * add emitonlydeclarations flag </cmt> <cmt> * fix name </cmt> <cmt> * verifyoptions checking logic </cmt> <cmt> * passing tests </cmt> <cmt> * dojsemitbaseline </cmt> <cmt> * tests !!! </cmt> <cmt> rename switch --emitdeclarationsonly to --emitdeclarationonly (#21651) </cmt> <cmt> * rename --emitdeclarationsonly to --renamedeclarationonly </cmt> <cmt> * rename test files </cmt>,port --emitdeclarationonly flag support to release-2.7
3507,"<desc> original pull-request #30244 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix [i]like function </cmt> <cmt> add test </cmt> <cmt> fix like function </cmt>",cherry pick #30244 to 21.3: fix like function
3508,<desc> making tls testing available to rabbitmq modules. setup_tls setup_rabbitmq the setup_tls integration test target makes use of the  a basic server configuration is included. related to: #47714 </desc> <cmt> make tls available for rabbitmq </cmt> <cmt> use correct path </cmt>,setup tls integration test for rabbitmq
3509,"<desc> update commons-compress to 1.21 due to cve-2021-35517 updated other apache.commons dependencies to latest version separate commits for addressing the commons-compress update and the other apache.commons updates the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) </desc> <cmt> [flink-24034] upgrade commons-compress to 1.21 </cmt> <cmt> [flink-24034] update multiple apache.commons dependencies </cmt>",upgrade commons-compress to 1.21 and other apache.commons updates
3510,"<desc> adds the logic for handling joins by a prospective leader. introduces the coordinator class with the basic lifecycle modes (candidate, leader, follower) as well as a joinhelper class that contains most of the plumbing for handling joins. </desc> <cmt> node joining </cmt> <cmt> start testing </cmt> <cmt> request serialozatono </cmt> <cmt> more testing </cmt> <cmt> factor out into separate class </cmt> <cmt> smaller stuff </cmt> <cmt> own joincallback </cmt> <cmt> simplify logic in handlejoinrequestunderlock </cmt> <cmt> minor stuff </cmt>",add leader-side join handling logic
3511,"<desc> closes #3170 just return success if there is no packages which needs to be removed. the final results looks like followings. pipenv uninstall --all un-installing all packages from virtualenv... found 0 installed package(s), purging... environment now purged and fresh! a news fragment in the news/ directory to describe this fix with the extension .bugfix, .feature, .behavior, .doc. .vendor. or .trivial (this will appear in the release changelog). use semantic line breaks and name the file after the issue number or the pr #. </desc> <cmt> skip purging if there is no packages needs to be removed </cmt> <cmt> add feature news for issue 3170 </cmt> <iss> pipenv uninstall --all returns error when there is no installed packages in virtuanlenv </iss>",do not show error for pipenv uninstall --all in a fresh virtuanlenv
3512,"<desc> this pr is to update source-map-support. also, this is needed in facebook/jest#7968 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> update source-map-support to include type definition for resetretrievehandlers </cmt> <cmt> update header version </cmt> <cmt> add test </cmt>",update source-map-support to include definition for resetretrievehandlers
3513,"<desc> discussed in #19800 (comment) quoting here, i don't think this necessarily fixes it because the updates could still be delayed so resources and updated might have the same values, but it could the old and not the updated values. a better fix would look like this: #19800 (not be closed yet) i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> added retry logic in test_ray_options </cmt> <cmt> applied linting format </cmt>",added retry logic in test_basic::test_ray_options
3514,"<desc> have parser inherit from pipe. due to the cdef for the parser, i could only get this to work with a pipe.pxd, but i think that's fine? or am i missing a more easy solution? obliterated the syntax folder - hooray! the old nn_parser is moved to transition_parser in spacy.pipeline the old _parser_model is moved to spacy.models as parser_model everything else is now in spacy.pipeline._parser_internals made some small code fixes in some of the pipe classes removed unnecessary imports enhancement / refactor i have submitted the spacy contributor agreement. </desc> <cmt> moving syntax folder to _parser_internals </cmt> <cmt> moving nn_parser and transition_system </cmt> <cmt> move nn_parser and transition_system out of internals folder </cmt> <cmt> moving nn_parser code into transition_system file </cmt> <cmt> rename transition_system to transition_parser </cmt> <cmt> moving parser_model and _state to ml </cmt> <cmt> move _state back to internals </cmt> <cmt> the parser now inherits from pipe! </cmt> <cmt> small code fixes </cmt> <cmt> removing unnecessary imports </cmt> <cmt> remove link_vectors_to_models </cmt> <cmt> transition_system to internals folder </cmt> <cmt> little bit more cleanup </cmt>",the parser is now a pipe (2)
3515,"<desc> follow-up pr to #54124. changes the name of one of the return values of docker_host_info from host_facts to host_info. also changes the name of docker_node's return value node_facts to node, so that it is more similar to other module's return values and also fits docker_node_info's nodes return value name. docker_host_info docker_node </desc> <cmt> docker_host_info: host_facts -> host_info </cmt> <cmt> docker_node: node_facts -> node </cmt>",docker_host_info and docker_node: fix return variable names
3516,<desc> keyversionregistry registry for managing the available key version implementations. enables the storage system to easily create a keyversion.builder for a given type. also maintains the protobuf extension registry (contains all the extensions declared by the key version protos). registry and its accompanying registeredkeyversion class are thread-safe. </desc> <cmt> add key version registry. </cmt> <cmt> - structure is similar to storage driver handling. </cmt> <cmt> - completely thread-safe. </cmt> <cmt> - added appropriate exceptions for the registry. </cmt> <cmt> - includes some alterations to keyverions. </cmt>,"add keyversionregistry, and read/write support on key."
3517,<desc> as discussed in the forums the first commit makes the logging of incoming json-rpc requests optional. for json-rpc requests over http there is still a debug log message from the webserver (which is not json-rpc specific) but i guess most of the json-rpc log spam comes from json-rpc requests of python addons. and a lot of remotes use json-rpc over tcp. the second commit reduces the log level of a log json-rpc log message from error to warning. the problem is that at the time we don't know if it's actually an error or not. there are cases where it will be an error and others where it can resolved later on. so logging it as a warning should be less confusing. </desc> <cmt> json-rpc: make logging of incoming requests optional </cmt> <cmt> json-rpc: reduce log level of potential error to warning </cmt>,make logging of incoming requests optional and configurable
3518,"<desc> what do these changes do? add a grpc server to the worker that registers with the raylet (but no communication through here yet). also convert rayletclient references to unique_ptr. for more details, refer to #5039 #5029 linter </desc> <cmt> refactor grpc server </cmt> <cmt> format </cmt> <cmt> change gettask() to pushtask() </cmt> <cmt> merge code, and fix test </cmt> <cmt> merge </cmt> <cmt> change pushtask to assigntask </cmt> <cmt> format </cmt> <cmt> update </cmt> <cmt> fix test </cmt> <cmt> format </cmt> <cmt> merge </cmt> <cmt> merge with latest code </cmt>",add grpc server to worker
3519,"<desc> epe-835 added test case that starts up a 4+ producer network, adds all but one producer into the security group, verifies that the producers in the security group are building on each others blocks and that the excluded producer is on its own fork. after that, it adds the remaining producer into the security group and verifies the all eventually become in sync. select one: select any that apply: </desc> <cmt> added verifying network is in-sync to securitygroup validation and fixed validation for non-participating producers. </cmt> <cmt> added test case #4 test to verify security group forked networks. </cmt> <cmt> added new test for privacy test scenario #4. </cmt>",added  privacy test case #4
3520,<desc> this renames methods on workspaceview that return paneviews. previously it appeared like the methods returned pane objects. now the methods are named so it is clear that they return paneviews. </desc> <cmt> replace workspaceview:eachpane with workspaceview:eachpaneview </cmt> <cmt> rename workspace::getpanes to workspace::getpaneviews </cmt> <cmt> rename pane focusing methods on workspace </cmt> <cmt> :lipstick: </cmt> <cmt> remove workspace::getfocusedpane </cmt> <cmt> add comment to panecontainer::indexofpane </cmt> <cmt> remove workspaceview::indexofpane </cmt>,rename workspace view pane methods
3521,"<desc> this utils.tex_file_writing.get_null() was added in #47 . it was unnecessary as os.devnull does the exact same thing for nt and posix. two places have typos that causes running them failling from syntaxerror in old_projects. one is the keyword arguments with parenthesis. the other is somewhere with an extra parenthesis. i followed how 3b1b uses key=foo rather than key = foo in sort functions of submojects. </desc> <cmt> update tex_file_writing.py </cmt> <cmt> change ""/dev/null"" to os.getnull in utils/sounds.py sox ""play"" command </cmt> <cmt> fix typo </cmt>",use os.devnull instead of utils.tex_file_writing.get_null(); also small typos that cause syntaxerror
3522,"<desc> stop module from running net on empty commands. this fixes a bug where nclu would run net for empty lines produced in jinja templates. this will check to ensure that the command has content before being passed to net, which should improve performance and clean up the msg return value. nclu ansible version ansible 2.7.0.dev0 (devel 577427b1c2) last updated 2018/07/17 15:23:05 (gmt +000) config file = none configured module search path = [u'/home/cumulus/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/cumulus/ansible/lib/ansible executable location = /home/cumulus/ansible/bin/ansible python version = 2.7.9 (default, jun 29 2016, 13:08:31) [gcc 4.9.2] task: - name: add 2 interfaces and commit the change. nclu: template: | {% for iface in range(1,3) %} add int swp{{iface}} {% endfor %} commit: true description: ""ansible - add swps1-2"" output before task [examply : add 2 interfaces and commit the change.] ************************************************************************************************************************************************************ ok: [leaf01] => {""changed"": false, ""msg"": ""\n\nusage:\n    # net <command> [<args>] [help]\n    #\n    # net is a command line utility for networking on cumulus linux switches.\n    #\n    # commands are listed below and have context specific arguments which can\n    # be explored by typing \""<tab>\"" or \""help\"" anytime while using net.\n    #\n    # use \""man net\"" for a more comprehensive overview.\n\n    net abort\n    net commit [verbose] [confirm [<number-seconds>]] [description <wildcard>]\n    net commit delete (<number>|<number-range>)\n    net commit permanent <wildcard>\n    net del all\n    net help [verbose]\n    net pending [json]\n    net rollback (<number>|last)\n    net rollback description <wildcard-snapshot>\n    net show commit (history|<number>|<number-range>|last)\n    net show rollback (<number>|last)\n    net show rollback description <wildcard-snapshot>\n    net show configuration [commands|files|acl|bgp|multicast|ospf|ospf6]\n    net show configuration interface [<interface>]\n\noptions:\n\n    # help commands\n    help     : context sensitive information; see section below\n    example  : detailed examples of common workflows\n\n    # configuration commands\n    add      : add/modify configuration\n    del      : remove configuration\n\n    # commit buffer commands\n    abort    : abandon changes in the commit buffer\n    commit   : apply the commit buffer to the system\n    pending  : show changes staged in the commit buffer\n    rollback : revert to a previous configuration state\n\n    # status commands\n    show     : show command output\n    clear    : clear counters, bgp neighbors, etc\n\n    <number-seconds> : number of seconds\n\n\n\nusage:\n    # net <command> [<args>] [help]\n    #\n    # net is a command line utility for networking on cumulus linux switches.\n    #\n    # commands are listed below and have context specific arguments which can\n    # be explored by typing \""<tab>\"" or \""help\"" anytime while using net.\n    #\n    # use \""man net\"" for a more comprehensive overview.\n\n    net abort\n    net commit [verbose] [confirm [<number-seconds>]] [description <wildcard>]\n    net commit delete (<number>|<number-range>)\n    net commit permanent <wildcard>\n    net del all\n    net help [verbose]\n    net pending [json]\n    net rollback (<number>|last)\n    net rollback description <wildcard-snapshot>\n    net show commit (history|<number>|<number-range>|last)\n    net show rollback (<number>|last)\n    net show rollback description <wildcard-snapshot>\n    net show configuration [commands|files|acl|bgp|multicast|ospf|ospf6]\n    net show configuration interface [<interface>]\n\noptions:\n\n    # help commands\n    help     : context sensitive information; see section below\n    example  : detailed examples of common workflows\n\n    # configuration commands\n    add      : add/modify configuration\n    del      : remove configuration\n\n    # commit buffer commands\n    abort    : abandon changes in the commit buffer\n    commit   : apply the commit buffer to the system\n    pending  : show changes staged in the commit buffer\n    rollback : revert to a previous configuration state\n\n    # status commands\n    show     : show command output\n    clear    : clear counters, bgp neighbors, etc\n\n    <number-seconds> : number of seconds\n""} output after task [examply : add 2 interfaces and commit the change.] ************************************************************************************************************************************************************ ok: [leaf01] => {""changed"": false, ""msg"": ""\n""} </desc> <cmt> update nclu.py </cmt> <cmt> stop module from running net on empty commands. </cmt> <cmt> update nclu.py </cmt> <cmt> updated the copyright date </cmt>",improve performance by not operating on empty lines
3523,"<desc> this short document lists useful asp.net core perf diagnostic tools. there's not much 'meat' since the tools are all well-documented elsewhere, but i think it's valuable to have this sort of list so that asp.net core devs can discover the tools (especially perfview and perfcollect, which can be hard to find without links from official docs). fixes #9525 </desc> <cmt> add asp.net core perf diagnostic tools list </cmt> <cmt> add diagnostic tools doc to toc </cmt> <cmt> a few minor phrasing tweaks </cmt> <cmt> remove a few stray 'en-us' elements from links </cmt>",document asp.net core perf tools
3524,"<desc> updates recent changes to my keymaps and userspace in qmk's repo. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> remove macromode functionality </cmt> <cmt> update kbdfans/kbd75/rev1:noroadsleft keymap </cmt> <cmt> - replace _______ instances with xxxxxxx on system layer </cmt> <cmt> - add line breaks between keymap layers </cmt>",update noroadsleft userspace and keymaps (2021-12-13)
3525,"<desc> javascript 0.82.0 now tokenizes the $ in  $something as an instance constructor and also fixes tokenization when destructuring in const assignments (const [first, second, ...rest] = array);) python 0.38.0 correctly tokenizes self.something now go 0.31.0 adds the fmt printf snippet for debugging </desc> <cmt> :arrow_up: language-javascript@0.82.0 </cmt> <cmt> :arrow_up: language-python@0.38.0 </cmt> <cmt> :arrow_up: language-go@0.31.0 </cmt>","update language-javascript, python, and go"
3526,<desc> needed for flashing to use zigbeebridge with tasmota the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.2.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> create readme.txt </cmt> <cmt> efr32 firmware for zigbeebridge </cmt>,add firmware efr32 files for zigbeebridge
3527,"<desc> i was having issues getting an rpm to build. my error was processing files: superset-0.20.1-1.noarch error: file must begin with ""/"": lockup error: file must begin with ""/"": with error: file must begin with ""/"": text.svg error: file must begin with ""/"": lockup error: file must begin with ""/"": with error: file must begin with ""/"": text@2x.png error: file must begin with ""/"": lockup error: file must begin with ""/"": without error: file must begin with ""/"": text@1x.svg error: file must begin with ""/"": lockup error: file must begin with ""/"": without error: file must begin with ""/"": text@2x.png error: file must begin with ""/"": mark.png error: file must begin with ""/"": mark@1x.svg for ref pypa/setuptools#767 file renaming fixes this issue </desc> <cmt> merging in updates from main repo </cmt> <cmt> updating my fork </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> rename files to allow rpm build </cmt> <cmt> i was having issues getting an rpm to build. my error was </cmt> <cmt> processing files: superset-0.20.1-1.noarch </cmt> <cmt> error: file must begin with ""/"": lockup </cmt> <cmt> error: file must begin with ""/"": with </cmt> <cmt> error: file must begin with ""/"": text.svg </cmt> <cmt> error: file must begin with ""/"": lockup </cmt> <cmt> error: file must begin with ""/"": with </cmt> <cmt> error: file must begin with ""/"": text@2x.png </cmt> <cmt> error: file must begin with ""/"": lockup </cmt> <cmt> error: file must begin with ""/"": without </cmt> <cmt> error: file must begin with ""/"": text@1x.svg </cmt> <cmt> error: file must begin with ""/"": lockup </cmt> <cmt> error: file must begin with ""/"": without </cmt> <cmt> error: file must begin with ""/"": text@2x.png </cmt> <cmt> error: file must begin with ""/"": mark.png </cmt> <cmt> error: file must begin with ""/"": mark@1x.svg </cmt> <cmt> for ref </cmt> <cmt> file renaming fixes this issue </cmt>",renaming files to allow rpm build
3528,"<desc> make section names unique in loops, as catch doesn't support duplicate sections, see also catchorg/catch2#816 (comment) as a result, when built with gcc, loop iterations were skipped. when built with clang, the test aborted with an assertion in catch.hpp line 6222. this also addresses the issues discussed here: #1032 (comment) and here: catchorg/catch2#1241 as some of the unit tests which never ran before failed now, i added an exclude list for one of the tests (this is due to nlohmann-json ordering dictionaries by key, while the output files it compares against kept the key order of the json files). also, the way the tests were written, they would now take a long time, therefore i moved parsing the source into individual sections (more code, but 99% less parsing operations for the same tests). read the contribution guidelines for detailed information. changes are described in the pull request, or an existing issue is referenced. the test suite compiles and runs without error. code coverage is 100%. test cases can be added by editing the test suite. the source code is amalgamated; that is, after making changes to the sources in the include/nlohmann directory, run make amalgamate to create the single-header file single_include/nlohmann/json.hpp. the whole process is described here. the c++11 support varies between different compilers and versions. please note the list of supported compilers. some compilers like gcc 4.8 (and earlier), clang 3.3 (and earlier), or microsoft visual studio 13.0 and earlier are known not to work due to missing or incomplete c++11 support. please refrain from proposing changes that work around these compiler's limitations with #ifdefs or other means. specifically, i am aware of compilation problems with microsoft visual studio (there even is an issue label for these kind of bugs). i understand that even in 2016, complete c++11 support isn't there yet. but please also understand that i do not want to drop features or uglify the code just to make microsoft's sub-standard compiler happy. the past has shown that there are ways to express the functionality such that the code compiles with the most recent msvc - unfortunately, this is not the main objective of the project. please refrain from proposing changes that would break json conformance. if you propose a conformant extension of json to be supported by the library, please motivate this extension. please do not open pull requests that address multiple issues. </desc> <cmt> make section names unique in loops, as catch doesn't support duplicate </cmt> <cmt> sections, see also </cmt> <cmt> as a result, when built with gcc, loop iterations were skipped. when </cmt> <cmt> built with clang, the test aborted with an assertion in catch.hpp </cmt> <cmt> line 6222. </cmt> <cmt> this also addresses the issues discussed here: </cmt> <cmt>  </cmt> <cmt> and here: </cmt> <cmt>  </cmt> <cmt> please note that this introduces new problems, as some of </cmt> <cmt> the unit tests fail now - the library stores keys in </cmt> <cmt> lexographical order, while the cbor/msgpack/ubjson examples </cmt> <cmt> store them in original order. </cmt> <cmt> exclude bytewise comparison in certain tests. </cmt> <cmt> these tests never worked - they weren't run before </cmt> <cmt> d5aaeb4. </cmt> <cmt> note that these tests would fail because of this library </cmt> <cmt> ordering dictionary keys (which is legal). so changing the </cmt> <cmt> input files (or modifying stored cbor/msgpack/ubjson files) </cmt> <cmt> would make the tests work and they could get removed from </cmt> <cmt> ""exclude_packaged"". </cmt> <cmt> also move parsing of files in these unit tests to within </cmt> <cmt> the inner sections, so that they're only parsed </cmt> <cmt> number_of_files * number_of_sections instead of </cmt> <cmt> number_of_files * number_of_files * number_of_sections </cmt> <cmt> (so, instead of close to 100k parses about 700). </cmt>",fix unit tests that were silently skipped or crashed (depending on the compiler)
3529,<desc> matches the browser default inputs we have and cleans up some code. </desc> <cmt> make custom select and file inputs 100% wide </cmt> <cmt> matches browser default inputs and swaps some max-width properties for a regular width </cmt> <cmt> space custom select sizing examples </cmt>,full width custom select and file inputs
3530,"<desc> bug fixes apis fix the bug of div operation result using scale method do not exactly equal the result of elementwise_div method. remove the _scalar_div_ function. the bug is as follow. and after fixing the bug remove __div__ ,__rdiv__ methods which do not be defined in python3 standard. </desc> <cmt> fix the bug of div operation result using scale method do not exactly equal the result of elementwise_div method </cmt> <cmt> remove __div__ , __rdiv__ methods which do not define in python3 </cmt>",change '/' method from scale op to elementwise_div op
3531,<desc> replaces the deprecated reacttype with elementtype in react-test-renderer ref -  add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> </desc> <cmt> fix: add propswithchildren to exoticcomponent </cmt> <cmt> fix[react-test-renderer] - replace reacttype with elementtype </cmt>,fix[react test renderer]  replace deprecated type reacttype
3532,"<desc> this pr adds a functional sub-test for calling decodescript with a p2tr / segwit v1 output script (op_1 <32-bytes push>), expecting to return ""witness_v1_taproot"" as type result. in the first two commits, the test rpc_decodescript.py is also improved by adding logging (plus getting rid of the enumerations) and also adding missing checks type result checks for all other output script types. </desc> <cmt> test: add logging to rpc_decodescript.py </cmt> <cmt> also remove the enumerations (""1)"", ""2)""...) from the test </cmt> <cmt> cases as those potentially hinder maintainability; e.g. if a </cmt> <cmt> new case in inserted in-between, all the remaining </cmt> <cmt> enumerations would need to be adapted. </cmt> <cmt> test: check for decodescript rpc 'type' results </cmt>",add decodescript rpc test for p2tr output script
3533,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> types/node-forge/index.d.ts </cmt> <cmt> fix test and add functional </cmt>",@types/node-forge added resolvers for the
3534,"<desc> indexing 'option-checking' out of known_args had a type error when option checking is disabled, don't error on duplicate args, just take the last add config.toml stubs for datadir, infodir, and localstatedir (which were already accepted, but broken) this fixes a regression from 1.21 to beta, when the configure script was rewritten in python. </desc> <cmt> configure.py: fix --disable-option-checking </cmt> <cmt> getting the value of this argument needs another level of indexing, </cmt> <cmt> as known_args are stored in {dict}[list](opt, value) form. </cmt> <cmt> also, when option-checking is disabled, let this bypass the check that </cmt> <cmt> options are only passed once, and just apply the last value. </cmt> <cmt> config.toml: add stubs for recognized-but-unused install paths </cmt> <cmt> ... specifically datadir, infodir, and localstatedir.  these were </cmt> <cmt> already accepted by configure.py, but it didn't have any place to put </cmt> <cmt> the values. </cmt>",fix --disable-option-checking and extra config paths
3535,<desc> fix a crash when the filter chain only update listener update is superseded by the listener removal or full listener update. risk level: low testing: unit test </desc> <cmt> tcplistener: allow remove filter chain after listener is removed </cmt> <cmt> add listener manager test </cmt> <cmt> address comment: defer delete filter chain </cmt> <cmt> version history </cmt>,fix mixed full listener update and intelligent listener update
3536,"<desc> we're currently handling redirects in our api gateway layer. this pr will allow redirects to happen client side. for example, a client may specify a list of redirects in their gatsby-browser.js as follows. exports.modifyroutes = routes => { const redirects = [ { path: '/cat', onenter: (nextstate, replace) => replace('/dog?utm_campaign=cat') } ]; const childrouteslength = routes.childroutes.length; const childroutesbutlast = routes.childroutes.slice(0, childrouteslength - 1); const childrouteslast = routes.childroutes[childrouteslength - 1]; routes.childroutes = childroutesbutlast.concat(redirects).concat([childrouteslast]); return routes; }; </desc> <cmt> allow client to modify routes </cmt> <cmt> update readme </cmt>",allow client to modify react-router routes
3537,"<desc> this fixes some metadata/ast encoding problems that lead to ices.  the way this is currently handled will need revisiting if abstract return types are added, as unboxed closure types from extern crates could show up without being inlined into the local crate. closes #16790 (i think this was fixed earlier by accident and just needed a test case) closes #18378 closes #18543 r? @pcwalton </desc> <cmt> fix decoding of unboxed closure kinds </cmt> <cmt> closes #18378.  note that cross-crate unboxed closures are </cmt> <cmt> still unimplemented and will fail to work currently. </cmt> <cmt> treat cross-crate unboxed closure def ids consistently </cmt> <cmt> always translate the id into the local crate id space since </cmt> <cmt> presently the only way to encounter an unboxed closure type </cmt> <cmt> from another crate is to inline once of its functions. </cmt> <cmt> this may need to change if abstract return types are added. </cmt> <cmt> closes #18543 </cmt> <cmt> add regression test for #16790, #18378 and #18543 </cmt> <iss> internal compiler error in metadata::tydecode::parse_def_id related to unboxes closures </iss> <iss> unboxed closures ice: expected(expected ebml doc with tag esenumvid but found tag 27) </iss> <iss> cross-crate unboxed closures are not fully implemented </iss>",fix some cross-crate unboxed closure bugs
3538,"<desc> my recollection is that this was mostly working, but we were seeing just enough failures that we didn't want to leave it enabled while branching for release. let's see whether that's (still) true. see also #19217. / </desc> <cmt> revert ""leave all our tests as order_dependent! for now"" </cmt> <cmt> this reverts commit 2f52f969885b2834198de0045748436a4651a94e. </cmt> <cmt> conflicts: </cmt> <cmt> actionmailer/test/abstract_unit.rb </cmt> <cmt> actionview/test/abstract_unit.rb </cmt> <cmt> activemodel/test/cases/helper.rb </cmt> <cmt> activerecord/test/cases/helper.rb </cmt> <cmt> activesupport/test/abstract_unit.rb </cmt> <cmt> railties/test/abstract_unit.rb </cmt> <cmt> revert ""for now, we will keep sorting the tests."" </cmt> <cmt> this reverts commit 7025d7769dc53f0a3ffab8b537727ef3fee367fc. </cmt>",run all our tests in random order
3539,"<desc> the paddings on the outer edges of dialog content (not between content) should be smaller for larger text scale size. this pr computes a factor for scaling down the padding and applies it to the space between the edge of the dialog and the content inside. before: after: related issues i added the following tests: 25 padding tests 3 configurations of alertdialog x 5 textscalefactors 2 configurations of simpledialog x 5 textscalefactors before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> adjust edge paddings on alertdialog title, content, and actions </cmt> <cmt> increase padding de-scale multiplier </cmt> <cmt> adjust logic for padding scaling </cmt> <cmt> update dialogs </cmt> <cmt> add padding rules to simpledialog </cmt>",automatically scale down dialog padding for larger text scale factors
3540,"<desc> this allows counting occurrences of unique items (e.g. user id, url, etc.) over rollup intervals in a time range, as well as calculating the total number of unique items over an aggregate time range that spans several rollup intervals. the redis implementation uses hyperloglog to provide cardinality estimates (it probably makes sense to document that there is a approximate standard error of 0.81%) while the in-memory implementation uses sets. this adds support for the following time series queries: users that have been affected by events within a group (issue) users that have been affected by events within a project </desc> <cmt> add demonstration of distinct counters using hyperloglog in tsdb. </cmt> <cmt> execute queries concurrently (pardon my dust and terrible variable names.) </cmt> <cmt> use target_key from rb==1.3. </cmt> <cmt> style. </cmt> <cmt> allow querying for series data. </cmt> <cmt> cleanup, move interval calculation onto base. </cmt> <cmt> default end to the current time if not provided. </cmt> <cmt> fix expiration logic. </cmt> <cmt> add in memory backend, add it to the test script. </cmt> <cmt> remove extraneous argument from pfadd call. (this is why variadics are bad.) </cmt> <cmt> improve names. </cmt> <cmt> add simple test case for distinct counts. </cmt> <cmt> clean up documentation. </cmt> <cmt> remove example script. </cmt>",add distinct counters to tsdb backends.
3541,"<desc> a proposed fix for #4802 i added 'replay' option to the playtoggle component. change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) </desc> <cmt> sync with origin branch </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> feat: add 'replay' option to the playtoggle component </cmt>",add 'replay' option to the playtoggle component.
3542,"<desc> i'd like to see the component description from __docgeninfo in the story documentation in the info plugin. i'd like to get the prop type from __docgeninfo for when the type comes back as ""other"". propval had a problem where 'content' was being directly rendered as an object. added to proptable added to propval added to story make a story with a component that has documented (via docgen-style text) description, and the description will show up. like this: /** component description here */ const button = ({children, onclick}) => ( <button onclick={onclick}>{children}</button> ) button.proptypes = { onclick: proptypes.func // make sure this does not come from react, make it come from prop-types module. } storiesof('button', module) .addwithinfo('demo', 'button with children', () => ( <button onclick={action('clicked')}>david</button> )) .addwithinfo('demo', '', () => ( <button onclick={action('clicked')}>david</button> )) you will see a description under the info description, you will also see that the prop type is not 'other' when you use proptypes from something other than react (for support of react >= 15.5.x. </desc> <cmt> added version number. </cmt> <cmt> working on getting more documentation. </cmt> <cmt> added a post install script. </cmt> <cmt> added code to support js documentation for adding descriptions to a component, fixed issue with content was being rendered as an object and give errors for that, added a fix to when you use proptypes from something other than react that you can get the type from docgen. </cmt> <cmt> removed version number. </cmt>",fix semi broken __docgeninfo integration in addon info
3543,"<desc> see discussion in #25007, and particularly #25007 (comment) this changes the parameter value of true to none (without any change in behaviour), so we keep the possibility open to have sort=true to mean ""always sorting"" in the future. i started from the branch of tom in #25007 (as there were already useful doc changes + new tests), and changed the value + updated the tests from there.  closes #24959 </desc> <cmt> [wip]: api: change default for index.union sort </cmt> <cmt> closes </cmt> <cmt> update test </cmt> <cmt> fixups </cmt> <cmt> multi </cmt> <cmt> doc typo </cmt> <cmt> intersection </cmt> <cmt> whatsnew </cmt> <cmt> update whatsnew </cmt> <cmt> symdiff </cmt> <cmt> whatsnew </cmt> <cmt> doc </cmt> <cmt> index multi </cmt> <cmt> change true to none; disallow true </cmt> <cmt> fix concat tests </cmt> <iss> index.intersection changed behavior to sort by default in pandas 0.24 </iss>",change index set ops sort=true -> sort=none
3544,<desc> this pr is first step into better support for polish language. it is just a polish version of lex_attrs.py based on english one and signed contribution agreement. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> signed spacy contributor agreement </cmt> <cmt> added polish version of english lex_attrs </cmt>,lex _attrs for polish language
3545,"<desc> this is a continuation of #11614 which takes care of a few other issues as well as making the auto-disabling part of the auto-update feature as opposed to a hard/global policy, and will not interfere with any user actions. i.e when auto-updates are on they will auto disable + show a notification. when off, it should be clearly visible on the info screen before hitting update. </desc> <cmt> [addons] fix query. broken table is unused and not updated anymore </cmt> <cmt> [addons] dont prevent installation of addons marked broken in addonmgr </cmt> <cmt> this is a soft flag and should be handled in gui layer </cmt> <cmt> [addons] add isautoupdate flag to install job </cmt> <cmt> [addons] remove non-functioning broken status code </cmt> <cmt> [estuary] fix message for broken addons </cmt> <cmt> 'broken' does not include incompatible </cmt> <cmt> [addons] auto-disable broken addons after update </cmt>",auto-disable broken addon on update
3546,"<desc> the problem is that currently to load a model using from_pretrained requires 2x model size on cpu memory and for those odd cases where a user has large gpu memory, but very little cpu memory it's a problem. this pr is trying to solve the puzzle of loading ""eleutherai/gpt-j-6b"", with revision=""float16"" and torch_dtype=torch.float16 for the model in full fp16. it shouldn't use more than 12.1gb of cpu ram to work on colab. so this should use 12.1gb of cpu memory including peak memory: m = gptjforcausallm.from_pretrained(""eleutherai/gpt-j-6b"", revision=""float16"", torch_dtype=torch.float16, low_cpu_mem_usage=true) this of course won't be enough to be used on the free google colab since it has a total of 12gb of cpu ram for everything, so by the time we come to from_pretrained a few gbs will be already consumed by python/torch/transformers, leaving less than 10gb of cpu ram. here is what this pr does: load state_dict and register which keys we have drop state_dict switch to the meta device all params/buffers that are going to be replaced from the loaded state_dict load state_dict 2nd time replace the params/buffers from the state_dict see the snapshot showing the memory use of just 1x model size and a bit more for temps (this includes peak memory usage). (the automatic cpu/gpu memory usage reporting in the snapshot is courtesy of  todo: if this gets a green light - need to write a test that measure 1x memory size @lysandrejik, @sgugger </desc> <cmt> one possible solution </cmt> <cmt> low mem from_pretrained </cmt>",1x model size cpu memory usage for from_pretrained
3547,"<desc> closes: #17765 bug fix for get_pandas_df() to avoid an exception when reading an empty table. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. </desc> <cmt> bug fix to allow empty dataframes in get_pandas_df </cmt> <iss> get_pandas_df() fails when it tries to read an empty table </iss>",hivehook fix get_pandas_df() failure when it tries to read an empty table
3548,<desc> fixes the link to security.md in the contributing.md file and makes the filename uppercase for consistency. requires documentation to be updated </desc> <cmt> fix link to security.md in contributing.md </cmt> <cmt> uppercase contributing.md filename for consistency </cmt>,fix link (and filename) in contributing.md
3549,"<desc> please refer to the individual commit messages for additional details. smaller diff with </desc> <cmt> [pdfsidebarresizer] skip the css.supports checks for mozcentral builds </cmt> <cmt> since css variable support cannot be disabled any more in firefox, the run-time checks are of no using for mozcentral builds. </cmt> <cmt> [pdfsidebarresizer] refactor the clamping in _updatewidth </cmt> <cmt> rather than manually clamping the width here, we can just export an already existing helper function from ui_utils.js instead. </cmt> <cmt> (hopefully it will eventually be possible to replace this helper function with a native math.clamp function, given that there exists a ""stage 1 proposal"" for adding such a thing to the ecmascript specification.) </cmt> <cmt> [pdfsidebarresizer] re-factor the resize event listener to improve readability </cmt> <cmt> i've absolutely no idea why i wrote the code that way originally, since the nested ifs are not really helping readability one bit. </cmt> <cmt> hence this patch which changes things to use early returns instead, to help readability. </cmt>",add a couple of (small) readability improvements in the code
3550,"<desc> description: this pr adds functionality for locks expressed through the smartthings platform. locking/unlocking is working great, however i'm not sure whether we should update the state straight away (faster ui feedback) or wait for the confirmation from smartthings (removes false positives). also as mentioned in the referenced issue, there are some other attributes that could possibly be added to the entity. @andrewsayre any chance you could expand on those here? related issue (if applicable): fixes #20889 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#8493 example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. if the code does not interact with devices: </desc> <cmt> bumped pysmartthings version to 0.6.1 </cmt> <cmt> added lock to supported platforms </cmt> <cmt> added smartthings lock component </cmt> <cmt> updated lock to eagerly set state </cmt> <cmt> updated requirements_all.txt & requirements_test_all.txt with pysmartthings==0.6.1 </cmt> <cmt> added smartthings lock tests </cmt> <cmt> removed inapplicable comment </cmt> <iss> smartthings component doesn't show smart lock status </iss>",add lock capability to smartthings platform
3551,"<desc> added arcface face recognition model to example list added arcface, mobilenet, resnet, squeezenet, vgg models to onnx api page please feel free to remove inapplicable items for your pr. code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change added arcface face recognition model to example list fixed contents in example readme to link to ""other deep learning examples with mxnet"" section added arcface, mobilenet, resnet, squeezenet, vgg to onnx api page (created a new section ""onnx examples"") all the models and related artifacts are linked from onnx model zoo for each model, there are pretrained models in onnx format with notebooks for training, validation and inference, scripts for pre/post processing and dataset prep in mxnet. </desc> <cmt> added arcface example </cmt> <cmt> updated onnx.md with arcface </cmt> <cmt> updated onnx.md with imagenet models </cmt>",adding models to example list and onnx api page
3552,"<desc> when config file i/o was centralized to the main process, the config object's mainsource is disregarded and all configs are serialized to the same file. this results in config file loss when using atom-mocha-test-runner because the atomenvironments built there enable persistence to a temporary directory: global.buildatomenvironment = function (params = {}) { let defaultparams = { applicationdelegate, window, document, enablepersistence: true, configdirpath: tmpdir } return buildatomenvironment(object.assign(defaultparams, params)) } this restores the ability to track multiple config objects and atom environments by passing the source as well as the config payload to the main process through ipc. partial fix for #14909, specifically the bit where atom/github's test suite was resetting configuration </desc> <cmt> :art: remove extra space </cmt> <cmt> maintain a global map of configfile instances </cmt> <cmt> accept a filepath in the set-user-settings ipc call </cmt> <cmt> pass a configfilepath along with the user settings </cmt> <cmt> pass config file path to applicationdelegate call </cmt>",support multiple config file paths
3553,"<desc> @mugen87 there were only minor corrections to the ts introduced with #16969 i realized that codeserializer was poorly documented and that it needed clean-up especially with regard to unused functionality. that's why it became the biggest change here. </desc> <cmt> codeserializer: clean, update doc and typescript definitions </cmt> <cmt> general: align js docs and ts signature files </cmt> <cmt> codeserializer: clean-up/remove functionality no longer needed. make override clearer via codeserializationinstruction </cmt> <cmt> fixed comments and made minor ts adjustments </cmt>","clean-up, code doc update and ts alignment"
3554,"<desc> this is a collection of smaller changes, the most invasive being a change to the socket setup process. instead of only tracking connected and disconnected, we now track the initialisation process too. ultimately this allows asynchronous errors from the tcp stack to bubble up to the original connect() call. bonus feature: better logging of tcp state transitions. fixes #419 </desc> <cmt> kernel: move tcp state logging into tcpsocket </cmt> <cmt> kernel: use a more detailed state machine for socket setup </cmt> <cmt> kernel: detect some outgoing tcp connection failures </cmt> <iss> connect() doesn't fail properly </iss>",detect outgoing tcp connection errors
3555,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. sorry for my last awful pr </desc> <cmt> rails-actioncable: add npm support </cmt> <cmt> rails-actioncable: fix ambiguous datatype </cmt>,support import + fix ambicious datatype
3556,<desc> implement function retrieval python apis on existing abis add documentation generation scripts for functions minor fixes on dependencies and configurations in cmake files </desc> <cmt> add for test function build </cmt> <cmt> add pybind functions for getfunction api </cmt> <cmt> implement fc function testcase </cmt> <cmt> lint code using clang-format </cmt> <cmt> disable warning in covert protobuf::int64 to int </cmt> <cmt> update doc generation scripts and functions doc </cmt> <cmt> trimming some comments </cmt> <cmt> fix doc generation scripts for typecheck </cmt> <cmt> improve cmake scripts for unittest project dependencies and fix linux build issues </cmt> <cmt> lint python code </cmt> <cmt> update api to support functions with multiple versions </cmt> <cmt> update line ending </cmt> <cmt> add changelogs for functions </cmt> <cmt> refactor and lint code </cmt>,implement function retrieval apis; add documentation for functions
3557,"<desc> this is a backport of #32657 </desc> <cmt> adding job process pojos to protocol pkg (#32657) </cmt> <cmt> * adding job process pojos to protocol pkg </cmt> <cmt> * removing unused results_field </cmt> <cmt> * addressing pr comments, removing unnecessary methods </cmt> <cmt> removing min_version field </cmt>",feature/backport ml job process to protocol
3558,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> give the correct type </cmt> <cmt> add a signature </cmt> <cmt> modify a test </cmt>,modify the type of array.compact method in yup
3559,<desc> adds and enhances tests for the dashboard filterbar (nativefilters.) test plan all tests should pass </desc> <cmt> add filterbar tests </cmt> <cmt> finalize filterbar tests </cmt> <cmt> add tests for filterbar header </cmt> <cmt> add tests for filterbar filterconfigurationlink </cmt> <cmt> add tests for filterbar filtersets editsection </cmt> <cmt> add tests for filterbar filtersets </cmt> <cmt> clean up </cmt> <cmt> add tests for filterbar filtersetunit </cmt> <cmt> add tests for filterbar filtersets filtersheader </cmt> <cmt> add tests for filterbar filtersets footer </cmt> <cmt> fix linting </cmt> <cmt> fix import </cmt>,tests audit for the dashboard filterbar
3560,"<desc> _baseencoder._transform() currently calls _encode_check_unknown(), and then calls _encode() which will call _encode_check_unknown() a second time (if the dtype is compatible with numpy) since _encode_check_unknown() calls np.unique() on a given column, its complexity is o(n_samples) which is not negligible on large training sets. this pr avoids this by adding a check_unknown parameter to _encode() which defaults to true. </desc> <cmt> avoid calling _encode_check_unknown twive </cmt> <cmt> pep8 </cmt> <cmt> cosmetics </cmt>",avoid calling _encode_check_unknown() twice in baseencoder.transform
3561,"<desc> @matthiasplappert this pull request is a follow up to #1299 here we added -v1 environments: handmanipulate{block, egg, pen}touchsensors-v1 use original sensordata readings (mujoco); handmanipulate{block, egg, pen}touchsensors-v0 use boolean readings; and we also improved gym/envs/robotics/hand/manipulate_touch_sensors.py </desc> <cmt> envs/__init__.py: register all handmanipulate...touchsensors envs </cmt> <cmt> manipulate_touch_sensors.py > touch_get_obs='sensordata' </cmt> <cmt> handmanipulate...touchsensors-v0 - boolean sensor readings; handmanipulate...touchsensors-v1 - original mujoco sensordata readings; </cmt>","gym/envs/robotics - handmanipulate{block, egg, pen}touchsensors-v1"
3562,<desc> fixes #14522 (this demonstrates that mocking is possible and shows how). fix a bug in test.callasyncduplexstreamingcall (reverse order of generic args). show how to create a fake client stub show how to test server-side impl classes that implement the generated server methods. </desc> <cmt> add tests demonstrating how to mock client stubs </cmt> <cmt> demonstrate testability of server-side impl classes </cmt> <iss> c# how to mock generated client base? </iss>,add c# tests that demonstrate how to unit test grpc code with test doubles.
3563,"<desc> fix #2808 for expo init and expo eject project, name is existing in app.json other than package.json. example output d:\repo\awesomeproject>react-native windows --template vnext reading application name from package.json... reading application name from app.json... reading react-native version from node_modules... microsoft reviewers: open in codeflow </desc> <cmt> read name from app.json </cmt> <cmt> change files </cmt> <iss> rnw cli doesn't detect the project name for an expo project </iss>",cli reads name from app.json if it doesn't exist in package.json
3564,"<desc> use resizeobserver when available for better and more performant resizing information, otherwise, fall back to a throttled resize event on an iframe that's the size of the player. allows a video.js user to disable this by setting resizemanager: false as an option since the component will not be initialized. this probably needs to revert #4800 (e0ed0b5) because we end up getting two playerresize events with the dimension methods now. todo: revert #4800 fix current tests make ro polyfill possible allow ro to be disabled debounce calls instead of throttle write tests documentation make sure things are disposed properly events objects </desc> <cmt> resizer </cmt> <cmt> wip </cmt> <cmt> use resize observer or iframe </cmt>",playerresize event in all cases
3565,<desc> i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> chore(sudoku): added type hints [hacktober-fest] </cmt> <cmt> updating directory.md </cmt>,added sudoku type hints [hacktober fest]
3566,"<desc> we are still using the hostcache for syntactic features, but no resolution. that means that the host can not ask about files that it did not reference in the list of rootfiles returned by getscriptfilenames(). ideally we would get rid of hostcache, but the only reason we use it is that vs does not handle normalized slashes correctly. once that is done, we can yank it. </desc> <cmt> remove host cache uses in syntactic features </cmt> <cmt> consolidate the use of normalizeslashes in lookup helpers </cmt> <cmt> remove getcurrentsourcefile and use syntaxtreecache.getcurrentsourcefile instead </cmt> <cmt> remove hostcache.getchangerange </cmt>",simplify updating the host cache for syntactic ls features
3567,"<desc> performance optimization others sorted the grad by dtype before coalescing, can decrease the number of coalescing op. besides, by reducing the number of coalesce op, the number of c_allreduce_sum op can also be reduced. all test are based on ernie3.0, pp=dp=mp=2 fp16_allreduce=true optimize_cast=true decrease in number of coalesce op number before this opt number after this opt gain card 0/4 48 6 -700% card 1/5 48 6 -700% card 2/6 120 12 -900% card 3/7 120 12 -900% one dp group 336 36 -833% loss diff performance throughput  before this opt throughput after this opt gain 39146 39232 + 0.2% </desc> <cmt> sorted the grad by dtype </cmt> <cmt> supports all dtype </cmt>",optim the grad fuse for pipeline mode by sorting the grad by dtype
3568,<desc> i have followed (at least) the pr section of the contributing guide. update autocomplete component documentation for issue closes #22443 </desc> <cmt> [autocomplete] update doc  autocomplete/autofill </cmt> <cmt> remove extra blank line </cmt> <iss> unable to disable the browser auto complete feature for the autocomplete component </iss>,improve the documentation on autocomplete/autofill
3569,<desc> silence all the remaining warnings in video_core generated by gcc 10.2.0. enforce -warray-bounds and -wmissing-field-initializers. </desc> <cmt> maxwell_to_vk: silence -wextra warnings about using different enum types </cmt> <cmt> maxwell_3d: silence array bounds warnings </cmt> <cmt> video_core: silence -wmissing-field-initializers warnings </cmt> <cmt> video_core/cmake: enforce -warray-bounds and -wmissing-field-initializers </cmt>,silence the remaining gcc warnings and enforce them
3570,"<desc> original pull-request #27298 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix bug from #23515. </cmt> <cmt> fix test from fuzzer. </cmt> <cmt> fix spellign. </cmt> <cmt> fix bug from #23515. </cmt>",cherry pick #27298 to 21.7: fix bug from #23515.
3571,"<desc> fused_elementwise_activetion can fuse some binary and unary computation. two patterns are supported: binary(x, unary(y)) and unary(binary(x, y)). paddle should detect the patterns and do the transformation automatically, but writing a pass is time-assuming. so i pose the api in contrib.layers for first benchmark. example, the computation in paddingrnn: c = pre_cell * layers.sigmoid(f) + layers.sigmoid(i) * layers.tanh(j) m = layers.tanh(c) * layers.sigmoid(o) can be replaced by: # layers.sigmoid(i) * layers.tanh(j) tmp0 = fused_elemwise_activation(x=layers.tanh(j), y=i, functor_list=['elementwise_mul','sigmoid']) # pre_cell * layers.sigmoid(f) tmp1 = fused_elemwise_activation(x=pre_cell, y=f, functor_list=['elementwise_mul','sigmoid']) c = tmp0 + tmp1 # layers.tanh(c) * layers.sigmoid(o) m = fused_elemwise_activation(x=layers.tanh(c), y=o, functor_list=['elementwise_mul','sigmoid']) </desc> <cmt> enhance fused_elementwise_activation op. </cmt> <cmt> test=develop </cmt> <cmt> move the api fused_elementwise_activation to contrib. </cmt> <cmt> test=develop </cmt>",enhance fused_elementwise_activation op and add python api in contrib.layers
3572,"<desc> this simple pr is similar to #6047. it gets rid of leftover calls to global l: in tilelayer.wms: the global call had been introduced by pr #5618. in canvas: introduced by pr #5115, while the pr #4989 that switched to es6 was in process. these should be the last references to global l, apart from l.mixin in checkdeprecatedmixinevents of class, which refers to it on purpose. </desc> <cmt> fix(tilelayerwms): get rid of l.tilelayer global call </cmt> <cmt> and rely on imported tilelayer instead. </cmt> <cmt> fix(canvas): get rid of l.stamp global call </cmt> <cmt> and rely on imported util.stamp instead. </cmt>",get rid of calls to global l
3573,<desc> it is a small change in travis.yml which migrates the build to container based infrastructure. solves #181 </desc> <cmt> migrate to container based infrastructure </cmt> <cmt> updated travis.yml to migrate build process from legacy infrastructure to container based infrastructure </cmt> <cmt> migrate to container based infrastructure </cmt>,pr for #181 migrate to container based infrastructure
3574,"<desc> use gcsclient instead of redisgcsclient in ray. closes #5058 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> modify redis gcs client usage of raylet and core worker </cmt> <cmt> modify ut usage </cmt> <cmt> rm friend class of redisgcsclient </cmt> <cmt> update comments of redisgcsclient </cmt> <cmt> add override to redisgcsclient methods </cmt>",use new interface class gcsclient in ray
3575,"<desc> this pr updates the bottom navigation semantics tests to use the matchessemantics api, which is the newer function for accomplishing the same as the previous tests. i added the following tests: 4 variants of semantics tests in the bottom navigation bar tests. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: </desc> <cmt> update semantics tests </cmt>",update bottom nav semantics tests to use matches semantics
3576,"<desc> the idea is to enqueue mini-tasks (so-called oneshots) for the stuff that should be done on a signal. these oneshots are much lighter than real tasks, because they are not run in an own thread, but they also cannot be scheduled, they simply run until they are done. i had to block signals around locking core->tasks_lock to prevent deadlocks when a signal handler is called while it is still locked. </desc> <cmt> add task oneshots </cmt> <cmt> use oneshot for cons->event_resize </cmt>",fix segfaults when resize signals occur with running background tasks
3577,"<desc> backport of #10193. fix a couple of bugs found by testing in release mode, closes #10185. bug: fix numpy.testing.assert_equal in release mode. to be complete, the nat handling needs to raise assertionerror when comparing nat's with different types. that check was previously passed on and the resulting check, which would succeed in development mode because deprecationwarning was converted to an error, warns in release mode. bug: fix test_1d_format test. the test failed for numpy installed in release mode as the pendingdeprecationwarning issued by object.format(a, '30') was no longer converted to an error. the fix here is to make the test python version dependent and suppress the warning when needed. </desc> <cmt> bug: fix test_1d_format test. </cmt> <cmt> the test failed for numpy installed in release mode as the </cmt> <cmt> pendingdeprecationwarning issued by object.__format__(a, '30') was no </cmt> <cmt> longer converted to an error. the fix here is to make the test python </cmt> <cmt> version dependent and suppress the warning when needed. </cmt> <cmt> bug: fix numpy.testing.assert_equal in release mode. </cmt> <cmt> to be complete, the nat handling needs to raise assertionerror when </cmt> <cmt> comparing nat's with different types. that check was previously passed </cmt> <cmt> on and the resulting check, which would succeed in development mode </cmt> <cmt> because deprecationwarning was converted to an error, warns in release </cmt> <cmt> mode. </cmt>",fix bugs found by testing in release mode.
3578,"<desc> this pr ensures that handlers have the correct parent.  this change does for handlers what tasks already had done. this ensures that things like the following apply to handlers: - import_role: name: thing delegate_to: localhost fixes #36518 additionally, on a small note, task_list.extend is in place and returns nothing, don't assign to t. ansible version </desc> <cmt> ensure role handlers are parented correctly. fixes #36518 </cmt> <cmt> add delegate_to test for include_role handlers </cmt> <iss> import_role with delegate_to does not run handlers on the delegated to host </iss>",ensure handlers have proper parent
3579,<desc> description: this pr removes the restriction that was in place preventing the creation of a zha device for the zigbee coordinator. this fixes a hard error on the ootb devices page when attempting to load device triggers and actions if someone selects the coordinator and it allows us to interact with the coordinator in group management in the zha configuration panel do not merge without ui pr: home-assistant/frontend#4541 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> allow zha device creation for coordinator </cmt> <cmt> don't let coordinator get removed </cmt> <cmt> fix truthy issue in logical device type </cmt>,allow zha device creation for the zigbee coordinator
3580,"<desc> these changes allow rust to generate position-independent code on riscv64 targets with code model medium. closes: #59802 see also: rust-embedded/riscv-rt#25, rust-embedded/wg#218 </desc> <cmt> update llvm: apply patches for pc-relative addressing on 64-bit risc-v </cmt> <cmt> use code model 'medium' for 64-bit risc-v targets </cmt> <iss> risc-v -mcmodel=medium </iss>",add support for pc-relative addressing on 64-bit risc-v
3581,"<desc> this allows you to customize the barrier tween for any modalroute. it currently only defaults to curves.ease. this allows for any subclass of modalroute to implement its own barriercurve. class _dialogroutewithcustombarriercurve<t> extends popuproute<t> { _dialogroutewithcustombarriercurve({ animatable<double> barriercurve, // ... }) : assert(barriercurve!= null), // ... _barriercurve = barriercurve, // ... @override animatable<double> get barriercurve => barriercurve; final animatable<double> _barriercurve; // ... related issues n/a i added the following tests: a test to validate that the default barrier tween remains as curvetween(curve: curves.ease) a test to validate that a custom barrier tween is honored. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> implement barriertween in modalroute<t> </cmt> <cmt> add modalroute default barriertween test </cmt> <cmt> add tests for custom modalroute.barriertween </cmt> <cmt> group tests </cmt>",allow for customizable modalroute barriertween
3582,"<desc> this pr updates deno doc so default exports are handled. currently only variable/function/class exports are supported and they would show up as ""default"" in the doc page. we still need to add support for expressions that are default exports: export default { foo, bar, } unfortunately it requires to change node structure. </desc> <cmt> test experiments </cmt> <cmt> export default fn </cmt>",deno doc handles default exports
3583,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""../tslint.json"" }. </desc> <cmt> add .type(func) to assertion </cmt> <cmt> check if wrapper has type </cmt>",chai-enzyme add .type(func) typing
3584,"<desc> fixes #395 this is a natural continuation of pr #446 this allows masking of the cost function for sequence to sequence learning with different lengths. it does so with an optional flag mask_cost at model.compile. </desc> <cmt> added masking to cost function </cmt> <cmt> when dealing with sequences of different lenghts, this optionally </cmt> <cmt> fixes cost function bias to the largest sequences. </cmt> <cmt> test previous commit </cmt>",optionally mask cost function for sequence to sequence learning
3585,<desc> closes #10041 this pull request seperates standalone::run logic for denort and deno_cli in a way so that deno_cli could intialize it's own ops. title can be improved. </desc> <cmt> feat(cli/standalone): initialise runtime_compiler ops for cli standalone </cmt> <cmt> quick fix </cmt> <iss> optionally support thick binaries for compile </iss>,initialize runtime_compiler ops for deno compile
3586,"<desc> the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.3.0, 2.4.2, 2.5.2, and pre-2.6 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> update it-it.h </cmt> <cmt> update pt-br.h </cmt>",shutter and pcf8574 translations for it-it and pt-br
3587,"<desc> superset has a few pages that were using  default template provided by appbuilder framework. one problem with this layout is that title, filter, pagination are all stacked row by row, which took a lot of space before actual list content. so we want to make a new list view layout, to make top section cleaner and keep all the existed functionalities. </desc> <cmt> improve superset list view page layout </cmt> <cmt> - less header spaces and stacks </cmt> <cmt> - move pagination down to bottom </cmt> <cmt> - apply material design style to 'add' action button </cmt> <cmt> - will apply to all superset list view, like slices list, security tab lists etc. </cmt> <cmt> improve superset list view page layout </cmt> <cmt> - less header spaces and stacks </cmt> <cmt> - move pagination down to bottom </cmt> <cmt> - apply material design style to 'add' action button </cmt> <cmt> - will apply to all superset list view, like slices list, security tab lists etc. </cmt>",improve superset list view content layout
3588,"<desc> with #8548 we introduced the notion of ""type guards as assertions"". this has caused a steady stream issues as users are surprised by the arguably counter-intuitive effects. with this pr we limit type guards as assertions to only affect incomplete types in control flow analysis of loops. effectively this makes type guards as assertions an implementation detail of the control flow analyzer that isn't observable in the final types computed by the checker, and #8548 is for all practical purposes revoked. for example, we now handle the following from #9246 correctly: type shape = { kind: ""circle""; radius: number } | { kind: ""rectangle""; width: number; height: number }; function area(s: shape) { if (s.kind === ""circle"") { return math.pi * s.radius ** 2; } else if (s.kind === ""rectangle"") { return s.width * s.height; } return assertnever(s);  // no error here } function assertnever(x: never): never { return x; } likewise we produce the expected never type in this example from #9869: let stringornumber: string | number = 3 > 5 ? ""a"" : 7; if (typeof stringornumber === ""number"") { if (typeof stringornumber !== ""number"") { stringornumber;  // never } } fixes #9246, #9254, #9260, #9869, #10087. (yeah, it's been causing some confusion!) </desc> <cmt> limit type guards as assertions to incomplete types in loops </cmt> <cmt> accept new baselines </cmt> <cmt> fix linting error </cmt>","limit ""type guards as assertions"" behavior"
3589,<desc> i sorted the index list and the sections below in alphabetical order. i also added a mysql link to the index. </desc> <cmt> sort sections and list </cmt> <cmt> add mysql link to the index </cmt>,sort and add mysql to index
3590,"<desc> original pull-request #13624 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> first attempt </cmt> <cmt> better </cmt> <cmt> add test </cmt> <cmt> update 00157_cache_dictionary.reference </cmt> <cmt> add locks to fix datarace </cmt> <cmt> better </cmt> <cmt> disable test with tsan because it is too slow </cmt> <cmt> update skip_list.json </cmt> <cmt> update test and bump ci </cmt> <cmt> update skip_list.json </cmt> <cmt> final fix </cmt> <cmt> cache-dictionary flap </cmt>",cherry pick #13624 to 20.5: cache-dictionary flap
3591,"<desc> hardcoded key escape sequences (such as [[a for arrow-up) serve their purpose in most cases, but not in any terminal configuration. it's a better practice to query the right codes dynamically from $terminfo instead. i expect this to become a real-world problem as soon as recent debian and ubuntu versions become used more widely: those ship with a /etc/zsh/zshrc which enables ""application mode"", in which oh-my-zsh's key bindings partially don't work. i've written down more about that problem on my blog. my commits migrate the key bindings to terminfo wherever possible. please note that in order to use $terminfo, my code hast to activate the ""application mode"" as well and might therefore break custom hardcoded key bindings. i based my work on the documentation efforts by @kylewest from pull request #889. </desc> <cmt> added documentation to key bindings. </cmt> <cmt> conflicts: </cmt> <cmt> lib/key-bindings.zsh </cmt> <cmt> forgot to save before committing. doh </cmt> <cmt> don't clobber standard esc+. behavior </cmt> <cmt> esc+. works as ""last arg"" on both bash and zsh. seems like a shame to introduce a new standard. </cmt> <cmt> conflicts: </cmt> <cmt> lib/key-bindings.zsh </cmt> <cmt> make sure the terminal is always in application mode when zle is active. </cmt>",use terminfo key codes instead of hardcoded ones for key bindings
3592,"<desc> it was reported to me by mwb that on the soldered pcb, both the backspace and left shift keys were not correct on the layout_65_ansi layout. also took the opportunity to do some minor clean ups. my code follows the code style of this project. i have read the contributing document. </desc> <cmt> both backspace and left shift matrix positions off by one </cmt> <cmt> update the led_update routine </cmt> <cmt> update readme </cmt>",think 6.5 soldered matrix fix
3593,<desc> several changes in react native 0.28 and 0.29 are not reflected in the current definition. this pr fixes that. </desc> <cmt> rn: widen limit of refreshcontrol </cmt> <cmt> rn: update navigationexperimental to 0.28 </cmt> <cmt> rn: define new method from 0.28 </cmt> <cmt> rn: promisify requestpermissions per 0.28 </cmt> <cmt> rn: remove onnavigate method </cmt> <cmt> see: </cmt> <cmt> rn: add onnavigateback method </cmt> <cmt> see: </cmt> <cmt> rn: deprecate statusbarios </cmt> <cmt> rn: update stylesheet api per 0.29 </cmt> <cmt> rn: define keyboardavoidingview added in 0.29 </cmt> <cmt> rn: define savetocameraroll added in 0.29 </cmt> <cmt> rn: define cancellable from interactionmanager </cmt> <cmt> rn: add new possible values of flexdirection </cmt> <cmt> rn: define linebreakmode </cmt> <cmt> rn: allow zindex prop </cmt> <cmt> rn: allow dimension limits </cmt>,document changes in 0.28 and 0.29 in react native
3594,"<desc> control flow analysis can easily hit circularities or exponential behaviour when requesting the contextual type of an expression. when adding an element type to an evolving array type, there is no point in checking the contextual type of the new element type because it is unknown -- it is exactly the type of the evolving array, which is in the middle of being found. fixes #14628 this is code of the form: let x = [] x[0] = { contextual: 'no' } x[1] = { contextual: 'should not check' } x[2] = { contextual: 'contextual type' } // : // : i considered adding a third parameter to gettypeofexpression and calling checkexpressionwithcontextualtype, but i decided having a new function that delegates to gettypeofexpression is less confusing. </desc> <cmt> evolving array element ignores contextual type </cmt> <cmt> control flow analysis can easily hit circularities or exponential </cmt> <cmt> behaviour when requesting the contextual type of an expression. when </cmt> <cmt> adding an element type to an evolving array type, there is no point in </cmt> <cmt> checking the contextual type of the new element type because it is </cmt> <cmt> unknown -- it is exactly the type of the evolving array, which is </cmt> <cmt> in the middle of being found. </cmt> <cmt> fixes #14628 </cmt> <cmt> this is code of the form: </cmt> <cmt> ts </cmt> <cmt> let x = [] </cmt> <cmt> x[0] = { contextual: 'no' } </cmt> <cmt> x[1] = { contextual: 'should not check' } </cmt> <cmt> x[2] = { contextual: 'contextual type' } </cmt> <cmt> // : </cmt> <cmt> // : </cmt> <cmt>  </cmt> <cmt> test: object literal assignments->expanding arrays </cmt> <cmt> previously, the compiler would run out of memory for more than 13 or 14 </cmt> <cmt> of these assignments. </cmt>",evolving array element type ignores contextual type
3595,<desc> update generatenm2.ts to create constant spec for turbo modules move react_constant and react_constant_provider to react_get_constants appstatemodule i18nmanagermodule deviceinfomodule microsoft reviewers: open in codeflow </desc> <cmt> split method validation generation to a single file </cmt> <cmt> refactor </cmt> <cmt> refactor </cmt> <cmt> generate constant spec </cmt> <cmt> update generatenm2.ts </cmt> <cmt> yarn build </cmt> <cmt> update appstatemodule </cmt> <cmt> update i18nmanagermodule </cmt> <cmt> update deviceinfomodule </cmt> <cmt> change files </cmt>,check constants in generated turbo module specs
3596,"<desc> new features others first, build the cluster graph from the cluster representation. second, build the process graph from the partitioned program. third, do the mapping between the two graphs. </desc> <cmt> [auto parallel]  add the unified cluster representation </cmt> <cmt> [auto parallel] add the graph class for physical mapping </cmt> <cmt> [auto parallel] add the simple physical mapper </cmt>",do the physical mapping between the process graph and the cluster graph
3597,<desc> backported #948 to master. </desc> <cmt> fixed npp error constants usage </cmt> <cmt> fixed constructors for functional objects (added __host__ modifier) </cmt> <cmt> rewrite core/cuda/vec_math.hpp file </cmt> <cmt> old version isn't compiled with cuda 5.5 </cmt> <cmt> new version doesn't depend on functional.hpp </cmt> <cmt> fixed broxopticalflow regression test </cmt> <cmt> the output of broxopticalflow differs a bit in cuda 5.5 </cmt> <cmt> fixed boxfilter sanity test (different rounding results) </cmt> <cmt> fixed broxopticalflow sanity test (increase epsilon value) </cmt>,fixed gpu modules build with cuda 5.5 rc (master branch)
3598,"<desc> gitpython did a new release which breaks our tests:  see:  pinning gitpython for now to make circle ci work did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> fix_torch_device_generate_test </cmt> <cmt> remove @ </cmt> <cmt> pin git python </cmt>",pin git python to <3.1.19
3599,<desc> #11520 edit: a change to the defaults of a public method needs to go through the deprecation cycle. this pr has been revised to update the docstring and introduce a futurewarning to power_transform(). looks like the function version of powertransformer wasn't updated when yeo-johnson was added. just matching the defaults and updating the docstring with this pr. congrats on the 0.20 release!! </desc> <cmt> fix make yeo-johnson default in power_transform() </cmt> <cmt> doc update power_transform() docstring </cmt> <cmt> tst update power_transform() tests with new default </cmt>,fix update power_transform docstring and add futurewarning
3600,"<desc> this pull request provides two fixes: prevents cmake from not allowing to create debs due to treating rbpi differently to linux. wiiremote was not build and thus packaging was failing, due to not having the wiiremote target defined. this will also require a backport to v17. pr: #11332 forum topic:  see above built kodi with cpack_generator=deb option. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document </desc> <cmt> [cmake] allow rbpi platform to create deb packages </cmt> <cmt> [rpi] adds symlink to linux/extratargets.cmake so it doen't break on building and packaging wiiremote </cmt>",fixes cpack support and wiiremote packaging for rpi
3601,"<desc> this did not just work because we build libsdl2_mixer_ogg etc., with a suffix for the codecs we build in. this pr adds an explicit mapping to handle such cases. also improve the test to check this, and add a lot more checks there, like that we don't use sdl1 somehow (which can happen with files like this where the sdl1 and sdl2 apis agree, and so sdl2 does not need to be linked in to get a running executable). fixes #12589 </desc> <cmt> auto [ci skip] </cmt> <cmt> fixes #12589 </cmt> <cmt> test </cmt> <cmt> test </cmt> <cmt> changelog </cmt> <iss> support -lsdl2_mixer and others </iss>",allow linking with -lsdl2_mixer to work properly
3602,"<desc> add error message when there are conflicting star exports (fixes #7562) use tracked reexport target for sideeffectsplugin improves handled cases regarding dynamic modules display reexport target in module info header (output.pathinfo) refactoring, bugfix, feature yes no optimization.sideeffects depends on optimization.providedexports </desc> <cmt> track the target binding of harmony reexports </cmt> <cmt> display target binding in module info header </cmt> <cmt> check conflicting star exports (fixes #7562) when statically known </cmt> <cmt> add test case </cmt> <cmt> store multiple targets per exportinfo </cmt> <cmt> resolve target when reading </cmt> <cmt> replace recursion with loop </cmt> <cmt> fix bug in target tracking </cmt> <cmt> use target info to implement side effects plugin </cmt> <cmt> improve test case </cmt> <cmt> update snapshots </cmt> <cmt> add another test case </cmt> <iss> conflicting esm star re-exports should yield a syntaxerror </iss>",track reexport target during providedexports analysis
3603,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> added missing params from statuses/update </cmt> <cmt>  </cmt> <cmt> made all params optional and changed types </cmt>",add properties to params interface in twit package to support the statuses/update endpoint
3604,"<desc> description: this pr introduces the initial implementation of an api listener based on the proto configuration merged in #8170. notably, this pr introduces the ability to add only one api listener via bootstrap config only. this decision was made in order to iterate into more complex setups (multiple listeners, lds supplied listeners) in subsequent prs. moreover, the api listener is created in the context of envoy's main thread not worker threads. a first use of this api listener can be seen in envoyproxy/envoy-mobile#616. risk level: low, only used in envoy mobile. the risk here is about building something generally useful and flexible. note however that a couple of things were rejiggered in the hcm. testing: unit and integration tests. additional testing in  docs changes: added inline comments and todos. proto documentation is up-to-date. release notes: similar to doc changes. </desc> <cmt> wip: get an api listener at all costs </cmt> <cmt> fmt build </cmt> <cmt> building and worksgit add source/! :tada: </cmt> <cmt> initial clean up. builds, tested </cmt> <cmt> fmt </cmt> <cmt> back to singleton. apilistener and apilistenerhandle interfaces </cmt> <cmt> fmt </cmt> <cmt> comments </cmt> <cmt> comments split up </cmt> <cmt> move read callbacks outside of the lambda </cmt> <cmt> comment </cmt> <cmt> fmt </cmt> <cmt> change api listener to implemented </cmt>",first implementation of an api listener
3605,<desc> switches rustup to using the beta channel by default. includes #23824 for the implementation. cc #20453 closes #21149 </desc> <cmt> rustup: fix comment about darwin's uname -m </cmt> <cmt> add support for channel selection </cmt> <iss> update rustup.sh for beta </iss>,default to the beta channel
3606,"<desc> this pr: adds support for running an rllib policy server with n listen ports (n workers) accepting one or more client connections. makes sure that in case not all ports have active client connections (or incoming data in general), learning on the server can still continue (not blocked) on all other workers using whatever data comes in from different clients. removes the need to create a randomenv dummy env on the server, only to specify the action/observation space through that env. the spaces can be given now in the config. in a future pr, action and observation spaces will be sent from connected clients and may not be specified at all anymore on the server side. updates the cartpole server/client example script to show how a multi-port setup can be achieved. also enhances the policy server/client test cases to 3 connected clients (from just 1) connecting to different ports. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> # conflicts: </cmt> <cmt> #	rllib/evaluation/sampler.py </cmt> <cmt> # conflicts: </cmt> <cmt> #	rllib/evaluation/sampler.py </cmt> <cmt> # conflicts: </cmt> <cmt> #	rllib/evaluation/rollout_worker.py </cmt> <cmt> fix and lint </cmt> <cmt> fix and lint </cmt> <cmt> fix and lint </cmt>",external env enhancements + more examples.
3607,"<desc> we currently contextually type un-annotated iife parameters by their corresponding arguments. this pr expands upon this concept by inferring un-annotated iife parameter with missing arguments as optional. that allows us to handle the following common idiom with no errors: let foo = (function (window, undefined) { // body })(window); without this pr the example is an error because the undefined isn't marked optional. note that the pr also simplifies some overly complicated logic for computing the minargcount property in signatures. </desc> <cmt> allow missing argument for iife parameter with no type annotation </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt>",infer optional types for iife parameters with missing arguments
3608,<desc> the gatsby-node for the wp plugin was meant to be a jumping off point that didn't include any logic. this pr refactors that file so that continues to be the case. it also allows us to reuse this first-supported-api-name logic for any node api in the future if framework adds new node api's. </desc> <cmt> abstract using multiple lifecycle api names for any node api's </cmt> <cmt> add example </cmt>,refactor logic for supported node api names
3609,"<desc> inspired by this. while writing tests i've found some inconsistency between default value of param in c++ code and sklearn wrapper: bagging_freq, default=0, type=int, alias=subsample_freq subsample_freq : int, optional (default=1) also sklearn description says: ""frequence of subsample, <=0 means no enable."", but on c++ side there is a validation check(bagging_freq >= 0); @guolinke which side should be fixed? even after bringing the consistency in subsample_freq tests fail. for instance, after first predict we have res_engine[0][0] >>> 0.0013241289219269466 res_sklearn[0][0] >>> 0.0013241290058445348 also, is there any way to test pred_parameter works? as i understand, there is no validation for keywords in booster.predict(). </desc> <cmt> fixed docs </cmt> <cmt> reworker predict method of sklearn wrapper </cmt> <cmt> fixed encapsulation </cmt> <cmt> added test </cmt> <cmt> fixed consistency between docstring and params docs </cmt> <cmt> fixed verbose </cmt> <cmt> replaced predict_proba with predict in test </cmt> <cmt> fixed verbose again </cmt>",reworked predict method in sklearn wrapper and docs improvements
3610,<desc> this pr fix managing of ownstate in explore page before chart was saved includes db migration (follow approval process in sip-59) </desc> <cmt> fix:fix get permission function </cmt> <cmt>  conflicts: </cmt> <cmt> 	superset-frontend/src/dashboard/util/getpermissions.ts </cmt> <cmt> fix: fix ownstate for unsaved explore chart </cmt>,fix explore state - backend pagination checkbox in table
3611,"<desc> there are a couple of core worker tests that are not quite stable, including testdirectactortaskcrossnodesreconstruction, testdirectactortaskcrossnodesnoreturnperformance .etc, basically the ones that are using waitfordirectcallactorstate() in core_worker_test.cc. the problem is that sometimes the notification for the actor creation is not received by the core worker, thus these tests timeout after 30 seconds.  the underlying issue is subscribe and other operations use different redis contexts, thus it's not guaranteed that which one gets processed earlier. if the requestnotification is processed earlier than subscribe request, then the core worker will not receive the initial notification. this can be fixed by making sure the requestnotification is only called after subscribe is finished. because there can be multiple requestnotification requests (subscribing different ids) submitted before the done callback for subscribe request is invoked, thus we use a list to cache the requestnotification requests when the subscribe request's done callback is not called yet. </desc> <cmt> fix gcs client subscribe </cmt> <cmt> fix build </cmt> <cmt> format </cmt>",fix flaky core worker tests because of race condition in gcs client subscription
3612,"<desc> bias tensor reorder overhead in int8 inference is significant, especially for low latency models (i.e. mobilenet). the reorder primitive is used to quantize fp32 bias tensor into int8. by caching the reordered bias tensor, int8 models' latency got significant improvement. </desc> <cmt> bias cache implemented. </cmt> <cmt> remove useless comment lines. </cmt> <cmt> add test cases. </cmt> <cmt> remove debug log lines. </cmt> <cmt> add 'const' qualifier to 'scaled_bias'. </cmt> <cmt> do not cache bias_md anymore. </cmt> <cmt> add comments to note: currently we're not inspecting the persistent tensor </cmt> <cmt> contents to see if the cached data is being resued. </cmt> <cmt> add attr ""is_bias_const"" to _mklquantizedconv* ops. </cmt> <cmt> fix a typo: 'is_filter_const' should be 'is_bias_const'. </cmt> <cmt> fix clang format issues of mkl_fused_ops_test.cc </cmt> <cmt> port bias reorder code to mkl-dnn v1.x </cmt>",cache bias tensor for int8 inference
3613,"<desc> please see #19146 (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #19041 #19146 was missing this, because if we keep quote we still get empty quotes as values for clusterip. as it stands we will still wind up with clusterip: """" if no value is provided ... just {{ . }} is better since it will not add clusterip to rendered files if no value is provided, but the user needs to quote any provided values themselves also forgot to do it for metrics service in previous pr dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> no empty string clusterip </cmt> <cmt> no empty quotes value for clusterip </cmt> <iss> [stable/nginx-ingress] cannot upgrade release with helm 3 </iss>",nginx ingress no empty quotes clusterip
3614,"<desc> i saw that in the java version there was the factorial algorithm, so, i thought that it would be nice to have the same but this time made with c. and i also made a fibonacci algorithm that asks for a number and than it tells which number is in the n position according to the fibonacci sequence. hope you like it :) </desc> <cmt> add a factorial algorithm </cmt> <cmt> add a fibonacci algorithm </cmt>",add 2 more algorithms (fibonacci and factorial)
3615,<desc> description: fixes and error where devices exposed to emulated hue without a friendly name attribute set would cause emulated hue to fail. related issue (if applicable): fixes # fixes #4787 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> get entity name from entity.name </cmt> <cmt> grabbing the attr_friendly_name directly produces an error. instead </cmt> <cmt> grab from entity.name. </cmt> <iss> emulated_hue error with google home </iss>,emulated_hue friendly_name key error fix
3616,"<desc> fixes #18072 adds support for the suggestions stated in #18072 when an unknown category is encountered and there is a dropped category, then the unknown category will be encoded as the dropped category. (all zeros) the inverse transform will map all zeros to the dropped category if a category was dropped. </desc> <cmt> wip </cmt> <cmt> enh adds support for handle_unknown=ignore and drop </cmt> <cmt> enh adds inverse_tranform with dropped category </cmt> <iss> drop must be none for onehotencoder to utilize handle_unknown = 'ignore' </iss>",enh adds support for drop + handle_unknown=ignore in the onehotencoder
3617,"<desc> since version 0.7.0, xmldom is published to npm as @xmldom/xmldom and no longer as xmldom, because the package owners are no longer able to publish xmldom. see xmldom/xmldom#271 for more information. we need to upgrade our xmldom dependencies to mitigate cve-2021-32796. see ghsa-5fg8-2547-mr8q. this issue was partially mitigated by commit bfc26ac, but that commit did not bump the version of xmldom used by @react-native-windows/cli. this pr does do. we would also need to backport this all the way back to 0.63 to mitigate security component governance alerts in internal dependent repos. microsoft reviewers: open in codeflow </desc> <cmt> bump xmldom to 0.7.0 in @react-native-windows/cli. </cmt> <cmt> change files </cmt>",bump the version of xmldom used by @react-native-windows/cli to 0.7.0.
3618,"<desc> this is reduced version of #5694. only obvious fixes. </desc> <cmt> [vfs] [win32] win32file: really support ""test"" read() and write() with zero buffer size </cmt> <cmt> [vfs] [win32] win32file: better handle partially read/written buffer in read()/write() </cmt> <cmt> [vfs] cfile: workaround in read() and write() for vfses that do not support null buffer pointer </cmt> <cmt> [emufnc] dll_read(): set errno if read() failed </cmt> <cmt> [emufnc] dll_write(): set errno if write() failed </cmt> <cmt> [emufnc] fix: ""-1"" is incorrect return value for dll_fwrite() and dll_fread() (return type is size_t) </cmt> <cmt> [emufnc] fix: return zero for dll_fread()/dll_fwrite() if size or count is zero </cmt> <cmt> [emufnc] fix: always read all data in dll_fread() </cmt> <cmt> [emufnc] fix: always read all data in dll_fwrite() </cmt> <cmt> [emufnc] fix: return correct value in dll_fclose() </cmt> <cmt> [emufnc] fixes: correctly emulate on bigendian platforms, use cast to _unsigned_ char in dll_fputc() </cmt> <cmt> [emufnc] use proper macro instead of hardcoded value in dll_ungetc() </cmt> <cmt> [emufnc] fix: use correct return value on error in dll_filbuf, try to restore proper file pointer </cmt> <cmt> [emufnc] fix: use correct return value on error in dll_flsbuf, flush file buffers, properly write data </cmt>",even better emulate posix file functions (reduced)
3619,<desc> just come across this comment </desc> <cmt> [sema] adding deprecation warning for protocol inheritance class keyword syntax </cmt> <cmt> [test] adjusting test files where class syntax is used for protocol inheritance </cmt> <cmt> [test] adding specific tests for the warning for protocol inheritance class keyword syntax deprecation </cmt> <cmt> [test] adjusting stdlib ocurrences where class syntax is used for protocol inheritance </cmt>,adding deprecation warning for protocol inheritance 'class' syntax
3620,"<desc> cherry pick of #102306 #102465 on release-1.21. #102306: return unschedulableandunresolvable instead of error when #102465: return unschedulableandunresolvable when looking up part of #102305 for details on the cherry pick process, see the cherry pick requests page. </desc> <cmt> return unschedulableandunresolvable instead of error when failing to lookup pvc or storageclass in volumezone plugin </cmt> <cmt> return unschedulableandunresolvable when looking up volume-related resources returns notfound error </cmt>","return unschedulableandunresolvable instead of error when
#102465: return unschedulableandunresolvable when looking up"
3621,<desc> recently we have noticed multiple instances where kafkaproducers have failed to constructer due to the following exception: org.apache.kafka.common.kafkaexception: failed to construct kafka producer at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:440) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:291) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:318) java.base/java.lang.thread.run(thread.java:832) caused by: java.util.concurrentmodificationexception at java.base/java.util.hashmap$hashiterator.nextnode(hashmap.java:1584) at java.base/java.util.hashmap$keyiterator.next(hashmap.java:1607) at java.base/java.util.abstractset.removeall(abstractset.java:171) at org.apache.kafka.common.config.abstractconfig.unused(abstractconfig.java:221) at org.apache.kafka.common.config.abstractconfig.logunused(abstractconfig.java:379) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:433) ... 9 more exception.class:org.apache.kafka.common.kafkaexception exception.message:failed to construct kafka producer this is due to the fact that used below is a synchronized set. used is being modified while removeall is being called. this is due to the use of recordingmap in the sender thread (see below). switching to a concurrenthashset avoids this issue as it support concurrent iteration. at org.apache.kafka.clients.producer.producerconfig.ignore(producerconfig.java:569) at org.apache.kafka.common.config.abstractconfig$recordingmap.get(abstractconfig.java:638) at org.apache.kafka.common.network.channelbuilders.createprincipalbuilder(channelbuilders.java:242) at org.apache.kafka.common.network.plaintextchannelbuilder$plaintextauthenticator.<init>(plaintextchannelbuilder.java:96) at org.apache.kafka.common.network.plaintextchannelbuilder$plaintextauthenticator.<init>(plaintextchannelbuilder.java:89) at org.apache.kafka.common.network.plaintextchannelbuilder.lambda$buildchannel$0(plaintextchannelbuilder.java:66) at org.apache.kafka.common.network.kafkachannel.<init>(kafkachannel.java:174) at org.apache.kafka.common.network.kafkachannel.<init>(kafkachannel.java:164) at org.apache.kafka.common.network.plaintextchannelbuilder.buildchannel(plaintextchannelbuilder.java:79) at org.apache.kafka.common.network.plaintextchannelbuilder.buildchannel(plaintextchannelbuilder.java:67) at org.apache.kafka.common.network.selector.buildandattachkafkachannel(selector.java:356) at org.apache.kafka.common.network.selector.registerchannel(selector.java:347) at org.apache.kafka.common.network.selector.connect(selector.java:274) at org.apache.kafka.clients.networkclient.initiateconnect(networkclient.java:1097) at org.apache.kafka.clients.networkclient.access$700(networkclient.java:87) at org.apache.kafka.clients.networkclient$defaultmetadataupdater.maybeupdate(networkclient.java:1276) at org.apache.kafka.clients.networkclient$defaultmetadataupdater.maybeupdate(networkclient.java:1164) at org.apache.kafka.clients.networkclient.poll(networkclient.java:637) at org.apache.kafka.clients.producer.internals.sender.runonce(sender.java:327) at org.apache.kafka.clients.producer.internals.sender.run(sender.java:242) </desc> <cmt> wip </cmt> <cmt> kafka-12791: fix concurrentmodificationexception in abstractconfig </cmt>,concurrentmodificationexception in abstractconfig use by kafkaproducer
3622,"<desc> bpo-30721 added a ""did you mean ...?"" suggestion to rshift typeerror messages that triggers when the lhs is a python c function called ""print"". since this custom error message is expected to be triggered primarily by attempts to use python 2 print redirection syntax in python 3, and is incredibly unlikely to be encountered otherwise, it is also being backported to the next 3.6 maintenance release. </desc> <cmt> bpo-30721: show correct syntax hint in py3 when using py2 redirection syntax (#2345) </cmt> <cmt> bpo-30721: add missing '?' to new error message (gh-3131) </cmt>",backport custom print rshift message
3623,"<desc> this is an initial stab at splitting the autoscaler public/private interface. it moves most of autoscaler (verbatim) into _private, and exposes tags.py, node_provider.py, and a new sdk.py. the public interface should be considered wip at this point pending refinement. since this pr is moving a lot of files, we should try to merge it quickly and iterate. closes #10837 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for </desc> <cmt> move </cmt> <cmt> update </cmt> <cmt> wip </cmt> <cmt> fix </cmt> <cmt> add sdk </cmt> <cmt> update </cmt> <cmt> fix up imports </cmt> <cmt> audit </cmt> <cmt> fix </cmt> <cmt> lint </cmt> <cmt> wip </cmt> <cmt> fix tests </cmt> <iss> [autoscaler] expose stable public api, move internals to _private package </iss>",split autoscaler interface public private
3624,<desc> related issue: #10331 #15850 #17158 #17586 #17958 #20997 adreno drivers do not handle gl_frontfacing properly so we need a workaround. i've made sure that the models in #17804 look correct. </desc> <cmt> shaderchunk: gl_frontfacing workaround. </cmt> <cmt> shaderchunk: use gl_frontfacing workaround everywhere. </cmt>,workaround for adreno gpus gl_frontfacing bug.
3625,"<desc> (i'm finally following up on #11090, noticed that we do not do libcryptsetup debug logging correctly) </desc> <cmt> basic/log: fix systemd_log_* parsing error messages </cmt> <cmt> (likely a copy-paste gone wrong) </cmt> <cmt> cryptsetup: set libcryptsetup global log callback too </cmt>",properly handle libcryptsetup debug logging
3626,"<desc> we recently had two migrations merged into master that had the same upstream migration. this pr: adds a merge migration. adds a unit test to catch such cases in the future. #5317, #5267 </desc> <cmt> add unit test to test for multi-head migrations issue </cmt> <cmt> add merge migration </cmt>",add a merge migration to solve multi head issue
3627,"<desc> it has turned out that h2o has stopped sending tls alerts upon handshake failure, when a recent version of openssl is being used (the issue known to happen in 1.1.0g, but not in 1.1.0d). see #1865 (comment) for how it happens. this pr brushes up the fix proposed in #1865 as well as adding a test. </desc> <cmt> add failing test that fails only with openssl newer than 1.1.0g (likely) </cmt> <cmt> send the tls alert on handshake errors </cmt> <cmt> use dedicated callback </cmt> <cmt> use the exact same error string as we do now </cmt> <cmt> report the *first* fatal error </cmt>",send tls alert on handshake failure when recent versions of openssl is used
3628,"<desc> the enhanced sourcekitd requests are editoropen and edtiorreplacetext. in these two requests, the clients can specify a flag ""key. enablesyntaxtree = 1"" to get a serialize libsyntax tree with the response. to help this integration, we added a function in syntaxparsingcontext to explicitly finalize the creation of a sourcefilesyntax to incorporate the fact that sourcekit needs the tree before its destroying the parser instance. to test this integration, we diff the syntax tree serialized from the frontend action and the tree serialized from a sourcekitd response. they should be identical. </desc> <cmt> libsyntax integration with sourcekit </cmt> <cmt> add test. </cmt> <cmt> make it lazy. </cmt> <cmt> add documentation. </cmt>",integrating libsyntax representation of a source file with several sourcekitd syntax request.s
3629,"<desc> userrolemapper.userdata is constructed by each realm and it is used to ""match"" role mapping expressions that eventually supply the role names of the principal. null values as group names or metadata values were not properly supported. most of the time they were filtered out, but under some circumstances they might cause npes (depending of how the oidc and saml's underlying libraries parse purposefully crafted assertions - these libraries don't have internal null checks the same way that the unboundid library does). this pr enforces non-null collection values (lists and maps) earliest in the process and utilizes java 9 unmodifiable collections api, with the goal of eliminating redundant null filtering and repeated wrapping incolllections.unmodifiable* . </desc> <cmt> wip all but saml </cmt> <cmt> groups don't dig nulls </cmt> <cmt> kerberos and ldap metadata </cmt> <cmt> oidc metadata </cmt> <cmt> done </cmt> <cmt> nits </cmt>",userrolemapper non-null groups and metadata
3630,"<desc> as requested, adding in the parameters required to claim a node immediately after installation as part of using kickstart.sh or kickstart-static64.sh or calling netdata-install.sh manually. component name area/docs area/packaging </desc> <cmt> add section to kickstart doc </cmt> <cmt> add to kickstart64 </cmt> <cmt> add section to manual, add examples </cmt>",add documentation for claiming during kickstart installation
3631,"<desc> this pr is a subset of #25586. when performing internal patches, we noticed it touches a large number of internal build targets so that they can depend on the new targets introduced in #25586. the downside is that it also involves a large number of reviewers which will make the rollback process slow and difficult. in order to ease the process, in this pr, we introduced new empty targets that will be depended by internal targets, which will be sufficient to make internal changes via lsc. note that this pr includes the minimum code changes needed to successfully build the new targets. </desc> <cmt> add empty targets </cmt> <cmt> fix format error </cmt>",introduce empty targets to ease the internal merge of #25586
3632,"<desc> fixes issue #9193 i could use some extra eyeballs and feedback on this, i'm not entirely familiar with the schema dumper. thanks for your time </desc> <cmt> add some tests to enumerate how extensions should be stored in the schema output </cmt> <cmt> improve tests to check for existence of extensions method, and skip testing dumped extensions if they are unsupported by the database </cmt> <cmt> add activerecord::abstractadapter#extensions and activerecord::connectionadapters::postgresqladapter#extensions to allow dumping of enabled extensions to schema.rb, add activerecord::schemadumper#extensions to dump extensions to schema.rb </cmt>",adding database extension support to schema.rb
3633,"<desc> hi! here's what the three commits are doing: c8ee20a: trivial fix, add a missing break; in the option parsing. i noticed that the option in question, -r is not documented and given the --depth option possibly useless anyway. bcd8e2d: remove strlcat and strlcpy once again. these were removed in 579af6d and added back again in d5625e4. linux does not have these, so we can't use them. my solution is to use manual memcpying, which saves some unnecessary hunting for the null terminator that strlcat would have to do. 29f9ae1: this is the major one. in non-literal mode, the -w option, translates to a set of \bs around the regexp, which means that the word has to lie at word-character boundaries. it makes sense to keep the same semantics for literal mode, especially given that literal mode is enabled implicitly if the query has no regex special characters. the old behaviour is that the match must be surrounded by whitespace characters. </desc> <cmt> options.c: fix unintentional switch fallthrough </cmt> <cmt> affects undocumented options -r, -r, which are slightly unnecessary anyway </cmt> <cmt> make it compile on linux (has no strl{cpy,cat}) </cmt> <cmt> replacement is also a little faster: </cmt> <cmt> does not search for null terminator twice unnecessarily </cmt> <cmt> fix semantics of -w on literals </cmt> <cmt> ensure the meaning is the same as when using regexes, i.e. look at </cmt> <cmt> whether start and end of the match are both at word-char / non-word-char </cmt> <cmt> boundaries. should also improve performance a little bit. </cmt>","""-w"" fix; remove strlcat once again; option parsing switch fallthrough fix"
3634,"<desc> the problem with my previous pr (#36517) was when you were using nested objects, they have to be specified as full objects with all props. this pr fixes that. however, this requires typescript 2.8 which adds support for mapped types. i had to update all other definitions depending on mongoose. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). </desc> <cmt> add deep partial </cmt> <cmt> change typescript version to 2.8 </cmt> <cmt> change connect-mongo typescript version to 2.8 </cmt> <cmt> change joigoose typescript version to 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update packages depending on mongoose to ts 2.8 </cmt> <cmt> update test to cover deep partial </cmt> <cmt> restore format </cmt>",accept deep partial in model interface
3635,"<desc> fix travis deployment condition condition: $multiplatform_jars = 1 || $mac_jars = 1 and bring back java dist commit. the previous condition: $multiplatform_jars = 1 || $mac_jars=1 cause master ci failure. the correct condition should be condition: $multiplatform_jars = 1 || $mac_jars = 1 #9758 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> revert ""revert ""[dist] swap mac/linux wheel build order (#9746)"" and ""fix package and upload ray jar (#9742)"" (#9758)"" </cmt> <cmt> this reverts commit 423dc96cc44b26e3696d80d31b02d194ffafc926. </cmt> <cmt> fix deploy </cmt>",fix travis deploy for java dist
3636,<desc> mcu & flash speed entrys are not needed anymore in platformio ini files the correct values are defined in the boards.json the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> remove redundant speed settings (mcu & flash) from platformio </cmt> <cmt> since it is in boards </cmt>,remove redundant entrys from platformio
3637,"<desc> adds two new aliases: npm info and npm search the realize the aliases themselves may not be ideal in differentiating them from others. i attempted to find a balance between easy/memorable, while also trying to avoid collisions with other aliases. i'm definitely open to feedback if others feel strongly for better-named aliases. thanks! </desc> <cmt> npm: add aliases for search and info </cmt> <cmt> npm: update table of aliases </cmt>",add aliases for npm search and npm info
3638,"<desc> following the steps in the guide, errors will occur running the workflow due to these syntax problems. example failed run with the guide syntax for environment variables before these changes:  example successful run with the updated environment variable syntax reflected in this pr:  example failed run with the output redirect to $github_env before these changes:  example successful (step) with the updated ::set-ouput syntax reflected in this pr:  syntax of environment variables used in jobs.<job_id>.steps[*].with, from $env_var to ${{ env.env_var }} fix to output command, from redirecting to $github_env to using ::set-output name=variable:: i have reviewed my changes in staging. (look for the deploy-to-heroku link in your pull request, then click view deployment) for content changes, i have reviewed the localization checklist for content changes, i have reviewed the content style guide for github docs. direct link to staging deploy: </desc> <cmt> use env context syntax for step variables </cmt> <cmt> top-level environment variables cannot be referenced from jobs.<job_id>.steps[*].with using the direct environment variable syntax (e.g. $aws_region) </cmt> <cmt> ::set-output to send image name to steps context </cmt> <cmt> redirecting to $github_env does not populate the ${{ steps.[*].outputs.* }} context </cmt>",updates to aws ecs deploy guide
3639,"<desc> from auto-562 and im, another business unit decided to use our service account for docker hub, and they blew through our rate limits. eosio builds are now stuck anywhere that we are hitting docker hub for manifest queries or pulls. this pull request edits the pipeline code to only query our mirror, except in cases where no mirror is specified or where the image does not exist. this should unblock nearly all builds. see also pull request 10044 -- eos:develop pull request 10046 -- eos:release/2.1.x pull request 10047 -- eos:release/2.0.x pull request 10048 -- eos:release/1.8.x select one: ci. select any that apply: none. none. none. </desc> <cmt> build: don't check manifests at docker hub unless absolutely necessary </cmt> <cmt> simplify variables </cmt> <cmt> bug fixes </cmt> <cmt> generic names </cmt> <cmt> avoid hitting docker hub in docker tag/label step, where possible </cmt>",reduce docker hub manifest queries
3640,"<desc> new module pull request network/aos/aos_device ansible version ansible 2.3.0 (aos_device_clean de9d90c9e6) last updated 2017/02/10 15:59:02 (gmt -700) config file = configured module search path = default w/o overrides i'm working for apstra, we are making a product to automate datacenter networks and we are developed a dozen of ansible modules and one dynamic inventory to control our product with ansible. we have tried to follow ansible's best practices as much as possible, all our modules are idempotent and support the mode --check. currently, this module has limited features but the few it has are very useful :). we have implemented the parameter state even if it only supports 1 state right because we know that we will add more very soon, unfortunately it won't be ready for the 2.3 deadline. this is the third batch of modules that i'm submitting for review, the first aos_ip_pool #21044 has been recently approved. </desc> <cmt> initial version of aos_device </cmt> <cmt> clean up documentation </cmt> <cmt> move try/except closer to device.approve </cmt> <cmt> remove non valid characters </cmt>",aos_device as part of network/aos
3641,<desc> first commit fix log and gui strings. second commit fix log and fix potential bug when some incompatible locales settings (system/user/xbmc). </desc> <cmt> [win32] network::gethostname: convert result to utf-8 </cmt> <cmt> [win32] winsystemwin32 use widestring functions instead of ansi </cmt>,fix ansi used as utf-8
3642,"<desc> this pull request updates the expiration date of the wp8/universal app project certificates. from:  renewing a certificate the default certificate that visual studio generates expires one year after the date on which the certificate was created. before the certificate expires, you must use the app manifest designer to either regenerate the certificate or, as the previous procedure describes, provide a different, valid certificate. to renew the certificate in solution explorer, open the shortcut menu for the .appxmanifest file, choose open with, and then choose app manifest designer. in the app manifest designer, choose the packaging tab, and then choose the choose certificate button. in the choose certificate dialog box, expand the configure certificate list, and then choose create test certificate. in the create test certificate dialog box, click the ok button. visual studio regenerates the certificate with a new expiration date. </desc> <cmt> updated expiration date of project certificates </cmt>",v3 updated expiration date of wp8/universal app project certificates
3643,"<desc> and included are some sample userspace files that include my _keymap ""hack"" </desc> <cmt> cleanup of keymaps </cmt> <cmt> fix merge </cmt> <cmt> remove tap dance from orthodox keymap </cmt> <cmt> cleaned up userspace and keymaps </cmt> <cmt> added sample (template)userspace files to my folder </cmt>",cleaned uppersonal userspace and keymaps
3644,<desc> commit message: this is a follow up (performance nit) after #13423. this builds the replacement map on the first use. additional description: #13423 (comment) risk level: low testing: existing tests docs changes: n/a release notes: n/a </desc> <cmt> stream_info: build replacement map once </cmt> <cmt> this is a follow up (performance nit) after #13423. </cmt> <cmt> newlines </cmt>,build replacement map on first use
3645,"<desc> this pr marks features commented as deprecated with attributes; [[deprecated]] if compiled with c++14 and __attribute__((deprecated)) or __declspec(deprecated) if not. i was able to replace most of the cases where deprecated functionality was used in the library, but one case lingers:  arg_map::init takes const basic_format_args<context>& as its sole argument, which can only be extracted from context_base with the deprecated member function args(). </desc> <cmt> replace comments regarding deprecation with attributes </cmt> <cmt> remove use cases of deprecated functionality </cmt>",mark deprecated functionality with attributes and remove usage of such features
3646,<desc> i hereby agree to the terms of the cla available at:  category: short description: added possibility to init a clickhouse instance which requires authentication. duplicated: #5321 detailed description: changes make it possible to provide environment variables clickhouse_user & clickhouse_password that will be used for clickhouse-client during initialization. </desc> <cmt> pr #5321 fix </cmt> <cmt> update documentation for docker image </cmt> <cmt> update documentation for docker image: fix </cmt>,add auth support for init script: fix pr #5321
3647,"<desc> this pr improves nuxt ts support by adding a build option useforktschecker that enable type checking thanks to fork-ts-checker-webpack-plugin. type checking makes you able to know if there is ts related errors within your code, which means that without it you may have nuxt webpack compilation succeed, but the errors only reported at runtime and not in an elegant way. the type checker will check your code each time you make changes. in other terms, it's trigerred after each new webpack compilation. usage // nuxt.config.js export default { build: { useforktschecker: true } } useforktschecker can either be a boolean or an object. if it's an object, it will override the plugin options // nuxt.config.js export default { build: { useforktschecker: { silent: true, tslint: false } } } example of an error reported by the type checker project requirements to use this feature the fork-ts-checker-webpack-plugin is used/enabled only if the user project meets these requirements : useforktschecker option is enabled (true) in the nuxt configuration file ts-loader is configured with the transpileonly mode (to not have double type checkers) fork-ts-checker-webpack-plugin (and also tslint) devdependencies are installed if the two first rules are fulfilled but not the latter, a warning will let you know that your project is missing the dependencies required : documentation related to this pr will come later as a whole ts support documentation. </desc> <cmt> wip </cmt> <cmt> further work </cmt> <cmt> fix lint </cmt> <cmt> useforktschecker only when ts-loader is in transpileonly mode </cmt> <cmt> more understandable code (move console.warn location) </cmt>",provide type checking through fork-ts-checker-webpack-plugin
3648,"<desc> #10111 hi @tristazero, @wgy8283335. i've added sql definition for select statement's with clause. please check it. i'll change them based on your feedback. added sql definition for select statement's with clause. added test cases for with clause. i asserted subquery in the withclauseassert. in the sqlserverdmlstatementsqlvisitor, i changed the subquerysegment's start and stop indices by getting from cteclauses()'s subquery(). </desc> <cmt> add definition for with clause </cmt> <cmt> add start, stop indices for subquery segment </cmt>",add with clause for oracle select statement
3649,"<desc> this adds api entries for managing the in-memory list of ignore rules for a repository, along with tests for those apis. this also implements core git's newly introduced default value for the core.excludesfile config setting. </desc> <cmt> add public api for internal ignores </cmt> <cmt> this creates a public api for adding to the internal ignores </cmt> <cmt> list, which already existing but was not accessible. </cmt> <cmt> this adds the new default value for core.excludesfile also. </cmt> <cmt> wrap up ignore api and add tests </cmt> <cmt> this fills out the ignore api and adds tests. </cmt>",api for managing in-memory ignore rules
3650,<desc> a typing file for google sign-in api: </desc> <cmt> initial creation of new gapi.auth2 types </cmt> <cmt> add auth2 typings file </cmt> <cmt> let's try this as an interface instead </cmt> <cmt> initial test creation </cmt> <cmt> fix missing return types </cmt> <cmt> add some missing required params to tests </cmt>,new typing for google sign-in api
3651,"<desc> references #4830 since that pr was already merged. had the c++ template aliases commit in my master already, so i had to revert that. sorry about that. </desc> <cmt> added preprocessor define for c++ if template aliases are supported by the compiler </cmt> <cmt> revert ""revert ""performance increase of vector of structures using .net blockcopy (#4830)"""" </cmt> <cmt> this reverts commit 1f5eae5d6a135ff6811724f6c57f911d1f46bb15. </cmt> <cmt> put<t> method was inside #if unsafe_bytebuffer which caused compilation failure when building in unsafe mode </cmt> <cmt> revert ""added preprocessor define for c++ if template aliases are supported by the compiler"" </cmt> <cmt> this reverts commit a75af7352127c261baf0b6cca5cb823e13e78f11. </cmt>",mono fix for unsafe mode
3652,"<desc> this magic method was missing. allow the natural abs(x). please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change add abs magic method. test for the same. </desc> <cmt> add magic method abs to ndarray </cmt> <cmt> add relevant tests </cmt>",add magic method abs to ndarray and symbol.
3653,"<desc> doing thigns this way makes incremental parsing (specifically, determining if we can reuse a node) much easier. </desc> <cmt> rename context flag. </cmt> <cmt> move 'disallowin' into being an ambient parser context flag. </cmt> <cmt> this greatly simplifies how we will do incremental parsing. </cmt>",change 'disallowin' into an ambient parser context flag.
3654,"<desc> ensures all bottom sheets use non-linear animations for entrance and exits, while still allowing dragging (linearly) bottom sheets. fixes the animation durations to match the spec. before (in slow motion): after (in slow motion):1 related issues closes #19469 future work  #51627 i added the following tests: a test to ensure that persistent bottom sheets animate non-linearly a test to ensure that modal bottom sheets animate non-linearly before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. </desc> <cmt> merge changes from marcoms:bottom-sheet-curve </cmt> <cmt> add material curves </cmt> <cmt> fix modal bottom sheet duration and easing </cmt> <cmt> fix typo </cmt> <cmt> fix standard bottom sheet easing </cmt> <cmt> remove extraneous exit curve </cmt> <cmt> rename persistentbottomsheetcurve to standardbottomsheetcurve </cmt> <cmt> add tests </cmt> <iss> material bottom sheet reveal/dismiss animation should use a curved animation </iss>",material bottom sheet reveal/dismiss animation uses a curved animation
3655,"<desc> updated the info.json and .h files to reflect the odd switch matrix regarding the long keys on the right. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> updated info.json </cmt> <cmt> update v2.h to reflect strange physical layout </cmt>",fixed info.json file for layout_default and layout_ansi_splitspace
3656,"<desc> important: pull requests should only be issued against the dev branch. prs against the master branch will always be closed. this pr changes (delete as applicable) nothing, it's a bug fix because the tilemaplayer position is not accounted for in the tilemap collision check, collision fails as it expects the tilemaplayer to have a default position of 0,0 with regards to fixedtocamera being set to false. the benefit of this fix is apparent when creating near infinite (well until you get an arithmetic overflow in regards to position calculations...) tilemap worlds by stitching multiple tilemaplayer's together, and in order to achieve that you would need to set the position of that tilemaplayer to something other than 0,0. </desc> <cmt> take into account position of tilemap in collision </cmt> <cmt> take into consideration tilemap position into collision </cmt>","fixing tilemap collision when tilemaplayer is set to a position other than 0,0"
3657,<desc> description: based on  related issue (if applicable): fixes  pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4482 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> handle daikin ac devices without fan_mode and swing_mode support </cmt> <cmt> handle daikin ac devices without fan_mode and swing_mode support </cmt>,handle daikin ac adapters without fan mode and swing mode support
3658,<desc> what's in this pull request? this pr implements se-0134. merge simultaneously with apple/swift-corelibs-foundation#486. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. </desc> <cmt> [se-0134] rename utf8-related properties on string </cmt> <cmt> [se-0134] fix-up for renaming utf8-related properties </cmt> <cmt> [se-0134] another fixup for utf8-related property renaming </cmt>,rename/remove two properties on string
3659,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr continues the planned set that will together add up to #45201 and includes the following changes: adds tests for where, findwhere, shuffle, and sample. updates where and findwhere to take a partial<t> instead of an object to provide better autocomplete support where available and provide an error for inline object declarations with no matching properties. updates the overload of sample in which n is not provided to include undefined as a possible result (for the case where an empty collection is provided). updates the return type for _chain.findwhere to include undefined. removes the redeclaration of the t generic in underscore.sample and _chain.sample which will fix #20440 for those functions. updates the return type of _chain.where, _chain.shuffle, and _chain.sample to use the correct wrapped value type v to partially fix #36308. updates underscorestatic.where and underscorestatic.findwhere to work with both lists and dictionaries to partially fix #20623. </desc> <cmt> updating type definitions for where, findwhere, shuffle, and sample and adding tests. </cmt> <cmt> fixing a test group comment in map that was missing its collection type differentiator. </cmt> <cmt> adding ""any"" tests for where and findwhere. </cmt> <cmt> fixing various issues. </cmt> <iss> inaccurate typings for underscore's _.sample method </iss> <iss> underscore collections functions should take objects </iss> <iss> @types/underscore error ts2322 for `_.chain` after upgrade to v1.9 </iss>","collection and array tests - where, findwhere, shuffle, and sample"
3660,"<desc> closes #26068 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry </desc> <cmt> enh : adding support to parse unsigned long long from json (#26068) </cmt> <cmt> tst: refactored tests where necessary and added new testing conditions (#26068) </cmt> <iss> read_json: valueerror: value is too big </iss>",enabling parsing ulonglong from json
3661,"<desc> related issue = #2590, #2637 one of the remaining issues in #2637 is that grouped loop indices of struct fors are exposed to users as ti.vector however they are (naturally) implemented as individual variables, therefore dynamic indexing cannot work here. my solution is different from the idea in #2637: instead of making members of ti.vector loopable, i prefer to keep the individual variables and assign them to a ti.vector so that the user api is not affected and we don't have to re-design the looping mechanism. furthermore, after we implement complete optimization passes of tensor types in the future, the ti.vector allocation and assignments here can be eliminated, which leads to the same performance as before. </desc> <cmt> remove disable_local_tensor when building struct for loop indices </cmt> <cmt> fix type assertion error in offsets </cmt>",make dynamic indexing compatible with grouped loop indices of struct fors
3662,"<desc> some options need backend to support specific extension, like: default_fp=ti.f64 and ti.extension.data64 dynamic_index=true and ti.extension.dynamic_index currently, the former one is implemented outside @ti.test() and the latter one is implemented inside @ti.test(). we may want to figure out a more elegant way to deal with such cases. we don't want to sneakily change the user's init configurations. how should we respond with dynamic_index=true, when the target backend doesn't support dynamic_index? clean up tests without no ti.init(). figure out how to print to the terminal while running pytest. </desc> <cmt> wip </cmt> <cmt> clean up fixcrossoffloadreferences </cmt> <cmt> fix tests </cmt> <cmt> avoid storing globalptrstmt more strictly </cmt> <cmt> add test for local tensor </cmt> <cmt> auto format </cmt> <cmt> fix matrix </cmt> <cmt> fix test, only throw exception when can't deduce type </cmt>",unify tests decorators with @ti.test()
3663,<desc> fixes rdar://72999296. cherry-picked from #35488. </desc> <cmt> [nfc] add crash test case for _atomic(_bool) irgen. </cmt> <cmt> (cherry picked from commit 56f9c89c7e66ea3546f1f7f4204de230739b8bc5) </cmt> <cmt> [irgen] add hack to handle _atomic(_bool) correctly. </cmt> <cmt> (cherry picked from commit a6d0cca20149069f2db793e5ce2c191ebf2aae15) </cmt>,fix crash when trying to compile _atomic(_bool)
3664,"<desc> fix the not-working toolbar. now it's working again. some workaround to reduce the chance assert failed.  this pr does not fix this bug. i know what's causing it and fixing it completely requires a lot of time (which i don't have now). i will probably refactor all code about downloading later (which will fix this bug) as it's annoying and influencing user experience, i check the window's existence each time before operating on the window to reduce the chance assert failed. </desc> <cmt> [rapps] fix the bug that toolbar is not working </cmt> <cmt> [rapps] some renaming </cmt> <cmt> [rapps] reduce the chance assert failed </cmt>",small bugfix and some workaround
3665,<desc> rdar://44109268 </desc> <cmt> [libsyntax] fix places in which rawsyntax nodes were created without an arena </cmt> <cmt> [libsyntax] make rawsyntax nodes hold a strong reference to their arena </cmt> <cmt> this allows an elegant design in which we can still allocate rawsyntax </cmt> <cmt> nodes using a bump allocator but are able to automatically free that </cmt> <cmt> buffer once the last rawsyntax node within that buffer is freed. </cmt> <cmt> this also resolves a memory leak of rawsyntax nodes that was caused by </cmt> <cmt> parserunit not freeing its underlying astcontext. </cmt>,cherry pick @ahoppen's syntax arena changes to swift-5.0-branch.
3666,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { ""extends"": ""dtslint/dt.json"" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> fix: added 'deep' to mergedeepright's type </cmt> <cmt> fix: merge types </cmt> <cmt> fix: missing semicolon </cmt> <cmt> fix: bad test </cmt>",accurate types for mergeall & a fix
3667,"<desc> for details see commits. rdar://problem/39978743 </desc> <cmt> stdlib: remove some @inlineables from string api functions. </cmt> <cmt> beside the general goal to remove inlinable functions, this reduces code size and also improves performance for several benchmarks. </cmt> <cmt> the performance problem was that by inlining top-level string api functions into client code (like string.count) it ended up calling non-inlinable internal string functions eventually. </cmt> <cmt> this is much slower than to make a single call at the top-level api boundary into the library. inside the library all the internal string functions can be specialized and inlined. </cmt> <cmt> rdar://problem/39921548 </cmt> <cmt> stdlib: fix performance regression for long string appends. </cmt> <cmt> re-wrote the inner memcpy loops so that they can be vectorized. </cmt> <cmt> also added a few inline(__always). </cmt> <cmt> since we removed some @inlineable attributes this string-append code is not code generated in the client anymore. </cmt> <cmt> the code generation in the stdlib binary is different because all the precondition checks are not folded away. </cmt> <cmt> using explicit loop control statements instead of for-in-range removes the precondition-overhead for those time critical memcpy loops. </cmt> <cmt> stdlib: speed up utf8view -> array conversion by using _copycontents </cmt>",fixes for string performance regressions
3668,<desc> i have added a backspace and delete with mod macro as well as change the bottom row to make the layout more familiar and usable by all </desc> <cmt> add initial ep40 files </cmt> <cmt> fixed issues </cmt> <cmt> updated keymap </cmt> <cmt> added media control </cmt> <cmt> update keyboards/handwired/ep40/rules.mk </cmt> <cmt> fixed requested changes </cmt> <cmt> fixed more requested changes </cmt> <cmt> added delete key to layor 1 </cmt> <cmt> updated defualt keympap to have a backspace mod del key </cmt>,fixed poor layout of ep40 default keymap
3669,<desc> address some of #15880 add from_estimator and from_predictions method and deprecate the plot_roc_curve. todo: add new class methods deprecate plot_roc_curve add check for raising deprecation warnings catch deprecation warning in test add common test for the curve add tests for the display update the examples update the user guide </desc> <cmt> iiter </cmt> <cmt> iter </cmt>,api add from_estimator and from_predictions to roccurvedisplay
3670,"<desc> fixes #19238 relates #16561 cvmat with different dimensions were copied to outputarray _circles. hough_gradient : mat(1, numcircles, cv::traits::type<circletype>::value, &circles[0]).copyto(_circles); vs hough_gradient_alt : std::vector<vec3f> cwow(ncircles); mat(cwow).copyto(_circles); this has been fixed and a test has been added. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work </desc> <cmt> fix outputarray _circles dimensions </cmt> <cmt> add houghcircles_alt test </cmt> <iss> different shape of result of the method hough_gradient_alt in python </iss>",fix hough circles alt dimensions
3671,<desc> see title </desc> <cmt> [win32] directx: fix switching display mode in true fullscreen in case when os silently bring app out of full screen </cmt> <cmt> [win32] windowing: resize dx buffers after resolution change to avoid black screen after fall creators update. </cmt>,fixes for display mode switching issues
3672,"<desc> as per @samuelgruetter's comments in #55, i added some tests against interval together with multiple subscribers, and then proceeded to fix the behavior by wrapping it in another subscription function. i hope it's ok now. </desc> <cmt> added test with multiple subscribers </cmt> <cmt> added missing mock </cmt> <cmt> added another test against multiple staggered subscribers </cmt> <cmt> wrapped subscription so that interval works for multiple subscribers and added a test for staggered subscriptions with publish/connect, too </cmt>",make interval work with multiple subscribers
3673,"<desc> i just built my jj40 today and decided to port over some of the rgb underglow code i used on the mechmini qmk subdirectory (which is also a ps2avrgb board). the code turned out to move over pretty easily: it's a matter of defining a custom rgblight_set() function in jj40.c, and changing a few things in config.h and rules.mk to enable rgb underglow as i did with the mechmini. all that is different is the number of rgb leds - 5 for the jj40 versus 16 on the mechmini. perhaps this implementation could be used with other ps2avrgb boards? i also cleaned up the redundant/extraneous rgb backlighting code on the mechmini subdirectory (as setting rgb underglow modes/colours is already handled by qmk's built-in rgb support), and reset the keyboard's advertised power draw to 500 ma in usbconfig.h, as i am not sure that the keyboard only draws 100 ma with the underglow set on full. on this - i do now have a usb power draw meter, but i feel like setting the value back to the default is better, with the option for users to modify the value in usbconfig.h as needed instead. </desc> <cmt> cleanup mechmini keymap. once the custom rgb function is defined, there is no need to manually handle rgb code. </cmt> <cmt> change default to keymap_mit, not keymap_offset </cmt> <cmt> add custom rgb code for jj40 </cmt> <cmt> reset mechmini advertised power draw to 500. will have to test actual maximum power draw later. </cmt> <cmt> rgb working on jj40. </cmt> <cmt> fix: saturation increase/decrease flipped </cmt>","rgb underglow support for jj40, clean up redundant code in mechmini keymap"
3674,"<desc> this sequence of relatively small commits dramatically improves the memory management in epiloguearcanalysis and on certain projects reduces compile time spent in the swift optimizer 36%. </desc> <cmt> move the include guard of analysis.h /above/ the includes. </cmt> <cmt> otherwise, every time we include analysis.h, we will try to include those other </cmt> <cmt> files even if we have already included analysis.h. this can increase compile </cmt> <cmt> time. </cmt> <cmt> rdar://33841629 </cmt> <cmt> (cherry picked from commit 6b54531455c7898b54a8d59c5e3b6a1b472a34c1) </cmt> <cmt> [sil-analysis] add functionanalysisbase::{hasanalysis,maybeget}(silfunction *f). </cmt> <cmt> today, if one wants to invalidate state relative to your own function analysis, </cmt> <cmt> you have to use functionanalysisbase::get() to get the analysis. the problem </cmt> <cmt> here is that if the analysis does not exist yet, then you are actually creating </cmt> <cmt> the analysis. this is an issue when one wants to perform an action on an </cmt> <cmt> analysis only if the analysis has already been built. an example of such a </cmt> <cmt> situation is when one is processing a delete notification. if one does not have </cmt> <cmt> an analysis for a function, one should just do nothing. </cmt> <cmt> i am going to use this to fix a delete notification problem in </cmt> <cmt> epiloguearcanalysis. </cmt> <cmt> rdar://33841629 </cmt> <cmt> (cherry picked from commit eb4d94f10b6f66388ce9448fc00d49ce9fdc4e7b) </cmt> <cmt> [epilogue-arc] use maybeget instead of get when handling delete notifications. </cmt> <cmt> by using this the maybeget api on functionanalysisbase instead of get, we stop </cmt> <cmt> epiloguearcanalysis from building itself if it does not yet exist, only to </cmt> <cmt> invalidate itself. </cmt> <cmt> rdar://33841629 </cmt> <cmt> (cherry picked from commit ae25f444087c3e5d866f57a0611f71b5f2f2fc45) </cmt> <cmt> [sil-analysis] add a new utility class for functionbaseinfo based analyses: lazyfunctioninfo. </cmt> <cmt> commonly when an analysis uses subanalyses, we eagerly create the sub function </cmt> <cmt> info when constructing the main function info. this is not always necessary and </cmt> <cmt> when the subanalyses do work in their constructor, can be actively harmful if </cmt> <cmt> the parent analysis is never invoked. </cmt> <cmt> this utility class solves this problem by being a very easy way to perform a </cmt> <cmt> delayed call to the sub-analysis to get the sub-functioninfo combined with a </cmt> <cmt> cache so that after the lazyfunctioninfo is used once, we do not reuse the </cmt> <cmt> densemap in the sub-analysis unnecessarily. </cmt> <cmt> an example of where this can happen is in epiloguearcanalysis in combination </cmt> <cmt> with postorderfunctioninfo. postorderfunctioninfo eagerly creates a new post </cmt> <cmt> order. so, if we were to eagerly create the postorderfunctioninfo (the </cmt> <cmt> sub-functioninfo) when we created an epiloguearcfunctioninfo, we would be </cmt> <cmt> creating a post order even if we never actually invoke epiloguearcfunctioninfo. </cmt> <cmt> (cherry picked from commit b70c8b64a10a51bfe9a5acdc8c3461715e133805) </cmt> <cmt> [epilogue-arc-analysis] be more efficient with memory usage. </cmt> <cmt> this patch fixes a number of issues: </cmt> <cmt> the analysis was using epiloguearccontext as a temporary when computing. this is </cmt> <cmt> an performance problem since epiloguearccontext contains all of the memory used </cmt> <cmt> in the analysis. so essentially, we were mallocing tons of memory every time we </cmt> <cmt> missed the analyses cache. this patch changes the pass to instead have 1 </cmt> <cmt> epiloguearccontext whose internal state is cleared in between invocations. since </cmt> <cmt> the data structures (see below) used after this patch do not shrink memory after </cmt> <cmt> being cleared, this should cause us to have far less memory churn. </cmt> <cmt> the analysis was managing its block state data structure by allocating the </cmt> <cmt> individual block state structs using a bumpptrallocator/densemap stored in </cmt> <cmt> epiloguearccontext. the individual state structures were allocated from the </cmt> <cmt> bumpptrallocator and the densemap then mapped a specific silbasicblock to its </cmt> <cmt> state data structure. ignoring that we were mallocing this memory every time we </cmt> <cmt> computed rather than reusing global state, this pessimizes performance on small </cmt> <cmt> functions significantly. this is because the bumpptrallocator by default heap </cmt> <cmt> allocates initially a page and densemap initially mallocs a 64 entry hash </cmt> <cmt> table. thus for a 1 block function, we would be allocating a large amount of </cmt> <cmt> memory that is just unneeded. </cmt> <cmt> instead this patch changes the analysis to use a std::vector in combination with </cmt> <cmt> postorderfunctioninfo to manage the per block state. the way this works is that </cmt> <cmt> postorderfunctioninfo already contains a map from a silbasicblock to its post </cmt> <cmt> order number. so, when we are allocating memory for each block, we visit the cfg </cmt> <cmt> in post order. thus we know that each block's state will be stored in the vector </cmt> <cmt> at vector[post order number]. </cmt> <cmt> this has a number of nice effects: </cmt> <cmt> 1. by eliminating the need for the densemap, in large test cases, we are </cmt> <cmt> signficiantly reducing the memory overhead (by 24 bytes per basic block assuming </cmt> <cmt> 8 byte ptrs). </cmt> <cmt> 2. we will use far less memory when applying this analysis to small functions. </cmt> <cmt> rdar://33841629 </cmt> <cmt> (cherry picked from commit b1debfc401bd80cfe519761155d6219a23dd83ff) </cmt>",fix memory management issues in epiloguearcanalysis
3675,"<desc> i'm headed out of town, so i figured i'd go ahead and get some eyes on this and let some people start playing with it. this is the start of cleanly handling intents on android, so we can avoid a huge mess of jni as we start to do more. here, we add a new bridge that lets us call native from java, which is much cleaner for more android-y interfaces like listeners and broadcasters. next step is to add functionality for waiting on messages, callbacks, etc, and to remove our jni code for sending intents in favor of adding it here. </desc> <cmt> intents: add a java class for listening to intent broadcasts </cmt> <cmt> intents: hook up a jni_onload for finding our java functions </cmt> <cmt> this should be extended to do lots more, so that we can quickly add java code </cmt> <cmt> and access it from native, without the mess that is jni. </cmt>",beginning of android intents handling
3676,"<desc> the parser and ner components use transition-based models, that build a state representation by combining the vectors from some tokens in the context. the previous ner feature set was: current word next word previous word first word of the current entity word before first word of the current entity word after first word of the current entity this pr adds a feature set that seems to perform a bit better, while using fewer tokens: current word first word of current entity, if it exists last word of current entity, if it exists this is less redundant, and runs faster. it also prepares us better for the wider token vectors we'll be expecting from transformer models. you can change the feature set by passing nr_token_features to the begin_training method. care should be taken with this, as not all numbers are valid --- they're basically shorthand for particular feature sets. there's also currently no error handling for invalid values, so this is basically internals until we have a better config system in place. nlp.begin_training(component_cfg={""ner"": {""nr_feature_tokens"": 3}}) i have submitted the spacy contributor agreement. </desc> <cmt> support option of three ner features </cmt> <cmt> expose nr_feature parser model setting </cmt> <cmt> give feature tokens better name </cmt> <cmt> test nr_feature=3 for ner </cmt> <cmt> format </cmt>",add option for improved ner feature extraction
3677,"<desc> category enhancement (new features, refinement) added support to connect to dremio. tested it on the master. test plan requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> added spec for dremio </cmt> <cmt> installation instructions for dremio </cmt>",add support for dremio as a new source
3678,"<desc> homing phase. makes homing super repeatable by retracting from endstop hit back to a very specific stepper coil phase. tmc only. delta only. the implementation changes delta homing so when the endstop is hits, the tmc phase is queried and the distance to the next target phase away from endstop is computed and added to endstop trim. notes: trinamic drivers use a stepper phase table with 1024 values which spans 4 full steps with 256 positions each therefore 1024 positions. the full steps (positions 128, 384, 640, 896) have the highest holding torque. the endstop needs to be repeatable to at least half a step. improve homing repeatability. home is now a position with the highest hold torque. #16383 </desc> <cmt> tmc home to position </cmt> <cmt> stepper home position </cmt> <cmt> fit and finish </cmt> <cmt> phase per axis, warning. </cmt> <cmt> extra space </cmt>",homing phase for tmc drivers
3679,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #42860 (review) include tests for your changes </desc> <cmt> fix(markdown-it): fix helper parselinklabel argument state type </cmt> <cmt> test(markdown-it): change test due to helper parselinklabel update </cmt> <cmt> chore(markdown-it): correct url for contributors </cmt>,markdown-it helper parselinklabel argument state type
3680,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. changelog updated type definitions for parse 2.10 typescript version 3.3 now using conditional types from ts 2.8 more complex generic inferences from ts 3.3 made parse.object a generic in order to type its attributes in order to handle parse.object's complex construct signature, class object was switched to const object: objectconstructor. this is modeled based on the native const array: arrayconstructor type pattern. the default attributes type is intentionally broad to minimize breaking changes: { [key: string]: any }. users are able to ""opt in"" to stricter typing by passing a type parameter to parse.object all classes that extend parse.object are also generic. added many more tests, and made use of // $expecttype and // $expecterror comments for stricter assertions fixed removed all but two tslint rule exceptions ban-types: false is still necessary because parse has its own object interface that tslint thinks is a banned type no-unnecessary-generics is still necessary because we allow users to type various return types via a type parameter parse/node and parse/react-native module declarations are now in their own files, per tslint preference various other lint fixes: semi-colons, combined overloads, whitespace, comment formatting errorcode was a global type, but is not actually a global in the parse library. it is no longer global. the baseobject interface and class were removed the parse library did not export any such class it was only being used as a convenience to add tojson(): any as a method on other interfaces, but in reality those various tojson methods will not have the same return type. each interface now has its own tojson method, so that in the future it will be easier to provide better typings for them individually. classes that extended parse.object had constructors that were typed incorrectly. parse.user, parse.session, parse.installation, and parse.role now have construct signatures that match the documentation. parse.config does not actually extend parse.object - it is no longer typed as such. some types were removed that are not documented or found in parse's source code parse.version parse.object.cid and parse.object.changed </desc> <cmt> parse: fix tslint issues </cmt> <cmt> parse: update ts test cases </cmt> <cmt> parse: stricter types for parse.object attributes </cmt> <cmt> better constructor handling for parse.object </cmt> <cmt> use keyof t for more attribute parameters and add tests </cmt> <cmt> parse: improve parse.object method types and add more tests </cmt> <cmt> remove parse.version type as it does not exist in documentation </cmt> <cmt> add references for other declaration files to index.d.ts </cmt> <cmt> parse: fix constructor types for classes that extend parse.object </cmt> <cmt> parse: fix parse.object child classes </cmt> <cmt> return parse functions to old location for more readable diff </cmt>","stricter parse.object attributes type, improve linting, and add tests"
3681,<desc> we do two things here: validate that arbitrary properties result in actual parsable css declarations ignore malformed css properties (for example beginning with a number) this prevents generation of classes for things like [0:02] or [autoplay:${autoplay}] which result in invalid css. this does not fix all cases but should help significantly. fixes #6395 </desc> <cmt> move arbitrary value check </cmt> <cmt> validate that css values are actually parsable </cmt> <iss> abnormal css ouput when some string in the code is wrapped in square brackets </iss>,don't output unparsable values
3682,"<desc> policy.compute_single_actions is broken for nested (e.g. tuple) actions due to the simplified assumption that the returned action is a simple batch (list). this pr adds an unpatch step and only then returns. issue #8411. closes #8411. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip and lint. </cmt> <iss> [rllib] apparently broken compute_actio function for multiagent environments </iss>",policy.compute_single_action() broken for nested actions (issue 8411).
3683,"<desc> calls to hlfmt_hash () should check if the resulting hash_buf is not null and the length (hash_len) is at least 1. i discovered that sometimes it happens that the format was e.g. detected as shadow, but parsing it failed, therefore the len was 0 and the buf was null. oclhashcat didn't check for such situations and sometimes it resulted in a segfault/crash. thank you very much </desc> <cmt> added check for hash_len after calls to hlfmt_hash () </cmt> <cmt> also add check for null pointers </cmt>",added check for hash_len/hash_buf after calls to hlfmt_hash ()
3684,"<desc> disallow updating zstd_c_literalcompressionmode during compression, since the optimal parsers statistics would be messed up. tell the optimal parser that literals are 1 byte each when using zstd_lcm_uncompressed, and avoid updating the literal frequencies. add a flag on the cli to control literals compression --[no-]compress-literals. update the regression tests to test level 19 with uncompressed literals. 3d7377b shows the difference after fixing the pricing (-2% on silesia, -5% on github). fix a bug in the compress cctx method that was causing decompression failures. respect --[no-]compress-literals in benchmark mode add cli tests to playtests.sh so they get executed with different configurations. </desc> <cmt> [regression] test level 19 with uncompressed literals </cmt> <cmt> [libzstd] handle uncompressed literals </cmt> <cmt> fix a bug in the compress cctx method </cmt> <cmt> [zstdcli] add a flag to control literals compression </cmt>",fix optimal parser prices with uncompressed literals
3685,"<desc> category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation wip - this is the first of several prs which addresses sip-24 requires db migration. confirm db migration upgrade and downgrade tested. reviewers </desc> <cmt> first cut at app factory </cmt> <cmt> setting things back to master </cmt> <cmt> working with new flask_app </cmt> <cmt> # conflicts: </cmt> <cmt> #	superset/__init__.py </cmt> <cmt> still need to refactor celery </cmt>",flask app factory pr #1
3686,"<desc> format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> distro check datastorage status before send verify data. </cmt> <cmt> add source server address info for distro verify. </cmt> <cmt> refactor distro verify task. </cmt> <cmt> refactor distro client verify task </cmt>",refactor and enhance for client distro protocol
3687,<desc> for #3691. </desc> <cmt> add single data source api for shardingdatasourcefactory </cmt> <cmt> fix example </cmt> <cmt> add single data source api for yamlshardingdatasourcefactory </cmt> <cmt> fix example </cmt> <cmt> refactor abstractencryptjdbcdatabaseandtabletest </cmt> <cmt> remove yamlencryptdatasourcefactory </cmt> <cmt> refactor shadowdatasourcefactory </cmt> <cmt> refactor spring boot starter for encrypt </cmt>,redesign spring boot starter api for encrypt
3688,"<desc> in order to better maintain the ansible files, i propose to identify these files. please give me a hand for this,if it is ok. thanks. best regard. .github/botmeta.yml </desc> <cmt> update botmeta.yml </cmt> <cmt> update for cloudengine. </cmt>",update to label cloudengine files.
3689,"<desc> a function declaration like: func dog cow() {} ... yields a bunch of noisy diagnostics about expecting certain tokens, like ""expected '(' in argument list of function declaration"", or the dreaded ""consecutive statements on a line must be separated by ';'"". instead, look for a repeated identifier in this position and affirm that the repeated identifier wasn't expected, suggesting that maybe this was a single identifier with a break in it. rdar://problem/25761940 </desc> <cmt> qoi: provide a fix-it for repeated identifiers in function declarations </cmt> <cmt> a function declaration like: </cmt> <cmt> func dog cow() {} </cmt> <cmt> ... yields a bunch of noisy diagnostics about expecting certain tokens, like </cmt> <cmt> ""expected '(' in argument list of function declaration"", or the dreaded </cmt> <cmt> ""consecutive statements on a line must be separated by ';'"". instead, </cmt> <cmt> look for a repeated identifier in this position and affirm that the </cmt> <cmt> repeated identifier wasn't expected, suggesting that maybe this was a </cmt> <cmt> single identifier with a break in it. </cmt> <cmt> rdar://problem/25761940 </cmt> <cmt> direct and camel-cased concatenation fixits for repeated identifiers in function declarations </cmt> <cmt> additional qoi to also provide a fix-it to concatenate in camel-case. </cmt> <cmt> rdar://problem/25761940 </cmt>",better diags for repeated identifier in function declarations
3690,"<desc> original pull-request #18130 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix remove ttl for column </cmt> <cmt> fix test </cmt> <cmt> fix remove ttl for column </cmt>",cherry pick #18130 to 20.11: fix remove ttl for column
3691,"<desc> the commit message contains more information about the individual changes. </desc> <cmt> optimize textlayerrendertask._layouttext to avoid intermediate string creation </cmt> <cmt> this method creates quite a few intermediate strings on each call and </cmt> <cmt> it's called often, even for smaller documents like the tracemonkey </cmt> <cmt> document. scrolling from top to bottom in that document resulted in </cmt> <cmt> 12936 strings being created in this method. with this commit applied, </cmt> <cmt> this is reduced to 3610 strings. </cmt> <cmt> optimize canvasgraphics.setfont to avoid intermediate string creation </cmt> <cmt> this method creates quite a few intermediate strings on each call and </cmt> <cmt> it's called often, even for smaller documents like the tracemonkey </cmt> <cmt> document. scrolling from top to bottom in that document resulted in </cmt> <cmt> 14126 strings being created in this method. with this commit applied, </cmt> <cmt> this is reduced to 2018 strings. </cmt>",optimizations to avoid intermediate string creation
3692,"<desc> nothing substantial, just clarified how the algorithm works and what is expected (i.e. the bandwidth parameter). </desc> <cmt> update to mean shit clustering narrative documentation. </cmt> <cmt> update to docstring of meanshift </cmt> <cmt> docstring of module </cmt>",update to mean shift clustering documentation
3693,<desc> this pull has several fixes for issues raised in #154: enhance @selectkey to support multiple key columns (like the existing support with jdbc generated keys) enhance  to support multiple key columns allow select key and generated keys in update statements two tests are marked as ignored because hsql is not returning generated columns after an update statement. </desc> <cmt> support multiple key properties in @selectkey </cmt> <cmt> add support for selectkey and generated keys in update statements </cmt> <cmt> add xml mapper for selectkey update tests </cmt>,changes for #154 - enhanced support for optimistic locking
3694,"<desc> description: added support for humidity and pressure in 1-wire devices. also added support for a couple of new (old) devices. this update changes the names of the sensors from ""<sensor_name>"" to ""<sensor_name> <sensor_type>"" example: kitchen -> kitchen temperature. in the database this looks like: sensor.kitchen -> sensor.kitchen_temperature. this was a necessary change as devices with multiple sensors would be given additional _n suffixes in the database that would be not be persistent per sensor across restarts of ha. if you wish to maintain a single line of record in the database this can be achieved by the following recipe. connect to your database using the instructions from  check the names of sensors: select entity_id, count(*) as count from states group by entity_id order by count desc limit 10; alter the names of sensors using the following examples: update states set entity_id='sensor.<sensor_name>_temperature' where entity_id like 'sensor.<sensor_name>%' and attributes like '%\u00b0c%'; update states set entity_id='sensor.<sensor_name>_pressure' where entity_id like 'sensor.<sensor_name>%' and attributes like '%mb%'; update states set entity_id='sensor.<sensor_name>_humidity' where entity_id like 'sensor.<sensor_name>%' and attributes like '%%%' escape ''; remember to replace <sensor_name> with the actual name of the sensor as seen in the select query. checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. </desc> <cmt> added more devices and sensor types. </cmt> <cmt> flake8 fixes </cmt>",added more devices and types to onewire
3695,"<desc> fixes a bug related to how ""closed replicated indices"" (introduced in 7.2) interact with the index metadata storage mechanism, which has special handling for closed indices (but incorrectly handles replicated closed indices). on non-master-eligible data nodes, it's possible for the node's manifest file (which tracks the relevant metadata state that the node should persist) to become out of sync with what's actually stored on disk, leading to an inconsistency that is then detected at startup, refusing for the node to start up. the solution used here is to remove the code that treats closed indices specially. this code has not aged well, and its use is dubious as best. closes #47276 </desc> <cmt> omit writing index metadata for closed indices on data-only node </cmt> <cmt> simplify test </cmt> <iss> elasticsearch fails to start with error: ""failed to find metadata for index"" on every restart </iss>",omit writing index metadata for non-replicated closed indices on data-only node
3696,"<desc> after the discussion earlier - i put together a bit of what i was thinking the model structure would look like - it eliminates the dataprovider layer and just defines static functions on the models themselves, which i think will make things a bit cleaner as we build out the model layer, and make things a bit easier to picture see what goes where and how things relate. it uses all of the stuff that @jgable put in there already, but puts them onto a base model, which the other inherit from. it also creates a specific namespaced ""ghost"" instance of bookshelf/knex, in case others are using a copy of bookshelf/knex already in their application, which should be accessed from data/models/base.js whenever you need to grab bookshelf/knex. </desc> <cmt> a bit of organizing/simplifying/fattening the models </cmt> <cmt> merging master </cmt>",shifting around the model structure a bit
3697,<desc> add layout_60_ansi to xd60 rename layout_all to layout_all fix bug in krusli's keymap put 60_ansi in rules.mk so i can generate my default keymap for it. </desc> <cmt> add new layout and fix formatting </cmt> <cmt> add 60_ansi layout so i can use my user space defined layouts </cmt> <cmt> make qmk_keyboard_h and layout renames </cmt> <cmt> update info.json file </cmt>,add standard layout to xd60
3698,<desc> updating the raygun4js ts definition to 2.4.2. prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. </desc> <cmt> updated raygun4js definition to match version 2.4.2 </cmt> <cmt> tests updated </cmt> <cmt> raygun function interface created for the v2 api </cmt> <cmt> added window definition. v2 user details interface added. refactored v2 declaration. </cmt> <cmt> v2 api tests added </cmt> <cmt> documentation added to options. </cmt>,update raygun4js definition to version 2.4.2
3699,"<desc> adds a conditional protocol extension that defines mutablecollection.mutablecollection.subscript(bounds: range<_>) -> slice<self> only when subsequence == slice<self>. attempts to mark the unconditional extension method mutablecollection.subscript(bounds: range<_>) -> slice<self> as unavailable mutablecollections where subsequence == slice<self> still get the expected default implementation. adds a default implementation of mutablecollection.subscript(bounds: range<_>) -> subsequence, marked unavailable, in order to prevent invalid conformances from compiling when subsequence is not slice<self>. resolves sr-14850 / rdar://79898408 (and completes the fix to sr-14848). </desc> <cmt> [test] add a definition that shouldn't compile </cmt> <cmt> [stdlib] mutablecollection fix to _smallstring </cmt>",prevent mutablecollections from inappropriately inheriting a slice<self> subscript
3700,"<desc> description: twilio changed the class that needs to be used from twiliorestclient to client. source. this broke after the twilio client was upgraded in #17424 and an api change was missed. related issue (if applicable): fixes #17871 this one is affecting 0.81.x and should be shipped in the next bugfix release. however, i'm not sure how to do that since the component itself was rewritten in #17715 (so the files are not in the same place in dev and master). this pull request is targeted at master in case that helps for the hotfix and #17883 is targeted at dev which should fix it for 0.82.0 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> 0.81 </cmt> <cmt> switch to using client from twilio.rest rather than the deleted twiliorestclient </cmt>",switch to using client from twilio.rest rather than the deleted twilliorestclient
3701,"<desc> @piiswrong  hi, pls review the changes. the purpose is to remove the annoying full mkl dependency when set blas=mkl. </desc> <cmt> rebase to latest one </cmt> <cmt> rebase latest </cmt> <cmt> merge the latest </cmt> <cmt> git pull </cmt>",remove full mkl package dependency for blas=mkl
3702,<desc> please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues #3583 make create a project of plugin testcase easier. i will provide a script to use it later. and any suggestions and discussions are welcome. </desc> <cmt> provide archetypes for testcase </cmt> <cmt> provide archetypes for testcase </cmt>,provide archetypes for plugin testcase
3703,<desc> update the backend to add an array of project level threshold and metric to the user misery. apdex to follow. </desc> <cmt> check in progress </cmt> <cmt> check in progress </cmt> <cmt> check in progress </cmt> <cmt> add fcp support </cmt> <cmt> add multiply and tests </cmt>,add a snuba user misery query that takes project-level thresholds
3704,"<desc> these are related typing fixes for #20322, separated to be more easily reviewed and hopefully merged quickly. </desc> <cmt> fix typing errors in external task sensors </cmt> <cmt> fix types in python operator and sensors </cmt> <cmt> fix typing errors in airflow.operators.datetime </cmt> <cmt> properly type airflow/utils/operator_helpers </cmt> <cmt> fix typing in airflow.utils.weekday </cmt> <cmt> relax jinja rendering function typing </cmt> <cmt> we don't really need to restrict the context to be an airflow context; </cmt> <cmt> any (mutable) mapping would do. </cmt>",typing fixes needed to deprecation warning fixes
3705,"<desc> softmax test failed because recently some tests uses 3d tensors as input. before, mkl softmax only supported 2d tensors. now, in this pr, we are supporting 1d, 2d, 3d, 4d and 5d tensors as input to softmax. thus, this pr fixes the ci regression. </desc> <cmt> adding support of input dimension of 1 to 5 in mkl dnn softmax </cmt> <cmt> fixed clang formatting </cmt> <cmt> cleaing up comments </cmt>","softmax dim fix: supporting 1d to 5d tensors, address the regression of ci"
3706,<desc> resolves #18752 catches warnings before the pytest.warns can catch them for voting* filter out non convergence warnings for the rest. </desc> <cmt> tst fixes warnings for scipy 1.3.0 </cmt> <cmt> rev places back record check </cmt> <iss> failing tests due to scipy.optimize deprecationwarnings </iss>,mnt catches scipy 1.3.0 for using deprecated tostring method
3707,"<desc> closes #31575 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> tst: add test case (#31575) </cmt> <cmt> bug: fix reac_csv with rawiobase broken (#31575) </cmt> <iss> pandas 1.0.0  read_csv() is broken use `open( buffering=0)` option. </iss>",read_csv used in file like object rawiobase is not recognize encoding option
3708,"<desc> addresses @zhengbli's concern in #4978 (comment). this pr enables us to grab parameters from a ""simple""/""canonical"" callable/constructable expression in a variable statement with a single declaration. we only do this for a function expression, arrow function, or class expression with a constructor, or any of the aforementioned in nested parentheses. in the presence of a class expression, if there are multiple constructor declarations, the parameters are acquired from the first one. </desc> <cmt> modified/added tests. </cmt> <cmt> try to grab parameters for single-declaration variable statements. </cmt> <cmt> we only do this for a (parenthesized) function expression, arrow function, </cmt> <cmt> or class expression with a constructor. </cmt> <cmt> in the presence of a class expression, if there are multiple constructor </cmt> <cmt> declarations, the parameters are acquired from the first one. </cmt>",grab '@param' tags from initializers
3709,"<desc> this will allow us to run the conpty tests in ci. closes msft:24265197, closes #3851 i've run the tests. please note: this code is unchanged (apart from wil::scopeexit -> wil::scope_exit) from windows. now is not the time to comment on their perfectness. </desc> <cmt> conpty: add feature tests from windows </cmt> <cmt> and make them build </cmt> <iss> pull winconpty api tests out into this project and ci inner-loop </iss>",migrate the conpty functional tests out of windows
3710,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr continues the planned set that will together add up to #45201 and includes the following changes: adds tests for sortby, indexby, countby, and invoke. updates sortby, indexby, countby, and invoke to use collection and iteratee to partially fix #20623. updates invoke return types from any and t to any[]. updates the return type of _chain.sortby, _chain.indexby, _chain.countby, and _chain.invoke to use the correct wrapped value type v to partially fix #36308. updates the collection type result for _chain.countby to be number instead of t. updates overloads of groupby to be more consistent with these overloads by making tweaks to summary comments, making iteratee optional, and adding tests for all iteratee types. updates test group comments for max and min to say ""iteratee"" instead of ""iterator"" because i messed that up in my last pr. this is the last pr in the collections family. </desc> <cmt> updating type definitions for sortby, indexby, and countby and adding tests. </cmt> <cmt> switching ""iterator"" to ""iteratee"" for a few test groups. </cmt> <cmt> making a few adjustments to groupby to better match similar functions. </cmt> <iss> underscore collections functions should take objects </iss> <iss> @types/underscore error ts2322 for `_.chain` after upgrade to v1.9 </iss>","collection and array tests - sortby, indexby, countby, and invoke"
3711,"<desc> this started out as just a ""remove s65-plus support from s65-x folder,"" but as i went it kind of snowballed. commit log s65-x: remove s65-plus support (293f9df) the original qmk codebase for the sentraq s65-x actually supported both the s65-x and the s65-plus. in the interim, the s65-plus has been broken off into its own directory. this commit removes support for the s65-plus from the keyboards/s65_x/ directory, as that code has been superseded by the code in the s65-plus directory (keyboards/s65_plus/). deleted s65-plus layout macros from s65_x.h and info.json deleted s65plus keymap directory removed references to the unused column pins removed the two unused columns for the switch matrices renamed switch k300 in layout_ansi to k301 (reflects matrix position) renamed switch k214 in layout_iso to k114 (reflects matrix position) s65-x: keymap refactor (060a7ff) all keymaps now use #include qmk_keyboard_h default and iso keymaps refactored for readability deleted redundant kc_trns and kc_no keycode definitions from smt keymap s65-x: readme update (39dbab0) updated hardware availability link updated docs links s65-plus: add layout_iso data (89226b4) adds layout_iso macro to s65_plus.h and info.json, and an iso layout version of the default keymap. s65-plus: refactor default keymap (43fcfa9) refactor for alignment/readability removed fn_actions code block add empty process_record_user block s65-plus: readme update (911936f) hardware availability link is now a hyperlink updated docs links s65-x: enable 65_ansi and 65_iso community layouts (5f2a3c2) thi commit allows the sentraq s65-x to use the 65_ansi and 65_iso community layouts. layout_ansi renamed to layout_65_ansi layout_iso renamed to layout_65_iso added layouts rule to rules.mk </desc> <cmt> s65-x: remove s65-plus support </cmt> <cmt> the original qmk codebase for the sentraq s65-x actually supported both the s65-x and the s65-plus. in the interim, the s65-plus has been broken off into its own directory. </cmt> <cmt> this commit removes support for the s65-plus from the keyboards/s65_x/ directory, as that code has been superseded by the code in the s65-plus directory (keyboards/s65_plus/). </cmt> <cmt> - deleted s65-plus layout macros from s65_x.h and info.json </cmt> <cmt> - deleted s65plus keymap directory </cmt> <cmt> - removed references to the unused column pins </cmt> <cmt> - removed the two unused columns for the switch matrices </cmt> <cmt> - renamed switch k300 in layout_ansi to k301 (reflects matrix position) </cmt> <cmt> - renamed switch k214 in layout_iso to k114 (reflects matrix position) </cmt> <cmt> s65-x: keymap refactor </cmt> <cmt> - all keymaps now use #include qmk_keyboard_h </cmt> <cmt> - default and iso keymaps refactored for readability </cmt> <cmt> - deleted redundant kc_trns and kc_no keycode definitions from smt keymap </cmt> <cmt> s65-x: readme update </cmt> <cmt> - updated hardware availability link </cmt> <cmt> - updated docs links </cmt> <cmt> s65-plus: add layout_iso data </cmt> <cmt> adds layout_iso macro to s65_plus.h and info.json, and an iso layout version of the default keymap. </cmt> <cmt> s65-plus: refactor default keymap </cmt> <cmt> - refactor for alignment/readability </cmt> <cmt> - removed fn_actions code block </cmt> <cmt> - add empty process_record_user block </cmt> <cmt> s65-plus: readme update </cmt> <cmt> - hardware availability link is now a hyperlink </cmt> <cmt> - updated docs links </cmt> <cmt> s65-x: enable 65_ansi and 65_iso community layouts </cmt> <cmt> thi commit allows the sentraq s65-x to use the 65_ansi and 65_iso community layouts. </cmt> <cmt> - layout_ansi renamed to layout_65_ansi </cmt> <cmt> - layout_iso renamed to layout_65_iso </cmt> <cmt> - added layouts rule to rules.mk </cmt>",s65-x and s65-plus updates and refactoring
3712,<desc> adapted pinouts and configs from the planck layout for the kbdfans niu mini. i also consulted the auto-generated qmk files from kbfirmware.com (github) from the provided json file by kbdfans. </desc> <cmt> add niu mini keymap from planck keymap </cmt> <cmt> remove old keymap files </cmt>,add niu mini from kbdfans
3713,"<desc> also contains #10418, because in practice we're going to want the same baseline on master and 1.14 to fix the regressions on top of. backports #10430 </desc> <cmt> maint: remove repeated #ifdefs implementing isinstance(x, basestring) for field names </cmt> <cmt> maint: use valueerror for duplicate field names in lookup </cmt> <cmt> keyerror suggests the field name does not exist, which is inaccurate. </cmt>",use valueerror for duplicate field names in lookup (backport)
3714,"<desc> this pr fixes the mouse events (enter, hover exit) so that the event objects contain correct localpositions. related issues fixes #33675 no tests are added. existing tests are added so that they also test local positions. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> new api </cmt> <cmt> add tests </cmt> <cmt> add tests for mouse region </cmt> <iss> transform mouse events to the local coordinate system </iss>",mouse events report correct local positions
3715,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> created definitions & tests for pick-weight </cmt> <cmt> fix no-single-module </cmt> <cmt> added uniqid definition </cmt> <cmt> m </cmt> <cmt> rge branch 'master' of </cmt> <cmt> merge remote-tracking branch 'source/master' </cmt> <cmt> fix for no documents found - make results optional </cmt>",mongoose-simple-random fix results - make them optional
3716,"<desc> see #14913 what is include in the pr: a fix for #14913 download image in found in issue #2447 (comment) resize the image check if all the metadata is there before this fix: after this fix: linked issue: #14913 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> metadata.clone() fails also for situations where we still can recover metadata </cmt> <cmt> metadata.clone() is also an expensive operation (deep copy) and it is not necessary anymore as we build up the metadata object from scratch anyway </cmt> <cmt> if an exception is throw here something is seriously wrong with the metadata structure </cmt> <cmt> we take all metadata we have read so far an write it to the resized image </cmt>",try to recover metadata even when the metadata data structure is invalid (#14913)
3717,"<desc> this pr: lets you do python runner.py --help moves some potentially printing code into if __name__ == '__main__' prints help text as soon as possible, so some warnings will come after it lets you run tests from multiple suites on the same command line (e.g. python runner.py other.test_sixtyfour_bit_return_value asm2.test_time) and lists any missing tests - previously it just refused to run anything ensures that if you have 256 test failures it won't come back as 0! </desc> <cmt> teach test runner about --help </cmt> <cmt> try to execute less if importing the test runner </cmt> <cmt> print help text first for a better chance of seeing warnings </cmt>",allow running tests from different suites
3718,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. add constraint for s type parameter. </desc> <cmt> update redux dependency </cmt> <cmt> update for the current 3.x redux </cmt> <cmt> add required restriction of redux </cmt>",update react-redux-i18n for react-redux 5.0.18 types
3719,"<desc> this brings pr #16228 up to date, adds tests and fixes some issues with it. that pr was meant to fix #14567, close #14627 and close #15529 by adding the option to select n features by percentage instead of by absolute number. the changes pr #16228 made to isotronic.py have since been added already and are not included in this pr. here i fix some bugs from pr #16228 and add tests for the new functionality. ping @noatamir </desc> <cmt> added code from pr #14627 </cmt> <cmt> fixed error handling none as n_features_to_select </cmt> <cmt> added test for error message and percentage passing </cmt> <iss> rfi: setting the number of features to select 'n_features_to_select' to be percentage </iss>",enable percentage for n_features_to_select in rfe(fix pr #16228)
3720,"<desc> new features others added onednn fuse pass for fc + activation. currently gelu, sigmoid and tanh are supported. performance improvement is around 4,5% - benchmarked on bert model using intel(r) d on(r) gold 6348h cpu @ 2.30ghz i1218 22:56:33.140385 102746 helper.h:363] ====== threads: 1, thread id: 0 ====== i1218 22:56:33.140409 102746 helper.h:365] ====== batch size: 1, iterations: 4962, repetitions: 1 ====== i1218 22:56:33.140413 102746 helper.h:367] ====== batch latency: 3.02517ms, number of samples: 4962, sample latency: 3.02517ms, fps: 330.56, data type: float ====== </desc> <cmt> added base fc+ gelo/tanh activation fuse pass, without tests and formatting </cmt> <cmt> added clang-formatting </cmt> <cmt> minor change </cmt> <cmt> added tests </cmt> <cmt> added formatting </cmt>","added fc + activation fuse pass (currently only gelu, sigmoid and tanh are supported)"
3721,"<desc> the regex for matching the client list did depend on an ipv4 address, so if a client was connected to the openvpn server via ipv6, it got ignored. so i modified the regex to also match ipv6 addresses; and also ignored clients with the common name undef, which are unauthenticated clients. ( if you get dos-ed, the plugin currently reports hundreds of undef clients, see </desc> <cmt> openvpn plugin: process also incoming ipv6 connections </cmt> <cmt> openvpn plugin: ignore undef clients </cmt>",fix for ipv6 connections & ignore unauthenticated clients
3722,"<desc> this fixes an issue reported on the forums where a removed movie item is not picked up by the update library routine because you can't query a previously removed fileid :) fix for episodes and tvshows has to be done separately as it's a lot more complicated and i don't want to add yet another regression to the upcoming helix betas at this point. bug report @  regression introduced with a32dcc1 and some other refactoring (movie vs movieview) @montellese, @topfs2 for review please. </desc> <cmt> [videodatabase] path hash is not invalidated when removing movie from library </cmt> <cmt> [videodatabase] path hash is not invalidated when removing musicvideo from library </cmt>",invalidate path hash on remove so the infoscanner can pick it up again
3723,"<desc> i fired up windows 8.1 today went through the build instructions. i removed some steps there weren't needed and i also added some requirement verifications to script/bootstrap. closes #2265 / </desc> <cmt> removed unnecessary instruction. </cmt> <cmt> create separate instruction </cmt> <cmt> i'm not sure if this step is needed, but it existed before. if it is </cmt> <cmt> needed we should include why you have to do this. </cmt> <cmt> ensure that node is 32bit on win32 </cmt> <cmt> make sure python2.7 is installed on win32 </cmt> <cmt> closes #2193 </cmt> <cmt> closes #2167 </cmt> <cmt> closes atom/node-runas#5 </cmt> <cmt> remove unnecessary instructions </cmt> <cmt> update windows build instructions </cmt> <cmt> require fs in bootstrap </cmt> <iss> aborted due to warnings - download atom-shell task [error] </iss>",update windows build instructions and requirements
3724,<desc> there's a lot of work being done on the wp source plugin but a lot of visitors to the site are requesting information on woocommerce specifically. i'm proposing this as a sort of in-between to at least point people in the right direction while that work is being done. this guide presents some options for working with wordpress and woocommerce. i went back and forth about including some more woo-specific instructions (things done in the dashboard). thoughts on whether i should i add that back in? addresses #20222 </desc> <cmt> add woocommerce guide draft </cmt> <cmt> add wc details </cmt>,reference guide for using woocommerce
3725,"<desc> the current bits implementation doesn't cope well when the backing array differs in length. this affects: hashcode/equals: hashcode and equality should only consider set bits. bitwise operations, except andnot(): only performs the operation up to the length of the shortest array. </desc> <cmt> unit test for bits. </cmt> <cmt> bitwise operations and equals/hashcode work even when word length differs. </cmt>",fixing bits - more considerate about set bits.
3726,"<desc> ray currently fails to shutdown clusters with over 1000 nodes, because the aws instance termination api only accept a maximum of 1000 instances to terminate in a single request. to fix this, we loop over all the instances we want to terminate, breaking them into chunks of 1000. we previously attempted to implement this in #17642, but that pr was buggy and needed to be reverted. this pr includes a stronger unit test, and fixes typos that were in #17642. i've run scripts/format.sh to lint the changes in this pr. the new unit test makes sure that spot and/or on-demand instances are stopped/terminated with the correct ec2 calls, where each ec2 call stops/terminates a maximum of 1000 nodes. the unit test also makes sure that the aws node provider never attempts to stop a spot instance (because spot instances can only be terminated, not stopped). i have also tested this pr manually by running ray down on clusters with the following configurations (by changing the cluster config yaml): 1 on-demand head node, 2 spot worker nodes, cache_stopped_nodes: true 1 on-demand head node, 2 spot worker nodes, cache_stopped_nodes: false 1 on-demand head node, 2 on-demand worker nodes, cache_stopped_nodes: true 1 on-demand head node, 2 on-demand worker nodes, cache_stopped_nodes: false 1 on-demand head node, 1002 spot worker nodes, cache_stopped_nodes: true i have not yet tested this pr on a cluster with 1000+ nodes except for within the new unit test which mocks all ec2 calls. is there a ray aws account that we could test a 1000+ large cluster on? </desc> <cmt> revert ""revert ""shutdown clusters when large number of nodes (#17642)"" (#17836)"" </cmt> <cmt> this reverts commit 6957ce66f6eb370d633444b4420c874b2e517505. </cmt> <cmt> update unit test and fix terminate_nodes </cmt>",shutdown clusters on aws with >1000 nodes
3727,"<desc> two optimizations: compress foo.bc in each rlib with flate. these are just taking up space and are only used with lto, no need for lto to be speedy. stop install librustc.rlib and friends, this is a huge source of bloat. there's no need for us to install static libraries for these components. cc #12440 </desc> <cmt> rustc: compress bytecode files in rlibs </cmt> <cmt> these are only ever used with lto, so there's no need for reading them to be </cmt> <cmt> speedy. </cmt> <cmt> mk: don't install host rlibs </cmt> <cmt> you rarely want to statically link against librustc and friends, so there's no </cmt> <cmt> real reason to install the rlib version of these libraries, especially because </cmt> <cmt> the rlibs are massive. </cmt>",reduce the size of a rust install slightly
3728,"<desc> original pull-request #32389 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update storagereplicatedmergetree.cpp </cmt> <cmt> follow-up to #32140 </cmt>",cherry pick #32389 to 21.8: follow-up to #32140
3729,"<desc> add jumptoitem() to list view. refactor the layout related methods of list view to comply with layout's practice like layout::dolayout(). requestdolayout() and dolayout() are overridden and have to use another dirty flag for list view layout other than layout::_dolayoutdirty because layout::onenter() forces _dolayoutdirty to be true always. but, list view should have a way not to do layout in onenter(). </desc> <cmt> add 'jumptoitem()' to list view. </cmt> <cmt> refactor list view's layout refreshing logic. </cmt>",add a feature of jumping to a specific item in list tview
3730,"<desc> if you look at  also if someone wants to do ioc::resolve('classname', [$dep1]); i have added a patch for this. before it would just auto resolve to a new (instanceof $dep1) instead of assigning $dep1 to the reflector's classname::__construct(classname2 $dep) arguments. wrote unit tests in laravel\laravel\cases\ioc.test.php to look for these types cases if they might arise again </desc> <cmt> ioc resolves classes with optional params and accepts arguments </cmt> <cmt> adding unit tests for ioc changes </cmt>",ioc container not resolving classes with optional parameters (i.e. models that use eloquent)
3731,"<desc> there is an error in document named readme.md,the word 'tables' should be modified to 'table'. </desc> <cmt> add a new version to it </cmt> <cmt> upgrade the version of it </cmt> <cmt> find an error in line 47,update readme.md </cmt> <cmt> find an error in line 47 of readme.md,the word 'tables' should be changed to 'table' </cmt>","fix an error in line 47,change the word 'tables' to 'table'"
3732,"<desc> num_restarts must be set before state, or the restarting actor notification might contain a wrong num_restarts. because gcs is updated asynchronously. this will cause a critical problem that i met today: when an actor restarts, since the problem mentioned, restarting notification might contain a lagger num_restarts than expected. for example, when an actor died and restarts for the first time,  all other actors might receive a restarting notification containing num_restarts=1(which is expected to be 0). then, in direct_actor_transport.cc  coreworkerdirectactortasksubmitter::disconnectactor, num_restars in clinetqueue will be set to 1. then alive notification arrives, but in direct_actor_transport.cc  coreworkerdirectactortasksubmitter::connectactor, it will be skipped since 1<=1 if (num_restarts <= queue->second.num_restarts) { // this message is about an old version of the actor and the actor has // already restarted since then. skip the connection. return; } at last, the restarted actor can't be called and won't receive any task, since no rpc_client is available. my fix approach the easiest way i think is to set num_restars before updating the state to restarting. after that restarting notification will always contain num_restarts that are already updated. then in the handler of restarting notification, num_restart should be minus by 1. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> bug fixed for num_restart updating </cmt> <cmt> add log </cmt>",[core]async updating issue fixed for actor's num_restart
3733,"<desc> updated versions of the patches that was submitted to the bug tracker. </desc> <cmt> don't add trailing slash to source with options </cmt> <cmt> sources with |option=value, like http or wedav would get a trailing </cmt> <cmt> slash after the options. for example, davs://example.net/|auth=digest </cmt> <cmt> would become davs://example.net/|auth=digest/ which causes problem later </cmt> <cmt> on. </cmt> <cmt> this solves bug #10871. </cmt> <cmt> respect |option=value with uriutils::getdirectory </cmt> <cmt> keep the |option=value for dav/http paths when getting the directory </cmt> <cmt> part. this is required when playing video from webdav with options like </cmt> <cmt> auth=digest </cmt> <cmt> this solves bug #10862. </cmt>","fixes for webdav with auth=digest option, bug #10862 and #10871"
3734,"<desc> backport 9ab2b3f and ad03952, allowing libevent 2.0.x to be build on systems with old autoconfs (rhel5, i'm looking at you). </desc> <cmt> fix missing ac_prog_sed on older autoconfs </cmt> <cmt> for pre-2.59b autoconfs, ac_prog_sed is not available [1]; on such </cmt> <cmt> systems, avoid calling ac_prog_sed, while providing a sensible sed. </cmt> <cmt> this aids backporting to autoconf 2.59. </cmt> <cmt> [1] </cmt> <cmt> backport libevent to vanilla autoconf 2.59 (as used in rhel5) </cmt> <cmt> this is a backport of ad03952. </cmt>","workaround for missing ac_prog_sed, drop to autoconf 2.59"
3735,<desc> description: based on #29379 comments it sounds we may want the automation to be reloadable only by the admin users. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: </desc> <cmt> homeassistant/components/automation/__init__.py </cmt> <cmt> register automation.reload as an admin service. </cmt>,register automation.reload service as an admin service.
3736,"<desc> allows for testing with various versions of python (relatively independently of os version), simplifies and parallelizes testing logic. </desc> <cmt> base test docker image on python images </cmt> <cmt> fix py3 build </cmt> <cmt> fixes for python-based dockerfile </cmt> <cmt> re-enable py27 build </cmt> <cmt> remove requirements_dev.txt and unittest.cfg (cleaning up build pipeline) </cmt>",test docker images based on python images
3737,<desc> proposed changes upgrade spring cloud consul to the latest version minor fixing include java example and configuration for leadership election with consul pull request checklist please check if your pr fulfills the following requirements: tests build locally code format / lint docs have been reviewed and added other information i followed those guidelines how consul can help in the leadership election using sessions and k/v store </desc> <cmt> include the following changes: </cmt> <cmt> - upgrade spring cloud consul to latest version </cmt> <cmt> - deploy the spring boot version as web as described in the article </cmt> <cmt> - add leadership-consul dependendencies </cmt> <cmt> add leadership election example and configuration </cmt>,bael-3217 leadership election with consul
3738,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: mrdoob/three.js#15015 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update accepted material types to match documentation </cmt> <cmt> fix aframe-io-tests </cmt> <cmt> fix spritecanvasmaterial </cmt> <cmt> fix meshfacematerial </cmt> <cmt> fix spritematerial </cmt>",update object materials to match documentation
3739,"<desc> to me it seemed weird that this is a mixin that always returns the line color: #xxx; i modified it to be an actual function and only return a value to be used in any property also updated every use of the 'function' to use the actual function </desc> <cmt> updating fork of bs to v4-beta1 </cmt> <cmt> browsers-devices.md: fix typo. (#23495) </cmt> <cmt> update from official repo </cmt> <cmt> update forked v4-dev </cmt> <cmt> modified the yiq to to an actual function </cmt> <cmt> function only returns a value, not the attribute itself </cmt> <cmt> updated every use of the former mixin to use the new function </cmt>",change yiq mixin to an actual function
3740,"<desc> hi, this solve the issue #2491 and i hope future issues of the same type. </desc> <cmt> trying skip devices instead of return -1 </cmt> <cmt> switch to skip instead return -1 for all checks, moved cuda counter update to the end of loop </cmt> <cmt> use skip also with first checks of backend_session_begin() </cmt>",skipping devices instead of stop with error
3741,"<desc> taking over #12085. besides fixing the average path length for isolationforest this pr also improves the checks for the predicted number of outliers in the common tests. closes #12085, fixes #11839 only modifications in the tests were required. </desc> <cmt> fix issue  #11839 </cmt> <cmt> fix issue #11839 : sklearn.ensemble.isolationforest._average_path_length returns incorrect values for input < 3. </cmt> <cmt> add non-regression test. </cmt> <cmt> changed existing test to reflect correct values now produced by _average_path_length(), and added checks to ensure non-regression on all ""base case"" values in {0,1,2}. </cmt> <cmt> improve comment & test. </cmt> <cmt> made recommended enhancements to comments, and change assert_almost_equal to assert_equal where constants should be returned. </cmt> <cmt> fix tests in tie cases & match conventions. </cmt> <cmt> change assert_equal to assert ... == to adhere to latest conventions, and change test to properly deal with anomaly score ties in critical regions if 'decision_function' method is supported by the estimator in question, or default to the old behavior if not. </cmt> <cmt> sundry convention tweaks. </cmt> <cmt> add tests of tests. </cmt> <cmt> refactoring and adding more tests to try and get coverage to an acceptable level. </cmt> <cmt> fix test to take lof into account </cmt> <cmt> fix check_outlier_corruption and corresponding tests </cmt> <iss> sklearn.ensemble.isolationforest._average_path_length returns incorrect values for input < 3. </iss>",fix iforest average path length
3742,<desc> i used systemd for celery today and found out that the given example did not work so i just fixed that and updated the doc. please note that i also fixed a missing dash (-) in the .service file for the --logfile argument. </desc> <cmt> fix systemd example file (fixes #2131) </cmt> <cmt> update sample celery files and improve daemonizing with systemd doc </cmt>,update systemd extra files and update doc
3743,<desc> resolves devrel-1530 - private access: create tutorial for security group feature select one: select any that apply: </desc> <cmt> add first draft of privacy feature tutorial :doc </cmt> <cmt> rename privacy feature tutorial filename :doc </cmt> <cmt> add review edits to privacy feature tutorial :doc </cmt>,add privacy access feature tutorial
3744,"<desc> fixes #3830. this adds a setting redis_backend_use_ssl, identical to broker_use_ssl, but used by the backend to determine whether it should use ssl. it also updates the broker_use_ssl documentation which was previously only correct for pyamqp and not redis. </desc> <cmt> add redis_backend_use_ssl option </cmt> <cmt> correct documentation for broker_use_ssl with redis </cmt> <cmt> the previous documentation was only correct for pyamqp but not redis, </cmt> <cmt> which doesn't allow true and requires a slightly different set of keys </cmt> <cmt> when passing a dictionary. </cmt> <cmt> document redis_backend_use_ssl </cmt>",add ssl option for redis backends
3745,"<desc> this pr begins to implement docs recommendations from the plugin authoring workflow evaluation found in #20232 in the effort to improve gatsby workflows from #13708. the changes here make updates to some of the overview pages to link to more recent guides on plugins that have been added as well as adding additional context. i added an example repository for loading local plugins using several different methods as well as a section on verifying that your plugin is loading since those were some things i had questions with when i started loading my own custom local plugins. related to #20232 i also started working on a flowchart/table of plugin vs theme vs starter features in reference to this card on the learning roadmap project: </desc> <cmt> additional examples to loading/creating, and plugin authoring overview pages </cmt> <cmt> correct minor errors and add tweaks to titles </cmt>",plugin authoring workflow overview pages
3746,"<desc> add properties in doc.to_json if they were set, not if they're available. this way, if a processed doc exports ""pos"": none, it means that the tag was explicitly unset. if it exports ""ents"": [], it means that entity annotations are available but that this document doesn't contain any entities. before, this would have been unclear and problematic for training. add doc.is_nered (lol) to indicate if entities have been set. also returns true if not all tokens have entity tags set, e.g. if some tokens have unknown values. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> use default return instead of else </cmt> <cmt> add doc.is_nered to indicate if entities have been set </cmt> <cmt> add properties in doc.to_json if they were set, not if they're available </cmt> <cmt> this way, if a processed doc exports ""pos"": none, it means that the tag was explicitly unset. if it exports ""ents"": [], it means that entity annotations are available but that this document doesn't contain any entities. before, this would have been unclear and problematic for training. </cmt>",improve doc.to_json and add doc.is_nered
3747,<desc> fixed building package on debian jessie lowered initial hashtable size for aggregatefunctiontopk from #778 </desc> <cmt> build: pass path to debuild </cmt> <cmt> this fixes build on debian </cmt> <cmt> iostream_debug_helpers: fixed build </cmt> <cmt> aggregatefunctiontopk: smaller initial table size </cmt> <cmt> by default start with 2^4 elements </cmt>,"fixed build on debian, lower aggregatefunctiontopk initial size"
3748,"<desc> good morning, i just found this project and it looks awesome. i will probably be joining as a contributor soon, but wanted to start off with something simple that most people don't enjoy taking: grammar fixes! i helped a bit with punctuation and restructured a few sentences without altering meaning, as well as adding uppercase letters in the beginning of a few sentences. i hope you find my changes to your liking. </desc> <cmt> fix grammar and punctuation a bit </cmt> <cmt> add uppercase where it seemed fit </cmt>",fix grammar and punctuation in readme.md
3749,<desc> cleaned up and adjusted #7601 add a new configuration to inhibit xyz movements if homing hasn't been done. </desc> <cmt> only marlinconfig.h ahead of feature block </cmt> <cmt> implementing [fr] #7548 </cmt> <cmt> added new configuration to inhibit xyz movements when home is not done </cmt> <cmt> updated all examples configurations </cmt> <cmt> forgot to update examples configurations. done now </cmt>,option to disallow motion before homing
3750,"<desc> noticed that syntax like vec![0; 5] is never mentioned in vec<t>'s docs, nor used in any of its methods' docs, so i figured i should add a mention of it. also noticed vec!(1, 2) being used in one spot while i was at it, so i fixed that as well for consistency's sake. r? @steveklabnik </desc> <cmt> mention vec![x; len] syntax in vec docs </cmt> <cmt> make docs for vec::push() use vec! with square brackets </cmt>","mention vec![x; len] syntax in vec<t> docs, fix inconsistent use"
3751,"<desc> this pr fixes #86288 while commit 520c999 fixed problem with main search field types in ""files to include/exclude"" fields still produced a ton of new history entries. this pr make history entries for these fields created on type delayed in the same way as search field to prevent pollution. alternative implementation can be used if there is need to handle immediate history submit in case when triggeredontype === false, but it looks a bit overkill if only one field can be edited at the time and it will save own history entry on enter. other should be already saved (even by timeout) in general case (i doubt that users will tab to next field and continue typing so ""save"" will be delayed for 2 fields at the same time). </desc> <cmt> also delay include/exclude pattern fields </cmt> <cmt> force pattern fields history save on enter </cmt> <iss> search history pollution with search.searchontype enabled </iss>","debounce on type history entries for ""files to include/exclude"" fields"
3752,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. x] run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. </desc> <cmt> adding class and method descriptions for exchange api </cmt> <cmt> adding class and method descriptions for exchange api - hyperlink fix </cmt> <cmt> adding class and method descriptions for exchange api - note fixing </cmt> <cmt> outlook documentation migration - spacing </cmt>","adding class, method, and parameter descriptions to exchange apis in office.js"
3753,"<desc> hot fix because in some cases additionalproperties in the available_node_types schema breaks validation. it's unclear why or when, but it seems to be prevalent and not caught by unit tests. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> . </cmt> <cmt> fix </cmt> <cmt> cleanup </cmt>",remove additionalproperties from available_node_types schema
3754,"<desc> what this pr does / why we need it: uses git archive to embed version information in the kubernetes source tarball produced in releases. due to recent changes, the version information was missing from the source tarball, causing builds from these source tarballs to potentially fail. this also includes a fix inspired by #56216, since the ld flags in hack/lib/version.sh are not space-safe. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #56246 release note: /assign @david-mcmahon /priority urgent-soon /sig release </desc> <cmt> rename tree state from 'git archive' to 'archive' </cmt> <cmt> use git archive to produce kubernetes-src.tar.gz when possible </cmt> <iss> version information missing from kubernetes-src.tar.gz </iss>",use git archive to produce kubernetes-src.tar.gz when git tree is clean
3755,"<desc> here is the idea: packages should use editor and its methods the main api to manipulate text. this pr removes functionality from editorview that was being used to manipulate text. </desc> <cmt> remove delegate methods from editorview </cmt> <cmt> fix editorview spec </cmt> <cmt> fix core specs </cmt> <cmt> add commonly used editor methods to editor view </cmt> <cmt> mini-editors use these methods very often, but really we shouldn't need to do </cmt> <cmt> this. </cmt>",remove editor view delegate methods
3756,"<desc> cleanup remove unused binddescription struct from youtube-api-wrappers.hpp remove unused members of channeldescription and streamdescription structs as well as related code fixes restore auth.reset() on service switch (fixes #5236) obsolete code makes us unhappy. so do bugs. compiled on windows, verified that #5236 is no longer happening. bug fix (non-breaking change which fixes an issue) code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. </desc> <cmt> ui: remove unused struct </cmt> <cmt> ui: restore auth reset when switching services </cmt> <cmt> fixes #5236 </cmt> <cmt> ui: remove obsolete/unused struct members </cmt> <iss> switching from a streaming service with linked account to service with stream key leaves account linked </iss>",more youtube cleanup and fixes
3757,"<desc> summary allow unrolling rnns with input_length=1. for e.g, this is required to deploy seqseq models on mobile (tflite doesnt support symbolic loop) related issues pr overview </desc> <cmt> allow len1 </cmt> <cmt> add test </cmt> <cmt> pep8 </cmt>",allow unrolled rnns with input_length=1
3758,"<desc> two commits: don't allow slow timer callbacks to block script event handling (including quit). timers added from idle observers could fire long after they're due. more details and example at the commit messages. </desc> <cmt> lua: timers: don't block forever with slow callbacks </cmt> <cmt> previously, process_timers() kept going as long as there were due </cmt> <cmt> timers, which could be for extended periods of time or even forever </cmt> <cmt> if there were slow timer callbacks with either periodic timers or if </cmt> <cmt> timers were added repeatedly. </cmt> <cmt> this prevented dequeuing mpv events, and subsequently, among others, </cmt> <cmt> prevented mpv from quitting until process_timers() completed. </cmt> <cmt> for instance, this caused process_timers() to never return: </cmt> <cmt> function render() <longer than 1/60 s on a slow system> end </cmt> <cmt> mp.add_periodic_timer(1/60, render) </cmt> <cmt> similarly, it never returned if a timer callback always added a new </cmt> <cmt> one-shot which was already due by the time the callback completed. </cmt> <cmt> this commit ensures that process_timers() only executes callbacks which </cmt> <cmt> were due when it started, so that timers which are added (or repeated) </cmt> <cmt> during process_timers() will wait for the next iteration - after mpv </cmt> <cmt> events are dequeued. </cmt> <cmt> this has no performance impact under normal conditions (when callbacks </cmt> <cmt> complete before the next timer is due). </cmt> <cmt> additionally, previously idle-observers were executed unconditionally </cmt> <cmt> after the timers because indeed there was nothing due when (if...) </cmt> <cmt> process_timers() completed. however, now process_timers() can return </cmt> <cmt> even if there are due timers, so skip idle-observers on such case. </cmt> <cmt> lua: idle observers: ensure timers are up-to-date </cmt> <cmt> this fixes two issues, both of which resulted from the timers-wait </cmt> <cmt> period not being re-calculated after idle-observers were executed: </cmt> <cmt> - if timers were added from an idle observer then they could fire long </cmt> <cmt> after they were due (only when/if the next mpv event arrives). </cmt> <cmt> - idle observers don't execute in zero time, and the wait period for </cmt> <cmt> the next timer was implicitly extended by the idle observers </cmt> <cmt> execution time (because it was calculated before the idle observers). </cmt> <cmt> this commit ensures that if idle-observers were executed, then the </cmt> <cmt> timers wait period is re-calculated, which solves both issues. </cmt>",refine timers and idle observers
3759,"<desc> this pull request handles part of the problem raised in issue #380. specifically, urls whose scheme is not http or https will throw valueerrors. </desc> <cmt> added failing test for issue #380. </cmt> <cmt> remove a wayward change. </cmt> <cmt> fail if unsupported schemas are used. </cmt> <cmt> requests only supports http and https. this change enforces that. </cmt> <cmt> correct unfortunate typo. </cmt>",provide useful exceptions for unexpected urls.
3760,"<desc> this pr adds the rgblight_set_effect_range(start_pos, num_leds) to quantum/rgblight.c. use as in the following example. (i also updated the documentation. docs) #ifdef rgblight_enable // the first three leds are used as indicators for caps_lock, num_lock and scroll_lock. void keyboard_post_init_user(void) { rgblight_set_effect_range(3, rgbled_num-3); led_set_user((1<<usb_led_caps_lock)|(1<<usb_led_num_lock)|(1<<usb_led_scroll_lock)); wait_ms(300); led_set_user(0); } #define hsv_black  0, 0, 0 void led_set_user(uint8_t usb_led) { if (usb_led & (1<<usb_led_caps_lock)) { sethsv_raw(hsv_white, (led_type *)&led[0]); } else { sethsv(hsv_black, (led_type *)&led[0]); } if (usb_led & (1<<usb_led_num_lock)) { sethsv_raw(hsv_green, (led_type *)&led[1]); } else { sethsv(hsv_black, (led_type *)&led[1]); } if (usb_led & (1<<usb_led_scroll_lock)) { sethsv_raw(hsv_yellow, (led_type *)&led[2]); } else { sethsv(hsv_black, (led_type *)&led[2]); } rgblight_set(); } void my_sethsv_range(uint8_t hue, uint8_t sat, uint8_t val, uint8_t start, uint8_t end) { led_type tmp_led; sethsv_raw(hue, sat, val, &tmp_led); for (uint8_t i = start; i < end; i++) { led[i] = tmp_led; } rgblight_set(); } uint32_t layer_state_set_kb(uint32_t state) { switch (biton32(state)) { case _raise: // the top row is used as raise and usb led indicator. rgblight_set_effect_range(matrix_cols, rgbled_num-matrix_cols); my_sethsv_range(hsv_white, 3, matrix_cols); break; case _lower: // the top row is used as lower and usb led indicator. rgblight_set_effect_range(matrix_cols, rgbled_num-matrix_cols); my_sethsv_range(hsv_green, 3, matrix_cols); break; case _adjust: // the top two lines are used as adjust and usb led indicators. rgblight_set_effect_range(matrix_cols*2, rgbled_num-matrix_cols*2); my_sethsv_range(hsv_red, 3, matrix_cols*2); break; default: rgblight_set_effect_range(3, rgbled_num-3); rgblight_sethsv_noeeprom(rgblight_config.hue, rgblight_config.sat, rgblight_config.val); break; } return state; } #endif my code follows the code style of this project. i have read the contributing document. </desc> <cmt> add rgblight_set_effect_range() </cmt> <cmt> implement effect range </cmt> <cmt> arrange the order of function list in rgblight.h . </cmt> <cmt> update docs/feature_rgblight.md </cmt> <cmt> fix rgblight_rainbow_swirl_range default value </cmt> <cmt> add example code about utility functions </cmt> <cmt> add example code about direct operation functions </cmt> <cmt> when rgblight_split is defined, the following function has no meaning and is invalidated. </cmt> <cmt> * rgblight_setrgb_master(r, g, b) </cmt> <cmt> * rgblight_setrgb_slave(r, g, b) </cmt> <cmt> * rgblight_sethsv_master(h, s, v) </cmt> <cmt> * rgblight_sethsv_slave(h, s, v) </cmt> <cmt> add temporary test code for rgblight_set_effect_range </cmt> <cmt> fix rgblight_effect_knight() bug </cmt> <cmt> test end. revert ""add temporary test code for rgblight_set_effect_range"" </cmt> <cmt> this reverts commit 5680cddd012d68b2db75a532862a7fef250f8973. </cmt>",add effect range to rgblight.c
3761,"<desc> adds a few functions to mark and span that i found useful in an upcoming refactor of nll region error reporting. also includes some new documentation based on my discussion with @jseyfried on irc. r? @jseyfried </desc> <cmt> add documentation for syntaxcontext::remove_mark </cmt> <cmt> implement parent() on syntax_pos::span </cmt> <cmt> ... and reimplement proc_macro::span::parent using it. this function turns out </cmt> <cmt> to be useful in the compiler as well </cmt> <cmt> implement a least upper bound for marks. </cmt> <cmt> this is useful when trying to compute when something is lexically before </cmt> <cmt> something else, but they aren't necessarily in the same syntaxcontext </cmt>",add some utilities to libsyntax
3762,"<desc> changes to jison spec to allow underscores in entity names and entities with no relationships.  minor updates to docs, unit tests, and e2e tests resolves #1710 no real design involved; simple changes to improve flexibility </desc> <cmt> allow underscores in entity names, and entities with no relationships </cmt> <iss> support underline for table names in er diagrams </iss>",bug/1710 underscore in entity names
3763,"<desc> this pr addresses all the basic setup required to implement capturing child tasks. it was discussed in the simple design doc with @ericl. it implements pg.ready() & pg.bundle_spec calls gcs server to obtain bundle when they are called for the first time. this helps us to avoid having bundles as an argument of class placementgroup. setup placement group id to the worker context. for actors, it is set at the process level. for tasks, it is set at the thread level. get_current_placement_group api to obtain class placemenetgroup where a current task / actor belongs to. #9808 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> in progress. </cmt> <cmt> in progers. </cmt> <cmt> done. </cmt>",capture child task part 1
3764,"<desc> signature help for tagged templates this pr enables signature help support in the language service for tagged template strings. the idea is that a tagged template is a bit of an implicit function invocation. whenever a user requests signature help (or it is triggered by the consuming environment), we should figure out what function a tag refers to, which overload should be chosen, and which parameter is currently being fed. substitution-argument correspondence when a template expression is tagged, each substitution expression corresponds to an argument in invoking that tag. specifically, the nth substitution expression in a tagged template expression is the (n+1)th argument in an invocation. templatestringsarray argument whenever the cursor lies within a template literal (whether a no-substitution literal, or a fragment of a template expression), the parameter in question is the first parameter of the tag in question. this is because each template literal in a tagged template corresponds to an array element in the cooked/raw array object specified in es6. this means that as the cursor moves through a template expression, parameters will not be highlighted from left-to-right consistently. </desc> <cmt> initial signature help work for tagged templates. </cmt> <cmt> stylistic changes/comment fixups. </cmt> <cmt> got sig help working in the template head. </cmt> <cmt> got sig help working in tagged no-sub templates. </cmt> <cmt> refactored code, adjusted for residing out of bounds of the template. </cmt> <cmt> fixed isunclosedtemplateliteral to account for new possible inputs. </cmt> <cmt> conflicts: </cmt> <cmt> src/services/signaturehelp.ts </cmt> <cmt> fixed template head offsetting. </cmt> <cmt> tests for signature help on tagged templates with no overloads. </cmt> <cmt> added tests for overloads. </cmt> <cmt> fixed broken test. </cmt>",tagged template signature help support in language service
3765,"<desc> my next plugin ;) node.js plugin readme page section in node.d/readme.md default configuration in conf.d/node.d/stiebeleltron.conf.md updated infographic. had to move the lowest section down a bit, to provide space for this and future plugins i didn't update the ""add charts"" wiki yet. should i split the ""ups and power"" section into ""ups"" and ""household appliances""? or just a new section? which links would get broken? i'm thinking of moving the solar power plugins and this one to ""household"", which would make more sense to me. i'm aware that the plugin is collecting values based on a rather large json configuration (definition of charts, dimensions etc.). i decided to do it in this way so that other people are able to collect different values in their systems. i cannot provide a plugin that is working for every setup, since i cannot test them (there are air/water systems, geothermal probes, etc). but i can make it adaptive. also the metrics are collected using regex. not optimal but there is no direct api (afaik) and performance-wise they are just fine (some 0.9% spikes on a intel xeon). the slowest component is the device response itself (usually around 1s, sometimes it takes up to 4s). </desc> <cmt> first implementation </cmt> <cmt> first working implementation. </cmt> <cmt> improvements to dashboard </cmt> <cmt> create stiebeleltron.conf.md </cmt> <cmt> update isg web link </cmt> <cmt> fixed dimension id bug. </cmt> <cmt> renamed charts of output in the default config. </cmt> <cmt> update netdata-overview.xml with stiebel eltron logo </cmt> <cmt> added the stiebel eltron wiki </cmt>",add plugin for stiebel eltron heat pump system
3766,"<desc> if user never made a new virtual desktop, there will be no information about virtual desktop id in the registry, and zeroed-guid will be used. migrate persisted information for zeroed-guid in primary desktop when virtual desktop switch occurs. don't use ivirtualdesktopmanager::getwindowdesktopid on getforegroundwindow during initialization. if powertoys start right away when system starts, getforegroundwindow might not contain valid hwnd, and we could end up with zeroed-guid. pr checklist applies to: #7790 #7011 cla signed. if not, go over here and sign the cla validation steps performed clear the registry (both software\microsoft\windows\currentversion\explorer\sessioninfo\\virtualdesktops and software\microsoft\windows\currentversion\explorer\virtualdesktops) and persisted fancyzones settings (c:\users<user-name>\appdata\local\microsoft\powertoys\fancyzones), reboot the machine. start powertoys and apply either template or custom layout on primary desktop. verify that layout information is persisted, and zeroed guid is used to define primary desktop. create new virtual desktop. verify that layout information for primary desktop is preserved, but guid is updated to the real one. </desc> <cmt> update primary desktop data after virtual desktop switch </cmt> <cmt> don't remove zeroed-guid inside removedeleteddesktops method </cmt>",update primary desktop data on virtual desktop switch
3767,"<desc> a point is a fairly basic abstraction that is better put in common (along with rectangle, and vec), which can then be reused elsewhere without bringing in any unrelated code. </desc> <cmt> common: extract point into a common struct </cmt> <cmt> this is generic enough that it can be moved into the common class for </cmt> <cmt> reuse. </cmt> <cmt> touchscreen: make use of common point struct </cmt>",extract point struct into common
3768,"<desc> this is something i always need when making some pixel art / graphics, so i've added this feature. preview: pixel_grid_demo.mp4 special mention to @tobyase for fixing the bug that allows this to work nicely :^) </desc> <cmt> pixelpaint: show a pixel grid when zoomed in enough </cmt> <cmt> the editor now draws a grid showing the pixels if you are zoomed </cmt> <cmt> in enough. currently the threshold is a scale of 15 (so if one </cmt> <cmt> pixel side on the image takes up > 15 pixels in the editor) </cmt> <cmt> pixelpaint: add menu action to toggle pixel grid visibility </cmt> <cmt> you can now toggle on/off the visibility of the pixel grid from </cmt> <cmt> the view menu, if you don't want it shown for some reason. </cmt>",show a pixel grid when zoomed in :^)
3769,"<desc> for #22821 the first approach we tried was #25325. this only logs the messages from allocation commands once the cluster state update has been acknowledged. @ywelsch (who i got this in a little too late for) recommended to hold off on exposing it in the rest layer for now. </desc> <cmt> wip #22821 </cmt> <cmt> write the messages as a new element to the reroute response. </cmt> <cmt> tests not passing </cmt> <cmt> wip #22821 </cmt> <cmt> build messages from explanations and log them on cluster state </cmt> <cmt> ack. it passes </cmt> <cmt> wip #22821 only log if dry run, fill in it which passes </cmt> <cmt> wip #22821 clean up imports and formatting </cmt>",log messages from allocation commands
3770,"<desc> some sample sites still had 'copyright 2012' in the footer, updated to 2013. </desc> <cmt> update docs/examples/fluid.html </cmt> <cmt> updated copyright to 2013 </cmt> <cmt> update docs/examples/carousel.html </cmt> <cmt> updated copyright to 2013 </cmt> <cmt> update docs/examples/hero.html </cmt> <cmt> updated copyright to 2013 </cmt> <cmt> update docs/examples/marketing-alternate.html </cmt> <cmt> updated copyright to 2013 </cmt> <cmt> update docs/examples/marketing-narrow.html </cmt> <cmt> updated copyright to 2013 </cmt>",updated copyright to 2013 in examples
3771,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add accesstype to jest.spyon </cmt> <cmt> adjust version </cmt>",add accesstype to jest.spyon as supported in jest 22.1.0+ for types/jest
3772,"<desc> original pull-request #13386 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> done </cmt> <cmt> fix build </cmt> <cmt> update ownsplitchannel.cpp </cmt> <cmt> fix style </cmt> <cmt> deadlock in textlog </cmt>",cherry pick #13386 to 20.4: deadlock in textlog
3773,<desc> new features apis add complex apis: paddle.real paddle.imag paddle.conj cherry-pick prs: #29603 #29672 #29527 </desc> <cmt> add complex dtype op (add) test example (#29603) </cmt> <cmt> * add op test case for complex </cmt> <cmt> * polish code details </cmt> <cmt> * add xpu set constant support </cmt> <cmt> * fix argument rror </cmt> <cmt> * remove useless pyc file </cmt> <cmt> [complex] add real & imag op and api for complex tensor (#29672) </cmt> <cmt> * add complex real op & api & unittest </cmt> <cmt> * add imag op & api & unittest </cmt> <cmt> * refactor op impl </cmt> <cmt> * revert simplify writing due to complile failed </cmt> <cmt> * polish details </cmt> <cmt> * polish grad op code </cmt> <cmt> add conj op for complex types (#29527) </cmt> <cmt> * add conj op for complex types </cmt> <cmt> * add conj for complex types </cmt> <cmt> * add more test case </cmt> <cmt> * add conj_op test </cmt> <cmt> * modify conj api and impl </cmt> <cmt> * add complex type for fill_constant_op xpu </cmt> <cmt> * add setconstant for complex type </cmt> <cmt> * remove complex conj test file </cmt> <cmt> * user define grad for test_conj_op </cmt> <cmt> * add test case for static mode of conj api </cmt> <cmt> * modify conj doc </cmt> <cmt> * change input args name to x </cmt> <cmt> * remove useless codes </cmt> <cmt> * conj support real types </cmt> <cmt> * add conj test case for real number </cmt>,"add complex api conj, real and imag"
3774,"<desc> this pr silences some compiler warnings, and also fixes an error in cvideoinfoscanner where an int parameter was used as a string. </desc> <cmt> rendermanager: fix log line </cmt> <cmt> guidialogaddoninfo: fix compiler warning </cmt> <cmt> warning was: </cmt> <cmt> comparison of integers of different signs: 'int' and 'size_type' (aka 'unsigned long') </cmt> <cmt> videoinfoscanner: fix logging error </cmt> <cmt> guiwindowslideshow: fix signed vs. unsigned compiler warnings </cmt> <cmt> stringutils: fix signed vs. unsigned compiler warning </cmt> <cmt> colormanager: fix signed vs. unsigned compiler warning </cmt> <cmt> capplication: fix initialization order </cmt> <cmt> this fixes the following compiler warning: </cmt> <cmt> field 'm_processedexternalcalls' will be initialized after field 'm_ignoreskinsettingchanges' </cmt>",fix 1 error and 5 compiler warnings
3775,"<desc> fix issue #5953 by giving its associated opening tag. initially, the pr tried to address preventing adding the global symbols that is not in jsx into the opening tag. however, doing so cause some inconsistent so the change is rolled back. </desc> <cmt> update tests </cmt> <cmt> don't include completion in opening tag, include name of opening in closing tag </cmt> <cmt> update baseline from returning with unknownsymbol </cmt>",fix crash inside jsx closing tag
3776,<desc> performance optimization ops this pr optimize current implementations for sgd and sum operators for bf16 data type (mainly) when selectedrows (sparse) tensors were used by reusing onednn handler. the performance results on word2vec model are as follows on cpx 6348 machine with single thread: commit engine words/sec bf16 c56d697 onednn 18142.32 bf16 this pr onednn 20814.31 fp32 c56d697 cpu 27680.99 this gives ~15% speedup. from profiling: commit sgd total[ms] sgd % sum total[ms] sum % fp32 c56d697 117.77 2.5 395.31 8 bf16 c56d697 954.94 8.6 5151.35 47 bf16 wo cache 339.28 4.6 2159.22 29 </desc> <cmt> create stateful onednnaxpyhandler object. </cmt> <cmt> this makes it possible to call it multiple times without recreating the </cmt> <cmt> onednn primitives every time. </cmt> <cmt> prepare sgdopkernel to reuse its implementation from onednn kernel. </cmt> <cmt> onednn sgd kernel. </cmt> <cmt> update call to use new onednnaxpyhandler object api. </cmt> <cmt> setup seed in proper place. </cmt> <cmt> enable onednn kernel only for single case. </cmt> <cmt> * for dense param and sparse grad. </cmt> <cmt> small refactor. </cmt> <cmt> enable onednn by op attr or by cmd line flag. </cmt> <cmt> use int64_t type for number of elements. </cmt> <cmt> support dense param and grad from onednn kernel. </cmt> <cmt> enable sgd onednn kernel when use mp bf16 optimizer. </cmt> <cmt> force non-copyable/movable onednnaxpyhandler. </cmt> <cmt> reuse onednnaxpyhandler for spare tensors in sum op. </cmt>,reuse onednn handler for sgd and sum for selectedrows input tensors.
3777,"<desc> issue: follow up to #13775 i added support for vue 3 in addon-storyshots. additionally, i added some more stuff to the vue-3-cli example that makes it easier to try out the storyshots stuff. as you can see, i was able to successfully generate the snapshots with storyshots, but those can't run during a normal test run because of all the troubles i've been encountering with having vue 2 and vue 3 in the dependency tree of this monorepo. is this testable with jest or chromatic screenshots? generated but not run on normal test runs does this need a new example in the kitchen sink apps? added does this need an update to the documentation? updated the readme for storyshots </desc> <cmt> feat: utilize typescript in vue 3 example files </cmt> <cmt> chore: cleanup some vue 3 example stories </cmt> <cmt> feat: add vue3 support to storyshots </cmt> <cmt> feat: add storyshots to vue 3 example but disable in suite </cmt> <cmt> docs: document vue3 storyshots setup </cmt>",add support for vue 3
3778,"<desc> the slug package support an option to allow having whitespace at the end of a string. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  add it to notneededpackages.json. </desc> <cmt> adds trim property for the slug package </cmt> <cmt> the slug package support an option to allow having whitespace at the end of a string. </cmt> <cmt> update slug-tests.ts </cmt>",slug@v5.1.0 - adds trim property for the slug package
3779,<desc> what types of changes does your pr introduce? put an x in all boxes that apply </desc> <cmt> add royal tsx to remote login software </cmt> <cmt> add raycast to productivity </cmt> <cmt> add vectornator to design tools </cmt> <cmt> add vectornator to design tools </cmt> <cmt> add responsively to developer utilities </cmt> <cmt> add responsively to developer utilities </cmt>,add responsively to developer tools
3780,"<desc> as null safety feature for flutter driver was merged (#67570), we'd need to reland the extension feature patch (#67456). it should be compliant now, no lint nor build errors are reported. related issues #67570 #67456 packages/flutter_driver/test/src/real_tests/extension_test.dart before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> flutter driver - create widget finders from serialized finders extensions </cmt> <cmt> add license header </cmt> <cmt> tests </cmt> <cmt> add new line </cmt> <cmt> stubs & tests </cmt> <cmt> widget tests </cmt> <cmt> fix tests typo </cmt> <cmt> expose finder factory to finder creator </cmt> <cmt> rename test variable </cmt> <cmt> format </cmt> <cmt> remove trailing whitespaces </cmt> <cmt> null safety </cmt>","reland ""flutter driver - create widget finders from serialized finders extensions"" with null safety"
3781,"<desc> miscellaneous cleanups for same-type requirements: use isderivedrequirement() consistently, which fixes an issue that showed up in printing, clean up printing via requirement signatures a little, associating self == self.a requirements with a when we can </desc> <cmt> [gsb] use isderivedrequirement() for same-type connected components </cmt> <cmt> [ast printer] associate ""self == self.foo requirements with ""foo"". </cmt> <cmt> [ast printer] swap the order of ""self == self.a"" requirements associated with a </cmt> <cmt> it looks better this way. </cmt>",clean up handling of same-type requirements
3782,"<desc> the main patch is by klim with some subsequent updates and fixes </desc> <cmt> add ipp support in resize, warpaffine, warpperspective functions </cmt> <cmt> fixed bug in ipp-accelerated morphology; added several ipp imgwarp functions (by klim) </cmt>","accelerated resize, warpaffine, warpperspective using ipp"
3783,"<desc> fixes #43493. </desc> <cmt> fix getrecursionidentity, undo changes from #43435 (but keep tests) </cmt> <cmt> remove test that takes excessively long to run </cmt> <cmt> accept new baselines </cmt> <cmt> fix formatting </cmt> <iss> ""excessive stack depth comparing types 'flatarray<arr, ?>' and 'flatarray<arr, ?>'"" false positive </iss>",fix getrecursionidentity function to always return some identity
3784,"<desc> discovered using clang's memorysanitizer. an msan build will fail by simply executing: ./python -c 'u""\n""' (cherry picked from commit 746b2d3) </desc> <cmt> fix an out of bounds memory access. </cmt> <cmt> news entry </cmt>",fix oob memory access in unicode escape parser (gh-10506)
3785,"<desc> update some behaviors of ndarrayiter change the functionality of class ndarrayiter last_batch_handle = roll_over. change the timing of shuffling. previously, it shuffles only during the initialization, which didn't meet training needs. the above change is tackled by #12285. this pr add the following thing, please refer to concat, edge case for end variable, unit test for different kinds of input of labels and ndarrayiter_csr fix index out of range error (#12526 #12539 #12538) by handling the missing labels case. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change shuffle when calling the reset. when last_batch_handle is roll_over, the last batch should be rolled over to next epoch add the unit tests for different situations (shuffle equals to true/false, data source is mx.ndarray/ np.ndarray, 3 last_batch handle parameters and pass the normal labels/ none/ empty list) @sandeep-krishnamurthy @zhreshold </desc> <cmt> 1. move the shuffle to the reset 2. modify the roll_over behavior accordingly </cmt> <cmt> refactor the concat part </cmt> <cmt> refactor the code </cmt> <cmt> implement unit test for last_batch_handle </cmt> <cmt> refactor the getdata part </cmt> <cmt> add docstring and refine the code according to linter </cmt> <cmt> 1. add test case for ndarrayiter_h5py 2. refactor the implementation </cmt> <cmt> update contributions doc </cmt> <cmt> fix wording </cmt> <cmt> update doc for roll_over </cmt> <cmt> 1. add test for second iteration of roll_over 2. add shuffle test case </cmt> <cmt> fix some wording and refine the variables naming </cmt> <cmt> move utility function to new file </cmt> <cmt> move utility function to io_utils.py </cmt> <cmt> change shuffle function name to avoid redefining name </cmt> <cmt> make io as a module </cmt> <cmt> rename the utility functions </cmt> <cmt> disable wildcard-import </cmt>",change the way ndarrayiter handle the last batch
3786,"<desc> with this pr we narrow the string and number types as appropriate when they are compared with values of literal types. function move(direction: ""up"" | ""down"") { // ... } function do1(command: string) { if (command === ""up"" || command === ""down"") { move(command);  // narrowed to type ""up"" | ""down"" } } function do2(command: string) { switch (command) { case ""up"": case ""down"": move(command);  // narrowed to type ""up"" | ""down"" break; } } function f1(x: number, y: 1 | 2) { if (x === 0 || x === y) { x;  // narrowed to type 0 | 1 | 2 } } function f2(x: number | ""foo"" | ""bar"", y: 1 | 2 | string) { if (x === y) { x;  // narrowed to type ""foo"" | ""bar"" | 1 | 2 y;  // narrowed to type ""foo"" | ""bar"" | 1 | 2 } } interestingly this found a bug in our scanner, pointing out that type 2 is not comparable to type 8. fixes #7447. fixes #10417. fixes #11306. </desc> <cmt> narrow string and number types in equality checks and switch cases </cmt> <cmt> fix bug in scanner </cmt> <cmt> properly narrow union types containing string and number </cmt> <cmt> accept new baselines </cmt> <cmt> add tests </cmt>",narrow string and number types in literal equality checks
3787,"<desc> two cleanups to the representation of archetypetype: eliminate the isrecursive bit that nobody is using; yay for single bits forcing 31 bits of padding. overlap 'associated type' and 'name' storage; the latter is derivable from the former. </desc> <cmt> [ast] drop the 'isrecursive' bit from archetypetype. nfc </cmt> <cmt> [ast] compress archetypetype's storage slightly. </cmt> <cmt> the ""associated type"" and ""name"" fields are mutually independent, </cmt> <cmt> because one can recover the name from the associated type. </cmt> <cmt> [serialization] simplify serialized representation of archetype types. </cmt> <cmt> we don't need to store the associated type declaration and name </cmt> <cmt> separately in the module file, either. </cmt>",improve the representation of archetypetype
3788,"<desc> i hereby agree to the terms of the cla available at: </desc> <cmt> clickhouse-2: support negative tests </cmt> <cmt> update client.cpp </cmt> <cmt> clickhouse-2 client testmode fixes: reconnect on clienterror, clear expected errors, return error to os </cmt>",fix client's --testmode (allow multiple negative tests with clienterror)
3789,"<desc> this pr updates keyedjsonatomicfielddata to always return ordinals in the range [0, (maxord - minord)], which is necessary for certain aggregations and sorting options to be supported. as discussed in #41220, i opted not to support keyedindexfielddata#getordinalmap, as it would add substantial complexity. the one place this affects is the 'low cardinality' optimization for terms aggregations, which now needs to be disabled for keyed json fields. it was fairly difficult to incorporate this change, and i have a couple follow-up refactors in mind to help simplify the global ordinals code. (i will likely wait until this feature branch is merged though before opening prs on master). </desc> <cmt> add unit tests that exercise ordinal rebasing. </cmt> <cmt> rebase global ordinals to lie in the range [0, (maxord-minord)]. </cmt> <cmt> add tests around cardinality aggregations. </cmt> <cmt> disable the low cardinality optimization to make sure getordinalmap is not accessed. </cmt>",rebase keyed json ordinals to start from zero.
3790,"<desc> reopening #1200 i cannot provide continuous integration for xboxone, but i was able to run the following tests with this change: //#include ""test/gtest-filepath_test.cc"" #include ""test/gtest-linked_ptr_test.cc"" #include ""test/gtest-message_test.cc"" //#include ""test/gtest-options_test.cc"" //#include ""test/gtest-port_test.cc"" #include ""test/gtest_pred_impl_unittest.cc"" #include ""test/gtest_prod_test.cc"" #include ""test/gtest-test-part_test.cc"" #include ""test/gtest-typed-test_test.cc"" #include ""test/gtest-typed-test2_test.cc"" //#include ""test/gtest_unittest.cc"" #include ""test/production.cc"" the others required getenv, chdir or capturestdout would this output be enough to get approval for the pull request? connect to pipe \sevpipe\9021f601f657ec5f </desc> <cmt> added support for winapi_partition_tv_title which is defined on xboxone </cmt> <cmt> added support for winapi_partition_tv_title which is defined on xboxone </cmt> <cmt> added support for winapi_partition_tv_title which is defined on xboxone </cmt>",added support for winapi_partition_tv_title to support xboxone applications
3791,"<desc> this is re-submission of #20687 but removed test import related changes. closes #20684 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> [job submission] use specific redis_address and redis_password instead of ""auto"" (#20687) </cmt> <cmt> fix test imports </cmt> <iss> [bug][jobs] job submission cli didn't work on first ray install </iss>",fix job server's ray init(to use redis address rather than auto
3792,<desc> this change is </desc> <cmt> disable redirection for wow64 processes. issue #899 </cmt> <cmt> fixing for winxp compatibility </cmt> <cmt> format code </cmt> <cmt> format code </cmt> <cmt> still trying to fix issues with 32bit systems </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/launcher/x64_dbg_launcher.cpp </cmt> <cmt> remove extra new line </cmt>,disable fs redirection for 64bit applications on wow64
3793,<desc> correctly check that an item does not exist in the aclk thread list and ignore it (instead of accessing invalid memory and crash) ignore error when attempting to wake up event loop (do not fatal) component name aclk the code is not active yet </desc> <cmt> make sure an element was found for removal </cmt> <cmt> remove fatal if async send fails </cmt> <cmt> add newline </cmt>,fix list corruption in aclk sync code and remove fatal
3794,<desc> use stable ship protocol for transaction_trace move eosio-tester type conversion to state_history library select one: select any that apply: </desc> <cmt> move eosio => ship type conversion to type_convert.hpp </cmt> <cmt> use ship protocol trnsaction_trace for amqp_trace_plugin </cmt>,amqp_trace_plugin ship protocol for transaction_trace
3795,<desc> this pr fixes asan detected global-buffer-overflow in issue #5281 . the fixes apply variable.defined() checks before reading any member variable of the variable. tested with asan_symbolizer_path=/usr/bin/llvm-symbolizer asan_options=symbolize=1 python test/test_autograd.py please review @ezyang @apaszke edit : reverted change in any_variable_requires_grad in function.h </desc> <cmt> fix asan buffer overflow in autograd saved_variable.cpp </cmt> <cmt> fix asan global buffer overflow in any_variable_requires_grad </cmt>,fix asan detected global buffer overflows in autograd
3796,"<desc> i've been working on synthetickeyboardevent test and have gotten a significant amount of tests to pass but wanted to see if the community had feedback on my work so far and advice on how to complete the few remaining tests where i am stuck. problem: i am unable to fire events and pass tests that require a 'keypress' event. i've looked thru other examples, specifically mdn docs and pr #11365 to fire the keypress event, specifically on line 41. via mdn and other pr's, i've found no significant difference on why a 'keypress' event and and the 'keydown'/'keyup' which fire as expected. @gaearon any feedback or tips would be on my approach/code appreciated </desc> <cmt> keyboardevent interface-keypress </cmt> <cmt> pass first 6 tests </cmt> <cmt> merge </cmt> <cmt> merge </cmt>",refactor synthetickeyboardevent tests to only use the public api
3797,"<desc> this implements the direct call <-> plasma interop described in  after this change, we have near feature parity for direct call tasks / actors on a single node. there are two remaining issues for full parity: failure handling. right now objects promoted to plasma have no task lease, so we need to add back fault handling so that workers don't block forever waiting for failed objects. spillback scheduling. direct call tasks aren't spilled yet. </desc> <cmt> wip </cmt> <cmt> fix test </cmt> <cmt> add mem test </cmt>",handle exchange of direct call objects between tasks and actors
3798,"<desc> feat: implementation of a* search algorithm. topic: ai/ml. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines this code might be too long, so any suggestions about any changes are welcome. </desc> <cmt> fix: lgtm warnings in... </cmt> <cmt> updating directory.md </cmt> <cmt> update current tree </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> feat: a* search algorithm, type: ai/ml </cmt> <cmt> type changes </cmt> <cmt> code reformatting. </cmt> <cmt> code reformatting-2 </cmt> <cmt> code refactoring-3. </cmt> <cmt> code refactoring-3. </cmt> <cmt> code refactoring-4. </cmt> <cmt> code refactoring-4. </cmt> <cmt> code refactoring-5. </cmt> <cmt> updating directory.md </cmt>","a star search, type: ai/ml"
3799,"<desc> detailed description / documentation draft: small blog post snippet that links to the mindsdb blog for further reading. </desc> <cmt> initial mindsdb blog post content and image references. </cmt> <cmt> update mindsdb blog post content, title and slug. </cmt>",blog post how to enable predictive capabilities in clickhouse
3800,"<desc> currently, travis runs 12 build jobs: (linux | osx) * (gcc | clang) * (googletest | googlemock | googlemock-c++11) but the googlemock build includes googletest already, including all unit tests and samples of googletest, so a separate build of googletest doesn't provide additional knowledge. by removing the googletest build, we can reduce the build number from 12 to 8 builds and thus get a much quicker response from travis, without reducing the test coverage. </desc> <cmt> switch on verbose make </cmt> <cmt> run combined build only </cmt> <cmt> there is no need for separate 'googlemock' and 'googletest' builds, </cmt> <cmt> as the 'googlemock' build includes 'googletest' and it's unit tests. </cmt>",reduce travis buildjobs by 4/12
3801,"<desc> fixes #17728 modifies section 1.12 multiclass and multilabel algorithms as follows: change section title to ""multiclass and multioutput algorithms"" to match sklearn module names (sklearn.multiclass and sklearn.multioutput) change overall section structure so that headers == problem type, and subheaders == target format and meta-estimators redistribute content from introduction (problem types, target formats) into corresponding sections rewrite the rest of the introduction to be concise, and to mention sklearn.multioutput add chart image to introduction that shows hierarchy of topics/classes fix :mod:/:class:/:func: links to sklearn.multioutput/sklearn.utils.multiclass that weren't rendering because of the presence of the ..currentmodule sklearn.multiclass directive apart from the introduction, right now the existing content is left largely unmodified -- i've simply moved it around into new header sections to improve clarity. that said, i feel some sections are still unclear, and could possibly use rewriting: the multiclass-multioutput classification section is tricky. it's the combination of multiclass and multioutput, so it doesn't read like a distinct problem type. that makes it tough to fit into the topic hierarchy. the existing content never mentions which meta-estimators support this. is it the same as meta-estimators which support the multilabel-indicator target type? this could be clarified. onevsrestclassifier, a multiclass estimator, can also do multilabel classification. this is unintuitive and potentially confusing! the class docstring was changed in #17646, but further changes could be made to the user guide and api reference to clarify the dual nature of this estimator. classifierchain and regressorchain sections are somewhat brief, and don't have usage examples. regarding the chart figure the chart image i added is possibly difficult to maintain. if changes are made to sklearn.multiclass or sklearn.multioutput, the image would need to be updated too. i wanted to generate the visualization programmatically, but i couldn't figure out how using sphinx/matplotlb/etc. i created it using google drawings, so here is a shareable link for anyone coming from the future wondering what the source of the chart image is. you should be able to make a copy and edit it if need be. </desc> <cmt> remove multilabel target format section </cmt> <cmt> this information is already presented in the prelude of this user guide </cmt> <cmt> page. </cmt> <cmt> restructure headers to match problem domains </cmt> <cmt> previously, headers were organized by strategy type. however, i feel it </cmt> <cmt> is easier to parse when organized by problem type. strategies are </cmt> <cmt> relegated to subheaders within each problem header. as well, a </cmt> <cmt> subheader for target format is added. </cmt> <cmt> no content is edited in this commit -- only headers. </cmt> <cmt> redistribute content from intro to new sections </cmt> <cmt> again, no edits made to the content itself -- simply redistributing </cmt> <cmt> content from the introduction to the body sections of the page. </cmt> <cmt> retitle section ""multiclass and multioutput"" </cmt> <cmt> the previous title was ""multiclass and multilabel"", but multilabel </cmt> <cmt> doesn't account for multioutput regression. this new title is more </cmt> <cmt> inclusive of all multilearning problem types. </cmt> <cmt> rewrite introduction to include multioutput module </cmt> <cmt> also included is a chart which outlines the responsibilities and </cmt> <cmt> classes for each module. </cmt> <cmt> clarify multioutput/multilabel classification term </cmt> <cmt> fix class/function links </cmt> <cmt> the ..currentmodule directive was set to sklearn.multiclass, so sphinx </cmt> <cmt> assumed all links were from that module. but, this guide contains links </cmt> <cmt> to sklearn.multioutput and sklearn.utils.multiclass. to make them </cmt> <cmt> render properly, i've removed the ..currentmodule directive, and updated </cmt> <cmt> links accordingly. </cmt> <cmt> update subheader titles to class names </cmt> <cmt> subheaders were previously titled either using the name of the strategy </cmt> <cmt> or the name of the problem type. when headers (not subheaders) were </cmt> <cmt> changed to problem types, this resulted in some subheaders having the </cmt> <cmt> same name as headers (e.g. ""multioutput regression""). this change fixes </cmt> <cmt> the conflicts. </cmt> <cmt> tweak multiclass-multioutput content </cmt> <cmt> * re-add entry to summary table </cmt> <cmt> * make sure all terms use ""multiclass-multioutput"" and not </cmt> <cmt> ""multioutput-multiclass"" </cmt> <iss> restructure ""section 1.12. multiclass and multilabel algorithms"" to make distinctions between concepts clearer </iss>",doc restructure multiclass and multilabel in user guide
3802,"<desc> #16763 is adding an internal listener. the internal listener is not driven by event dispatcher. however, it shares the common functionalities of structuring the ownership of connections with the tcp listener. this pr extracts the common functions out of activetcplistener so those can be reused by internal listener. the common includes activeconnection definition the helper method of remove an active connection and remove an filter chain risk level: low </desc> <cmt> initial internal listener </cmt> <cmt> for new pr </cmt> <cmt> merge main </cmt> <cmt> delete test/integration/internal_tcp_proxy_integration_test.cc </cmt> <cmt> coverage </cmt> <cmt> remove clientconnectionimpl ctor for internal socket </cmt> <cmt> revert dispatcher </cmt> <cmt> merged main </cmt> <cmt> revert internal listener </cmt>",move active connection collection out of active tcp listener
3803,"<desc> see #18751 for more info on the bug. this changes the ref counting protocol to make sure that workers report any nested objectrefs that are still in scope. the main issue is that we need to make sure to eventually clean up all objectrefs that have gone out of python scope, but we also need to make sure to account for all nested objectrefs that might still be in scope. this pr uses a per-object flag to indicate whether it has any nested objectrefs that might still be in scope. the flag gets updated recursively whenever a nested objectref is used. when an object ref goes out of scope and the borrower responds to the waitforrefremoved rpc, the reply includes all nested refs and we reset the flag. then, we just have to make sure not to delete an objectref if its flag is set. this should not result in any additional messages, but individual messages may be larger because they can include object refs that have already gone out of scope and don't need to be reported. i chose not to optimize this for now. closes #18751. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> fix assertion crash </cmt> <cmt> test, lint </cmt> <cmt> todo </cmt> <cmt> tests </cmt> <cmt> protocol </cmt> <cmt> test </cmt> <cmt> fix </cmt> <cmt> lint </cmt> <cmt> header </cmt> <cmt> recursive </cmt> <cmt> note </cmt> <cmt> forward test </cmt> <iss> [bug] ref count safety bug when inlining objectrefs or deserializing objectrefs multiple times </iss>",fix bug in ref counting protocol for nested objects
3804,"<desc> this builds on #33518 . wildcard index expressions are tricky because when security is enabled, widcards (inclusions and exclusions) have to be expanded in the scope of the authenticated user. relates: #33805 edit: the security plugin authorizes actions on indices. this implies that a request with the indices expression containing wildcards has to be first evaluated, in the authorization layer, before the request is handled. for authorization purposes, wildcards in expressions will only be expanded to indices visible by the authenticated user. however, this ""constrained"" evaluation has to be compatible with the expression evaluation that a cluster without the security plugin installed would do. therefore every change in the evaluation logic in any of the to sites has to be mirrored in the other. #33518 added support forwildcard exclusion (-...*) at the core logic site. this pr mirrors that at the indicesandaliasesresolver site, which is the site that does the affore mentioned ""constrained"" expression evaluation. </desc> <cmt> wip main code </cmt> <cmt> main code </cmt> <cmt> getalias 404 for requested indices </cmt> <cmt> darn indicestodisplay bs </cmt> <cmt> get alias wildcard rest-api tests </cmt> <cmt> almost all tests pass </cmt>",get alias api wildcard exclusion with security
3805,<desc> this pull request adds additional documentation as requested by #7578. the documentation contains how to properly configure the dospagecount from the mod_evasive apache module for a virtual host. component name docs </desc> <cmt> docs(running-behind-apache): add vhost example for dospagecount </cmt> <cmt> docs(running-behind-apache): adjust indentation level for code block; change dospagecount value from 50 to 30 </cmt>,add configuration details for vhost about dospagecount to apache proxy guide
3806,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). added property types to the existing draweritems (was missing). flow source </desc> <cmt> improved draweritems </cmt> <cmt> ran 'npm run lint package-name' </cmt>,added property type to draweritems
3807,"<desc> fix: some refactor about datazoom and axis scale extent calculation: the ""scale extent calculation"" is depended by both coord sys and ""datazoom"". so it need to be performed in different stage of workflow and should avoid to call it repleatly or implement it repeatly. but previously, the ""scale extent calculation"" is implemented both in axishelper.ts and datazoom/axisproxy.ts, where different code implements similar logic. ""scale extent calculation"" is based on input of: (i) option specified min/max/scale (including callback) and (ii) dataextent and (iii) some filter related components like datazoom. currently we need add more filters depends on that axis scale calculation. e.g., (i) one axis min max effect the other axis extent (ii) custom filter. so we refactor that ""scale extent calculation"" as a reusable module (see scalerawextentinfo.ts). based on (1), make the callback of axis.min/axis.max consistent whatever it is called in ""data processing stage"" or ""coord sys updating stage"" based on (1), fix some ""inconsistent"" flaw in datazoom when handling stacked series. fix the type of axis.min/max to scaledatavalue. and enable the callback of axis.min/max to return scaledatavalue. remove some code that never used. make the ""data filter"", which will ""block stream"", not as the default data processor in the register api. feature: enable category axis min/max to shrink the other axis extent in cartesian. after this modification, if some data if out of the range of a category axis, the data item will not be filtered, but the extent of the other axis will be calculated based on the filtered data. if datazoom is used in either of the xaxis or yaxis in that cartesian, the shrink will not be performed. </desc> <cmt> fix: some refactor about datazoom and axis scale extent calculation: </cmt> <cmt> (1) the ""scale extent calculation"" is depended by both coord sys and ""datazoom"". </cmt> <cmt> so it need to be performed in different stage of workflow and should avoid to call it repleatly or implement it repeatly. </cmt> <cmt> but previously, the ""scale extent calculation"" is implemented both in axishelper.ts and datazoom/axisproxy.ts, </cmt> <cmt> where different code implements similar logic. </cmt> <cmt> ""scale extent calculation"" is based on input of: </cmt> <cmt> (i) option specified min/max/scale (including callback) and </cmt> <cmt> (ii) dataextent and </cmt> <cmt> (iii) some filter related components like datazoom. </cmt> <cmt> currently we need add more filters depends on that axis scale calculation. </cmt> <cmt> e.g., </cmt> <cmt> (i) one axis min max effect the other axis extent </cmt> <cmt> (ii) custom filter. </cmt> <cmt> so we refactor that ""scale extent calculation"" as a reusable module (see scalerawextentinfo.ts). </cmt> <cmt> (2) based on (1), make the callback of axis.min/axis.max consistent whatever it is called in </cmt> <cmt> ""data processing stage"" or ""coord sys updating stage"" </cmt> <cmt> (3) based on (1), fix some ""inconsistent"" flaw in datazoom when handling stacked series. </cmt> <cmt> (4) fix the type of axis.min/max to scaledatavalue. and enable the callback of axis.min/max to return scaledatavalue. </cmt> <cmt> (5) remove some code that never used. </cmt> <cmt> (6) make the ""data filter"", which will ""block stream"", not as the default data processor in the register api. </cmt> <cmt> feature: enable category axis min/max to shrink the other axis extent in cartesian. </cmt> <cmt> after this modification, if some data if out of the range of a category axis, </cmt> <cmt> the data item will not be filtered, but the extent of the other axis will be calculated </cmt> <cmt> based on the filtered data. </cmt> <cmt> if datazoom is used in either of the xaxis or yaxis in that cartesian, the shrink will not be performed. </cmt>",extent filtered by other axis
3808,"<desc> this patch allows over 44words fqdn for backend server name. in aws elasticache provides long server name (eg. cache-cluster-hoge.bixxxx.0001.apne1.cache.amazonaws.com) but,   nc_inet_addrstrlen limits 45words. so, domain is not recognized only up to 44 characters. </desc> <cmt> fix fail long fqdn name resolve </cmt> <cmt> remove strdup </cmt> <cmt> remove unuse define </cmt>",fix long server  fqdn can not recognized
3809,"<desc> this accessibility prop is needed by some partners for the help of reading comments/replies. i will backport this to .65/.64/.63 uia_itemtypepropertyid - identifies the itemtype property, which is a text string describing the type of the automation element. itemtype is used to obtain information about items in a list, tree view, or data grid. for example, an item in a file directory view might be a ""document file"" or a ""folder"". when itemtype is supported, the string must match the application ui language or the operating system default ui language. microsoft reviewers: open in codeflow </desc> <cmt> adding accessibilityitemtype property to viewwin32 </cmt> <cmt> revert unneccesary change </cmt> <cmt> adding to testpage </cmt> <cmt> removing old change </cmt>",adding accessibility prop accessibilityitemtype on viewwin32
3810,"<desc> hi, when you try to use serverless framework with localstack is impossible to deploy because the cloudformation generated by serverless doesn't come with accesscontrol property so the deployment breaks, i debug into the issue and we only need to make a quick fix and set a default value for this acl to continue with the deployment. this also fixes the issue #475  that i reported before. note: i also add a gitignore entry because i use pycharm as ide and there always create an .idea directory. </desc> <cmt> ignore .idea folder of pycharm ide </cmt> <cmt> add s3 acl publicread as default value fixes #475 </cmt>",set s3 acl default value in case comes empty
3811,"<desc> this pr is part of the process separation project. move nodeimpl from interfaces/node.cpp to node/interfaces.cpp move chainimpl from interfaces/chain.cpp to node/interfaces.cpp move walletimpl from interfaces/wallet.cpp to wallet/interfaces.cpp no changes to any classes (can review with git diff --color-moved=dimmed_zebra) motivation for this change is to move node and wallet code to respective directories where it might fit in better than src/interfaces/, but also to remove all unnecessary code from src/interfaces/ to unblock #19160 review, which has been hung up partially because of code organization. building on top of this pr, #19160 should now be able to organize interface implementations more understandably in src/node/ src/wallet/ src/ipc/ and src/init/ directories instead of having so much functionality all in src/interfaces/ </desc> <cmt> move nodeimpl from interfaces/node.cpp to node/interfaces.cpp </cmt> <cmt> move chainimpl from interfaces/chain.cpp to node/interfaces.cpp </cmt> <cmt> no changes to chainimpl or any related classes (review with git diff --color-moved=dimmed_zebra) </cmt> <cmt> move walletimpl from interfaces/wallet.cpp to wallet/interfaces.cpp </cmt>",move node and wallet code out of src/interfaces
3812,"<desc> when running in modern server mode, our response varies depending on user-agent. a reverse-proxy may wrongly cache the modern/legacy response and use it for others. this pr tries to prevent that. </desc> <cmt> fix(vue-renderer): add vary header for server mode </cmt> <cmt> test: add test for vary user-agent </cmt>",add vary header for user-agent in modern server mode
3813,"<desc> fix a few small issues that could cause crashes with property wrappers: provide source locations for synthesized initializer calls (fixes rdar://problem/52969503 and rdar://problem/53183030) check for a null type before digging into an expression to find the type-checked ""initial value"" (fixes rdar://problem/53120878) </desc> <cmt> [se-0258] fix source locations for implicitly-generated initializer calls. </cmt> <cmt> fixes rdar://problem/52969503, a crash due to missing source location </cmt> <cmt> information in implicitly-generated calls. </cmt> <cmt> [se-0258] check for a null type. </cmt> <cmt> within invalid code, we might encounter expressions without type </cmt> <cmt> information yet. check for null here. </cmt> <cmt> fixes crash from rdar://problem/53120878. </cmt> <cmt> add now-fixed test case from rdar://problem/53183030 </cmt>",fix a few more crashes involving property wrappers in invalid code
3814,"<desc> add v8 jsi executor support (disabled via use_v8 by default), with the requisite include directories, libraries, etc. if the given bundle name is already an absolute path, don't attempt to append the executable's path to it (useful for debugging bundle loading) microsoft reviewers: open in codeflow </desc> <cmt> native modules in jsi mode </cmt> <cmt> merge master </cmt> <cmt> attempt to fix v8 build </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> revert v8 and hermes defaults </cmt>",add optional v8 jsi executor support (disabled by default)
3815,<desc> add documentation in doc-src explaining how to add a new content viewer view class to contentview.py. </desc> <cmt> begin work on documenting adding a new view </cmt> <cmt> continue work on documentation of adding views </cmt> <cmt> more documentation </cmt> <cmt> more documentation </cmt> <cmt> more documentation cleanup and formatting </cmt> <cmt> further cleanup of documentation </cmt> <cmt> finalizing documentation </cmt>,documentation for adding a new content viewer / view class
3816,"<desc> continuation of #9642 add config option system_tables_lazy_load that, if set to false, loads system tables with logs at the server startup. alexander burmak, svyatoslav tkhon il pak, #9642 </desc> <cmt> added a patch from alexander burmak </cmt> <cmt> added a test from svyatoslav tkhon il pak @deifythegod #9642 </cmt>","system tables eager creation, continuation"
3817,"<desc> this pr is to add typings for part of the dynamic values functionality in react-jss. a few things i'm not happy with: i can't work out how to define typings for the other part of the spec (classname: props => {color: 'red', etc...}) i had to disable strict function checking in tsconfig.json to get tsc to pass with the changes made to the test file. would be glad if anyone has pointers or wants to look at these parts. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> allow dynamic css values based on component props </cmt> <cmt> add attribution, fix linter errors </cmt> <cmt> rename to dynamiccssrule </cmt> <cmt> update tests - had to disable strict function checking, if anyone knows how to make it work with this, please do! </cmt>",allow dynamic css values based on component props in react-jss
3818,<desc> add validator for javanese script (based on khmer). validation rules may need an update after review by language experts. </desc> <cmt> initial commit to add aksara jawa - javanese script </cmt> <cmt> fix typo re javanese </cmt>,add support for javanese script - aksara jawa
3819,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. documentation for #6226 </desc> <cmt> typo fix. </cmt> <cmt> update log_family.md (#43) </cmt> <cmt> update tinylog.md (#44) </cmt> <cmt> docapi-7991: ru translation. </cmt>,"en review,  ru translation for the update of log engines docs"
3820,<desc> fixes argos running on empty screenshots. following screenshots are still empty:     would keep them so that we're notified once they start working. no idea why they won't render. </desc> <cmt> fix react-select using no space in regression test </cmt> <cmt> fixup customization route change </cmt> <cmt> fix certain regression demos taking no space </cmt> <cmt> ignore container demos </cmt>,fix empty visual rergression screenshots
3821,<desc> the pdf unit tests use a mock of the istream interface which fails if it can't copy the contents of the stream in a single pass. what is include in the pr: fixes for the mock to run correctly even when it receives a smaller buffer side. also run pdf thumbnail tests as part of the automated tests. took the chance to also add pdf modules to the bug report template. tests run successfully. linked issue: #13247 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries </desc> <cmt> [ci] reduce pdf preview and thumbnail flakiness </cmt> <cmt> [ci] run pdf thumbnail tests </cmt>,fix pdf thumbnail unit tests flakiness
3822,"<desc> this pr removes interpolation of values into event errors. to make errors more clear when not expanded, the name attribute is special cased in rendering and prepended to the error message, if available (and set). this is a preparation for auto-generating event errors from _meta (#10779). </desc> <cmt> ref(eventerror): make the eventerror class more useful </cmt> <cmt> ref(eventerror): stop interpolating error messages </cmt> <cmt> ref(ui): render event error paths explicitly </cmt>",stop interpolating event error messages
3823,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> missing number array test </cmt> <cmt> fix whitespace </cmt> <cmt> fix comment alignment </cmt>",add missing methods for signale 1.4
3824,"<desc> veml7700: command support values are normalized update de language: update de language  ""illuminance"" for a ""more"" german word related issue (if applicable): fixes # the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> update de language for illuminance for a ""more"" german word </cmt> <cmt> add 2 commands for veml7700 sensor (gain, integration time); value normalizing activated </cmt>","update de language for ""illuminance"", update veml7700 sensor"
3825,"<desc> see jenkins-49044. jenkins-49044: descriptorvisibilityfilter extensions are now applied to securityrealm and authorizationstrategy. changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) @reviewbybees </desc> <cmt> [jenkins-49044] honor descriptorvisibilityfilter for securityrealm and authorizationstrategy </cmt> <cmt> [jenkins-49044] the test </cmt>",apply visibility filters to securityrealm and authorizationstrategy
3826,"<desc> if the user is using a version of git < 2.7.0, disable git integration (to prevent gitpython from prompting for credentials), and warn the user to upgrade their git: the text needs a product pass: do we want it above or below the streamlit welcome text? should we be more specific about what git integration means? (possibly link to docs?) should we be less prominent with this warning? maybe it's just a single line? git integration is disabled. streamlit requires git 2.7.0 or later, but you have 2.6.4. to use streamlit's git integration, please update git. fixes #2323 </desc> <cmt> disable gitrepo if git is old, and warn the user </cmt> <cmt> mypy annotation </cmt> <cmt> test_print_old_git_warning </cmt> <iss> using git below version 2.7 requires remote (e.g. github) credentials on every run (for private repos) </iss>",disable git integration for ancient gits
3827,"<desc> tested with visual studio 2015 community, without mkl, and python 3.5.0b4, 32 and 64 bit. travis ci failures seem unrelated. </desc> <cmt> bld: enable c99 complex for msvc14 </cmt> <cmt> bld: enable c99 isnan and isinf for msvc14 </cmt> <cmt> bld: disable broken msvc14 trigonometric functions </cmt>",enable visual studio 2015 c99 features
3828,"<desc> the tests assume that hashmap is iterated in a certain order, which can cause the tests to fail under different java versions or platforms. the fix simply changes hashmap to linkedhashmap, as linkedhashmap does guarantee an order of iteration. </desc> <cmt> fixed com.alibaba.json.bvt.bug.bug_for_smoothrat5#test_map to not rely on nondeterministic apis </cmt> <cmt> fixed com.alibaba.json.bvt.bug.bug_for_smoothrat9#test_set to not rely on nondeterministic apis </cmt>",fixed 2 more tests that relied on non-deterministic apis
3829,<desc> objects which are not naively dumpable to json break ansible-connection rpc. this pickles any non-string to avoid this issue. ansible-connection </desc> <cmt> fail more helpfully when data is not str </cmt> <cmt> pickle arbitrary objects to return from connection </cmt>,pickle non-str objects to survive connection return
3830,"<desc> added the 20 key (4x5) macropad/keyboard called emi20 to the list of keyboards. added the default keymap. this keymap includes a simpel numpad like layer on layer 0 and extra keys on layer 1 with the comments to help new users to edit the firmware themselves. updated the store on which this keyboard will be sold at my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. </desc> <cmt> added emi20 as a keyboard with the default firmware as it was previously not in the list of keyboards </cmt> <cmt> i updated the store on which this keybaord will be sold in the readme file </cmt>",added emi20 as a keyboard with the default keymap
3831,"<desc> this pr adds user timing marks at key points in the reconciler's execution. the marks are used by this new concurrent mode profiler tool that @kartik918 and i are building under @bvaughn and @jevakallio's guidance. high level breakdown of this pr: add a enableschedulingprofiling feature flag. add functions that call user timing apis to a new schedulingprofiling.js file. the file follows debugtracing's structure. add user timing marks to places where debugtracing logs. add user timing marks to most other places where @bvaughn's original draft debugtracing branch marks. tests added more context (and discussions with @bvaughn) available at our internal pr mlh-fellowship#11 and issue mlh-fellowship#5. similar to debugtracing, we've only added scheduling profiling calls to the old reconciler fork. test plan yarn test-prod yarn flow dom this test app that i created has a custom build of react with enableschedulingprofiling and enabledebugtracing set to true. when profiled with firefox profiler, the marks are visible in the output. </desc> <cmt> add enableschedulingprofiler feature flag </cmt> <cmt> add mark utility functions </cmt> <cmt> combines those defined in both debugtracing.js and </cmt> <cmt> [this branch]( </cmt> <cmt> rename enableschedulingprofiler -> enableschedulingprofiling </cmt> <cmt> add all marks except commits and effects </cmt> <cmt> reduce performance api requirements </cmt> <cmt> add tests for schedulingprofiling </cmt> <cmt> comment out tests covering kartik's code </cmt> <cmt> add tests to cover markrenderabandoned and fix passive effect marks </cmt> <cmt> comment out tests covering kartik's code </cmt> <cmt> add remaining user timing marks </cmt> <cmt> re add tests </cmt> <cmt> add missing markcommitstopped calls, relocated some mark* calls for consistency, add blank lines </cmt> <cmt> replace binary lane bitmask with decimal for compactness </cmt> <cmt> reduce test strictness to fix test-prod </cmt> <cmt> remove todo for markrenderscheduled </cmt> <cmt> add markcommitstarted call to new logcommitstarted location </cmt> <cmt> remove markrenderabandoned </cmt>",add user timing marks for scheduling profiler tool
3832,"<desc> fixes #57172 when an ansible vault password file is specified in config and another is passed in as a command line argument, they need to be combined. the value from config is a tuple (by design) and needs to be converted to a list so it can be modified. the integration tests did not test this scenario, so i added a test for this case. lib/ansible/cli/vault.py </desc> <cmt> convert vault_password_files to a list </cmt> <cmt> add changelog and tests </cmt> <iss> ansible-vault: 'tuple' object has no attribute 'append' when multiple password files are configured </iss>",convert vault_password_files to list to prevent traceback
3833,"<desc> i just extended the types of the arguments for the #registerpartial function, because per the implementation that function is polymorphic. if the first argument is a string then the second must be a template fn, but in case the first argument is an object then the second argument is discarded making it optional. the implementation in question </desc> <cmt> updating types for #registerpartial </cmt> <cmt> #registerpartial is a polymorphic function now it accepts a single object making the second param optional. </cmt> <cmt> excerpt from the implementation: </cmt> <cmt> js </cmt> <cmt> registerpartial: function(name, partial) { </cmt> <cmt> if (tostring.call(name) === objecttype) { </cmt> <cmt> extend(this.partials, name); </cmt> <cmt> } else { </cmt> <cmt> if (typeof partial === 'undefined') { </cmt> <cmt> throw new exception(attempting to register a partial called ""${name}"" as undefined); </cmt> <cmt> } </cmt> <cmt> this.partials[name] = partial; </cmt> <cmt> } </cmt> <cmt> }, </cmt> <cmt>  </cmt> <cmt> updated handelbars#registerpartials </cmt> <cmt> removed extra spaces </cmt>",updated type definitions for handlebars#registerpartials
3834,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #23723 increase the version number in the header if appropriate. (not appropriate) if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. (already exists) fixes #23723, along with other related improvements. generally increased support for properly typed results when using lodash with numericdictionary collections (object with numeric key type). in methods that use iterators (foreach, map, etc.), the key param of the iterator is now string to match the run-time type of keys of objects. omit now returns exactly the same kind of dictionary/numericdictionary that was provided as a param. many methods updated to remove overloads to handle numericdictionary explicitly, and now instead rely on more generic handling of t extends object where possible. many other methods that previously accepted dictionary param are now updated to also accept numericdictionary. added unit tests for mapvalues, which uncovered many flaws with signature overloads. added a few missing signatures, re-ordered as necessary, etc. removed explicit type parameters from many calls to methods in unit tests. several other small improvements/additions to unit tests. </desc> <cmt> change numericdictionaryiterator's ""key"" to type ""string"" </cmt> <cmt> finish updating unit tests </cmt> <cmt> improve support of numericdictionary. </cmt> <cmt> * update signature overloads of many methods. </cmt> <cmt> * improve many unit tests. </cmt> <cmt> fix some mapvalues overloads </cmt> <cmt> revert changes to v3 files </cmt> <cmt> improve _.omit to fully support dictionary and numericdictionary </cmt> <cmt> remove unused dictionaryiterator typedefs </cmt> <cmt> improve signatures of mapvalues and add tons of unit tests </cmt>",improve support for numericdictionary collections
3835,"<desc> de-capitalize variables in etcd make the image pull policy as ""ifnotpresent"" use image.repository to replace image which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # </desc> <cmt> de-capitalize all the variables of etcd </cmt> <cmt> remove unused variables </cmt> <cmt> refactor the image definition </cmt>",refactor etcd to meet the chart tech requirement
3836,"<desc> an implementation of single widget reloads which delegates to the compiler provided widget cache. this is the last step for implementing single widget reloads. since the compiler is able to detect all subtypes, the tool no longer needs to perform an expression evaluation in order to perform a fast reassemble. this updates the tool code to forward the compiler specified widget class, and updates the tests to perform real integration tests. fixes #61407 </desc> <cmt> widget cache mark 2 </cmt> <cmt> update for latest draft of widget cache </cmt> <iss> implement faster single-widget hot reloads </iss>",connect widget cache from frontend_server
3837,<desc> this sets up the public files route similar to how we set up the static files route and makes sure we handle the same special file names for the public folder that we did for the static folder closes: #10004 closes: #9706 closes: #9705 </desc> <cmt> update serving of files from public folder to handle special chars </cmt> <iss> 9.1.5 path-to-regexp error with static routes with special symbols * ( + </iss> <iss> 404 if public/ filename contains a space </iss>,fix public/ file name encoding
3838,"<desc> the removes images from the clojure package to help resolve license issues from #15542 please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> remove test images </cmt> <cmt> add script and .gitignore </cmt> <cmt> add test helper to download images </cmt> <cmt> remove unlicensed pic </cmt>",clojure package remove source images
3839,"<desc> today, stmt matchers stop too early when parsing expression statements that begin with non-braced macro invocations. for example, fn main() { macro_rules! m { ($s:stmt;) => { $s } } id!(vec![].push(0);); //^ before this pr, the stmt matcher only consumes ""vec![]"", so this is an error. //| after this pr, the stmt matcher consumes ""vec![].push(0)"", so this compiles. } this change is backwards compatible due to the follow set for stmt. r? @eddyb </desc> <cmt> macros: fix bug in statement matchers </cmt> <cmt> add regression test </cmt>",fix bug in stmt matchers
3840,<desc> case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. </desc> <cmt> added react-big-calendar module declaration </cmt> <cmt> added test file </cmt> <cmt> added tests cases </cmt> <cmt> updated definitions </cmt> <cmt> fixing moment import </cmt> <cmt> reindent to 4 spaces </cmt> <cmt> reindented to 4 spaces </cmt> <cmt> fix author url </cmt>,add a new definition for react-big-calendar
3841,"<desc> i'd like to be able to build android host tools and libraries on android. </desc> <cmt> [cmake] make sourcekit respect link_libraries and library_search_directories </cmt> <cmt> add_sourcekit_default_compiler_flags was invoking </cmt> <cmt> _add_variant_link_flags and getting link flags but not actually using </cmt> <cmt> the link_libraries or library_search_directories. in android builds, </cmt> <cmt> this means that the correct libc++ is not being linked against. </cmt> <cmt> [cmake] make sure icu libdir is correctly added to library_search_directories </cmt> <cmt> the cmake variables ${sdk} and ${arch} are only set if </cmt> <cmt> _add_variant_link_flags is invoked from add_swift_target_library calling </cmt> <cmt> _add_swift_library_single. if you get to _add_swift_library_single from </cmt> <cmt> add_swift_host_library, those variables will not be set and subsequent </cmt> <cmt> linking will not find icu libraries. this was an issue when building </cmt> <cmt> swift host libraries on android. </cmt>",add support for building swift host libraries and tools for android host
3842,"<desc> make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. create it with npm run new-package package-name, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. </desc> <cmt> add typing files for react-portal </cmt> <cmt> add header to restrict tsc version to 2.1 </cmt>",new definition for react-portal 3.0 npm module
3843,"<desc> this prepares data to be abi stable. primarily we are now letting the compiler do the work of any public inline accessors. our internal structure is defined to have certain paths marked as usable from inline and specific internal methods to be inlined, the reset of the public interface will defer to the wisdom of the compiler itself to understand which methods can and cannot be inlined. in most cases this results in a performance gain due to the conversion to private/internal types. however there is one known regression when appending a sequence that is not an array or data or unsafebufferpointer etc. one particular case that is a known regression is repeating. we plan on addressing this in a followup change that will add better inlines for this type of case (perhaps even boiling down to memset). resolves rdar://problem/33678210 </desc> <cmt> [foundation] migrate data to a abi stable variant </cmt> <cmt> this has one known performance regression; appending with a sequence (not an array, but something like a repeated<uint8>) is slower. we aknowlege this regression and plan to offer an update later that has a specialized variation of this api that optimizes to a memset/memset_pattern. this set of changes is limited to specifically targeting abi stability and inline characteristics of data and leaves that optimization as a future addition. </cmt> <cmt> remove additional inlines </cmt> <cmt> remove last public inlines </cmt>",swift 4.2 branch update data inlines
3844,"<desc> updated the linear regression example documentation. the original documentation had duplicated work ""the"" and following sentence seemed choppy therefore modified to a more appealing tone. </desc> <cmt> deleted duplicated word {the} and and made sentences more clear. </cmt> <cmt> deleted duplicated word {the} and and made sentences more clear. </cmt> <cmt> deleted duplicated word {the} and and made sentences more clear. </cmt> <cmt> deleted duplicated word {the} and and made sentences more clear. </cmt>",doc cleaned descriptive paragraph for linear regression example
3845,"<desc> these changes: verify only specific roles are able to edit settings limits editing of members flag by the owner role only clean up settings test @allouis let me know what you think about these. i had to create this new concept of unsafeattrsobject in controllers to be able to leave the permissions layer less coupled from controller implementation. it also only checks for single labs key right now, but think that's fine as it's only use case we care about. some more descriptions about the thinking in commit messages ;) another thing to consider here is somehow disabling toggling members for no owner in the ui. at the moment it just drops the error in top banner and disallows toggling. </desc> <cmt> moved existing suite inside 'as owner' group </cmt> <cmt> added test cases to check edit permission on settings endpoints </cmt> <cmt> symetric changes to v2 test pt. 1 </cmt> <cmt> symetric changes to v2 test pt. 2 </cmt> <cmt> added test to demonstrate only owner being able to toggle members flag </cmt> <cmt> permission check when editing settings lab.members </cmt> <cmt> - passed additional function to permissions to allow custom selection of unsafe attributes due to settings object structure. </cmt> <cmt> - fully implementing this check on controller level would be wrong architecturally and not that straight forward because we lack role data in ""frame"" </cmt> <cmt> cleaned up test after moving default_content_visibility to it's own property </cmt>",added permission restrictions to editing members flag
3846,"<desc> problem when you want to run a script located in the root dir in a complicated dir structure, when there is no fixed pattern for the distance of the sub-dir level  from the root dir. root-dir/ packages/ cool-package/ @some-scope/ some-package/ other-package/ scripts/ lerna.json package.json /root-dir/packages/cool-package$ node ../../scripts/some-script.js /root-dir/packages/@some-scope/some-package$ node ../../../scripts/some-script.js /root-dir$ lerna exec node ../{???}/scripts/some-script.js solution if there is a environment variable that contains the root path dir, it is possible to run scripts that are located in the root dir easily. /root-dir$ cross-env lerna exec node $lerna_root_path/scripts/some-script.js </desc> <cmt> feat: add $lerna_root_path environmental variable for lerna exec </cmt> <cmt> to make it easy to run a script that located in the root dir, in a complicated dir structurean, when </cmt> <cmt> there is no fixed pattern for the distance of the sub-dir level from the root dir. </cmt> <cmt> docs: add docs for $lerna_root_path environment variable </cmt>",root path dir environment variable
3847,"<desc> fixes #3874, closes #3886. previously @wintercomes  tried to solve the issue but hasn't responded to one final query by @kmike. i completed the simple query. </desc> <cmt> change download_maxsize logger level from error to warning </cmt> <cmt> reverted maxsize warning log message </cmt> <iss> download_maxsize logger level shouldn't be error </iss>",download_maxsize logger level changed from error to warning
3848,"<desc> the padding after the magic signature value should be 12 bytes rather than 28 bytes. the other 16 should be placed after the title id pattern for nrrs. also amend the nroheader structure to reflect information on switchbrew. </desc> <cmt> service/ldr: corrent padding within the nrr header layout </cmt> <cmt> the padding after the magic signature value should be 12 bytes rather </cmt> <cmt> than 28 bytes. the other 16 should be placed after the title id pattern. </cmt> <cmt> service/ldr: amend layout of the nro header </cmt> <cmt> the first word is just a padding byte, it's not an actual entry </cmt> <cmt> instruction. also renames the rest of the entries according to </cmt> <cmt> switchbrew. </cmt>",amend layouts of nro and nrr headers
3849,"<desc> use kparsefullprecision to turn on this option in compile-time. the implementation of new option should have no performance impact if the flag is not used. implementation details the full-precision path tries to use fast-path if possible. if the criteria of fast-path cannot be met, it falls back to use strtod() to convert string. note that the parser still verify the json syntax of number as in normal-precision path. to fulfill the above requirement, the parser needs to backup the correctly parsed characters from stream (as some streams cannot read back). a helper template class genericreader::numberstream is designed for this. if full-precision is set, then backup is required, and a specialized numberstream will backup the characters during numberstream::take() into the genericreader::stack_. that stack_ was previously used only for storing the decoded characters in parsestring(). unit test added random numbers to test more cases for integer types and double. this experimental results show that full precision generate exact representation (no error), while normal precision parsing has maximum error of 3 ulp. denormal numbers () are not tested as it varies among platforms. implementations of strtod() in standard libraries may also simply flush denormal to zero. fix #120 </desc> <cmt> add test case </cmt> <cmt> fallback strtod() when not able to do fast-path </cmt> <cmt> this shall generate best possible precision (if strtod() is correctly </cmt> <cmt> implemented). need more unit tests and performance tests. may add an </cmt> <cmt> option for accepting precision error. otherwise lut in pow10() can be </cmt> <cmt> reduced. </cmt> <cmt> add random tests for parsenumber </cmt> <cmt> check ""fast path cases in disguise"" in strtod </cmt> <cmt> refactor parsenumber for two modes (incomplete) </cmt> <cmt> merge master and implement kparsefullprecision </cmt> <cmt> optimize parsenumber() </cmt> <cmt> fix parsenumber_integer test </cmt> <cmt> compute error statistics of normal precision </cmt> <cmt> update document for kparsefullprecisionflag </cmt> <iss> float point reading is lossy. </iss>",parse json number to double in full-precision.
3850,<desc> allows usage of more windows apis such as winhttp for networking components. microsoft reviewers: open in codeflow </desc> <cmt> bump min. windows desktop supported version to 8. </cmt> <cmt> use winver property to set _win32_winnt. </cmt> <cmt> drop _win32_winnt in favor of winver. </cmt> <cmt> place controlflowguard in the appropriate property sheet. </cmt> <cmt> change files </cmt>,upgrade minimum supported version to windows 8.
3851,<desc> docs(vi-mode): revamp readme and document settings fix(vi-mode): hide cursor-change logic behind vi_mode_set_cursor setting fixes #9570 </desc> <cmt> docs(vi-mode): revamp readme and document settings </cmt> <cmt> fix(vi-mode): hide cursor-change logic behind vi_mode_set_cursor setting </cmt> <cmt> fixes #9570 </cmt> <iss> vi-mode changed the cursor shape; how do i disable it? </iss>,hide cursor-change logic behind opt-in setting
3852,"<desc> the proposal is to offer an uncomplicated example of distributed load execution. with just a few steps we have locust provisioned and distributed in the number of nodes provided, running in the aws cloud under ec2. 1. aws authentication export aws_access_key_id=aiaxxxxxxxxxxxxxxxxx export aws_secret_access_key=t9hyxxxxxxxxxxxxxxxxxxxxxxxxxxxx 2. configure your provisioning don't forget to provide the correct subnet name in the variable file define location and file of your locust plan script define the number of nodes to create variables.tf variable ""node_size"" { description = ""size of total nodes"" default = 2 } variable ""loadtest_dir_source"" { default = ""plan/"" } variable ""locust_plan_filename"" { default = ""basic.py"" } variable ""subnet_name"" { default = ""subnet-prd-a"" description = ""subnet name"" } 3. execute terraform cd examples/distribuited_execution_terraform/aws terraform init terraform apply --auto-approve 4. access ui click on the link below to access the ui: result exemple: apply complete! resources: 14 added, 0 changed, 0 destroyed. outputs: dashboard_url = "" leader_private_ip = ""10.17.5.119"" leader_public_ip = ""3.237.255.123"" nodes_private_ip = [ ""10.17.5.167"", ""10.17.5.39"", ] nodes_public_ip = [ ""3.235.45.218"", ""100.24.124.0"", ] 5. cleanup terraform destroy --auto-approve 6. more information terraform aws-get-started >> install-terraform-on-linux terraform module aws loadtest distribuited </desc> <cmt> example of distribuited execution on aws ec2 using terraform </cmt> <cmt> fix new line </cmt>",new provisioning example for distributed execution using iac - terraform/aws/ec2
3853,"<desc> strip trailling comments from /etc/default/passwd like: minweeks=1 #minweeks=2 maxweeks=12  # maxweeks=8 which otherwise cause failures with ""failed to read /etc/default/passwd: too many values to unpack"" user module ansible version ansible 2.4.2.0 config file = /development/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, may 31 2018, 09:41:32) [gcc 4.8.5 20150623 (red hat 4.8.5-28)] but present in the current 2.6+ releases too. example input file #ident  ""@(#)passwd.dfl 1.8     14/01/24 smi"" # copyright (c) 1989, 2014, oracle and/or its affiliates. all rights reserved. maxweeks=12 #maxweeks=8 minweeks=0  # minweeks=4 passlength=8 minalpha=1 # minalpha = 2 #whitespace=yes old code fails with valueerror: too many values to unpack import sys def get_password_defaults(): # read password aging defaults minweeks = '' maxweeks = '' warnweeks = '' for line in open(""/tmp/default_passwd"", 'r'): line = line.strip() if (line.startswith('#') or line == ''): continue key, value = line.split('=') if key == ""minweeks"": minweeks = value.rstrip('\n') elif key == ""maxweeks"": maxweeks = value.rstrip('\n') elif key == ""warnweeks"": warnweeks = value.rstrip('\n') return (minweeks, maxweeks, warnweeks) minweeks, maxweeks, warnweeks = get_password_defaults() fixed code strips trailing comments import sys import re def get_password_defaults(): # read password aging defaults minweeks = '' maxweeks = '' warnweeks = '' for line in open(""/tmp/default_passwd"", 'r'): line = line.strip() if (line.startswith('#') or line == ''): continue m = re.match(r'^([^#]*)#(.*)$', line) if m:  # the line contains a hash / comment line = m.group(1) key, value = line.split('=') if key == ""minweeks"": minweeks = value.rstrip('\n') elif key == ""maxweeks"": maxweeks = value.rstrip('\n') elif key == ""warnweeks"": warnweeks = value.rstrip('\n') return (minweeks, maxweeks, warnweeks) minweeks, maxweeks, warnweeks = get_password_defaults() </desc> <cmt> strip additional comments from /etc/default/passwd </cmt> <cmt> strip trailling comments from /etc/default/passwd like </cmt> <cmt> minweeks=1 #minweeks=2 </cmt> <cmt> maxweeks=12  # maxweeks=8 </cmt> <cmt> which otherwise cause failures with ""failed to read /etc/default/passwd: too many values to unpack"" </cmt> <cmt> fix carriage return typo in commit </cmt> <cmt> yet another typo in commit </cmt>",strip trailing comments from /etc/default/passwd
3854,<desc> a lot of vulnerabilities are found. i updated the following packages for fixing it. jest babel-jest react-svg-loader lodash now: </desc> <cmt> fix vulnerabilities </cmt> <cmt> update jest configuration </cmt> <cmt> add license header </cmt> <cmt> fix lint warning of webpack configs </cmt> <cmt> add svgo options to webpack configs </cmt>,update packages which has vulnerabilities
3855,"<desc> please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  pkg.go.dev:  goreportcard.com:  coverage service link (codecov, coveralls, gocover etc.):  very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. </desc> <cmt> add package btnguyen2k/olaf </cmt> <cmt> merge with avelino/awesome-go:master </cmt> <cmt> add database client and driver for azure cosmos db </cmt>",add rest client and database/sql driver for azure cosmos db
3856,"<desc> this pr adds the following features: netdata saves the alarms log to /var/lib/netdata/health/health_log.db. this file is a machine readable text file. this file is auto-rotated by netdata (by default every 10000 entries the file is renamed to .old and a new one is created. these files (the primary and its .old) are loaded back when netdata restarts, so that the alarm log at the dashboard shows the alarm history properly. this also allows the alarm log and the alarms themeselves to have incremental ids. fixes #1036 other changes: added fping plugin. check #1122 - this requires a special version of fping, which currently can be downloaded from  netdata installer now runs with priority 19 (the lowest) and uses all the available processors to compile netdata. ansible playbook removed in favor of:  minor other improvements </desc> <cmt> health log is saved and loaded back </cmt> <cmt> add fping.plugin; fixes #1122 </cmt> <cmt> fixed minor printf formating issues regards signed numbers </cmt> <cmt> added fping.conf and resize secondary fping charts </cmt> <cmt> updated configs.signatures </cmt> <iss> alarm log should be saved and loaded back on netdata restart </iss>",alarm log is saved and loaded back; added fping.plugin
3857,"<desc> there are subtle differences between loki and sift query operators that we are trying to account for. this fixes some of those: sift allows querying arrays with $eq and $ne, which translates to $contains and $containsnone in loki the special case for $nin added false, which should be undefined. this also needed removing cloning the query args with json.parse/stringify, because undefined=>null, but it does not seem to serve a purpose anymore anyway. the fix for { $ne: true } now handles nesting levels > 2, e.g.  { ""foo.bar.baz"": { $ne: true } } the conversion to dotted query fields was producing { """": {} } for an empty object. </desc> <cmt> fix(gatsby): fix loki special-casing for $ne: true </cmt> <cmt> fix loki query operators </cmt>",fix loki query operators special casing
3858,"<desc> to make the explore code more maintainable, i will refactor some controls, so first i need to move some files to the sub-component. this change will not change any codebase logic this change will not change the filename test plan it / cypress run ok requires db migration. confirm db migration upgrade and downgrade tested. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> move spec </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> remove unused file </cmt> <cmt> wip </cmt> <cmt> wip </cmt>",move metriccontrol and filtercontrol to sub-component
3859,"<desc> backporting #47096 into v2.6. junos ansible version ansible 2.6.5.post0 (backport/2.6/47096 85b161065e) last updated 2018/10/17 10:12:01 (gmt -500) config file = none configured module search path = [u'/users/fxfitz/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/fxfitz/dev/ansible/lib/ansible executable location = /users/fxfitz/.pyenv/versions/ansible/bin/ansible python version = 2.7.15 (default, may 29 2018, 20:16:38) [gcc 4.2.1 compatible apple llvm 9.1.0 (clang-902.0.39.1)] n/a </desc> <cmt> fix junos terminal regex (#47096) </cmt> <cmt> fix junos stdout regex </cmt> <cmt> change at hing </cmt> <cmt> (cherry picked from commit fc341e01face3544c649b54015605f94597e069c) </cmt> <cmt> changelog: adds fragment for junos fix terminal </cmt>",junos terminal regex prompt fix to v2.6
3860,"<desc> these changes should take care of the final 7 post-migration errors triggered by ansible-test sanity --test docs-build. docs.ansible.com </desc> <cmt> address toc-tree-glob-pattern-no-match errors </cmt> <cmt> address include-file-not-found error </cmt> <cmt> address 2.10 porting guide errors, add warning to page </cmt>",fix last 7 docs errors on post-migration test runs
3861,"<desc> xref #32865 1 tests added / 1 passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry scope of pr this pr does a couple things to fix the performance of skew, and this also fixes the behavior of all the functions that have require_min_periods for small values of min_periods: clarify docs. name all sample methods uniformly, add a note to the caveat that users should in general be careful about using sample methods with windows fix bug in _apply that made us never go into the baseindexer control flow branch fix bug in _apply: pass window_indexer.window_size into calc_min_periods instead of min_periods or 1. we want the custom indexer window size there, so it's not clear to me why we were passing min_periods or 1 . details the algorithm itself is robust, but it defaults to sample skewness, which is why there was a difference between its output and numpy. to prevent misunderstandings, i clarified the docs a bit. we were also passing a wrong value to calc_min_periods, and we weren't going into the proper if branch, because we were checking the type of window instead of self.window. background on the wider issue we currently don't support several rolling window functions when building a rolling window object using a custom class descended from pandas.api.indexers.baseindexer. the implementations were written with backward-looking windows in mind, and this led to these functions breaking. currently, using these functions returns a notimplemented error thanks to #33057, but ideally we want to update the implementations, so that they will work without a performance hit. this is what i aim to do over a series of prs. perf notes no changes to algorithms. </desc> <cmt> whitelist rolling skewness </cmt> <cmt> doc: clarify that all sample metrics need careful treatment </cmt> <cmt> clarify that any method that has sample before its name needs to </cmt> <cmt> be used carefully with windows as this is almost never what the </cmt> <cmt> user wants. </cmt> <cmt> bug: fix self.window type check </cmt> <cmt> also fix the value passed to calculate_min_periods </cmt> <cmt> for custom baseindexer implementations. </cmt> <cmt> tst: add test </cmt> <cmt> doc: add whatsnew entry </cmt> <cmt> cln: run black pandas </cmt>",support skew function for custom baseindexer rolling windows
3862,"<desc> this implements a better (more python-style) list.sort. it's not really about that, though; it's about me figuring out a sane way forward for keyword-argument functions (and function metadata). but it's useful as is, and shouldn't break any existing code, so here you have it; i'm going to park it in my mind for a bit while sorting out the rest of the dict branch. </desc> <cmt> this implements a better (more python-conformant) list.sort. </cmt> <cmt> it's not really about that, though; it's about me figuring out a sane </cmt> <cmt> way forward for keyword-argument functions (and function </cmt> <cmt> metadata). but it's useful as is, and shouldn't break any existing </cmt> <cmt> code, so here you have it; i'm going to park it in my mind for a bit </cmt> <cmt> while sorting out the rest of the dict branch. </cmt> <cmt> conflicts: </cmt> <cmt> py/obj.h </cmt> <cmt> py/objbool.c </cmt> <cmt> py/objboundmeth.c </cmt> <cmt> py/objcell.c </cmt> <cmt> py/objclass.c </cmt> <cmt> py/objclosure.c </cmt> <cmt> py/objcomplex.c </cmt> <cmt> py/objdict.c </cmt> <cmt> py/objexcept.c </cmt> <cmt> py/objfun.c </cmt> <cmt> py/objgenerator.c </cmt> <cmt> py/objinstance.c </cmt> <cmt> py/objmodule.c </cmt> <cmt> py/objrange.c </cmt> <cmt> py/objset.c </cmt> <cmt> py/objslice.c </cmt> <cmt> a bit of stylistic cleanup (chose the wrong side during conflict resolution). </cmt>",a more python-style list.sort. and keyword arguments.
3863,"<desc> resolves #56377, very much along the same lines as #52073 this pr changes the shrink action to also be allowed in the hot phase after a rollover. as with #52073, a shrink in the hot phase must be accompanied by a rollover, and policy validation has been updated to check for this. reviewing commit-by-commit is best, there's a few relatively self-contained cleanup commits. </desc> <cmt> getordefault with null is just get </cmt> <cmt> map.of makes this immutable </cmt> <cmt> and lets us drop the static initializer </cmt> <cmt> refactor a bit </cmt> <cmt> to allow the possibility that there could be more actions in the hot </cmt> <cmt> phase that require rollover, rather than only just forcemerge. </cmt> <cmt> allow shrink in the hot phase </cmt> <cmt> as long as there's an accompanying rollover. </cmt> <cmt> tidy up some whitespace </cmt> <iss> add shrink action to the hot phase </iss>",allow shrink in the hot phase for ilm policies
3864,<desc> should fix #1439 (comment) - with automatic selection based on browser detection. </desc> <cmt> tilelayer - globalcompositionoperation set once </cmt> <cmt> this might fix a safari issue; it also avoids repeatedly setting the </cmt> <cmt> [same] composition operation and saving/loading context states. </cmt> <cmt> tilemaplayer: re-added secondary copy-canvas </cmt> <cmt> - this change uses a secondary canvas and rectangle clearing instead of a </cmt> <cmt> 'copy' composition on the same canvas. this should hopefully address </cmt> <cmt> the flickering issue in safari and safari mobile </cmt> <cmt> tilemaplayer rendering double-copy </cmt> <cmt> - memory optimization of delta-scroll shifting. </cmt> <cmt> - the copy canvas is shared between all tilemaplayers </cmt> <cmt> - the copy is done in segments to reduce the memory usage of the copy </cmt> <cmt> canvas. currently this is a 1/4 ratio. </cmt> <cmt> - device has the feature (by browser) check to see if bitblt works </cmt> <cmt> - tilemaplayer will automatically enable the double-copy as needed </cmt> <cmt> - device.whenready can be used to override the device value </cmt>,fix / double-copy for safari tilemap bug when rendering with delta scrolling
3865,"<desc> excludeclass used to get called twice, which internally used to check if class is a innerclass, or an anonymous or local class. attaching the cpu profiler snapshot. with this change, we only check once and return if the class has to be excluded. </desc> <cmt> optimized the create() method, excludeclass used to get called two times, changed it to one </cmt> <cmt> fixed the create() method, and added support to disableanonymousandlocalclassserialization </cmt>",optimised the create() call for excluder typeadapterfactory
3866,<desc> update #7615 since it was a couple of months out of date. </desc> <cmt> support this.prop = expr; assignments as declarations for es6 js classes </cmt> <cmt> handle jsdoc tags on 'this' properties </cmt> <cmt> update tests </cmt>,support this.prop = expr; assignments as declarations for es6 js classes &mdash; take 2
3867,"<desc> another step toward #11638 this pr is a continuation of #12732. there were blas calls in the following cython files: weight_vector.pyx, cd_fast.pyx and    _k_means.pyx. there were also blas calls in the c file cholesky_delete.h. i decided to move (using fused types) the only function there to cython in arrayfuncs.pyx where there was a python wrapper for it. i added rot an rotg to the cython blas functions which i forgot in #12732 because i didn't check c files... i also removed linking to blas libs in some setups for modules which didn't call blas functions. the only remaining calls to bundled cblas in sklearn appear in tron.cpp, used in liblinear. they can't be replaced easily by calls to scipy cython blas because the calls to blas are not from cython files but from c files. </desc> <cmt> replace cblas calls in utils/weight_vector </cmt> <cmt> add rot & rotg to cython_blas </cmt> <cmt> cholesky_delete -> cython to use cython_blas </cmt> <cmt> add rot & rotg to cython_blas </cmt> <cmt> rot & rotg cython_blas tests </cmt> <cmt> cholesky delete fix </cmt> <cmt> cblas to scipy cython_blas in linear_model/cd_fast </cmt> <cmt> cblas to scipy cython_blas in cluster/_k_means </cmt> <cmt> cleanup manifold setup </cmt>",continue moving from cblas to scipy cython blas
3868,<desc> addressed issue that can arise when user has libtool installed multiple locations or runs into conflict with homebrew installing /usr/local/bin/glibtool. $ find /usr /library -type f -name libtool -print 2>/dev/null /usr/bin/libtool /usr/local/bin/libtool /usr/local/src/libtool-2.4.6/libtool /library/developer/commandlinetools/usr/bin/libtool </desc> <cmt> darwin: new procedure for indentifying installed homebrew dependencies </cmt> <cmt> darwin: change the libtool check to glibtool </cmt> <cmt> darwin: added doxygen to homebrew dependency installation </cmt> <cmt> merging master into eosio_build_darwin_bullettproof </cmt> <cmt> last merge before pr for branch eosio_build_darwin_bulletproof </cmt>,eosio build darwin libtool conflict addressed
3869,<desc> na_ontap_qtree: added new operation to modify qtree options. added new parameters: -- export-policy -- unix-permissions -- oplocks -- security-style na_ontap_gather_facts: new subsets: -- igroup_info -- qos_policy_info -- qos_adaptive_policy_info na_ontap_qtree na_ontap_gather_facts </desc> <cmt> qtree new parameters and modify action </cmt> <cmt> fixing pylint offenses </cmt> <cmt> fixing shippable fails </cmt> <cmt> added igroup_info gather_subset </cmt> <cmt> added qos_policy_info / qos_adaptive_policy_info gather_subsets </cmt> <cmt> pylint fixes </cmt>,qtree new params and modify operation / new subsets
3870,"<desc> this pr enables checking exclusivity violations for no escape closures. for testing purposes it includes all the commits from #10360 plus one additional commit (73d7476) that is the only new content for this pr w/r/t 10360. </desc> <cmt> [exclusivity] make helper functions to static. nfc. </cmt> <cmt> make helper functions static and avoid defining one except when assertions </cmt> <cmt> are enabled. </cmt> <cmt> [exclusivity] relax enforcement for separate struct stored properties </cmt> <cmt> relax the static enforcement of exclusive access so that we no longer diagnose </cmt> <cmt> on accesses to separate stored structs of the same property: </cmt> <cmt> takesinout(&s.f1, &s.f2) // no-warning </cmt> <cmt> and perform the analogous relaxation for tuple elements. </cmt> <cmt> to do this, track for each begin_access the projection path from that </cmt> <cmt> access and record the read and write-like modifications on a per-subpath </cmt> <cmt> basis. </cmt> <cmt> we still warn if the there are conflicting accesses on subpaths where one is </cmt> <cmt> the prefix of another. </cmt> <cmt> this commit leaves the diagnostic text in a not-so-good shape since we refer </cmt> <cmt> to the descriptivedeclkind of the access even describing a subpath. </cmt> <cmt> i'll fix that up in a later commit that changes only diagnostic text. </cmt> <cmt>  </cmt> <cmt> rdar://problem/31909639 </cmt> <cmt> [exclusivity] update static diagnostic text for ""simultaneous"" accesses </cmt> <cmt> remove the descriptive decl kind (since with subpaths it is not correct and </cmt> <cmt> cannot represent a tuple element) and change ""simultaneous"" to ""overlapping"" </cmt> <cmt> in order to lower the register slightly and avoid connoting threading. </cmt> <cmt> for example, for the following: </cmt> <cmt> takestwoinouts(&x.f, &x.f) </cmt> <cmt> the diagnostic will change from </cmt> <cmt> ""simultaneous accesses to var 'x.f', but modification requires exclusive access; </cmt> <cmt> consider copying to a local variable"" </cmt> <cmt> to </cmt> <cmt> ""overlapping accesses to 'x.f', but modification requires exclusive access; </cmt> <cmt> consider copying to a local variable"" </cmt> <cmt> [exclusivity] remove erroneous no-error comments from tests. nfc. </cmt> <cmt> copy-pasta strikes again! </cmt> <cmt> [sil utils] move indextrienode into its own header in utils. nfc. </cmt> <cmt> move indextrienode from deadobjectelimination into its own header. i plan to </cmt> <cmt> use this data structure when diagnosing static violations of exclusive access. </cmt> <cmt> [exclusivity] add analysis pass summarizing accesses to inout_aliasable args </cmt> <cmt> add an interprocedural sil analysis pass that summarizes the accesses that </cmt> <cmt> closures make on their @inout_aliasable captures. this will be used to </cmt> <cmt> statically enforce exclusivity for calls to functions that take noescape </cmt> <cmt> closures. </cmt> <cmt> the analysis summarizes the accesses on each argument independently and </cmt> <cmt> uses the bottomupipanalysis utility class to iterate to a fixed point when </cmt> <cmt> there are cycles in the call graph. </cmt> <cmt> for now, the analysis is not stored-property-sensitive -- that will come in a </cmt> <cmt> later commit. </cmt> <cmt> [exclusivity] switch static checking to use indextrie instead of projectionpath </cmt> <cmt> indextrie is a more light-weight representation and it works well in this case. </cmt> <cmt> this requires recovering the represented sequence from an indextrienode, so </cmt> <cmt> also add a getparent() method. </cmt> <cmt> [exclusivity] statically enforce exclusive access in noescape closures (#10310) </cmt> <cmt> use the accesssummaryanalysis to statically enforce exclusive access for </cmt> <cmt> noescape closures passed as arguments to functions. </cmt> <cmt> we will now diagnose when a function is passed a noescape closure that begins </cmt> <cmt> an access on capture when that same capture already has a conflicting access </cmt> <cmt> in progress at the time the function is applied. </cmt> <cmt> the interprocedural analysis is not yet stored-property sensitive (unlike the </cmt> <cmt> intraprocedural analysis), so this will report violations on accesses to </cmt> <cmt> separate stored properties of the same struct. </cmt> <cmt> rdar://problem/32020710 </cmt>",diagnose exclusivity violations for noescape closures
3871,"<desc> type: fix description: when this.props.data.values is undefined, many functions are broken because they expect a defined thread. this pr fixes the problem by returning null in case of undefined thread ps: i also made a small change in threadselector style </desc> <cmt> fix(ui): fixed undefined thread </cmt> <cmt> ref(ui): updated style </cmt>",return null when thread is undefined
3872,"<desc> in pull_requests.md commit message: currently the fault filter will create a stats storage for each http request with ""x-envoy-downstream-service-cluster"" field set, which introduce unbounded memory usage. by adding a flag to control whether downstream server name should be traced in stats, envoy can be protected from downstream servers that send requests header setting different downstream cluster names. risk level: low testing: add unit test and integration test. docs changes: will change doc for fault filter </desc> <cmt> add member variable </cmt> <cmt> fix test </cmt> <cmt> add comment </cmt>",add option to disable fault filter stats that trace downstream server name
3873,<desc> my solution about issue #5179 and i implemented part of todo about avoid forks in 'izz*' / 'izzq' / 'izzj'. </desc> <cmt> removed some forks </cmt> <cmt> a bit of refactoring </cmt> <cmt> done test and fix bug </cmt>,#5179 and todo about avoid forks
3874,<desc> no whats new this is a 1.4.0 feature fix. </desc> <cmt> longtable label allowed even when caption is none </cmt> <cmt> longtable label allowed even when caption is none </cmt> <cmt> longtable label allowed even when caption is none </cmt>,"no label render in styler.to_latex if caption and ""longtable"""
3875,"<desc> original pull-request #19443 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix wrong parts in parts_to_do </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> addition to #15537 </cmt>",cherry pick #19443 to 20.8: addition to #15537
3876,"<desc> in forms/checks-radios: give examples of the pure toggle checks and radios, without the button group class. show that these work fine without .btn-group, but still cross-reference it move the explanation from ""checkbox toggle buttons"" directly to ""toggle buttons"", as the mention of using button classes applies equally to the subsequent ""radio toggle buttons"" and ""outlined styles"" subsections. in components/button-groups: expand button group page description as it's not just single line, but vertical as well add more colour ... .btn-secondary is just dull and uninspiring new section to showcase ""checkbox and radio button groups"" add a mixed styles example add an example of vertical radio button group follow-up from #30650 (comment) which suggested porting some of the docs changes trialled in #28463 previews: checks & radios toggle buttons / button group </desc> <cmt> keep checks/radio toggle buttons on topic </cmt> <cmt> - give examples of the pure toggle checks and radios, without the button group class. show that these work fine without .btn-group, but still cross-reference it </cmt> <cmt> - move the explanation from ""checkbox toggle buttons"" directly to ""toggle buttons"", as the mention of using button classes applies equally to the subsequent ""radio toggle buttons"" and ""outlined styles"" subsections. </cmt> <cmt> expand button group description </cmt> <cmt> as it's not just single line, but vertical as well </cmt>","separate button group out of checks/radios, expand button groups page"
3877,"<desc> this pr changes the configure.ac to require zmq version 4.x or newer, which is provided on debian and derivatives as package libzmq3-dev.  it also updates the release notes, build-unix.md, and zmq.md docs to reflect this change and add missing documentation. (whitespace changes are purely trimming of extraneous previous whitespace by my editor.) </desc> <cmt> zmq: require version 4.x or newer of libzmq </cmt> <cmt> zmq: update and cleanup build-unix, release-notes, and zmq docs </cmt>",require zmq version 4.x and update/cleanup zmq docs
3878,"<desc> change this change adds a more fully functional search to the sqliteindex.  it implements both exact and substring matching across id, name, moniker, tags, and commands.  only one ""search"" string can be used at a time, either the generic query argument or one of the filters.  more extensive match options and filtering will be enabled in a future checkin. search is implemented by creating a temporary table to hold the results.  we iteratively insert results from specific searches on a given field and match type.  each successive search should be broader, as we will order the results given back to the caller in the order that they were performed.  thus for a substring query search that is not field specific, we perform exact match searches across all fields, then substring search across all fields.  in this way, if app a has a tag ""foo"" and app b has id ""foobar"", we will sort a higher in a search for ""foo"", but b higher in a search for ""fo"" (as id is searched before tags). as the search priority is driven solely by the order in which we perform searches, we can change the prioritization in the future simply be changing the order of the calls. testing tests are added to ensure that all search combinations (field x match type) can execute properly, and to ensure that searches are consistent with intentions. </desc> <cmt> groundwork laid, algorithm sketched out </cmt> <cmt> search functionality complete, working on getting results </cmt> <cmt> query working, needs more testing </cmt>",implement search across all fields
3879,"<desc> builtins.__import__ was missing a check to flag that if no dot was found in the __name__ of a module that isn't explicitly a submodule of a package then a relative import is incorrect. </desc> <cmt> regression tests for bpo-37409 </cmt> <cmt> bpo-37409: fix builtin/importlib discrepancy for ""from . import *"" where no package exists </cmt> <cmt> relative imports use resolve_name to get the absolute target name, </cmt> <cmt> which first seeks the current module's absolute package name from the globals: </cmt> <cmt> if __package__ (and __spec__.parent) are missing then </cmt> <cmt> as a hail mary it uses __name__, truncating the last segment if </cmt> <cmt> the module is any submodule rather than a package __init__.py </cmt> <cmt> (which it guesses from whether __path__ is defined). </cmt> <cmt> the hail mary should fail if there is no parent package (top level modules), </cmt> <cmt> if __name__ is uninformatively '__main__' (-m entry points), or both (scripts). </cmt> <cmt> that is, if both __name__ has no subcomponents and the module does not seem </cmt> <cmt> to be a package __init__ module. </cmt> <cmt> (bug silently used module as if package, aliasing unexpected objects. </cmt> <cmt> note importlib contained an unaffected alternative __import__ implementation.) </cmt>",fix relative import with no parent
3880,"<desc> this pr changes how #[inline] functions are translated. before, there was one ""master instance"" of the function with external linkage and a number of on-demand instances with available_externally linkage in each codegen unit that referenced the function. this had two downsides: public functions marked with #[inline] would be present in machine code of libraries unnecessarily (see #36280 for an example) llvm would crash on i686-pc-windows-msvc due to what i suspect to be a bug in llvm's win32 exception handling code, because it doesn't like available_externally there (#36309). this pr changes the behavior, so that there is no master instance and only on-demand instances with internal linkage. the downside of this is potential code-bloat if llvm does not completely inline away the internal instances because then there'd be n instances of the function instead of 1. however, this can only become a problem when using more than one codegen unit per crate. </desc> <cmt> trans: only translate #[inline] functions if they are used somewhere. </cmt> <cmt> adapt run-make/sep-comp-inlining test case to new behaviour </cmt> <cmt> trans: allow base::internalize_symbols() to internalize #[no_mangle] symbols </cmt> <cmt> adapt codegen-unit test cases to new behaviour </cmt>",only instantiate #[inline] functions in codegen units referencing them
3881,"<desc> while the transform is running, it will be good to persist the running statistics to an index. this should not happen on each change, but at some determined periodicity. overview: the docs are going to be stored in the .data-frame-internal-1 index along with the configurations and the checkpoint documents stats will be associated to a transform via the transform.id, and the document id will be deterministic in containing the transform id pagination is now supported in the _stats call, and the associated transport, rest, action classes have been updated to reflect that. dataframefeatureset#usage has been refactored to account for the stats living in documents. closes #39994 </desc> <cmt> [ml] add mappings, serialization, and hooks to persist stats </cmt> <cmt> adding tests for transforms without tasks having stats persisted </cmt> <cmt> intermittent commit </cmt> <cmt> adjusting usage stats to account for stored stats docs </cmt> <iss> [ml] handle large number of dataframe transforms in internal logic </iss>",periodically persist data-frame running statistics to internal index
3882,"<desc> this restores the behavior of the old frontend - which would skip these post-pipeline actions wholesale. #33672 tried turning it on, but it turns out we were modeling objc header inputs as swift files, and so the first post-pipeline action to build the main module would suck in the bridging header and try to parse it as swift code. to tackle that last one, explicitly model objcheader as an input kind. this is just plumbing i'll need for later. rdar://68587228 </desc> <cmt> [nfc] mark sourcemanager::getidforbufferidentifier const </cmt> <cmt> model objcheader inputs </cmt> <cmt> these inputs were previously modeled as swift files, which would lead to bizarre situations where parts of the pipeline expecting swift inputs actually wound up parsing objective-c. </cmt> <cmt> add doesactionperformendofpipelineactions </cmt> <cmt> for now, force the clang-based actions to skip the end of the pipeline. this restores the previous behavior of the frontend, but may not be desirable in the long run. for example, one may want to dump clang stats after running an -emit-pch job, but that is impossible without forcing the end of the pipeline to be more tolerant of objcheader/modulemap-only inputs. </cmt> <cmt> rdar://68587228 </cmt>",-disable end of pipeline actions for objc actions
3883,"<desc> ... and added skflow to default import of contrib. builds on top of #1829 </desc> <cmt> added datasets package, added boston and iris datasets. (prep for removing hard dep on sklearn) </cmt> <cmt> correct datasets loading to match sklearn output </cmt> <cmt> add first version of sklearn-related functionality when sklearn is not found. </cmt> <cmt> changing skflow modules to use _sklearn for loading sklearn tools </cmt> <cmt> bump size of histogram test to medium </cmt> <cmt> moved datasets into filegroup and added skflow by default import in contrib </cmt> <cmt> correct more imports in ops/ to use full paths </cmt> <cmt> adding csv files to manifest for pip </cmt> <cmt> fixing skflow imports to use global import for tensorflow ops </cmt> <cmt> add skflow import by default to contrib, to make tf.contrib.skflow work </cmt>",fix imports to use specific tf modules
3884,"<desc> this slightly changes the behavior of scrollpane#scrollto centering, and removes scrollpane#scrolltocenter. scrollpane#scrolltocenter was equivalent to scrollpane#scrollto(x, y, width, height, false, true); </desc> <cmt> add centering to scrollpane.scrollto; fix #2561 </cmt> <cmt> scrolltocenter(x, y, width, height) is now equivalent to scrollto(x, y, width, height, false, true); </cmt> <cmt> update changes, reflect scrollpane#scrollto change </cmt>",add another scrollpane#scrollto; fix #2561
3885,"<desc> fixes #25987 as mentioned in-person with @mhegazy, since our goal with the index signature was to just squelch a class of errors in js, this accomplishes the same thing without the unfortunate side effect of mangling our inferences. this has the fortunate side-effect that the meaningless index signatures are no longer present in quickinfo and the like. these accesses are also now marked in noimplicitany mode now - which i'd argue is a correct thing to do. that is the breaking change referenced in the pr labels, however in practice it's unlikely to break much (and when it does it's probably desirable!) as js codebases using noimplicitany are relatively rare. </desc> <cmt> remove index signatures from js literals, use an object flag to indicate errors should be ignored instead </cmt> <cmt> add focused test on the keyof problem </cmt> <cmt> fix fourslash test </cmt>","flag js literals and ignore assignments/accesses to invalid props, instead of adding an index"
3886,"<desc> passing by values means extra copies + extra atomic addref and release. pass by ref instead. this was a quick find/replace, inspect, and see if we compile deal. i didn't bother trying to catch everything in every view manager, and just fixed the main interface. much of this will likely get nuked when abiviewmanager becomes the sole source of goodness. microsoft reviewers: open in codeflow </desc> <cmt> pass xamlview's through reactuwp view managers by const ref </cmt> <cmt> passing by values means extra copies + extra atomic addref and release. pass by ref instead. </cmt> <cmt> this was a quick find/replace, inspect, and see if we compile deal. i didn't bother trying to catch everything in every view manager, and just fixed the main interface. much of this will likely get nuked when abiviewmanager becomes the sole source of goodness. </cmt> <cmt> change files </cmt> <cmt> yarn format </cmt>",pass xamlviews through reactuwp view managers by const ref
3887,"<desc> closes #20878 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> update warnings on attribute access </cmt> <cmt> update warnings on attribute access </cmt> <iss> update docs on reserved attributes </iss>",fixes update docs on reserved attributes #20878
3888,"<desc> freeze those objects: internal objects vm app element comment listener app.prototype document.prototype element.prototype comment.prototype listener.prototype build-in objects object array object.prototype array.prototype string.prototype number.prototype boolean.prototype error.prototype date.prototype regexp.prototype once the object is frozen, there has no chance to unfreeze it. in addition, because we use strict mode in the js bundle, modify those frozen objects will throw a typeerror. </desc> <cmt> + [jsfm] add test case for strict mode </cmt> <cmt> * [jsfm] freeze the prototype of build-in objects </cmt> <cmt> * [jsfm] istanbul ignore ployfills </cmt> <cmt> + [jsfm] add test case for freezeprototype </cmt>",freeze the prototype of intrenal and build-in objects
3889,"<desc> this cherry-picks from main changes for the winsdk module to the 5.4 release branch.  this only impacts the windows path and should be safe for the platform as it only changes how headers are mapped into the clang importer. </desc> <cmt> add winsdk.winsafer </cmt> <cmt> (cherry picked from commit 281ae3c2a68e2fbda7d6dd560bbd9dfaa08679f1) </cmt> <cmt> platform: add directx mappings </cmt> <cmt> add the module definitions for: </cmt> <cmt> - direct3d v12 </cmt> <cmt> - xaudio 2.9 </cmt> <cmt> - xinput 1.4 </cmt> <cmt> additionally, add the following, unusable modules: </cmt> <cmt> - dxcore </cmt> <cmt> dxcore requires c++ support (c++11 or newer to be precise) and is not </cmt> <cmt> yet available until c++ interop can be made to work fully. </cmt> <cmt> (cherry picked from commit c5bc227ac7d88538bc4980e92620597495216ec1) </cmt> <cmt> winsdk: add xaml hosting submodule </cmt> <cmt> this exposes idesktopwindowxamlsourcenative interface, which is used for embedding winui xaml controls into win32 apps </cmt> <cmt> (cherry picked from commit 6970054b63168999b1236fd1e34021dee19745f7) </cmt> <cmt> platform: add a cplusplus requirement to xaudio </cmt> <cmt> in some cases when building the xaudio module, we would end up going </cmt> <cmt> down c++ paths: </cmt> <cmt>  </cmt> <cmt> c:\program files (x86)\windows kits\10\/include/10.0.17763.0/um/xaudio2.h:61:26: error: 'uuid' attribute is not supported in c </cmt> <cmt> interface __declspec(uuid(""2b02e3cf-2e0b-4ec3-be45-1b2a3fe7210d"")) ixaudio2; </cmt> <cmt> ^ </cmt> <cmt> <module-includes>:29:10: note: in file included from <module-includes>:29: </cmt> <cmt> ^ </cmt> <cmt>  </cmt> <cmt> although this works with newer sdks, it does not work with older sdks. </cmt> <cmt> filter out the module for the time being with a requirement on c++. </cmt> <cmt> this should be possible to use with -enable-cxx-interop. </cmt> <cmt> (cherry picked from commit 715d81cf269ba77b9e580924621c1df97487f0e6) </cmt> <cmt> winsdk: use xinput instead of xinputuap </cmt> <cmt> the uap variant is included into the winsdk module which then fails to </cmt> <cmt> run.  adjust the linkage. </cmt> <cmt> (cherry picked from commit 5bfbaadb4377ab19ffa9d5821e95bd475406d5d7) </cmt> <cmt> platform: add activex module </cmt> <cmt> add the activex module to the windows sdk.  this is needed for the </cmt> <cmt> ipropbag2 interface. </cmt> <cmt> (cherry picked from commit fc8cd455d0084953e3d7244c8e20eea34385939e) </cmt> <cmt> platform: add direct3d11 module </cmt> <cmt> this adds the direct3d v11 module for windows.  this is required to gain </cmt> <cmt> access to the dxgi interfaces, which homes the dxgiswapchain interface. </cmt> <cmt> (cherry picked from commit 86a8b1b4dc0e40a2d97d19a01b5abd95ff6ff7ff) </cmt> <cmt> platform: extend the d3d v10 module </cmt> <cmt> add the extensions for the direct3d v10 api to enable access to the </cmt> <cmt> newer dxgiswapchain interfaces.  additionally, correct the linking to </cmt> <cmt> ensure that we pick up the v10 version of the import library. </cmt> <cmt> (cherry picked from commit e508b1ab1481555dc863cd42026d9c697ade4c1e) </cmt> <cmt> platform: add dxgi1_6 to the direct3d module </cmt> <cmt> there is no usermode header which has the dxgi1.6 interfaces included </cmt> <cmt> unfortunately.  this adds the interfaces to the module which is required </cmt> <cmt> for idxgiadapter4 interface. </cmt> <cmt> (cherry picked from commit 4084f7a5a667ae11bb04a30ab8e7bcfdb97c45b9) </cmt> <cmt> platform: add hlsl compiler to the winsdk modulemap </cmt> <cmt> the directx subsystem may require access to the hlsl compiler for </cmt> <cmt> building the shaders before uploading to the gpu.  this is adds to the </cmt> <cmt> modulemap the d3dcompiler module to get access to the compiler. </cmt> <cmt> (cherry picked from commit 997cb0f6719c3f487795f1f7487c6364e1dd44e1) </cmt> <cmt> platform: add dxgidebug.h to _dxgi module </cmt> <cmt> the debug header is used for enumeration of certain dxgi interfaces </cmt> <cmt> related to debugging of the pipeline.  add this to gain access to the </cmt> <cmt> interfaces and some of the global guids associated with it. </cmt> <cmt> (cherry picked from commit 66a9ae44b43450c2db9bdb89d25480166cf20fce) </cmt>",update winsdk module for latest changes
3890,"<desc> needs to applied to the docker environment after #236 is submitted, before the ruby docker images are rebuilt, so that the tests are run with the correct flags </desc> <cmt> updates the ruby dockerfile to copy the cacerts directory from the docker host </cmt> <cmt> updates/adds test commands </cmt> <cmt> - the client test gets new, necessary flags </cmt> <cmt> - adds a prod test command that explicitly sets the ssl_cert_file to pick up </cmt> <cmt> certs that the c core can load successfully. </cmt> <cmt> adds a func for installing the googles's roots.pem </cmt> <cmt> roots.pem is not added to source control, but is instead saved on gcs. </cmt> <cmt> the func copies roots.pem to docker host, to a location that can referenced by </cmt> <cmt> dockerfiles using the add directive </cmt>",grpc tools update ruby to run prod tests
3891,<desc> this addresses #494. this diff includes multiple fixes and workarounds to make the current master build and pass tests on windows 7 & 10 without cuda. we will be putting up official windows ci as soon as possible and it will make it easier to maintain windows compatibility. all credit goes to @peterjc123 who have been spending a lot of effort maintaining the windows build for a long time. </desc> <cmt> don't override cmake_generator in windows </cmt> <cmt> hide the unknown headers for win32 </cmt> <cmt> disable funsion_compiler for windows </cmt> <cmt> add at_api to tensorgeometry.h </cmt> <cmt> fix test cases for windows </cmt>,fix issues with windows 7 & 10 cpu build
3892,<desc> closes #8508 i made more changes than absolutely necessary for documenting this. it's a bit more complete and it reads a more similar to pd.read_csv() </desc> <cmt> fix typo </cmt> <cmt> update to_csv docstring </cmt> <iss> allow writing to s3 paths </iss>,document s3 and gcs path functionality of dataframe.to_csv()
3893,"<desc> this major change to slate removed change and folded all of its functionality into the editor controller. i have updated the slate definitions to reflect this, included doc comments for the new commands, and added additional tests. i've also applied the respective changes to the slate-react package. this is quite a large change so any feedback is appreciated add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: pr merge increase the version number in the header if appropriate. </desc> <cmt> implement new 'command' logic for editor </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> add tests for commands </cmt> <cmt> fix slate-react tests </cmt> <cmt> revert unintended change </cmt> <cmt> version number </cmt>",update typings to reflect new command structure
3894,<desc> added support for amd require / es6 import to the text-encoding typed definition. it falls under case 2: improvement to existing type definition. here you can find some context for the change. </desc> <cmt> merge remote-tracking branch 'refs/remotes/definitelytyped/master' </cmt> <cmt> support amd require / es6 import </cmt>,support amd require / es6 import for text-encoding
3895,<desc> iterate through custom packages locations instead of assuming packages/* my project has custom packages locations and all needs canary publish. see also #875 tests have been updated </desc> <cmt> fix: custom packages location used with publish --canary (#875) </cmt> <cmt> include build in git </cmt>,use all packages locations when resetting canary changes
3896,"<desc> following discussion in #11398, changing obj to the object names may avoid confusion. </desc> <cmt> [mrg] fix misleading doc in contibuting guidelines </cmt> <cmt> the estimator object is that which implements fit, not the one returned by fit. </cmt> <cmt> changed obj into predictor, estimator... </cmt>",clearer doc in contibuting guidelines
3897,<desc> cab is a wrapper around ghc-pkg and cabal. this pr adds autocompletion for cab if the command is present. </desc> <cmt> added cab autocompletion to the cabal plugin. </cmt> <cmt> cab is a wrapper for ghc-pkg and cabal that provides some nice features </cmt> <cmt> like listing outdated packages. </cmt> <cmt> see </cmt> <cmt> program. </cmt>,add cab autocompletion to the cabal plugin
3898,"<desc> as discussed on  from </desc> <cmt> v4l2: fix incorrect pool sizing </cmt> <cmt> v4l2: add option to disable enum_framesizes. </cmt> <cmt> gstreamer's handling of a driver that advertises </cmt> <cmt> v4l2_frmsize_type_stepwise to define the supported </cmt> <cmt> resolutions is broken. see bug </cmt> <cmt>  </cmt> <cmt> optional parameter of gst_v4l2src_is_broken added. </cmt> <cmt> if non-zero, the driver claims not to support that </cmt> <cmt> ioctl, and gstreamer should be happy again (it </cmt> <cmt> guesses a set of defaults for itself). </cmt>","fix regression, and gstreamer workaround"
3899,"<desc> fixes #968 </desc> <cmt> server: upgrade browserify preprocessor to 1.0.1 </cmt> <cmt> server: rename preprocessor config to file object </cmt> <cmt> server: normalize path when removing preprocessor file </cmt> <cmt> server: only add one listener for file:updated in socket </cmt> <cmt> previously, a listener would be added for every spec file opened, linearly increasing how many watched:file:changed events would be fired when a single file changed </cmt>",fix firing 'watched:file:changed' twice on change
3900,<desc> we would like to know when a route update is loaded to envoy. this pr adds a stat to indicate the same. commit message: add config reload time stat. risk level: low testing: added docs changes: updated release notes: updated </desc> <cmt> add test for priority </cmt> <cmt> add config reload time stat </cmt> <cmt> format </cmt>,add config reload time stat for rds
3901,"<desc> what do these changes do? this pr thread is identical to  as the source branch was mis-deleted, i have to reopen a pr. </desc> <cmt> add noisy network </cmt> <cmt> distributional q-learning in dev </cmt> <cmt> add distributional q-learning </cmt> <cmt> validated rainbow module </cmt> <cmt> add some comments </cmt> <cmt> supply some comments </cmt> <cmt> remove redundant argument to pass ci test </cmt> <cmt> async replay optimizer does not need annealing beta </cmt>",add noisy network and distributional q-learning to implement rainbow
3902,"<desc> closes #7738 now, when you have multiple cursors or selections and press esc, the single cursor or selection that will remain is the original cursor/selection </desc> <cmt> reduce multiple cursors/selections to the first, original, cursor/selection </cmt> <cmt> :tulip: change the spec for consolidateselections </cmt> <iss> feature request: pressing `esc` on multiple cursors returns you to original cursor location. </iss>",pressing esc on multiple cursors returns to original cursor or selection
3903,"<desc> set environment variables: ndk_root and cocos_console_root. because there is not api in python to set system environment variables, so i add it in ~/.bash_profile on linux and mac os x, and modify register table on windows.  any other elegant way? after setting environment variables, any way to make it take effect immediately? i want to use the environment value to use cocos-console after install.py return, like this ./install cocos project new ... i wanted to use os.system() to do it, but found it would create a new process. </desc> <cmt> add install.py </cmt> <cmt> check validation of ndk root </cmt>",create install.py to set environment variables needed by cocos2d-x
3904,<desc> description: revert unnecessary changes to platforms during previous device registry pr. dr uses device_info now instead of device. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> revert tank_utility </cmt> <cmt> fix soundtouch </cmt> <cmt> fix plex </cmt> <cmt> fix emby </cmt> <cmt> fix radiotherm </cmt> <cmt> fix juicenet </cmt> <cmt> fix qwikswitch </cmt> <cmt> fix xiaomi miio </cmt> <cmt> fix nest </cmt> <cmt> fix tellduslive </cmt> <cmt> fix knx </cmt>,revert changes to platforms using self.device
3905,"<desc> since i was having trouble with the minifier (part of our codebase minifies correctly only with uglify-es, part only with babeli), i updated the minifier-js package to report which backend was used for minification to ease debugging. </desc> <cmt> remove outdated fallback. </cmt> <cmt> report used minifier. </cmt> <cmt> this allows packages such as standard-minifier-js to generate statistics per minifier, which is useful to analyze how often the fallback is needed. </cmt>",minifier js report used minifier
3906,"<desc> removes our dependency on css.escape and ensures we always rely on postcss-selector-parser's built-in escape handling for any situations where we need to escape anything to avoid subtle inconsistencies. </desc> <cmt> update postcss-selector-parser </cmt> <cmt> use postcss-selector-parser class escape handling </cmt> <cmt> switch from css.escape to cssesc </cmt> <cmt> this is what postcss-selector-parser uses internally, best to rely on the same escaping logic everywhere. </cmt> <cmt> remove dependency on cssesc </cmt> <cmt> makes it easier to guarantee that our escape behavior stays in line with postcss-selector-parser if their internal implementation ever changes. </cmt>",leverage built-in escape handling in postcss-selector-parser
3907,"<desc> description fixes #18338 - fixed an issue with trailingslash: true adding a slash to the end of an external link. after <h1 class=""home_title__3djr7"">welcome to <a href="" <h1 class=""home_title__3djr7"">welcome to <a href="" <h1 class=""home_title__3djr7"">welcome to <a href="" <h1 class=""home_title__3djr7"">welcome to <a href="" </desc> <cmt> fix: no slashes for external links </cmt> <cmt> test: added test code </cmt> <iss> trailing slashes appends slashes to external links </iss>",issue #18338 - don't add a trailing slash to external links
3908,<desc> closes #14759 this is my first pr here. not sure about the missing entries in api reference. need some guidance on that. the same doubt about the best place to put the xref in computation.rst and timeseries.rst thanks. </desc> <cmt> documentation of groupby resample expanding </cmt> <cmt> removing foo </cmt> <iss> doc: document groupby.resample/rolling </iss>,add section on groupby().rolling/expanding/resample
3909,"<desc> changes the vertical alignment of inputs and buttons to be middle rather than baseline, which allows for stable alignment across all browsers. (e.g.  the search and inline form fields and buttons match exactly.) also fixes display of checkboxes in ie9+ by removing round corners, and fixes checkbox labels across all browsers, which were off from the left-aligned field label by 1px. </desc> <cmt> fixes off-by-1px between checkbox and form label (all browsers) </cmt> <cmt> clears border-radius on checkboxes because they look bad on ie </cmt> <cmt> makes inputs and buttons align middle so they line up in all browsers </cmt> <cmt> rebuild *.css </cmt>",form alignment in ie and others
3910,"<desc> original pull-request #13386 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> done </cmt> <cmt> fix build </cmt> <cmt> update ownsplitchannel.cpp </cmt> <cmt> fix style </cmt> <cmt> deadlock in textlog </cmt>",cherry pick #13386 to 20.6: deadlock in textlog
3911,"<desc> closes #26122 1 test added passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry added </desc> <cmt> add is_coerce arg to array_to_datetime_object </cmt> <cmt> add one test </cmt> <cmt> add whatsnew note </cmt> <iss> unexpected 'to_datetime' behaviour for datetime strings with different offset in 'arg', when errors='coerce' </iss>",add is_coerce argument to func array_to_datetime_object (gh26122)
3912,"<desc> adds useslider hook and updates the sliderunstyled component's logic to be compatible with the other unstyled components. i don't expect there to be breaking changes in the @mui/material's slider component. one change that i needed to make is to handle the component prop in the slider component, as it differs to how it is implemented in the sliderunstyled (the component prop just changes the tag, the components.root replaces the whole root element, for example the styles won't be applied). in a follow up pr i plan to address the todos that came up while converting the code to the hook which is written in typescript. </desc> <cmt> [sliderunstyled] update components & componentsprops </cmt> <cmt> [useslider] add hook (wip) </cmt> <cmt> proptypes & docs:api </cmt>",add useslider hook and polish
3913,"<desc> our application has tens of chunks. we don't need a prefetch for all files. in addition, my laptop started to heat up strongly in developer mode since this observer exists. and most important: chrome doesn't like excessive preload. look how the console looks on zeit.co (pic rel). </desc> <cmt> restoring not working mouse event </cmt> <cmt> restoring possibility of conditionally switching off the prefetch </cmt>",restoring possibility of conditionally switching off the <link/> prefetch
3914,"<desc> @dt-bot follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). < < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix type definition of spreadsheetapp.getactive </cmt> <cmt> fix type definition of spreadsheetapp.getactivespreadsheet </cmt>",modify type definitions of functions which can return null
3915,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> an assumption was made that the string indexable collections new with xrm 9 applied to all collections.  they don't.  i've have added seperate collection index to be able to allow for the string indexability of the new collections. </cmt> <cmt> added back accidently removed overlaod </cmt> <cmt> f </cmt>",added new collection interface defined via the client web api
3916,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> adding new options for nodemailer-mailgun-transport 1.4 </cmt> <cmt> adjusting tests to use host option </cmt>",@types/nodemailer-mailgun-transport added options for 1.4
3917,"<desc> closes #17361 </desc> <cmt> respect mut in &mut str in astconv </cmt> <cmt> closes #17361 </cmt> <cmt> add regression test for issue #17361 </cmt> <iss> can't return `&mut str` (""values differ in mutability"") from a method when implementing a trait for `str` </iss>",don't throw away mutability of &mut str in astconv
3918,<desc> fixes #9830. </desc> <cmt> librustc: don't ice on packed structs in statics. </cmt> <cmt> update test for packed structs to also test being placed in statics. </cmt> <iss> static instance of #[packed] struct makes rustc fail </iss>,don't ice on packed structs in a static.
3919,"<desc> removes the blocking flag from serve.init(), replacing it with a time-based timeout defined in ray.serve.constants. n/a i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  only ray serve tests were run. </desc> <cmt> removed blocking flag from serve.init(). </cmt> <cmt> added timeout parameter to block_until_http_ready(). </cmt> <cmt> moved sleep to end of loop. </cmt> <cmt> removed retries and exponential sleep from block_until_http_ready. moved default timeout to ray.serve.constants </cmt>",remove blocking flag from serve.init()
3920,"<desc> as per title, this pr attempts to improve react's textnode update/patch performance by accessing the firstchild.nodevalue. this can have a big impact on performance where textnode updates are frequently changing. this pr also removes the polyfill for element.textcontent as this is no longer required for ie9+. no new tests were added to this pr as the test coverage already covers this use-case, let me know if you think this is wrong and i can add tests for use cases that may not have been covered given the changes. </desc> <cmt> added logic to apply an update using node.firstchild.nodevalue, which is a more performant text update operation. also removed the ie8 polyfill for textcontent (ie8 is no longer supported?). </cmt> <cmt> removed un-needed typof check on lastcontent and ensured updatetextcontent gets called with same argument count </cmt>",settextcontent should attempt to set textnode nodevalue where possible
3921,"<desc> had the same json deserialization problem as in issue 1559; now that it's fixed, i had a look at the code and noticed that test code was left in. also, small typo fix. </desc> <cmt> removed leftover test code. </cmt> <cmt> fixed typo: managedtexurelist -> managedtexturelist </cmt>",issue 1559 and typo fix
3922,<desc> closes #4009 added a processcreation folder in operating system folder. it contains implementation in c. </desc> <cmt> add process creation algo </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <iss> add new algorithm in c for child process creation in linux operating system </iss>,add child process creation code in linux operating system
3923,"<desc> this pr fixes #6574. sometimes users have the expectation that calling map on a homogeneous tuple will create a tuple type of the same size, but with the element types appropriately mapped on. for instance: interface person { name: string; } declare let couple: [person, person]; // should have type '[string, string]', but currently has type 'string[]'. let names = couple.map(p => p.name); now that we have this-types, we can actually enable overloads that can only apply if the target object (the thing being dotted on) has a specific type. i'd like to hear feedback from the team (especially @sandersn & @ahejlsberg) about whether this is a good idea. this fulfills a lot of users' expectations, but they could instead just augment array<t> with these overloads if they're interested. also tagging @philpee2 who asked me about this yesterday. </desc> <cmt> added test. </cmt> <cmt> accepted baselines. </cmt> <cmt> added overloads for 'map' on tuple types. </cmt> <cmt> accepted baselines. </cmt> <iss> tuple types and map </iss>",add overloads for 'map' on tuple types
3924,"<desc> second try, replaces #6373, 9600 baud tested by @jason2866 (thanks a lot) improvements to tasmotaserial leverage attachinterruptarg() from stage and pre-2.6, removes the need for multiple interrupt functions, saves 224 bytes of iram pre-compute m_bit_start_time time for first byte, instead of computing it in the interrupt handler removed optimistic_yield(1) from the interrupt handler, optimistic_yield is not in iram, i'm not sure it's safe to call it from the interrupt handler. anyways, low baud (9600) should use the nw option. changed while (esp.getcyclecount()-start < wait) to while (esp.getcyclecount() < wait + start), the addition gets out of the loop (minor change) removed first digitalwrite(m_tx_pin, high);, if the output is not already in high mode then it's too late to change it (am i missing something?) when sending, re-enable interrupts at the beginning of stop bits, instead of after stop bits. total time won't change but it allows other interrupts to be served earlier i did lots of tests with zigbee and discovered that sometimes bytes were misread. what happens is that when receiving a row of bytes, interrupts are disabled for each byte, re-enabled after stop bit and disables again for next byte. this short window would allow other interrupts to fire and delay enough the serial interrupt that the first bit would be missed. i changed so that the interrupt handler wait for 3.5 stop bits if the next message is already there. if so it continues to read it without lifting interrupts, if not it re-enables interrupts. overall i saw a huge improvement in reliability when receiving at 115200. overall iram saving: 280 bytes theo, i didn't change the tasmotaserial verion number. i hope i did not change the behavior at lower baud rate, this might need some more testing. the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.3.0, 2.4.2 and 2.5.2 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. </desc> <cmt> change improve reliability of tasmotaserial at 115200 bauds and reduce iram usage for stage/pre-2.6 </cmt> <cmt> tasmotaserial 2.3.5 </cmt>",reduce iram usage by 280 bytes and improve reliability at 115200 bauds (v2)
3925,"<desc> relates to #3954. in addition to changing exceptions types returned to be more explicit, this pull incorporates the following changes: adds a new assertraisesregexp to util/testing.py to port the assertraisesregexp helper from 2.7+ unittest cleans up stats/common. fix up initial assertions in tseries.offset._cached_range that were all off + fix the test cases which were all just raising typeerrors because they were calling with the wrong arguments. changes the example timezone from asia/beijing to asia/hong+kong b/c asia/beijing is not supported by pytz. any tz-aware : tz-naive comparison fails with typeerror, as will mismatched, localize, etc. calls. changes sparsearray indexing error messages to match tuple message for completeness. improves the window check in ols. after you all say it's okay to merge, i'll update the docs to reflect changes. </desc> <cmt> enh/tst: add assertraisesregexp to util/testing </cmt> <cmt> port of assertraisesregexp from python 2.7 unittest </cmt> <cmt> cln: change merge to raise valueerror on overlapping indices </cmt> <cmt> tst: change exceptions to appropriate cases for tests involving merge. </cmt> <cmt> cln: change internal error from exception to pandaserror </cmt> <cmt> cln: stats/common: replace bare exceptions </cmt> <cmt> replace with more descriptive exceptions </cmt> <cmt> tst: add test case for unrecognized cluster </cmt> <cmt> cln: cleaner window check in ols + add error message </cmt> <cmt> cln: cleanup stats/common and change exception type </cmt> <cmt> made it explicit that cluster_type checks if it's a window type first. </cmt> <cmt> changed get_cluster_type to be clearer as well. </cmt> <cmt> replaced the exception raise with a valueerror raise. </cmt> <cmt> tst: add test case for bad window_type </cmt> <cmt> cln: pandas/sparse: replace bare exceptions </cmt> <cmt> replace with more descriptive exceptions </cmt> <cmt> cln: sparsepanel: replace bare exceptions </cmt> <cmt> cln: sparseframe: change bare exceptions </cmt> <cmt> cln: sparseseries: change bare exceptions </cmt> <cmt> cln: sparsearray: change bare exceptions </cmt> <cmt> harmonize capitalization of sparsearray indexerrors </cmt> <cmt> added note about possible unreachable code fragment </cmt> <cmt> tst: add test cases for sparsearray </cmt> <cmt> tst: add sparseframe test cases for the improved exceptions </cmt> <cmt> cln: tools/tile: replace bare exceptions </cmt> <cmt> tst: add test for new valueerror in tile tests </cmt> <cmt> cln: pandas/tseries: replace bare exceptions </cmt> <cmt> replaces bare exceptions with more descriptive ones. </cmt> <cmt> cln: tseries/frequencies: replace bare exceptions </cmt> <cmt> cln: tseries/index: replace bare exceptions (mostly tz-aware + tz-naive </cmt> <cmt> typeerror stuff) </cmt> <cmt> cln: tseries/offsets: replace bare exceptions </cmt> <cmt> cln: tseries/tools: replace bare exceptions </cmt> <cmt> cln: remove exclamation points from error messages. </cmt> <cmt> tst: add more descriptive tests for tseries. </cmt> <cmt> tst: change tests in tseries/test_offsets to be more descriptive </cmt> <cmt> tst: update tests for exceptions from frequencies.py </cmt> <cmt> tst: make more exception tests in tseries/test_timezones explicit </cmt> <cmt> tst: change test of ole2datetime to use explicit exception check </cmt> <cmt> tst: fix up tests in tseries/test/test_daterange </cmt> <cmt> in particular, fix up a bunch of test cases that were failing because </cmt> <cmt> of typeerrors/clearly not changing when _cached_range changed type </cmt> <cmt> signature. </cmt> <cmt> cln: use timezone natively supported by pytz </cmt> <cmt> apparently asia/beijing is actually used in china, but it's </cmt> <cmt> not natively supported in timezone software. see for example: </cmt> <cmt>  </cmt> <cmt> that said, example timezone in docs should at least work, so </cmt> <cmt> that's the reason for the change </cmt> <cmt> cln: make aware vs. naive always a typeerror </cmt>",change bare exceptions pt 1
3926,<desc> replaces the solution merged with #1327 a better solution. handles the problem and guides the user (dev). see updated discussion in #1231 </desc> <cmt> fix(generator):  #1231 'generate container' produces unnecessary return </cmt> <cmt> fix(generator): improved solution to 'generate container' produces unnecessary return #1327 </cmt> <cmt> merge dev into useless-return </cmt>,'generate container' produces unnecessary return - better solution
3927,"<desc> fixed the bug from #5407 and #2603. the function matchesfilter returned true if the file's relative path or its basename matched the given regular expression. i adjusted this to only test the basename for a match if the base option is not set (or set to .). i added the test pack should include files only ignored in other directories. two tests were failing on my local build, but they were also failing before making the changes. all other tests were green. </desc> <cmt> test: test .gitignore files restricting to their own subdirectories (#2603) </cmt> <cmt> currently, .gitignore statements extend to the parent directory. as such, even files in different </cmt> <cmt> directories, not targetted by that specific .gitignore file are ignored when packaging. </cmt> <cmt> fix: don't filter files by basename </cmt> <cmt> files are filtered by basename, even when being in a subdirectory </cmt> <cmt> closes #2603, #5407 </cmt>",restrict .gitignore to their own subdirectories
3928,"<desc> closes #67. yes i know i should keep cleanup separate from new features. </desc> <cmt> these parens are extraneous. </cmt> <cmt> start of --pager support. </cmt> <cmt> change all printf()s to fprintf()s and all putchar()s to fputc()s. </cmt> <cmt> no, these should not be macros. </cmt> <cmt> pclose() out_fd if we're using a pager. </cmt> <iss> pager support (for paging through colored results) </iss>","random cleanup, add --pager option."
3929,<cmt> note performance aspects of using multiple accumulators </cmt> <cmt> add accuracy notes </cmt> <cmt> show where each footnote applies </cmt> <cmt> better wording for the incremental loop costs </cmt> <cmt> improve wording for the accuracy paragraph </cmt> <cmt> add test cases </cmt> <cmt> show subtest parameters in hex. </cmt> <cmt> improve comment </cmt> <cmt> remove doubt by computing reference values directly </cmt> <cmt> add documentation </cmt>,add docs and tests for hypot()
3930,"<desc> drag gesture recognizer now accepts all pointers when any pointer is accepted. this is useful when the accepted pointer is accepted by default, i.e. when all other arena memebers has quit (been disposed). fixes #82784. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> basic test </cmt> <cmt> fix </cmt> <iss> drag gesture crashes when one of the 2 pointers wins by default and is then released </iss>",drag gesture recognizer accepts all pointers when any pointer is accepted
3931,<desc> based on: #53588 & #53519 but upgraded to popper v2 as requested note: i upped the minimal node version add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> upgrade react-datepicker to v4 and popper v2 </cmt> <cmt> fix: use arrey </cmt> <cmt> fix: set minimal typescript version </cmt>,upgrade react datepicker v4 & popper v2
3932,<desc> this should get our unit tests going again. also it fixes bad clean of our source tree (which left xbmc/addons/addons.a and object files stale) because the exclude pattern also applied for xbmc/addons and not only the addons subdir (thx @wsnipex for the correct syntax). i have compile tested this with and without unit tests already on jenkins and have now kicked a build for verifying the clean issue. once it looks good i will merge this with out further jenkins torture. this partly reverts: 3764f03 </desc> <cmt> [buildsys/make] - remove main.a from the list of directory_archives for preventing duplicate linkage when compiling unit tests </cmt> <cmt> [jenkins] - ensure that only the path workspace/addons is excluded from the clean - before it excluded workspace/xbmc/addons aswell which left the stale addons.a file around </cmt>,fixed duplicate main function during linkage of unit tests
3933,<desc> description what does your pr belong to? website snippets general / things regarding the repository (like ci integration) tests types of changes bug fix (non-breaking change which fixes an issue) enhancement (non-breaking improvement of a snippet) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) checklist: my code follows the code style of this project. my change requires a change to the documentation. i have updated the documentation accordingly. i have checked that the changes are working properly i have checked that there isn't any pr doing the same i have read the contributing document. </desc> <cmt> test for randomnumberinrange </cmt> <cmt> update test for random hexcolorcode </cmt> <cmt> test for randomintarray </cmt> <cmt> fix conflicts </cmt> <cmt> fix typo in average test </cmt>,fix typo in average test and add test for randomhexcolorcode
3934,"<desc> a backport of #11248 broke the 2.8 build due to usage of the embeddedkafkacluster#stop method, which used to be private. it seems we made this public when we upgraded to junit5 on the 3.0 branch and had to remove the externalresource that was previously responsible for calling start() and stop() for this class using the no-longer-available @classrule annotation. rather than adapt this test to the 2.8 style by migrating it to use @classrule as well, i opted to just make the stop() method public as well (since its analogue start() has always been public anyways). this should hopefully prevent any future backports that include integration tests from having to manually go in and adapt the test, or accidentally break the build as happened here. </desc> <cmt> use embeddedkafkacluster as classrule in 2.8 </cmt> <cmt> just make it public instead for future compatibility </cmt>",fix backport of #11248 by future-proofing the embeddedkafkacluster
3935,"<desc> the status is recorded into a separate bigquery table, due to the limit of streaming uploading of run that block the record from being updated. the new status table is only inserted/updated via standard sql query. </desc> <cmt> update benchmark logger to update the run status. </cmt> <cmt> this is important for streaming upload to bigquery so that the </cmt> <cmt> dashboard can ignore the 'running' benchmark at the moment since </cmt> <cmt> its not finished yet. </cmt> <cmt> move the run status into a separate table. </cmt> <cmt> also update the run status in the benchmark uploader and </cmt> <cmt> bigquerybenchmarklogger. </cmt> <cmt> insert instead of update for the benchmark status for file logger. </cmt>",record the status for a benchmark run.
3936,"<desc> i'm currently working toward getting a src/ci/docker container working to do isolated/automated builds and testing of x86_64-unknown-cloudabi. this is working pretty well, but still requires some fixes to libtest and compiletest. here is the first set of fixes that i had to apply. </desc> <cmt> add cloudabi to the list of supported targets in compiletest. </cmt> <cmt> without this change, compiletest will fail to run when targetting </cmt> <cmt> cloudabi. </cmt> <cmt> move the testpaths structure from libtest to compiletest. </cmt> <cmt> this structure doesn't seem to be used by libtest itself. it is used by </cmt> <cmt> compiletest, but never passed on to anything externally. this makes it </cmt> <cmt> easier to get the testing framework to work for cloudabi crossbuilds, as </cmt> <cmt> cloudabi currently lacks pathbuf, which is used by testpaths. </cmt>",tiny fixes to make compiletest work for cloudabi cross builds
3937,"<desc> original pull-request #27317 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> update dockerfile </cmt> <cmt> update pvs checksum </cmt>",cherry pick #27317 to 21.7: update pvs checksum
3938,"<desc> this is a follow up for #29526 which removes all left-overs from gatsby-image as the output looked very unfinished, i gave the layout and output a few css updates. the code related to gatsby-image removal is in the first commit </desc> <cmt> refactor: use gatsby-plugin-image only </cmt> <cmt> fix: improve header layout and use layout on image example page </cmt>",using-contentful to use gatsby-plugin-image exclusively
3939,"<desc> see individual commits. the goal is to narrow down those utilities because they are copied into both bundles. while we're at it, also making some things dev-only. there is a bit more duplication than i'd like, but it's partly due to stack. for things like symbols, i don't think modules are super useful. note: this 441a04e breaks ie8 hard. </desc> <cmt> make reactcontrolledvalueproptypes dev-only </cmt> <cmt> remove candefineproperty </cmt> <cmt> this breaks ie8. we don't support it. </cmt> <cmt> remove getnextdebugid </cmt> <cmt> it was added temporarily to avoid stack shared state issues across renderers. </cmt> <cmt> not a problem anymore. </cmt> <cmt> make keyescapeutils.unescape() dev-only </cmt> <cmt> remove unused deprecated() module </cmt> <cmt> it's unlikely we'll deprecate anything else on react.* object soon. </cmt> <cmt> inline getiteratorfn at the call sites </cmt> <cmt> inline reactelementsymbol </cmt> <cmt> inline keyescapeutils into children and move the file into stack </cmt> <cmt> it's only used in one place in isomorphic. </cmt> <cmt> it's used more broadly in stack so we move it there to die. </cmt> <cmt> update artifacts </cmt>","inline some internals, reduce shared/ utilities between isomorphic and renderers"
3940,<desc> @brendandburns @roberthbailey </desc> <cmt> update the kubelet to ignore syncing pods until the container runtime is up. </cmt> <cmt> truncate ssh usernames to 32 chars. </cmt> <cmt> pass through an explicit proxy_ssh_user. </cmt> <cmt> use user@user instead of user@hostname in case hostname is too long. </cmt>,allow passing through an explicit proxy_ssh_user.
3941,"<desc> performance yes if relevant, link to documentation update: n/a summary sort parents, children, siblings in stats improve way of getting combinations of chunks no other information </desc> <cmt> sort parents, children, siblings in stats </cmt> <cmt> update test case to be more complex </cmt>",improve performance of chunk splitting combinations
3942,"<desc> in the guides of active storage overview, there is an example for direct_uploads.js, which contains xss attack vulnerability. the web application fails to sanitise the name of the uploaded file for special html characters and allows injection of html/javascript payload into the dom model of the web page. for example, when an file with the following name is uploaded, the simple javascript code embedded in the filename is executed: ""><img src=a onerror=alert(1)>.png solution: sanitised file name for file uploads before it is incorporated in html dom model. i have chosen to add sanitised file name as a text content after inserting of direct-upload html, so that text remains same for user. if i just replace ${file.name} for ${encodeuri(file.name)}, user will see encoded characters in direct-upload html, in example case: ""%22%3e%3cimg%20src=a%20onerror=alert(1)%3e.png"". </desc> <cmt> updated active storage overview guide by sanitizing direct upload file name </cmt> <cmt> updated active storage overview guide by sanitizing direct upload file name </cmt>",fixed active storage overview guide containing xss vulnerability
3943,"<desc> this takes #4933 but only runs the invasive tests during the nightly runs. </desc> <cmt> ci: move coverity in its own pipeline </cmt> <cmt> since coverity is down for a unspecified timeframe, isolate it from the </cmt> <cmt> ""hosted"" nightlies. </cmt> <cmt> ci: enable some of the invasive testcases </cmt> <cmt> tests: fix test expectation mismatch </cmt> <cmt> ci: precisely identify the invasive tests </cmt> <cmt> ci: clear settings variables in powershell </cmt> <cmt> ci: only run invasive tests during nightly runs </cmt> <cmt> ci: run all invasive tests on windows </cmt>",only run invasive tests in nightly
3944,"<desc> dear @peng-yongsheng @ascrutae @candyleer @liuhaoyang @adriancole @basvanbeek @jcchavezs, i am working on this pull request, which is about receiving and analysis zipkin trace. i paste the reamde doc of this module at here, to give everyone a brief: zipkin receiver zipkin receiver provides the feature to receive span data from zipkin instrumented applications. skywalking backend provides analysis, aggregation and visualization. so the user will not need to learn how skywalking auto instrumentation agents(java, .net, node.js) work, or they don't want to change for some reasons, such as zipkin integration has been completed. zipkin receiver is only an optional features in skywalking, even now it is an incubating feature. limits as an incubating feature, it is a prototype. so it has following limits: don't try to use skywalking native agents and zipkin's libs in the same distributed system. considering headers of zipkin and skywalking aren't shared/interoperable, their two will not propagate context for each other. trace will not continue. don't support cluster mode. analysis based on trace will be finished in the certain and given duration. the default assumption is 2 min most. skywalking used more complex header and context to avoid this in analysis stage. right now(28th, may.), i just finished my codes with following features: open and listen /api/v2/spans service receive and deserialize spans from existed openzipkin/sleuth-webmvc-example. use caffeine cache implementor to organize all spans into a trace. use cache expired mechanism, assume trace can be analysis x(setting) mins after last span of the certain traceid reported. i want to ask any one who has time, interest and is familiar with zipkin format, especially @adriancole @basvanbeek @jcchavezs , to check whether i miss anything for a zipkin v2 json format. the next i am going to do is: after trace finished, analysis the whole trace(spans), transfer them to tracesegment based on its tree structure and localendpoint/servicename as application code. for milestone, in beta2, i will definitely consider this as an incubating feature only.  wait for me or someone else to change the local cache implementor to redis(cluster) based in 5.1.x series, maybe. </desc> <cmt> add zipkin receiver module </cmt> <cmt> open http service at zipkin tranditional port, and context path. and put some doc for it. </cmt> <cmt> update description. </cmt> <cmt> add the link to zipkin.io </cmt> <cmt> make zipkin sdk connected. </cmt> <cmt> finish zipkin trace cache and finish mechanism(based on timeout) </cmt>",zipkin receiver in skywalking collector
3945,<desc> this pr removes the need for a custom named column in case of a distinct count function. fixes #39511. </desc> <cmt> removed custom naming for distinct count </cmt> <iss> sql: count(distinct) column name has an extra distinct in it </iss>,fix count distinct column name
3946,"<desc> this pull requests enables caps lock to be remapped to either escape or control which is very useful for for instance using vim where you hit escape a lot. if you remap caps lock to escape for instance and then want to remap it back to caps lock you will need to restart the application for it to register properly, but i find that to be ok for this cut, it can be improved upon later. another improvement down the line would be to move the settings to the actual settings panel inside the app. this fixes #38 . </desc> <cmt> remap caps lock to be escape </cmt> <cmt> right now this always remaps caps lock to be escape, but with support to </cmt> <cmt> change this later. </cmt> <cmt> add settings.bundle </cmt> <cmt> this bundle keeps the setting of what to remap caps lock to. this should </cmt> <cmt> be changed to use the in-app settings system instead. the transition </cmt> <cmt> there should be pretty straight forward. </cmt> <cmt> let caps lock be overwritten from settings </cmt> <cmt> now you can go to settings and ish and chose what you want the caps lock </cmt> <cmt> to be verwritten to! </cmt> <iss> allow to map cap-lock to escape </iss>",allow caps lock to be remapped to escape and control
3947,"<desc> the test_scheduler_reschedule method fails when creating processes in spawn mode, which is the default mode for python 3.8 on macos. test_scheduler_reschedule depends on mock.patch() decorators around the .do_schedule() method in the parent process to mock dagbag objects in the child process. since spawn mode limits the amount of parent state accessible within the child process, dagbag is not properly mocked in the new process, causing the test to fail. this pr forces the test to use fork instead of spawn when creating a child process, allowing the mocks to work as intended. make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> use 'fork' in test bc 'spawn' breaks mocks. </cmt>",use fork when test relies on mock.patch in parent process.
3948,"<desc> what this pr does / why we need it: before we had the hyperkube base image, it was difficult to build the hyperkube with bazel. now that we have the base image with all the necessary dependencies, this has become trivial. this will enable federation jobs etc on prow. release note: /assign @bentheelder @mikedanese @spxtr </desc> <cmt> bazel: bump rules_go </cmt> <cmt> build hyperkube image with bazel </cmt>",build hyperkube image using bazel
3949,"<desc> changes in this pull request: fixes to scoped_exit. check for redundant signatures due to multiple signatures from same key. fix bug in record_locks_for_data_access (did not account for intersection between read_locks of transaction_trace and write_locks of existing shard_trace). put limits on number of keys/accounts in authorities (but a high limit like 2^16) to make overflow of accumulated weights impossible. disallow empty parent for permissions other than owner. actually enforce the existence of permissions contained in an updated authority (changed find to get). reserve account names starting with ""eosio."" (previously was a much stricter check of whether the name contains ""eosio.""). reserve permission names starting with ""eosio."" create dummy permission_object as first object in permission_index during chain initialization so that a parent id of 0 can never refer to a legitimate object. use fc::microseconds for delay rather than time_point. fixed bug with how a permission visitor works with the authority_checker. it would visit permissions that did not end up contributing towards satisfying the authority. my quick fix (a more elegant fix is eventually desired) causes the permission visitor to visit unneeded permissions but now with extra surrounding information (push_undo, pop_undo, squash_undo) to help it discard the side effects of visits to permissions that ended up not being used. this bug had implications on the minimum delay calculated by check_authorization (they could have been higher than necessary). changes to validating signatures/authorities/tapos/expiration/uniqueness (affects #1753 and #1755): see details below. there are two stages to validating a transaction. the first stage involves checks that can be made with minimal state information: just the information either included in the packed_transaction itself or the state available as of the end of the previous block (specifically head block timestamp and tapos block ids). the first stage of checks are mostly done in a function called validate_transaction_with_minimal_state. it checks that there is at least one action in the transaction, that is has not expired yet, that its tapos referenced block is valid, and that the network usage due to the packed_transaction alone is not too much to cause the transaction to be invalid based on its (soon to be) upper bound on net usage committed in the transaction header. there is also another check/processing that can be done in this first stage (except for generated transactions): recovering the public keys from the signatures and ensuring there are not multiple signatures signed by the same key. the second stage involves the remaining checks that require the state information at the point at which the transaction is scheduled to execute (or be delayed). they include the checks on uniqueness of the transaction, that the expiration in the transaction header is not too far in the future relative to the appropriate reference time (head block time + any delay imposed) based on the limits in the chain parameters, and that the accounts referenced in the authorizations of the transaction exist. they also include checking the authorizations using: if an input transaction, the set of recovered public keys from the signatures; or if a generated transaction, only the owner permission of the contract code that generated the transaction. for delayed input transactions or generated transactions (whether delayed or not), checks occur at two different times. first, the delayed input or generated transaction is checked using the stage 1 and stage 2 checks at the time of dispatch. then, at the time of scheduling/execution additional checks are performed: check that the transaction is not executing prematurely, check that the transaction has not expired yet again, and check uniqueness again. </desc> <cmt> fix scoped_exit #1755 </cmt> <cmt> check expiration time of deferred tx to avoid keeping the tx id in transaction_index for too long #1753 </cmt> <cmt> unit test on deferred transaction expiring too late #1753 </cmt> <cmt> remove redundant validate_block_header when generating a block #1755 </cmt> <cmt> added signature/authorization check for input transactions. #1755 </cmt> <cmt> also, disallowed redundant signatures in a tx that are signed by the </cmt> <cmt> same key. </cmt> <cmt> modified block_tests/irrelevant_sig_soft_check to check for multiple </cmt> <cmt> signatures by same key and to account for the fact that blocks with </cmt> <cmt> transactions that have irrelevant signatures are objectively invalid. </cmt> <cmt> also added block_tests/irrelevant_sig_hard_check unit test to verify </cmt> <cmt> that such objectively invalid blocks are rejected. </cmt> <cmt> send_action_large in api_tests/transaction_tests is behaving very oddly. </cmt> <cmt> the size of the too large inline action it is sending is calculated as </cmt> <cmt> 8107 when it should be 8227. </cmt> <cmt> (there is no miscalculation of the inline action size if the dummy data </cmt> <cmt> is increased to 9*1024.) </cmt> <cmt> this causes read_action_normal to actually execute when instead the </cmt> <cmt> ""inline action too big"" error should have been thrown. </cmt> <cmt> even more bizarrely, the boost_check_exception of the ""inline action too </cmt> <cmt> big"" error for that test succeeds if there are print statements in </cmt> <cmt> read_action_normal. </cmt> <cmt> but whenever the print statements in read_action_normal are removed, it </cmt> <cmt> instead gives another error message ""abort() called"" causing the </cmt> <cmt> boost_check_exception to fail. </cmt> <cmt> fixed bug in record_locks_for_data_access. </cmt> <cmt> limits on authority size to prevent accumulated weight overflow </cmt> <cmt> also, added a comment regarding a potential issue with </cmt> <cmt> shared_authority::get_billable_size() which is relevant whenever new </cmt> <cmt> public keys are to be added via hardfork after launch of a live network. </cmt> <cmt> bug fixes for permissions and reserved names </cmt> <cmt> permissions in updated authority should exist. </cmt> <cmt> non-privileged account creators should be restricted from using account </cmt> <cmt> names that _start_ with ""eosio."". </cmt> <cmt> reserve ""eosio.any"" as permission name. </cmt> <cmt> disallow empty parent for any permission other than owner. </cmt> <cmt> reserve id = 0 in permission_index so that a parent id of 0 always means </cmt> <cmt> ""no parent"" rather than referring to a legitimate permission_object </cmt> <cmt> (e.g. the owner permission of the system account). </cmt> <cmt> permission visitor should not consider visits that did not contribute to satisfying the authority </cmt> <cmt> also, now using fc::microseconds for delay. </cmt> <cmt> progress on #1755 and on cleaning up delayed transactions </cmt> <cmt> reserve all permission names that start with 'eosio.' </cmt>","check signatures, transaction validation checks, and many other bug fixes"
3950,<desc> currententry is taken from string array this.history. it represents an url string but not an object. the field currententry.url should not be accessible by any means. i believe this was a coding error made by mistake. this pr fixes this bug. this pr also removes return statement from the callback in order to keep consistency. </desc> <cmt> fix a minor bug in navigation-controller where a string is used as an object </cmt> <cmt> simplify logic </cmt>,fix a bug in navigation-controller where string is used as object
3951,<desc> same as #2121 but for both react and vue apps (the change doesn't seem to make sense for rn app) </desc> <cmt> avoid logging an object on compilation errors </cmt> <cmt> in certain configurations storybook might log the whole webpack </cmt> <cmt> build object when warnings or errors are thrown. this was caused </cmt> <cmt> by a logger.error call inside the index.js catch. this fixes by logging </cmt> <cmt> the error only when it's an instance of an error. </cmt> <cmt> copypaste the change to vue app </cmt>,avoid logging an object on compilation errors [2]
3952,<desc> resolves devrel-1575: fix broken references to eos repo docs (backport of pr #10570 #10571 to 2.1) select one: select any that apply: </desc> <cmt> remove broken cleos wrap cmd ref link :doc </cmt> <cmt> fix broken links in cleos wallet keys cmd :doc </cmt> <cmt> fix broken link in cleos wallet create cmd :doc </cmt> <cmt> fix broken link in cleos create account cmd :doc </cmt> <cmt> fix broken link in cleos get transaction cmd :doc </cmt> <cmt> update eosio overview index file from 2.0 :doc </cmt> <cmt> fix broken link in how to connect to specific net :doc </cmt> <cmt> fix broken links in cleos system buyram cmd :doc </cmt> <cmt> fix broken links in nodeos deep mind logger :doc </cmt> <cmt> fix self link in keosd wallet plugin index :doc </cmt>,fix some broken anchors and links - 2.1
3953,<desc> this change points users in the direction of 1.x docs in the repo. </desc> <cmt> link to 1.x documentation in notes </cmt> <cmt> update readme to link to previous versions </cmt> <cmt> note - this removed now not required mention of liquid tags in docs. </cmt>,link to previous version docs
3954,<desc> description: the states opening and closing was inverted for homekit covers which is fixed with this change. related issue (if applicable): fixes #25945 checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> update cover.py </cmt> <cmt> update test_cover.py </cmt> <iss> closing/opening seems to be swapped </iss>,inverting states for opening/closing homekit covers
3955,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the load method can also be modified to take a second argument, an object with an integrations dictionary, which used to load only the integrations that are marked as enabled with the boolean value true. works in version 4.1.0 or higher. more info about this can be found in segment analytics documentations. </desc> <cmt> configure segment with write key & integration management </cmt> <cmt> capitalize a word in comments </cmt>",segment-analytics | configure segment with write key & integration management
3956,<desc> added missing some enum values to predefined types (according to tabulator documentation/examples) </desc> <cmt> update index.d.ts </cmt> <cmt> added missing some enum values to predefined types (according to tabulator documentation/examples) </cmt> <cmt> update index.d.ts </cmt> <cmt> replaced function with specific function type </cmt> <cmt> update index.d.ts </cmt> <cmt> updated onrendered type for formatter type definition </cmt> <cmt> updated formatter definition. updated tabulator-tables-tests according formatter definition </cmt> <cmt> update tabulator-tables-tests.ts </cmt> <cmt> fixed tabulator.emptycallback reference in tabulator-tables-tests </cmt>,updated some type declaration for tabulator-tables
3957,"<desc> this will reintroduce the changes from #64678, which was reverted because it was out of date with test files that had been migrated to nnbd. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. </desc> <cmt> wrap popupmenu with safearea to respect status bar </cmt> <cmt> edit second popupmenu test </cmt> <cmt> add newline between tests </cmt> <cmt> add newline between added tests </cmt> <cmt> remove trailing spaces </cmt> <cmt> specify type in test code </cmt> <cmt> update tests </cmt> <cmt> remove trailing space </cmt> <cmt> add nnbd to tests </cmt>",re-land 'wrap popupmenu with safearea to respect status bar'
3958,<desc> closes: #7370 </desc> <cmt> upgrade gradle-wrapper (and gradle) to the latest version. </cmt> <cmt> this is a snapshot after 'gradlew wrapper --gradle-version 6.5.1' </cmt> <cmt> * make it work. </cmt> <cmt> * use the latest clojure and clojurescript gradle pluguin. they are renamed. </cmt> <cmt> * fix gradle deprecated warnings. </cmt> <cmt> * upgrade libs to sync with the java invoke bridge. </cmt> <iss> the dependency gradle-wrapper.jar has a number of security flaws as identified by a veracode static scan </iss>,upgrade gradle-wrapper and gradle to fix #7370
3959,"<desc> i'm proposing 3 different automations to manage our issues: close issues opened without using one of our pre-defined issue templates close stale issues labeled as stat: need more info after 2 weeks close stale issues without any comments after 67 days the stale issue handling are done via a github action called stale and the other one via close issue app. the main idea behind this is to get rid of very old and not relevant issues so we can focus on the important ones. once we enabled this, this is the issues that would be immediately affected: 1459 issues marked as stale to be closed after 7 days if nobody adds a comment - link to preview 23 issues marked with ""no response"" to be closed after 4 days if nobody adds a comment - link to preview how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog this is how they are intended to work: stale issues (without interaction) bot will search for issues without new comments in the last 60 days that doesn't have any of the following labels: epic feature: planned sla sponsored stat: waiting pr merge triaged subj: security for issues matching the criteria the bot will add the label stat: stale and will add a comment to explain that the issue is now marked as stale. if the issue receives a new comment or any other update after being marked as stale, it will automatically be removed from stale and have it's label removed. issues with the label stat: stale that didn't receive new comments or updates after 7 days will be automatically closed. new comments after the issue is closed will not open the issue again (not supported by the bot). what we could do in this (and is supported by the bot) is to add a new comment saying what the issue owner can do, it could be something like ""please test with most recent release and open a new issue if still happening"". no response issues bot will search for issues with label stat: need more info without new comments or updates in the last 10 days for issues matching the criteria the bot will add the label stat: no response and will add a comment to explain that the issue is now marked as stale. if the issue receives a new comment or any other update after being marked as stale, it will automatically be removed from stale and have it's label removed. issues with the label stat: no response that didn't receive new comments or updates after 4 days will be automatically closed. since someone have interacted with the issue before the bot actually close the issue, if the owner replies after it is closed, it's responsibility to the user that add the label stat: need more info to evaluate the reply and open issue again. </desc> <cmt> remove custom issue template </cmt> <cmt> add stale app config </cmt> <cmt> add no response app config </cmt> <cmt> add isse close app config </cmt> <cmt> add comment </cmt> <cmt> use github actions for stale issues </cmt>",add apps to control github issues
3960,"<desc> there are a few things i missed in gh-27980.  this is a follow-up that will make subsequent prs cleaner.  it includes fixes to tests and tools that reference the frozen modules. (fyi, these changes come from gh-28107.  @gvanrossum already reviewed them there.) </desc> <cmt> fix freeze_module() in freeze_modules.py. </cmt> <cmt> add frozensource and frozenmodule to freeze_modules.py. </cmt> <cmt> leave all non-required frozen modules uncommitted. </cmt> <cmt> leave *all* frozen modules uncommitted. </cmt> <cmt> generate the list of frozen modules used by test_ctypes. </cmt> <cmt> ignore frozen submodules in generate_stdlib_module_names.py. </cmt> <cmt> add a comment to the frozen modules manifest file. </cmt> <cmt> show how the frozen manifest changed. </cmt> <cmt> go back to keeping frozen modules in the repo. </cmt> <cmt> also stop tracking the frozen manifest. </cmt> <cmt> mark the frozen manifest as a generated file. </cmt> <cmt> drop a superfluous prefix on makefile rule dependencies. </cmt> <cmt> do not generate test code. </cmt> <cmt> drop unused code from freeze_modules.py. </cmt> <cmt> do not clear the frozen .h files with ""make distclean"", now that they are back in the repo. </cmt> <cmt> always flush the printed ""title"" when freezing modules. </cmt> <cmt> add the frozen manifest back into the repo. </cmt> <cmt> on windows, only freeze the essential modules for now. </cmt>",do some cleanup related to frozen modules.
3961,"<desc> pass devicestatus to iob.calctotal and cob.cobtotal let iob be undefined sometimes (no treatments and no devicestatus in sandbox == haven't heard from device in a while == undefined iob, displayed as ""---u"". assuming/showing ""0u"" in this case would be misleading.) ...but always return a number on /pebble for backwards compatibility with the clients in the wild </desc> <cmt> pass devicestatus to iob.calctotal </cmt> <cmt> show iob from devicestatus when available </cmt> <cmt> make day-to-day report able to plot negative or discontinuous iob </cmt> <cmt> don't assume iob is 0 in the absence of treatments </cmt> <cmt> handle iob format from mm connect </cmt> <cmt> show 0 iob on /pebble even when undefined, for backwards compatibility </cmt>",show iob from devicestatus when available (openaps or mm connect)
3962,"<desc> fixes #12314. however, whether the solution is optimal is tbd. furthermore, i put the sentry_dsn environment variable into the envobject in next.config.js. however, it is not 100% clear to me whether this is correct. </desc> <cmt> update sentry packages </cmt> <cmt> disable sentry in development and add auth for sourcemap upload </cmt> <iss> with-sentry-simple requires auth to upload sourcemaps via webpack plugin </iss>",#12314 add auth to with-sentry-simple example
3963,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). multi:  tokey:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fix: add multi and tokey methods </cmt> <cmt> fix: return pipeline without promise </cmt> <cmt> test: add test </cmt>",add missing low level methods
3964,<desc> class which calculates pi using nilakanthas infinite series #2323 i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> added class pinilakantha.java </cmt> <cmt> which calculates pi using nilakanthas infinite series </cmt> <cmt> added link to explanation </cmt> <cmt> partially fixes #2323 </cmt>,added class that calculated pi
3965,<desc> for #5301 fix #6003 fix select_distinct_with_multi_column_without_order_by fix select_distinct_without_order_by fix select_with_case_expression enable db rule type </desc> <cmt> fix select_distinct_with_multi_column_without_order_by </cmt> <cmt> fix select_with_case_expression & enable db rule type </cmt> <iss> distinct sql assert failed in integration test after open db rule type </iss>,fix integrate test error in db rule type mode
3966,"<desc> towards #16155 remove boston dataset in sklearn/ensemble/tests/test_gradient_boosting.py. use a subset of california housing dataset for test_boston and use diabetes dataset for all remaining tests. used california dataset for test_boston due to the high mse error if diabetes dataset used (for parameters in test, mse ranged from ~600-1700). correspondingly there was also a bigger difference between predictions (assert_array_almost_equal(last_y_pred, y_pred)) and predictions were only equal with decimals=-2. happy to change to diabetes/another dataset if california not suitable. </desc> <cmt> check diabetes </cmt> <cmt> use diabetes and cali </cmt> <cmt> pytest network </cmt>",tst replace boston in test_gradient_boosting.py
3967,<desc> making it possible to build libchromiumcontent locally instead of downloading prebuilt binaries from internet. close #3310. refs #259. </desc> <cmt> add --build_libchromiumcontent option </cmt> <cmt> docs: cleanup unnecessary parts in build-instructions-linux.md </cmt> <cmt> docs: the --build_libchromiumcontent switch </cmt>,add --build_libchromiumcontent command line switch
3968,"<desc> this change introduces a bottomsheettheme that allows you to theme color, elevation, and shape of bottomsheet. this can be done at the theme level and at call time of showbottomsheet and showmodalbottomsheet. see the following image for an example (with some questionable design choices): related issues closes #26854 closes #30444 i added the following tests: tests for the theme and modifying the color/elevation/shape of the bottomsheet itself tests for ensuring the showbottomsheet and showmodalbottomsheet pass through color/elevation/shape to the bottomsheet before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> introduce bottomsheettheme and shape support for bottom sheet </cmt> <cmt> add bottom sheet theme to themedata. use theme in bottom sheet build </cmt> <iss> adding shape for bottom sheet </iss> <iss> implement shape support for bottomsheet </iss>","add bottomsheettheme to enable theming color, elevation, shape of bottomsheet"
3969,<desc> this fixes requiring next/document directly failing since it uses webpack loader syntax at the top level fixes: #9401 </desc> <cmt> don't use loader import at top level in next/document </cmt> <iss> 9.1.3 fails using jest when a test involves something imported from next/document </iss>,remove top level usage of loader imports in next/document
3970,"<desc> recreated pr #19844 by @senseisimple so it can be edited. keep an eye out for this check-box when creating prs: compile error when case_light_no_brightness is set but case_light_default_brightness is disabled/commented creating minor confusion since one definition implies that the other is not needed or is in conflict. further, the serial echo behavior for turning the case light on with case_light_no_brightness defined is echo:case light: <brightness> which doesn't make semantic sense for the  setting since the brightness value (pnnn) is ignored. since the functionality for the output of echo:case light: off (language const) was already there for a non-pwm pin, a simple solution is to hardcode a default case_light_default_brightness  to 0 (zero) when the case_light_no_brightness is enabled so as to not disturb current functionality and a modified evaluation for the serial echo string is  (!pwm_pin(case_light_pin) || enabled(case_light_no_brightness)) this improves the intuitive understanding between configuring either case_light_no_brightness and/or  case_light_default_brightness as well as a nicer serial output message for on/off states when the case light is not pwm but on a pwm pin. none, definitions already present in configuration_adv.h none </desc> <cmt> case light no_brightness on pwm pin serial echo </cmt> <cmt> compile error when case_light_no_brightness is set but case_light_default_brightness is disabled/commented. </cmt> <cmt> before this patch the serial echo behavior for turning the case light on was echo:case light: <brightness> which doesn't make semantic sense for the no_brightness setting since the brightness value (pnnn) is ignored. </cmt> <cmt> since the functionality for echo echo:case light: off (language const) was already there for non-pwm pin, a simple solution is to hardcode a default case_light_default_brightness to 0 (zero) when the no_brightness is enabled (so as to not disturb current functionality) and a new evaluation for the serial echo string is  (!pwm_pin(case_light_pin) || enabled(case_light_no_brightness)) </cmt> <cmt> case_light_brightness m115 cap </cmt>",case_light_no_brightness on pwm pin improvement
3971,<desc> title is self-explanatory. closes #15895. </desc> <cmt> doc: document pandas.core.dtypes.common </cmt> <cmt> closes gh-15895. </cmt> <cmt> tst: add tests for pandas.core.dtypes.common </cmt> <cmt> the testing of this module was especially lacking </cmt> <cmt> with the exception of is_dtype_equal and pandas_dtype. </cmt>,document and test functions in dtypes/common.py
3972,"<desc> when a tokenizer is being loaded with pretrainedtokenizer._from_pretrained, it should set added_tokens and all_special_tokens to unique_added_tokens_encoder. if we don't do it, it will corrupt the tokenization. example: import transformers tokenizer = transformers.berttokenizer.from_pretrained(""bert-base-uncased"") tokenizer.tokenize(""[cls] token should not be splitted."") # correct output # ['[cls]', 'token', 'should', 'not', 'be', 'split', '##ted', '.'] # incorrect output # ['[', '[unk]', ']', 'token', 'should', 'not', 'be', 'split', '##ted', '.'] </desc> <cmt> fixed lack of added and special tokens </cmt> <cmt> add special tokens to unique_added_tokens_encoder </cmt>",correct tokenization for special and added tokens
3973,"<desc> change this change creates an isource implementation for sqliteindex that provides the interface glue around new functionality to perform a search and query specific data from an index.  the source can also hold a crossprocessreaderwriterlock to prevent any other processes from writing to the index file while it is being used. the search functionality implemented within sqliteindex is minimal; only exact match on id is supported through the query parameter currently (also, everything can be retrieved by giving no query parameter).  however, this still enables all other functionality to be exercised.  additionally, any existing semantics that require version sorting are not implemented, and the results returned are in a somewhat arbitrary order (expect reverse insertion order). additionally, the preindexedpackagesourcefactory has also been enlightened (in both forms) to create a source in response to the opensource function.  this enables the client to complete an e2e scenario of: adding a source searching for an id installing based on an id (and optionally version and channel) other minor changes of note: utility::download will now create any missing directories required to be able to write to the dest file. testing tests are added for the new functionality exposed from sqliteindex, as well as their use through the sqliteindexsource. </desc> <cmt> most of barebones support in </cmt> <cmt> baseline code complete </cmt> <cmt> tests for sqliteindex changes </cmt> <cmt> merge from upstream/master </cmt> <cmt> hook up source factory to sources and add tests for source </cmt> <cmt> fix downloading manifest from remote </cmt>",create sqliteindexsource with bare minimum search functionality
3974,"<desc> this syncs miri with what the nomicon and the reference say, and resolves rust-lang/miri#447. also this would not have worked without #62982 due to new cycles. ;) r? @oli-obk </desc> <cmt> check that ptr is valid already when doing deref, not only when doing the access </cmt> <cmt> discourage use of ref_to_mplace </cmt> <cmt> the alignment checks on access can no longer fail now </cmt> <iss> check that offset is not too big, check projection offset to be inbounds </iss>",check that a ptr is aligned and inbounds already when evaluating *
3975,<desc> add a new addon database feature which can be used by addons to persist data with the storybook. the default configuration stores data in a json file inside the storybook config directory (.storybook). </desc> <cmt> update storybook-addons api </cmt> <cmt> from v1.5 it include get/set database methods </cmt> <cmt> implement database server </cmt> <cmt> add default database client </cmt> <cmt> fix lint errors </cmt>,add database support for addons
3976,"<desc> hello @kazuho !! i implemented some h2o::request methods. for example, executed curl 127.0.0.1:8080/index.html?a=1: r = h2o::request.new r.hostname    #=> ""127.0.0.1:8080"" r.authority   #=> ""127.0.0.1:8080"" r.uri         #=> ""/index.html?a=1"" r.path        #=> ""/index.html?a=1"" r.method      #=> ""get"" r.qeury       #=> ""?a=1"" # if not found query, r.query return nil </desc> <cmt> add h2o::request#{uri,path} </cmt> <cmt> cleanup exmaple </cmt> <cmt> add h2o::request#{hostname,authority} </cmt> <cmt> add h2o::request#method </cmt> <cmt> add h2o::request#query </cmt> <cmt> add test of h2o::request#{uri,query,method,hostname} </cmt>",add some h2o::request methods
3977,"<desc> cherry pick of #100183 on release-1.21. #100183: add e2e test for nodeunstage error cases for details on the cherry pick process, see the cherry pick requests page. </desc> <cmt> add e2e test for nodeunstage error cases </cmt> <cmt> fix unmountdevice error cases </cmt> <cmt> when unmountdevice fails, kubelet treat the volume mount as uncertain, </cmt> <cmt> because it does not know at which stage unmountdevice failed. it may be </cmt> <cmt> already partially unmonted / destroyed. </cmt> <cmt> as result, mountdevice will be performer when a new pod is started on the </cmt> <cmt> node after unmountdevice faiure. </cmt> <cmt> add getpossiblymountedvolumesforpod to let kubelet know all volumes were unmounted </cmt> <cmt> podvolumesexist() should consider also uncertain volumes (where kubelet </cmt> <cmt> does not know if a volume was fully unmounted) when checking for pod's </cmt> <cmt> volumes. added getpossiblymountedvolumesforpod for that. </cmt> <cmt> adding uncertain mounts to getmountedvolumesforpod would potentially break </cmt> <cmt> other callers (e.g. verifyvolumesmountedfunc). </cmt> <cmt> add podremovedfromvolume </cmt> <cmt> to know when a volume has been fully unmounted (incl. uncertain mounts). </cmt> <cmt> refactor dswp unit tests </cmt> <cmt> change existing desiredstateofworldpopulator.findandaddnewpods tests to use </cmt> <cmt> a common initialization function. </cmt> <cmt> add unit test for dswp with uncertain volume </cmt> <cmt> desiredstateofworldpopulator.findandremovedeletedpods() should remove </cmt> <cmt> volumes from dsw when a pod is deleted on the api server and the volume is </cmt> <cmt> uncertain in asw. </cmt>",mark volume as uncertain after unmount* fails
3978,"<desc> first of all, thanks for your contribution! :-) please makes sure these boxes are checked before submitting your pr, thank you! make sure you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. </desc> <cmt> swedish locale </cmt> <cmt> create sv_se.tsx </cmt> <cmt> create sv_se.tsx </cmt> <cmt> create sv_se.tsx </cmt>",add support for swedish locale
3979,<desc> this refactors the remote module to use weakref instead of our bespoke weakref-like solution on the renderer side. similar browser-side refactor to follow. depends on #24034. npm test passes tests are changed or added pr title follows semantic commit guidelines this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: none </desc> <cmt> refactor: tsify remote </cmt> <cmt> refactor: use weakref instead of v8util.createidweakmap in remote </cmt>,use weakref on renderer side of remote
3980,<desc> this pr implements a onrefresh action to let the native filters reload when the dashboard reloads. fixes #15808 126416469-24a7a2ad-3f6b-4da9-9dfd-68d724a1e1eb.mp4 untitled.dashb.3.mp4 open a dashboard with native filters on add a filter remove any of the options from the dataset refresh the dashboard observe that the option is not appearing in the filter has associated issue: #15808 includes db migration (follow approval process in sip-59) </desc> <cmt> implement onrefresh action </cmt> <cmt> update tests </cmt> <cmt> clean up </cmt> <iss> [native filter] options for value filter should refresh when dashboard refresh but currently only when page refresh </iss>,refresh native filters when dashboard refreshes
3981,"<desc> fixes the slave encoder state syncing to reduce dropped pulses. includes fix for iris rev3/rev4 phantom pulses. fixes #7055 my code follows the code style of this project. i have read the contributing document. </desc> <cmt> updated slave encoder sync to reduce dropped pulses </cmt> <cmt> fixing encoder direction </cmt> <cmt> encoder behavior fixes, tested </cmt> <cmt> update keyboards/rgbkb/sol/keymaps/xulkal/rules.mk </cmt> <cmt> to make fauxpark happy </cmt> <cmt> update custom_encoder.c </cmt> <cmt> update rules.mk </cmt> <cmt> iris r4 fix </cmt> <iss> rotary encoder unresponsive on slave half of split keyboard </iss>",updated slave encoder sync to reduce dropped pulses - v2
3982,"<desc> more typing cleanups original failures: pandas/core/groupby/ops.py:13: error: module 'pandas._libs' has no attribute 'groupby' pandas/core/groupby/ops.py:13: error: module 'pandas._libs' has no attribute 'reduction' pandas/core/groupby/groupby.py:22: error: module 'pandas._libs' has no attribute 'groupby' pandas/core/groupby/groupby.py:329: error: need type annotation for '_apply_whitelist' pandas/core/groupby/generic.py:220: error: incompatible types in assignment (expression has type ""callable[[arg(any, 'arg'), vararg(any), kwarg(any)], any]"", base class ""selectionmixin"" defined the type as ""callable[[arg(any, 'func'), vararg(any), kwarg(any)], any]"") </desc> <cmt> removed groupby modules from mypy blacklist </cmt> <cmt> fixed typing issues in pandas.core.groupby </cmt>",fix up typing in groupby
3983,<desc> adds [lint skip] marker to azure pipeline ci to run all the tests even if linting fails. </desc> <cmt> mnt adds lint skipping to azure ci </cmt> <cmt> bld [lint skip] </cmt> <cmt> bug fix [lint skip] </cmt>,mnt adds skip lint to azure pipeline ci
3984,"<desc> moved the different cli managers into their own modules, to allow reuse of sub command names. added two new commands to data source cli: edit and delete (guess what they do...). removed some obsolete commands. </desc> <cmt> remove import from settings command (obsolete). </cmt> <cmt> split cli commands to several files for easier editing and naming. </cmt> <cmt> added edit & delete commands to data source cli </cmt>",new data source management commands in manage.py
3985,"<desc> this pr fixes two related bugs that happened after running retokenizer.split: the lemma information was not updated and was still referring to the old token.text attributes. this is fixed/reset by calling token.lemma = 0 on the split tokens. the vector attributes were left unchanged, causing an out-of-bounds error as described in issue #3540. this is fixed by extending the doc.tensor and setting the vectors of the split tokens to an array of zeros (not sure what else to do). bug fix i have submitted the spacy contributor agreement. </desc> <cmt> fixing vector and lemma attributes after retokenizer.split </cmt> <cmt> fixing unit test with mockup tensor </cmt> <cmt> xp instead of numpy </cmt>",update lemma and vector information after splitting a token
3986,<desc> fixes rdar://problem/78960468. </desc> <cmt> sema: resolveidenttypecomponent() can use a for loop instead of recursion </cmt> <cmt> sema: allow omitting generic parameters when accessing member type with a fully-constrained 'where' clause </cmt> <cmt> fixes rdar://problem/78960468. </cmt>,allow omitting generic parameters when accessing member type with a fully-constrained 'where' clause [5.5-05/14/2021]
3987,"<desc> changes id and class names of svg image elements in challenge, to ensure their uniqueness for the image, and to stop interference from logo svg. slightly cleans-up formatting. tested on local fork. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #41247 </desc> <cmt> fix: correct displaying of malformed svg </cmt> <cmt> fix: formatting clean-up </cmt> <iss> rosetta code: cut a rectangle - svg image impacted by svg in navbar </iss>",prevent malforming of svg image
3988,"<desc> this pr addresses issue #15613. this adds a git setting which determines whether or not to prompt the user if there are changes in the working tree and none of them are staged. </desc> <cmt> add git enablesmartcommit setting </cmt> <cmt> if false, this setting will prompt the user if they want to commit all files if none are staged </cmt> <cmt> check git enablesmartcommit if no staged files </cmt> <cmt> prevent redundant enablesmartcommit prompt </cmt> <cmt> this prevents a prompt for enablesmartcommit if there are no changes at all </cmt>",issue 15613 all files committed
3989,"<desc> the english version is a pdf file, and make chinese version a md file which is easier to maintain later. </desc> <cmt> committed a file into the wrong directory on june 9 </cmt> <cmt> this is a stupid mistake, i found that there missed one chinese version file that i committed yesterday, finally i realized that it was in the wrong directory. the fact that it isn't in the right place can cause a real problem, because all pictures can not be shown. so please merge this modification. </cmt> <cmt> merge from source </cmt> <cmt> create coordination_cn.md </cmt> <cmt> 4 new pictures for coordination_cn.md </cmt> <cmt> create coordination_cn.md </cmt>",commit coordination_cn chinese version along with 4 newly added pictures
3990,"<desc> split the monolithic grab-bag into targeted modules. promotes separation of concerns, easier maintenance, and more targeted mocking. package instance methods hasdependencyinstalled and hasmatchingdependency were moved to separate files, as they are only used in lerna bootstrap. createpackagegraph was removed in favor of direct instantiation of packagegraph. adddependencies is now a packagegraph instance method, which encapsulates the logic better. initcommand no longer checks for the ancient version file, and its tests were significantly simplified. </desc> <cmt> feat: split packageutilities into src/utils/* </cmt> <cmt> validatepackagenames should be a bootstrapcommand method, and throw an error </cmt> <cmt> adddependencies should be a packagegraph instance method </cmt> <cmt> batch-packages does not need a separate test file </cmt> <cmt> collect-packages does not need a separate test file </cmt> <cmt> filter-packages does not need a separate test file </cmt> <cmt> matchpackagename.js -> match-package-name.js </cmt> <cmt> symlinkpackages + createbinarylink = src/utils/symlink </cmt> <cmt> dependencyissatisfied moved entirely within package instance method </cmt> <cmt> run-parallel-batches doesn't need a separate test file </cmt> <cmt> remove createpackagegraph util </cmt> <cmt> move dependency-related utils out of package, only consumed in bootstrap </cmt>",split packageutilities into smaller files
3991,<desc> i carefully read the contribution guidelines and agree to them. this is a preview of the changes that match the requested change in issue #3183 </desc> <cmt> removing the search bar icon when in search mode. issue: #3138 </cmt> <cmt> removing the search bar icon when in search mode. issue: #3183 </cmt> <iss> ui remove search icon when in search mode </iss>,remove search icon in search mode. issue: #3183
3992,"<desc> allow lcd_bed_leveling to be used with the automatic abl options so that fade, probe z offset, etc. are more easily found. counterpart to #10587 </desc> <cmt> fewer includes of vector_3.h </cmt> <cmt> rename float32 => float52, etc. </cmt> <cmt> lcd_bed_leveling enables a sub-menu for abl </cmt>",sub-menu for abl with lcd_bed_leveling
3993,"<desc> this is a copy of #5950, but for the 0.10 branch. unfortually a fallback to ""c"" locale via std::locale::global does not cover all scenarios with messed up environment locale settings and on ubuntu 14.01 (with lang=en_us.utf-8, language=en_us, lc_* empty) setting lang=invalid triggers a crash right at the start of bitcoind and bitcoin-qt. this also affects test_bitcoin and test_bitcoin-qt, which were not guarded at all. the pr expands the scope of the locale fallback and prevents crashes due to invalid locale settings of bitcoind, bitcoin-qt, test_bitcoin and test_bitcoin-qt. i used the rpc test test_locale.py to confirm the 0.10 branch is affected by bad locale environment settings in this build, and that this pr does what it should in another build. the test was not added to this pr, because it executes the boost tests a few times, which seems too expensive and wasteful. </desc> <cmt> initialization: set fallback locale as environment variable </cmt> <cmt> the scope of std::locale::global appears to be smaller than setenv(""lc_all"", ...) and insufficient to fix messed up locale settings for the whole application. </cmt> <cmt> initialization: setup environment before starting tests </cmt> <cmt> the environment is prepared by the main thread to guard against invalid locale settings and to prevent deinitialization issues of boost path, which can result in app crashes. </cmt> <cmt> initialization: setup environment before starting qt tests </cmt> <cmt> the environment is prepared by the main thread to guard against invalid locale settings. </cmt>",fix locale fallback and guard tests against invalid locale settings
3994,"<desc> overview conform range, closedrange, partialrangeupto, partialrangethrough and partialrangefrom to codable. bug report sr-8649 forum thread range conform to codable proposal amendment pr swift evolution pr #915 </desc> <cmt> added codable conformance for range, closedrange, partialrangeupto, partialrangethrough and partialrangefrom </cmt> <cmt> codable cleanup </cmt>",range types conform to codable
3995,"<desc> on windows we can't reference the runtime's builtin.nativeobject value witness table directly from class metadata. instead fill it in at runtime for singleton metadata initialization. do this on all platforms, even though its not needed on linux or darwin, for simplicity. a subsequent windows-specific change will force the use of singleton metadata initialization for all classes, even when the class is otherwise fixed. </desc> <cmt> runtime: some const correctness </cmt> <cmt> runtime: the ivar destroyer can be null </cmt> <cmt> this reverts commit b3a50ea9fdd6fb8cb0cbcba059dcb5b8029db7c4. </cmt> <cmt> runtime: the class metadata relocation function can be null </cmt> <cmt> irgen always just emits a simple implementation that immediately </cmt> <cmt> calls swift_relocateclassmetadata(); so allow the function to be </cmt> <cmt> null in this case to save on code size. </cmt> <cmt> runtime: fill in the value witness table of a class when doing singleton metadata initialization </cmt> <cmt> on windows the image format does not support cross-image absolute </cmt> <cmt> data symbol references. one case where we emit these is in class </cmt> <cmt> metadata, because the value witness table always points at the </cmt> <cmt> value witness table for builtin.nativeobject, defined in the </cmt> <cmt> runtime. </cmt> <cmt> instead, fill in the value witness table at runtime when doing </cmt> <cmt> singleton metadata initialization. </cmt> <cmt> another change that will come later is to force use of singleton </cmt> <cmt> metadata initialization on windows, even if the class is otherwise </cmt> <cmt> completely fixed. </cmt>","class metadata fix for windows [5.0, abi]"
3996,"<desc> i tried to translate the original file into arabic, but there are some blocks that cannot be translated into arabic because the meaning is very different, for the tables, i could not translate them completely </desc> <cmt> add the ds link </cmt> <cmt> finish translating math </cmt> <cmt> add arabic version of the readme file </cmt> <cmt> add arabic version of the readme file </cmt> <cmt> add the arabic readme file link to main readme file </cmt> <cmt> add the arabic readme file link to main readme file </cmt> <cmt> add the arabic readme file link to main readme file </cmt>",add an arabic version of the readme file
3997,"<desc> if not proxying 100-continue, swallow 100-continues. also handle the case of multiple continues headers ""cleanly"" by resetting the stream, rather than crashing.  support for responses with multiple headers, such as 103 (early hint) can be added when there's a need. risk level: medium (on top of a high risk feature) testing: lots and lots of extended integration tests. docs changes: envoyproxy/data-plane-api#492 release notes: 100-continue support already docced. fixes #2563 </desc> <cmt> handling the case of double 100 continue </cmt> <cmt> fixes from #2560 </cmt>",guard against multiple 100 responses
3998,"<desc> fixes #1818 . add sql.simple to sharding config. if this properties is true,in shard module,log will display in sample style. </desc> <cmt> add sql.simple.length config </cmt> <cmt> just async </cmt> <cmt> add sql.simple to sharing config </cmt>",#1818 add sql.simple to sharding config
3999,"<desc> (duplicate of #29970. the commit from that pr was accidentally reverted in master, so here's another pr to bring it back.) gray 200 is not an accessible icon color. we should use the subtext color alias instead. before: after: </desc> <cmt> fix(ui): use gray300 for requestinterface's icon </cmt> <cmt> gray 200 is not an accessible icon color. we should use the subtext color alias instead. </cmt>",use subtext alias for requestinterface's icon
4000,"<desc> while looking for some example code to initialize an op's output shape from a shape provided in an attribute, i found a six-line snippet that is repeated in seven different places. it looks like some copying and pasting has happened in the past. this pull request pulls that shared code into a single function in common_shape_fns.cc. </desc> <cmt> factoring out explicitshape() shape function. </cmt>",pull out repeated shape-related code into shared function
4001,"<desc> since error boundaries are ""atomic"" in fiber, and errors in ""did"" lifecycles and ""willunmount"" only surface after committing, we can end up in a situation where two independent boundaries should receive two independent errors from several components with broken lifecycle hooks. this pr adds support for this and removes some unnecessary recursion. it also ""fixes"" (i'm not sure it's a fix though) a problem: rethrowing errors makes some roots forever skip updates. you can search for ""fixme"": // we need to make sure any future root can get scheduled despite these errors. // currently after throwing, nothing gets scheduled because these fields are set. // fixme: this is likely a wrong fix! it's still better than ignoring updates though. nextscheduledroot = null; lastscheduledroot = null; if i don't those fields, this test fails: var container = document.createelement('div'); expect(() => { reactdom.render(<brokenrender />, container); }).tothrow('hello'); container = document.createelement('div'); expect(() => { reactdom.render(<brokencomponentwillmount />, container); }).tothrow('hello'); container = document.createelement('div'); expect(() => { reactdom.render(<brokencomponentdidmount />, container); }).tothrow('hello'); it fails because second and third requests to render are completely ignored since scheduler thinks they're already scheduled. i don't understand the scheduler well enough to propose a better fix. </desc> <cmt> add more tests for error boundaries </cmt> <cmt> add a failing test for multiple independent boundaries </cmt> <cmt> now that commits are treated as atomic, it is possible that componentdidmount, componentdidupdate, or componentwillunmount threw in multiple places during the commit. we need to make sure we notify all affected boundaries of the first errors in them. </cmt> <cmt> add tests verifying we don't swallow exceptions </cmt> <cmt> handle multiple errors in boundaries </cmt>",error boundaries should handle errors independently
4002,<desc> addresses #20308 this pr ensures histgradientboostingclassifier is compatible with numpydoc. remove histgradientboostingclassifier from docstring_ignore_list. verify that all tests are passing. #dataumbrella sprint </desc> <cmt> remove histgradientboostingclassifier from docstring_ignore_list. </cmt> <cmt> fix numpydocs from histgradientboostingclassifier. </cmt>,doc ensures that histgradientboostingclassifier passes numpydoc validation
4003,"<desc> fix #85462. this will not affect abi since the other variant of the enum is bigger. it may break some code, but that would be very strange: usually people don't continue after the first done (or none for a normal iterator). @rustbot label t-libs a-str a-patterns </desc> <cmt> fix #85462 by adding a marker flag </cmt> <cmt> this will not affect abi since the other variant of the enum is bigger. </cmt> <cmt> it may break some code, but that would be very strange: usually people </cmt> <cmt> don't continue after the first done (or none for a normal iterator). </cmt> <cmt> add test for the fix </cmt> <iss> strsearcher does not behave correctly with empty strings as needle/haystack </iss>",make strsearcher behave correctly on empty needle
4004,<desc> (cherry picked from commit 0f268e7) fixes #44075 ios_user.py ansible version stable-2.5 </desc> <cmt> fix ios_user issues (#44904) </cmt> <cmt> * fix ios_user issues </cmt> <cmt> * modify regex and fix unittests </cmt> <cmt> (cherry picked from commit 0f268e70a1694f4f40e7251fb9488602d2c0a616) </cmt> <cmt> added changelog </cmt>,fix ios_user issue cp in 2.5
4005,"<desc> editor output folder: modules\keyboardmanager\keyboardmanagereditor keyboardmanagereditorlibrary and keyboardmanagerenginelibrary output folder: modules\keyboardmanager what is include in the pr: rebuild projects and verify that files are in place. linked issue: #10127 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> editor output folder </cmt> <cmt> lib output </cmt>",changed editor and libraries output folders
4006,"<desc> this pr fixes the path of the secret key value in the deployment. in the values.yaml file and readme the path of the secret key is auth.secret.key. however, in the deployment the path is secret.key. the pr also updates the redisaddress field in the readme to indicate that rediss:// should be used for ssl connections. none dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> update secret key path in deployment </cmt> <cmt> clarify use of ssl connections in redis address </cmt> <cmt> update chart version </cmt>",fix secret key path in deployment
4007,"<desc> the first commit allows us to run markdown in serial mode again (the remark plugin was not awaiting the cache plugins so it was not properly running in serial). this may also fix a race condition where the same source is parsed twice at the same time, since the cache.set call of the first may not have been completed when the second starts. but that's a very unlike scenario as these caches are more likely to be hit for subsequent builds, not the same session. the remaining commits refactor the code. i can be okay to drop most of them if people feel it's too much. </desc> <cmt> chore(gatsby-transformer-remark): refactor async logic to allow serial mode </cmt> <cmt> refactor the rest while we are here </cmt> <cmt> move addslugtourl out of the inner-inner function </cmt> <cmt> arrow -> nfe </cmt>",wait for cache promises before returning
4008,"<desc> fixes #8337 #8431 this pr cleans up some of the health-related documentation, and adds references to the [health] section of netdata.conf, as requested by chris, and makes consistent how we reference the ip/fqdn of a user's node. i do want to push this node syntax across the docs, but that's for another project. component name health/ </desc> <cmt> fix chris' bug and cleanup </cmt> <cmt> fixes for thiago </cmt> <iss> health configuration interconnections </iss>",improve health docs by adding daemon config to health section and standardizing ip references
4009,<desc> add parameters to module vmware_guest for conversion of disk to thin or thick when vm is cloned or deployed with template @akasurde vmware_guest.py ansible version 2.8-devel </desc> <cmt> update vmware_guest.py </cmt> <cmt> add parameters to module vmware_guest for conversion of disk to thin or thick when vm is cloned or deployed with template </cmt> <cmt> update vmware_guest.py </cmt>,update vmware_guest.py  add option to modify disk type while cloning template
4010,"<desc> additional changes: 36cefa6 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. </desc> <cmt> reland ""make filteringtextinputformatter's filtering selection/composing region agnostic"" </cmt> <cmt> relax assert constraints in fluteringtextinputformatter </cmt>","reland ""make filteringtextinputformatter's filtering selection/composing region agnostic"" #89327"
4011,"<desc> most important is the aml fix for the mode strings, that they changed in latest sdk (top-left corner thumb effect) @holzhaus can provide more info on the libamcodec.so patch. for review: @mrmc @stefansaraev @stane1983 </desc> <cmt> pd#113872:first kodi 15.2 version for amlogic </cmt> <cmt> 1.fixed can not play h265 and 4k with amcodec </cmt> <cmt> 2.fixed video zoom error </cmt> <cmt> 3.merge some patch from old versionx </cmt> <cmt> change-id: i79e333d5ce30ea461f849416df446032d8936d85 </cmt> <cmt> chg: [aml] remove cpufreq hacks </cmt> <cmt> chg: [aml] drop device-specific hacks </cmt> <cmt> fix: [aml] smarter capabilities detection </cmt> <cmt> [amlcodec] remove unreachable code in set_header_info() </cmt> <cmt> [amlcodec] remove unused methods/members from dlllibamcodec/am_private_t </cmt> <cmt> the methods ""h263vld"" and ""decodeble_h263()"" from dlllibamcodec are not </cmt> <cmt> used anymore. the ""h263_decodable"" member from the am_private_t struct </cmt> <cmt> is also obsolete now. although the struct member ""flv_flag"" gets </cmt> <cmt> assigned, is never read, so we remove it, too. </cmt> <cmt> [amlcodec] remove dependency on amffmpeg and use libavutil instead </cmt> <cmt> [amlcodec] use libamcodec.so if libamplayer.so is missing </cmt> <cmt> some linux distibutions like openelec and archlinuxarm ship </cmt> <cmt> libamcodec.so instead of libamplayer.so, which is included in the latest </cmt> <cmt> buildroot package (2015-01-20-4a5990f135) from amlogic: </cmt> <cmt>  </cmt> <cmt> (buildroot/package/multimedia/aml_libs/src/amcodec/makefile, line 26) </cmt> <cmt> thus, users of these distros will eventually run into this issue: </cmt> <cmt> error: unable to load libamplayer.so, reason: libamplayer.so: cannot </cmt> <cmt> open shared object file: no such file or directory </cmt> <cmt> this commit fixes that by checking if libamplayer.so can be loaded, and </cmt> <cmt> if not, we'll try to use libamcodec.so instead. </cmt>",various aml fixes and cleanups
4012,"<desc> this pr is the refactoring mentioned here: #29135 tbc the clients (amazonec2 and storage) were already built lazily (and cached and reused) for the afore mentioned plugins. this is the refactoring of that logic. the 'client settings' and the 'client instance' always had to go together which made the code bug prone, i.e. when the settings changed you had to make sure the client was destroyed so that it was lazily rebuilt using the new settings. for the discovery-ec2 and repository-gcs plugins, it replaces the duality '(map) client settings' - '(map) client instance' with a lazy client supplier. the supplier encapsulates the settings required to build the client. the lazy supplier caches the returned value once computed. this factors out the memoize supplier behavior (e.g. elasticsearch/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/internalawss3service.java line 75 918827c public amazons3reference client(string clientname) { ) in a lazy instance. this change was not required for the repository-azure plugin as it does not caches client instances (hence only the settings are stored) because client instances are not thread-safe. this change cannot be applied to the repository-s3 plugin, until the feature branch reload-secure-store-action is merged, because this plugin explicitly requires the settings to be stored so that they can be overriden from the cluster state ( elasticsearch/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/s3repository.java line 223 918827c void overridecredentialsfromclusterstate(awss3service awsservice) { ), see also: 17d0155 originally, the goal for this refactoring was much more ambitious: to have an abstract component that creates and caches clients for all plugins that have clients using secure settings. but this is currently not possible, as the plugin requirements are quite diverse, eg: discovery-ec2 and repository-s3 have closeable, thread-safe clients, but the repository-azure clients are not thread-safe. repository-gcs clients are thread-safe but not closeable. the repository plugins use a dictionary of clients, but the discovery-ec2 plugin only uses one client. relates #29135 </desc> <cmt> added lazy </cmt> <cmt> gcs removed double map (config + clients) </cmt> <cmt> ec2 plugin lazy client ditching cached settings </cmt>",ec2 and gcs plugins build client lazily
4013,"<desc> this adds the following new functionality: envvar $systemd_in_initrd can be used to test generator behaviour in the real system allow{suspend,hibernation,suspendthenhibernate,hybridsleep}=yes|no can be used to pick what does are advertised 'noresume' on the kernel command line can be used to disable resuming (only to be used in rare circumstances, for example when the filesystem was modified using a different root partition and the resume image is stale). the longer-term goal is to autodetect the resume partition. but that is a more complicated problem and cannot be solved in all cases. so even if we have auto-detection, we still need to disable hibernation in cases where we cannot auto-detect the resume partition. also, people want to disable hibernation if it does not work on their hardware. i'll submit the autodection part later. </desc> <cmt> bootspec: fix include lines </cmt> <cmt> list all files we use definitions from. </cmt> <cmt> bootspec: rename ""filename"" field to ""id"" </cmt> <cmt> this follows the renaming done a few commits earlier too systemd-boot </cmt> <cmt> itself. </cmt> <cmt> also, let's show the id, since it's useful. </cmt>",switches to disable hibernation and/or resuming
4014,"<desc> add a note about custom cuda paths in windows guide, like in linux one. encourage users to pass boost paths via cmake options instead of environment variables to deal with cmp0074. i tested on windows 10 with visual studio 2017 the following cases: cmake 3.14.1 and boost 1.69.0 (after adding cmp0074); cmake 3.11.0 and boost 1.65.1 (before adding cmp0074). they worked fine. closed #2081. refer to #2081 (comment), #1632, </desc> <cmt> updated installation guide </cmt> <cmt> updated python installation guide </cmt> <cmt> added note about opencl path to windows section </cmt> <cmt> added space before path in message </cmt> <cmt> minor correction for option description in python installation guide </cmt> <iss> error: please install cmake first </iss>",updated the part about boost in installation guide
4015,"<desc> description: the set_config_paramter failed for devices having an int in the configuration option list. while debugging this, i also came accross another bug, that button value types were not set, and generated a traceback. this is also fixed in this pr. related issue (if applicable): fixes #12419 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: </desc> <cmt> cast list and bool options to str </cmt> <cmt> add button options to str </cmt> <cmt> add type_button to value types </cmt> <cmt> adjust comparison </cmt> <cmt> remove logging </cmt> <cmt> remove empty line </cmt> <cmt> update tests </cmt> <iss> zwave node configuration options broken? </iss>",zwave set_config_parameter failed when config list contained int
4016,"<desc> this fixes a bug that only became apparent when wasm2js started to emit more interesting js code, which confused the pass. historically the pass was just used on asm.js globals, which are trivial, and it was reused for wasm2js, but as wasm2js output changed we ran into the issue. specifically, the old code made some assumptions about fastcomp output like that the first item shouldn't be minified, and that we can ignore some things and not others; those hacks are now all removed. the new design is cleaner and more general, but still not 100% fully general, see the corner case it doesn't handle in the comment. it may be good to handle that to prevent future bugs, but it would add significant complexity here. adding just an assert might be better, but that would still need the complexity to reason about scopes. unintentionally, this cleaner design can also do better at minifying, improving wasm2js hello world's total size by over 10% (!) this removes the old fastcomp-style handling in minifyglobals, with the testcase for that. the new pass just focuses on wasm2js's output format. once this lands we can re-enable minification in binaryen.js ci, which is disabled atm. </desc> <cmt> fix? [ci skip] </cmt> <cmt> update tests </cmt> <cmt> work [ci skip] </cmt> <cmt> update tests </cmt> <cmt> comment </cmt>",rewrite minifyglobals js optimizer pass
4017,<desc> i have followed (at least) the pr section of the contributing guide. as per #14427 (comment) closes #14427 </desc> <cmt> fix 1 new autofill error occurance. </cmt> <cmt> completed fix </cmt> <iss> [textfield] handle chrome autofill </iss>,fix remaining issues with chrome autofill
4018,"<desc> some small improvements to texteditor. set cut and copy actions to disabled on init and enable them first when a selection is made. this is mostly an indicator to the user that it's not possible to use these actions with nothing selected. previously they would simply not do anything when clicked. reset editor width when disabling preview mode. when disabling preview mode after adjusting the splitter the editor would still be fixed width and therefore not fill out the window. this is one of the solutions that @trflynn89 proposed in #7462. i believe it's an ok fix in this particular case, but with splitters containing more elements his other solution might be better suited. fixes #7462 don't discard changes if user closes save dialog. this breaks out the save-if-modified-logic into it's own function, getting rid of some code duplication and makes sure that the  logic in 9720261 also applies when the user aborts a save dialog on new/open and not just on exit. dropping this one since it was fixed in 928364e. </desc> <cmt> libgui/texteditor: set cut and copy actions to disabled on init </cmt> <cmt> we can presume that there is nothing to cut or copy on init since </cmt> <cmt> nothing is selected yet. </cmt> <cmt> texteditor: reset editor width when disabling preview mode </cmt> <cmt> when disabling preview mode, reset the fixed width of m_editor so that </cmt> <cmt> it fills out the window again even after resizing the splitter. </cmt> <iss> texteditor: ""no preview"" mode does not hide preview panel </iss>",small fixes when asking to save & disabling preview mode
4019,"<desc> when the viewport is moved to the ""virtual bottom"" of the buffer (via the movetobottom method), it is important that the horizontal viewport offset be left as it is, otherwise that can result in some undesirable side effects. since the vt coordinate system is relative to the top of the viewport, many vt operations call the movetobottom method to make sure the viewport is correctly positioned before proceeding. there is no need for the horizontal position to be adjusted, though, since the x coordinates are not constrained by the viewport, but are instead relative to the underlying buffer. setting the viewport x coordinate to 0 in movetobottom (as we were previously doing) could result in the cursor being pushed off screen. and if the operation itself was moving the cursor, that would then trigger another viewport move to bring the cursor back into view. these conflicting movements meant the viewport was always forced as far left as possible, and could also result in cursor ""droppings"" as the cursor lost track of where it had been. i've now fixed this by updating the getvirtualviewport method to match the horizontal offset of the active viewport, instead of having the x coordinate hardcoded to 0. i've manually confirmed that this fixes the cursor ""droppings"" test case reported in issue #8213. i've also added a screen buffer test that makes sure the movetobottom method is working as expected, and not changing the horizontal viewport offset when it moves down. closes #8213 </desc> <cmt> retain the horizontal viewport offset in the virtual viewport. </cmt> <cmt> add test to confirm x offset isn't updated by movetobottom. </cmt> <iss> more cursor droppings </iss>",retain horizontal viewport offset when moving to bottom
4020,<desc> ability to customize webview2 version needed in order to add access to the winui webview2 control. added  option to experimental features. microsoft reviewers: open in codeflow </desc> <cmt> add webview2version to experimental props </cmt> <cmt> change files </cmt>,add webview2 version customization to experimental features
4021,<desc> this prevents failing to write to these clusters from failing the entire write operation. </desc> <cmt> feels bad </cmt> <cmt> it's not as bad as it looks </cmt> <cmt> test suppression wrapper </cmt> <cmt> explain suppressionwrapper </cmt> <cmt> explain return type of get_cluster </cmt>,enable marking clusters as non-durable for writes
4022,"<desc> inspired by the direction @bjnath took in the rewrite of the glossary page in gh-16996, i moved many of the numpy/doc/*.py informative documents into their *.rst counterparts. i used git grep doc.xxx to find places the page was referenced, copy-pasted the content of the page as-is into its counterpart git rm numpy/doc.xxx.py removed it from test_public_apii. in the second commit, which was suprisingly small, i cleaned up a few build problems with the resulting docs. i did not remove numpy/doc/consts.py nor numpy/doc/ufuncs.py since the former is code with docstrings for constants, and the latter should be merged with the content in doc/source/reference/ufuncs.rst. once this goes in, it will be easier to review the content of gh-16996. </desc> <cmt> doc: redistribute docstring-only content from numpy/doc </cmt> <cmt> doc: post-transition clean-up </cmt>",move informational files from numpy.doc..py to their .rst counterparts
4023,"<desc> this pr adds example code for fsner (few-shot named entity recognition) using huggingface's transformers library. only prediction/inference code is provided, training code will be provided very soon. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link #13155 documentation guidelines, and here are tips on formatting docstrings. @nielsrogge @lysandrejik </desc> <cmt> add example use of few-shot named entity recognition model in research_projects folder. </cmt> <cmt> apply suggestions from code review </cmt> <cmt> update fsner example readme.md. </cmt> <cmt> - change wrong import fsnertokenizerwrapper to fsnertokenizerutils in the example code </cmt> <cmt> - add a link to the model identifier </cmt> <cmt> update examples/research_projects/fsner/src/fsner/model.py </cmt> <cmt> fix spelling mistake in the default parameter of pretrained model name. </cmt> <cmt> add example use of few-shot named entity recognition model in research_projects folder. </cmt> <cmt> apply suggestions from code review </cmt> <cmt> update fsner example readme.md. </cmt> <cmt> - change wrong import fsnertokenizerwrapper to fsnertokenizerutils in the example code </cmt> <cmt> - add a link to the model identifier </cmt> <cmt> update examples/research_projects/fsner/src/fsner/model.py </cmt> <cmt> fix spelling mistake in the default parameter of pretrained model name. </cmt> <cmt> run checking/fixing examples/flax/language-modeling/run_clm_flax.py examples/flax/question-answering/run_qa.py examples/flax/question-answering/utils_qa.py examples/flax/token-classification/run_flax_ner.py examples/legacy/multiple_choice/utils_multiple_choice.py examples/legacy/seq2seq/seq2seq_trainer.py examples/legacy/token-classification/utils_ner.py examples/pytorch/image-classification/run_image_classification.py examples/pytorch/language-modeling/run_clm.py examples/pytorch/language-modeling/run_clm_no_trainer.py examples/pytorch/language-modeling/run_mlm.py examples/pytorch/language-modeling/run_mlm_no_trainer.py examples/pytorch/language-modeling/run_plm.py examples/pytorch/multiple-choice/run_swag.py examples/pytorch/multiple-choice/run_swag_no_trainer.py examples/pytorch/question-answering/run_qa.py examples/pytorch/question-answering/run_qa_beam_search.py examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py examples/pytorch/question-answering/run_qa_no_trainer.py examples/pytorch/summarization/run_summarization.py examples/pytorch/summarization/run_summarization_no_trainer.py examples/pytorch/test_examples.py examples/pytorch/text-classification/run_glue.py examples/pytorch/text-classification/run_glue_no_trainer.py examples/pytorch/text-classification/run_xnli.py examples/pytorch/token-classification/run_ner.py examples/pytorch/token-classification/run_ner_no_trainer.py examples/pytorch/translation/run_translation.py examples/pytorch/translation/run_translation_no_trainer.py examples/research_projects/adversarial/utils_hans.py examples/research_projects/distillation/grouped_batch_sampler.py examples/research_projects/fsner/setup.py examples/research_projects/fsner/src/fsner/__init__.py examples/research_projects/fsner/src/fsner/model.py examples/research_projects/fsner/src/fsner/tokenizer_utils.py examples/research_projects/jax-projects/big_bird/evaluate.py examples/research_projects/jax-projects/hybrid_clip/run_hybrid_clip.py examples/tensorflow/language-modeling/run_clm.py examples/tensorflow/multiple-choice/run_swag.py examples/tensorflow/question-answering/run_qa.py examples/tensorflow/summarization/run_summarization.py examples/tensorflow/text-classification/run_glue.py examples/tensorflow/translation/run_translation.py src/transformers/__init__.py src/transformers/commands/add_new_model.py src/transformers/configuration_utils.py src/transformers/convert_slow_tokenizer.py src/transformers/data/__init__.py src/transformers/data/data_collator.py src/transformers/data/datasets/glue.py src/transformers/data/datasets/language_modeling.py src/transformers/data/datasets/squad.py src/transformers/deepspeed.py src/transformers/dependency_versions_table.py src/transformers/feature_extraction_sequence_utils.py src/transformers/file_utils.py src/transformers/generation_flax_utils.py src/transformers/generation_logits_process.py src/transformers/generation_tf_utils.py src/transformers/generation_utils.py src/transformers/integrations.py src/transformers/modelcard.py src/transformers/modeling_flax_utils.py src/transformers/modeling_outputs.py src/transformers/modeling_tf_utils.py src/transformers/modeling_utils.py src/transformers/models/__init__.py src/transformers/models/albert/__init__.py src/transformers/models/albert/modeling_albert.py src/transformers/models/albert/modeling_flax_albert.py src/transformers/models/albert/tokenization_albert_fast.py src/transformers/models/auto/__init__.py src/transformers/models/auto/auto_factory.py src/transformers/models/auto/configuration_auto.py src/transformers/models/auto/dynamic.py src/transformers/models/auto/feature_extraction_auto.py src/transformers/models/auto/modeling_auto.py src/transformers/models/auto/modeling_flax_auto.py src/transformers/models/auto/modeling_tf_auto.py src/transformers/models/auto/tokenization_auto.py src/transformers/models/bart/configuration_bart.py src/transformers/models/bart/modeling_bart.py src/transformers/models/bart/modeling_flax_bart.py src/transformers/models/bart/modeling_tf_bart.py src/transformers/models/barthez/tokenization_barthez_fast.py src/transformers/models/beit/__init__.py src/transformers/models/beit/configuration_beit.py src/transformers/models/beit/modeling_beit.py src/transformers/models/beit/modeling_flax_beit.py src/transformers/models/bert/configuration_bert.py src/transformers/models/bert/modeling_bert.py src/transformers/models/bert/modeling_flax_bert.py src/transformers/models/bert_generation/configuration_bert_generation.py src/transformers/models/bert_generation/modeling_bert_generation.py src/transformers/models/big_bird/configuration_big_bird.py src/transformers/models/big_bird/modeling_big_bird.py src/transformers/models/big_bird/modeling_flax_big_bird.py src/transformers/models/big_bird/tokenization_big_bird_fast.py src/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py src/transformers/models/blenderbot/configuration_blenderbot.py src/transformers/models/blenderbot/modeling_blenderbot.py src/transformers/models/blenderbot/modeling_tf_blenderbot.py src/transformers/models/blenderbot_small/configuration_blenderbot_small.py src/transformers/models/blenderbot_small/modeling_blenderbot_small.py src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py src/transformers/models/byt5/tokenization_byt5.py src/transformers/models/camembert/tokenization_camembert_fast.py src/transformers/models/canine/configuration_canine.py src/transformers/models/canine/modeling_canine.py src/transformers/models/clip/configuration_clip.py src/transformers/models/clip/convert_clip_original_pytorch_to_hf.py src/transformers/models/clip/modeling_clip.py src/transformers/models/clip/modeling_flax_clip.py src/transformers/models/clip/tokenization_clip.py src/transformers/models/convbert/modeling_convbert.py src/transformers/models/ctrl/configuration_ctrl.py src/transformers/models/deberta/modeling_tf_deberta.py src/transformers/models/deberta_v2/__init__.py src/transformers/models/deberta_v2/modeling_deberta_v2.py src/transformers/models/deberta_v2/modeling_tf_deberta_v2.py src/transformers/models/deit/configuration_deit.py src/transformers/models/deit/modeling_deit.py src/transformers/models/detr/configuration_detr.py src/transformers/models/detr/modeling_detr.py src/transformers/models/distilbert/__init__.py src/transformers/models/distilbert/configuration_distilbert.py src/transformers/models/distilbert/modeling_distilbert.py src/transformers/models/distilbert/modeling_flax_distilbert.py src/transformers/models/dpr/configuration_dpr.py src/transformers/models/dpr/modeling_dpr.py src/transformers/models/electra/modeling_electra.py src/transformers/models/electra/modeling_flax_electra.py src/transformers/models/encoder_decoder/__init__.py src/transformers/models/encoder_decoder/modeling_encoder_decoder.py src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py src/transformers/models/flaubert/configuration_flaubert.py src/transformers/models/flaubert/modeling_flaubert.py src/transformers/models/fnet/__init__.py src/transformers/models/fnet/configuration_fnet.py src/transformers/models/fnet/convert_fnet_original_flax_checkpoint_to_pytorch.py src/transformers/models/fnet/modeling_fnet.py src/transformers/models/fnet/tokenization_fnet.py src/transformers/models/fnet/tokenization_fnet_fast.py src/transformers/models/fsmt/configuration_fsmt.py src/transformers/models/fsmt/modeling_fsmt.py src/transformers/models/funnel/configuration_funnel.py src/transformers/models/gpt2/__init__.py src/transformers/models/gpt2/configuration_gpt2.py src/transformers/models/gpt2/modeling_flax_gpt2.py src/transformers/models/gpt2/modeling_gpt2.py src/transformers/models/gpt2/modeling_tf_gpt2.py src/transformers/models/gpt_neo/configuration_gpt_neo.py src/transformers/models/gpt_neo/modeling_gpt_neo.py src/transformers/models/gptj/__init__.py src/transformers/models/gptj/configuration_gptj.py src/transformers/models/gptj/modeling_gptj.py src/transformers/models/herbert/tokenization_herbert_fast.py src/transformers/models/hubert/__init__.py src/transformers/models/hubert/configuration_hubert.py src/transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py src/transformers/models/hubert/modeling_hubert.py src/transformers/models/hubert/modeling_tf_hubert.py src/transformers/models/ibert/modeling_ibert.py src/transformers/models/layoutlm/__init__.py src/transformers/models/layoutlm/configuration_layoutlm.py src/transformers/models/layoutlm/modeling_layoutlm.py src/transformers/models/layoutlmv2/__init__.py src/transformers/models/layoutlmv2/configuration_layoutlmv2.py src/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py src/transformers/models/layoutlmv2/modeling_layoutlmv2.py src/transformers/models/layoutlmv2/processing_layoutlmv2.py src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py src/transformers/models/led/configuration_led.py src/transformers/models/led/modeling_led.py src/transformers/models/longformer/modeling_longformer.py src/transformers/models/luke/configuration_luke.py src/transformers/models/luke/modeling_luke.py src/transformers/models/luke/tokenization_luke.py src/transformers/models/lxmert/configuration_lxmert.py src/transformers/models/m2m_100/configuration_m2m_100.py src/transformers/models/m2m_100/modeling_m2m_100.py src/transformers/models/m2m_100/tokenization_m2m_100.py src/transformers/models/marian/configuration_marian.py src/transformers/models/marian/modeling_flax_marian.py src/transformers/models/marian/modeling_marian.py src/transformers/models/marian/modeling_tf_marian.py src/transformers/models/mbart/configuration_mbart.py src/transformers/models/mbart/modeling_flax_mbart.py src/transformers/models/mbart/modeling_mbart.py src/transformers/models/mbart/tokenization_mbart.py src/transformers/models/mbart/tokenization_mbart_fast.py src/transformers/models/mbart50/tokenization_mbart50.py src/transformers/models/mbart50/tokenization_mbart50_fast.py src/transformers/models/megatron_bert/configuration_megatron_bert.py src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py src/transformers/models/megatron_bert/modeling_megatron_bert.py src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py src/transformers/models/openai/configuration_openai.py src/transformers/models/pegasus/__init__.py src/transformers/models/pegasus/configuration_pegasus.py src/transformers/models/pegasus/modeling_flax_pegasus.py src/transformers/models/pegasus/modeling_pegasus.py src/transformers/models/pegasus/modeling_tf_pegasus.py src/transformers/models/pegasus/tokenization_pegasus_fast.py src/transformers/models/prophetnet/configuration_prophetnet.py src/transformers/models/prophetnet/modeling_prophetnet.py src/transformers/models/rag/modeling_rag.py src/transformers/models/rag/modeling_tf_rag.py src/transformers/models/reformer/configuration_reformer.py src/transformers/models/reformer/tokenization_reformer_fast.py src/transformers/models/rembert/configuration_rembert.py src/transformers/models/rembert/modeling_rembert.py src/transformers/models/rembert/tokenization_rembert_fast.py src/transformers/models/roberta/modeling_flax_roberta.py src/transformers/models/roberta/modeling_roberta.py src/transformers/models/roberta/modeling_tf_roberta.py src/transformers/models/roformer/configuration_roformer.py src/transformers/models/roformer/modeling_roformer.py src/transformers/models/speech_encoder_decoder/__init__.py src/transformers/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py src/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py src/transformers/models/speech_to_text/configuration_speech_to_text.py src/transformers/models/speech_to_text/feature_extraction_speech_to_text.py src/transformers/models/speech_to_text/modeling_speech_to_text.py src/transformers/models/speech_to_text_2/__init__.py src/transformers/models/speech_to_text_2/configuration_speech_to_text_2.py src/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py src/transformers/models/speech_to_text_2/processing_speech_to_text_2.py src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py src/transformers/models/splinter/configuration_splinter.py src/transformers/models/splinter/modeling_splinter.py src/transformers/models/t5/configuration_t5.py src/transformers/models/t5/modeling_flax_t5.py src/transformers/models/t5/modeling_t5.py src/transformers/models/t5/modeling_tf_t5.py src/transformers/models/t5/tokenization_t5_fast.py src/transformers/models/tapas/__init__.py src/transformers/models/tapas/configuration_tapas.py src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py src/transformers/models/tapas/modeling_tapas.py src/transformers/models/tapas/tokenization_tapas.py src/transformers/models/transfo_xl/configuration_transfo_xl.py src/transformers/models/visual_bert/modeling_visual_bert.py src/transformers/models/vit/configuration_vit.py src/transformers/models/vit/convert_dino_to_pytorch.py src/transformers/models/vit/modeling_flax_vit.py src/transformers/models/vit/modeling_vit.py src/transformers/models/wav2vec2/__init__.py src/transformers/models/wav2vec2/configuration_wav2vec2.py src/transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py src/transformers/models/wav2vec2/modeling_flax_wav2vec2.py src/transformers/models/wav2vec2/modeling_wav2vec2.py src/transformers/models/wav2vec2/tokenization_wav2vec2.py src/transformers/models/xlm/configuration_xlm.py src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py src/transformers/models/xlnet/configuration_xlnet.py src/transformers/models/xlnet/tokenization_xlnet_fast.py src/transformers/onnx/convert.py src/transformers/onnx/features.py src/transformers/optimization.py src/transformers/pipelines/__init__.py src/transformers/pipelines/audio_classification.py src/transformers/pipelines/automatic_speech_recognition.py src/transformers/pipelines/base.py src/transformers/pipelines/conversational.py src/transformers/pipelines/feature_extraction.py src/transformers/pipelines/fill_mask.py src/transformers/pipelines/image_classification.py src/transformers/pipelines/object_detection.py src/transformers/pipelines/question_answering.py src/transformers/pipelines/table_question_answering.py src/transformers/pipelines/text2text_generation.py src/transformers/pipelines/text_classification.py src/transformers/pipelines/text_generation.py src/transformers/pipelines/token_classification.py src/transformers/pipelines/zero_shot_classification.py src/transformers/testing_utils.py src/transformers/tokenization_utils.py src/transformers/tokenization_utils_base.py src/transformers/tokenization_utils_fast.py src/transformers/trainer.py src/transformers/trainer_callback.py src/transformers/trainer_pt_utils.py src/transformers/trainer_seq2seq.py src/transformers/trainer_utils.py src/transformers/training_args.py src/transformers/training_args_seq2seq.py src/transformers/utils/dummy_detectron2_objects.py src/transformers/utils/dummy_flax_objects.py src/transformers/utils/dummy_pt_objects.py src/transformers/utils/dummy_tf_objects.py src/transformers/utils/dummy_tokenizers_objects.py src/transformers/utils/dummy_vision_objects.py tests/deepspeed/test_deepspeed.py tests/sagemaker/conftest.py tests/sagemaker/test_multi_node_data_parallel.py tests/test_configuration_auto.py tests/test_configuration_common.py tests/test_data_collator.py tests/test_feature_extraction_auto.py tests/test_feature_extraction_layoutlmv2.py tests/test_feature_extraction_speech_to_text.py tests/test_feature_extraction_wav2vec2.py tests/test_file_utils.py tests/test_modeling_auto.py tests/test_modeling_bart.py tests/test_modeling_beit.py tests/test_modeling_bert.py tests/test_modeling_clip.py tests/test_modeling_common.py tests/test_modeling_convbert.py tests/test_modeling_deit.py tests/test_modeling_distilbert.py tests/test_modeling_encoder_decoder.py tests/test_modeling_flaubert.py tests/test_modeling_flax_albert.py tests/test_modeling_flax_bart.py tests/test_modeling_flax_beit.py tests/test_modeling_flax_distilbert.py tests/test_modeling_flax_encoder_decoder.py tests/test_modeling_flax_gpt2.py tests/test_modeling_flax_gpt_neo.py tests/test_modeling_flax_mt5.py tests/test_modeling_flax_pegasus.py tests/test_modeling_fnet.py tests/test_modeling_gpt2.py tests/test_modeling_gpt_neo.py tests/test_modeling_gptj.py tests/test_modeling_hubert.py tests/test_modeling_layoutlmv2.py tests/test_modeling_pegasus.py tests/test_modeling_rag.py tests/test_modeling_reformer.py tests/test_modeling_speech_encoder_decoder.py tests/test_modeling_speech_to_text.py tests/test_modeling_speech_to_text_2.py tests/test_modeling_tf_auto.py tests/test_modeling_tf_deberta_v2.py tests/test_modeling_tf_hubert.py tests/test_modeling_tf_pytorch.py tests/test_modeling_tf_wav2vec2.py tests/test_modeling_wav2vec2.py tests/test_onnx_v2.py tests/test_pipelines_audio_classification.py tests/test_pipelines_automatic_speech_recognition.py tests/test_pipelines_common.py tests/test_pipelines_conversational.py tests/test_pipelines_feature_extraction.py tests/test_pipelines_fill_mask.py tests/test_pipelines_image_classification.py tests/test_pipelines_object_detection.py tests/test_pipelines_question_answering.py tests/test_pipelines_summarization.py tests/test_pipelines_table_question_answering.py tests/test_pipelines_text2text_generation.py tests/test_pipelines_text_classification.py tests/test_pipelines_text_generation.py tests/test_pipelines_token_classification.py tests/test_pipelines_translation.py tests/test_pipelines_zero_shot.py tests/test_processor_layoutlmv2.py tests/test_processor_wav2vec2.py tests/test_sequence_feature_extraction_common.py tests/test_tokenization_auto.py tests/test_tokenization_byt5.py tests/test_tokenization_canine.py tests/test_tokenization_common.py tests/test_tokenization_fnet.py tests/test_tokenization_layoutlmv2.py tests/test_tokenization_luke.py tests/test_tokenization_mbart.py tests/test_tokenization_mbart50.py tests/test_tokenization_speech_to_text_2.py tests/test_tokenization_t5.py tests/test_tokenization_tapas.py tests/test_tokenization_xlm_roberta.py tests/test_trainer.py tests/test_trainer_distributed.py tests/test_trainer_tpu.py tests/test_utils_check_copies.py utils/check_copies.py utils/check_repo.py utils/notification_service.py utils/release.py utils/tests_fetcher.py </cmt> <cmt> python utils/custom_init_isort.py </cmt> <cmt> python utils/style_doc.py src/transformers docs/source --max_len 119 </cmt> <cmt> running deps_table_update </cmt> <cmt> updating src/transformers/dependency_versions_table.py </cmt> <cmt> python utils/check_copies.py </cmt> <cmt> python utils/check_table.py </cmt> <cmt> python utils/check_dummies.py </cmt> <cmt> python utils/check_repo.py </cmt> <cmt> checking all models are public. </cmt> <cmt> checking all models are properly tested. </cmt> <cmt> checking all objects are properly documented. </cmt> <cmt> checking all models are in at least one auto class. </cmt> <cmt> python utils/check_inits.py </cmt> <cmt> python utils/tests_fetcher.py --sanity_check and fix suggested changes. </cmt> <cmt> run black examples tests src utils </cmt> <cmt> isort examples tests src utils </cmt> <cmt> skipped 1 files </cmt> <cmt> make autogenerate_code </cmt> <cmt> make[1]: entering directory '/mnt/c/users/admin/desktop/home/projects/transformers' </cmt> <cmt> running deps_table_update </cmt> <cmt> updating src/transformers/dependency_versions_table.py </cmt> <cmt> make[1]: leaving directory '/mnt/c/users/admin/desktop/home/projects/transformers' </cmt> <cmt> make extra_style_checks </cmt> <cmt> make[1]: entering directory '/mnt/c/users/admin/desktop/home/projects/transformers' </cmt> <cmt> python utils/custom_init_isort.py </cmt> <cmt> python utils/style_doc.py src/transformers docs/source --max_len 119 </cmt> <cmt> make[1]: leaving directory '/mnt/c/users/admin/desktop/home/projects/transformers' for reformatting code. </cmt> <cmt> add installation dependencies for examples/research_projects/fsner. </cmt>",add fsner example in research_projects
4024,<desc> description: add 'priority' attribute to set the priority of the hyperion remote instance. pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3751 example entry for configuration.yaml (if applicable): light: - platform: hyperion host: 127.0.0.1 priority: 128 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass </desc> <cmt> remove async_update (#9997) </cmt> <cmt> light.hyperion: add priority attribute </cmt> <cmt> allows to set the priority of the hyperion remote instance. </cmt>,add priority attribute for hyperion
4025,"<desc> change types to have latest api in  p.s: current readme wasn't updated after keys() method removal, pr already exist to fix that: jonschlinkert/parse-git-config#11 and there is only expandkeys() method left: </desc> <cmt> sync latest parse-git-config api changes </cmt> <cmt> parse-git-config - fix tabulation </cmt>",sync with latest api changes
4026,<desc> related issue: 55f98ce#r51139097 import oimo via namespace to make the oimophysics.js helper work also in the examples/js world since the library is exposed as window.oimo in non-module script. </desc> <cmt> import oimo using namespace </cmt> <cmt> esline: add oimo in globals </cmt>,import oimo using its namespace
4027,"<desc> this means you can set test_args on the command line, in a .properties config for a jenkins job, etc, to toggle gated features. for example: test_args='--feature-gates=dynamickubeletconfig=true' / this change is </desc> <cmt> feature-gates flag plumbing for node e2e tests </cmt> <cmt> this gives the node e2e test binary a --feature-gates flag that populates a </cmt> <cmt> featuregates field on the test context. the value of this field is forwarded </cmt> <cmt> to the kubelet's --feature-gates flag and is also used to populate the global </cmt> <cmt> defaultfeaturegate object so that statically-linked components see the same </cmt> <cmt> feature gate settings as provided via the flag. </cmt> <cmt> this means that you can set feature gates via the test_args environment </cmt> <cmt> variable when running node e2e tests. for example: </cmt> <cmt> test_args='--feature-gates=dynamickubeletconfig=true' </cmt> <cmt> enable dynamic kubelet configuration for node e2e jenkins serial tests </cmt> <cmt> this commit enables the dynamic kubelet configuration feature for the </cmt> <cmt> node e2e jenkins serial tests, which is where the test for dynamic kubelet </cmt> <cmt> configuration currently runs. </cmt>",plumb --feature-gates from test_args to components in node e2e tests
4028,"<desc> the user-agent format is ""tornado\{tornado_version}"". if self.request.user_agent isn't set and self.request.headers has no user-agent in it's keys the default user-agent is added. fixes: #2702 </desc> <cmt> getting changes from tornado december 9, 2019 </cmt> <cmt> added default user-agent to the simple http client if not provided. </cmt> <cmt> the user-agent format is ""tornado\{tornado_version}"". </cmt> <cmt> if self.request.user_agent isn't set and self.request.headers has </cmt> <cmt> no user-agent in it's keys the default user-agent is added. </cmt> <cmt> fixes: #2702 </cmt> <cmt> checked request headers using it's get method. </cmt> <cmt> fixes: #2702 </cmt> <iss> provide default user-agent in simpleasynchttpclient </iss>",provided default user-agent to simpleasynchttpclient if not provided.
4029,<desc> issue: #16763 #14612 #15246 #15855 not solve but provide a solution / or related for #15261 #15351 add styles and stylepreprocessoroptions options storybook angular builder allow the angular 12.2.x and >=13  project to set styles config without using browsertarget in order to rely on another builder's config. very useful in the case of a library where you don't have an application but you want to configure styles in storybook like an app </desc> <cmt> fix(angular): missing remove oneof in builder schema </cmt> <cmt> this onof is no more necessary </cmt> <cmt> feat(angular): add styles and stylepreprocessoroptions to add dedicated styles config </cmt> <cmt> allow the angular project to set styles config without using browsertarget in order to rely on another builder's config. </cmt> <cmt> very useful in the case of a library where you don't have an application but you want to configure styles in storybook like an app </cmt>,add styles and stylepreprocessoroptions to angular builder
4030,"<desc> i hereby agree to the terms of the cla available at:  fix infinite non joined block stream in partial_merge_join close #26325 </desc> <cmt> cleanup joiningtransform::readexecute </cmt> <cmt> fix infine non joined block stream in merge join </cmt> <iss> infinite loop in ""partial merge join"". </iss>",fix infinite non joined block stream in merge join
4031,<desc> this pull request moves the logic from os::make_absolute() into the path module and fixes path joining for windows.  it does this by adding an unsafe_join() function that implements the operating system's path joining semantics. additionally it also adds an is_restricted() method to the trait which will return true if the path points to a windows device file. </desc> <cmt> refactored make_absolute into functionality on the path </cmt> <cmt> improved windows path handling support </cmt> <cmt> added is_restricted() to path </cmt>,os::make_absolute() and windowspath refactoring and fixes
4032,<desc> create step 1 database ui connection flow to allow users to pick the type of engine before entering credentials add on to #14881  includes db migration (follow approval process in sip-59) </desc> <cmt> poc picker for db selection </cmt> <cmt> working select </cmt> <cmt> setup is loading for available dbs and step1 view </cmt> <cmt> fix on close </cmt> <cmt> update on fetch </cmt>,allow users to pick engine
4033,"<desc> the problem was that the library was assuming that fs::exists() would return false for directories, which is true for spiffs, but not for littlefs. i changed the implementation to be compatible with both. i don't like using fs.open(), but i couldn't find any better way to check if something is a directory or a file. if there is such a thing, please point me in the right direction and i will be happy to use that instead. </desc> <cmt> remove trailing whitespace </cmt> <cmt> improve ""is file"" check for littlefs support </cmt> <cmt> the previous implementation was based on a quirk of spiffs (that exists </cmt> <cmt> returns false for directories) so it wouldn't work with littlefs. this </cmt> <cmt> implementation works with both. </cmt>",add littlefs support to esp8266webserver.servestatic()
4034,"<desc> jenkins-27607 subsumes #1595: adds a test. @reviewbybees </desc> <cmt> fix mime tipe with jsonp </cmt> <cmt> using </cmt> <cmt> refused to execute script from 'jenkins_url' because its mime type ('application/json') is not executable, and strict mime type checking is enabled. </cmt> <cmt> fix: bump stapler version </cmt> <cmt> bump stapler to lastest. </cmt> <cmt> enh: bump stapler to stable version </cmt> <cmt> bump to stapler 1.236 stable </cmt> <cmt> [jenkins-27607] reproduced in test. </cmt> <cmt> merged #1595 and enabled test. </cmt>",fix mime type with jsonp
4035,"<desc> description: use the sni value as the upstream cluster name. this is similar to the cluster_header feature in hcm. leverages the perconnectionstate to dynamically control the cluster used by tcp_proxy filter. we plan to use this in istio, where pilot would manage two kubernetes setups, such that the envoys will have the same set of clusters, but the non-local clusters will have the ip of a gateway envoy (edge/front envoy). mtls traffic arriving at the gateway envoy will be routed to the internal (envoy)clusters based on the sni value depends on #4454 risk level: low testing: unit tests docs changes: yes release notes: yes </desc> <cmt> cluster name from sni </cmt> <cmt> tests and more </cmt> <cmt> fixes </cmt> <cmt> tests and fixes </cmt> <cmt> streamline </cmt>",network filter to set upstream cluster from sni
4036,"<desc> first pr for the implementation of on prem server. this pr adds the ability in oss to automatically manage local/onprem clusters. the user on the server runs python coordinator_server.py --ips  --ports then the user can modify the current example-full.yaml for local clusters and replace head_ip and worker_ips with coordinator_address as follows: before: # local specific configuration. provider: type: local head_ip: your_head_node_hostname worker_ips: [worker_node_1_hostname, worker_node_2_hostname, ... ] after: # local specific configuration. provider: type: local coordinator_address: ""<the coordinator address>"" in addition to auto-management, closes #9662. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> on prem server first commit </cmt> <cmt> minor fix </cmt> <iss> can't reduce num_workers for local node provider </iss>",on prem server first pr
4037,<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. </desc> <cmt> docapi-5203: direct i/o settings for mergetree descriptions. </cmt> <cmt> docapi-5203: edits after prereview of pull. </cmt>,direct i/o settings for mergetree descriptions. en review and ru translation.
4038,"<desc> checklist: my code follows the code style of this project. i have read the contributing document. ( it compiles correctly for the promicros, which is what i had to test with: * the firmware size is fine - 28664/28672 (8 bytes free) </desc> <cmt> adding my keymap primarily to iris </cmt> <cmt> adding my crkbd keymap and update my iris keymap readme with an extra pic </cmt>",adding my keymap for the helidox and update my iris keymap readme
4039,"<desc> changes: make uvscalemap updates backwards-compatible fix error in morph targets if normal attributes are undefined (the frog rome model broke here) flatten a three.group if it only contains a single mesh try to eliminate more cases where names might be duplicated, breaking animation. examples: parent node and child mesh share the same name in source gltf mesh is reused by multiple nodes (see: cesiummilktruck) this fixes all of the rome examples, although they still require three.doubleside. demo:  the demo will print a tree of mesh names coming out of the loader. examples: animatedmorphsphere cesiummilktruck fixes #12368. problems with rome models were related to (1) missing normals in one model, and (2) nodes and meshes sharing names in many models. improves #11944, although there's still more we can do to flatten the output. polly (#12364) still does not work completely; the head disappears at odd intervals. looks like an animation problem, or some ambiguity in the gltf spec. </desc> <cmt> gltfloader: deduplicate node/mesh names and flatten single-mesh nodes. </cmt> <cmt> gltfloader: keep uvscalemap updates backwards-compatible. </cmt> <cmt> gltfloader: disambiguate names for multiple instances of the same mesh. </cmt> <iss> gltfloader: morph targets not animating correctly in rome models </iss>","more robust de-duping of mesh/node names, morph target fixes, etc."
4040,"<desc> dqn ape-x and ddpg ape-x agents do not take the value set by users for the parameter prioritized_replay  into account. in addition to the unexpected per behavior, this prevents these agents from being used with replay_mode=lockstep. closes #17540 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> feat(rllib/apex): do not update priorities when 'prioritized_replay == false' </cmt> <cmt> feat(rllib/apex): prevent worker side prioritization without per </cmt> <cmt> feat(rllib/ddpg): add config check for 'prioritized_replay' parameter </cmt> <cmt> feat(rllib/ddpg): add config checks for 'prioritized_replay' parameter </cmt> <iss> [rllib] apex doesn't take the value of `prioritized_replay` into account. </iss>",ape-x doesn't take the value of prioritized_replay into account
4041,<desc> for #8057. </desc> <cmt> add tablecontainedrule </cmt> <cmt> remove useless implements </cmt> <cmt> refactor generic type of shardingspheremetadataloader </cmt> <cmt> refactor generic type of shardingspheremetadataloader </cmt> <cmt> refactor schemametadataloader </cmt> <cmt> rename datanodecontainedrule's variable </cmt> <cmt> remove useless shardingspheremetadataloader.load </cmt> <cmt> refactor schemametadataloader </cmt> <cmt> merge shardingspheremetadatadecorator into shardingspheremetadataloader </cmt>,add tablecontainedrule to simplify shardingspheremetadataloader
4042,"<desc> this pr is trying to fix compilation problems in gpu code with msvc 2015, in issue #439. @tt83 can you test if it removes all warnings? for the long string literal problem i am still trying to figure out a clean resolution. </desc> <cmt> fix warnings when compiled with -pedantic </cmt> <cmt> add -dboost_all_no_lib for windows build </cmt>",fix compilation problems with msvc
4043,<desc> this is the proper fix / improvement for #7573 by supporting minimum/step/maximum not only in spinners but also in lists. to not duplicate a lot of code i added an additional base class csettingcontrolformattedrange used by csettingcontrolspinner and csettingcontrollist and i refactored the integer/string options handling so that the same code can be used by cguicontrolspinexsetting and cguicontrollistsetting. this doesn't touch the settings library at all because it already supports this use case. just the gui integration was missing this part. </desc> <cmt> settings: use range based for loop in cguicontrolbasesetting and derived classes </cmt> <cmt> settings: add support for minimum/step/maximum in csettingcontrollist </cmt> <cmt> settings: refactor handling of integer/string spinners/lists and add support for minimum/step/maximum in cguicontrollistsetting </cmt>,support minimum/step/maximum in lists (not only spinners)
4044,<desc> removed trival warnings from the files </desc> <cmt> removed warning from the file. </cmt> <cmt> fixed the warning in the file. </cmt> <cmt> removed warning from the file. </cmt> <cmt> fixed warning from the file. </cmt> <cmt> removed warning from the file. </cmt> <cmt> fixed warning in the file. </cmt> <cmt> fixed warning in the file. </cmt> <cmt> removed the warning in the file. </cmt>,fixed warnings in the files
4045,<desc> prior modifications to the chart (in order to enforce mongo oplog for version 1.x+ )  creates a  mongodb replicaset consisting of 3x mongo instances.   this has unnecessarily tripled the resource requirement to deploy the default basic chart. this pr corrects the situation and starts a single mongodb instance with oplog enabled. significantly reducing the minimal deploy resource requirements. please review and test   @geekgonecrazy dco signed title of the pr starts with chart name (e.g. [stable/chart]) </desc> <cmt> start mongo primary with oplog only by default; no need for secondary or arbiter </cmt> <cmt> bump chart version </cmt>,correct mongodb to single node oplog enabled by default
4046,<desc> bug fixes in @next/eslint-plugin-next. adds rules to recommended config. </desc> <cmt> addinng no html-link lint rule </cmt> <cmt> fixing lint tests </cmt> <cmt> adding the utils file </cmt> <cmt> fixing lock file </cmt> <cmt> prettier fix </cmt> <cmt> bug fixes </cmt> <cmt> exact regexpmatch </cmt>,bug fixes for lint routing
4047,"<desc> original pull-request #19443 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> fix wrong parts in parts_to_do </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> update replicatedmergetreequeue.cpp </cmt> <cmt> addition to #15537 </cmt>",cherry pick #19443 to 20.12: addition to #15537
4048,<desc> document manage_inactivity function allow extruder_runout_prevent to work with all extruders use faster memcpy for copying coordinates fix some spelling in the configurations </desc> <cmt> spacing and spelling </cmt> <cmt> fix manage_inactivity </cmt> <cmt> - document manage_inactivity function </cmt> <cmt> - allow extruder_runout_prevent to work with all extruders </cmt> <cmt> - use faster memcpy for copying coordinates </cmt>,"optimize coordinate copying, fix extruder_runout_prevent"
4049,"<desc> fixes a part of #9325 fixes docstring parameters test for cross_decomposition and discriminant_analysis the issue is not closed, other packages still need to be checked. don't hesitate to tell me if i can improve anything in this pr! </desc> <cmt> fixing cross_decomposition docstring parameters </cmt> <cmt> fixing discriminant analysis docstring parameters </cmt>",docstring parameters improvements for cross_decomposition and discriminant_analysis
4050,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). createkeyring:  createcryptokey:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. i'm not </desc> <cmt> add createkeyring declarations </cmt> <cmt> add createcryptokey declarations that don't quite work with all options </cmt> <cmt> apparently it worked with rotationperiod </cmt> <cmt> add nanos field to make it happy </cmt> <cmt> function order </cmt> <cmt> run lint </cmt> <cmt> update package version from 1.3 to 1.5.1 in header </cmt>",add missing types for creating keyrings and cryptokeys
4051,<desc> addresses #4009 added : patch for moto sns create platform endpoint refactored api logic to use snsbackend class to keep track of state instead of global variables. refactored sns integration test to use snsbackend class instead of global variables </desc> <cmt> merge original repo to update forked repo </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fix create platform endpoint idempotency </cmt>,sns create platform endpoint idempotency
4052,"<desc> makes more ci jobs compatible with github actions. #631 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> fix typo in job triggers </cmt> <cmt> check if travis before not enabling -ux </cmt> <cmt> try gimme_go_version=stable </cmt> <cmt> explicitly read file as utf-8 for check_import_order.py to address windows cp-1252 encoding issue </cmt> <cmt> add llvm/clang to path on windows for linter </cmt> <cmt> use gcc in build.sh for psutil </cmt>",factor out more travis code and update github actions
4053,<desc> fix #4873 </desc> <cmt> fix a bug that index url is not correctly saved in pipfile </cmt> <cmt> add news entry </cmt> <iss> `pipenv install --index <my-pypi-registry> <my-package>` generates a pipfile that `pipenv lock` can't handle </iss>,fix a bug of source saving in pipfile
4054,<desc> part of #34338 </desc> <cmt> add documentation for many of the atomic_* intrinsics </cmt> <cmt> part of #34338 </cmt> <cmt> add documentation for the volatile_read and volatile_write intrinsics </cmt> <cmt> part of #34338 </cmt> <cmt> add documentation for some of the add/sub/mul intrinsics </cmt> <cmt> part of #34338 </cmt>,add documentation to some of the unstable intrinsics
4055,"<desc> original pull-request #16205 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. </desc> <cmt> add a test for dictget in sharding_key after dictionary reload </cmt> <cmt> do not cache dictionary for dictget*/dicthas* </cmt> <cmt> there are places where expressionactionsptr is cached </cmt> <cmt> (storagedistributed caching it for sharding_key_expr and </cmt> <cmt> optimize_skip_unused_shards), and if the dictionary will be cached </cmt> <cmt> within ""query"" then cached expressionactionsptr will always have first </cmt> <cmt> version of the query and the dictionary will not be updated after </cmt> <cmt> reload. </cmt> <cmt> for example this will fix dictget in sharding_key (and similar places, </cmt> <cmt> i.e. when the function context is stored permanently) </cmt> <cmt> fixes: 01527_dist_sharding_key_dictget_reload </cmt> <cmt> do not cache dictionary for dictget*/dicthas* </cmt>",do not cache dictionary for dictget/dicthas
4056,"<desc> improve git helper scripts and provide a readme.md fix spelling, formatting, and reduce size of some config comments </desc> <cmt> minor fix in k8200 readme </cmt> <cmt> tweak command index increment </cmt> <cmt> tweak git helper scripts </cmt> <cmt> edit configuration comments </cmt>","update git helper scripts, config comments"
4057,<desc> this fix tries to fix the issue raised in #13506 where int64 data types for bounds in tf.image.pad_to_bounding_box crashes. the reason of the crash is caused by the fact that int64 was directly converted into int32 without passing through kernel registeration. this fix fixes the issue by adding typename tpadding to the template and adds appropriate kernels. this fix fixes #13506. </desc> <cmt> add int64 bounds support for tf.image.pad_to_bounding_box </cmt> <cmt> this fix tries to fix the issue raised in 13506 where int64 data types </cmt> <cmt> for bounds in tf.image.pad_to_bounding_box crashes. </cmt> <cmt> the reason of the crash is caused by the fact that int64 was directly </cmt> <cmt> converted into int32 without passing through kernel registeration. </cmt> <cmt> this fix fixes the issue by adding typename tpadding to the template. </cmt> <cmt> this fix fixes 13506. </cmt> <cmt> add test cases for int64 bounds of tf.image.pad_to_bounding_box </cmt> <cmt> this fix adds test cases for int64 bounds of tf.image.pad_to_bounding_box </cmt> <cmt> add gpu support for int64 bound of tf.image.pad_to_bounding_box </cmt> <cmt> address gpu build for int64 bounds support of tf.image.pad_to_bounding_box </cmt> <iss> tf.image.pad_to_bounding_box crashes when passed bounds with dtype int64 </iss>,fix crash when tf.pad is used with int64 paddings.
4058,<desc> resolves #5069 </desc> <cmt> add sections describing default and custom file names in file pipelines </cmt> <cmt> add sections describing default and custom file names in file pipelines </cmt> <iss> document how to change file system storage default file name </iss>,add docs sections describing default and custom file names
4059,"<desc> change adds the packagefamilyname and productcode values to parsing by the manifest.  these can be at the root level, where they will be inherited.  they can also be provided per installer, but they must match the installertype or it will be an error. also makes major changes to the way the manifestversion is handled.  for now, the version is largely ignored (except it must be major version 0 if provided).  a concept of extensions is added, which are defined as the hyphen separated values after the primary version.  these can also be versioned, although the code does not exist to check it.  the syntax is: manifestversion := version (- extension) extension := version (- extension) where the version portion of extension is treated as name.version.  for instance, 1.0.0-extension and 1.0.0-extension.2. additionally: fixes an issue with the version sorting where additional version characters would sort higher than those without (ex. 1.0 will now be greater than 1.0-alpha) validation tests are added for packagefamilyname and productcode, as well as the manifest version parsing. microsoft reviewers: open in codeflow </desc> <cmt> manifest parser updates to not be minor version strict and create extension semantics </cmt> <cmt> add tests and fixes based on them </cmt>",add system reference values to manifest parsing
4060,"<desc> what did you implement: adding documentation for environment variables how did you implement it: simple documentation change how can we verify it: check the doc/providers/spotinst/ : guide/variables.md guide/quick-start.md todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable ""allow edits from maintainers"" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no </desc> <cmt> spotinst- adding variables documentation in the user guide </cmt> <cmt> spotinst - updating the quickstart guide </cmt> <cmt> spotinst - fixing spelling error </cmt>",spotinst - adding documentation for new environment variables feature and update the quick start
4061,"<desc> after the merging of #9848 , we can now interact with the jsonapi endpoints of a drupal site behind basic authentication. this works, however gatsby cannot retrieve remote files, because the calls executed in createremotefilenode do not currently take into consideration the basic auth credentials. this pull request adds those credentials so that files are correctly fetched from the remote drupal site behind basic auth. </desc> <cmt> gatsby-source-drupal: use basic auth credentials also when fetching remote files. </cmt> <cmt> gatsby-source-drupal: better support the case where no basic auth is specified. </cmt>",use basic auth credentials to fetch remote files as well.
4062,"<desc> resolve #6163 conflicts adding suggested changes. most of the resources was already listed, so in those cases complete info according to review suggestions. resolves #6163, closes #6163, locks #6163 read our contributing guidelines search for duplicates. #6163 </desc> <cmt> add book mysql </cmt> <cmt> fixing </cmt> <cmt> added course laravel </cmt> <cmt> update free-courses-id.md </cmt> <cmt> fixing directly youtube </cmt> <cmt> added belajar vue.js </cmt> <cmt> fixing book mysql & course laravel </cmt> <cmt> solve lint errors + add book author as seen in the footer of webpage </cmt> <cmt> add  ""account required"" notation </cmt> <cmt> resolves: </cmt> <cmt> - </cmt> <cmt> - </cmt> <cmt> recover removed authoring after add access notes </cmt> <cmt> recovered from commit </cmt> <cmt> apply review suggestions </cmt> <cmt> - yt playlist </cmt> <cmt> - complete instructors </cmt> <cmt> - alphabetize </cmt> <cmt> solve outdated conflicts </cmt>",bump pr/endrose/6163 - added belajar vue js
4063,"<desc> move some dev tools files around since i'm gonna have to add more. call out material stuff explicitly with material. call out generated stuff explicitly with generated. related issues #13452 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. my pr includes tests for all changed/updated/fixed behaviors (see test coverage). i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). no, this is not a breaking change. </desc> <cmt> cupertino global localization </cmt> <cmt> do 2 arbs </cmt> <cmt> start messing with gen_localizations </cmt> <cmt> re-combed the arb file and categorized the global source in the interface </cmt> <cmt> cupertino localization step 3: in-place move some material tool around to make room for cupertino </cmt>",in-place move some material tools around to make room for cupertino
4064,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: </desc> <cmt> added quill isenabled method </cmt> <cmt> added quill isenabled method </cmt> <cmt> updated header with my name </cmt>,quill - added isenabled type method
4065,<desc> remove the devtools extensions file when the loaded extensions array is empty instead of writing an empty array to the file. this prevents the file from getting created when no extensions are used in the app. fixes #4296 </desc> <cmt> correct typo in comment </cmt> <cmt> add failing spec for dev tools extensions file </cmt> <cmt> delete extensions file when there are no loaded extensions </cmt>,don't write empty dev tools extensions file
4066,"<desc> this is independent from #8779 and doesn't require an update of electron. the good thing is all native modules are now update-to-date, and we no longer need to worry the build would break when we update a module or package to a later version. the only change is to update the modules to use nan 2, the build is green, but we might probably encounter bugs due to the update. fixes #8508 / </desc> <cmt> :arrow_up: runas@3.1 </cmt> <cmt> :arrow_up: atom-keymap@6.0.0 </cmt> <cmt> :arrow_up: pathwatcher@6.2 </cmt> <cmt> :arrow_up: nslog@3 </cmt> <cmt> :arrow_up: oniguruma@5 </cmt> <cmt> :arrow_up: git-utils@4 </cmt> <cmt> :arrow_up: scrollbar-style@3.2 </cmt> <cmt> :arrow_up: text-buffer@7.1.0 </cmt> <cmt> :arrow_up: scandal@2.2 </cmt> <cmt> :arrow_up: apm@1.1.1 </cmt> <cmt> :arrow_up: link@0.31.0 </cmt> <cmt> :arrow_up: markdown-preview@0.153.0 </cmt> <cmt> :arrow_up: symbols-view@0.108.0 </cmt> <cmt> :arrow_up: tree-view@0.189.0 </cmt> <cmt> :arrow_up: spell-check@0.60.0 </cmt>",update all native modules and their dependents to nan 2
4067,"<desc> currently, these attributes are not visited, so they are not gated feature checked in the post expansion visitor. this only affects crates using #![feature(stmt_expr_attributes)]. r? @nrc </desc> <cmt> visit statement and expression attributes </cmt> <cmt> check that custom attributes are disallowed on statements and expressions </cmt>",visit statement and expression attributes in the ast visitor
4068,"<desc> updated glob-stream to version 3.1.0. this version allows users to set the base path for all files. use case: user wants to copy ""lib/"" and ""bin/"" to /my/path/lib and /my/path/bin. </desc> <cmt> update glob-stream to 3.1.0. this versions supports the ability to set </cmt> <cmt> the file base path to the cwd or custom. </cmt> <cmt> bump version </cmt>",update glob-stream version to 3.1.0
4069,"<desc> add and document cli options for batch size, max doc length, min doc length for spacy pretrain. also improve cli output. closes #3216 i have submitted the spacy contributor agreement. </desc> <cmt> improve pretrain progress log </cmt> <cmt> add batch_size, max_length and min_length cli arguments for pretrain </cmt> <cmt> document new pretrain arguments </cmt>",expose batch size and length caps on cli for pretrain
4070,"<desc> scale the retro terminal effects (#3468) scan lines with the screen's dpi. remove artifacts from sampling wrap around. before & after, with my display scale set to 350%: before & after showing artifact removal, with my display scale set to 100%, and image enlarged to 400%: closes #4362 cla signed. if not, go over here and sign the cla requires documentation to be updated adds a constant buffer, which could be used for other settings for the retro terminal pixel shader. i haven't touched c++ in over a decade before this change, and this is the first time i've played with directx, so please assume my code isn't exactly best practice. changed display scale with experimental.retroterminaleffect enabled, enjoyed scan lines on high resolution monitors. enabled experimental.retroterminaleffect, turned the setting off, changed display scale. retro tabs still scale scan lines. </desc> <cmt> scale retro scan lines initial </cmt> <cmt> just put the pixel shader settings into its own member struct </cmt> <cmt> undo unintended formatting changes </cmt> <iss> retro terminal effect prodces artifacts on the right screen edge </iss>",scale retro terminal scan lines
4071,"<desc> after careful discussion we decided we are not happy with the breaking change and will be making this configurable at the daemon level for users that do not want it to be sigkilled. </desc> <cmt> revert ""fix failing test to use kill instead of stop"" </cmt> <cmt> this reverts commit 4434dcee89f7d0d0239f6b492b24e940cdbafb21. </cmt> <cmt> docker-dco-1.1-signed-off-by: michael crosby <michael@crosbymichael.com> (github: crosbymichael) </cmt> <cmt> revert ""disable automatic killing of containers when docker stop fails"" </cmt> <cmt> this reverts commit 8b5cf51d600dc4f3611cf063c52cf3448e7b01e5. </cmt> <cmt> docker-dco-1.1-signed-off-by: michael crosby <michael@crosbymichael.com> (github: crosbymichael) </cmt>",revert back to the default stop functionality of sigkill after timeout
4072,<desc> others others optimize inplace logic and fix bugs when run kernel that has args of vector </desc> <cmt> add inplace op adaptation </cmt> <cmt> optimize inplace logic and fix bugs when run kernel that has args of vector<densetensor> </cmt>,[pten]make inplace_op and vector<densetensor> input compatible with old architecture
4073,"<desc> (this is part of the cleanup in activesupport::dependencies due to the deletion of classic.) the methods constantize and safe_constantize of activesupport::dependencies are private. they have nothing to do with autoloading, just forward to the inflector. they were there for historical reasons, but today we no longer need them. the public interface is in string. so model_name.constantize instead of activesupport::dependencies.constantize(model_name) the majority of the framework already did this, there were only a few occurrences. </desc> <cmt> delete as::dependencies.constantize </cmt> <cmt> delete as::dependencies.safe_constantize </cmt>",delete as::dependencies.(safe_)constantize
4074,"<desc> this is a continuation of the work started in #17870. mksnapshot must be run with the same arguments that generated the original mksnapshot, otherwise crashes happen. we currently ensure that these are the same by hand. this makes them the same by definition. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes </desc> <cmt> build: robustify verify-mksnapshot w.r.t. command-line parameters </cmt> <cmt> debugging </cmt> <cmt> debug args </cmt>",make sure mksnapshot is invoked with proper args.
4075,"<desc> fixed everywhere the chrome api documentation said something could be null but the types didn't allow it under strict null checking. added some additional tests for chrome.storage to check all the different ways the function can be called, enabled strict null checking for the tests, and fixed some issues with the existing tests i found after doing that. the example code at </desc> <cmt> fix strict null checking in chrome </cmt> <cmt> fixed everywhere the chrome api documentation said something could be null but </cmt> <cmt> the types didn't allow it under strict null checking. </cmt> <cmt> fix chrome tests with strict null checking enabled </cmt> <cmt> enabled strict null checking for chrome tests and fixed some issues with the </cmt> <cmt> existing tests. </cmt> <cmt> the example code at </cmt> <cmt>  </cmt> <cmt> would use an uninitialized 'span' variable if bookmarknode.title was empty. </cmt> <cmt> since i have no idea what it was supposed to do in that case, i just moved the </cmt> <cmt> declaration of span up a block. </cmt>",improve chrome definitions with strict null checking enabled
4076,"<desc> it's no longer grey and doesn't have a gradient. what the final wording of the description should be, i'm not sure. but i'm sure the community has ideas. </desc> <cmt> removed reference to button color and gradient </cmt> <cmt> changed the wording to reflect the default button's new look since it's no longer grey and doesn't have a gradient. i'd say this new wording isn't ideal and needs something a bit more, well, descriptive. </cmt> <cmt> removed extraneous space </cmt>",changed description of default button
4077,"<desc> preparatory change to enable reg-free winrt (only works with .exe's, not .dll's; meant to replace current link-time override of rogetactivationfactory) sharing of test code between microsoft.reactnative.integrationtests (already a gtest project) and react.native.desktop.abitests microsoft reviewers: open in codeflow </desc> <cmt> change abitest project to googletest executable </cmt> <cmt> change files </cmt>",change abitest project to gtest executable
4078,<desc> do not emit source maps when generating dts file json files from project reference should be able to do dts emit default if for any reason signature calculation fails should be source file version and exported modules from the file (just like what we do for d.ts file) </desc> <cmt> test update </cmt> <cmt> use source file version as default signature for the file whenever there is no dts emit for the file </cmt> <cmt> json source files from project reference should be able to calculate the signature </cmt> <cmt> dont emit declaration map when emitting dts files for force emit for signature </cmt>,improvements to dts emit for tsbuildinfo
4079,"<desc> regression, introduced in 3.5.0 send all keyboard events to single value change inputs fix #5476 we now send all the proper events to input elements with type date, time, and datetime-local #5476 when typing into certain inputs (like date), we now send all keyboard events as we did prior to 3.5.0. some frameworks were reacting to this bug by seemingly deleting the value after it's been typed </desc> <cmt> fix not firing key events on singlevaluechange inputs </cmt> <cmt> use http for livereload </cmt> <cmt> add link to issue </cmt> <iss> date/time input broken (no input events) since 3.5.0 </iss>",3.5.0 - send keyboard events for single value change inputs
4080,<desc> added actual link to the list items. added a link next to the view source button to open the example. </desc> <cmt> added defined default value to crossorigin </cmt> <cmt> added filter search to documentation page </cmt> <cmt> added mobile version with media queries </cmt> <cmt> conflicts: </cmt> <cmt> docs/index.html </cmt> <cmt> fix for retina displays </cmt> <cmt> reverted </cmt> <cmt> conflicts: </cmt> <cmt> examples/webgl_geometry_terrain_raycast.html </cmt> <cmt> added button to get direct link to the example </cmt> <cmt> fixed merge </cmt> <cmt> newline </cmt> <cmt> fix for panel repetition </cmt>,access to example link from examples page
4081,"<desc> currently all uncaught exceptions of the requests library that is used in winrm will lead to an ""unexpected failure during module execution"". instead of letting all exceptions bubble up we catch the connection related errors (inkl. timeouts) and re-raise them as ansibleconnectionerror so ansible will mark the host as unreachable and exit with the correct return code. this is especially important for zuul ( backport of #51744. winrm fatal: [win-node]: failed! => {""msg"": ""unexpected failure during module execution."", ""stdout"": """"} an exception occurred during task execution. to see the full traceback, use -vvv. the error was: requests.exceptions.readtimeout: httpsconnectionpool(host='xxx.xxx.xxx.xxx', port=5986): read timed out. (read timeout=120) traceback (most recent call last): file ""/opt/zuul/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request six.raise_from(e, none) file ""<string>"", line 2, in raise_from file ""/opt/zuul/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request httplib_response = conn.getresponse() file ""/usr/lib/python3.6/http/client.py"", line 1331, in getresponse response.begin() file ""/usr/lib/python3.6/http/client.py"", line 297, in begin version, status, reason = self._read_status() file ""/usr/lib/python3.6/http/client.py"", line 258, in _read_status line = str(self.fp.readline(_maxline + 1), ""iso-8859-1"") file ""/usr/lib/python3.6/socket.py"", line 586, in readinto return self._sock.recv_into(b) file ""/usr/lib/python3.6/ssl.py"", line 1012, in recv_into return self.read(nbytes, buffer) file ""/usr/lib/python3.6/ssl.py"", line 874, in read return self._sslobj.read(len, buffer) file ""/usr/lib/python3....ib/python3.6/site-packages/winrm/protocol.py"", line 417, in _raw_get_command_output res = self.send_message(xmltodict.unparse(req)) file ""/opt/zuul/lib/python3.6/site-packages/winrm/protocol.py"", line 234, in send_message resp = self.transport.send_message(message) file ""/opt/zuul/lib/python3.6/site-packages/winrm/transport.py"", line 256, in send_message response = self._send_message_request(prepared_request, message) file ""/opt/zuul/lib/python3.6/site-packages/winrm/transport.py"", line 261, in _send_message_request response = self.session.send(prepared_request, timeout=self.read_timeout_sec) file ""/opt/zuul/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send r = adapter.send(request, **kwargs) file ""/opt/zuul/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send raise readtimeout(e, request=request) requests.exceptions.readtimeout: httpsconnectionpool(host=""xxx.xxx.xxx.xxx"", port=5986): read timed out. (read timeout=120) </desc> <cmt> raise ansibleconnectionerror on winrm con errors </cmt> <cmt> currently all uncaught exceptions of the requests library that is used </cmt> <cmt> in winrm will lead to an ""unexpected failure during module execution"". </cmt> <cmt> instead of letting all exceptions bubble up we catch the connection </cmt> <cmt> related errors (inkl. timeouts) and re-raise them as </cmt> <cmt> ansibleconnectionerror so ansible will mark the host as unreachable and </cmt> <cmt> exit with the correct return code. </cmt> <cmt> this is especially important for zuul ( </cmt> <cmt> distinguish between failures and connection/host related errors. </cmt> <cmt> update lib/ansible/plugins/connection/winrm.py </cmt> <cmt> add changelog fragment </cmt>",raise ansibleconnectionerror on winrm connnection errors
4082,"<desc> closes #2420 closes #2433 (just main variables, have not checked parallelization) this exposed an issue #2439 that we can solve separately: this pr just extracts env variables for these two providers </desc> <cmt> extract build variables for bitbucket pipeline </cmt> <cmt> test bitbucket commit info </cmt> <iss> collect ci information from bitbucket pipeline </iss> <iss> collect env variables for vsts / teamfoundation microsoft ci </iss>",extract bitbucket pipeline and teamfoundation environment variables
4083,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: playground link include tests for your changes: history-tests.ts if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. updates overload signatures for history.pull and history.replace either a single parameter of either string or object. note: ran prettier on the latest version of history package definitions only prior to making changes to those declarations in a separate commit. </desc> <cmt> run 'prettier' on latest history package </cmt> <cmt> fix history package's overload signatures to support indeterminate location type </cmt>",accept single ambiguous location parameter for history's push and replace methods
4084,<desc> check prs with ci method without building firmware files the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.0 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass </desc> <cmt> build only when push </cmt> <cmt> update and rename ci_github.yml.off to ci_github.yml </cmt> <cmt> update and rename ci_github_esp32.yml.off to ci_github_esp32.yml </cmt>,build firmware only with action push
4085,"<desc> follow-up pr for #40429 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fix(parse/object): attributes in constructor should be optional </cmt> <cmt> refactor(parse/geopoint): update constructor params </cmt> <cmt> feat(parse/query): add generic attr check for functions </cmt> <cmt> lint(parse): fix lint issues </cmt> <cmt> feat(parse/query): key types for matcheskeyinquery() </cmt> <cmt> refactor(parse/query): add base attrs to query checks </cmt> <cmt> feat(parse/query): check type for value params in modifiers </cmt> <cmt> refactor(parse/query): remove unnecessary extract<> from modifiers </cmt> <cmt> feat(parse/query): support pointer for object attrs in equalto() </cmt>",add generic type check for modifiers functions
4086,<desc> closed my first pr so i could clean up my fork and submit a good pull. this has been working for a couple months now.  everything functions as intended.  engage and disengage without issue and never loose steering. heres a couple drives in case its needed hwy drive  city drive </desc> <cmt> 0.5.6 </cmt> <cmt> merge devel </cmt> <cmt> added acadia </cmt> <cmt> adding acadia </cmt> <cmt> adding acadia </cmt> <cmt> update radar_interface.py </cmt> <cmt> adding acadia </cmt> <cmt> added acadia </cmt> <cmt> refactored </cmt> <cmt> fixed tuning </cmt> <cmt> adding acadia </cmt>,adding support for 2018 gmc acadia denali
4087,"<desc> the issue is that when imgur upload fails and generates error, the text was not selectable to be copied by user. see the commit messages for more granular info. p.s: i'm not sure about the coding quality as i'm not a c++ dev nor a qt dev. so feel free to fix it (and i'll learn) </desc> <cmt> makes text of the imgur upload selectable </cmt> <cmt> fix the mouse to i shape for selectable texts </cmt>",minor fix and modification on selectable tests in dialogs
4088,"<desc> a pr for the only remaining ipv6 rule using state rather than conntrack, improves consistency of the rules. </desc> <cmt> update rules.v6.j2 </cmt> <cmt> updated to use -m conntrack for consistency as per the other ipv6 rules. </cmt> <cmt> update rules.v6.j2 </cmt>",use conntrack rather than state
4089,<desc> this pr will add a new utm info module which allows the management of network interface address entries of the sophos utm. this module integrates with the existing utm_utils . new module pull request module/web_infrastructure/sophos_utm/utm_network_interface_address.py module/web_infrastructure/sophos_utm/utm_network_interface_address_info.py </desc> <cmt> - initial commit </cmt> <cmt> - fix sanity checks </cmt> <cmt> - fixed documentation trailing whitespaces </cmt> <cmt> - changed author github contact as he has no account i'll (@steamx) take responsibility </cmt>,added ansible utm info module for network interface address entities.
4090,<desc> allow nozzle clean to be called with limited axis. specifically enables the use of wiper pads on purge buckets for multi tool machines where a z movement for the wipe would mean a definitive crash. </desc> <cmt> initial commit </cmt> <cmt> remove default since only called from one place </cmt> <cmt> minor corrections </cmt>,allow nozzle clean with limited axis
4091,"<desc> check out the rcharts lecture now. everything is in slidify so no switching between browser windows when recording. </desc> <cmt> added an rcharts lecture start, still working on it </cmt> <cmt> added a lot to the rcharts lecture, all plots are embedded in slidify </cmt> <cmt> added a googlevis lecture shell </cmt> <cmt> added library files so we don't have to keep fetching them </cmt>","the rcharts lecture is nearly complete, it's pretty slick. also added a googlevis shell"
4092,<desc> as per issue #184 this adds some short descriptions (following the established style) to some of the patterns of the class. (i may do some more later) </desc> <cmt> adds description to abstract factory </cmt> <cmt> adds description to builder </cmt> <cmt> adds description to object pool </cmt>,"add short descriptions to abstract factory, builder and objectpool"
4093,"<desc> closes #16223 earlier the title of the rooms wasn't clickable. an event was added to open the room info/user info page when clicked, instead. earlier: title not clickable now: </desc> <cmt> [feature] closes #16223. clicking room header opens room info/user info. </cmt> <cmt> removed redundancies and corrected lint errors </cmt> <iss> make the room name clickable and open room info </iss>",make the header for rooms clickable
4094,"<desc> without these properties, these sections of the page in the rust book do not have momentum scrolling in ios which makes reading the book on ios a fairly arduous experience. these commits adds the -webkit-overflow-scrolling: touch; property to both the toc and the page content itself. </desc> <cmt> add ""-webkit-overflow-scrolling: touch"" to book css for the page wrapper. </cmt> <cmt> this change permits native momentum scrolling in safari on ios in the book. </cmt> <cmt> add same ""-webkit-overflow-scrolling: touch"" to the table of contents in the book. </cmt>","add ""-webkit-overflow-scrolling: touch;"" to book css"
4095,"<desc> based on #85937 with #85937 (comment) addressed fix bug where kube-apiserver would fail to start when not providing service cidr the strings.split documentation states: // if s does not contain sep and sep is not empty, split returns a // slice of length 1 whose only element is s. import ( ""fmt"" ""strings"" func main() { serviceclusteripranges := """" serviceclusteriprangelist := strings.split(serviceclusteripranges, "","") fmt.printf(""len: %d, value: %+v"", len(serviceclusteriprangelist), serviceclusteriprangelist) } // output // len: 1, value: [] playground link this would fail the if check here and apiserver wouldn't start. this pr fixes this bug. does this pr introduce a user-facing change?: release note: </desc> <cmt> fix bug in apiserver service cluster cidr split </cmt> <cmt> refactor parsing logic for service ip and ranges, add tests </cmt>",fix bug in apiserver service cidr split
4096,"<desc> fixes rdar://problem/61407215 and rdar://problem/50905075. cherry-pick #31196 onto 5.3 branch. </desc> <cmt> [nfc] add test case for old arm64e fallback behavior. </cmt> <cmt> [moduleinterface] remove fallback behavior for arm64e -> arm64. </cmt> <cmt> addresses rdar://problem/61407215. </cmt> <cmt> [moduleloader] emit a better diagnostic for swiftinterfaces with wrong arch. </cmt> <cmt> before this change, we would emit the warning only for swiftmodules; however, </cmt> <cmt> it may be the case that only a swiftinterface (of a different arch) is present </cmt> <cmt> but no swiftmodule is present. </cmt> <cmt> fixes rdar://problem/50905075. </cmt>",remove fallback for arm64e -> arm64.
4097,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ghsa-7wwv-vh3v-89cq if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. note: besides, adjustments have been made in line with the changed api: markdown-it/markdown-it#626 </desc> <cmt> bump dependency highlight.js of types/markdown-it from 9.7.0 to 10.4.1 </cmt> <cmt> add support for changed api of markdown-it ( </cmt>",remove dependency highlight.js (and only keep @types/highlight.js) to resolve vulnerability ghsa-7wwv-vh3v-89cq
4098,<desc> this pr is based on #6160 </desc> <cmt> cceventdispatcher crash fix </cmt> <cmt> fix possible crashes which could be caused by the eventdispatcher having listeners associated with nodes are destroyed. catch the case where a node registers a listener while we are dispatching events and gets destroyed while that event is still being dispatched. check the list of nodes to be added into the event dispatcher fully when we are cleaning listeners for a target node. </cmt> <cmt> this issue was found using the extra debug verification in this pull request: </cmt> <cmt>  </cmt> <cmt> add an event dispatcher test </cmt> <cmt> add an event dispatcher test to help reproduce crashes fixed by the previous commit and to verify that the fix still works. </cmt> <cmt> unregistered listener when it's removed from _toaddedlisteners. </cmt>,"fixed a potential crash in eventdispatcher, based on pr #6160"
4099,"<desc> introduces new progressiverendering utility and uses it to display /asynchpeople incrementally. /people now a 404, but /people/api still works. </desc> <cmt> progressiverendering </cmt> <cmt> .classname, not .class. </cmt> <cmt> asynchpeople </cmt> <cmt> do initial refresh asynch; seems to work better with some kinds of html. </cmt> <cmt> ts_refresh </cmt> <cmt> using ts_refresh to resort properly. </cmt> <cmt> e.setattribute('a', v) is apparently different from e.a=v. </cmt> <cmt> ts_refresh was much harder than i thought. </cmt> <cmt> [fixed jenkins-15206] displaying <code>/people</code> can consume huge resources. </cmt> <cmt> forgotten link. </cmt> <cmt> no need to really wait the first time. </cmt> <cmt> @since </cmt>",displaying /people can consume huge resources.
4100,"<desc> important: this integration must be merged, not squashed! </desc> <cmt> sync from piper @368734211 </cmt> <cmt> protobuf_sync_piper </cmt> <cmt> merge tag 'refs/tags/sync-piper' into sync-stage </cmt> <cmt> # conflicts: </cmt> <cmt> #	src/google/protobuf/compiler/cpp/cpp_helpers.cc </cmt> <cmt> #	src/google/protobuf/port_def.inc </cmt> <cmt> ported c++ parse function generator to new enum names. </cmt> <cmt> updated changes.txt. </cmt>","integrate from piper for c++, java, and python"
4101,"<desc> this pr adds the detailed view for plugins in the new integration directory. here are some nifty screenshots: information tab: project config tab: you'll notice that the information tab contains information about the features that was added in this pr #16797. we pull them off the feature_descriptions of the plugin classes. for the configurations tab, i decided to call it project configurations so it's a bit more clear that these are project specific. the items you see in the rows have project badges so they look like projects elsewhere in sentry. you'll notice we have the following buttons in the rows: enable: enables a plugin that has already been configured configure: takes you to the configuration page of that plugin for that project uninstall: resets the configuration and disables the plugin for that project/plugin at the top we have the add to project button. clicking it generates the project select modal: doesn't look that great now but we will probably improve it once we have a proper design. </desc> <cmt> sets up initial detailed view for plugins </cmt> <cmt> chore(ts): convert actioncreator navigation </cmt> <cmt> make comingfromprojectid optional </cmt> <cmt> progress </cmt> <cmt> change import </cmt> <cmt> merge from master </cmt> <cmt> progress </cmt> <cmt> more changes </cmt> <cmt> merge from master </cmt> <cmt> update </cmt>",feat(integration-directory): plugin detailed view
4102,"<desc> this pr adds an optional parameter callback to the configuration of the highlight plugin. if a callback function is provided, the function is called with hljs as argument before the plugin starts to highlight the code. sample configuration reveal.initialize({ // ... highlight: { callback: registerampl }, // ... }); a new language can then be added, by including the respective function as shown below: function registerampl(hljs) { hljs.registerlanguage(""ampl"",function(hljs){ return   { contains: [ hljs.hash_comment_mode, hljs.c_block_comment_mode, { classname: ""number"", begin: string.raw\b(\d*\.?\d+)\b, relevance:0 }, { classname: ""strong"", begin: string.raw^ampl[\?:], relevance:0 } ], keywords: { keyword: 'maximize minimize subject to set within union inter diff symdiff cross sum in by mod var param default setof dimen symbolic if then else', type: 'binary integer', string: 'reset model solve data option solver solver_msg solution_precision display include print printf quit', built_in: 'abs max min sqrt round trunc ceil floor', number: 'infinity', symbol: '_nvars _varname _var' } }; }); } fixes #2761 </desc> <cmt> allow users to register additional languages via callback </cmt> <cmt> remove accidentally added tab </cmt>",add option for highlight plugin to register additional languages via callback
4103,<desc> closes #2733 i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> add bfs to binary tree - fixes #2733 </cmt> <cmt> add note on the equivalence of dfs and inorder - fixes #2733 </cmt> <iss> binary tree bfs/dfs missing </iss>,add bfs to binary tree and add note about inorder traversal == dfs
4104,"<desc> my third attempt at a fix for iso layouts in the configurator, last issue was caused by an unexpected key i left in the keymap. </desc> <cmt> added basic mxss support </cmt> <cmt> fixed split rshft for iso layouts </cmt> <cmt> updated readme.md for mxss </cmt> <cmt> added initial support for individual control of front rgb leds </cmt> <cmt> changed rgbled color selection to work using hue and saturation rather than rgb </cmt> <cmt> added code for led state change on layer change </cmt> <cmt> avoid needing an entire 8 bits to store the brightness value </cmt> <cmt> added custom keycodes, along with their handlers </cmt> <cmt> added eeprom storage for front led config </cmt> <cmt> fixed up ability to use qmk configurator and updated readme.md </cmt> <cmt> applied suggested changes from pull request: </cmt> <cmt> updated name in license descriptions </cmt> <cmt> updated layouts to snake case </cmt> <cmt> corrected mistakes in info.json </cmt> <cmt> updated layer_colors to a weak attributed array in mxss.c </cmt> <cmt> defined a new safe range for custom keycodes in keymap.c </cmt> <cmt> fixed up issues with front led </cmt> <cmt> fixed leds not always updating in indicator mode </cmt> <cmt> added support for the other rgblight modes in rgb mode </cmt> <cmt> attempted fix for iso layouts for qmk configurator </cmt> <cmt> synced to main fork </cmt> <cmt> updated mxss iso layouts to remove an unnecessary key </cmt>",fixed mxss iso layouts in qmk configuator (hopefully)
4105,<desc> issue #3803 added test_issue3803.pywithin regression/ to test true for spanish num-like tokens. added lex_attrs.pywithin lang/es/ to overwrite default getter for like_num and include spanish words for numbers. modified __init__.py within lang/es/ to import lex_attrs and update lex_attr_getters within spanishdefaults. added munozbravo.md to .github/contributors/ as specified for contributor agreement. enhancement lang/es i have submitted the spacy contributor agreement. </desc> <cmt> (#3803) spanish like_num returning false for number-like token </cmt> <cmt> (#3803) spanish like_num now returning true for number-like token </cmt>,overwrites default getter for like_num in spanish by adding _num_words and like_num to lex_attrs.py
4106,"<desc> see the individual commit messages for more detail. fixes #5389 </desc> <cmt> use consistent whitespace before comments </cmt> <cmt> changelog: note new error class git_error_http </cmt> <cmt> updates #5389 </cmt> <cmt> transports: use git_eauth for authentication failures </cmt> <cmt> when the failure is clearly an auth failure </cmt> <cmt> (as opposed to possibly an auth failure), </cmt> <cmt> use the error code git_eauth instead of git_error. </cmt> <cmt> while we're here, fix a typo and improve an error message. </cmt> <cmt> fixes #5389. </cmt> <iss> use error code git_eauth for http auth failures </iss>",use error code git_eauth for authentication failures
4107,"<desc> this opens up access to the tf_operationinputlistlength c api from java, for operations that return specified input lists. </desc> <cmt> java api to get the size of specified input list of operations </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt>",java api to get the size of specified input list of operations.
4108,"<desc> add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> fix parameteraddresses error in custom-functions-runtime/index.d.ts </cmt> <cmt> correct two req set numbers, update error code comments to match ui experience in types/custom-functions-runtime/index.d.ts </cmt> <cmt> fix whitespaces per npm lint </cmt>","fix syntax error, match comments to excel ui"
4109,"<desc> description: symboltables are conceptually and structurally really powerful ways to reduce memory overhead for repeated patterns. however the space savings was limited by some taxes: references in structures to aid in raii -- we can use assert statement to get most of the value. lots of very small integers held in arrays of uint32_t -- we can a utf-8-like encoding scheme 16 bytes overhead for vectors, to store size and capacity -- we can store fixed size in 2 uint8s. with these changes the raw space taken by all the stats in a 1k cluster system are reduced by 4x. this is one step toward resolving #4196. we will also be able to concatenate statnames without accessing the global symbol table, enabling lock-free scoped name lookup. risk level: low for now as they are not used yet, but probably wants to be fuzz-tested. testing: //test/common/stats/... docs changes: n/a release notes: n/a </desc> <cmt> typically tests in envoy for files named foo_impl.cc are called foo_impl_test.cc. </cmt> <cmt> this just corrects that for two tests. </cmt> <cmt> also make tag_extractor and tag_producer consistent. </cmt> <cmt> use uint8_t encoding for symbol arrays, and rely on asserts rather than raii to avoid leaks. </cmt> <cmt> the raii concept is nice but it's expensive; need to keep 8-byte </cmt> <cmt> symboltable reference with each stat-name. </cmt> <cmt> further naming clarification. </cmt> <cmt> format </cmt> <cmt> test sorting and hashing. </cmt> <cmt> add a test for memory usage. </cmt>",use a more compact rep for symboltable and add tests for memory usage
4110,"<desc> added working v3-beta version in package.json. also, example here has syntax error. this is my first pull request here, i'm not sure if i'm doing the right way :l </desc> <cmt> add next.config.js file for static routes </cmt> <cmt> reverted start npm script to default </cmt> <cmt> eslint fix </cmt>",add next.config.js for v3 next export example with-dynamic-import
4111,"<desc> i got it wrong on pr #13568.   m43's toggle and watch utilizes were not working because the parsed_pin_index function was not handling the default conditions properly. the pr #13568 changes have already been backed out. parsed_pin_index scans the command line for code and returns an index into the pin map.  if the code is found and the pin is valid then the index for the pin is returned.  it returns the default if the code is not found or the pin is not valid. parsed_pin_index changes: adding -1 results in getting the default when the code is not present. const uint16_t val = (uint16_t)parser.intval(code, -1), port = val / 100, pin = val % 100; changing to -1 results in getting the default value if an invalid pin is specified. return ind > -1 ? ind : dval; additional changes were needed to make the m43 toggle utility work reliably with a lpc176x: toggling the three usb pins causes hangs & disconnects.  the m43_never_touch macro was added to cover this. random hangs and disconnects were occurring when the wdt was enabled.  wdt resets were added to minimize. this. </desc> <cmt> games, for fun (and stress-testing) (#13464) </cmt> <cmt> backout previous pr, correct parsed_pin_index function </cmt> <cmt> remove menu_main.cpp from pr </cmt>",m43 & lpc176x - the real fix (pr #13568 was wrong)
4112,"<desc> resolves #12517 adds a decorator called _retry_if_error_with_cache_removed to implement the retry logic, when the read from cache fails. this pr includes a minor refactoring to use contextlib.closing to make sure streams are closed, when an exception gets raised. </desc> <cmt> enh: correctly handles closing </cmt> <cmt> enh: invalidates cache support </cmt> <cmt> rev: remove invalidates_cache </cmt> <cmt> enh: users decorator to handle retries </cmt> <cmt> rfc: one line message </cmt> <cmt> bug: only unlink if cache file exists </cmt> <iss> fetch_openml migration between 0.20.0 and 0.20.1 </iss>","openml, adds retrying if reading from cache fails"
4113,<desc> this pull request fixes two more build breakages on freebsd introduced recently: add freebsd to the list of platforms with pthread support in runtime/mutex.h link core library with libexecinfo which is required for backtrace_symbols link unit tests runtime with libexecinfo for the same reason before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. </desc> <cmt> add freebsd to the list of platforms with phreads </cmt> <cmt> link with libexecinfo on freebsd </cmt> <cmt> backtrace_symbols is defined in libexecinfo on freebsd </cmt>,"link with libexecinfo, fix runtime/mutex.h"
4114,"<desc> follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update from origin </cmt> <cmt> update from origin </cmt> <cmt> catch up </cmt> <cmt> add subscription items </cmt> <cmt> fix #22783 </cmt> <cmt> add subscriptionitem property and fix bugs </cmt> <cmt> add tests </cmt>",update stripe package to include subscription items
4115,"<desc> what do these changes do? before this pr, if we want to specify some resources, we must do as following codes: @rayremote(resources={resourceitem(""cpu"", 10)}) public static void f1() { // do sth } @rayremote(resources={resourceitem(""cpu"", 10)}) class demo { // sth } unfortunately, it's no way for us to create another actor or task with different resources required. after this pr, the thing will be: actorcreationoptions option = new actorcreationoptions(); option.resources.put(""cpu"", 4.0); rayactor<echo> echo1 = ray.createactor(echo::new, option); option.resources.put(""res-a"", 4.0); rayactor<echo> echo2 = ray.createactor(echo::new, option); //if we don't specify resource,  the resources will be {""cpu"":0.0} by default. ray.call(echo::echo, echo2, 100); n/a </desc> <cmt> support dynamic resources in raycall. </cmt> <cmt> add test. </cmt> <cmt> remove useless methods. </cmt> <cmt> fix minor err. </cmt> <cmt> add doc. </cmt>",support dynamic resources required when submitting task.
4116,<desc> also some cleanup to conform to documentation style. </desc> <cmt> doc: cleanup. </cmt> <cmt> remove ~~~ for code block specification. use /// over /** */ for doc </cmt> <cmt> blocks. </cmt> <cmt> doc: methods for result::result. </cmt> <cmt> doc: methods for option::option </cmt>,method examples for result and option
4117,<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: braintree/braintree-web#544 </desc> <cmt> add tokenize as valid payment intent </cmt> <cmt> format with prettier </cmt>,add tokenize as valid payment intent value
4118,<desc> found the request for adding title case to main article headings per the gatsby style guide. this adds title case to the tutorial sidebar menu. </desc> <cmt> remove title case from the heading to match the sidebar menu </cmt> <cmt> changed all top-level headings to title case </cmt> <cmt> all top-level headings (the main steps) were converted to title case. the sub-headings were left in sentence case. also changed instance of css in all lowercase to uppercase. </cmt>,adding title case to tutorial sidebar menu
4119,"<desc> another approach of webglrenderer webgl 2.0 initial support with glsl ""1 to 3"" conversion advantages compared to glsl 3 to 1 approach less changes because i don't change src/renderer/shaders keep webgl 1.0 stable for us, webgl 2.0 support is still unstable and experimental. so i don't think it's a good idea to affect three.js + webgl 1.0 stability by changing shader code. imo the change isn't too huge, and new codes aren't so mess. this webglrenderer webgl2.0 initial support pr is acceptable. but we may end up wanting to separate webgl2renderer from webglrenderer once we aggressively attempt to add webgl 2.0 features and optimize for them. related: glsl 3 to 1 approach #13701 </desc> <cmt> webglrenderer webgl2.0 basic support </cmt> <cmt> minor clean up </cmt> <cmt> add internalformat conversion function to webgltextures </cmt> <cmt> update setupframebuffertexture() </cmt> <cmt> skip glsl conversion if material is rawshadermaterial </cmt> <cmt> ignore ext_frag_depth for webgl 2.0 </cmt> <cmt> ignore ext_shader_texture_lod for webgl 2.0 </cmt> <cmt> update instancing for webgl 2.0 </cmt> <cmt> clean up webglutils </cmt> <cmt> clean up webglprogram </cmt> <cmt> add .isglsl3 to shadermaterial </cmt> <cmt> clean up webgltextures </cmt> <cmt> update ext_blend_minmax handling for webgl 2.0 </cmt> <cmt> update webglutils for webgl 2.0 unsigned_int_24_8 </cmt> <cmt> update internalformat for webgl2.0 </cmt> <cmt> add webgl_draw_buffers as built-in extensionn for webgl2.0 to webglextensions </cmt> <cmt> clean up webglprogram </cmt>",webglrenderer webgl2.0 initial support with glsl 1 to 3 runtime conversion
4120,<desc> attempting a reland of #87289. part of #86396. updated the skip tests in the 'cupertino' package. turned some tests back on and marked others with exclude instead of skip as they will never work on the web. </desc> <cmt> updated the skipped tests for cupertino package. </cmt> <cmt> reverted a change that was still needed. </cmt> <cmt> update from review. </cmt> <cmt> removed some left over 'exclude' parameters. </cmt>,updated the skipped tests for cupertino package. (reland)
4121,<desc> closes #12908 add a new setting to show/hide agent information on livechat widget. related to rocketchat/rocket.chat.livechat#279 </desc> <cmt> add new setting to show/hide agent infornation on livechat widget. </cmt> <iss> live chat: hide live agent name and profile picture </iss>,livechat setting to show/hide agent information on the widget
4122,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. fixes typed-ember/ember-cli-typescript#295 </desc> <cmt> [@ember/utils] move types from ember. @ember/utils is now the source of truth </cmt> <cmt> [ember] @ember/object as source of types, ember as re-export </cmt> <cmt> [ember] restore original mixin test </cmt>","move types to @types/ember__object, @types/ember is now the re-export"
4123,"<desc> this pr adds two additional tests for the ownership verifier. 8d519bd: this test makes sure that the ownership verifier asserts if we use a borrowed value after the relevant end_borrow has invalidated it. f44f7ea: this test makes sure that the verifier asserts if we destroy an owned value while there are borrows that have not been ended via end_borrow. rdar://29791263 edit: fixed typo in commit hash. </desc> <cmt> [semantic-sil] improve output for filecheck tests for ownership verifier by printing out the function name first. </cmt> <cmt> this just standardizes the output. </cmt> <cmt> rdar://29791263 </cmt> <cmt> [ownership-verifier] add a test for a use of a borrowed value after an end_borrow. </cmt> <cmt> this test makes sure that we properly error when we use a borrowed value after </cmt> <cmt> the borrow has been invalided by an ""end_borrow"". </cmt> <cmt> rdar://29791263 </cmt> <cmt> [ownership-verifier] add a test for a destroy of an owned value before it is no longer borrowed. </cmt> <cmt> this makes sure that we treat the end_borrow as a proper use of the original </cmt> <cmt> value. in such a situation since it is a use, the verifier should trigger that </cmt> <cmt> we have a use after free. </cmt> <cmt> rdar://29791263 </cmt>",add two ownership verifier tests
4124,"<desc> fix the hash checking mechanism upgrade pip before using wheel related pr #18276 </desc> <cmt> revert ""revert ""roll foward ""strip python wheel binary"""""" </cmt> <cmt> this reverts commit 98fc9022005126897b809c5337944afadf27c619. </cmt> <cmt> upgrade pip before using wheel </cmt> <cmt> fix the hash checking mechanism </cmt>","roll forward ""strip python wheel binary"" again"
4125,<desc> moved ols regression implementation from numerical methods to machine learning folder. fixed variable names to avoid mis-representation by doxygen added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines </desc> <cmt> move ols regressor to machine learning folder </cmt> <cmt> updating directory.md </cmt> <cmt> use better test function names to avoid conflict </cmt> <cmt> use better test data variable names to avoid conflict </cmt>,ols regressor should be considered an ml algorithm and not a numerical method
4126,"<desc> this fixes an issue with extends where the instantiation of a class-like ""constructor"" function used as a base class fails when the construct signature returns a type parameter default. this also fixes an issue where we were not reporting a grammar error for an empty type argument list in a heritage clause. fixes #16211 </desc> <cmt> fix grammar check for empty type argument list and compiler crash </cmt> <cmt> fix constructor instantiation with defaults </cmt> <iss> cannot extend from type which constructs intersection of type parameter with a default </iss>",fix 'extends' with type parameter default returned from superclass construct signature
4127,<desc> i have used the style of the <dialog> element in chrome as a baseline: </desc> <cmt> [modal] make the modal style more naked </cmt> <cmt> fix typo changelog </cmt> <cmt> remove noise from the console in dev mode </cmt> <cmt> fix eslint error </cmt> <cmt> make codesandbox edit work again </cmt>,"make the modal demo style more ""agnostic"""
4128,<desc> this is more hotfix than proper fix but this allows new clusters to be initialised even without ssl enabled. more details about issue in #18884 dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) </desc> <cmt> change from string null to nil </cmt> <cmt> bump version </cmt> <cmt> set ssl off </cmt>,fix initialisation of cluster when ssl is disabled
4129,<desc> this builds on top of #16237 to better address #14528. this pr focused on adding more explicit warnings while not changing the code of the examples. updating the examples to rewrite them to use permutation_importance can be done in another pr to be able to quickly merge this one. </desc> <cmt> warn about misleading cardinality bias for feature_importances_ in tree docstrings </cmt> <cmt> more explicit warning in the ensemble documentation </cmt> <cmt> small improvement to permutation_importance.rst </cmt> <cmt> add warning in the api doc for the feature_importances_ attribute </cmt>,doc more explicit warnings about the misleading use of impurity-based feature_importances
4130,"<desc> this is related to #22116. a number of modules (reindex, etc) use the rest client. the rest client opens connections using the apache http client. to avoid throwing securityexception when using the securitymanager these operations must be privileged. this is tricky because connections are opened within the httpclient code on its reactor thread. the way i confronted this was to wrap the creation of the client (and creation of reactor thread) in a doprivileged block. the new thread inherits the existing security context. </desc> <cmt> add privilege to the starting of http client </cmt>",wrap rest httpclient with doprivileged blocks
4131,"<desc> see #161 and #162. </desc> <cmt> d3.min & d3.max: pass index and array to accessor. </cmt> <cmt> fixes #162. </cmt> <cmt> d3.min & d3.max: ignore nan at [0]. </cmt> <cmt> note: this now returns infinity and -infinity for zero-element arrays, whereas </cmt> <cmt> previously an error would have occurred. </cmt> <cmt> fixes #161. </cmt>",fixes for d3.min and d3.max.
4132,"<desc> if a celery worker is segmented from a cluster and is told to die, it will try very aggressively to connect to the transport that may or not exist at this point. this can add a bit of time to shutdown procedures and usually ends up just getting sigkill'd by the init/supervisor regardless. this change makes it so that the worker-offline is still sent, but if it is lost, just accept it and die peacefully by setting retry=false on the worker-offline message. in cases where a cluster is still fully operational from the segmented worker, it will track the worker as lost by heartbeats instead of the offline message. </desc> <cmt> if worker-offline event fails to send, give up and die peacefully </cmt> <cmt> add test for retry= and msgs in heartbeat </cmt>",give up sending a worker-offline message if transport is not connected
4133,"<desc> this relands #65966, which was reverted by #66027. the reason for the reversion was a broken scuba test (see b/168761772).  i made an auxiliary fix in the original pr not directly related to the issue, and it seems that bug was relied upon by a dependent app.  i think the real solution there is a more complicated fix, which i'm tracking in the new issue #66050.  i've also added a new test here that should catch the problem before running post submit tests in the future. in the meantime, let's reland this so that the original layout bug #65572 will be fixed. related issues #65572 b/168761772 #66050 </desc> <cmt> revert ""revert ""textfield constrained layout bug (#65966)"" (#66027)"" </cmt> <cmt> this reverts commit 48ba488d33a457a1faab84f7cef55d7fbecb8771. </cmt> <cmt> remove fixbelow bugfix and open an issue for it </cmt>","reland ""textfield constrained layout bug (#65966)"""
4134,<desc> new features apis add support for double grad computation in reduce sum op. </desc> <cmt> set default value to strategy in distributed_optimizer test=develop </cmt> <cmt> set default value to strategy in distributed_optimizer test=develop </cmt> <cmt> add unittest </cmt> <cmt> add unittest test=develop </cmt> <cmt> merge </cmt> <cmt> update </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> merge </cmt> <cmt> support reduce_sum double grad test=develop </cmt>,add double grad in reduce sum
4135,"<desc> minor fixes to provisioning script: moved invoke-vcvarsall to osquery_utils.ps1 so all provisioning scripts can use it force set tls 1.2 in osquery_utils.ps1 explicitly check perl install to make sure incompatible version is not used clean up external executions for things like .bat scripts and 7z, nmake, etc </desc> <cmt> fixes to openssl provisioning script </cmt> <cmt> clean up external executions </cmt>",update win64 openssl provisioning script
4136,<desc> these changes are needed so that we can queue non-actor tasks as they are received at the executing workers. the changes will also facilitate work stealing (see pr #10607 ). the changes do not affect the way in which actor tasks are handled. the changes in this pr are required to simplify pr #10607 </desc> <cmt> separated adding tasks to queue and executing them (worker side) </cmt> <cmt> linting </cmt>,queueing non-actor tasks at the workers
4137,<desc> remove overloadchoicekind::basetype and re-introduce a couple of assertions. </desc> <cmt> [cs] nfc: remove overloadchoicekind::basetype </cmt> <cmt> this doesn't appear to be used any more. </cmt> <cmt> [cs] re-introduce some assertions </cmt> <cmt> these fixmes appear to now be outdated. </cmt> <cmt> this commit also adds an additional assertion in </cmt> <cmt> bindtypevariable. </cmt>,a couple of minor cleanups
4138,"<desc> hi oleksii, i've created a folder for ml in algorithms and added knn to it. added tests in tests folder, and they are running with full code coverage. i have created a readme explaining the algorithm. also i've added knn to the main readme with link. please do have a look and tell if anything else needs to be done. thanks, avi </desc> <cmt> updated knn and readme </cmt> <cmt> update readme.md </cmt>",adding k nearest neighbor to ml folder in algorithms with readme and tests
4139,"<desc> implement callbacks to collect worker stats in node manager. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> callback status canceld when collecting worker stats </cmt> <cmt> add get core worker stats handler in core worker </cmt>",collecting worker stats in node manager and implement webui display in the backend
4140,<desc> all system examples now use the sx prop in the examples instead of the deprecated box props. the basics page is not converted as it will be updated in a dedicated pr together with the other necessary updates in the content. </desc> <cmt> converted border demos </cmt> <cmt> displays examples converted </cmt> <cmt> flexbox examples converted </cmt> <cmt> converted palette examples </cmt> <cmt> positions examples converted </cmt> <cmt> visuallyhidden & shadows examples converted </cmt> <cmt> sizing examples converted </cmt> <cmt> spacing examples converted </cmt> <cmt> typography examples updated </cmt> <cmt> prettier </cmt>,update system pages to use sx prop instead of deprecated box props
4141,"<desc> commit message: remove envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2 multiplexing http connections (http/2, http/3) will always be sent a goaway when the overload action for disabling connection keepalive triggers. risk level: low testing: ran affected tests docs changes: n/a release notes: documented removed override platform specific features: n/a fixes #16010 </desc> <cmt> remove deprecated override </cmt> <cmt> remove deprecated override </cmt> <cmt> envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2. </cmt> <cmt> multiplexing http connections (http/2, http/3) will always be sent a </cmt> <cmt> goaway when the overload action for disabling connection keepalive </cmt> <cmt> triggers. </cmt> <cmt> document removed runtime override </cmt> <iss> envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2 deprecation </iss>",remove override for http/2 goaway
4142,"<desc> the commits below speed up retrieval of metadata during files mode in the video library by using a single query (or 2) based on the path being retrieved, rather than a separate query per item. speed up is reasonably significant with many items in a folder, and is generally faster even when only 1 item exists in the folder. please review for sanity - will commit in a day or two if no issues pop up. </desc> <cmt> use a single query for retrieving playcounts to speed up file listings </cmt> <cmt> make sure paths with content set are imported from xml prior to importing media, ensuring we can set the basepath correctly </cmt> <cmt> change addpath so it checks for a previously existing path and make it public </cmt> <cmt> add an extra column to the video database with the parent path id to allow faster lookup of items by folder </cmt> <cmt> update comment with note regarding items in a folder with content set that aren't yet in the db </cmt> <cmt> speed up retrieval of library info when browsing by file </cmt>",use a single query for playcounts/metadata in files views
4143,"<desc> desktop plugins with a pure dart implementation should generate a plugin class in the generated registrant. this change adds a dartpluginclass value that is not currently used, but in the future will be used to register a dart implementation of the plugin. related issues part of #52267. added a test to plugins_test.dart to make sure native files are not created. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide </desc> <cmt> working implementation with a couple of clean up </cmt> <cmt> fix and add testes </cmt> <cmt> fix test </cmt> <cmt> update comment </cmt>",don't generate native registrant classes if no pluginclass is defined
4144,<desc> new features apis add iterabledataset support for multiprocess dataloader add paddle.io.iterabledataset base class add paddle.io.get_worker_info to get worker process information for data splitting in iterabledataset </desc> <cmt> add iterabledataset support in multiprocess dataloader. test=develop </cmt> <cmt> fix single process exit. test=develop </cmt>,add iterable dataset support for multiprocess dataloader
4145,<desc> re: mozilla#458 </desc> <cmt> pull upstream to alison's fork july 4 </cmt> <cmt> pull upstream to fork 7.22.18 </cmt> <cmt> pull from upstream 7.29.18 </cmt> <cmt> ports propagating query execution errors from celery tasks properly </cmt> <cmt> re: </cmt>,propagate query execution errors from celery tasks properly
4146,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. </desc> <cmt> added missing $filter overload </cmt> <cmt> added missing $filter overload that allows multiple strings to translate and returns an object </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> make visitor.id optional </cmt> <cmt> update tests </cmt>",pendo.io - make visitor.id optional in initialize()
4147,"<desc> historically only two extra activities happened in the final reduction: empty buckets were filled, and pipeline aggs were reduced (since it was the final reduction, this was safe).  usage of the final reduction is growing however.  auto-date-histo might need to perform many reductions on final-reduce to merge down buckets, ccs may need to side-step the final reduction if sending to a different cluster, etc having pipelines generate their output in the final reduce was convenient, but is becoming increasingly difficult to manage as the rest of the agg framework advances. this commit decouples pipeline aggs from the final reduction: introduces a new ""top level"" reduce, which should be called at the beginning of the reduce cycle (e.g. from the searchphasecontroller) adds a materializepipeline() method to internalaggs and internalmultibucket.  this is essentially the final reduce for pipelines makes reductions on pipelines a no-op by separating pipeline reduction into their own set of methods, aggregations are free to use the final reduction for whatever purpose without worrying about generating pipeline results which are non-reducible closes #44914, predecessor pr was #45359 </desc> <cmt> decouple pipeline reductions from final reduction </cmt> <cmt> historically only two things happened in the final reduction: </cmt> <cmt> empty buckets were filled, and pipeline aggs were reduced (since it </cmt> <cmt> was the final reduction, this was safe).  usage of the final reduction </cmt> <cmt> is growing however.  auto-date-histo might need to perform </cmt> <cmt> many reductions on final-reduce to merge down buckets, ccs </cmt> <cmt> may need to side-step the final reduction if sending to a </cmt> <cmt> different cluster, etc </cmt> <cmt> having pipelines generate their output in the final reduce was </cmt> <cmt> convenient, but is becoming increasingly difficult to manage </cmt> <cmt> as the rest of the agg framework advances. </cmt> <cmt> this commit decouples pipeline aggs from the final reduction: </cmt> <cmt> 1. introduces a new ""top level"" reduce, which should be called </cmt> <cmt> at the beginning of the reduce cycle (e.g. from the searchphasecontroller) </cmt> <cmt> 2. adds a materializepipeline() method to internalaggs and </cmt> <cmt> internalmultibucket.  this is essentially the final reduce </cmt> <cmt> for pipelines </cmt> <cmt> 3. makes reductions on pipelines a no-op </cmt> <cmt> by separating pipeline reduction into their own set of methods, </cmt> <cmt> aggregations are free to use the final reduction for whatever </cmt> <cmt> purpose without worrying about generating pipeline results </cmt> <cmt> which are non-reducible </cmt> <cmt> remove unnecessary doreduce() </cmt> <cmt> add assertions, javadoc </cmt> <iss> auto_date_histogram fails where date_histogram does not </iss>",decouple pipeline reductions from final agg reduction
4148,"<desc> the first commit in this pr closes #11287 by adding a ""subscribe to releases on libraries.io"" link to the ""what's new"" page: i also noticed that there is no link to the changelog/what's new page from the </desc> <cmt> doc add ""subscribe to releases on libraries.io"" tip to whats_new page </cmt> <cmt> doc add ""what's new"" and libraries.io links to readme </cmt> <iss> include ""subscribe to releases on libraries.io"" in docs </iss>",doc add libraries.io and changelog links
4149,"<desc> the new ops based recovery, introduce as part of  #10708, is based on the assumption that all operations below the global checkpoint known to the replica do not need to be synced with the primary. this is based on the guarantee that all ops below it are available on primary and they are equal. under normal operations this guarantee holds. sadly, it can be violated when a primary is restored from an old snapshot. at the point the restore primary can miss operations below the replica's global checkpoint, or even worse may have total different operations at the same spot. this pr introduces the notion of a history uuid to be able to capture the difference with the restored primary (in a follow up pr). the history uuid is generated by a primary when it is first created and is synced to the replicas which are recovered via a file based recovery. the pr adds a requirement to ops based recovery to make sure that the history uuid of the source and the target are equal. under normal operations, all shard copies will stay with that history uuid for the rest of the index lifetime and thus this is a noop. however, it gives us a place to guarantee we fall back to file base syncing in special events like a restore from snapshot (to be done as a follow up) and when someone calls the truncate translog command which can go wrong when combined with primary recovery (this is done in this pr). we considered in the past to use the translog uuid for this function (i.e., sync it across copies) and thus avoid adding an extra identifier. this idea was rejected as it removes the ability to verify that a specific translog really belongs to a specific lucene index. we also feel that having a history uuid will serve us well in the future. last the pr also tightens up the connection between the checkpoint file, it's translog and it's lucene index by adding both the translog uuid and the history uuid to it and verifying on read. ps i still want to go through the test and make sure the coverage is good enough. i also want to validate the bwc logic that will only run properly on ci once this is backported. that said, i think we can start reviewing. </desc> <cmt> added a history uuid to engine/translog infra </cmt> <cmt> fix truncatetranslogcommand dir locking </cmt> <cmt> fix flush docs </cmt> <cmt> make history uuid a requirement for ops based recovery </cmt> <cmt> tighten up reading global checkpoint reading </cmt> <cmt> fix peerrecoverysourceservice or peerrecoverytargetservicetests </cmt> <cmt> testdifferenthistoryuuiddisablesopsrecovery </cmt>",introduce a history uuid as a requirement for ops based recovery
4150,<desc> following up on #1120 </desc> <cmt> remove py2 compatibility code from fasthttp </cmt> <cmt> remove six py2 compatibility usage </cmt> <cmt> remove some py2 compatibility code </cmt> <cmt> remove six dependency </cmt> <cmt> update readme to reflect that we dont support 2.7 any more. </cmt>,remove six and other 2.7 compatibility code
4151,"<desc> with this pr, given a variable x of type unknown, the pattern x && typeof x === 'object' narrows x to object. previously we'd narrow to object | null because a truthiness check applied to unknown is still unknown (and unknown includes null). note that this is a targeted fix for a relatively common pattern. in an ideal world we'd be able to accurately represent types that are known to be truthy, but we currently don't have that ability. fixes #36870. </desc> <cmt> for x && typeof x === 'object', narrow x to just type object </cmt> <cmt> add tests </cmt> <iss> truthy check loses effect based on position in ""&&"" chain </iss>",narrowing from truthy unknown to object
4152,"<desc> currently, the new scheduler only spills back from tasks that are ""pending"" scheduling. once the task has been scheduled to the local node, they are not spilled back again. this can cause load balancing tests to fail when a task is assigned to a node that doesn't have enough resources to run, but there are enough resources on a different node. this happens in test_actor_advanced::test_actor_lifetime_load_balancing in the following order: actor creation tasks a and b are queued by and scheduled to node 1. only one actor can live on the node at a time. node 1 starts a worker. node 1 assigns task a, b cannot run. this pr fixes the above scenario by rerunning the spillback policy on tasks that have been assigned to the local node. it spills back at most one queued task per resource shape per call to dispatchscheduledtaskstoworkers. note that this call is currently triggered once per remote node heartbeat received (in addition to local state transitions), so it is probably inefficient but it will guarantee that a task that is stuck in the local queue will eventually get spilled back. i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> spillback from dispatch queue and refactor </cmt> <cmt> unit test </cmt> <cmt> doc </cmt>",spillback from the queue of tasks assigned to the local node
4153,"<desc> this fixes sr-11540 by just disfavoring overloads to closures with anonymous var that are function types with more than one argument that matches arguments of no-arg function types. the first approach was to not accept cases like func foo(<t, r>(action: (t) -> r) -> void {}) match foo(action: { return }, in a way that: func foo<t, r>(action: (t) -> r) -> void {} foo(action: { return }) // expected-error {{contextual type for closure argument list expects 1 argument, which cannot be implicitly ignored}} // expected-error@-1 {{generic parameter 't' could not be inferred}} expected-error@-1{{generic parameter 'r' could not be inferred}} // is expected to be foo(action: { _ in return }) but since it broke few tests(that was actually accepting this syntax) and i was not sure if this would be a source-compatible change... so opting to just disfavor the overload disambiguate seemed like a better option :)  resolves sr-11540. </desc> <cmt> [cssimplify] difavor function type overload when trying to match no arg function type with a closure with a anonimous implicit var closure </cmt> <cmt> [tests] adding sr-11540 tests into test/expr/closure/inference.swift </cmt>",fix ambiguos overload apply to argument for contextual closure
4154,"<desc> i refactored the error message built during routes creation. previously tests were failing with node 4, but now it is ok for both stable and 4. </desc> <cmt> fix error message construction in index.js </cmt> <cmt> the error message in routes creation was not validated by eslint. </cmt> <cmt> now it is accepted as valid and every test runs well. </cmt> <cmt> fix error message for both latest and 4 node versions </cmt>",fixed eslint errors in tests
4155,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). when installing @types/fork-ts-checker-webpack-plugin in a project, its package.json is missing tslint as a dependency: ""dependencies"": { ""@types/webpack"": ""*"", ""@types/node"": ""*"" }, i'm not sure why tslint is not included in here, but from reading the documentation, i can manually add dependencies by creating a package.json file here, so i did that. let me know if there's a better way to go about this! </desc> <cmt> add tslint dependency to fork-ts-checker-webpack-plugin package.json </cmt> <cmt> add private:true prop to package.json </cmt>",[fork-ts-checker-webpack-plugin]: add missing tslint dependency
4156,<desc> relevant code from v3.5.17 of d3 ticksubdivide:  pie.sort allows null comparator:  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: urls above </desc> <cmt> d3: add ticksubdivide type to axis </cmt> <cmt> d3: allow null comparator for pie.sort </cmt> <cmt> d3: add test for ticksubdivide </cmt>,add ticksubdivide type to axis and allow null comparator for pie.sort
4157,"<desc> closes ##21471 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry this error related to pr #21249 and #21227. this is never supported use case and to use file-handle in to_csv with compression, the file-object itself should be a compression archive such as: with gzip.open('test.txt.gz', 'wt') as f: pd.dataframe([0,1],index=['a','b'], columns=['c']).to_csv(f, sep='\t') regressed to 0.22 to_csv with support for zipfile. zipfile doesn't support writing csv strings to a zip archive using a file-handle. so buffer is used to catch the writing and dump into zip archive in one go. the other scenarios remain unchanged. </desc> <cmt> implement closed attribute for py2 </cmt> <cmt> revert pr 21249 </cmt> <cmt> revert pr 21249 </cmt> <cmt> use _get_handle to produce a handle </cmt> <cmt> use _get_handle to produce file handle </cmt> <cmt> regression to 0.22 and add zipfile support </cmt>",file-handle object handled incorrectly in to_csv
4158,"<desc> please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change </desc> <cmt> add sparse block </cmt> <cmt> add sparse embedding </cmt> <cmt> add doc </cmt>",gluon sparse block and sparse embedding
4159,"<desc> this pr fixes the case where two applications use the same default storage key but they provide different custom color schemes. for example, app 1: support light, dark, and orange app 2: support light, dark, and yellow if you select orange in app 1 and then open app 2, it will break because they share the same storage key. this pr fixes this edge case by fallback to the default color scheme if the value in storage is not a supported color scheme. i have followed (at least) the pr section of the contributing guide. </desc> <cmt> fix no colorscheme case </cmt> <cmt> add edge case test </cmt>",fix colorscheme conflict between application
4160,"<desc> when executing an escape sequence that might cause the viewport to scroll, a check is made to see whether the cursor position is in the bounds of the scroll margins, otherwise the scroll operation shouldn't happen. in a couple of cases (in the ri, dl, and il escape sequence), these boundary tests were incorrect, so the scroll operation would sometimes not occur when it should have. this pr fixes those boundary tests. tested manually, and with the joe editor which was previously failing, and with some additional screen buffer unit tests. closes #1366 cla signed. if not, go over here and sign the cla requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #1366 the one problem was the use of viewport::isinbounds method to check whether the cursor was inside the margins. that method only works on the first column of the screen, because the horizontal margins are always set to 0. so that needed to be replaced with a test that only checked the y offset against the vertical margins. the other problem was not first checking whether the margins had actually been set. when the margins aren't set, the top and bottom boundaries are both 0, so that needs to be handled as a special case, otherwise it'll only match positions on the first line of the screen. having made these fixes in the dosrvprivatereverselinefeed and dosrvprivatemodifylinesimpl methods, i thought it might also be a good idea to refactor the boundary tests into a shared method in the screen_information class, to try and make the code more readable. i could also then make use of that method to simplify the dosrvmovecursorvertically implementation a little. i had initially planned to refactor the adjustcursorposition method as well, but i decided against that in the end, because the code is a lot more complicated in that case, and i didn't want to risk potential performance issues given the frequency of its use. in any event, i've committed the refactoring as a separate step, so i can always revert that if you don't think it's a good idea. i've added a few screen buffer units tests that make sure the ri, dl, and il escape sequences basically work, and also specifically check the conditions that were previously failing. i've also run a few of my own manual tests which check various margin boundary conditions. and i've made sure that the problem with joe editor that was reported in issue #1366 is now working. </desc> <cmt> fix margin boundary tests in the ri, dl, and il sequences. </cmt> <cmt> refactor the margin boundary tests into a reusable screen_information method. </cmt> <cmt> add screen buffer unit tests for the ri, dl, and il sequences. </cmt> <iss> screen margins and scrolling regions are acting strange for the joe editor </iss>","fix margin boundary tests in the ri, dl, and il escape sequences."
4161,"<desc> ne2000 was broken because the os thought the link was always down. fixed that and improved a few things, see the commits. sorry for the archeology, but this seemed like nice stuff for me to get more acquainted with the project :) </desc> <cmt> kernel/ne2000: correct receive ring buffer wrap-around </cmt> <cmt> next_packet_page points to a page, but was being compared to a byte </cmt> <cmt> offset rather than a page offset when adjusting the boundary register </cmt> <cmt> when the ring buffer wraps around. </cmt> <cmt> fixes #8327. </cmt> <cmt> kernel/ne2000: assume link status is up </cmt> <cmt> right now, ne2000 nics don't work because the link is down by default </cmt> <cmt> and this will never change. of all the ne2000 documentation i looked </cmt> <cmt> at i could not find a link status indicator, so just assume the link </cmt> <cmt> is up. </cmt> <cmt> kernel/ne2000: harvest entropy from ne2000 interrupts </cmt> <cmt> meta/run.sh: allow for overriding of qemu ethernet device type </cmt> <cmt> you can set the serenity_ethernet_device_type environment variable to </cmt> <cmt> pick another device type (i.e. ne2k_pci). defaults to e1000 as before. </cmt>",ne2000 working again and improved
4162,"<desc> fix #7161 org.apache.dubbo.config.sslconfig#getserverkeycertchainpathstream  each call will create a new stream,should be closed after use. public inputstream getserverkeycertchainpathstream() throws ioexception { if (serverkeycertchainpath != null) { serverkeycertchainpathstream = ioutils.geturl(serverkeycertchainpath).openstream(); } return serverkeycertchainpathstream; } make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. add some description to dubbo-website project if you are requesting to add a feature. if this contribution is large, please follow the software donation guide. </desc> <cmt> fix netty ssl file leak </cmt> <cmt> remove useless code </cmt>",[master]fix netty ssl file leak
4163,"<desc> the title says it all. rdar://28851920 </desc> <cmt> [semantic-arc] wire up parsing/printing/irgen/serialization/deserialization for copy_value, destroy_value. </cmt> <cmt> rdar://28851920 </cmt> <cmt> [semantic-arc] implement ownershipmodeleliminator support for copy_value, destroy_value. </cmt> <cmt> rdar://28851920 </cmt> <cmt> [gardening] refactor out setting insertion point and debug scope from each visitor to beforevisit in the ownershipmodeleliminator. </cmt>",ownership model eliminator support for copyvalueinst and destroyvalueinst
4164,<desc> i have followed (at least) the pr section of the contributing guide. the following demos of the transfer list component were migrated: basic transfer list enhanced transfer list related to #16947 </desc> <cmt> docs: migrate basic transfer lsit demo to emotion </cmt> <cmt> docs: migrate enhanced transfer list demo to emotion </cmt>,migrate transfer list demos to emotion
4165,"<desc> fixes use of the wrong exception name in openssl_certificate_info, and makes openssl_csr always use crypto_utils.load_certificate_request(). both changes get no changelog since they affect code new for 2.8. openssl_certificate_info openssl_csr </desc> <cmt> fix wrong exception name. </cmt> <cmt> use crypto_utils.load_certificate_request() to load csrs with both backends. </cmt>","fix wrong exception, and little refactoring"
4166,<desc> as the datastream information is stored in the clusterstate.metadata we exposed the metadata to the asyncwaitstep#evaluatecondition method in order for the steps to be able to identify when a managed index is part of a datastream. if a managed index is part of a datastream the rollover target is the datastream name and the highest generation index is the write index (ie. the rolled index). (cherry picked from commit 6b410df) backport of #57295 </desc> <cmt> ilm: add support for rolling over data streams  (#57295) </cmt> <cmt> as the datastream information is stored in the clusterstate.metadata we exposed </cmt> <cmt> the metadata to the asyncwaitstep#evaluatecondition method in order for </cmt> <cmt> the steps to be able to identify when a managed index is part of a datastream. </cmt> <cmt> if a managed index is part of a datastream the rollover target is the datastream </cmt> <cmt> name and the highest generation index is the write index (ie. the rolled index). </cmt> <cmt> (cherry picked from commit 6b410dfb78f3676fce1b7401f1628c1ca6fbd45a) </cmt> <cmt> replace java.uitl.list.of usage </cmt>,add support for rolling over data streams (#57295)
4167,"<desc> this pr introduces several enhancements to the native filters form and some new functionalities: it shows [untitled] on the left pane when no name is entered. this is consistent with other parts of the platform it shows an error indication on the left pane when an error is generated on the fly or on save. this drags the attention of the user to the right filters where an action is required it restructures a little bit the form using the antdesign form.item wherever possible. however, the constraints of this implementation are huge and i advocate for a full refactor asap video.game.sales.4.mp4 open a dashboard with native filters enabled fill in the form and observe the behavior when an error is generated includes db migration (follow approval process in sip-59) </desc> <cmt> implement errored filters </cmt> <cmt> clean up </cmt>",highlight errored filters on the left pane of the native filters form plus several enhancements
4168,"<desc> this pr fixes the issue where collapsing the side bar in demo mode shifted the demo header instead of leaving it in place. now, when collapsing and expanding the sidebar, the header stays in place and does not move. fixes jira grw-111 </desc> <cmt> header changes </cmt> <cmt> remove artificial delay </cmt>",fix demo header margin when collapsing and expanding
4169,"<desc> issue: #6604 #6605 the react-native storybook ui is lagging web. @domyen and others want to help but are not familiar with react-native. to make things easier, we'd like to use emotion just like on web to make it easier to contribute style changes. migrate the react-native codebase over from stylesheet to emotion. in a few places, the type of some components is manually annotated. that's temporary until emotion-js/emotion#1176 lands. one nice side effect of this change is that the ui becomes themeable almost for free. out of scope these changes do not include any visual changes. visual improvements will be implemented in a follow up pr. </desc> <cmt> add emotion dependency </cmt> <cmt> update ondeviceui/addons to use emotion </cmt> <cmt> update ondeviceui/navigation to use emotion </cmt> <cmt> update remaining ondeviceui to use emotion </cmt> <cmt> update storylistview to use emotion </cmt> <cmt> update storyview to use emotion </cmt> <cmt> rm remaining style files </cmt>",use emotion to style react-native ui
4170,"<desc> it turns out that in rare cases, ensureresources can fail. it's not currently known what can cause it. but the outcome of when it fails is that we hit an error accessing properties on an undefined object.  so this fix at least throws an error in render and doesn't try to render the app causing misleading errors. addresses #19959 </desc> <cmt> fix(gatsby): ensure that ensureresources ensures resources </cmt> <cmt> test </cmt>",improve error message when ensureresources fails to ensure a resource
4171,<desc> i hereby agree to the terms of the cla available at:  non-significant (changelog entry is not required) processors pipeline for reading from other storages. </desc> <cmt> processors support for storagedictionary. </cmt> <cmt> processors support for storagedistributed reading. </cmt> <cmt> processors support for storagefile reading. </cmt>,more processors for storage::read
4172,"<desc> this fixes a regression compared to fastcomp/emterpretify. enables browser.test_sdl_audio_beep_sleep on upstream. fixes #9823 </desc> <cmt> add sleep callbacks in asyncify, and use them for sdl audio. fixes #9823 </cmt> <cmt> fix </cmt> <iss> asyncify behaving differently then emterpreter </iss>","add sleep callbacks to asyncify, allowing sdl audio to automatically update"
4173,"<desc> you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? added a new extractor for the unity platform [ this site provides a number of free video tutorials for unity, a popular content creator for 3d games and apps. cheers and thank you! parmjit v. </desc> <cmt> [unity] add new extractor </cmt> <cmt> [unity] corrected test description field </cmt>",add new extractor (fixes issue #14528)
4174,"<desc> align redis chart documentation/readme to actual defaults. as shown here, the real default for master.service.type is clusterip, not loadbalancer. </desc> <cmt> fix docs to reflect actual default in values.yaml </cmt> <cmt> bump chart patch </cmt>",fix readme for master service type
4175,<desc> we are not going to support 32-bit platforms. but this pr adds 32-bit tests (gcc and clang). fixes #976 </desc> <cmt> permit 32-bit gcc compilation </cmt> <cmt> minor fixes to avoid 32-bit warnings. </cmt> <cmt> minor fixes to avoid 32-bit warnings. </cmt> <cmt> permit 32-bit gcc compilation </cmt> <cmt> patching things up and adding tests. </cmt> <iss> check for 32-bit mingw to permit r distribution on windows </iss>,fix for issue 976 (something like 32-bit support)
4176,"<desc> the showdialog function takes a context parameter. that parameter is used to get the current theme.of(context) when showdialog is called. the showdialog dart docs say that after showdialog is called, its widget can safely be removed from the tree, since context is only used when the method is called. this was not actually true, since the theme.of(context) call was happening inside the pagebuilder, even though the context being used was from the original function call. this meant that it was possible for theme.of(context) to be called with an already deactivated build context, throwing an error. related issues fixes #28505 i added the following tests: // regression test for  testwidgets('showdialog only gets theme from context on the first call', (widgettester tester) async { widget buildframe(key builderkey) { return materialapp( home: material( child: center( child: builder( key: builderkey, builder: (buildcontext outercontext) { return raisedbutton( onpressed: () { showdialog<void>( context: outercontext, builder: (buildcontext innercontext) { return const alertdialog(title: text('title')); }, ); }, child: const text('show dialog'), ); }, ), ), ), ); } // first time build. await tester.pumpwidget(buildframe(uniquekey())); // open the dialog. await tester.tap(find.bytype(raisedbutton)); await tester.pumpandsettle(); // second time build. await tester.pumpwidget(buildframe(uniquekey())); // app crashes when we try to open the dialog, because it tries to get the // theme from the old context. await tester.tap(find.bytype(raisedbutton)); }); before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> fix bug, add regression test. </cmt> <cmt> remove unnecessary space </cmt> <iss> showdialog is using the wrong context </iss>",fix showdialog crasher caused by old contexts
4177,<desc> added riot and svelte to the list of supported frameworks and added the a11y addon to all of the framework examples. modified the waiting text to use the word accessibility rather than a11y is this testable with jest or chromatic screenshots? yes does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no </desc> <cmt> modified the waiting text to use the word accessibility rather than a11y </cmt> <cmt> added a11y addon to the angular example </cmt> <cmt> added a11y addon to the cra example </cmt> <cmt> added a11y addon to the cra ts example </cmt> <cmt> added a11y addon to the html example </cmt> <cmt> added the a11y addon to the marko example </cmt> <cmt> added the a11y addon to the mithril example </cmt> <cmt> added the a11y addon to the polymer example </cmt> <cmt> added the a11y addon to the preact example </cmt> <cmt> added the a11y addon to the riot example </cmt> <cmt> added the a11y addon to the svelte example </cmt> <cmt> added the a11y addon to the vue example </cmt> <cmt> updated the addon support documentation </cmt>,add a11y examples and documentation
4178,<desc> provide type of key and value of key in std::out_of_range exception adds an additional requirement that key is streamable </desc> <cmt> add tuple_io include needed by chainbase key streaming </cmt> <cmt> update chainbase to unkown-key branch </cmt>,additional info for unknown key exceptions
4179,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> fix mousetrapstatic returned type </cmt> <cmt> fix mousetrapinstance returned type </cmt>",fix different from the actual return types
4180,<desc> closes #23216 freq inference is pure overhead for the series/dataframe op because freq gets discarded. </desc> <cmt> api: infer freq in fewer arithmetic ops </cmt> <cmt> dont need separate path </cmt> <iss> api: which datetimeindex/timedeltaindex ops should infer frequency? </iss>,dont infer freq in dta/tda arithmetic ops
4181,"<desc> was checking the wrong parameter, causing the code to ignore provided stream-specific ssl certificate. better error handling in sslcontext and crypto. follow up on #29871. </desc> <cmt> fix streampeerssl connect_to_stream w/ custom cert </cmt> <cmt> follow up on #29871. </cmt> <cmt> was checking the wrong parameter, causing the code to ignore provided </cmt> <cmt> stream-specific ssl certificate. </cmt> <cmt> better error handling in sslcontext, crypto </cmt>",fix streampeerssl connect_to_stream w/ custom cert.
4182,"<desc> this fixes three bugs with the formatting code (used by printf et al) .. well, arguably one of them is a new feature (one called for by the spec). if you zero-pad a negative integer (as with %010d), the zeros would appear before the negative sign (00000-1977) instead of after (-000001977). this was only a bug with integers, not with floats. if you force the display of the sign on a negative integer (as with %+d), the sign would be printed twice (--1977 instead of just -1977). again, this only seemed to be a problem on integers. the ""space"" formatting flag (which is basically the same as + but prints a space instead of a positive sign) was not implemented. i've added tests for all 3 new cases. i did note however that test_printf seems to have two reference output files, one for regular and one for precise 64-bit math. however there does not seem to be a way to run the test with precise 64-bit math. it looks like there was intended to be, but i don't see a way to trigger it. as for running the existing tests, i get 7 errors (out of 2718 tests) running all core tests on the incoming branch. this is before my changes, not after. the tests with errors are default.test_bigswitch, asm1.test_cases, asm2.test_cases, asm2.test_fuzz, asm2g.test_cases, asm2g.test_fuzz, asm2x86.test_cases. with my changes, the errors are exactly the same. i did not cause any of the errors, nor am i sure what is causing them. let me know if you have any questions.. thanks! </desc> <cmt> fix bug with zero-padded negative integers </cmt> <cmt> the zero padding was before the sign. it should be after. </cmt> <cmt> fix bug with forced display of sign on negative integers </cmt> <cmt> the negative sign was displayed twice. </cmt> <cmt> implement missing 'space' formatting flag </cmt> <cmt> this flag causes space (padding) to be reserved for the sign even if the </cmt> <cmt> number is positive. it is basically the same as the 'plus' flag except that </cmt> <cmt> a space is displayed instead of a plus sign. the 'plus' flag takes precedence. </cmt>",fix 3 issues with formatting (printf)
4183,"<desc> following prior work done in #25836, this pr delays emitting balloon events from the tray module to avoid entering v8 during a wndproc callback. implementation details since trayicon objects are deleted when the tray gets garbage collected, we don't want the callback to be processed if the icon is gone. this pr uses weakptr references to achieve this end. this also means that the affected events won't be emitted if the wndproc callback is entered, but the trayicon is destroyed. this behaviour seems in line with electron's existing tray api design, as a reference to the tray needs to be maintained for its api to be used at all.  npm test passes pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed a rare crash on windows that could occur when emitting certain tray events. </desc> <cmt> wip? </cmt> <cmt> attempt to use weakptr </cmt> <cmt> apply posttask change to other balloon events </cmt>",delay emitting notifyicon events on windows
4184,"<desc> backport of #25018 resolves #24942 for 10-x-y npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: none </desc> <cmt> tests: fix early-in-memory-session-create crash test on woa </cmt> <cmt> ci: cleanup user app data directories on woa </cmt> <cmt> (cherry picked from commit 43106d28d8425fd3056d329957beba1503d16f22) </cmt> <cmt> renable crash tests on woa </cmt>",fix woa failing tests (10-x-y)
4185,"<desc> as per discussion in the pr azure/msrest-for-python/#145, there some issues with server responses (specially from microsoft) that have bom in it. you can see errors in the tests from my branch here reproducing the same behavior when trying to parse both text and json. this has been fixed by forcing encoding to utf-8-sig when http header has signalized utf-8 or leave to chardet when no encoding has been identified. that way the parsing works as expected and no errors are thrown. </desc> <cmt> add utf8 with bom to test </cmt> <cmt> add failing tests for bom </cmt> <cmt> fix response with utf8 bom </cmt>",fix for response with utf-8 bom
4186,"<desc> i took another look at my original markdown to json conversion scripts and realized how painfully complicated i made my life while quickly writing them. this new converter does everything the old scripts did in half the lines (two for the price of one!). plus, it looks like the original conversion wiped out any punctuation (see the json file changes), so that bug has been squashed in the new version as well. plus, this saves @jbrooksuk from having to work on pr #421 </desc> <cmt> update build script </cmt> <cmt> display format file during build </cmt> <cmt> add markdown to json converter in python3 </cmt> <cmt> remove outdated conversion scripts </cmt> <cmt> update category split logic </cmt> <cmt> update build script to use new converter </cmt> <cmt> add new starter json </cmt> <cmt> remove duplicate json build steps </cmt>","update md2json, validate_format, and validate_links"
4187,<desc> run npm run lint meteor provide a url to documentation or source code which provides context for the suggested changes:  also it should be reflected in official doc </desc> <cmt> fix accounts.onlogout declaration </cmt> <cmt> fix email's form field according to code </cmt>,fix 'from' email's field for accounts.emailtemplates.xxx.from
4188,"<desc> this relands #35297 the followings have been done to fix the broken tests: add didsendfirstframerasterizedevent extension and its tests wait for didsendfirstframerasterizedevent instead of didsendfirstframeevent during start up tests mark missed (probably newly added) start up tests as flaky </desc> <cmt> revert ""revert ""fix the first frame logic in tracing and driver (#35297)"" (#37027)"" </cmt> <cmt> this reverts commit 3068fc4f7c78599ab4a09b096f0672e8510fc7e6. </cmt> <cmt> fix start up tests </cmt> <cmt> 1. add didsendfirstframerasterizedevent extension and its tests </cmt> <cmt> 2. wait for didsendfirstframerasterizedevent instead of </cmt> <cmt> didsendfirstframeevent during start up tests </cmt> <cmt> 3. mark missed (probably newly added) start up tests as flaky </cmt>","reland ""fix the first frame logic in tracing and driver (#35297)"""
4189,"<desc> hey. this is just a draft to add gcs feed export. i followed the same behavior as the filespipeline, so i'm just using the gcs_project_id setting and it requires the developer to provide the credentials through environment variables (refer to  about the credentials above, i think we could also add a new setting with a path to the credentials file and initialize it using  the list of todos, besides your thoughts are: add documentation add gcs schema add bucket policy options please note that i worked with unit tests here, but i'm open to idea of integration tests. do you have any thoughts? thanks for your time to review this pr (edit) closes #685 </desc> <cmt> adding gcsfeedstorage </cmt> <cmt> refactoring tests </cmt> <iss> google cloud storage support (storage backends) </iss>",fix for #685 add google cloud storage feed export
4190,"<desc> to ship gatsby-source-wordpress we previously removed docker from our tests and used a live wp url. this was done because in switching from github actions to circleci, we couldn't properly expose dockers wp url to gatsby. it turns out the reason was that we were using the custom node executor that all the other gatsby integration tests are using. custom executors run in a docker container and don't allow for networking with nested docker containers (due to a security hole that would open in circleci). switching to the machine executor runs the wp tests in a linux vm which allows for proper networking between gatsby and our docker containers. that fix was simple but our test setup turned out to need a bunch of other tweaks to get things running again properly, hence the long list of commits here. </desc> <cmt> use linux vm for wp int tests </cmt> <cmt> temp comment out other tests </cmt>",feat(gatsby-source-wordpress): use docker for tests
4191,"<desc> kip files are used by some sysmodules, both homebrew and official. this is intended to be a ""first step"" towards lle emulation of services, but all this pr adds is the ability to execute kips as if the main application is a kip. this supports both compressed (with blz) and uncompressed kips. this also adds ini file parsing, which is a custom yet simple container nintendo uses to package up to 0x50 kips together. this is used internally with package 2 (to contain some of the most essential sysmodules, like fsp-srv, sm, ldr, and pm) i wrote a quick sample homebrew and used elf2kip to make a kip out of it (as an initial poc): my kip if any of you want to try it: hello world kip file i was also able to launch: a homebrew kip for a custom sysmodule -- there was activity but ofc no graphics (it was xor.play so it wasn't possible to look for a service registration) the offical kip for the settings services, v262144 -- this actually tried to register the set service and threw fatal because we already have it. if you remove yuzu's hle of set, this will register it and then wait for requests as intended, a very good sign! </desc> <cmt> file_sys: add classes to parse kip1 and ini1 files </cmt> <cmt> partition_data_manager: remove kip processing and use filesys </cmt> <cmt> previously, this tu contained the necessary headers to parse kip/ini but now it should just use the filesys class. </cmt> <cmt> program_metadata: add function to load meta from raw parameters </cmt> <cmt> needed for kip loading as kips do not have an npdm but do have the essential parts of the data within. </cmt> <cmt> loader: add apploader_kip for kip files </cmt> <cmt> loader: add kip and ini file parser-specific errors </cmt> <cmt> loader: add recognition for kip file type </cmt> <cmt> game_list: accept *.kip as a file extension of executables </cmt>",add support for parsing and loading kip (kernel internal process) files
4192,<desc> this pr is a follow up fix to #44730. the pr implements a more thorough check to ensure references are non-mutable when they are narrowed by aliased conditional expressions. for example: function test(obj: { readonly x: string | number }) { const isstring = typeof obj.x === 'string'; obj = { x: 42 }; if (isstring) { let s: string = obj.x;  // not narrowed because obj is assigned in function body } } previously we'd just check that x is readonly. now we also check that obj isn't assigned in the function body. </desc> <cmt> check entire access path is constant when narrowing by inlining </cmt> <cmt> add tests </cmt> <cmt> accept new baselines </cmt>,fix constant reference check in cfa
4193,"<desc> fixes #32984 </desc> <cmt> add test case </cmt> <cmt> fix infer from usage property assignment </cmt> <cmt> property assignment and shorthand property assignment were incorrectly </cmt> <cmt> treated differently; both have objectliteralexpression as a parent, but </cmt> <cmt> the code previously assumed that property assignments had </cmt> <cmt> objectliteralexpression as parent.parent. </cmt> <cmt> also make fourslash directives case insensitive and less whitespace </cmt> <cmt> sensitive. </cmt> <iss> crash: infer from usage on create-react-app </iss>",fix infer from usage prop assignment
4194,"<desc> when updating sprite with different region of the same texture, region of existing particles is not updated. this change will call setregion on all active particles to update textureregion. this should fix #4496 </desc> <cmt> added particle emitter sprite change test </cmt> <cmt> update particle region </cmt> <cmt> fixes #4496 </cmt> <iss> unable to change particles sprite after spawn </iss>",fix particle emitter sprite update
4195,"<desc> add following awesome python packages: python-stop-words: get list of common stop words in various languages in python. python-currencies: display money format and its filthy currencies, for all money lovers out there. django-markwhat: a collection of template filters that implement common markup languages. short_url: python implementation for generating tiny url- and bit.ly-like urls. sanitize: bringing sanity to world of messed-up data. </desc> <cmt> add python-stop-words </cmt> <cmt> get list of common stop words in various languages in python. </cmt> <cmt> add python-currencies </cmt> <cmt> display money format and its filthy currencies, for all money lovers out there. </cmt> <cmt> add django-markwhat </cmt> <cmt> a collection of template filters that implement common markup languages. </cmt> <cmt> add short_url </cmt> <cmt> python implementation for generating tiny url- and bit.ly-like urls. </cmt> <cmt> add sanitize </cmt> <cmt> bringing sanity to world of messed-up data. </cmt>","add stop-words, currencies, django-markwha, short_url, sanitize"
4196,<desc> sorry @bvaughn and @gaearon. we can add it back. some of the concepts are changing. e.g. getting the current priority level isn't as obviously going to be in the same place. priority field on update isn't useful anymore since the lanes convey more info. this code is also in all the places moving around. it'll be easier to just add this back than to try to keep them each time they move. </desc> <cmt> remove priority field from tracing </cmt> <cmt> remove debugtracing mode from new reconciler (temporarily) </cmt> <cmt> run debugtracing tests in the *other* variant so it's no on for new reconciler </cmt>,temporarily remove debugtracing from the new reconciler
4197,"<desc> with this pr, we now support overload resolution when the tag of a tagged template has multiple signatures. type argument inference when performing overload resolution on a signature. </desc> <cmt> initial work on overload resolution with tagged templates. </cmt> <cmt> currently type argument inference breaks hard when the first parameter of a tag has a generic type. </cmt> <cmt> conflicts: </cmt> <cmt> tests/baselines/reference/taggedtemplatestringswithincompatibletypedtags.errors.txt </cmt> <cmt> proper type arg inference with apppropriate overload res tests. </cmt> <cmt> corrected comment. </cmt>",type checking for tagged template expressions
4198,<desc> backport of #7380 </desc> <cmt> [gui] introduce a dialog modality type to differ between modalities </cmt> <cmt> in some cases it happens that the busy dialog is already open before the window activation kicks in. </cmt> <cmt> this will results in a refuse of the activation and some pain for different addon devs because they need to hack around that issue. </cmt> <cmt> this is an attempt to overcome the root cause. it adds a new dialog modality type as a replacement for the current modal flag and </cmt> <cmt> specifed a new type system_modal which is left-out at the check in cguiwindowmanager::activatewindow_internal </cmt> <cmt> [gui] adjusts log level for the window activation refused message </cmt> <cmt> [cosmetics] removes left-over enum window_type in cguiwindow </cmt>,fix activation of window if top most modal is dialog busy
4199,"<desc> the viewsets and routers use both base_name and basename. it would be nice if this were consistent. i've deprecated base_name in favor of basename, and get_default_base_name in favor of get_default_basename. fortunately, the deprecation is fairly straightforward. router.register needs to handle both arguments appropriately (fallback to the old value if present, raise deprecation warnings, complain if both arguments are provided) django has a deprecation utility metaclass that already handles method renames. </desc> <cmt> rename base_name => basename for consistency </cmt> <cmt> update tests to use basename </cmt>",rename base_name => basename for consistency's sake
4200,<desc> updated generate_opcode_h.py. i made the little changes in the header of generate_opcode_h.py. which might be helpful for other to understand the flow of generation of opcode.h </desc> <cmt> updated </cmt> <cmt> updated latest </cmt> <cmt> updated </cmt> <cmt> updated header in generate_opcode_h.py </cmt> <cmt> run make regen-all successfully </cmt>,update opcode.h header to mention the source data file
4201,"<desc> imported render targets are a special case in the frame graph, in particular, the texture resource that refers to them is not a real texture with a hwtexture handle, it can be converted back to the render target, but it can never be used as an actual texture -- in particular it can't be used to create a hwrendertarget. there was other problem related to clearing render targets, individual fixes are explained in their respective cl. this should fix #4085 </desc> <cmt> add post-processing option to gltf-viewer </cmt> <cmt> fix opaque blit with imported render targets </cmt> <cmt> when the source of a blit refers to an imported render target, </cmt> <cmt> we can't create a hwrendertarget from it because the resource </cmt> <cmt> is not a real texture and doesn't have a hwtexture. </cmt> <cmt> however, it can be converted back to the hwrendertarget it </cmt> <cmt> represents, using the framegraph's declarerenderpass api. </cmt> <cmt> it's a slightly strange usage of this api, but not technically </cmt> <cmt> wrong. </cmt> <cmt> this is the main fix for bug #4085 </cmt> <cmt> fix imported target discard and clear flags </cmt> <cmt> an imported target shouldn't specify the discardstart flags, those </cmt> <cmt> are calculated from the graph. however, it needs to specify ""keep"" flags, </cmt> <cmt> to take into account constaints that the graph cannot see (due to the fact </cmt> <cmt> that it's imported into the graph). i.e. the imported target may have </cmt> <cmt> content that needs to be preserved. </cmt> <cmt> an imported target can specify a clear color and clear flags that will </cmt> <cmt> override the flags from the logical descriptor -- this is a way to </cmt> <cmt> delay the swapchain clear to when we're actually rendering into it </cmt> <cmt> (which usually happens in the very last pass). </cmt> <cmt> fix automatic clearing of rendertargets </cmt> <cmt> we were automatically clearing the color pass render target when </cmt> <cmt> the view was translucent -- the idea was that when it gets blended at </cmt> <cmt> the end it wouldn't override the content of the render target. </cmt> <cmt> unfortunately, this doesn't work when the rendertarget is imported, </cmt> <cmt> because in that case, it's not actually blended, we're just rendering </cmt> <cmt> into it directly. the clear would then erase the previous content. </cmt> <cmt> this is fixed by moving the clearing decision in the execute closure and </cmt> <cmt> piggy-backing on the computed discard flag. discard means clear. </cmt> <cmt> the discard flag will be set for newly created buffers and not for an </cmt> <cmt> imported target that needs to keep its content. </cmt> <cmt> disable skybox/clear optimization </cmt> <cmt> we were disabling the color pass render target clear when a skybox </cmt> <cmt> was present. this optimization doesn't work when the viewport is not </cmt> <cmt> full. currently there is no way to know that, so we disable this </cmt> <cmt> optimization for now. performance loss is not expected to be significant </cmt> <cmt> if present at all. </cmt> <iss> rendertarget crashes with transparent material </iss>",fix several framegraph issues related to imported render targets
4202,"<desc> this fix is for issue: #5713 for a reason still unknown, once py2-psycopg2 package fails to reinstall due to an upstream apk bug (which we are actively fixing), permanently putting apk into a broken state. initially, i had fixed this through a pr: 2925b27 but this had two problems: the less scalable problem was that the fix was targetted to py2-psycopg2 more so, it was discovered that apk fix itself only ever works intermittently (#5713) this change updates the reinstall block with the latest recommended blob from polyverse in general (running the install script, and then checking exit code before proceeding to update/reinstall as a separate if ... fi block.) in addition, we have blacklisted py2-psycopg2 in our repository, thus preventing it from reinstalling, and created a mechanism to ensure we can add more blacklisted packages as we find them in the medium run. in the long run, we're going to fix apk itself to remedy the situation in general for all alpine users (the issue also happens with non-polyverse involvement, we just ended up surfacing it due to the in-place reinstall case.) component name docker packaging </desc> <cmt> fix py2-psycopg2 right after upgrade </cmt> <cmt> this mitigates the issue </cmt> <cmt> merge remote-tracking branch 'netdata/master' </cmt> <cmt> improve reinstall script so it doesn't get into broken state </cmt>",fix the polyverse reinstall that caused apk broken state
4203,"<desc> the current pisink has a few issues that these commits address. it fixes some high cpu and underrun issues. it fixes passthrough of dts/ac3. it fixes the speaker mapping of multichannel. it has been tested for a few weeks in milhouse and miappa test builds with positive results. i think it is suitable for gotham. </desc> <cmt> [pisink] ensure audio buffers use reasonable sized chunks </cmt> <cmt> previously the sink tried to consume exactly the number of samples required to maintain the desired audio latency. </cmt> <cmt> that has a problem that we reapeatedly get called, and just consume a few samples each call. </cmt> <cmt> as the cost of sending the data to the gpu is quite high, this results in a lot of cpu being used. </cmt> <cmt> this changes the buffering to sleep for a quarter of buffer size, which ensures the samples submitted are always at lease a quarter of the total </cmt> <cmt> also, now the latency is never more than audio_playbuffer, so report that directly in getcachetotal. </cmt> <cmt> [pisink] add support for float and 32-bit formats </cmt> <cmt> significant cpu is consumed in converting audio to the sink's format, so add support for common formats to the sink. </cmt> <cmt> requires update firmware to handle this </cmt> <cmt> [pisink] fix multichannel and passthough </cmt> <cmt> the current pi sink has random speaker allocation and plays noise when passthrough is enabled. </cmt> <cmt> this adds messages to gpu to describe speaker layout for multichannel, and signal when passthrough is used </cmt> <cmt> fixing both these issues </cmt> <cmt> [pisink] increase pi sink's buffering </cmt> <cmt> we do get underruns and breakups at 50ms latency. increase to 100ms. </cmt>","fixes for underrun, passthrough and multichannel"
4204,"<desc> this project has the code to mock spring webclient mock integration test using ""okhttp - mockwebserver"" </desc> <cmt> adding complete code implementation of hexagonal architectute example </cmt> <cmt> refactored the code </cmt> <cmt> added the webclient mocking </cmt> <cmt> removed the unwanted repo </cmt>",spring webclient mocking code repo
4205,"<desc> fix for #3171. </desc> <cmt> core: split out selinux label retrieval logic into a function of its own </cmt> <cmt> this should bring no behavioural change. </cmt> <cmt> core: don't implicit open missing socket fds on daemon reload </cmt> <cmt> previously, when the daemon was reloaded and the configuration of a socket unit </cmt> <cmt> file was changed so that a different set of socket ports was defined for the </cmt> <cmt> socket we'd simply reopen the socket fds not yet open. this is problematic </cmt> <cmt> however, as this means the socket_chown state is not run for them, and thus </cmt> <cmt> their uid/gid is not corrected. </cmt> <cmt> with this change, don't open the missing file descriptors, but log about this </cmt> <cmt> issue, and ask the user to restart the socket explicit, to make sure all </cmt> <cmt> missing fds are opened. </cmt> <cmt> fixes: #3171 </cmt> <cmt> core: rework how we flush incoming traffic when a socket unit goes down </cmt> <cmt> previously, we'd simply close and reopen the socket file descriptors. this is </cmt> <cmt> problematic however, as we won't transition through the socket_chown state </cmt> <cmt> then, and thus the file ownership won't be correct for the sockets. </cmt> <cmt> rework the flushing logic, and actually read any queued data from the sockets </cmt> <cmt> for flushing, and accept any queued messages and disconnect them. </cmt>",don't reopen socket fds when reloading the daemon
4206,"<desc> this replaces the searchcontext passed to the ctor of aggregations with aggregationcontext. it ends up adding a fairly large number of methods to aggregationcontext but in exchange it shows a path to removing a few methods from searchcontext. that seems nice! it also gives us an accurate inventory of ""all of the stuff"" that aggregations use to build and run. </desc> <cmt> wip </cmt> <cmt> drop searchcontext from agg ctors </cmt> <cmt> cleanup </cmt> <cmt> don't stick to searchcontext </cmt> <cmt> markup </cmt> <cmt> wip </cmt> <cmt> extras </cmt> <cmt> figure out </cmt>",remove searchcontext from constructing aggregations
4207,"<desc> _pyunicode_transformdecimalandspacetoascii() missed trailing nul char. it cause buffer overflow in _py_string_to_number_with_underscores(). this bug is introduced in bpo-31979, 9b6c60c. </desc> <cmt> fix int(s) and similar function may break memory </cmt> <cmt> _pyunicode_transformdecimalandspacetoascii() missed trailing nul char. </cmt> <cmt> it cause buffer overflow in _py_string_to_number_with_underscores(). </cmt> <cmt> this bug is introduced in bpo-31979, 9b6c60cb. </cmt> <cmt> add news </cmt>",fix buffer overflow in int(s) and similar functions
4208,"<desc> this pr: tweaks some copy in parts 1, 2, and 4 of the tutorial. embeds the livestream video for part 1. /docs/tutorial/part-1/ /docs/tutorial/part-2/ /docs/tutorial/part-4/ </desc> <cmt> docs(tutorial): copy edits for part 1; embed livestream </cmt> <cmt> docs(tutorial): copy edits for part 4 </cmt> <cmt> docs(tutorial): copy edits for part 2 </cmt>","copy edits for parts 1, 2, 4"
4209,"<desc> test forward with requires_grad=false (this wasn't currently broken but was reported recently). test forward with requires_grad=true (this was actually fixed recently in aten when making size/stride native functions) fix and test backwards.  this required changing the gradient formula and also changing gradcheck to support empty inputs. gradgradcheck fails due to some size issues that don't look related to the formula for this specific function.  it may not be able to handle multiple outputs where some are empty tensors. </desc> <cmt> add test for empty variable cat (forward only). </cmt> <cmt> test for empty cat (no grad/gradgrad checks) </cmt> <cmt> support gradcheck on empty inputs, check it for cat with an empty variable. </cmt>",improvements around torch.cat on empty variables
4210,"<desc> this pull requests adds a setthumbnailclip(region) api to browserwindow instances on windows that can be used to control which region of the window is used to generate the thumbnail image displayed in the taskbar when the window is hoverered over. for the sample electron app if you called it as: require('electron').remote.getcurrentwindow().setthumbnailclip({x:0, y:0, width:500, height:100}) it would change the taskbar thumbnail from: default set via setthumbnailclip this can be useful for media-related apps that want the thumbnail to be the specific content such as an image, video element, etc. closes #2623 </desc> <cmt> win: add setthumbnailclip window api </cmt> <cmt> document setthumbnailclip </cmt>",add setthumbnailclip api on windows
4211,<desc> source code for the mini article bael-2534 @thombergs </desc> <cmt> source code for hexagonal architecture article. </cmt> <cmt> source code for hexagonal architecture article. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> source code for bael-2534 : determine if all elements are the same in a java list </cmt> <cmt> source code for bael-2534 : determine if all elements are the same in a java list </cmt> <cmt> removing code done for demo on hexagonal design pattern. </cmt>,bael-2534 - determine if all elements are the same in a java list
4212,<desc> work in progress. made new folder static/asset under articles. i use this to store example images in docs. </desc> <cmt> [doc] complete outline of docs in gui system </cmt> <cmt> add links to apis </cmt> <cmt> complete simple apis with links </cmt> <cmt> added examples to gui drawing apis </cmt>,add documentation for gui system and install trouble shooting.
4213,<desc> see electron/asar#25 for more. fixes #1205. </desc> <cmt> no need to override child_process.fork </cmt> <cmt> we already support asar in node mode. </cmt> <cmt> spec: test asar archive with unpacked files </cmt> <cmt> recognize asar archive with unpacked files </cmt> <iss> asar native module unpacking triggers virus scanners </iss>,add support for asar archives with unpacked files
4214,"<desc> our public python apis are often situated next to internal, private apis, with an indication to the user (in code) that those apis are private. this results in users depending on our internal apis, making our python codebase more difficult to evolve. this pr moves some modules containing internal apis to ray._private in an attempt to mitigate this issue. each commit is isolated to the movement of a single module (and all associated changes required); the module that was moved is given in the commit message. the one exception is for monitor, log_monitor, and ray_process_reaper, which were all moved in the same commit in order to make a single update to ray/_private/services.py, which needed a python executable path adjustment. between each commit, i ran ray/tests/test_basic.py to ensure that there weren't any immediately obvious breaks. we'll see if anything else broke in the ci. not that i only changed python code that was contained in python/ray, or symlinked within (such as the dashboard, rllib, streaming etc.). i haven't looked at any other python code that may be hanging around in ray. todos validate that all of these modules strictly contain private apis, and that we want to move them to ray._private. ensure all tests are still passing and that there are no regressions in general. towards #13995 i've run scripts/format.sh to lint the changes in this pr. </desc> <cmt> async_compat </cmt> <cmt> utils </cmt> <cmt> cluster_utils </cmt> <cmt> compat </cmt> <cmt> function_manager </cmt> <cmt> import_thread </cmt> <cmt> memory_monitor </cmt> <cmt> monitor, log_monitor, ray_process_reaper </cmt> <cmt> metrics_agent </cmt> <cmt> parameter </cmt>",first pass at privatizing non-public python apis.
4215,<desc> for #6869. </desc> <cmt> use mocked data source on spring boot test </cmt> <cmt> remove useless fixture of sharding spring boot test </cmt> <cmt> move shardingspringbootconditiontest package </cmt> <cmt> remove useless javadoc </cmt> <cmt> rename shadowspringbootconditiontest </cmt> <cmt> rename masterslavespringbootstartertest </cmt> <cmt> rename encryptspringbootstartertest </cmt>,replace mock data source to spring boot integrate tests
4216,"<desc> closes #26397 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> bug: ensure that top and freq are reported as none for empty dataframes </cmt> <cmt> bug: ensure that the index values obtained when calling describe on an empty categorical / object column is the same as that of an non empty column </cmt> <iss> dataframe.describe excludes top and freq for empty dataframe </iss>",fix the output of df.describe on an empty categorical / object column
4217,"<desc> @gretzky, i think what was happening was some of the commits in master were also in dev but not all of them. so git/github were freaking out. i created a new branch from the same point as master and rebased those commits on top of dev. everything should be good now and we'll be able to merge dev into master when we're ready for a release. </desc> <cmt> update issue templates </cmt> <cmt> replace gitter with spectrum (#2483) </cmt> <cmt> replace gitter with spectrum </cmt> <cmt> update issue template and issue-close-app </cmt>",master changes back into dev
4218,<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: pinojs/pino#588 </desc> <cmt> add bindings definition to baselogger </cmt> <cmt> linting fix </cmt>,add definition for logger bindings
4219,"<desc> this pr adds support for defining the textcolor of buttons when the button is in the hovered, focused, or pressed states. this is useful for preserving the contrast ratio of the text on a button. often, when buttons are interacted with, the contrast ratio can drop. this makes the text on buttons more difficult to read, and less accessible. for example, we can make the blue text in this button darker on hover, and even darker on pressed. implementation the implementation comes in three parts. creating an enum for materialstate, this includes, hovered, pressed, focused, dragged, disabled, and, error. creating a materialstatecolor class. materialstatecolor has a resolve method that gets the color given a set of states. or just use materialstatecolor.resolvewith(...) and pass a callback that will be used to get a color given a set of states. updating the rawmaterialbutton to keep track of a set<materialstate>, the using it to get the color for the current state from materialstatecolor (or just the color itself if the text color is not a materialstatecolor). i added the following tests: contrast ratio tests for flatbutton, outlinebutton, and raisedbutton in the hovered and focused states. tests that the text/icon of flatbutton, outlinebutton, and raisedbutton can be updated depending on the hovered, focused, and pressed states (using materialstatecolor). tests for buttons in a blue color scheme.  normally in the blue color scheme, the button text is inaccessible in interactive states, but with materialstatecolor, they can be fixed. tests that verify that passing a materialstatcolor to a buttontheme still allows you to specify the hovered, pressed, and focused text color of a given button. tests that verify that passing a materialstatecolor to textcolor will cause disabledtextcolor to be ignored. instead, textcolor in the disabled state will be used. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read [handling breaking changes]). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. </desc> <cmt> support for stateful text colors in buttons </cmt> <cmt> add color and a11y tests for buttons </cmt> <cmt> fix npe </cmt> <cmt> add documentation </cmt>","add support for hovered, pressed, and focused text color on buttons."
4220,<desc> added bson binary definition and a couple of indexing overloads of mongodb. ensureindex and createindex options field is optional so added an overload for that. </desc> <cmt> added binary class to mongodb. </cmt> <cmt> added createindex and ensureindex overloads to mongodb.collection. </cmt>,mongodb binary object and index overloads.
4221,"<desc> this is related to #27260. this commit moves the niotransport from :test:framework to a new nio-transport plugin. additionally, supporting tcp decoding classes are moved to this plugin. generic byte reading and writing contexts are moved to the nio library. additionally, this commit adds a basic mockniotransport to :test:framework that is a tcptransport implementation for testing that is driven by nio. </desc> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt> <cmt> wip </cmt>",create nio-transport plugin for niotransport
4222,"<desc> fix missing versionadded/versionchanged for version 0.23, and also fix doc formatting. </desc> <cmt> fix minor typo in hyperlink </cmt> <cmt> add versionchanged to make_circles and make_moons </cmt> <cmt> fix minor docstring format </cmt> <cmt> fix docstring containing randomstateinstance </cmt> <cmt> add versionadded to basehistgradientboosting and baseloss </cmt> <cmt> add versionadded to histgradientboostingregressor/classifier </cmt> <cmt> add versionadded to votingclassifier/regressor verbose </cmt> <cmt> fix class name in docstring note </cmt> <cmt> add versionchanged to histgradientboostingregressor loss </cmt> <cmt> add versionchanged to iterativeimputer min_value/max_value </cmt> <cmt> add versionadded to glm </cmt> <cmt> add versionadded to elasticnet.fit sample_weight </cmt> <cmt> fix docstring convention formatting </cmt> <cmt> add versionadded to lars/lassolars jitter and random_state </cmt> <cmt> fix pr id in whatsnew </cmt> <cmt> add versionadded to ridgecv/ridgeclassifiercv best_score_ </cmt> <cmt> fix docstring hyperlinks </cmt> <cmt> add versionchanged to onehotencoder drop </cmt> <cmt> add versionchanged to onehotencoder drop_idx_ </cmt>",doc fix versionadded for 0.23
4223,"<desc> in jungle testnet, libs were not advancing in a mixed of rel. 2.0.x and rel. 2.1.x nodes. this was due to 2.0.x validation failure of blocks produced by 2.1.x, and in turn caused by incorrect conversion between packed_transaction_v0 and packed_transaction_v1. the solution is to make sure a conversion does not stripped any data. new test cases are added. select one: select any that apply: </desc> <cmt> fix packed_transaction version conversion problem </cmt> <cmt> remove commented out code </cmt> <cmt> call local_pack_context_free_data in packed_transaction_v0 </cmt>",fix packed transaction version conversion -- release 2.1.x
4224,"<desc> refactor current tests should pass if relevant, link to documentation update: n/a summary upgrade harmonyexportimportedspecifierdependency and harmonyexportimportedspecifierdependencytemplate to es6 no </desc> <cmt> raw refactor of harmonyexportimportedspecifierdependency to es6 </cmt> <cmt> raw refactor of harmonyexportimportedspecifierdependencytemplate to es6 </cmt> <cmt> extract content generation into own method and early return on each stage in harmonyexportimportedspecifierdependencytemplate </cmt> <cmt> extract and simplify getreexportstatement in harmonyexportimportedspecifierdependencytemplate </cmt> <cmt> move comments on top of ifs to make them easier readable </cmt> <cmt> add helper method to determine the hash value in harmonyexportimportedspecifierdependency </cmt> <cmt> early return on getexports if importedmodule is not available </cmt> <cmt> return as early as possible in getreference in harmonyexportimportedspecifierdependency </cmt>",refactor harmony export import specifier dependency to es6
4225,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: none. it is a purely internal change not based on any changes to the lib. increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> add generic to tomatchobject </cmt>","added generic for ""tomatchobject"" function"
4226,"<desc> some people on #tox-dev complained that there are too many statuses: user status, connection status and friend status. this pr removes friend status from client-side api and replaces it with two new functions: /* checks friend's connecting status. * *  return 1 if friend is connected to us (online). *  return 0 if friend is not connected to us (offline). *  return -1 on failure. */ int tox_get_friend_connectionstatus(tox *tox, int friendnumber); /* checks if there exists a friend with given friendnumber. * *  return 1 if friend exists. *  return 0 if friend doesn't exist. */ int tox_friend_exists(tox *tox, int friendnumber); </desc> <cmt> removed friendstatus from client api </cmt> <cmt> modified test </cmt>","removed friendstatus from client-side api, replacing it with alternative functions"
4227,"<desc> a massive set of updates to office.js, accumulating changes from the past ~6 months for excel, word, and onenote addition of the excelapi 1.7 api set, which adds some 400+ apis codegen updates to word and onenote apis (e.g., new codegen-ed interfaces for .set and .tojson methods) refactoring of enums into strongly-typed strings, for superior intellisense & compile-time safety.  also introducing method overloads that make use of these enums removing of ipromise and promise classes in favor of using the native promise type. adding typings for a few additional apis on the officeextension namespace (more information exposed in debuginfo, pendingstatements, etc.) add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. </desc> <cmt> update to excelapi 1.7 and with latest word d.ts codegen </cmt> <cmt> remove other ipromise dependencies, making everything be just regular promises </cmt> <cmt> annotate with ts 2.4 requirement in the header </cmt>","excelapi 1.7, additions to word and onenote codegen"
4228,"<desc> secrets management file of elasticsearch username and password the value of secretsmanagementfile should point to the secrets management file absolute path. the file includes username and password of elasticsearch server in the properties format. user=xxx password=yyy the major difference between using user/password configs in the application.yaml and this file is, this file is being watched by the oap server. once it is changed manually or through 3rd party tool, such as vault, the storage provider will use the new username and password to establish the connection and close the old one. if the information exist in the file, the user/password will be overrided. </desc> <cmt> temp commit </cmt> <cmt> support secretsmanagementfile file. </cmt> <iss> support es username/password change dynamically </iss>",support secrets management file in the elasticsearch 6/7 storage
4229,"<desc> i'm ""cherry picking"" these features because i missed them when migrating to 2.1 from 2.2-legacy (i noticed this because of this post on facebook group). i had to do these changes manually because the structure of 2.1 (and master) is different from 2.2 (eg: 2.1 and master has no /tools folder). i made the commits separately for easier testing and revision ^^ </desc> <cmt> re-add script button from b77200728e7f2b2dd446a9717c83a20c9aac0ce4 </cmt> <cmt> re-add create/load script button and context menu </cmt> <cmt> - create from f51b202566e9b2a9deb3eb4836f6e00fb30e8500 </cmt> <cmt> - load from 41329f9750379b3c2e506d1e9ed7f6195c812920 </cmt> <cmt> re-add script icons from 544194053a54870320d860f1cf333f45723758b9 </cmt> <cmt> re-add clear script button and context menu from ce5200b30e6d262905912c6571d51ba6f5979bd7 </cmt> <cmt> re-add attach button and context menu from 1880238c3e54f57a14361d2c347387edebc6391b </cmt>",add attach and clear script buttons (2.1)
4230,"<desc> running the publish command on a new initialized lerna repo, e.g. with no commits at all, will lead to an error message as reported in issue #773. this change will add a test if there are any commits and will exit the publish command with a more elaborated error message in order to push the user in the right direction what happened and why publish won't proceed. the issue is described in #773. the error message leads the user in a wrong direction what the issue with the failing publish really is: there are no commits, therefore there's nothing to publish. i refactored the init-fixture in order to prepare the test environment without any commits. afterwards i wrote the tests for the added functionality, which is located in commands/publish/lib/is-anything-commited.js and updated the tests for this and for get-current-branch.js as well. the change affects @lerna-test/init-fixture as well as commands/publish/get-current-branch.js. tested on macos 10.13.4 w/ git version 2.15.1 (apple git-101). i have read the contributing document. </desc> <cmt> refactor(init-fixture): init without commits </cmt> <cmt> fix(command-publish): crash on publish w/o commits </cmt> <cmt> lerna will throw an error, when publishing the current project and </cmt> <cmt> there are no commits at all. this change will check if there are </cmt> <cmt> any commits before proceeding with the publish command. </cmt> <cmt> - refactor the fixtures as preparation for tests with/without commit </cmt> <cmt> - add check if any commits are present </cmt> <cmt> - add tests for this behaviour </cmt> <cmt> closes #773. </cmt>",exit early when publishing w/o commits
4231,"<desc> (also make btree's filevtable const, included just to test on travis) </desc> <cmt> extmod/modbtree: make filevtable const to put it in rom. </cmt> <cmt> py/nativeglue: remove unused mp_obj_new_cell from mp_fun_table. </cmt> <cmt> it has been unused since 9988618e0e0f5c319e31b135d993e22efb593093 </cmt>",remove mp_obj_new_cell from native fun table
4232,"<desc> plasma::seal was not synchronous in the previous version of arrow. this meant that a worker trying to create an object would send an async seal to the plasma store, then send an ipc to the local raylet to pin the object. the local raylet would send a get to the plasma store, which could be received before the client's seal. then, it would appear as if the object is not in the plasma store. this will likely have an impact on ray.put() performance for small objects. on my laptop: before this pr single client put calls per second 10610.79 +- 161.55 single client put gigabytes per second 7.39 +- 0.18 multi client put calls per second 16235.04 +- 191.21 multi client put gigabytes per second 10.53 +- 0.53 after this pr: single client put calls per second 8897.05 +- 41.73 single client put gigabytes per second 7.28 +- 0.33 multi client put calls per second 13717.71 +- 345.07 multi client put gigabytes per second 9.51 +- 0.33 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at </desc> <cmt> upgrade arrow to master </cmt> <cmt> fix build </cmt>","upgrade plasma to latest version, use synchronous seal"
4233,"<desc> closes #20835 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> added test case </cmt> <cmt> round trippable read/write with errors </cmt> <cmt> added index to test case </cmt> <cmt> mirrored encoding impl </cmt> <cmt> updated whatsnew </cmt> <cmt> lint fixup </cmt> <iss> ""to_hdf()"" with ""format='table'"" ignores encoder ""errors"" argument. </iss>",allow errors keyword for hdf io encoding err handling
4234,"<desc> the audio mixer tracks changes to the volume using the settings: tdesktop/telegram/sourcefiles/media/audio/media_audio.cpp lines 588 to 596 in 5000902 core::app().settings().songvolumechanges( ) | rpl::start_with_next([=] { qmetaobject::invokemethod(_fader, ""onsongvolumechanged""); }, _lifetime); core::app().settings().videovolumechanges( ) | rpl::start_with_next([=] { qmetaobject::invokemethod(_fader, ""onvideovolumechanged""); }, _lifetime); however it uses the internal value _volumesong to set the volume, so if the setting is updated before the mixer value, the previous value is used. when the slider value changes, the value in settings gets updated before the mixer value, causing the previous value to be used in the mixer, which causes #16276 additionally, setting the volume with media controls only updates the setting, causing the playback volume to not change, which causes #16905 </desc> <cmt> set mixer volume before changing setting </cmt> <cmt> set mixer volume on media control change </cmt>","fix song volume controls, closes #16276 #16905"
4235,"<desc> this pr requires  #21990 to be merged in first. addresses #20724 and #21927 #dataumbrella summary of changes to basegradientboosting: add tests to ensure gradientboostingclassifier and gradientboostingregressor raise proper errors when invalid arguments are passed in. use the helper function check_scalar from sklearn.utils to validate the scalar parameters. test and validation progress: in both estimators learning_rate n_estimators min_samples_split min_samples_leaf min_weight_fraction_leaf max_depth min_impurity_decrease subsample max_features ccp_alpha verbose max_leaf_nodes warm_start validation_fraction n_iter_no_change tol in gradientboostingregressor alpha references check_scalar docs pr #20723 for the unchecked tasks, validation is coming from basedecisiontree, however, tests have been added for them here. </desc> <cmt> n_estimators: update unit tests </cmt> <cmt> n_estimators: add validation with check_scalar </cmt>",maint use check_scalar in basegradientboosting
4236,"<desc> static saml conf some idps provide metadata urls, okta refers to this scheme as ""dynamic"" configuration. however, some idps do not provide this metadata url, and the alternative is to ""statically"" specify an sso url, entity id, and x509 certificate on the client-side. with this pr, this is configurable through the ui and environment variables. saml response encryption it may be desirable to encrypt the saml response from the idp to the sp. with this pr, this is configurable through environment variables. n/a recording: </desc> <cmt> change front-end and data model for saml2 auth - static configuration </cmt> <cmt> add changes to use inline metadata. </cmt> <cmt> add changes to use inline metadata. </cmt> <cmt> add switch for static and dynamic saml configurations </cmt> <cmt> fixed config of backend static/dynamic to match ui </cmt> <cmt> add ability to encrypt/decrypt saml assertions with pem and crt files. upgraded to pysaml2 6.1.0 to mitigate signature mismatch during decryption </cmt> <cmt> remove print debug statement </cmt>",static saml configuration and assertion encryption
4237,"<desc> fixes: #5971 by re adding the code generation command back in. ran tests/generate_code.sh and . src/clang-format-git.sh which included all the other files and minor formatting issues. </desc> <cmt> fixed refractoring issue in reflection/generate_code.sh. also, mv deletes the original file, so i don't need to clean it up manually in that case. </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixed dart tests by removing code-gen for included files. </cmt> <cmt> added code gen for evolution tests back in. </cmt> <cmt> merge remote-tracking branch 'origin/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> general generate code and clang format </cmt> <iss> add code gen step for evolution test schema </iss>",re-added evolution schema code generation command
4238,"<desc> requirements filling out the template is required. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. all new code requires tests to ensure against regressions description of the change my previous attempt to prevent specs from modifying the recent project history (#16255) worked for the most part but had some edge cases that i'm attempting to fix in this pr.  specifically, #16255 only spied on atom.history.savestate.  if a different historymanager was instantiated, it would be able to save history state and globally modify the recent project history.  i found this to occur in at least two specs: a workspace spec that was creating a new atomenvironment (and hence associated historymanager) and historymanager specs that used its own historymanager instance.  to prevent any historymanagers from modifying project history, spec-helper now spies on the historymanager prototype rather than a specific instance.  that means all instances of historymanager will now have savestate spied on.  however, since some historymanager specs explicitly test savestate, for those tests i temporarily unspy savestate and instead spy on the underlying state store.  my previous ""fix"" for historymanager was to spy on atom.applicationdelegate.didchangehistorymanager, which is responsible for broadcasting project history changes to other atom windows.  this was a faulty implementation because while the project history would appear to be conserved, the state store would still be updated with the incorrect project history data.  therefore as soon as you opened another window the recent projects menu would again be incorrect. test plan run some specs in the dedicated spec window and then close it.  ensure that other non-spec windows have their project history maintained, even after opening a new window. run all workspace specs.  ensure that other non-spec windows have their project history maintained, even after opening a new window. run all historymanager specs.  ensure that other non-spec windows have their project history maintained, even after opening a new window. alternate designs none. why should this be in core? the legacy spec helper is in core. benefits no specs should be able to modify project history unless you explicitly unspy savestate. possible drawbacks none. applicable issues #16255 </desc> <cmt> spy on historymanager prototype </cmt> <cmt> to prevent other instances of historymanager from messing up the project </cmt> <cmt> history </cmt> <cmt> update historymanager spec to mock the state store </cmt> <cmt> don't require historymanager in spec-helper </cmt> <cmt> :art: </cmt> <cmt> :memo: </cmt>",more history manager fixes in specs
4239,"<desc> this is a workaround for #54. i'm also sending a separate commit to update autogen.sh to advocate using --with-rootprefix=/ which i believe is slightly better since it's more usual and explicit way to specify the root. i'll try to work with autoconf-archive to extend the macro upstream. i didn't do a full test, just ran autogen.sh and then ./configure --with-rootprefix= and checked the value of the generated rootprefix variable in makefile but i'm fairly confident this should work fine in all cases. more testing is definitely appreciated. @mbiebl @martinpitt @zonque cheers! filipe </desc> <cmt> build-sys: recommend --with-rootprefix=/ for split-usr </cmt> <cmt> since we started using ax_normalize_path, that is a valid supported </cmt> <cmt> setup and is more explicit than --with-rootprefix= (empty) which is </cmt> <cmt> actually currently broken. </cmt> <cmt> let's advocate for it in the ./configure suggestion from autogen.sh. </cmt> <cmt> build-sys: work around --with-rootprefix= (empty) not producing / </cmt> <cmt> since we introduced ax_normalize_path, using --with-rootprefix=/ does </cmt> <cmt> produce an empty string, but using --with-rootprefix= (empty) now </cmt> <cmt> produces ""."" instead which is wrong. </cmt> <cmt> work around it until we can find a better solution for ax_normalize_path </cmt> <cmt> upstream at autoconf-archive. </cmt> <cmt> bug: </cmt>",fix --with-rootprefix= (empty) with a workaround for now.
4240,"<desc> this allows requests from non-admin users that have at least ""view_only"" permissions on the ds. also adds the view_only information and limit the result information when the user is non-admin. reverts #4927 as with this the specific route can be used. reasoning: it removes the need for the ""list_data_sources"" permission when accessing the view query page. -- -- </desc> <cmt> update ds api to accept get from non-admins </cmt> <cmt> revert ""fork button disabled on view query page for non-admin users (#4927)"" </cmt> <cmt> this reverts commit d55042748532517a2b37d23423402c00620aa5ac. </cmt>",allow get from non-admins on data source resource
4241,"<desc> this is a continuation of #2460 by @paulfalgout. the former boolean shallow parameter of both the internal and the external flatten is replaced by a depth parameter which can be either boolean or numeric. boolean values still have the same meaning. numeric 1 has the same meaning as true while 0 or less results in a shallow copy without any flattening. the default is still infinite depth. @jashkenas the original pr was approved by @akre54 and @michaelficarra in 2016. if this is sufficiently reassuring for you, you can stop reading here. @paulfalgout i moved your checks against nonnumeric and nonpositive depth values back from the public to the internal flatten. at the time, you were concerned that this would be inconsistent with strict === true, but there is actually no conflict. when depth === 1, every nested element of every array is copied whether the nested element is an array or not, even when strict === true. extrapolating this to depth === 0, ""every array"" is just the top-level array, so every element of it should be copied, regardless of whether it is an array and regardless of the value of strict. merging this should automatically also merge #2460. </desc> <cmt> allow a specified depth for flatten </cmt> <cmt> per a new tc39 proposal </cmt> <cmt> this was fairly trivial to implement without breaking the current functionality. </cmt> <cmt> thoughts? </cmt> <cmt> account for 0 and negative depths for _.flatten </cmt> <cmt> move a comment back to where it came from </cmt> <cmt> update the comment to _.flatten </cmt> <cmt> add sanity checks </cmt> <cmt> this is mostly to ensure that the internal flatten is still </cmt> <cmt> well-behaved, since it being called internally with boolean arguments, </cmt> <cmt> and there is no check in place to enforce that false is interpreted as </cmt> <cmt> infinite depth. </cmt> <cmt> move the depth guard to the internal flatten </cmt> <cmt> manual testing revealed that flattening with depth=false behaved as a </cmt> <cmt> shallow flatten instead of a deep one. </cmt>",enable flattening to a specified depth (continued)
4242,"<desc> currently, the test_logging_config.test_reload_module test fails when processes are created in spawn mode, because the change in how memory is shared between processes means the test logging configs don't get loaded properly in the child. this saves the logging config to an environment variable, which is accessible from the child process. make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow ""how to write a good git commit message"" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. </desc> <cmt> ensure test_logging_config.test_reload_module works w spawn. </cmt> <cmt> reset configs after reload_logging test is complete. </cmt>",ensure test_logging_config.test_reload_module works in spawn mode.
4243,<desc> description: this pr bumps the version of the zha quirks lib. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> bump zha quirks version </cmt> <cmt> update requirements </cmt>,bump zha quirks to 0.0.31
4244,<desc> this is an example patch for  issue #9177 </desc> <cmt> add 'normalized' bool and accessor to bufferattribute array in interleavedbufferattribute </cmt> <cmt> add webgl_buffergeometry_points_interleaved example </cmt> <cmt> featuring interleavedbuffer with different numercial type (float32 and </cmt> <cmt> uint8) </cmt>,fix problems with non floating type in interleavedbufferattribute.
4245,"<desc> my plugin had been updated, so i  want to update it description </desc> <cmt> add a new context menu component </cmt> <cmt> update vue-mouse-menu to 2.0.0 version, add some new function and supported multi-terminal running. </cmt>","my plugin description have been updated, support for mobile.  please accept my pull request, thanks"
4246,"<desc> merged a commit that broke test_metrics. this fixes the test for the changes and recommits. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> revert ""revert ""[dashboard] group by actor class (#10147)"" (#10180)"" </cmt> <cmt> this reverts commit e4d2ca620a20211ccd1ae01c240fe3e21ab8dee3. </cmt> <cmt> fix metrics test to agree with the new logical view api </cmt>",fix and recommit reverted group by actor class pr
4247,<desc> add get_addr() to retrieve the pointer of an snode. this only works on llvm backends for now. </desc> <cmt> sparse examples and get_addr </cmt> <cmt> . </cmt> <cmt> temp commit. get_addr not working </cmt> <cmt> remove redundant logging </cmt> <cmt> remove more redundant logging </cmt>,add get_addr() to retrieve the buffer addr of an snode
4248,"<desc> similar to pull request #5736, this sorts some of the properties in order to be in the same order as the parameters. i went through all the files so hopefully i didn't miss any. additionally, fixed some typos and added a description to two parameters. </desc> <cmt> fixed typos and reordered properties to reflect parameter order </cmt>",sorted remaining docs properties and added parameter descriptions
4249,"<desc> i started with the commit already in #4435: joshwillik@c77bed6 i rebased it on to master to make sure it still applied cleanly, which it does. i checked for test coverage of the related checkssl middleware and found no unit tests, presumably because of the dependencies on config, req and res. i added a commit which is purely a refactor which moves most of checkssl into a unit-testable routine and added several unit tests for it. since the routine was not tested, i moved it from the middleware/index.js to middleware/middleware.js as the docs say that the later is the location for unit-testable middleware. the two commits are not squashed because they are clearer as two: the former shows the logic change, the latter is a refactor. there some functional testing in test/functional/routes/admin_test.js which confirms the refactor doesn't break anything. </desc> <cmt> make https compatible with a ghost module </cmt> <cmt> closes #4434 </cmt> <cmt> - change an incorrect redirect </cmt> <cmt> refactor: make checkssl unit-testable and add unit tests for it. </cmt> <cmt> - code was moved to core/server/middleware/middleware.js, which is the </cmt> <cmt> home for unit-testable middleware. </cmt> <cmt> - functional code coverage for this code also exists at: </cmt> <cmt> test/functional/routes/admin_test.js </cmt>","fixes #4435, also refactors checkssl to be unit-tested."
4250,"<desc> this change adds the after_key of a composite aggregation directly in the response. it is redundant when all buckets are not filtered/removed by a pipeline aggregation since in this case the after_key is always the last bucket in the response. though when using a pipeline aggregation to filter composite buckets, the after_key can be lost if the last bucket is filtered. this commit fixes this situation by always returning the after_key in a dedicated section. </desc> <cmt> returns the after_key in composite aggregation response </cmt> <cmt> this change adds the after_key of a composite aggregation directly in the response. </cmt> <cmt> it is redundant when all buckets are not filtered/removed by a pipeline aggregation since in this case the after_key is always the last bucket </cmt> <cmt> in the response. though when using a pipeline aggregation to filter composite buckets, the after_key can be lost if the last bucket is filtered. </cmt> <cmt> this commit fixes this situation by always returning the after_key in a dedicated section. </cmt> <cmt> fix rest test </cmt>",always return the after_key in composite aggregation response
4251,"<desc> some modules have more than one component, which is not recommended for maintenance. by extracting those components, we can avoid duplication (e.g. modals and filters). additionally some components were rewritten in typescript and fuselage typings were updated. how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog </desc> <cmt> replace toastr in components </cmt> <cmt> convert contexts to typescript </cmt> <cmt> split account components </cmt> <cmt> split apps components </cmt>",refactor some react pages and components
4252,"<desc> preconditions should retry internally on stale watch data instead of surfacing an error. fixes #82130 does this pr introduce a user-facing change?: fix a bug in apiserver that could cause a valid update request to be rejected with a precondition check failure. /sig api-machinery / </desc> <cmt> test </cmt> <cmt> in guaranteedupdate, retry on precondition check failure if we are working with cached data </cmt> <iss> ""precondition failed: uid in precondition"" flakes </iss>","in guaranteedupdate, retry on a precondition check failure if we are working with cached data"
4253,"<desc> the custom layout zone number is limited with 40 zones as like as a template. what is include in the pr: linked issue: #9352 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. </desc> <cmt> disable add zone button </cmt> <cmt> unify zone adding </cmt>",limit zones number for custom layouts.
4254,"<desc> bug fixes ops removed unreasonable code, and fixed an input uninitialized problem. </desc> <cmt> support elementwise_add triple grad kernel </cmt> <cmt> change code-format to follow ci std </cmt> <cmt> removed unreasonable code, and fixed an input uninitialized issue </cmt> <cmt> support elementwise_add triple grad kernel </cmt> <cmt> change code-format to follow ci std </cmt> <cmt> removed unreasonable code, and fixed an input uninitialized issue </cmt> <cmt> merge commit 'fetch_head' into elementwise_add_triple_grad </cmt>","elementwise_add triple grad, fixed an input uninitialized problem"
4255,"<desc> this pr gets rid of the singleton implementation of the valuessourceregistry i had been using for prototyping, and replaces it with something that behaves like we generally expect a registry to behave.  searchmodule creates an instance of valuessourceregistry, which then gets pulled down through the various index management classes, until it gets made available to the aggregations framework via queryshardcontext. this also lets us get rid of the atomic initialization guards on the aggregation builders, since tests creating multiple searchmodule instances now get isolated valuessourceregistry instances. special thanks to @nik9000 for pointing me in the right direction on this! </desc> <cmt> get the vsregistry from queryshardcontext </cmt> <cmt> pass vsregistry into queryshardcontext </cmt> <cmt> wire all the way back to search module </cmt> <cmt> valuessourceregistry member for searchmodule </cmt> <cmt> clean up other uses of vsregistry.getinstance </cmt> <cmt> get rid of singleton & weird atomic init guards </cmt>",plumb valuessourceregistry through to querysearchcontext
4256,"<desc> i spent a lot of time to get my jtag debugger to work with arduino and marlin in order to have a real dev environment for my planned multi extruder changes. to be able to use jtag it was required to port the project to avrstudio to compile / upload / debug it there (i tried eclipse without success since avrice and my jtag ice mkii don't really like each other). this pull request includes some correction (typos), bug fixes and stabilizations (have a look at the individual commit comments) i back ported which i think are useful to apply to marlin. maik </desc> <cmt> fixed typo in comment </cmt> <cmt> delete obsolete and wrong code </cmt> <cmt> ""i"" runs from 0 to 4 but ""add_homeing"" array size is 3 only. on the </cmt> <cmt> other hand the calculated value gets overwritten by either one of the </cmt> <cmt> if choice. </cmt> <cmt> explicit includes to make it compile with avrstudio/eclipse </cmt> <cmt> moved lcd initialization out of constructor </cmt> <cmt> since the class ""mainmenu"" was used within a static variable the </cmt> <cmt> initialization of the object (constructor call) was done before arduino </cmt> <cmt> library startup. it always caused a crash when using avrstudio with </cmt> <cmt> jtag debugger (caused from calling the lcd initialization / the lot of </cmt> <cmt> i/o work / the stack used during this calls). by moving the lcd_init </cmt> <cmt> out of the constructor and using an explicit call inside of arduino </cmt> <cmt> setup() implementation immediately fixed all problems and the jtag </cmt> <cmt> debugger runs fine. </cmt>",marlin v1 - bug fixes / corrections
4257,"<desc> #24738, but for 2021 and not 2018. the parts from the original pr description that still hold: interestingly, there is some fallout here in some odd places: first of all, some small changes needed to occur to replicate old behavior. right now, a computed name of type any produces a number index signature. with this change, we make a string index signature instead (it's more broad and closer to correct). lastly, some emit changes - specifically, where previously we'd elide symbol.iterator when it appeared as a property name (and assume that the expression had no sideffects), now we retain and emit it (and potentially cache it), as we generally do not assume property access expressions are safe to elide or copy. fixes #24622 an important implementation note: as we discussed in person, inside the checker, if we see members of the global symbolconstructor of type symbol, we also assume you meant to say unique symbol. in this way, we retain compatibility with older libs or definition files (even as they update), which is how this can build (at all), given node is shimming symbol.iterator as a symbol. fixes #24622 fixes #27525 fixes #31253 fixes #21603 fixes #37182 fixes half of #36468 (indirect calls to symbol() still do not produce fresh unique symbols like direct calls do - but that should be a separate change, imo) </desc> <cmt> eliminate well-known symbols in the checker: 2021 edition </cmt> <cmt> actually update the lib text to say unique symbol, too (this is unneeded with compat code in place, but this makes goto-def make more sense) </cmt> <cmt> add test showing mismatched symbol constructor type interop </cmt> <cmt> add more test cases for some other related issues this fixes </cmt> <iss> use unique symbol for well-known symbols </iss> <iss> keyof does not include well known symbols </iss> <iss> make symbol.* (e.g. symbol.iterator) unique symbols </iss> <iss> readonly<float32array> not assignable to float32array </iss> <iss> readonly<t> miss all internal symbol keys </iss>",eliminate well known symbols as a concept in the checker and rely on unique symbols
4258,"<desc> attrs in retokenizer.merge and retokenizer.split can now also include lexical attributes and binary flags (like lower, is_stop or like_num). those will be set on the lexeme, so they'll be valid for all entries in the vocabulary, not just that particular token in context. enhancement i have submitted the spacy contributor agreement. </desc> <cmt> fix formatting and whitespace </cmt> <cmt> add support for lexical attributes (closes #2390) </cmt> <cmt> document lexical attribute setting during retokenization </cmt>",support lexical attributes in retokenizer attrs (closes #2390)
4259,"<desc> this adds a new action, clearbuffer. it accepts 3 values for the clear type: ""clear"": ""screen"": clear the terminal viewport content. leaves the scrollback untouched. moves the cursor row to the top of the viewport (unmodified). ""clear"": ""scrollback"": clear the scrollback. leaves the viewport untouched. ""clear"": ""all"": (default) clear the scrollback and the visible viewport. moves the cursor row to the top of the viewport (unmodified). ""clear buffer"" has also been added to defaults.json. from microsoft/vscode#75141 originally closes #1193 closes #1882 i work here requires documentation to be updated this is a bit tricky, because we need to plumb it all the way through conpty to clear the buffer. if we don't, then conpty will immediately just redraw the screen. so this sends a signal to the attached conpty, and then waits for conpty to draw the updated, cleared, screen back to us. works for each of the three clear types as expected tests pass. works even with ping -t 8.8.8.8 as you'd hope. </desc> <cmt> blindly, i think this is the conpty half of the ask </cmt> <cmt> this plumbs #1882 and #1193 all the way through. </cmt> <cmt> unfortunately, i need to reset the cursor position, and i actually just need </cmt> <cmt> to do this differently entirely. </cmt> <cmt> iterm actually maintains the last line of the buffer entirely. that's kind of </cmt> <cmt> important! otherwise the prompt just disappears too. </cmt> <cmt> they're actually even smarter than that: </cmt> <cmt> * </cmt> <cmt> * </cmt> <cmt> and know where the prompt starts and ends, and keep all of multi-line prompts. </cmt> <cmt> that's a very 2023 feature, but we should keep at least one line. </cmt> <cmt> the revert i was talking about </cmt> <cmt> this is almost right, but we're clearing the attributes of the top line, which is _not_ right. </cmt> <cmt> whatever, it works man </cmt> <cmt> add a roundtrip test </cmt> <cmt> much cleanup. add resource strings </cmt> <cmt> comments comments comments </cmt> <cmt> write a test for controlcore </cmt> <iss> support manually clearing the conpty buffer </iss> <iss> add a terminal-side shortcut for clearing the screen and/or scrollback </iss>",implement and action for manually clearing the terminal (and conpty) buffer
4260,"<desc> followup to #7108 - this further improves code size with that option (by not disabling wasm-only mode). we do still disable it when in a shared module, as further work needs to be done there, but for standalone code this works fine. </desc> <cmt> don't export the entire table unless we are in a shared module </cmt> <cmt> in wasm mode, emulated function pointers don't force us to export the whole table (but asm.js would need more work to benefit from that) </cmt> <cmt> add test </cmt> <cmt> test </cmt> <cmt> move test </cmt> <cmt> ifdef out asm.js code for emulated function pointers in wasm mode </cmt> <cmt> don't emit table checking code without assertions </cmt> <cmt> try to leave wasm-only with emulated function pointers </cmt> <cmt> update test </cmt> <cmt> update test </cmt> <cmt> wip [ci skip] </cmt> <cmt> merge </cmt> <cmt> update binaryen, and fix a test which assumed vars are called  in the text format (we changed to just ) </cmt> <cmt> fix </cmt> <cmt> fix test [ci skip] </cmt> <cmt> allow wasm-only with emulated function pointers, except in shared modules </cmt> <cmt> restore fix </cmt>",allow wasm-only mode with emulated_function_pointers
4261,"<desc> i added the new recipes for pages and layouts to get this docs train moving! this pr also includes some of the restructuring i proposed in previous issues (and in the recipe spreadsheet). new recipes in this pr: gatsby project structure creating pages automatically creating pages from markdown posts with createpage (bonus recipe!) creating pages without graphql creating a layout component i also added a numbering system (1.1, 1.2, 2.1, etc.) since these are longer than i'd hoped to still be actionable on-page - that's a goal of these content pieces. i think the table of contents in #15251 will help a lot, too, and we could potentially add an expand/collapse component in the future to make the page easier to digest and scan. closes #14807 closes #14808 closes #14809 closes #14810 </desc> <cmt> fix: restructure recipes </cmt> <cmt> add new recipes for pages and layouts </cmt> <iss> [docs][recipes] pages/layouts: project structure </iss> <iss> [docs][recipes] pages/layouts: create pages without graphql </iss> <iss> [docs][recipes] pages/layouts: create pages automatically </iss> <iss> [docs][recipes] pages/layouts: create a layout component </iss>",rearrange and add new recipes on pages and layouts
4262,"<desc> updating the rel documentation section and syncing it with the latest code from  i'm not in favor of directly showing the actual code from the project repo, as sometimes i simplified the code a little to avoid clutter and focus on the main parts. i also really like the current way of showing the implementation in the main body of the docs and the corresponding config section on the right. docs update i have submitted the spacy contributor agreement. </desc> <cmt> add link to rel project </cmt> <cmt> update rel model code </cmt> <cmt> small fixes and formatting </cmt> <cmt> edits and updates to implementing rel component docs </cmt> <cmt> final fixes </cmt> <cmt> more small corrections </cmt> <cmt> typo </cmt>",update rel example in docs
4263,"<desc> this is @mattklein123  idea of to fix #5311 store end_stream for each filter,  if a filter has been ""end_stream"", not to call its decodedata() or encodedata() again. need to do this for response_encoder too. risk level:  low testing:  added unit-test </desc> <cmt> test continuedecoding </cmt> <cmt> use end_stream for each filter </cmt> <iss> bug: continuedecoding calls the wrong filter for decodedata() calls </iss>","store end_stream for each filter, and use it to not call decodedata again()"
4264,"<desc> currently it only throws the error if you make the request using request.head(uri) this pr updates to also throw the error when making the request by manually setting the method request({ uri: uri, method: 'head' }) </desc> <cmt> failing test for setting head with a body </cmt> <cmt> throw error if method is head and sending a body </cmt>",throw error when making head request with a body
4265,"<desc> related to #11000. minor refactor before my actual pr for #10516. i moved some related syntax tests out of nameandtyperesolution/ and gave them more descriptive names. there are actually two tests that were duplicated version of others, with a typo in their names. </desc> <cmt> move several tests related to function types from nameandtyperesolution/ to more specific directories </cmt> <cmt> remove duplicate syntax tests for functions taking internal struct types </cmt>",minor cleanup in syntax tests for function types
4266,"<desc> this pr adds a tooltip to the guidetool which shows the current offset of the guide that is changing. also, when holding shift, we can snap to a multiple of a value, which is controlled by the property widget. </desc> <cmt> libgui: add show_tooltip_immediately() </cmt> <cmt> this allows an application to display a tooltip without waiting for a </cmt> <cmt> timer to fire first. </cmt> <cmt> pixelpaint: add tooltip to guidetool to show current offset </cmt> <cmt> the offset of the currently edited guide is shown in a tooltip when </cmt> <cmt> using the guidetool. </cmt>",show offset and add snapping
4267,"<desc> this strives to fix several issues with cordova integration plugins handling: fixes several cases causing cordova plugins reinstall on every build: proper handling of scoped npm cordova plugins (adding one would cause reinstall on every build) proper detection of plugin removal (previously a cordova plugin containing a dependency would make the algorithm think a package was removed from cordova-plugins) proper handling of plugins which have plugin.xml id different than the npm package name additionally: rechecks the build integrity verifying if packages were really installed and perform a retry if needed. allows to override a meteor package cordova dependency with scoped package i.e. @scope/cordova-dummy-plugin will now override a cordova-dummy-plugin dependency. (now in this case the same plugin will be installed twice, cordova will leave the last one installed) fixes <dependency id=""es6-promise-plugin"" url="" the main benefit is that the full plugins uninstall and reinstall will only happen on plugin being updated, removed or added. now for most projects it happens every build even though cordova-plugins file did not change. additionally because cordova_lib is not handling properly the promises from plugin remove a situation is happening when plugins are missing - this adds a re-check of plugins state and retries to add missing plugins. fixes: #9548 #9973 </desc> <cmt> validating cordova plugins installation (#9548) </cmt> <cmt> improvements to cordova plugin set change detection algorithm </cmt> <cmt> fixes several cases causing cordova plugins reinstall on every build: </cmt> <cmt> - proper handling of scoped npm cordova plugins </cmt> <cmt> - proper detection of plugin removal (previously a cordova plugin containing a dependency would make the algorithm think a package was removed from cordova-plugins) </cmt> <cmt> - proper handling of plugins which have plugin.xml id different than the npm package name </cmt> <cmt> additionally rechecks the build integrity verifying if packages were really installed and perform a retry if needed. </cmt> <cmt> allows to override a meteor package cordova dependency with scoped package i.e. @scope/cordova-dummy-plugin will now override a cordova-dummy-plugin dependency. </cmt>",cordova plugin handling algorithm consistency improvements
4268,"<desc> compiled by vs2010. update powervr libs to 2.09.29. </desc> <cmt> compilation bug fix. starting android port. </cmt> <cmt> glintptr compilation fix </cmt> <cmt> compilation fix for iphone/android regarding opengl and gl usage </cmt> <cmt> android gles2.0 black screen but compile and run </cmt> <cmt> gles2.0 on android device, some work should be done to detect the correct gles version and launch with the correct parameter. </cmt> <cmt> compilation issue fix </cmt> <cmt> some bug fixes about ios compilation </cmt> <cmt> remove debug and android-10 target downgraded to 8 </cmt> <cmt> remove debug from cocos2x android.mk </cmt> <cmt> opengles11context can run on win32, and update pvr lib to 2.0.9. </cmt> <cmt> opengles20context compiled ok, and add pvr gles2 libs to 2.09.29.0649. </cmt> <cmt> issue #757 helloworld and tests compiled by vs2010 based on ogles2 run correctly on win32. </cmt>",gles2.0 helloworld and tests perform correctly on win32.
4269,<desc> description: changes a few coding cases to make import cleaner. risk level: low testing: //test/... docs changes: n/a release notes: n/a </desc> <cmt> make imports easier with some minor cleanups. </cmt> <cmt> format </cmt> <cmt> rename a variable to make it easier to find with 'sed' in google's import. </cmt>,minor changes to make import to google easier
4270,<desc> replace uses of _.kebabcase() with kebabhash(). #4637 this is our first gatsby pr so all feedback welcome. i ran yarn test and updated the snapshots to have the same number of test failures as the v2 branch. </desc> <cmt> add dep kebab-hash to packages/gatsby. #4637 </cmt> <cmt> replace _.kebabcase() with kebabhash(). #4637 </cmt> <cmt> add dep kebab-hash to packages/gatsby. #4637 </cmt> <cmt> replace _.kebabcase() with kebabhash(). #4637 </cmt> <cmt> in the gatsby-plugin-netlify package. </cmt> <cmt> bump kebab-hash to 0.1.2. #4637 </cmt> <cmt> update snapshots for new path id format. #4637 </cmt>,use kebabhash() instead of _.kebabcase()
4271,"<desc> i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): when determining shards of a ""distributed"" table to be covered by a read query (for optimize_skip_unused_shards = 1) clickhouse now checks conditions from both prewhere and where clauses of select statement </desc> <cmt> process prewhere clause in optimize_skip_unused_shards </cmt> <cmt> added +x for test </cmt>","process prewhere clause in ""skip unused shards"" optimization"
4272,"<desc> c# apps use the ""x86"" platform identified whereas c++ use win32. fix the cli to account for this. fixes #6213 microsoft reviewers: open in codeflow </desc> <cmt> c# apps have x86 platform=x86 but c++ apps have win32 </cmt> <cmt> change files </cmt> <iss> ""yarn windows --release"" fails to deploy in e2etest </iss>",fix deploy of c# apps in release x86
4273,"<desc> update node.js to v4.8.1. notable changes:  update npm package to v4.4.4. notable changes:  i'll highlight this part: less verbose error messages with this change the output is cut down substantially, centering the error message. this means that users should expect a lot of the extra (generally repetitive and unhelpful) details to go away with this update.  for example, the following verbiage is no longer always present: npm err! make sure you have the latest version of node.js and npm installed. npm err! if you do, this is most likely a problem with the error-prone package, npm err! not with npm itself. npm err! tell the author that this fails on your system: npm err!     echo ""error: success"" && exit 255 npm err! you can get information on how to open an issue for this project with: npm err!     npm bugs error-prone npm err! or if that isn't available, you can get their info via: npm err!     npm owner ls error-prone update node-gyp and node-pre-gyp packages. node-gyp - adds support for visual studio 2017.  node-pre-gyp - nothing notable. </desc> <cmt> update node.js to v4.8.1. </cmt> <cmt> notable changes: </cmt> <cmt>  </cmt> <cmt> disable display of update msg about npm itself, since it's bundled. </cmt> <cmt> as of npm 4.4.0 this is necessary as it will now self-check once per day </cmt> <cmt> for updates.  meteor pre-bundles the version of npm though so this </cmt> <cmt> message will be confusing to users of the meteor tool. </cmt> <cmt>  </cmt> <cmt> update npm package to v4.4.4. </cmt> <cmt> notable changes: </cmt> <cmt>  </cmt> <cmt> update node-gyp and node-pre-gyp packages. </cmt> <cmt> * node-gyp - adds support for visual studio 2017. </cmt> <cmt> - </cmt> <cmt> * node-pre-gyp - nothing notable. </cmt> <cmt> - </cmt>","update node.js, npm, node-gyp, node-pre-gyp."
4274,"<desc> closes #35889 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry in v1.1.2.rst </desc> <cmt> bug: add unit test, should fail (#35889) </cmt> <cmt> expand tests: group with no np.nan, fix expected output (#35889) </cmt> <cmt> * tests should still fail. </cmt> <cmt> * test dropna=true|false with no np.nan in groupings. </cmt> <cmt> * fix expected outputs, declare expected multiindex in resulting </cmt> <cmt> dataframe after df.group().apply() </cmt> <cmt> double quotes instead of single quote (#35889) </cmt> <cmt> adjust comparison: handle np.nan compare (#35889) </cmt> <cmt> * nans at same positions in level and key compares as equal. </cmt> <cmt> refactor test: handle multiindex dropping nan (#35889) </cmt> <cmt> * this makes test pass. </cmt> <cmt> * follow existing style where we create multiindex, </cmt> <cmt> then set_levels to reinsert nan for case when </cmt> <cmt> dropna=false, and groups has nan grouping. </cmt> <cmt> bug: update rst (#35889) </cmt> <cmt> bug: run code formatters (#35889) </cmt> <cmt> * black pandas </cmt> <cmt> * git diff upstream/master -u -- ""*.py"" | flake8 --diff </cmt> <iss> bug: groupby dropna=false with nan value in groupby causes valueerror when apply() </iss>",fix dataframe.groupby().apply() for nan groups with dropna=false
4275,"<desc> we want to build networkmanager with -wvla to forbid variable-length arrays. the reason is that glib's g_static_assert() is implemented using an array of negative size, and it can easily happen by mistake that the argument is not a const-argument. for example, when using a static-assert inside a macro, it's much less obvious that the argument is expected to be a constant expression. a non-const expression leads to silently accept the condition by interpreting the result at run-time (actually, at runtime there isn't anything to execute either, because the statement is just a variable declaration). for macros we often declare a temporary variable using typeof() to evaluate the argument only once and avoid size-effects. with variable-length arrays, typeof() and sizeof() are evaluated at runtime, unexpectedly evaluating the expression. as networkmanager has a fork of some systemd sources, we patch them to not use strlen() in such cases to avoid the -wvla warning. but we don't like deviating our fork from upstream and try to minimize such modifications. an alternative would be to build the particular sources with -wno-vla, but that would require to detect support for -wvla in the first place (which it's even more ugly then patching the fork). obviously, systemd makes many uses of this like char path[strlen(""/proc/self/fdinfo/"") + decimal_str_max(int)]; the pull request doesn't fix most uses, only the two that annoy us. i don't actually believe that systemd likes this approach, but i would be happy if  the pull request would be accepted. an alternative would be to forgo the strlen() macro and use sizeof() directly. i don't mind either way. thanks for consideration. </desc> <cmt> basic/macros: add strlen() to get length of string literal as constant expression </cmt> <cmt> while the compiler likely optimizes strlen(x) for string literals, </cmt> <cmt> it is not a constant expression. </cmt> <cmt> hence, </cmt> <cmt> char buffer[strlen(""option_000"") + 1]; </cmt> <cmt> declares a variable-length array. strlen() can be used instead </cmt> <cmt> when a constant espression is needed. </cmt> <cmt> it's not entirely identical to strlen(), as strlen(""a\0"") counts 2. </cmt> <cmt> also, it only works with string literals and the macro enforces </cmt> <cmt> that the argument is a literal. </cmt> <cmt> tree-wide: use strlen() to allocate buffer of constant size </cmt> <cmt> using strlen() to declare a buffer results in a variable-length array, </cmt> <cmt> even if the compiler likely optimizes it to be a compile time constant. </cmt> <cmt> when building with -wvla, certain versions of gcc complain about such </cmt> <cmt> buffers. compiling with -wvla has the advantage of preventing variably </cmt> <cmt> length array, which defeat static asserts that are implemented by </cmt> <cmt> declaring an array of negative length. </cmt>",don't use strlen() to declare variable-length arrays
4276,"<desc> note: this doesn't really do anything, but will allow testing the subroutines pr. also it is unclear whether berlin will have any changes which require breaking evmc api changes. </desc> <cmt> update evmc to 7.2.0 </cmt> <cmt> evmhost: simplify code using new evmc features </cmt> <cmt> evmhost: enable support for berlin </cmt>",update evmc to 7.2.0 and enable berlin support
4277,"<desc> some existing tests are modifying the caffe mode halfway through the execution, this is documented to be invalid:  if, for performance reasons, host memory is allocated through cudamallochost, changing the mode halfway can cause a pointer returned by cudamallochost to be freed by free(2), resulting in undefined behavior. the reciprocal is also possible. another possible issue is that if some tests incorrectly assume that the default mode is cpu, the test could actually run on the gpu if the previous test clobbered the global mode. see the full analysis of this issue in #2398 the solution is, imho, to forbid calls to caffe::set_mode() in individual test cases, this function should only be called by the test framework in order to limit the risks of a misuse. to achieve this, the following patch set reuses the existing multidevicetest class and similarly add new classes gpudevicetest and cpudevicetest. in the case where we need to share code between cpu and gpu tests, the shared test code can directly derive from class multidevicetest but derived classes needs to be defined for cpu and gpu. </desc> <cmt> refactor types floatcpu and doublecpu into a new type cpudevice<t> </cmt> <cmt> similarly, floatgpu and doublegpu are replaced by a new type gpudevice<t>. </cmt> <cmt> split class mathfunctionstest into cpumathfunctionstest and gpumathfunctionstest </cmt>",fix invalid mode changes during tests
4278,"<desc> fixes #16326 allow falsy union types like false | t or null | t in spread in order to allow conditionally spreading: function f(shouldspread: boolean, origin: a, spreadee: b) { return { ...origin, ...shouldspread && spreadee }; } it's worth noting that this works currently without strictnullchecks because the type of shouldspread && spreadee is b. however, with strictnullchecks it becomes false | b. this pr special-cases changes the isvalidspreadtype check to allow falsy unions, which are unions that have (1) have one or more falsy types (2) whose non-falsy parts return true for isvalidspreadtype. this is actually stricter than before; these spreads are no longer allowed: var n = { ...null }; var u = { ...undefined }; var un = { ...null, ...undefined }; earlier in the pr's history, i had to to create a bespoke partial<t> which was pretty clunky, but this code is not actually needed to fix the example from #16326, which i believe is by far the most common pattern. </desc> <cmt> allow booleans in spread types </cmt> <cmt> special-case types produced by bool && expr with the type false | t. </cmt> <cmt> this spreads partial<t> instead of false | t. </cmt> <cmt> update spread tests for booleans in spread types </cmt> <iss> [suggestion] support conditionally setting keys with the spread operator </iss>",allow falsy | t spreads for falsy primitives
4279,"<desc> i created maze search problem using bfs. for example if the input grid is: 101111 101010 101011 111011 the minimum steps from location (0,0) to (3,5) is 14, so the output is 14. another example: 100 011 011 you cannot go from (0,0) to (2,2), so the output is -1. if creating a new file : added links to it in the readme files ? included tests with it ? added description (overview of algorithm, time and space compleixty, and possible edge case) in docstrings ? </desc> <cmt> create maze_search.py </cmt> <cmt> create test_bfs.py </cmt> <cmt> create __init__.py </cmt> <cmt> update readme.md </cmt> <cmt> update readme.md </cmt> <cmt> update readme_cn.md </cmt> <cmt> update readme_ge.md </cmt> <cmt> update readme_jp.md </cmt> <cmt> update readme_kr.md </cmt>",created bfs maze_search.py and test case
4280,"<desc> closes #33313 tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry  n/a pandas.io.parquet.get_engine() uses handling of importerrors for flow control to decide which parquet reader engine is used. in doing so, it quashed lower-level error messages that would have been helpful to the user attempting to diagnose the error, replacing it with a misleading error message. i refactored the error handling, allowing for these lower-level error messages to be collected and explicitly ""bubbled up"". thus fixing the incorrect error message. no tests added -- this behaviour is not worthy of testing. presumably not worthy of a whatsnew entry either. </desc> <cmt> collect import error messages and display them </cmt> <cmt> black </cmt> <iss> bug: bad error message on read_parquet() when wrong version of pyarrow is installed </iss>",fix read parquet import error message
4281,"<desc> this pr introduces the following fixes: duplicate tags are largely eliminated on /blog/tags (e.g. react vs. react, jamstack vs. jamstack, etc.) only tags tied to blog posts are shown (e.g. fixes  removes redundant gatsby tags (note: this was manual and not programmatic) i feel like the tolowercase() and kebabcase mix is a little janky. in the past, i've solved this by adding a custom slug resolver, but it's a bit harder to do with tags. that said, other approaches more than welcome :) </desc> <cmt> chore: remove gatsby tag from blog posts </cmt> <cmt> fix: iron out some issues on the tag pages </cmt>",fix tag pages on blog/docs
4282,"<desc> update scripts under tools/ to use $map.increment and documentation examples. the 1st commit replaces the increments by 1 the 2nd commit replace increments of steps bigger than 1, as introduced in #1897 the 3rd one updates the documentation cc/ @bobrik </desc> <cmt> replace boilerplate for increment with a call to increment </cmt> <cmt> from new tooling. found cases to replace using ripgrep[1]: </cmt> <cmt>  </cmt> <cmt> $ rg '\(\*\w+\)\s*\+\+' -l | grep tools | grep -v old </cmt> <cmt>  </cmt> <cmt> [1]: </cmt> <cmt> replace boilerplate for bigger than 1 increments with the new </cmt> <cmt> increment call </cmt> <cmt> from new tooling. found cases to replace using ripgrep[1]: </cmt> <cmt>  </cmt> <cmt> $ rg '\(\*\w+\)\s*\+=' -l | grep tools | grep -v old </cmt> <cmt>  </cmt> <cmt> [1]: </cmt>",update scripts to use increment
4283,"<desc> with index.js imports a.glsl imports sub/a.glsl imports sub/b.glsl, the last import (using require(./b)) should be relative to sub, not asset.filepath (which is in the parent folder. closes #7253 </desc> <cmt> add test </cmt> <cmt> fix </cmt> <iss> glsl transformer fails to find nested vendor dependencies (works in v1, fails in v2) </iss>","resolve glsl relative to the importer, not the asset"
4284,<desc> we're proud to have launched vue formulate 2.0 as an open-source form authoring solution for vue.js. this pr adds vue formulate to 3 lists which all apply to the capabilities of the tool. additions have been made to the bottom of the lists on: generator form form -> validation </desc> <cmt> adds vue formulate to relevant sections of the readme.md file </cmt> <cmt> specifies front-end validation in regards to form validation </cmt>,adds vue formulate to relevant lists
4285,<desc> don't checkout llvm-project don't require cmake and ninja fixes #78564 </desc> <cmt> don't checkout llvm-project when the llvm backend isn't built </cmt> <cmt> don't require cmake and ninja when the llvm backend is not used </cmt> <iss> bootstrap: don't mandate cmake and ninja when the llvm backend is disabled </iss>,misc rustbuild improvements when the llvm backend isn't used
4286,<desc> on the way towards #602 note: i could not find as last_change for linux interfaces. note2: these might want to include flags (on both osx/linux). </desc> <cmt> added interfaces to linux </cmt> <cmt> merged linux/osx interfaces implementation </cmt>,"implement interface_addresses, interface_details for linux"
4287,<desc> this pr fixes the error in #42489 this error is caused by not sending activation parameter with conv + bn + leakyrelu pattern in remapper.cc 4d022d6 is the squeeze commit for all  commits in #42489 6aabcb1 updates the unit test to capture the error found in google internal test. 62db9a7 fixes the error. </desc> <cmt> enable conv + (bias/bn) + leakyrelu fusion </cmt> <cmt> update remapper tests for copy leakyrelu alpha </cmt> <cmt> fix missing activation in conv bn leakyrelu copyattr </cmt>,enable conv + (bias+bn) + leakyrelu fusion with eigen implementation in cpu (resubmit)
4288,<desc> description: adds reset reason to logs for debug purpose and to the body as well. risk level: low testing: existing tests docs changes: n/a release notes: n/a </desc> <cmt> log reset reason and add it to body </cmt>,add reset reason to logs and body
4289,"<desc> both the sentencepiece and tokenizers libraries can limit the users: sentencepiece is not available on conda on every plateform and one of the reason transformers is not on conda tokenizers cannot be used inside some labs which need to build all from source and don't have a rust tooling. this pr aim at making both optional leveraging the addition of sentencepiece algorithms in tokenizer. note: at least one of sentencepiece and tokenizers will be required to use the sentencepiece tokenizers. tokenizers is also required to use the fast tokenizers. main changes in the library organization: fast tokenizers are now separated in tokenization_xxx_fast.py files a convert_slow_tokenizer.py file host conversion methods for a slow to a fast tokenizer but a direct path from a tokenizers serialization file is favored when such a file is available. the test suite for slow and fast tokenizers are now gathered in a single test suite. main new requirements for the tokenizers to pass the new test suite: at least one default vocabulary checkpoint (and max length) should be provided, it is used for the deep tests the fast tokenizer should have an explicit tokenizer_file keyword argument with a default to none (we check that to be sure all the fast tokenizer can accept the new serialization format. to-add: when the documentation for tokenizers is ready: add a lot of link on how to build and add a fast tokenizer add a detailed explanation on how to add a fast tokenizer in the library this pr also: add a __repr__ for the tokenizers (finally...) add a name_or_path attribute to the models and tokenizers giving the shortcut name or the path of the pretrained checkpoint used for instantiation update the fast tokenizer to use (when possible) the new serialization format of the tokenizers library, falling back on the old diverse set of saving format if not available. clean up the tests for the fast tokenizers to bring them in the common tokenizer tests fixes #7402 #5100 (and maybe others) documentation guidelines, and here are tips on formatting docstrings. </desc> <cmt> splitting fast and slow tokenizers [wip] </cmt> <cmt> [wip] splitting sentencepiece and tokenizers dependencies </cmt> <iss> tokenizers as an optional dependency </iss>",make both sentencepiece and tokenizers optional dependencies
4290,"<desc> fixes #111 the modulo operator on this calculator gives the result that is different to the most used calculators. the current modrate function is the equivalent of rem(...)/remainder(...), not mod(...)/modulo(...) available in some popular math apps. rename modrate in remrate to be more accurate. add modrate, calculating modulo similarly to matlab, bing, google calculator, maxima, wolfram alpha and microsoft excel add rationalmath::mod using modrate as an alternative to rational::operator% using remrate add a helper sign to retrieve the sign of a rational. modify calcengine to use modrate in normal and scientific mode and remrate in programmer mode. manually and unit tests added </desc> <cmt> - rename modrate in remrate </cmt> <cmt> - add modrate (arithmetic modular) </cmt> <cmt> - modify calcengine to use modrate in normal and scientific mode and remrate in programmer mode </cmt> <cmt> add unit tests to test rem(x, 0) and mod(x, 0) </cmt> <iss> modulo operator should work like other calculators out there </iss>",modify how modulo is calculated in normal and scientific mode.
4291,<desc> description: use renamed pypi dependency to 'pyps4-2ndscreen' from 'pyps4-homeassistant' fixes issue where cannot turn on ps4 consistently. try to fix flaky tests leaving files behind checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. </desc> <cmt> change to renamed dependency pyps4-2ndscreen 0.9.0 </cmt> <cmt> rename / bump to ps4 dependency to 1.0.0 </cmt>,ps4 bump to renamed dependency
4292,"<desc> xcpretty has been pretty bad at showing reasonable test failure messages recently, so i am reverting to egrep filter strategy and made some changes to better debug jenkins/kokoro test failures. </desc> <cmt> revert to more useful debug info </cmt> <cmt> show passed tests as well </cmt>",get more useful debug info out of jenkins
4293,<desc> backport of: don't suggest placing use statements into expanded code #44215 stabilize tcpstream_connect_timeout #44563 stabilized iterator_for_each #44567 travis: move sccache to the us-west-1 region #44574 stabilized ord_max_min #44593 stabilized compiler_fences #44595 ci: upload/download from a new s3 bucket #44617 stabilized needs_drop #44639 stabilized vec_splice and modified splice tracking issue #44640 backport libs stabilizations to 1.21 beta #44824 </desc> <cmt> stabilize tcpstream_connect_timeout (closes #43079) </cmt> <cmt> travis: move sccache to the us-west-1 region </cmt> <cmt> most of the other rust-lang buckets are in us-west-1 and i think the original </cmt> <cmt> bucket was just accidentally created in the us-east-1 region. let's consolidate </cmt> <cmt> by moving it to the same location as the rest of our buckets. </cmt> <cmt> stabilized ord_max_min (fixes #25663) </cmt> <cmt> stabilized iterator_for_each (closes #42986) </cmt> <cmt> updated clippy and rls as it uses the iterator_for_each </cmt> <cmt> stabilized compiler_fences (fixes #41091) </cmt> <cmt> added example to compiler_fence docs taken from unstable-book </cmt> <cmt> added more text from unstable-book to compiler_fence docs </cmt> <cmt> ci: upload/download from a new s3 bucket </cmt> <cmt> moving buckets from us-east-1 to us-west-1 because us-west-1 is where </cmt> <cmt> rust-central-station itself runs and in general is where we have all our other </cmt> <cmt> buckets. </cmt> <cmt> stabilized needs_drop (fixes #41890) </cmt> <cmt> stabilized vec_splice (fixes #32310) </cmt> <cmt> updated tracking issue for string::splice and its unstable-book entry </cmt>,backport accepted prs to 1.21
4294,"<desc> deleting directory make gatsby crash. when working with markdownfiles and deleting a directory the developer server will crash. the same check that is for files should also be on directories, otherwise it might try to delete a directory that does not exist. </desc> <cmt> update gatsby-node.js </cmt> <cmt> deleting directory make gatsby crash. when working with markdownfiles and deleting a directory the developer server will crash. the same check that is for files should also be on directories, otherwise it might try to delete a directory that does not exist. </cmt> <cmt> update gatsby-node.js </cmt>",developer server crash when deleting markdown directories
4295,"<desc> release notes for maven-surefire-plugin 2.19: new parser of test patterns, let's call it test filter api, related to parameters: test, ex/includes, ex/includesfile; a feature to interrupting the test-set after exceedded certain number of errors/failures new doxia version anchoring test class names shutdown operations command based communication between in-plugin and forked process improvements in junit and testng runners etc. see  release notes for maven-checkstyle-plugin 2.17: bug improvement task release notes - apache maven clean plugin  version 3.0.0  improvements: release notes - apache maven shade plugin  version 2.4.2  bugs: improvements: same as #14193 but on 2.x branch </desc> <cmt> update surefire to 2.19 and checkstyle to </cmt> <cmt> # release notes for maven-surefire-plugin 2.19: </cmt> <cmt> * new parser of test patterns, let's call it test filter api, related to </cmt> <cmt> parameters: test, ex/includes, ex/includesfile; </cmt> <cmt> * a feature to interrupting the test-set after exceedded certain number of </cmt> <cmt> errors/failures </cmt> <cmt> * new doxia version </cmt> <cmt> * anchoring test class names </cmt> <cmt> * shutdown operations </cmt> <cmt> * command based communication between in-plugin and forked process </cmt> <cmt> * improvements in junit and testng runners </cmt> <cmt> * etc. </cmt> <cmt> see </cmt> <cmt> # release notes for maven-checkstyle-plugin 2.17: </cmt> <cmt> ## bug </cmt> <cmt> * [mcheckstyle-302] - using inline configuration does not work with maven 2.2.1 </cmt> <cmt> * [mcheckstyle-304] - using inline configuration, checkstyle-checker.xml is generated using dtd v1.2 </cmt> <cmt> * [mcheckstyle-310] - parrallel build failing with various errors </cmt> <cmt> * [mcheckstyle-311] - ""mvn clean site -preporting"" fails with could not find resource 'config/maven_checks.xml' </cmt> <cmt> ## improvement </cmt> <cmt> * [mcheckstyle-291] - change format of violation message </cmt> <cmt> * [mcheckstyle-293] - update to use non deprecated method checker.setclassloader() </cmt> <cmt> ## task </cmt> <cmt> * [mcheckstyle-307] - upgrade to checkstyle 6.11 </cmt> <cmt> * [mcheckstyle-313] - upgrade to checkstyle 6.11.2 </cmt> <cmt> update clean plugin to 3.0.0 </cmt> <cmt> # release notes - apache maven clean plugin  version 3.0.0 </cmt> <cmt>  </cmt> <cmt> ## improvements: </cmt> <cmt> * [mclean-56] - make plugin only 3.x compatible - get rid of maven 2. </cmt> <cmt> * [mclean-62] - upgrade to maven-plugins parent version 27 </cmt> <cmt> * [mclean-63] - make naming of properties consistent </cmt> <cmt> * [mclean-65] - bump version to 3.0.0 </cmt> <cmt> * [mclean-66] - upgrade maven-shared-utils to 0.9 </cmt> <cmt> * [mclean-67] - change package name to org.apache.maven.plugins </cmt> <cmt> * [mclean-69] - upgrade maven-shared-utils to 3.0.0 </cmt> <cmt> update maven shade plugin to 2.4.2 </cmt> <cmt> although not really used: </cmt> <cmt> release notes - apache maven shade plugin  version 2.4.2 </cmt> <cmt>  </cmt> <cmt> bugs: </cmt> <cmt> * [mshade-172] - ""java.lang.arithmeticexception: / by zero"" in minijarfilter </cmt> <cmt> * [mshade-190] - shade does not relocate the contents of meta-inf/services files </cmt> <cmt> * [mshade-209] - [regression] ""java.lang.arithmeticexception: / by zero"" in minijarfilter (reporter jon mclean). </cmt> <cmt> improvements: </cmt> <cmt> * [mshade-205] - better use of clazzpathunit for improved jar minimization (contribution of benoit perrot). </cmt> <cmt> * [mshade-207] - replace wrong link to codehaus with correct location </cmt> <cmt> * [mshade-210] - upgrade maven-plugins parent to version 28. </cmt> <cmt> * [mshade-211] - keep java 1.5 </cmt>","update surefire to 2.19, checkstyle to 2.17, clean to 3.0.0, shade to 2.4.2"
4296,"<desc> fixes #13102 did you read the contributor guideline, pull request section? was this discussed/approved via a github issue or the forum? inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) #13102 @patrickvonplaten @patil-suraj </desc> <cmt> fix inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) (#13102) </cmt> <cmt> fix missing elements in outputs tuple </cmt> <iss> inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) </iss>",fix flax gpt2 hidden states
4297,"<desc> the pattern let &(ref a, ref b) = &selfcauses a compiler ice. avoid use of it in libcore/to_bytes.rs. </desc> <cmt> libcore/to_bytes.rs: add iterbytes impls for pairs and triples </cmt> <cmt> libcore/to_bytes.rs: fix iterbytes instances for pairs, triples to not cause ice when used </cmt>","fix tuple instances for iterbytes to avoid ice, fixes #4092"
4298,<desc> fixes #40488 and #40489. </desc> <cmt> modify test case to reproduce error </cmt> <cmt> fix typeonlyexport codefix to work with 3 or more type exports in the same declaration </cmt> <cmt> the check to ensure that a fixed export declaration wasn't fixed again </cmt> <cmt> was reversed. this only surfaced when 3 or more type exports existed in </cmt> <cmt> the same declaration. </cmt> <cmt> add failing test cases for comments being duplicated </cmt> <cmt> fix converttotypeonlyexport codefix from duplicating leading comments </cmt> <iss> converttotypeonlyexport codefix breaks when applying all codefixes to an export with 3 re-exported types </iss>,fix two issues with converttotypeonlyexport codefix
4299,"<desc> --preload-file / --embed-file add some pre-js code to load the file. a user pre-js can break that if it does module = {} for example, as the files have assigned to module.prerun to set up a task. this is rare because preloading files is really just common on the web, and there we normally don't do module = { .. } in the js. instead the module is defined on the html earlier. however, i debugged something now that ended up being this, and it can be confusing. to avoid others being confused, add some assertions that check that module.prerun has the right values even after the user pre-js. </desc> <cmt> rev </cmt> <cmt> more [ci skip] </cmt> <cmt> more </cmt> <cmt> fix </cmt> <cmt> flake8 </cmt>",add an assertion for bad --pre-js / files interaction
4300,"<desc> this adds host grouping based on ""service"" and ""stack"" to the docker.py inventory script. docker.py inventory ansible version ansible 2.7.0 config file = none configured module search path = [u'/home/eric/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible executable location = /usr/local/bin/ansible python version = 2.7.15rc1 (default, apr 15 2018, 21:51:34) [gcc 7.3.0] this makes no change to existing functionality but extends the grouping of containers based on image to group on stack and service as well. this is done by conditionally keying the a host's groups off of the labels com.docker.stack.namespace and com.docker.swarm.service.name. the derived groups are in the format service_<service_name> and stack_<stack_name> you can find the docker-compose file i used to create these groups here. excerpt from ""pretty"" docker.py output: $ contrib/inventory/docker.py | jq .service_ansible_mock_host [ ""ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef"", ""ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann"", ""ansible_mock_host.3.sn74oapkk5ay3la148js5z93n"", ""ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b"", ""ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg"", ""ansible_mock_host.3.ly13cxwzvibmuf6volsr8t1z8"", ""ansible_mock_host.2.bkiiay0a48a3koxkgbvvte9me"" ] $ contrib/inventory/docker.py | jq .stack_ansible_mock [ ""ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef"", ""ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann"", ""ansible_mock_host.3.sn74oapkk5ay3la148js5z93n"", ""ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b"", ""ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg"", ""ansible_mock_host.3.ly13cxwzvibmuf6volsr8t1z8"", ""ansible_mock_host.2.bkiiay0a48a3koxkgbvvte9me"" ] # warnings omitted from output for legibility $ ansible -i contrib/inventory/docker.py 'stack_ansible_mock:&running' \ -m ping -e ansible_connection=docker -e ansible_python_interpreter=/usr/local/bin/python ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann | success => { ""changed"": false, ""ping"": ""pong"" } ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg | success => { ""changed"": false, ""ping"": ""pong"" } ansible_mock_host.3.sn74oapkk5ay3la148js5z93n | success => { ""changed"": false, ""ping"": ""pong"" } ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b | success => { ""changed"": false, ""ping"": ""pong"" } ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef | success => { ""changed"": false, ""ping"": ""pong"" } </desc> <cmt> adding service and stack grouping to docker inventory </cmt> <cmt> updating documentation </cmt>",docker inventory service/stack groups for docker swarm
4301,<desc> not sure if this is already fixed upstream but in case it's not @merceyz tests failed for me as well with core.autocrlf=false on win10 and passed after this fix. @mnajdova could you check this out and see if it works? if not please include the output of git config --get core.autocrlf </desc> <cmt> [test] fix ttp tests failing on windows </cmt> <cmt> fix macro tests as well </cmt>,fix failing tests on windows
4302,"<desc> summary master: installation of mkl and mkl-services: 10.10s installation of pil/pillow: 11s installation of pydot graphvis: 21s total: 43s proposed: grouped installation of  mkl ,mkl-services pil/pillow pydot graphvis: 24.8s. we can save ~18s on all travis jobs. related issues pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) </desc> <cmt> grouped conda installation together. </cmt> <cmt> added travis retry. </cmt>",grouped conda installations together to speed up the travis build.
4303,"<desc> this pr adds min, max and clamp as css functions to data types. this allows us to also write more ""modern"" arbitrary values, e.g.: <div class=""text-[min(10vh,100px)]""></div> which results in: .text-\[min\(10vh\2c 100px\)\] { font-size: min(10vh, 100px); } before this pr, this code wouldn't even be generated, if you wanted this to be generated then you had to force the length: data type for example: <div class=""text-[length:min(10vh,100px)]""></div> </desc> <cmt> update changelog </cmt> <cmt> add tests to verify that w-[0] works </cmt> <cmt> ensure that min, max and clamp also work with arbitrary values </cmt>",add css functions to data types
4304,<desc> this will add support for google voice sms. this is dependent on </desc> <cmt> pygooglevoice-sms support </cmt> <cmt> pygooglevoice-sms support </cmt> <cmt> updated googlevoicesms version </cmt> <cmt> added target support for googlevoice </cmt> <cmt> fixed style errors </cmt> <cmt> added test exclude in .coveragerc </cmt>,google voice sms notification support
4305,"<desc> this changes add documentation for accessing datetimes in painless scripts from the three most common inputs of params, _source, and doc. </desc> <cmt> add inputs for datetimes </cmt> <cmt> quick word change </cmt> <cmt> checkpoint </cmt> <cmt> add painless datetime input documentation </cmt>",add painless docs for datetime inputs
4306,"<desc> have you signed the contributor license agreement? resolves #409 when resource.pri is not present a winrt::hresult_error is thrown by the loader. we then catch the exception and try to log using a localized string which makes the exception be thrown again. this changes adds a try catch in winrt::hresult_error catch. the new catch will default to the english message for unexpectederrorexecutingcommand. also add logging when the loader fails. microsoft reviewers: open in codeflow </desc> <cmt> add try catch and logging for failed to load resources file </cmt> <cmt> handle exception better </cmt> <iss> after building from source code, winget ""install"" command crashes when trying load string from resources. </iss>",fix crash when resource.pri is not present
4307,"<desc> allow user to disconnect a connection on server side and passing websocket close status code (1000 or 4000-4999 and close reason. modify the handler of close frame in swwebsocket_dispatch_frame, avoid sending double close frames when the server actively close the connection. add a simple test tests/swoole_websocket_server/websocket_disconnect.phpt for testing disconnect method. </desc> <cmt> add websocket_server disconnect, change websocket dispatch close frame logic </cmt> <cmt> websocket_server->disconnect($fd, $code, $reason) </cmt> <cmt> close frame: </cmt> <cmt> 1. start and send by client, response with close frame with echo </cmt> <cmt> 2. start by server and send by client, no reply </cmt> <cmt> add test for websocket_server->disconnect() </cmt> <cmt> fix tab intend with 4 spaces </cmt> <cmt> fix tab intend with 4 spaces </cmt>",add websocket server disconnect method with status code and reason
4308,<desc> backport of #16666 </desc> <cmt> [ios] add iphones 11 to the list of known devices </cmt> <cmt> [ios] don't rely on main screen having only one screen mode - it's not true for iphones 11 </cmt> <cmt> partially reverts a85e511 </cmt>,add support for iphones 11
4309,"<desc> the cleanup after federation service e2e tests is not effective as this function cleanupserviceshardsandproviderresources is getting called with empty string for namespace (""nsname"") because the nsname variable is getting redefined. another issue is we are prematurely exiting the poll in waitforserviceorfail and the error check is incorrect. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # fixing the 2 issues mentioned above. release note: </desc> <cmt> fix lb and service leak in federated clusters in e2e tests </cmt> <cmt> fix prematurely exiting testcase while waiting for clustered service </cmt>",fix resource leak in federation e2e tests and another issue
4310,"<desc> changing accidental contentrootpath link to webroot link on generic host doc. this fix should have been in #14108 (diff)     discovered just as it was merged however so fixing here. fixes issue #10559 </desc> <cmt> just updated sxs link per issue 10559 </cmt> <cmt> updates for side by side and web root references </cmt> <cmt> updated per tdykstra recommendations, link changes </cmt> <cmt> changes xref to relative link for web root </cmt> <cmt> link fix, switching contentroot to webroot </cmt>",link fix related to 14108
4311,"<desc> decode the parent expansion for traits and enums in rustc_resolve, this was already being used for resolution in typeck avoid suggesting importing names with def-site hygiene, since it's often not useful add more tests r? @petrochenkov </desc> <cmt> handle cross-crate module expnids consistently </cmt> <cmt> - always use the expnid serialized to tables </cmt> <cmt> - use the id for traits and enums from other crates in resolution. </cmt> <cmt> don't suggest importing items with hygienic names </cmt> <cmt> this will potentially hide a few correct suggestions, but importing </cmt> <cmt> these items from another module is not generally possible. </cmt>",improve and test cross-crate hygiene
4312,"<desc> newlines in the command, args, env.value, or annotations fields are not uncommon. wrap and indent these fields so that describe is more readable. before: host port:     <none> command: /bin/bash #!/bin/bash set -euo pipefail # set by the node image unset kubeconfig trap 'kill $(jobs -p); exit 0' term # track the current state of the config after: host port:     <none> command: /bin/bash #!/bin/bash set -euo pipefail # set by the node image unset kubeconfig trap 'kill $(jobs -p); exit 0' term # track the current state of the config annotations when wrapping: annotations:  kubectl.kubernetes.io/desired-replicas: 1 openshift.io/deployer-pod.completed-at: 2018-07-31 22:47:15 +0000 utc openshift.io/deployer-pod.created-at: 2018-07-31 22:37:11 +0000 utc openshift.io/deployer-pod.name: test-3-deploy openshift.io/deployment-config.latest-version: 3 openshift.io/deployment-config.name: test openshift.io/deployment.phase: failed openshift.io/deployment.replicas: 0 openshift.io/deployment.status-reason: manual change openshift.io/encoded-deployment-config: {""kind"":""deploymentconfig"",""apiversion"":""apps.openshift.io/v1"",""metadata"":{""name"":""test"",""namespace"":""clayton-dev"",""selflink"":""/apis/apps.op... handle newlines for command, args, env, and annotations in kubectl describe wrapping </desc> <cmt> break command and args in description by newline </cmt> <cmt> inline scripts may use newlines in these fields, and properly indenting makes the output more readable: </cmt> <cmt>  </cmt> <cmt> command: </cmt> <cmt> /bin/bash </cmt> <cmt> -c </cmt> <cmt> #!/bin/bash </cmt> <cmt> echo ""inline script should be indented"" </cmt> <cmt>  </cmt> <cmt> environment vars with newlines should be indented </cmt> <cmt> break env var values with newlines so they form a consistent left alignment. </cmt> <cmt> add tests for newline in command, arg, and env </cmt> <cmt> break annotations with newlines and shorten length </cmt> <cmt> make annotations with newlines display a more consistent left edge, and indent the value </cmt> <cmt> when the annotation is too long to give the value more space. shorten the width of the </cmt> <cmt> trimmed annotation to a value more consistent with our -o wide value. </cmt> <cmt> instead of putting the key and value flush with a = separator, make annotations closer </cmt> <cmt> to fields than to labels by using :  as a separator. </cmt>",make kubectl describe more tolerant of newlines
4313,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. / </desc> <cmt> [yandex-maps] fix module format </cmt> <cmt> add missing each() method for layers </cmt> <cmt> make context optional in each() </cmt> <cmt> add tests for layers.each() </cmt>","fix module format, fix each()"
4314,"<desc> background when we have worked on #16991 we wanted to test the new functionalities in concrete and accurate unittest. all chartdata flows and its components are too couple to superset so it is impossible to create unittests. the flows are not testable and so many components do not meet the very important principle srp and the code became so dirty so i've started to refactor it (#17344 ) but many changes were added and it was hard to review so i decided to split those changes into small prs so will be easier to follow this is the eleventh pr in a sequence of prs to meet these the next pr is #17497 pr description querycontext class contains static methods used as dataframe utils. to meet srp, those methods moved to a utils package. to keep the utils meeting srp, it implies arranging the utils to be as package and separating each of the related methods into ad hoc modules. test plans there is no logic added so new tests are not required previous prs #17399 #17400 #17405 #17407 #17425 #17461 #17465 #17466 #17479 #17495 </desc> <cmt> chore(common.utils): modified utils from module based to package based </cmt> <cmt> refactor(common.utils): move querycachemanager to ad-hoc module </cmt> <cmt> refactor(querycontext): move df method utils to utils module </cmt>",move df methods utils to utils package
4315,"<desc> using the gi command provided by the gitignore plugin was causing a % to be shown in the terminal at the end of output. i opened an issue on the gitignore.io repository and they suggested adding -w '\n' to the curl command in order to make curl add the new line character at the end. the linked issue explains what my problem was in more detail. this pr applies the suggested fix. further, arguments expansion has been double-quoted for security reasons. see </desc> <cmt> add trailing new line at the end of output </cmt> <cmt> double-quote variable expansion </cmt> <cmt> it's good practice to double-quote variable expansions, for security </cmt> <cmt> reason. </cmt> <cmt> see </cmt>",minor improvements to the gitignore plugin
4316,"<desc> as is described in #5667, the flannbasedmatcher doesn't work in python (linux and osx confirmed, python 2.7 and 3.5) at the moment. the following code generates an error as of the 3.1 tag: import numpy as np import cv2 img1 = cv2.imread('opencv/samples/data/box.png',0)          # queryimage img2 = cv2.imread('opencv/samples/data/box_in_scene.png',0) # trainimage sift = cv2.xfeatures2d.sift_create() # initiate sift detector kp1, des1 = sift.detectandcompute(img1,none) # find the keypoints and descriptors with sift kp2, des2 = sift.detectandcompute(img2,none) flann_index_kdtree = 0 index_params = dict(algorithm = flann_index_kdtree, trees = 5) search_params = dict(checks=50)   # or pass empty dictionary matcher = cv2.flannbasedmatcher(index_params, search_params) matches = matcher.knnmatch(des1, des2, k=2) # error is thrown opencv error: assertion failed (the data should normally be null!) in allocate, file opencv/modules/python/src2/cv2.cpp, line 163 traceback (most recent call last): file ""test.py"", line 21, in <module> matches = flann.knnmatch(des1, des2,  k=2) cv2.error: opencv/modules/python/src2/cv2.cpp:163: error: (-215) the data should normally be null! in function allocate this seems to be caused by the flannbasedmatcher::add overload, as this does not occur when using the bfmatcher. given the logic from descriptormatcher:add, it looks as though the inputarray was not being properly marshalled. this fixes that and i can confirm that the error no longer occurs on this branch. </desc> <cmt> update indentation to match rest of file </cmt> <cmt> very cosmetic, but was analyzing code and just wanted to make it </cmt> <cmt> consistent. </cmt> <cmt> fix parsing of training vecs for flannbasedmatcher </cmt> <cmt> flannbasedmatcher::add is overloaded, but the style of parsing the </cmt> <cmt> inputarrayofarrays does not match the style from </cmt> <cmt> descriptormatcher::add. the issue is that inputarrayofarrays </cmt> <cmt> must be properly marshalled so that the data can be read </cmt> <cmt> correctly. in this case, the method expects the training </cmt> <cmt> descriptors to be either a vector of matrices or a single matrix </cmt> <cmt> (as is shown in descriptormatcher::add). these code </cmt> <cmt> replicates that for the case of the flannbasedmatcher::add. </cmt> <cmt> in fact, a similar commit to this was added by 26d9a7c but was </cmt> <cmt> ultimately not accepted in #4111. this is likely due to the </cmt> <cmt> fact that the input arrays were not parsed properly and the </cmt> <cmt> case of a single matrix was being improperly handled. i believe </cmt> <cmt> this commit to be correct given the logic from </cmt> <cmt> descriptormatcher::add. </cmt>",flannbasedmatcher python fix (fixes #5667)
4317,"<desc> $ hexo help list above command causes outofmemory. cause at hexo v3.0.1, printlist(title, list) ( hexo/lib/plugins/console/help.js line 59 e8e45ed function printlist(title, list){ ) has a problem. if list have only one element, variable length becomes zero (because of the list is not sorted). then while (padding--){ ... } causes infinite loop. solution i separate setting length from sorting. </desc> <cmt> add test </cmt> <cmt> fix infinite loop </cmt> <cmt> set initial value of length to avoid inifinite loop. </cmt>",hexo help list command causes outofmemory
4318,"<desc> add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { ""extends"": ""dtslint/dt.json"" }. former declaration was broken on koa-websocket 5.0. latest version of koa framework and its components doesn't rely on this. middlewares shares the request context using their first parameter context. </desc> <cmt> fix koa-websocket to match with its implementation </cmt> <cmt> the major change is about middleware. koa-websocket doesn't inject </cmt> <cmt> this argument to its middlewares. instead, additional properties are </cmt> <cmt> appended on the koa context. </cmt> <cmt>  </cmt> <cmt> extract context.websocket </cmt> <cmt> it's necessary to use well with other middlewares, </cmt> <cmt> like koa-router or else. </cmt> <cmt> add context.app to be able to access ctx.app.ws </cmt> <cmt> add a test about context.app </cmt>",fix to match with its implementation
4319,"<desc> add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { ""extends"": ""dtslint/dt.json"" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: < add it to notneededpackages.json. additional info about the change: ioredis package adds a standard version and a buffer version for each redis method there is, but not everyone is exposed through this typing. it's done at the line 83 of this code and is applied at the line 199 of this one. as i'm aware that not all methods provided will fit well with the buffer version typing, hmgetbuffer is an exception: it'll work as expected. @luin @dominikpalo fyk </desc> <cmt> feat: adding hmsetbuffer and hmgetbuffer to ioredis.redis contract </cmt> <cmt> fix: removing hmgetbuffer, as it not fit well typing yet </cmt>",adding hmgetbuffer to ioredis.redis contract
4320,"<desc> add the itemstyle to legend symbol. the default borderwidth of legend symbol is 0, so the bordercolor only can be seen when the legend.itemstyle.borderwidth isn't 0. legend.itemstyle.borderwidth !== 0 the borderwidth of legend symbol only depends on  legend.itemstyle.borderwidth the bodercolor of legend symbol depends on legend.itemstyle.bordercolor and series[i].itemstyle.bordercolor, and the legend.itemstyle.bordercolor has higher priority. the bordercolor of emptycircle legend symbol is the same as color of series the legend bordercolor is incompatible with barbordercolor the former pr </desc> <cmt> fix bug #7340 </cmt> <cmt> fix bug #7340 </cmt>",feature #7340. add the itemstyle to legend
4321,<desc> add new parameters to ovirt_vms module to support high performance vm:  ovirt_vms ansible version 2.4.2 </desc> <cmt> ovirt_vms: add cpu_mode </cmt> <cmt> ovirt_vms: add placement_policy </cmt> <cmt> ovirt_vms: add cpu_pinning </cmt> <cmt> ovirt_vms: add soundcard_enabled </cmt> <cmt> ovirt_vms: add smartcard_enabled </cmt> <cmt> ovirt_vms: add io_threads_enabled </cmt> <cmt> ovirt_vms: add ballooning_enabled </cmt> <cmt> ovirt_vms: add rng_device </cmt> <cmt> ovirt_vms: add custom_properties </cmt> <cmt> ovirt_vms: add memory_max </cmt>,support high performance vm in ovirt
4322,"<desc> fix #1698 #1609 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> subject to the actual startup context path </cmt> <cmt> if not set the context path with the webserverinitializedevent then real '/' is context path </cmt> <cmt> runningconfig support get from spring.properties configuration file </cmt> <cmt> 1. optimize log printing </cmt> <cmt> 2. improve the robustness and readability of your code </cmt> <cmt> support datum is null case </cmt> <cmt> repair httpgetlarge#httpgetlarge will call entity.getcontenttype().getelements() the contenttype is npe </cmt> <cmt> normalize http response entity with responseentity by spring </cmt> <iss> nullpointer exception if sync content is empty </iss>",repair the npe and optimize related code
4323,"<desc> tests added / passed passes black pandas passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry i ran into this while implementing the hvplot backend. in hvplot you can do: df.hvplot.hist(y='y', by='category') but with the pandas version pd.options.plotting.backend= 'holoviews' df.plot.hist(y='y', by='category') will fail because data = data[y]  is called before the plotting is passed off to the backend. basically it seems like backend writers should be free to get the passed pandas objects with as little interference as possible. </desc> <cmt> when using another backend, don't do the munging ahead of time </cmt> <cmt> fixing data </cmt>","when using another plotting backend, minimize pre-processing"
4324,"<desc> before pr all modules were enabled by default. it is a lot of work to enable the ones i need and disable the rest. default: default_run = yes from python.d.conf # if ""default_run"" = ""yes"" the default for all modules is enabled (yes). # setting any of these to ""no"" will disable it. # if ""default_run"" = ""no"" the default for all modules is disabled (no). # setting any of these to ""yes"" will enable it. </desc> <cmt> python.d.plugin: ""default_run"" option for python.d.conf added </cmt> <cmt> python.d.plugin: python.d.conf update </cmt>",option to change default behavior (enabled/disabled) for python modules
4325,"<desc> all packaging environment under docker, now it support: - os=fedora dist=25 - os=fedora dist=26 - os=ubuntu dist=trusty       //14.04 lts, only for build & test & appimage - os=ubuntu dist=xenial       //16.04 lts - os=ubuntu dist=zesty        //17.04 - os=ubuntu dist=artful        //17.10 - os=debian dist=jessie        //8 - os=debian dist=stretch      //9 and appveyor ci for windows. p.s. deb, rpm, appimage package for linux has been realized by the script .travis_linux.sh . i wish you can upload .deb, .rpm, .appimage and windows portable zip archive to github release. </desc> <cmt> improvement of deb package </cmt> <cmt> update </cmt> <cmt> update </cmt> <cmt> rpm and deb package & add appveyor </cmt> <cmt> deploy to github release </cmt>",deb and rpm packaging & add appveyor
4326,"<desc> format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. </desc> <cmt> grpc port modified;change notify bugfix. </cmt> <cmt> default member port fix </cmt> <cmt> modify grpc port to offset </cmt> <cmt> modify grpc port to offset </cmt>",tag publish bugfix; ignore server port for connection reset request.
4327,"<desc> i hereby agree to the terms of the cla available at:  check #3695 (comment) and further comments waiting for server start (via http pings) clickhouse-client added to clickhouse-server image, that is just a symlink but makes it possible to connect to the server running in the container in a natural way with simple sudo docker container exec -it container_name clickhouse-client. related to #580 wget added (actually waiting for accepting connections can be implemented w/o it, but wget is quite tiny and handy) greps changed to clickhouse extract-from-config format_schema_path added gosu moved higher (that makes rebuilds of image connected to lines below it cheaper) </desc> <cmt> documenting numbers table function, verticalraw format, http sessions, http compression. </cmt> <cmt> fixing bad copy-paste, shorten sample </cmt> <cmt> fixing obsolete name of clickhouse-compressor </cmt> <cmt> fix word end </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> merge remote-tracking branch 'upstream/master' </cmt> <cmt> fixes from comments of #3695 </cmt>",docker fixes (related to #3695)
4328,"<desc> opening up a new pr based on #10513 which uses @sgugger's new image_utils.py instead of torchvision for the image transformations, and is up-to-date with master. things to do: fix one integration test (currently vitfeatureextractor converts the numpy arrays into doubletensors, but the model expects floattensors) fix styling (make style is not working as expected on my machine, see remaining comments in previous pr) perhaps change pooler logic? design (and updated conversion script) currently at branch ""add_pooler_to_vit"" </desc> <cmt> squash all commits into one </cmt> <cmt> rebase with master </cmt> <cmt> update vitfeatureextractor to use image_utils instead of torchvision </cmt> <cmt> remove torchvision and add pillow </cmt> <cmt> small docs improvement </cmt>",add vision transformer and vitfeatureextractor
4329,"<desc> closes #23970 tests added / passed passes git diff upstream/master -u -- ""*.py"" | flake8 --diff whatsnew entry </desc> <cmt> gh23970 added test-case that causes bug 23970 </cmt> <cmt> gh 23970 fixed source of the bug </cmt> <cmt> bug would have impacted any groupby function that relied on observed </cmt> <cmt> if it were true </cmt> <cmt> gh23970 added relevant docstring to whatsnew </cmt> <iss> groupby observed=true not working for aggregating a column </iss>",fix groupby observed=true when aggregating a column
4330,<desc> adding discussions links for faq - general as per 1785 updates to existing questions section i re-arranged the orders of few titles like dont use redux to appear together omitted this discussion  @markerikson please review </desc> <cmt> adding few more discussions links to faq-general - when should i use redux </cmt> <cmt> removing duplicate link </cmt>,faq general - discussion links for when should i use redux
4331,"<desc> this rule replaces incorrect yum commands, such as yum isntall into yum install and yum remove into yum uninstall. </desc> <cmt> - add skeleton code for yum_invalid_operation.py </cmt> <cmt> - add test for rule/yum_invalid_operation </cmt> <cmt> add: mocker for subprocess.popen. </cmt> <cmt> fix: invalid yum_operations. </cmt> <cmt> fix: added missing fixtures. </cmt> <cmt> add: yum_invalid_operation implementation. </cmt> <cmt> add: enabled_by_default variable for rules/yum_invalid_operation. </cmt> <cmt> update readme. </cmt>",support for yum invalid commands.
4332,"<desc> if a promise is rejected, we should halt the entire application, which we can do by just calling abort(), which is more concise. this changed the return code from 1 to 7 in that case, which required updating a test. </desc> <cmt> simplify node unhandledrejection-handling code </cmt> <cmt> update test </cmt>",simplify the node rejection handling code
4333,"<desc> when using ss through another socks5 proxy, the prev version still resolves ss server's domain name locally. this could lead to wrong results. this patch allow proxy module to resolve domain name itself. -socks5 proxy: just pass the domain name to socks5 proxy server cuz the protocol support domain name. -direct connect: still resolves locally and synchronously. </desc> <cmt> let proxy module handle name resolving itself. </cmt> <cmt> fix wrong output in proxyconnecttimer_elapsed. </cmt> <cmt> let socks5 proxy handle server host's domain name. </cmt> <cmt> don't resolve it locally because socks5 support domain name connection. </cmt>",resolving domain name through socks5 proxy
4334,"<desc> since 3b6314c the pretty printer seems to only print trait bounds for ast::ty_path(...)s that have a generics arguments list. that seems wrong, so let's always print them. closes #9253, un-xfails test for #7673. </desc> <cmt> pp: typo in comment </cmt> <cmt> pp: also print bounds in paths with no generic params </cmt> <cmt> since 3b6314c3 the pretty printer seems to only print trait bounds for </cmt> <cmt> ast::ty_path(...)s that have a generics arguments list. that seems </cmt> <cmt> wrong, so let's always print them. </cmt> <cmt> closes #9253, un-xfails test for #7673. </cmt> <iss> pretty printer doesn't preserve built-in trait bounds on trait objects </iss>",pretty-print bounds in paths with no generic params
4335,"<desc> add more default layers!! optimize default layer keycode handling remove rgb twinkling, since not enough firmware space :'( disable split keyboard on viterbi, and make necessary changes (it's a macro pad, so ...) better handle multiple keyboard versions add destiny 2 specific keycodes to ergodox, since must use le monarque add planck rev6 specific code sadly, this misses a lot of my more recent code changes, since i'm using a very customized branch that includes stuff like the expanded startup functionality, custom tapping terms, arm audio fixes, etc. checklist: my code follows the code style of this project. i have read the contributing document. ( </desc> <cmt> proper rules include </cmt> <cmt> minor tweaks </cmt> <cmt> minor tweaks </cmt> <cmt> add desitny 2 swapped layout support </cmt> <cmt> add keycode to keylogger </cmt> <cmt> convert my viterbi keymaps </cmt> <cmt> fix orthodox keyboard </cmt> <cmt> add more default layers </cmt> <cmt> make default layer keycodes more optimized </cmt> <cmt> update gitlab ci yaml file </cmt> <cmt> rev6 cleanup </cmt> <cmt> fix kc_make macro </cmt> <cmt> update gitlab ci yaml file </cmt> <cmt> more gitlab ci changes </cmt> <cmt> one final gitlab ci change </cmt> <cmt> optimize kc_make </cmt> <cmt> reformatting of config </cmt> <cmt> feature creeeeeeep </cmt> <cmt> planck rev6 updates </cmt>",update to drashna keymaps and userspace
4336,"<desc> not sure if this would be useful or not, but i added a text editor that you can use through the file system. you can click a file in the file explorer and it will open a popup that displays the filename (and extension), and the content of the file that's currently there. i've provided screenshots as well. open in the tron-disrupted theme open in the red theme right now, the only kinds of files that can be opened are html, css, javascript, xml, yaml, java, c#, c++ and h, markdown, batch and shell, gdscript (godot engine), json (excludes the themes, keyboards, settings.json, and shortcuts.json), plain text, and log files, though that list can be expanded as needed. in the future, i might try to make the different file types able to be differentiated by their icons, though that's a project for another day. i might also have the text inside the textarea a little bigger, and maybe always white, because the red theme is really hard to read from the default monospace font. lmk if i need to make any changes </desc> <cmt> fix #861 </cmt> <cmt> implement text editor feature - surge </cmt>",implement a text editor feature
4337,<desc> close #46201 and see more discussion in #46203 </desc> <cmt> merge the lastest commits from author </cmt> <cmt> do sync before closeintoreader to make sure we move most of the data to disk outside of the lock </cmt> <cmt> modify comments in translog.rollgeneration </cmt> <cmt> merge latest code from author </cmt> <cmt> merge lastest code from author </cmt> <cmt> trimunreferencedreaders: move sync translog operation outside writelock </cmt> <cmt> trimunreferencedreaders: move try-catch inside if condition </cmt> <cmt> merge latest code from author </cmt> <cmt> merge from author </cmt> <cmt> trimunreferencedreaders: sync before write lock </cmt> <iss> optimize translog writing by move sync outside writelock in trimunreferencedreaders </iss>,sync before trimunreferencedreaders to improve index preformance
4338,"<desc> during the development of atom-typescript they have added quite a bit of methods to atom's definitions, but the changes haven't been yet committed to this repo. i've added all their changes to atom.d.ts to this pull request and fixed the indentation a bit. </desc> <cmt> add atom.d.ts from atom-typescript project </cmt> <cmt> merge with the main branch </cmt> <cmt> add typings for igrammar interface </cmt> <cmt> fix indentation </cmt>",add definitions to atom.d.ts from atom-typescript
4339,"<desc> contains two commits. please rebase and merge. revert 02bd71d. please read comment here. add a small code snippet to bring back the functionality of the importer. </desc> <cmt> revert "" fixed importer duplicate detection for posts"" </cmt> <cmt> refs #8717 </cmt> <cmt> - we decided to not changing the current importer behaviour </cmt> <cmt> - no slug duplication detection means, importing posts can result in duplicates </cmt> <cmt> fixed import test: post duplication detection within a file to import </cmt> <cmt> no issue </cmt> <cmt> - with </cmt> <cmt> - this commit simply adds a small code snippet to reflect the importer behaviour </cmt> <cmt> 1) duplicate slugs *within* a file are getting ignored </cmt> <cmt> 2) existing posts in the database and posts to import with the same slug, result in duplicates </cmt> <cmt> further improvements regarding duplication detection will happen via #8717. </cmt>",duplicate slugs revert && bring back importer behaviour for detection
4340,<desc> this adds the ignorecase option for createredirect in gatsby v2 (from #29714) but in a backwards compatible (without the breaking change of setting it to true by default) </desc> <cmt> add ignorecase option for createredirect and support it in client side navigation </cmt> <cmt> add typings for ignorecase </cmt> <cmt> update packages/gatsby/src/redux/actions/public.js </cmt> <cmt> prepare lowercased redirects at build time </cmt> <cmt> add tests </cmt> <cmt> remove only </cmt> <cmt> switch to o(1) maps </cmt> <cmt> update navigate as well </cmt> <cmt> update packages/gatsby/index.d.ts </cmt> <cmt> update packages/gatsby/cache-dir/navigation.js </cmt>,ignore case option in create redirect
4341,<desc> this pr fixes #7169 </desc> <cmt> :lipstick: let -> const </cmt> <cmt> maintain undo stack across text model disposal / creation </cmt> <cmt> add more tests </cmt> <cmt> add textchange </cmt> <cmt> remove itextchange </cmt> <cmt> split into lines manually </cmt> <cmt> reduce usage of ivalidatededitoperation.lines </cmt> <cmt> remove ivalidatededitoperation.lines </cmt> <cmt> maintain version id across model disposing </cmt> <cmt> compress consecutive edits in undo stack </cmt> <cmt> reduce memory usage </cmt> <iss> keep undo stack between file close and reopen </iss>,keep undo-redo stack elements after a model is disposed
4342,"<desc> description: very small change, but it irritated me that mpd would write ""none"" when playing songs without meta-data. changes: mpd now shows file_name instead of ""none"" as the ""media_title"" i only changed five lines in the mpd component, and, as far as i could see, no test-cases exist in regards to the mpd component, so i didn't actually run any test cases to make sure it works, but you are very welcome to test it locally in case i made some massive mistake, however it should work. </desc> <cmt> added support for filename </cmt> <cmt> used the getter instead - minor mistake </cmt>",mpd now uses the filename if song doesn't have metadata
4343,"<desc> fix for #4357. the issue is that when a dependency (dep a) defined in resolutions (includes dep a, dep b) depends on another resolution (dep b), then it expects to match its own nested dep b to the top level resolution dep b. so the first part of this fix is ""don't run resolutions map check when it's in flat mode"", which is what threw the invariant warning. second part of the fix is that we still want that nested dependency (dep b) of a resolution (dep a) to be resolved correctly. --flat mode solves this by collapsing all versions after the resolver is done. for resolutions, i'm adding a delay queue for requests with resolutions but no manifests found yet so that they will be resolved later. added tests in resolutions </desc> <cmt> add tests </cmt> <cmt> add delay queue </cmt> <cmt> ignore resolutions when installed in flat mode </cmt>",fix #4357 - allow resolver to delay resolutions for nested dependencies
4344,"<desc> remove some useless configure for bindings-generator of lua in the ini files of  tools/tolua, because these classes and functions no longer exist. </desc> <cmt> update comment for lua </cmt> <cmt> remove useless configure for bindings-generator of lua </cmt>",update comments of lua and remove some useless configure for bindings-generator of lua
4345,"<desc> fix three different issues that affect the runtime's demangling to metadata: the verification enabled by swift_enable_mangled_name_verification could cause the metadata machinery to deadlock, because demangling to metadata was requesting complete metadata when it only needs abstract metadata. our mangling of generic parameter references, which are used in generic requirements (that runtime conditional conformances and runtime demangling depend on), could end up colliding, causing corrupted metadata. the resolution of generic parameter references used an older function signature for associated type access functions, which meant that we were calling it incorrectly... and getting bogus results. fixes sr-7553 / rdar://problem/39769906 </desc> <cmt> [irgen] move the protocol conformance descriptor builder. </cmt> <cmt> place it right there next to the witnesstablebuilder, because the </cmt> <cmt> two should be the same thing. nfc </cmt> <cmt> [runtime] only request abstract metadata when demangling to metadata. </cmt> <cmt> when swift_enable_mangled_name_verification is set, we would end up </cmt> <cmt> deadlocking when we encounter a metadata cycle. the demangling code only </cmt> <cmt> requires abstract metadata, because at most it needs type identity and </cmt> <cmt> filling in the type arguments of generics. update clients of </cmt> <cmt> _gettypebymangledname to assert the kind of metadata they require. </cmt> <cmt> [mangling] mangle protocol names in assoc-type-paths. </cmt> <cmt> the mangling of associated type paths was only adding the names of </cmt> <cmt> associated types, and not their enclosing protocols. this led to mangling </cmt> <cmt> collisions that could lead to corrupted metadata. in the standard </cmt> <cmt> library, for example, the generic requirements for the </cmt> <cmt> unicode _parsingiterator in the standard library ended up encoding an </cmt> <cmt> access to sequence.element rather than iteratorprotocol.element due </cmt> <cmt> to the mangling conflict. </cmt> <cmt> part of sr-7553 / rdar://problem/39769906. </cmt> <cmt> [runtime] replace outdated signature for associated type access functions. </cmt> <cmt> the resolution of generic parameter references, which is used for </cmt> <cmt> checking generic requirements at runtime, was written in terms of an </cmt> <cmt> outdated signature for associated type access functions that did not </cmt> <cmt> account for the metadatarequest parameter or metadataresponse result. </cmt> <cmt> use the existing associatedtypeaccessfunction typedef instead. </cmt> <cmt> fixes sr-7553 / rdar://problem/39769906 </cmt>",fixes for demangling to metadata
4346,"<desc> used to report td-1523, now able to display taos memory leak issues with python script. the check-in also included a so called valgrind error suppression file, generated using the valgrind tool itself, as the python run time does not always clean up all the memory it uses. without such suppression file, the taos related memory leaks will be hard to see among the numerous python memory leaks. </desc> <cmt> enhanced crash_gen tool to test against multiple databases concurrently, getting ready to test against clusters </cmt> <cmt> added tracking of longest time-consuming query in crash_gen tool </cmt> <cmt> half way through enabling read/write check </cmt> <cmt> added limited data verification to crash_gen tool, with -v option </cmt> <cmt> minor crash_gen tweaks </cmt> <cmt> adjusted crash_gen tool directory structure, added valgrind suppression file to expose client side memory leaks </cmt>",added valgrind memory check to crash_gen tool
4347,"<desc> i took the provided (from other repo) download script which should now work on all platforms. tested all steps, removed some errors and inconsistencies, updated to rtm. i am not exactly sure about that iis - asp.net core registration step, if that may also improved over time. the dotnetcore download script left my nano in inconsistent state, if there is not enough disk space. i added a tiny check. for ref see also #2089 </desc> <cmt> first changes to nano aspnetcore tutorial </cmt> <cmt> further updates </cmt> <cmt> update </cmt> <cmt> docs and download script updated </cmt>",updated nano server tutorial to rtm and dotnet-download script.
4348,"<desc> the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. </desc> <cmt> types for react-tag-autocomplete pkg </cmt> <cmt> add ts version to declarion file </cmt> <cmt> fix test errors </cmt>",add types for react-tag-autocomplete pkg
4349,"<desc> this change integrates deno_ast and lazily caches/reuses swc ast in the language server. i've yet to come up with a benchmark i think is worthwhile to have... given that swc is already so fast this change is only noticable with very large files. i would say this isn't so much a performance improvement, but rather just a refactoring. closes #11345 closes #11854 </desc> <cmt> documentdata - change bytes to source and make source and line_index non-optional </cmt> <cmt> committing what i've done for backup purposes. </cmt> <cmt> more work. for some reason the lsp tests fail when running together now though... </cmt> <cmt> improve lazy_init, but now i just found out about once_cell crate. that would be better. </cmt> <cmt> format. </cmt> <cmt> use oncecell for lazy initialization as we already have it as a dependency and it may be added to the standard library in the future. </cmt> <cmt> creating sourcefiletext. </cmt> <cmt> extract out documentsource for reuse in sources. </cmt> <cmt> format. </cmt> <cmt> move lineindex into documentsource. </cmt> <cmt> version bump, but looks like changes are required because of deno_doc changes </cmt> <cmt> format </cmt> <iss> lsp: cache swc asts </iss> <iss> support class static blocks (stage-3) </iss>",use deno_ast and cache swc asts
4350,<desc> import_role: mention version from which behavior changed fix typos in documentation s/default/defaults/ s/the the/the/ s/functinality/functionality/ import_role doc and 2.7 porting guide ansible version 2.7 </desc> <cmt> [doc] fix some typos </cmt> <cmt> [doc] import_role: mention version from which behavior changed </cmt>,mention version from which behavior changed and fix some typos
4351,"<desc> this pr fixes # #112755 </desc> <cmt> debug: do not render checkmark in view menu for the debug console </cmt> <cmt> ignore focus when toggling debug console visibility </cmt> <cmt> render ""debug console"" action after a separator </cmt>",debug console view menu action polish
4352,<desc> description: this pr makes the following enhancements to the prometheus component: all metrics gain an additional domain label. a new state_change metric is incremented for each state change. checklist: local tests pass with tox. your pr cannot be merged unless tests pass </desc> <cmt> add domain to labels </cmt> <cmt> count state changes </cmt>,add domain to labels and count state changes to prometheus
4353,"<desc> network/aos/aos_* ansible version ansible 2.3.0 (fix-aos-login cc16903b5c) last updated 2017/02/20 13:08:42 (gmt -700) config file = configured module search path = default w/o overrides change the name of the session variable in all aos_* modules to align with that is returned by aos_login module </desc> <cmt> fix examples to make session variable homogeneous across all modules </cmt> <cmt> fix parameter name in example, template not design_template </cmt>",network/aos - fix doc for session information
4354,"<desc> others docs add cpp_extension  en doc, zh doc: #31187 </desc> <cmt> split cxx/nvcc compile flags </cmt> <cmt> enhance input argument check </cmt> <cmt> rename extra_cflags into extrac_cxx_flags </cmt> <cmt> add name checking in setup </cmt> <cmt> fix test_dispatch failed </cmt> <cmt> fix word typo and rm usless import statement </cmt> <cmt> refine import statement </cmt> <cmt> fix unittest failed </cmt> <cmt> fix cuda flags error </cmt> <cmt> add cpp_extension en doc </cmt>",[customop]add cpp_extension  en doc
4355,"<desc> these two objectives are closely related. i included (1) a note in the docs to be explicit that xentropy is necessary when labels are not binary and (2) an example that makes the relationship clear for users coming at this with ""logistic regression"" in mind. non-binary labels are a trivial extension of binary ones under log-loss; any lack of generalization is in the code (i.e. enforcing int instead of float) rather than mathematical, and so it would be understandable if a user mistakenly tried applying binary with non-binary labels. if fact i was doing this in r and have yet to identify why it gave reasonable results and did not crash (while binary with non-binary labels does crash in python). </desc> <cmt> note the relationship between binary and xentropy in the docs and provide an example that compares them </cmt>",clarify relationship between xentropy and binary
4356,"<desc> as part of rust-lang/miri#1814, i realized that we currently allow deallocating immutable allocations. this pr fixes that, and also adds some new apis that are required to still support the existing miri backtrace support. r? @oli-obk </desc> <cmt> reject deallocation of read-only allocations </cmt> <cmt> avoid redundant immutability check </cmt>",fix deallocation of immutable allocations
4357,<desc> contribution to fix part of #15440 ensuring logisticregression methods pass numpy doc validation </desc> <cmt> densify docstring fixed </cmt> <cmt> fixed predict_log_proba doc </cmt> <cmt> sparsify docstring update </cmt> <cmt> set_params partial fix </cmt> <cmt> logit score docstring fix </cmt> <cmt> logistic predict_proba docstring fix </cmt> <cmt> logistic get_params docstring fixed </cmt> <cmt> logistic predict docstring fixes </cmt> <cmt> logistic set_params docstring fix </cmt>,doc numpy doc validations to logisticregression
4358,"<desc> fixes #30850. this pr improves the error messages shown when the return/instance type of the function/class used as a jsx component is not assignable to jsx.element or jsx.elementclass. i thought the problem is not specific to void; referring to constructor function is always misleading. so this pr fully replaces the current message with new ones. the new error messages refer to return type, instance type or element type depending on what call signatures the component has. also this pr changes the span of the error from whole jsx element to only its tag name so the actual cause is clearer. example source code: namespace jsx { export interface element { type: 'element'; } export interface elementclass { type: 'element-class'; } } const functioncomponent = () => ({ type: 'string', }); class classcomponent { foo = ""bar"" } const mixedcomponent = math.random() ? functioncomponent : classcomponent; const elem1 = <functioncomponent />; const elem2 = <classcomponent />; const elem3 = <mixedcomponent />; current behavior (ts3.5.3): test.tsx:20:15 - error ts2605: jsx element type '{ type: string; }' is not a constructor function for jsx elements. type '{ type: string; }' is missing the following properties from type 'element': props, key 20 const elem1 = <functioncomponent />; ~~~~~~~~~~~~~~~~~~~~~ test.tsx:21:15 - error ts2605: jsx element type 'classcomponent' is not a constructor function for jsx elements. type 'classcomponent' is missing the following properties from type 'elementclass': type, render, context, setstate, and 4 more. 21 const elem2 = <classcomponent />; ~~~~~~~~~~~~~~~~~~ test.tsx:22:15 - error ts2605: jsx element type 'classcomponent | { type: string; }' is not a constructor function for jsx elements. type 'classcomponent' is not assignable to type 'element | elementclass'. type 'classcomponent' is not assignable to type 'elementclass'. 22 const elem3 = <mixedcomponent />; ~~~~~~~~~~~~~~~~~~ found 3 errors. new behavior: index.tsx:20:16 - error ts2774: 'functioncomponent' cannot be used as a jsx component. its return type '{ type: string; }' is not a valid jsx element. types of property 'type' are incompatible. type 'string' is not assignable to type '""element""'. 20 const elem1 = <functioncomponent />; ~~~~~~~~~~~~~~~~~ index.tsx:21:16 - error ts2774: 'classcomponent' cannot be used as a jsx component. its instance type 'classcomponent' is not a valid jsx element. property 'type' is missing in type 'classcomponent' but required in type 'elementclass'. 21 const elem2 = <classcomponent />; ~~~~~~~~~~~~~~ index.tsx:6:5 6     type: 'element-class'; ~~~~ 'type' is declared here. index.tsx:22:16 - error ts2774: 'mixedcomponent' cannot be used as a jsx component. its element type 'classcomponent | { type: string; }' is not a valid jsx element. type 'classcomponent' is not assignable to type 'element | elementclass | null'. type 'classcomponent' is not assignable to type 'elementclass'. 22 const elem3 = <mixedcomponent />; ~~~~~~~~~~~~~~ found 3 errors. alternative option i chose to separate the new error messages to two parts: one is 'componentname' cannot be used as a jsx component.and the other isits return type '{0}' is not a valid jsx element.or similar. another option is to merge them into one so the new message is'componentname' cannot be used as a jsx component because its return type '{0}' is not a valid jsx element. i chose the first option for two reasons. one is that in this way we get the same top-level error message for all the three cases. the other reason is that the merged message, especially the part before '{0}', is too long. the cause of the error (the return type {0} in this case) should be reachable as easily as possible. this is achieved by chaining two messages as done in this pr. </desc> <cmt> new diagnostic message for wrong jsx function component </cmt> <cmt> component and mixed type </cmt> <cmt> fix existing tests </cmt> <cmt> add new test for jsx component return type error </cmt> <iss> better error message for void-returning functions used as jsx elements </iss>",improve error message for invalid return type of jsx component
4359,"<desc> backport of #17538. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed offscreen rendering not working with viz compositor. </desc> <cmt> fix: make osr work with viz compositor </cmt> <cmt> fix: update osr patch </cmt> <cmt> fix: update patch again </cmt> <cmt> fix: update viz_osr.patch for macos </cmt> <cmt> fix: gn check warnings </cmt> <cmt> chore: no need to change softwareoutputdevicewinproxy </cmt> <cmt> chore: add check in case we missed something </cmt> <cmt> fix: consider scale factor when compare size </cmt> <cmt> fix: make gpu osr work </cmt> <cmt> fix: autofill popups with osr </cmt> <cmt> chore: use unix line ending for osr_video_consumer </cmt> <cmt> chore: code is already in defined(os_macosx) </cmt> <cmt> fix: share same osr implementation on macos </cmt> <cmt> this should also fix the crash when there is navigation on macos. </cmt> <cmt> test: osr window should not crash after navigation </cmt> <cmt> fix: make osr work on mac properly </cmt> <cmt> fix: software osr on windows </cmt> <cmt> fix: software osr on linux </cmt> <cmt> fix: split local surface id allocation into two </cmt> <cmt> fix: update patch for 5-0-x </cmt> <cmt> fix: patch and update videoconsumer to report proper damage_rect </cmt>",port osr code to new viz compositor codepath (backport: 5-0-x)
4360,"<desc> cache results from queries that use scripts if they use only deterministic api calls.  nondeterministic api calls are marked in the whitelist with the @nondeterministic annotation.  examples are math.random() and new date(). refs: #49466 </desc> <cmt> notes </cmt> <cmt> wiring from whitelist annotations to painlessmethod and painlessconstructor </cmt> <cmt> generate isresultdeterministic </cmt> <cmt> formatting, parseint is deterministic </cmt> <cmt> wip </cmt> <cmt> update whitelist based on core-infra discussion, map/set iterators are ok </cmt> <cmt> revert linkedhashmap </cmt> <cmt> maxaggregatortests.testdontcachescripts -> testcachescripts </cmt>",cache script results if deterministic
4361,"<desc> this is the default set of keys used for jupyter notebooks, so it makes sense to support it too. note: this is only applied to the query source page i tried to make 314eae5 from the queryeditor component, without success. the main idea is not to have an annoying behavior of a new line added when you press shift+enter and the query cannot execute. -- -- </desc> <cmt> add shift+enter for query execution </cmt> <cmt> keep shortcut keys when execute button is disabled </cmt>",add shift+enter shortcut for query execution
4362,"<desc> pull request to discuss what to do with the tests for internal eas (and one of the comments i still had in #21160) basically, i would keep the tests/extension/.. only for subclassing the base extension array test suite, and any array-specific functionality is tested in tests/arrays/.. (eg closed attribute for intervalarray, specific arithmetic behaviour for integerarray, ...) this means that when adding a test related to eas, we need to think about: is this testing something that is applicable to all eas? (-> add a base test to tests/extension/base so this is tested for all internal and external eas) or is this testing something specific to a particular ea? (-> add a test in tests/array/eatype/..) of course often there can be some ambiguity here. main reason that i would split them is that over time, we probably add a lot of ea-type-specific tests, and then keeping the general ones mixed with the specific ones will make it only confusing / hard to see what is going on. drawback is of course that it is tested in two places. in practice what i propose in this pr, is also what we already do for categorical at the moment: categorical has its own tests in tests/arrays/categorical (and probably also some in indexes and frame, ..), but we also run the base extension tests for categorical in tests/extension/ </desc> <cmt> split integer array tests in tests/arrays/integer and tests/extension/integer </cmt> <cmt> split interval tests </cmt>",restructure internal extension arrays tests (split between /arrays and /extension)
4363,"<desc> this pr targets the next branch and not master you've included links to relevant issues, if any with #issue_num </desc> <cmt> update readme 1 (manpages) </cmt> <cmt> update 2 (create config.md) </cmt> <cmt> readme update final 1 </cmt> <cmt> rename to config </cmt> <cmt> readme update final 2 </cmt> <cmt> small update </cmt>",update to documentation by  raz0rr-two
4364,"<desc> related to #19939 build on the top of #19939 add the couple of equation for gaussianprocessregression and a link to the book. add small optimizations: do not check for finite inputs when solving systems; use original paper algorithm and only solve triangular system instead of two triangular system </desc> <cmt> use cho_solve when return_std=true </cmt> <cmt> resolving doc issue </cmt> <cmt> responding to comments, primarily style changes, minor revisions to test. </cmt> <cmt> doc add reference gpr and equation as comments </cmt>",ehn/doc add reference and small optimizations for gpr
4365,<desc> backports the following 1.4 fixes to 1.3 since atom is still on that version and hitting these bugs: #7209 #7980 / </desc> <cmt> add failing spec for missing remote properties </cmt> <cmt> only set members when members exist </cmt> <cmt> allow spec to be run multiple times in same runner </cmt> <cmt> don't load remote properties until they are accessed </cmt> <cmt> guard against missing members in setobjectmembers </cmt>,backport 1.4 remote module bug fixes to 1.3
4366,"<desc> this is the 2nd try for #14631 to verify this: git clean -fdx to clean all local files. run tensorflow/contrib/lite/download_dependencies.sh verify that you see ""download_dependencies.sh completed successfully"", so the script is completed. verify these files are downloaded to correct location. tensorflow/contrib/lite/examples/ios/camera/data/labels.txt tensorflow/contrib/lite/examples/ios/camera/data/mobilenet_quant_v1_224.tflite tensorflow/contrib/lite/examples/ios/simple/data/labels.txt tensorflow/contrib/lite/examples/ios/simple/data/mobilenet_v1_1.0_224.tflite run tensorflow/contrib/lite/build_ios_universal_lib.sh to verify the library can be built. </desc> <cmt> fix: can't build tflite after running download_dependencies.sh. </cmt> <cmt> root cause: the script downloads files for building tflite for ios </cmt> <cmt> example. it writes to downloads/ directory and conflicts with the </cmt> <cmt> visibility rule ""**/*"" in build </cmt> <cmt> retain lite/examples/ios/camera/data directory in git. </cmt> <cmt> fix some bugs in download_dependencies.sh </cmt> <cmt> * handle both the cases that the zip file has nested directories </cmt> <cmt> or not. </cmt> <cmt> * always use curl since wget sometimes has certificate problem </cmt> <cmt> in some mac machines. </cmt>",fixing download_dependencies.sh bugs for generating tflite ios exmaples
4367,"<desc> this pr is a follow up of #43691 and prevents a restart of the dispatcher if it has been configured without fault-tolerance. failing to do so will lead to a perpetual stream of warn messages on a dispatcher restart and unnecessarily extend the testing time without an immediate exit. @aaudiber until the enhancements are implemented to handle such scenarios (as per our discussion), this will help us in handling the upcoming test cases. </desc> <cmt> prevent restart of dispatcher w/o fault-tolerance </cmt> <cmt> remove unused import </cmt>","prevent restart of the dispatcher server w/o fault-tolerance, in the test bed"
4368,"<desc> this pr fix #4181, re-benchmark maskrcnn, and provide valid link of ckpt and log for cityscapes. </desc> <cmt> fix #4181, invalid link in readme for maskrcnn cityscapes </cmt> <cmt> undo </cmt> <cmt> fix #4181, invalid link in readme for maskrcnn cityscapes </cmt> <cmt> updating performance </cmt> <iss> invalid link in readme of cityscape </iss>",fix invalid ckpt and log in maskrcnn cityscapes
4369,"<desc> requirements for adding, changing, or removing a feature fill out the template below. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. the pull request must contribute a change that has been endorsed by the maintainer team. see details in the template below. the pull request must update the test suite to exercise the updated functionality. for guidance, please see  after you create the pull request, all status checks must be pass before a maintainer reviews your contribution. for more details, please see  issue or rfc endorsed by atom's maintainers #20071 also notarization is going to be a hard requirements this year. description of the change enabling codesign in hardened runtime and adding notarization as part of atom's build process. alternate designs we could migrate our code signing from cli to electron packager (oxs-sign) and implement the notarization using cli, if you will call that an alternate design, since it's all doing the exact same thing. possible drawbacks verification process the notarization didn't throw in the build process (in other words it succeeded). all ci tests are green. i downloaded the artifact (atom-mac.zip) and checked the codesign and notarization using cli. i didn't get the ""can't be open because apple can't check it for malicious software"" (check the screenshots for before and after) and i was able to launch the app normally without having to go to the download location and right-click to open the app. i did a smoke test by running the application to make sure basic io functions work (open a file, save a file, re-open a file). before: after: release notes </desc> <cmt> upgrade macos image to majove to support notarization </cmt> <cmt> enable hardend runtime for code-signing on mac </cmt> <cmt> pass notarization credentials to the build script </cmt> <cmt> add notarization to the build process </cmt> <cmt> remove entitlement allow-jit and downgrade ci to macos 10.13 </cmt> <cmt> attempt fix by adding more entitlements </cmt> <cmt> correct entitlements path </cmt> <cmt> try to make the app work with minimum entitlements </cmt>",add notarization to macos app
4370,"<desc> what this pr does / why we need it: in order to get istio to work with cockraochdb the port cannot be named grpc or it routes all traffic back to the pod that originated the traffic. to fix this, i broke the external and internal ports out into their own settings and then i can set the external port to be called grpc (thus leveraging istio's grpc featureset) and the internal port can be called something besides grpc (causing istio to use the protocol type field rather than infer from the name field.) i did some other tweaks along the way such as adding service annotations so i can use google internal load balancer for the service. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # </desc> <cmt> [stable/cockroachdb] added support for node selector </cmt> <cmt> merge with charts/stable </cmt> <cmt> [stable/cockroachdb] added support for node selector </cmt> <cmt> [stable/cockroachdb] added support for node selector </cmt> <cmt> new chart stable/mysqldump (#4069) </cmt> <cmt> * new chart stable/mysqldump </cmt> <cmt> helps the user backup mysql databases to a persistent volume </cmt> <cmt> * use chart.name from tpl, add app label </cmt> <cmt> * add app/chart fixes to mysqldump-cron.yaml </cmt> <cmt> * fix backofflimit in wrong place. </cmt> <cmt> * exit gracefully if db host not specified </cmt> <cmt> merge with charts/stable </cmt> <cmt> chart version bump </cmt> <cmt> added external and internal grpc port as options. also added options to customize service annotations. need these for istio config. </cmt> <cmt> updated readme to include values i added. reformatted the table so it reads pretty in plaintext </cmt>",breakout ports to support istio
4371,"<desc> the use_lstm flag is currently broken for tf and was never supported for pytorch. this pr fixes this issue by providing a modelv1-free lstm wrapper around any default model (tf or torch). add two short learning tests for ppo w/ use_lstm=true. closes issue #8615 closes issue #8615 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) </desc> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip. </cmt> <cmt> wip and lint. </cmt>",fix use_lstm flag for modelv2 (w/o modelv1 wrapping) and add it for pytorch.
4372,"<desc> fixes #6998 i added a deprecationwarning to the class dpgmm and the class vbgmm, as well as public functions in dpgmm.py i added tests for these warnings in test_dpgmm.py @tguillemot </desc> <cmt> added deprecation warnings to dpgmm and vbgmm classes and other functions </cmt> <cmt> modified/added functions test_digamma, test_gammaln, test_log_normalize to check for deprecationwarning </cmt> <cmt> added functions to test for deprecated warnings for wishart_log_det, wishart_logz </cmt> <cmt> updated test_log_normalize function </cmt> <cmt> fixed spelling in deprecationwarning for class dpgmm and </cmt> <cmt> added deprecationwarning tests test_dpgmm_deprecation, test_vbgmm_deprecation </cmt> <cmt> added blank lines near inserted deprecatedwarnings to conform to pep8 </cmt> <cmt> added blank lines and deleted trailing whitespace for pep8 </cmt> <cmt> removed 'import warnings' since not used </cmt> <iss> warning about dpgmm and vbgmm on instantiation </iss>",adds deprecationwarning to dpgmm and vbgmm
4373,"<desc> this pr fix the last consistency issue between scorer and metrics function (#2096). i finally chose to rename auc_score to roc_auc_score, auc_scorer to roc_auc_scorer to have the most explicit name. i haven't created an alias since i think that is a bad option. </desc> <cmt> enh more explicit name for auc + consistency for scorer, fix #2096 </cmt> <cmt> doc put the narrative documentation of roc_curve and roc_auc_score in one place </cmt> <cmt> fix search and replace misstake </cmt>",fix consistency issue between scorer string and metrics function
4374,"<desc> for changelog. remove if this is non-significant change. short description (up to few sentences): forbid to specify a database when creating a temporary table. in previous versions, the database was silently ignored. </desc> <cmt> forbid to specify a database when creating a temporary table [#clickhouse-4294] </cmt> <cmt> added a test </cmt>",forbid temporary tables in database
4375,"<desc> this is the last pr in the cable testing series (at least for now ): added channel_test generator added connection_test to app generator (unless --skip-action-cable) added ""action cable testing"" guides to ""testing"" guides added ""action cable testing"" as a highlight to 6.0 release notes (finally) added changelog entry. / </desc> <cmt> add channel test generator </cmt> <cmt> add connection_test to app generator </cmt>",add action cable testing guides and generators
4376,"<desc> rebased version of #4090 waiting for travis to be green, and merging </desc> <cmt> enh precomputed is now a valid metric for 'brute' </cmt> <cmt> enh precomputed is now a valid metric for 'auto' neighbors </cmt> <cmt> also, handle radius_neighbors case identically to kneighbors for precomputed </cmt> <cmt> enh support precomputed neighbors where query != index </cmt> <cmt> tst precomputed matrix validation in correct place </cmt> <cmt> fix add _pairwise and test to neighborsbase </cmt> <cmt> doc fix up parameter descriptions </cmt> <cmt> fix broken rebase </cmt> <cmt> tst add test for precomputed metric and x=none at predict </cmt> <cmt> fix test with invalid input; simplify dbscan precomputed </cmt> <cmt> tst: use a local random state </cmt>",support metric='precomputed' in nearest neighbors [rebased version of #4090]
4377,<desc> edward is a library for probabilistic programming with a few thousand active users. gpflow is a library for gaussian processes which also has an active user base. </desc> <cmt> add edward to community page </cmt> <cmt> add gpflow to community page </cmt>,add edward and gpflow to community page
4378,"<desc> bump go.d.plugin version to v0.24.0 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.24.0 </desc> <cmt> packaging: bump go.d version to v0.24.0 </cmt> <cmt> packaging: update go.d checksums </cmt>",update go.d.plugin version to v0.24.0
4379,"<desc> after refactoring the queries to make them parsable on the coordinating note and adding serialization and equals/hashcode capability to them. so far shapebuilders nested inside queries were still transported as a byte array that needs to be parsed later on the shard receiving the query. to be able to also serialize geo shapes this way, we also need to make all the implementations of shapebuilder implement writable. this pr adds this to pointbuilder, circlebuilder and envelopebuilder and also adds tests for serialization, equality and hashcode. relates to #14416 </desc> <cmt> geo: make shapebuilders implement writable </cmt> <cmt> we recently refactored the queries to make them parsable on the </cmt> <cmt> coordinating note and adding serialization and equals/hashcode </cmt> <cmt> capability to them. so far shapebuilders nested inside queries </cmt> <cmt> were still transported as a byte array that needs to be parsed </cmt> <cmt> later on the shard receiving the query. to be able to also </cmt> <cmt> serialize geo shapes this way, we also need to make all the </cmt> <cmt> implementations of shapebuilder implement writable. </cmt> <cmt> this pr adds this to pointbuilder and also adds tests for </cmt> <cmt> serialization, equality and hashcode. </cmt> <cmt> making circlebuilder writable and adding equals/hashcode </cmt>","make pointbuilder, circlebuilder & envelopebuilder implement writable"
4380,<desc> the following commits contain some cosmetic changes and a few optimisations for sql queries (specifically where conditions) generated for / used by smartplaylists. basically the idea is to use (not) exists instead of in because (not exists) can exit/break after the first match/mismatch in the subquery whereas in will always run the full sub-query. as verified by @popcornmix in </desc> <cmt> smartplaylists: use simple where conditions instead of expensive in statements </cmt> <cmt> smartplaylists: cosmetics in sql queries </cmt> <cmt> smartplaylists: use select distinct in sql sub-queries </cmt> <cmt> smartplaylists: replace sql in with sql exists in where conditions </cmt>,optimisations for sql queries generated for smartplaylists
4381,"<desc> this pr changes the existing base64_cipher.py with an easy to understand script that explains how the base64 algorithm works under the hood. the solution is not necessarily faster, but i believe it will help people understand how the algorithm works and why it is possible to use base64 in steganography to conceal the existence of a piece of data. further more, i believe the base64_cipher.py name can be misleading as base64 is considered an encoding, and not a cipher. improve an existing solution. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. </desc> <cmt> rename base64_cipher.py to base64_encoding.py </cmt> <cmt> edit base64_encoding.py </cmt>",replace base64_cipher.py with an easy to understand version
